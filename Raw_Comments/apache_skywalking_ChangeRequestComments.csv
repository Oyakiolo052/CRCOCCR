Pull,Path,Diff_hunk,Comment
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/api/Tracing.java,"@@ -21,4 +24,34 @@ public static String getTraceId() {
 
         return formatTraceId(spanData.getTraceId());
     }
+
+
+    /**
+     * Get the latest span of current trace.
+     *
+     * @return span. if it exists, or null
+     */
+    public static Span getLatestSpan() {","[{'comment': 'rename to `getActiveSpan` or `getCurrentSpan`. There is no guarantee about, the top span of stack, is the latest span.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/api/Tracing.java,"@@ -21,4 +24,34 @@ public static String getTraceId() {
 
         return formatTraceId(spanData.getTraceId());
     }
+
+
+    /**
+     * Get the latest span of current trace.
+     *
+     * @return span. if it exists, or null
+     */
+    public static Span getLatestSpan() {
+        Span spanData = CurrentThreadSpanStack.peek();
+        return spanData;
+    }
+
+    /**
+     * set tag to the latest span of current trace
+     *
+     * @param tags tags map
+     */
+    public static void setTags2CurrentSpan(Map<String, String> tags) {","[{'comment': 'The method should declare as\r\n`public static void setTag(Span span, String tagKey, String tagValue)`', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/api/Tracing.java,"@@ -21,4 +24,34 @@ public static String getTraceId() {
 
         return formatTraceId(spanData.getTraceId());
     }
+
+
+    /**
+     * Get the latest span of current trace.
+     *
+     * @return span. if it exists, or null
+     */
+    public static Span getLatestSpan() {
+        Span spanData = CurrentThreadSpanStack.peek();
+        return spanData;
+    }
+
+    /**
+     * set tag to the latest span of current trace
+     *
+     * @param tags tags map
+     */
+    public static void setTags2CurrentSpan(Map<String, String> tags) {
+        Span spanData = CurrentThreadSpanStack.peek();
+        if (spanData == null) {
+            return;
+        }
+
+        spanData.addTags(tags);
+    }
+
+
+    public static void putBaseSpan(ContextData contextData){","[{'comment': ""`BaseSpan` is a strange name. It's something like `prevSpanContext`, maybe should be a new type, which contains: traceid, parentSpanId. No need be a `span`."", 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/context/CurrentThreadSpanStack.java,"@@ -42,7 +42,22 @@ public static Span pop() {
         return nodes.get().pop();
     }
 
+    public static void putBaseSpan(Span baseSpan){
+        if (nodes.get() == null){
+            nodes.set(new SpanNodeStack());
+        }
+
+        nodes.get().initBaseSpan(baseSpan);
+    }
+
     static class SpanNodeStack {
+
+        /**
+         * This {@link SpanNode} represent the base span of all the next spans. the trace id and
+         * the level id will base on it.
+         */
+        private SpanNode baseSpan = null;","[{'comment': 'Rename, and add a new type.', 'commenter': 'wu-sheng'}, {'comment': '`RefContext` may be a good name.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/context/CurrentThreadSpanStack.java,"@@ -85,6 +105,10 @@ private void listPush(SpanNode spanNode) {
             spans.add(spans.size(), spanNode);
         }
 
+        private void initBaseSpan(Span baseSpan){","[{'comment': 'Rename to `initRefContext`.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/model/Identification.java,"@@ -29,41 +34,63 @@ public String getBusinessKey() {
         return businessKey;
     }
 
+    public long getStartTime() {
+        if (startTime == 0){
+            return System.currentTimeMillis();
+        }
+        return startTime;
+    }
+
+    public Map<String, String> getTags() {
+        if (tags == null){
+            return Collections.EMPTY_MAP;
+        }
+        return tags;
+    }
 
     public static IdentificationBuilder newBuilder() {
         return new IdentificationBuilder();
     }
 
     public static class IdentificationBuilder {
-        private Identification sendData;
+        private Identification identification;
 
         IdentificationBuilder() {
-            sendData = new Identification();
+            identification = new Identification();
         }
 
         public Identification build() {
-            return sendData;
+            return identification;
         }
 
         public IdentificationBuilder viewPoint(String viewPoint) {
-            sendData.viewPoint = viewPoint;
+            identification.viewPoint = viewPoint;
             return this;
         }
 
         public IdentificationBuilder businessKey(String businessKey) {
-            sendData.businessKey = businessKey;
+            identification.businessKey = businessKey;
             return this;
         }
 
         public IdentificationBuilder spanType(IBuriedPointType spanType) {
             if (StringUtil.isEmpty(spanType.getTypeName())) {
                 throw new IllegalArgumentException(""Span Type name cannot be null"");
             }
-            sendData.spanTypeDesc = spanType.getTypeName();
-            sendData.callType = spanType.getCallType().toString();
+            identification.spanTypeDesc = spanType.getTypeName();
+            identification.callType = spanType.getCallType().toString();
             return this;
         }
 
+        public IdentificationBuilder startTime(long startTime) {
+            identification.startTime = startTime;
+            return this;
+        }
+
+        public IdentificationBuilder tags(Map<String, String> tags) {","[{'comment': 'Method should be `tag`, instead of `tags`.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/util/ContextGenerator.java,"@@ -42,12 +42,12 @@ private static Span getSpanFromThreadLocal(Identification id) {
         // 2 校验Context，Context是否存在
         if (parentSpan == null) {
             // 不存在，新创建一个Context
-            span = new Span(id.getViewPoint());
+            span = new Span(id.getViewPoint(), id.getStartTime(), id.getTags());","[{'comment': '`Tags`, as a  constructor parameters, is an improper thing.\r\n`Span` should have a method, named `tag()`', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/SkyWalkingSpanActivation.java,"@@ -0,0 +1,84 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing;
+
+import com.a.eye.skywalking.plugin.interceptor.ConstructorInterceptPoint;
+import com.a.eye.skywalking.plugin.interceptor.InstanceMethodsInterceptPoint;
+import com.a.eye.skywalking.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Map;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.noneOf;
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+
+/**
+ * Created by xin on 2017/1/16.
+ */
+public class SkyWalkingSpanActivation extends ClassInstanceMethodsEnhancePluginDefine {
+    @Override
+    protected String enhanceClassName() {
+        return ""com.a.eye.skywalking.toolkit.opentracing.SkywalkingSpan"";
+    }
+
+    @Override
+    protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[]{
+                new ConstructorInterceptPoint() {
+                    @Override
+                    public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                        return takesArguments(String.class, long.class, Map.class);
+                    }
+
+                    @Override
+                    public String getConstructorInterceptor() {
+                        return ""com.a.eye.skywalking.toolkit.activation.opentracing"" +
+                                "".SpanConstructorInterceptor"";
+                    }
+                }
+        };
+    }
+
+    @Override
+    protected InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[]{
+                new InstanceMethodsInterceptPoint() {
+                    @Override
+                    public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                        return named(""setTag"");
+                    }
+
+                    @Override
+                    public String getMethodsInterceptor() {
+                        return ""com.a.eye.skywalking.toolkit.activation.opentracing"" +
+                                "".SkywalkingSpanTagsInterceptor"";","[{'comment': 'All interceptor name should refactor:\r\n`com.a.eye.skywalking.toolkit.activation.opentracing.SkywalkingSpanTagsInterceptor`\r\nrefactor to\r\n`com.a.eye.skywalking.toolkit.activation.opentracing.span.SetTagInterceptor`\r\n\r\nAll other methods should stay in the same principle.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/SkyWalkingSpanTagsInterceptor.java,"@@ -0,0 +1,36 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing;
+
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Created by xin on 2017/1/16.
+ */
+public class SkyWalkingSpanTagsInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
+       Map<String, String> tags = (Map<String, String>) context.get(""tags"");","[{'comment': '`tags` and something like this, should be a constant.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/api/Tracing.java,"@@ -21,4 +21,35 @@ public static String getTraceId() {
 
         return formatTraceId(spanData.getTraceId());
     }
+
+
+    /**
+     * Get the latest span of current trace.
+     *
+     * @return span. if it exists, or null
+     */
+    public static Span getCurrentSpan() {
+        Span spanData = CurrentThreadSpanStack.peek();
+        return spanData;
+    }
+
+    /**
+     * Set the tag to span
+     *
+     * @param span","[{'comment': 'Comments: the span will be tagged with the given key and value pair.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/api/Tracing.java,"@@ -21,4 +21,35 @@ public static String getTraceId() {
 
         return formatTraceId(spanData.getTraceId());
     }
+
+
+    /**
+     * Get the latest span of current trace.","[{'comment': 'Get the current span', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/api/Tracing.java,"@@ -21,4 +21,35 @@ public static String getTraceId() {
 
         return formatTraceId(spanData.getTraceId());
     }
+
+
+    /**
+     * Get the latest span of current trace.
+     *
+     * @return span. if it exists, or null
+     */
+    public static Span getCurrentSpan() {
+        Span spanData = CurrentThreadSpanStack.peek();
+        return spanData;
+    }
+
+    /**
+     * Set the tag to span
+     *
+     * @param span
+     * @param tagKey key of tag
+     * @param tagValue value of tag
+     */
+    public static void tag(Span span, String tagKey, String tagValue) {
+        span.tag(tagKey, tagValue);
+    }
+
+    /**
+     * set the ref context
+     *
+     * @param contextData context data
+     */
+    public static void putRefContext(ContextData contextData){","[{'comment': ""`putRefContext`'s parameter should be `RefContext` type. And caller in charge of converting `ContextData` to `RefContext`.\r\n\r\n`putRefContext` should be named `set...` or `init...`. There is nothing to put here."", 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/context/CurrentThreadSpanStack.java,"@@ -42,7 +43,20 @@ public static Span pop() {
         return nodes.get().pop();
     }
 
+    public static void putRefContext(RefContext refContext) {
+        if (nodes.get() == null){","[{'comment': 'Why need null-point check?', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/model/BaseSpan.java,"@@ -0,0 +1,8 @@
+package com.a.eye.skywalking.model;
+
+public class BaseSpan extends Span {","[{'comment': 'Why still have the `BaseSpan`?', 'commenter': 'wu-sheng'}, {'comment': 'will delete it', 'commenter': 'ascrutae'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/model/Span.java,"@@ -197,4 +201,16 @@ public byte getStatusCode() {
     public String getExceptionStack() {
         return exceptionStack;
     }
+
+    public void addTags(Map<String, String> tags) {","[{'comment': 'Why need `addTags`?  `tag` should enough. It causes confuse either using`addTags` or `tag`, and whether have diff-performances.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetOperationNameInterceptor.java,"@@ -1,22 +1,22 @@
-package com.a.eye.skywalking.toolkit.activation.opentracing;
+package com.a.eye.skywalking.toolkit.activation.opentracing.span.interceptor;
 
 import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
 import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
 import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
 
 /**
- * Created by wusheng on 2017/1/3.
+ * Created by xin on 2017/1/16.
  */
-public class ExtractCrossProcessByteBufferContextInterceptor implements InstanceMethodsAroundInterceptor {
+public class SpanSetOperationNameInterceptor implements InstanceMethodsAroundInterceptor {
     @Override
     public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
-
+        context.set(""operationName"", interceptorContext.allArguments()[0]);","[{'comment': '`""operationName""` is still not a constant.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java,"@@ -0,0 +1,36 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.span.interceptor;
+
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * Created by xin on 2017/1/16.
+ */
+public class SpanSetTagInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
+       Map<String, String> tags = (Map<String, String>) context.get(""tags"");","[{'comment': 'Still not a constant', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/tracer/interceptor/ExtractCrossProcessByteBufferContextInterceptor.java,"@@ -0,0 +1,36 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.tracer.interceptor;
+
+import com.a.eye.skywalking.api.Tracing;
+import com.a.eye.skywalking.model.ContextData;
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
+
+import javax.net.ssl.StandardConstants;
+
+/**
+ * Created by wusheng on 2017/1/3.
+ */
+public class ExtractCrossProcessByteBufferContextInterceptor implements InstanceMethodsAroundInterceptor {","[{'comment': ""Use the same naming principle. It's an activation, or a interceptor.\r\n\r\nThe principle is here:\r\n* Use interceptor, when it's a plugin.\r\n* Use activation, when it actives an application toolkit."", 'commenter': 'wu-sheng'}, {'comment': ""Use the same naming principle. It's an activation, or a interceptor.\r\n\r\nThe principle is here:\r\n* Use interceptor, when it's a plugin.\r\n* Use activation, when it actives an application toolkit."", 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/SkyWalkingSpanActivation.java,"@@ -0,0 +1,80 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.span;
+
+import com.a.eye.skywalking.plugin.interceptor.ConstructorInterceptPoint;
+import com.a.eye.skywalking.plugin.interceptor.InstanceMethodsInterceptPoint;
+import com.a.eye.skywalking.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Map;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.noneOf;
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+
+/**
+ * Created by xin on 2017/1/16.
+ */
+public class SkyWalkingSpanActivation extends ClassInstanceMethodsEnhancePluginDefine {
+    @Override
+    protected String enhanceClassName() {
+        return ""com.a.eye.skywalking.toolkit.opentracing.SkywalkingSpan"";
+    }
+
+    @Override
+    protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[]{
+                new ConstructorInterceptPoint() {
+                    @Override
+                    public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                        return takesArguments(String.class, long.class, Map.class);
+                    }
+
+                    @Override
+                    public String getConstructorInterceptor() {
+                        return ""com.a.eye.skywalking.toolkit.activation.opentracing.span.interceptor.SpanConstructorInterceptor"";","[{'comment': 'Not the correct name again. No need of `Span` prefix, it already existed in package name.\r\nMaybe `com.a.eye.skywalking.toolkit.activation.opentracing.span.interceptor.Constructor`? or use other principles.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/tracer/interceptor/ExtractCrossProcessByteBufferContextInterceptor.java,"@@ -0,0 +1,36 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.tracer.interceptor;
+
+import com.a.eye.skywalking.api.Tracing;
+import com.a.eye.skywalking.model.ContextData;
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.nio.ByteBuffer;
+import java.nio.charset.Charset;
+
+import javax.net.ssl.StandardConstants;
+
+/**
+ * Created by wusheng on 2017/1/3.","[{'comment': 'Comment code by the actual author name.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/tracer/interceptor/ExtractCrossProcessTextMapContextInterceptor.java,"@@ -0,0 +1,47 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.tracer.interceptor;
+
+import com.a.eye.skywalking.api.Tracing;
+import com.a.eye.skywalking.invoke.monitor.RPCServerInvokeMonitor;
+import com.a.eye.skywalking.model.ContextData;
+import com.a.eye.skywalking.model.Identification;
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.util.Iterator;
+import java.util.Map;
+
+import io.opentracing.propagation.TextMap;
+
+/**
+ * Created by wusheng on 2017/1/3.","[{'comment': 'Comment code by the actual author name.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/tracer/interceptor/ExtractCrossProcessTextMapContextInterceptor.java,"@@ -0,0 +1,47 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.tracer.interceptor;
+
+import com.a.eye.skywalking.api.Tracing;
+import com.a.eye.skywalking.invoke.monitor.RPCServerInvokeMonitor;
+import com.a.eye.skywalking.model.ContextData;
+import com.a.eye.skywalking.model.Identification;
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.util.Iterator;
+import java.util.Map;
+
+import io.opentracing.propagation.TextMap;
+
+/**
+ * Created by wusheng on 2017/1/3.
+ */
+public class ExtractCrossProcessTextMapContextInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
+        // Do nothing
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, Object ret) {
+        TextMap textMap = (TextMap) interceptorContext.allArguments()[0];
+        Iterator<Map.Entry<String, String>> iterator = textMap.iterator();
+        while (iterator.hasNext()){
+            Map.Entry<String, String> entry = iterator.next();
+            if (""SkyWalking-TRACING-NAME"".equals(entry.getKey())){
+                try {
+                    Tracing.putBaseSpan(new ContextData(entry.getValue()));","[{'comment': 'Still `putBaseSpan`, check your code carefully.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/tracer/interceptor/ExtractCrossProcessTextMapContextInterceptor.java,"@@ -0,0 +1,47 @@
+package com.a.eye.skywalking.toolkit.activation.opentracing.tracer.interceptor;
+
+import com.a.eye.skywalking.api.Tracing;
+import com.a.eye.skywalking.invoke.monitor.RPCServerInvokeMonitor;
+import com.a.eye.skywalking.model.ContextData;
+import com.a.eye.skywalking.model.Identification;
+import com.a.eye.skywalking.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.util.Iterator;
+import java.util.Map;
+
+import io.opentracing.propagation.TextMap;
+
+/**
+ * Created by wusheng on 2017/1/3.
+ */
+public class ExtractCrossProcessTextMapContextInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
+        // Do nothing
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, Object ret) {
+        TextMap textMap = (TextMap) interceptorContext.allArguments()[0];
+        Iterator<Map.Entry<String, String>> iterator = textMap.iterator();
+        while (iterator.hasNext()){
+            Map.Entry<String, String> entry = iterator.next();
+            if (""SkyWalking-TRACING-NAME"".equals(entry.getKey())){","[{'comment': '`SkyWalking-TRACING-NAME` need be a constant.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/context/CurrentThreadSpanStack.java,"@@ -42,7 +43,20 @@ public static Span pop() {
         return nodes.get().pop();
     }
 
+    public static void initRefContext(RefContext refContext) {
+        if (nodes.get() == null){
+            nodes.set(new SpanNodeStack());
+        }
+        nodes.get().initRefContext(refContext);
+    }
+
     static class SpanNodeStack {
+
+        /**
+         * This {@link RefContext} contain the trace context from another processor.
+         */
+        private RefContext refContext = null;","[{'comment': 'This field should set to `null`, when `spans` is empty after `pop` invokes.', 'commenter': 'wu-sheng'}, {'comment': 'If not, maybe cause a leak when the next transaction begins.', 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/model/Identification.java,"@@ -29,41 +35,63 @@ public String getBusinessKey() {
         return businessKey;
     }
 
+    public long getStartTime() {
+        if (startTime == 0){
+            return System.currentTimeMillis();","[{'comment': ""This is an identification, only be used in create span. Why need `getStartTime`?\r\nAnd even need this, why not assign `this.startTime` = 'return-value'?"", 'commenter': 'wu-sheng'}]"
81,skywalking-sniffer/skywalking-api/src/main/java/com/a/eye/skywalking/model/Identification.java,"@@ -29,41 +35,63 @@ public String getBusinessKey() {
         return businessKey;
     }
 
+    public long getStartTime() {
+        if (startTime == 0){
+            return System.currentTimeMillis();
+        }
+        return startTime;
+    }
+
+    public Map<String, String> getTags() {","[{'comment': 'Why need `get`?', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,202 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class{@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     *
+     * @param context            instance context, a class instance only has one {@link EnhancedClassInstanceContext} instance.
+     * @param interceptorContext method context, includes class name, method name, etc.
+     * @param result             change this result, if you want to truncate the method.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(invoker, invocation));
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+
+        Tags.URL.set(span, generateRequestURL(invoker, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.SPAN_LAYER.asRPCFramework(span);
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     *
+     * @param context            instance context, a class instance only has one {@link EnhancedClassInstanceContext} instance.
+     * @param interceptorContext method context, includes class name, method name, etc.
+     * @param ret                the method's original return value.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>
+     *
+     * @return operation name
+     */
+    private static String generateOperationName(Invoker<?> invoker, Invocation invocation) {
+        StringBuilder operationName = new StringBuilder();
+        operationName.append(invoker.getUrl().getPath());","[{'comment': 'Multi invocations about `invoker.getUrl()`, it may be a performance leak.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,202 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class{@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     *
+     * @param context            instance context, a class instance only has one {@link EnhancedClassInstanceContext} instance.
+     * @param interceptorContext method context, includes class name, method name, etc.
+     * @param result             change this result, if you want to truncate the method.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(invoker, invocation));
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+
+        Tags.URL.set(span, generateRequestURL(invoker, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.SPAN_LAYER.asRPCFramework(span);
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     *
+     * @param context            instance context, a class instance only has one {@link EnhancedClassInstanceContext} instance.
+     * @param interceptorContext method context, includes class name, method name, etc.
+     * @param ret                the method's original return value.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>
+     *
+     * @return operation name
+     */
+    private static String generateOperationName(Invoker<?> invoker, Invocation invocation) {
+        StringBuilder operationName = new StringBuilder();
+        operationName.append(invoker.getUrl().getPath());
+        operationName.append(""."" + invocation.getMethodName() + ""("");
+        for (Class<?> classes : invocation.getParameterTypes()) {
+            operationName.append(classes.getSimpleName() + "","");
+        }
+
+        if (invocation.getParameterTypes().length > 0) {
+            operationName.delete(operationName.length() - 1, operationName.length());
+        }
+
+        operationName.append("")"");
+
+        return operationName.toString();
+    }
+
+    /**
+     * Generate request url.
+     * The request url may be like this <code>dubbo://127.0.0.1:20880/com.a.eye.skywalking.plugin.test.Test.test(String)</code>
+     *
+     * @return request url
+     */
+    private static String generateRequestURL(Invoker<?> invoker, Invocation invocation) {
+        StringBuilder requestURL = new StringBuilder();
+        requestURL.append(invoker.getUrl().getProtocol() + ""://"");
+        requestURL.append(invoker.getUrl().getHost());
+        requestURL.append("":"" + invoker.getUrl().getPort() + ""/"");","[{'comment': 'Three `invoker.getUrl()` invocations. same as above.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/tomcat-7.x-8.x-plugin/src/main/java/com/a/eye/skywalking/plugin/tomcat78x/TomcatInterceptor.java,"@@ -0,0 +1,68 @@
+package com.a.eye.skywalking.plugin.tomcat78x;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.api.util.StringUtil;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+/**
+ * {@link TomcatInterceptor} fetch the serialized context data by use {@link HttpServletRequest#getHeader(String)}.","[{'comment': 'Type, `by using`', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/tomcat-7.x-8.x-plugin/src/main/java/com/a/eye/skywalking/plugin/tomcat78x/TomcatInterceptor.java,"@@ -0,0 +1,68 @@
+package com.a.eye.skywalking.plugin.tomcat78x;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.api.util.StringUtil;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+/**
+ * {@link TomcatInterceptor} fetch the serialized context data by use {@link HttpServletRequest#getHeader(String)}.
+ * The {@link com.a.eye.skywalking.trace.TraceSegment#primaryRef} of current trace segment will reference to the trace segment id
+ * of the previous level if the serialized context is not null.
+ */
+public class TomcatInterceptor implements InstanceMethodsAroundInterceptor {
+    public static final String HEADER_NAME_OF_CONTEXT_DATA = ""SKYWALKING_CONTEXT_DATA"";
+    public static final String TOMCAT_COMPONENT = ""Tomcat"";
+
+    /**
+     * The {@link com.a.eye.skywalking.trace.TraceSegment#primaryRef} of current trace segment will reference to the trace segment id
+     * of the previous level if the serialized context is not null.
+     *
+     * @param context            instance context, a class instance only has one {@link EnhancedClassInstanceContext} instance.
+     * @param interceptorContext method context, includes class name, method name, etc.
+     * @param result             change this result, if you want to truncate the method.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
+        Object[] args = interceptorContext.allArguments();
+        HttpServletRequest request = (HttpServletRequest) args[0];
+
+        Span span = ContextManager.INSTANCE.createSpan(request.getRequestURI());
+        Tags.COMPONENT.set(span, TOMCAT_COMPONENT);
+        Tags.URL.set(span, request.getRequestURL().toString());
+        Tags.SPAN_LAYER.asHttp(span);
+
+        String tracingHeaderValue = request.getHeader(HEADER_NAME_OF_CONTEXT_DATA);
+        if (!StringUtil.isEmpty(tracingHeaderValue)) {
+            ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(tracingHeaderValue));
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext, Object ret) {
+        HttpServletResponse response = (HttpServletResponse) interceptorContext.allArguments()[1];
+
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.STATUS_CODE.set(span, response.getStatus());","[{'comment': 'Miss `Tags.ERROR.set`, which based on `response.status`, 200 = false, otherwise true.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/ProviderInterceptor.java,"@@ -0,0 +1,88 @@
+package com.a.eye.skywalking.plugin.motan;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.ConstructorInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.weibo.api.motan.rpc.Request;
+import com.weibo.api.motan.rpc.Response;
+import com.weibo.api.motan.rpc.URL;
+
+/**
+ * Current trace segment will ref the trace segment from previous level if the serialized context data that fetch
+ * from {@link Request#getAttachments()} is not null.
+ *
+ * {@link ProviderInterceptor} intercept all constructor of {@link com.weibo.api.motan.rpc.AbstractProvider} for record
+ * the request url from consumer side.
+ *
+ * @author zhangxin
+ */
+public class ProviderInterceptor implements InstanceConstructorInterceptor, InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name of request url that stored in {@link EnhancedClassInstanceContext#context}
+     */
+    private static final String KEY_NAME_OF_REQUEST_URL = ""REQUEST_URL"";
+
+    /**
+     * The key name that the serialized context data stored in {@link Request#getAttachments()}
+     */
+    private static final String ATTACHMENT_KEY_OF_CONTEXT_DATA = ""contextData"";
+
+    @Override
+    public void onConstruct(EnhancedClassInstanceContext context, ConstructorInvokeContext interceptorContext) {
+        context.set(KEY_NAME_OF_REQUEST_URL, interceptorContext.allArguments()[0]);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        URL url = (URL) context.get(KEY_NAME_OF_REQUEST_URL);
+        if (url != null) {
+            com.weibo.api.motan.rpc.Request request = (com.weibo.api.motan.rpc.Request) interceptorContext.allArguments()[0];
+            Span span = ContextManager.INSTANCE.createSpan(generateViewPoint(url, request));
+            Tags.COMPONENT.set(span, ""Motan"");","[{'comment': ""Don't use literal."", 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/ConsumerInvokeInterceptor.java,"@@ -0,0 +1,93 @@
+package com.a.eye.skywalking.plugin.motan;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.weibo.api.motan.rpc.Request;
+import com.weibo.api.motan.rpc.Response;
+import com.weibo.api.motan.rpc.URL;
+
+/**
+ * {@link ConsumerInvokeInterceptor} create span by fetch request url from {@link EnhancedClassInstanceContext#context} and
+ * transport serialized context data to provider side through {@link Request#setAttachment(String, String)}.
+ *
+ * @author zhangxin
+ */
+public class ConsumerInvokeInterceptor implements InstanceMethodsAroundInterceptor {
+
+    /**
+     * Context name of request url in {@link EnhancedClassInstanceContext#context}
+     */
+    private static final String CONTEXT_NAME_OF_REQUEST_URL = ""REQUEST_URL"";
+
+    /**
+     * Attachment key of the serialized context data
+     */
+    private static final String ATTACHMENT_KEY_OF_CONTEXT_DATA = ""contextData"";
+
+    /**
+     * Motan component
+     */
+    private static final String MOTAN_COMPONENT = ""Motan"";
+
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        URL url = (URL) context.get(CONTEXT_NAME_OF_REQUEST_URL);
+
+        if (url != null) {
+            Request request = (Request) interceptorContext.allArguments()[0];
+
+            Span span = ContextManager.INSTANCE.createSpan(generateOperationName(url, request));
+            Tags.PEER_HOST.set(span, url.getHost());
+            Tags.PEER_PORT.set(span, url.getPort());
+            Tags.COMPONENT.set(span, MOTAN_COMPONENT);
+            Tags.URL.set(span, url.getIdentity());
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            Tags.SPAN_LAYER.asRPCFramework(span);
+
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            request.setAttachment(ATTACHMENT_KEY_OF_CONTEXT_DATA, contextCarrier.serialize());
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Response response = (Response) ret;
+        if (response != null && response.getException() != null) {
+            Span span = ContextManager.INSTANCE.activeSpan();
+            span.log(response.getException());
+            Tags.ERROR.set(span, true);
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        ContextManager.INSTANCE.activeSpan().log(t);
+    }
+
+
+    /**
+     * Generate operation name.
+     *
+     * @return operation name
+     */
+    private static String generateOperationName(URL serviceURI, Request request) {
+        StringBuilder viewPoint = new StringBuilder(serviceURI.getPath());
+        viewPoint.append(""."" + request.getMethodName());
+        viewPoint.append(""("" + request.getParamtersDesc() + "")"");","[{'comment': 'Why mix `StringBuilder` and `+` ?', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/jedis-2.x-plugin/src/main/java/com/a/eye/skywalking/plugin/jedis/v2/JedisMethodInterceptor.java,"@@ -0,0 +1,60 @@
+package com.a.eye.skywalking.plugin.jedis.v2;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.assist.NoCocurrencyAceessObject;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+
+/**
+ * {@link JedisMethodInterceptor} create span and set redis host and redis connection information
+ * from {@link EnhancedClassInstanceContext#context} to span tags.
+ *
+ * @author zhangxin
+ */
+public class JedisMethodInterceptor extends NoCocurrencyAceessObject {
+    /**
+     * The key name that redis connection information in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String KEY_OF_REDIS_CONN_INFO = ""REDIS_CONNECTION_INFO"";
+    /**
+     * The key name that redis host in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String KEY_OF_REDIS_HOSTS = ""KEY_OF_REDIS_HOSTS"";
+
+    @Override
+    public void beforeMethod(final EnhancedClassInstanceContext context, final InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
+        this.whenEnter(context, new Runnable() {
+            @Override
+            public void run() {
+                Span span = ContextManager.INSTANCE.createSpan(context.get(KEY_OF_REDIS_CONN_INFO, String.class) + "" "" + interceptorContext.methodName());
+                Tags.COMPONENT.set(span, ""Redis"");
+                Tags.PEER_HOST.set(span, (String) context.get(KEY_OF_REDIS_HOSTS));
+
+                Tags.SPAN_LAYER.asDB(span);
+                if (interceptorContext.allArguments().length > 0
+                        && interceptorContext.allArguments()[0] instanceof String) {
+                    span.setTag(""operation_key"", (String) interceptorContext.allArguments()[0]);","[{'comment': 'Why use this tag?', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */","[{'comment': 'Execute after {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, when dubbo instrumentation is active. \r\n\r\nCheck {@link Result#getException()} , if not NULL, log the exception and set tag `error=true`.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {","[{'comment': 'Log the throwable, which occurs in Dubbo RPC service.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>.","[{'comment': 'Format operation name.  e.g. com.a.eye.skywalking.plugin.test.Test.test(String)\r\n', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return operation name.
+     */
+    private static String generateOperationName(URL requestURL, Invocation invocation) {","[{'comment': 'Why static method?', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return operation name.
+     */
+    private static String generateOperationName(URL requestURL, Invocation invocation) {
+        StringBuilder operationName = new StringBuilder();
+        operationName.append(requestURL.getPath());
+        operationName.append(""."" + invocation.getMethodName() + ""("");
+        for (Class<?> classes : invocation.getParameterTypes()) {
+            operationName.append(classes.getSimpleName() + "","");
+        }
+
+        if (invocation.getParameterTypes().length > 0) {
+            operationName.delete(operationName.length() - 1, operationName.length());
+        }
+
+        operationName.append("")"");
+
+        return operationName.toString();
+    }
+
+    /**
+     * Generate request url.
+     * The request url may be like this <code>dubbo://127.0.0.1:20880/com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return request url.
+     */
+    private static String generateRequestURL(URL url, Invocation invocation) {
+        StringBuilder requestURL = new StringBuilder();
+        requestURL.append(url.getProtocol() + ""://"");
+        requestURL.append(url.getHost());
+        requestURL.append("":"" + url.getPort() + ""/"");
+        requestURL.append(generateOperationName(url, invocation));
+        return requestURL.toString();
+    }
+
+    /**
+     * Set the serialized context data to the first request param that extend {@link SWBaseBean} of dubbo service.
+     *
+     * @param contextDataStr serialized context data.","[{'comment': '@param contextDataStr {@link ContextCarrier.serialize()}', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return operation name.
+     */
+    private static String generateOperationName(URL requestURL, Invocation invocation) {
+        StringBuilder operationName = new StringBuilder();
+        operationName.append(requestURL.getPath());
+        operationName.append(""."" + invocation.getMethodName() + ""("");
+        for (Class<?> classes : invocation.getParameterTypes()) {
+            operationName.append(classes.getSimpleName() + "","");
+        }
+
+        if (invocation.getParameterTypes().length > 0) {
+            operationName.delete(operationName.length() - 1, operationName.length());
+        }
+
+        operationName.append("")"");
+
+        return operationName.toString();
+    }
+
+    /**
+     * Generate request url.
+     * The request url may be like this <code>dubbo://127.0.0.1:20880/com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return request url.
+     */
+    private static String generateRequestURL(URL url, Invocation invocation) {
+        StringBuilder requestURL = new StringBuilder();
+        requestURL.append(url.getProtocol() + ""://"");
+        requestURL.append(url.getHost());
+        requestURL.append("":"" + url.getPort() + ""/"");
+        requestURL.append(generateOperationName(url, invocation));
+        return requestURL.toString();
+    }
+
+    /**
+     * Set the serialized context data to the first request param that extend {@link SWBaseBean} of dubbo service.
+     *
+     * @param contextDataStr serialized context data.
+     */
+    private static void fix283SendNoAttachmentIssue(Invocation invocation, String contextDataStr) {","[{'comment': 'The second param should be `ContextCarrier`.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbo/DubboInterceptor.java,"@@ -0,0 +1,198 @@
+package com.a.eye.skywalking.plugin.dubbo;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.plugin.dubbox.BugFixActive;
+import com.a.eye.skywalking.plugin.dubbox.SWBaseBean;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.alibaba.dubbo.common.URL;
+import com.alibaba.dubbo.rpc.Invocation;
+import com.alibaba.dubbo.rpc.Invoker;
+import com.alibaba.dubbo.rpc.Result;
+import com.alibaba.dubbo.rpc.RpcContext;
+
+/**
+ * {@link DubboInterceptor} define how to enhance class {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}.
+ * the context data will transport to the provider side by {@link RpcContext#attachments}.but all the version of dubbo framework below 2.8.3
+ * don't support {@link RpcContext#attachments}, we support another way to support it. it is that all request parameters of dubbo service
+ * need to extend {@link SWBaseBean}, and {@link DubboInterceptor} will inject the serialized context data to the {@link SWBaseBean} bean and
+ * extract the serialized context data from {@link SWBaseBean}, or the context data will not transport to the provider side.
+ *
+ * @author zhangxin
+ */
+public class DubboInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String ATTACHMENT_NAME_OF_CONTEXT_DATA = ""contextData"";
+    public static final String DUBBO_COMPONENT = ""Dubbo"";
+
+    /**
+     * <h2>Consumer:</h2>
+     * The serialized context data will inject the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or the serialized context data will inject to the
+     * {@link RpcContext#attachments} for transport to provider side.
+     *
+     * <h2>Provider:</h2>
+     * The serialized context data will extract from the first param that extend {@link SWBaseBean} of dubbo service
+     * if the method {@link BugFixActive#active()} be called. or it will extract from {@link RpcContext#attachments}.
+     * current trace segment will ref if the serialize context data is not null.
+     */
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                             MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        Invoker invoker = (Invoker) arguments[0];
+        Invocation invocation = (Invocation) arguments[1];
+        RpcContext rpcContext = RpcContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        URL requestURL = invoker.getUrl();
+
+        Span span = ContextManager.INSTANCE.createSpan(generateOperationName(requestURL, invocation));
+        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
+        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
+        Tags.PEER_HOST.set(span, requestURL.getHost());
+        Tags.PEER_PORT.set(span, requestURL.getPort());
+        Tags.SPAN_LAYER.asRPCFramework(span);
+
+        if (isConsumer) {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+            ContextCarrier contextCarrier = new ContextCarrier();
+            ContextManager.INSTANCE.inject(contextCarrier);
+            if (!BugFixActive.isActive()) {
+                // context.setAttachment(""contextData"", contextDataStr);
+                // context的setAttachment方法在重试机制的时候并不会覆盖原有的Attachment
+                // 参见Dubbo源代码：“com.alibaba.dubbo.rpc.RpcInvocation”
+                //  public void setAttachmentIfAbsent(String key, String value) {
+                //      if (attachments == null) {
+                //          attachments = new HashMap<String, String>();
+                //      }
+                //      if (! attachments.containsKey(key)) {
+                //          attachments.put(key, value);
+                //      }
+                //  }
+                // 在Rest模式中attachment会被抹除，不会传入到服务端
+                // Rest模式会将attachment存放到header里面，具体见com.alibaba.dubbo.rpc.protocol.rest.RpcContextFilter
+                //invocation.getAttachments().put(""contextData"", contextDataStr);
+                rpcContext.getAttachments().put(ATTACHMENT_NAME_OF_CONTEXT_DATA, contextCarrier.serialize());
+            } else {
+                fix283SendNoAttachmentIssue(invocation, contextCarrier.serialize());
+            }
+        } else {
+            Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+
+            String contextDataStr;
+            if (!BugFixActive.isActive()) {
+                contextDataStr = rpcContext.getAttachment(ATTACHMENT_NAME_OF_CONTEXT_DATA);
+            } else {
+                contextDataStr = fix283RecvNoAttachmentIssue(invocation);
+            }
+
+            if (contextDataStr != null && contextDataStr.length() > 0) {
+                ContextManager.INSTANCE.extract(new ContextCarrier().deserialize(contextDataStr));
+            }
+        }
+    }
+
+    /**
+     * {@link DubboInterceptor#afterMethod(EnhancedClassInstanceContext, InstanceMethodInvokeContext, Object)} be executed after
+     * {@link com.alibaba.dubbo.monitor.support.MonitorFilter#invoke(Invoker, Invocation)}, and it will check {@link Result#getException()} if is null.
+     * current active span will log the exception and set true to the value of error tag if the {@link Result#getException()} is not null.
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+                              Object ret) {
+        Result result = (Result) ret;
+        if (result != null && result.getException() != null) {
+            dealException(result.getException());
+        }
+
+        ContextManager.INSTANCE.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+                                      InstanceMethodInvokeContext interceptorContext) {
+        dealException(t);
+    }
+
+    /**
+     * Active span will log the exception and set current span value of error tag.
+     */
+    private void dealException(Throwable throwable) {
+        Span span = ContextManager.INSTANCE.activeSpan();
+        Tags.ERROR.set(span, true);
+        span.log(throwable);
+    }
+
+    /**
+     * Generate operation name.
+     * the operation name should be like this <code>com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return operation name.
+     */
+    private static String generateOperationName(URL requestURL, Invocation invocation) {
+        StringBuilder operationName = new StringBuilder();
+        operationName.append(requestURL.getPath());
+        operationName.append(""."" + invocation.getMethodName() + ""("");
+        for (Class<?> classes : invocation.getParameterTypes()) {
+            operationName.append(classes.getSimpleName() + "","");
+        }
+
+        if (invocation.getParameterTypes().length > 0) {
+            operationName.delete(operationName.length() - 1, operationName.length());
+        }
+
+        operationName.append("")"");
+
+        return operationName.toString();
+    }
+
+    /**
+     * Generate request url.
+     * The request url may be like this <code>dubbo://127.0.0.1:20880/com.a.eye.skywalking.plugin.test.Test.test(String)</code>.
+     *
+     * @return request url.
+     */
+    private static String generateRequestURL(URL url, Invocation invocation) {
+        StringBuilder requestURL = new StringBuilder();
+        requestURL.append(url.getProtocol() + ""://"");
+        requestURL.append(url.getHost());
+        requestURL.append("":"" + url.getPort() + ""/"");
+        requestURL.append(generateOperationName(url, invocation));
+        return requestURL.toString();
+    }
+
+    /**
+     * Set the serialized context data to the first request param that extend {@link SWBaseBean} of dubbo service.
+     *
+     * @param contextDataStr serialized context data.
+     */
+    private static void fix283SendNoAttachmentIssue(Invocation invocation, String contextDataStr) {
+        for (Object parameter : invocation.getArguments()) {
+            if (parameter instanceof SWBaseBean) {
+                ((SWBaseBean) parameter).setContextData(contextDataStr);
+                return;
+            }
+        }
+    }
+
+    /**
+     * Fetch the serialize context data from the first request param that extend {@link SWBaseBean} of dubbo service.","[{'comment': 'Fetch the context from the first match element (typeof `SWBaseBean`) in {@link invocation#getArguments}. ', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/dubbo-plugin/src/main/java/com/a/eye/skywalking/plugin/dubbox/BugFixActive.java,"@@ -0,0 +1,28 @@
+package com.a.eye.skywalking.plugin.dubbox;
+
+/**
+ * {@link BugFixActive#active} is an flag that present the dubbox version is below 2.8.3,
+ * The version 2.8.3 of dubbox don't support attachment. so skywalking provided another way
+ * to support the function that transport the serialized context data. The way is that
+ * all parameters of dubbo service need to extend {@link SWBaseBean}, {@link com.a.eye.skywalking.plugin.dubbo.DubboInterceptor}
+ * fetch the serialized context data by using {@link SWBaseBean#getContextData()}.
+ *
+ * @author zhangxin
+ */
+public final class BugFixActive {
+
+    private static boolean active = false;
+
+    /**
+     * This method should be call first if the dubbo version is below 2.8.3.","[{'comment': 'Set active status, before startup dubbo services.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/jedis-2.x-plugin/src/main/java/com/a/eye/skywalking/plugin/jedis/v2/JedisMethodInterceptor.java,"@@ -0,0 +1,92 @@
+package com.a.eye.skywalking.plugin.jedis.v2;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.assist.NoCocurrencyAceessObject;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.api.util.StringUtil;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+
+/**
+ * {@link JedisMethodInterceptor} create span and set redis host and redis connection information","[{'comment': 'Comments should stay in logic, not the description of codes flow.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/jedis-2.x-plugin/src/main/java/com/a/eye/skywalking/plugin/jedis/v2/define/JedisClusterInstrumentation.java,"@@ -0,0 +1,97 @@
+package com.a.eye.skywalking.plugin.jedis.v2.define;
+
+import com.a.eye.skywalking.api.plugin.bytebuddy.AllObjectDefaultMethodsMatch;
+import com.a.eye.skywalking.api.plugin.interceptor.ConstructorInterceptPoint;
+import com.a.eye.skywalking.api.plugin.interceptor.InstanceMethodsInterceptPoint;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import com.a.eye.skywalking.plugin.jedis.v2.JedisClusterConstructorWithListHostAndPortArgInterceptor;
+import com.a.eye.skywalking.plugin.jedis.v2.JedisMethodInterceptor;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Set;
+
+import static com.a.eye.skywalking.api.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static net.bytebuddy.matcher.ElementMatchers.any;
+import static net.bytebuddy.matcher.ElementMatchers.not;
+import static net.bytebuddy.matcher.ElementMatchers.takesArgument;
+
+/**
+ * {@link JedisClusterInstrumentation} presents that skywalking will intercept all constructors and methods of {@link redis.clients.jedis.JedisCluster}.
+ * There are two intercept classes to intercept the constructor of {@link redis.clients.jedis.JedisCluster}.
+ * {@link com.a.eye.skywalking.plugin.jedis.v2.JedisClusterConstructorWithHostAndPortArgInterceptor} intercepts all constructor with argument {@link redis.clients.jedis.HostAndPort}
+ * and the other constructor will intercept by class {@link JedisClusterConstructorWithListHostAndPortArgInterceptor}.
+ * {@link JedisMethodInterceptor} will intercept all methods of {@link redis.clients.jedis.JedisCluster}
+ *
+ * @author zhangxin
+ */
+public class JedisClusterInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    /**
+     * {@link redis.clients.jedis.HostAndPort} argument type name
+     */
+    private static final String ARGUMENT_TYPE_NAME = ""redis.clients.jedis.HostAndPort"";
+    /**
+     * Enhance class
+     */
+    private static final String ENHANCE_CLASS = ""redis.clients.jedis.JedisCluster"";
+    /**
+     * Class that intercept all constructors with arg.","[{'comment': 'This comment make no sense. Which methods will be intercepted should be commented on the real class.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/ProviderInterceptor.java,"@@ -0,0 +1,92 @@
+package com.a.eye.skywalking.plugin.motan;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.ConstructorInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.weibo.api.motan.rpc.Request;
+import com.weibo.api.motan.rpc.Response;
+import com.weibo.api.motan.rpc.URL;
+
+/**
+ * Current trace segment will ref the trace segment from previous level if the serialized context data that fetch
+ * from {@link Request#getAttachments()} is not null.
+ *
+ * {@link ProviderInterceptor} intercept all constructor of {@link com.weibo.api.motan.rpc.AbstractProvider} for record
+ * the request url from consumer side.
+ *
+ * @author zhangxin
+ */
+public class ProviderInterceptor implements InstanceConstructorInterceptor, InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name of request url that stored in {@link EnhancedClassInstanceContext#context}
+     */
+    private static final String KEY_NAME_OF_REQUEST_URL = ""REQUEST_URL"";
+
+    /**
+     * The key name that the serialized context data stored in {@link Request#getAttachments()}","[{'comment': 'The {@link Request#getAttachments()} key. It maps to the serialized  {@link ContextCarrier}.', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/ProviderInterceptor.java,"@@ -0,0 +1,92 @@
+package com.a.eye.skywalking.plugin.motan;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.ConstructorInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.weibo.api.motan.rpc.Request;
+import com.weibo.api.motan.rpc.Response;
+import com.weibo.api.motan.rpc.URL;
+
+/**
+ * Current trace segment will ref the trace segment from previous level if the serialized context data that fetch
+ * from {@link Request#getAttachments()} is not null.
+ *
+ * {@link ProviderInterceptor} intercept all constructor of {@link com.weibo.api.motan.rpc.AbstractProvider} for record
+ * the request url from consumer side.
+ *
+ * @author zhangxin
+ */
+public class ProviderInterceptor implements InstanceConstructorInterceptor, InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name of request url that stored in {@link EnhancedClassInstanceContext#context}
+     */
+    private static final String KEY_NAME_OF_REQUEST_URL = ""REQUEST_URL"";
+
+    /**
+     * The key name that the serialized context data stored in {@link Request#getAttachments()}
+     */
+    private static final String ATTACHMENT_KEY_OF_CONTEXT_DATA = ""contextData"";
+    /**
+     * Motan component","[{'comment': ""This comment make no sense. It is likely: \r\n>The 'componet' tag value of Motan RPC framework.\r\n\r\nor\r\n\r\n> A constant for setting the span component name to indicate that it represents a motan client/server span."", 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/ProviderInterceptor.java,"@@ -0,0 +1,92 @@
+package com.a.eye.skywalking.plugin.motan;
+
+import com.a.eye.skywalking.api.context.ContextCarrier;
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.ConstructorInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.weibo.api.motan.rpc.Request;
+import com.weibo.api.motan.rpc.Response;
+import com.weibo.api.motan.rpc.URL;
+
+/**
+ * Current trace segment will ref the trace segment from previous level if the serialized context data that fetch
+ * from {@link Request#getAttachments()} is not null.
+ *
+ * {@link ProviderInterceptor} intercept all constructor of {@link com.weibo.api.motan.rpc.AbstractProvider} for record
+ * the request url from consumer side.
+ *
+ * @author zhangxin
+ */
+public class ProviderInterceptor implements InstanceConstructorInterceptor, InstanceMethodsAroundInterceptor {","[{'comment': 'You should have a naming policy, whether include the component name or not?', 'commenter': 'wu-sheng'}]"
87,skywalking-sniffer/skywalking-sdk-plugin/pom.xml,"@@ -33,6 +33,12 @@
 			<artifactId>skywalking-api</artifactId>
 			<version>3.0-2017</version>
 		</dependency>
+		<dependency>
+			<groupId>com.a.eye</groupId>
+			<artifactId>skywalking-sniffer-mock</artifactId>
+			<version>3.0-2017</version>","[{'comment': 'Why not {project.version}?', 'commenter': 'wu-sheng'}]"
98,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/MotanConsumerInterceptor.java,"@@ -13,37 +15,41 @@
 import com.weibo.api.motan.rpc.URL;
 
 /**
- * {@link MotanConsumerInvokeInterceptor} create span by fetch request url from
- * {@link EnhancedClassInstanceContext#context} and transport serialized context
- * data to provider side through {@link Request#setAttachment(String, String)}.
+ * Current trace segment will ref the trace segment from previous level if the serialized context data that fetch
+ * from {@link Request#getAttachments()} is not null.
+ *
+ * {@link MotanConsumerInterceptor} intercept all constructor of {@link com.weibo.api.motan.rpc.AbstractProvider} for record
+ * the request url from consumer side.
  *
  * @author zhangxin
  */
-public class MotanConsumerInvokeInterceptor implements InstanceMethodsAroundInterceptor {
+public class MotanConsumerInterceptor implements InstanceConstructorInterceptor, InstanceMethodsAroundInterceptor {
 
     /**
-     * Context name of request url in {@link EnhancedClassInstanceContext#context}.
+     * The
      */
-    private static final String CONTEXT_NAME_OF_REQUEST_URL = ""REQUEST_URL"";
+    private static final String KEY_NAME_OF_REQUEST_URL = ""REQUEST_URL"";
 
     /**
-     * Attachment key of the serialized context data.
+     * The {@link Request#getAttachments()} key. It maps to the serialized {@link ContextCarrier}.
      */
     private static final String ATTACHMENT_KEY_OF_CONTEXT_DATA = ""SWTraceContext"";
-
     /**
      * Motan component
      */
     private static final String MOTAN_COMPONENT = ""Motan"";
 
     @Override
+    public void onConstruct(EnhancedClassInstanceContext context, ConstructorInvokeContext interceptorContext) {
+        context.set(KEY_NAME_OF_REQUEST_URL, interceptorContext.allArguments()[1]);
+    }
+
+    @Override
     public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
                              MethodInterceptResult result) {
-        URL url = (URL) context.get(CONTEXT_NAME_OF_REQUEST_URL);
-
+        URL url = (URL) context.get(KEY_NAME_OF_REQUEST_URL);
+        com.weibo.api.motan.rpc.Request request = (com.weibo.api.motan.rpc.Request) interceptorContext.allArguments()[0];","[{'comment': 'Why use full class name? ', 'commenter': 'wu-sheng'}]"
98,skywalking-sniffer/skywalking-sdk-plugin/motan-plugin/src/main/java/com/a/eye/skywalking/plugin/motan/MotanConsumerInterceptor.java,"@@ -13,37 +15,41 @@
 import com.weibo.api.motan.rpc.URL;
 
 /**
- * {@link MotanConsumerInvokeInterceptor} create span by fetch request url from
- * {@link EnhancedClassInstanceContext#context} and transport serialized context
- * data to provider side through {@link Request#setAttachment(String, String)}.
+ * Current trace segment will ref the trace segment from previous level if the serialized context data that fetch","[{'comment': 'Did not understand. This is an interceptor, what is your meaning about `from previous level`.\r\n\r\nI think this class is for tracing a motan service calling.', 'commenter': 'wu-sheng'}]"
132,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/actor/AbstractClusterWorker.java,"@@ -11,18 +11,45 @@
 import org.apache.logging.log4j.Logger;
 
 /**
+ * The <code>AbstractClusterWorker</code> should be implemented by any class whose instances
+ * are intended to provide receive remote message that message will transfer across different jvm","[{'comment': 'The <code>AbstractClusterWorker</code> implementations represent workers, which receive remote messages.', 'commenter': 'wu-sheng'}, {'comment': 'Too long sentence.', 'commenter': 'wu-sheng'}]"
132,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/actor/AbstractClusterWorker.java,"@@ -11,18 +11,45 @@
 import org.apache.logging.log4j.Logger;
 
 /**
+ * The <code>AbstractClusterWorker</code> should be implemented by any class whose instances
+ * are intended to provide receive remote message that message will transfer across different jvm
+ * which running in same server or another address server.
+ * <p>
+ * Usually the implemented class used to receive persistence data or aggregation the metric.","[{'comment': 'Usually, the implementations are doing persistent, or aggregate works.', 'commenter': 'wu-sheng'}]"
132,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/actor/AbstractClusterWorker.java,"@@ -11,18 +11,45 @@
 import org.apache.logging.log4j.Logger;
 
 /**
+ * The <code>AbstractClusterWorker</code> should be implemented by any class whose instances
+ * are intended to provide receive remote message that message will transfer across different jvm
+ * which running in same server or another address server.
+ * <p>
+ * Usually the implemented class used to receive persistence data or aggregation the metric.
+ *
  * @author pengys5
+ * @since feature3.0","[{'comment': '`@since` should only target a version, and `feature3.0` is not a version number, clearly.', 'commenter': 'wu-sheng'}]"
132,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/actor/AbstractClusterWorker.java,"@@ -11,18 +11,45 @@
 import org.apache.logging.log4j.Logger;
 
 /**
+ * The <code>AbstractClusterWorker</code> should be implemented by any class whose instances
+ * are intended to provide receive remote message that message will transfer across different jvm
+ * which running in same server or another address server.
+ * <p>
+ * Usually the implemented class used to receive persistence data or aggregation the metric.
+ *
  * @author pengys5
+ * @since feature3.0
  */
 public abstract class AbstractClusterWorker extends AbstractWorker {
 
+    /**
+     * Constructs a <code>AbstractClusterWorker</code> with the worker role and context.","[{'comment': '- `Construct`, this is sentence, which starts with a verb.\r\n- **an** AbstractClusterWorker', 'commenter': 'wu-sheng'}]"
132,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/actor/AbstractClusterWorker.java,"@@ -11,18 +11,45 @@
 import org.apache.logging.log4j.Logger;
 
 /**
+ * The <code>AbstractClusterWorker</code> should be implemented by any class whose instances
+ * are intended to provide receive remote message that message will transfer across different jvm
+ * which running in same server or another address server.
+ * <p>
+ * Usually the implemented class used to receive persistence data or aggregation the metric.
+ *
  * @author pengys5
+ * @since feature3.0
  */
 public abstract class AbstractClusterWorker extends AbstractWorker {
 
+    /**
+     * Constructs a <code>AbstractClusterWorker</code> with the worker role and context.
+     *
+     * @param role           The responsibility of worker in cluster, more than one workers can have
+     *                       same responsibility which use to provide load balancing ability.","[{'comment': 'If multi-workers are for load balance, they should be more likely called worker instance. Meaning, each worker have multi instances.', 'commenter': 'wu-sheng'}]"
132,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/actor/AbstractClusterWorker.java,"@@ -11,18 +11,45 @@
 import org.apache.logging.log4j.Logger;
 
 /**
+ * The <code>AbstractClusterWorker</code> should be implemented by any class whose instances
+ * are intended to provide receive remote message that message will transfer across different jvm
+ * which running in same server or another address server.
+ * <p>
+ * Usually the implemented class used to receive persistence data or aggregation the metric.
+ *
  * @author pengys5
+ * @since feature3.0
  */
 public abstract class AbstractClusterWorker extends AbstractWorker {
 
+    /**
+     * Constructs a <code>AbstractClusterWorker</code> with the worker role and context.
+     *
+     * @param role           The responsibility of worker in cluster, more than one workers can have
+     *                       same responsibility which use to provide load balancing ability.
+     * @param clusterContext See {@link ClusterWorkerContext}
+     * @param selfContext    See {@link LocalWorkerContext}
+     */
     protected AbstractClusterWorker(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
+    /**
+     * Receive message","[{'comment': 'What is the relationship between `Receive message` and `allocateJob`?', 'commenter': 'wu-sheng'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/pom.xml,"@@ -0,0 +1,52 @@
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+  <modelVersion>4.0.0</modelVersion>
+	<parent>
+		<artifactId>skywalking-sdk-plugin</artifactId>
+		<groupId>com.a.eye</groupId>
+		<version>3.0.1-2017</version>
+	</parent>
+
+	<artifactId>skywalking-mongodb-plugin</artifactId>
+	<packaging>jar</packaging>
+
+	<name>mongodb-plugin</name>
+	<url>http://maven.apache.org</url>
+
+	<properties>
+		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>","[{'comment': 'The indentation should be 4 chars. e.g.\r\n```java\r\n\t<properties>\r\n\t\t<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>\r\n\t</properties>\r\n```\r\n\r\nbtw, @ascrutae @pengys5 , we should provide a `style-check` file and a `format` file to avoid this situation.', 'commenter': 'wu-sheng'}, {'comment': '+1 @ascrutae ', 'commenter': 'peng-yongsheng'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBMethodInterceptor.java,"@@ -0,0 +1,139 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import java.util.List;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.mongodb.bulk.DeleteRequest;
+import com.mongodb.bulk.InsertRequest;
+import com.mongodb.bulk.UpdateRequest;
+import com.mongodb.bulk.WriteRequest;
+import com.mongodb.operation.CountOperation;
+import com.mongodb.operation.CreateCollectionOperation;
+import com.mongodb.operation.CreateIndexesOperation;
+import com.mongodb.operation.CreateViewOperation;
+import com.mongodb.operation.DeleteOperation;
+import com.mongodb.operation.DistinctOperation;
+import com.mongodb.operation.FindAndDeleteOperation;
+import com.mongodb.operation.FindAndReplaceOperation;
+import com.mongodb.operation.FindAndUpdateOperation;
+import com.mongodb.operation.FindOperation;
+import com.mongodb.operation.GroupOperation;
+import com.mongodb.operation.InsertOperation;
+import com.mongodb.operation.ListCollectionsOperation;
+import com.mongodb.operation.MapReduceToCollectionOperation;
+import com.mongodb.operation.MapReduceWithInlineResultsOperation;
+import com.mongodb.operation.MixedBulkWriteOperation;
+import com.mongodb.operation.UpdateOperation;
+
+/**
+ * {@link MongoDBMethodInterceptor} intercept method of {@link com.mongodb.Mongo#execute(ReadOperation, ReadPreference)}
+ * or {@link com.mongodb.Mongo#execute(WriteOperation)}. record the mongoDB host, operation name and the key of the operation.
+ *
+ * @author baiyang
+ */
+public class MongoDBMethodInterceptor implements InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name that MongoDB host in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_HOST = ""MONGODB_HOST"";","[{'comment': 'Why `protected`? Do you have a subclass?', 'commenter': 'wu-sheng'}, {'comment': '+1', 'commenter': 'peng-yongsheng'}, {'comment': 'ok, i will turn it into a default', 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBMethodInterceptor.java,"@@ -0,0 +1,139 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import java.util.List;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.mongodb.bulk.DeleteRequest;
+import com.mongodb.bulk.InsertRequest;
+import com.mongodb.bulk.UpdateRequest;
+import com.mongodb.bulk.WriteRequest;
+import com.mongodb.operation.CountOperation;
+import com.mongodb.operation.CreateCollectionOperation;
+import com.mongodb.operation.CreateIndexesOperation;
+import com.mongodb.operation.CreateViewOperation;
+import com.mongodb.operation.DeleteOperation;
+import com.mongodb.operation.DistinctOperation;
+import com.mongodb.operation.FindAndDeleteOperation;
+import com.mongodb.operation.FindAndReplaceOperation;
+import com.mongodb.operation.FindAndUpdateOperation;
+import com.mongodb.operation.FindOperation;
+import com.mongodb.operation.GroupOperation;
+import com.mongodb.operation.InsertOperation;
+import com.mongodb.operation.ListCollectionsOperation;
+import com.mongodb.operation.MapReduceToCollectionOperation;
+import com.mongodb.operation.MapReduceWithInlineResultsOperation;
+import com.mongodb.operation.MixedBulkWriteOperation;
+import com.mongodb.operation.UpdateOperation;
+
+/**
+ * {@link MongoDBMethodInterceptor} intercept method of {@link com.mongodb.Mongo#execute(ReadOperation, ReadPreference)}
+ * or {@link com.mongodb.Mongo#execute(WriteOperation)}. record the mongoDB host, operation name and the key of the operation.
+ *
+ * @author baiyang
+ */
+public class MongoDBMethodInterceptor implements InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name that MongoDB host in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_HOST = ""MONGODB_HOST"";
+
+    /**
+     * The key name that MongoDB port in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_PORT = ""MONGODB_PORT"";
+
+    private static final String MONGODB_COMPONENT = ""MongoDB"";
+    
+    @Override
+    public void beforeMethod(final EnhancedClassInstanceContext context,
+            final InstanceMethodInvokeContext interceptorContext, final MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        OperationInfo operationInfo = this.getReadOperationInfo(arguments[0]);
+        Span span = ContextManager.createSpan(""MongoDB/"" + operationInfo.getMethodName());
+        Tags.COMPONENT.set(span, MONGODB_COMPONENT);
+        Tags.DB_TYPE.set(span, MONGODB_COMPONENT);
+        Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+        Tags.SPAN_LAYER.asDB(span);
+        Tags.DB_STATEMENT.set(span, operationInfo.getMethodName() + "" "" + operationInfo.getFilter());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+            Object ret) {
+        Span span = ContextManager.activeSpan();
+        Tags.PEER_HOST.set(span, context.get(MONGODB_HOST, String.class));
+        Tags.PEER_PORT.set(span, (Integer) context.get(MONGODB_PORT));
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+            InstanceMethodInvokeContext interceptorContext) {
+        ContextManager.activeSpan().log(t);
+    }
+
+    /**
+     *  Convert ReadOperation interface or WriteOperation interface to the implementation class.
+     *  Get the method name and filter info.
+     */
+    @SuppressWarnings(""rawtypes"")
+    private OperationInfo getReadOperationInfo(Object obj) {
+        if (obj instanceof CountOperation) {
+            return new OperationInfo(ReadMethod.COUNT.getName(), ((CountOperation) obj).getFilter().toString());","[{'comment': 'Can you demonstrate the value for me? I found out you set it as part of statement. Maybe you can give us a snapshot about the span detail of Mongdb span.', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng  Here is some snapshots about the span detail of Mongdb span.\r\n1、Find method：\r\n![find](https://cloud.githubusercontent.com/assets/20091216/25138744/e985574e-248d-11e7-9253-0ee9124c148d.jpeg)\r\n2、Insert method:\r\n![insert](https://cloud.githubusercontent.com/assets/20091216/25138753/eda9e772-248d-11e7-951a-9551a310df2e.jpeg)', 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBReadBindingInterceptor.java,"@@ -0,0 +1,46 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.mongodb.ServerAddress;
+import com.mongodb.binding.ReadBinding;
+
+/**
+ * {@link MongoDBReadBindingInterceptor} record the host and port information from {@link EnhancedClassInstanceContext#context},
+ *
+ * @author baiyang
+ */
+public class MongoDBReadBindingInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+            MethodInterceptResult result) {
+        
+    }
+
+    /**
+     * Execute after {@link com.mongodb.Mongo#getReadBinding(ReadPreference)},
+     * record the host and port information
+     */
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+            Object ret) {
+        ReadBinding readBinding = (ReadBinding) ret;
+        ServerAddress serverAddress = readBinding.getReadConnectionSource().getServerDescription().getAddress();
+        String host = serverAddress.getHost();
+        Integer port = serverAddress.getPort();
+        context.set(MongoDBMethodInterceptor.MONGODB_HOST, host);
+        context.set(MongoDBMethodInterceptor.MONGODB_PORT, port);
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+            InstanceMethodInvokeContext interceptorContext) {
+        ContextManager.activeSpan().log(t);","[{'comment': 'As you do not create `span`, I assume, why need log this? What happened if this method goes wrong?', 'commenter': 'wu-sheng'}, {'comment': ""@wu-sheng ，you're right！I will remove this log. In the `MongoDBMethodInterceptor` class ，error message has been recorded.\r\n"", 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBReadBindingInterceptor.java,"@@ -0,0 +1,46 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.mongodb.ServerAddress;
+import com.mongodb.binding.ReadBinding;
+
+/**
+ * {@link MongoDBReadBindingInterceptor} record the host and port information from {@link EnhancedClassInstanceContext#context},
+ *
+ * @author baiyang
+ */
+public class MongoDBReadBindingInterceptor implements InstanceMethodsAroundInterceptor {","[{'comment': 'Can you explain the relationship between `MongoDBMethodInterceptor` and `MongoDBReadBindingInterceptor`. From your pr, set the host/port in `MongoDBReadBindingInterceptor`, and create/stop `span` in `MongoDBMethodInterceptor`, is this always right? Regardless whatever the code style is?', 'commenter': 'wu-sheng'}, {'comment': '+1', 'commenter': 'peng-yongsheng'}, {'comment': 'Process first into the execute method, and then into the  getReadBinding method or getWriteBinding method. the getReadBinding method or getWriteBinding method will return the ReadBinding or WriteBinding .I want to get the Host and Port info from them. Process sequence can be identified, execute-> getReadBinding or getWriteBinding -> other method. MongoDBMethodInterceptor intercept  execute method, So i create span in MongoDBMethodInterceptor, set the host/port in MongoDBReadBindingInterceptor or MongoDBWriteBindingInterceptor.  \r\nAt first, I want to intercept the com.mongodb.Mongo#Mongo(final Cluster cluster, final MongoClientOptions options, final List<MongoCredential> credentialsList) Constructor to get the host/port info, in  the onConstruct method i can get host/port info and set them into EnhancedClassInstanceContext. but i can not get the host/port in the MongoDBMethodInterceptor class from the EnhancedClassInstanceContext. So i must get host/port from getReadBinding method or getWriteBinding method.', 'commenter': 'bai-yang'}, {'comment': 'I got your point, But as mentioned before, https://github.com/wu-sheng/sky-walking/pull/148#discussion_r111891405, I still need you to provide some `Mongo` source code to verify your story. Prevent to  trigger some bugs in the release version.', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng，Here is some code fragments of `MongoDB-Clinet`. The execute methods in `Mongo` class.\r\n\r\n![mongo-exe](https://cloud.githubusercontent.com/assets/20091216/25138451/20d896c6-248d-11e7-92a7-99daba8bfea9.jpeg)\r\n\r\nWhen `execute` method is executed, it is executed `getReadBinding ` or `getWriteBinding` method immediately.', 'commenter': 'bai-yang'}, {'comment': '+1, I think this is enough for verifying your story. Thanks.', 'commenter': 'wu-sheng'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/define/MongoDBInstrumentation.java,"@@ -0,0 +1,72 @@
+package com.a.eye.skywalking.plugin.mongodb.define;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import com.a.eye.skywalking.api.plugin.interceptor.ConstructorInterceptPoint;
+import com.a.eye.skywalking.api.plugin.interceptor.InstanceMethodsInterceptPoint;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+
+/**
+ * {@link MongoDBInstrumentation} presents that skywalking intercepts {@link com.mongodb.Mongo#execute(ReadOperation, ReadPreference)},{@link com.mongodb.Mongo#execute(WriteOperation)}
+ * by using {@link MongoDBMethodInterceptor}.
+ *
+ * @author baiyang
+ */
+public class MongoDBInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_CLASS = ""com.mongodb.Mongo"";
+
+    private static final String MONGDB_READ_BINDING_CLASS = ""com.a.eye.skywalking.plugin.mongodb.MongoDBReadBindingInterceptor"";
+
+    private static final String MONGDB_WRITE_BINDING_CLASS = ""com.a.eye.skywalking.plugin.mongodb.MongoDBWriteBindingInterceptor"";
+
+    private static final String MONGDB_METHOD_INTERCET_CLASS = ""com.a.eye.skywalking.plugin.mongodb.MongoDBMethodInterceptor"";
+
+    @Override
+    protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return null;
+    }
+
+    @Override
+    protected InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[] { new InstanceMethodsInterceptPoint() {
+            @Override
+            public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                return named(""execute"");","[{'comment': 'Do the `execute`, `getReadBinding` and `getWriteBinding` have the certain order of execution?', 'commenter': 'wu-sheng'}, {'comment': 'yes , do the execute first, if the read operation, it will do the getReadBinding method,  if the write operation, it will do the getWriteBinding method.', 'commenter': 'bai-yang'}, {'comment': '@bai-yang Can you give me some code fragments of `MongoDB-Clinet`, to show these three methods definitely run in certain order.', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng  Here is some code fragments of `MongoDB-Clinet`. The execute methods in `Mongo` class.\r\n\r\n![mongo-exe](https://cloud.githubusercontent.com/assets/20091216/25139468/e9dfb07a-248f-11e7-9726-0d552b2e99f2.jpeg)\r\nWhen execute method is executed, it is executed getReadBinding or getWriteBinding method immediately.', 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/pom.xml,"@@ -0,0 +1,52 @@
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+  <modelVersion>4.0.0</modelVersion>
+	<parent>
+		<artifactId>skywalking-sdk-plugin</artifactId>
+		<groupId>com.a.eye</groupId>
+		<version>3.0.1-2017</version>
+	</parent>
+
+	<artifactId>skywalking-mongodb-plugin</artifactId>","[{'comment': 'As you only declared:\r\n>Supported Version: mongo-java-driver-3.X.X\r\nI have tested based on version mongo-java-driver-3.4.2\r\n\r\nYour `artifactId` should be `skywalking-mongodb-3.x-plugin`.', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng ok, I will test based on version `mongo-java-driver-2.x.x`, I think it can also work well.When I finished the test, I will modify the `artifactId `', 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/pom.xml,"@@ -0,0 +1,52 @@
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+  <modelVersion>4.0.0</modelVersion>
+	<parent>
+		<artifactId>skywalking-sdk-plugin</artifactId>
+		<groupId>com.a.eye</groupId>
+		<version>3.0.1-2017</version>
+	</parent>
+
+	<artifactId>skywalking-mongodb-plugin</artifactId>
+	<packaging>jar</packaging>
+
+	<name>mongodb-plugin</name>
+	<url>http://maven.apache.org</url>
+
+	<properties>
+		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+	</properties>
+
+	<dependencies>
+		<dependency>
+			<groupId>log4j</groupId>
+			<artifactId>log4j</artifactId>
+			<version>1.2.17</version>
+			<scope>test</scope>","[{'comment': 'Why need this?', 'commenter': 'wu-sheng'}, {'comment': '+1', 'commenter': 'peng-yongsheng'}, {'comment': 'i will remove this.', 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBMethodInterceptor.java,"@@ -0,0 +1,139 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import java.util.List;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.mongodb.bulk.DeleteRequest;
+import com.mongodb.bulk.InsertRequest;
+import com.mongodb.bulk.UpdateRequest;
+import com.mongodb.bulk.WriteRequest;
+import com.mongodb.operation.CountOperation;
+import com.mongodb.operation.CreateCollectionOperation;
+import com.mongodb.operation.CreateIndexesOperation;
+import com.mongodb.operation.CreateViewOperation;
+import com.mongodb.operation.DeleteOperation;
+import com.mongodb.operation.DistinctOperation;
+import com.mongodb.operation.FindAndDeleteOperation;
+import com.mongodb.operation.FindAndReplaceOperation;
+import com.mongodb.operation.FindAndUpdateOperation;
+import com.mongodb.operation.FindOperation;
+import com.mongodb.operation.GroupOperation;
+import com.mongodb.operation.InsertOperation;
+import com.mongodb.operation.ListCollectionsOperation;
+import com.mongodb.operation.MapReduceToCollectionOperation;
+import com.mongodb.operation.MapReduceWithInlineResultsOperation;
+import com.mongodb.operation.MixedBulkWriteOperation;
+import com.mongodb.operation.UpdateOperation;
+
+/**
+ * {@link MongoDBMethodInterceptor} intercept method of {@link com.mongodb.Mongo#execute(ReadOperation, ReadPreference)}
+ * or {@link com.mongodb.Mongo#execute(WriteOperation)}. record the mongoDB host, operation name and the key of the operation.
+ *
+ * @author baiyang
+ */
+public class MongoDBMethodInterceptor implements InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name that MongoDB host in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_HOST = ""MONGODB_HOST"";
+
+    /**
+     * The key name that MongoDB port in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_PORT = ""MONGODB_PORT"";
+
+    private static final String MONGODB_COMPONENT = ""MongoDB"";
+    
+    @Override
+    public void beforeMethod(final EnhancedClassInstanceContext context,
+            final InstanceMethodInvokeContext interceptorContext, final MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        OperationInfo operationInfo = this.getReadOperationInfo(arguments[0]);
+        Span span = ContextManager.createSpan(""MongoDB/"" + operationInfo.getMethodName());","[{'comment': 'use static  variable', 'commenter': 'peng-yongsheng'}, {'comment': 'ok.', 'commenter': 'bai-yang'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBMethodInterceptor.java,"@@ -0,0 +1,139 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import java.util.List;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.mongodb.bulk.DeleteRequest;
+import com.mongodb.bulk.InsertRequest;
+import com.mongodb.bulk.UpdateRequest;
+import com.mongodb.bulk.WriteRequest;
+import com.mongodb.operation.CountOperation;
+import com.mongodb.operation.CreateCollectionOperation;
+import com.mongodb.operation.CreateIndexesOperation;
+import com.mongodb.operation.CreateViewOperation;
+import com.mongodb.operation.DeleteOperation;
+import com.mongodb.operation.DistinctOperation;
+import com.mongodb.operation.FindAndDeleteOperation;
+import com.mongodb.operation.FindAndReplaceOperation;
+import com.mongodb.operation.FindAndUpdateOperation;
+import com.mongodb.operation.FindOperation;
+import com.mongodb.operation.GroupOperation;
+import com.mongodb.operation.InsertOperation;
+import com.mongodb.operation.ListCollectionsOperation;
+import com.mongodb.operation.MapReduceToCollectionOperation;
+import com.mongodb.operation.MapReduceWithInlineResultsOperation;
+import com.mongodb.operation.MixedBulkWriteOperation;
+import com.mongodb.operation.UpdateOperation;
+
+/**
+ * {@link MongoDBMethodInterceptor} intercept method of {@link com.mongodb.Mongo#execute(ReadOperation, ReadPreference)}
+ * or {@link com.mongodb.Mongo#execute(WriteOperation)}. record the mongoDB host, operation name and the key of the operation.
+ *
+ * @author baiyang
+ */
+public class MongoDBMethodInterceptor implements InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name that MongoDB host in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_HOST = ""MONGODB_HOST"";
+
+    /**
+     * The key name that MongoDB port in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_PORT = ""MONGODB_PORT"";
+
+    private static final String MONGODB_COMPONENT = ""MongoDB"";
+    
+    @Override
+    public void beforeMethod(final EnhancedClassInstanceContext context,
+            final InstanceMethodInvokeContext interceptorContext, final MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        OperationInfo operationInfo = this.getReadOperationInfo(arguments[0]);
+        Span span = ContextManager.createSpan(""MongoDB/"" + operationInfo.getMethodName());
+        Tags.COMPONENT.set(span, MONGODB_COMPONENT);
+        Tags.DB_TYPE.set(span, MONGODB_COMPONENT);
+        Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+        Tags.SPAN_LAYER.asDB(span);
+        Tags.DB_STATEMENT.set(span, operationInfo.getMethodName() + "" "" + operationInfo.getFilter());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+            Object ret) {
+        Span span = ContextManager.activeSpan();
+        Tags.PEER_HOST.set(span, context.get(MONGODB_HOST, String.class));
+        Tags.PEER_PORT.set(span, (Integer) context.get(MONGODB_PORT));
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+            InstanceMethodInvokeContext interceptorContext) {
+        ContextManager.activeSpan().log(t);
+    }
+
+    /**
+     *  Convert ReadOperation interface or WriteOperation interface to the implementation class.
+     *  Get the method name and filter info.
+     */
+    @SuppressWarnings(""rawtypes"")
+    private OperationInfo getReadOperationInfo(Object obj) {","[{'comment': 'The ReadMethod or WriteMethod class is just use to define a name of operate? \r\n1. Is there any defined infomation in the super class of operation object?\r\n2. Is there any interface class had getFilter method?\r\nThat you can generate OperationInfo which will be in common use.', 'commenter': 'peng-yongsheng'}]"
148,skywalking-sniffer/skywalking-sdk-plugin/mongodb-plugin/src/main/java/com/a/eye/skywalking/plugin/mongodb/MongoDBMethodInterceptor.java,"@@ -0,0 +1,139 @@
+package com.a.eye.skywalking.plugin.mongodb;
+
+import java.util.List;
+
+import com.a.eye.skywalking.api.context.ContextManager;
+import com.a.eye.skywalking.api.plugin.interceptor.EnhancedClassInstanceContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import com.a.eye.skywalking.api.plugin.interceptor.enhance.MethodInterceptResult;
+import com.a.eye.skywalking.trace.Span;
+import com.a.eye.skywalking.trace.tag.Tags;
+import com.mongodb.bulk.DeleteRequest;
+import com.mongodb.bulk.InsertRequest;
+import com.mongodb.bulk.UpdateRequest;
+import com.mongodb.bulk.WriteRequest;
+import com.mongodb.operation.CountOperation;
+import com.mongodb.operation.CreateCollectionOperation;
+import com.mongodb.operation.CreateIndexesOperation;
+import com.mongodb.operation.CreateViewOperation;
+import com.mongodb.operation.DeleteOperation;
+import com.mongodb.operation.DistinctOperation;
+import com.mongodb.operation.FindAndDeleteOperation;
+import com.mongodb.operation.FindAndReplaceOperation;
+import com.mongodb.operation.FindAndUpdateOperation;
+import com.mongodb.operation.FindOperation;
+import com.mongodb.operation.GroupOperation;
+import com.mongodb.operation.InsertOperation;
+import com.mongodb.operation.ListCollectionsOperation;
+import com.mongodb.operation.MapReduceToCollectionOperation;
+import com.mongodb.operation.MapReduceWithInlineResultsOperation;
+import com.mongodb.operation.MixedBulkWriteOperation;
+import com.mongodb.operation.UpdateOperation;
+
+/**
+ * {@link MongoDBMethodInterceptor} intercept method of {@link com.mongodb.Mongo#execute(ReadOperation, ReadPreference)}
+ * or {@link com.mongodb.Mongo#execute(WriteOperation)}. record the mongoDB host, operation name and the key of the operation.
+ *
+ * @author baiyang
+ */
+public class MongoDBMethodInterceptor implements InstanceMethodsAroundInterceptor {
+
+    /**
+     * The key name that MongoDB host in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_HOST = ""MONGODB_HOST"";
+
+    /**
+     * The key name that MongoDB port in {@link EnhancedClassInstanceContext#context}.
+     */
+    protected static final String MONGODB_PORT = ""MONGODB_PORT"";
+
+    private static final String MONGODB_COMPONENT = ""MongoDB"";
+    
+    @Override
+    public void beforeMethod(final EnhancedClassInstanceContext context,
+            final InstanceMethodInvokeContext interceptorContext, final MethodInterceptResult result) {
+        Object[] arguments = interceptorContext.allArguments();
+        OperationInfo operationInfo = this.getReadOperationInfo(arguments[0]);
+        Span span = ContextManager.createSpan(""MongoDB/"" + operationInfo.getMethodName());
+        Tags.COMPONENT.set(span, MONGODB_COMPONENT);
+        Tags.DB_TYPE.set(span, MONGODB_COMPONENT);
+        Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
+        Tags.SPAN_LAYER.asDB(span);
+        Tags.DB_STATEMENT.set(span, operationInfo.getMethodName() + "" "" + operationInfo.getFilter());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+            Object ret) {
+        Span span = ContextManager.activeSpan();
+        Tags.PEER_HOST.set(span, context.get(MONGODB_HOST, String.class));
+        Tags.PEER_PORT.set(span, (Integer) context.get(MONGODB_PORT));
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Throwable t, EnhancedClassInstanceContext context,
+            InstanceMethodInvokeContext interceptorContext) {
+        ContextManager.activeSpan().log(t);
+    }
+
+    /**
+     *  Convert ReadOperation interface or WriteOperation interface to the implementation class.
+     *  Get the method name and filter info.
+     */
+    @SuppressWarnings(""rawtypes"")
+    private OperationInfo getReadOperationInfo(Object obj) {
+        if (obj instanceof CountOperation) {
+            return new OperationInfo(ReadMethod.COUNT.getName(), ((CountOperation) obj).getFilter().toString());
+        } else if (obj instanceof DistinctOperation) {
+            return new OperationInfo(ReadMethod.DISTINCT.getName(), ((DistinctOperation) obj).getFilter().toString());
+        } else if (obj instanceof FindOperation) {
+            return new OperationInfo(ReadMethod.FIND.getName(), ((FindOperation) obj).getFilter().toString());
+        } else if (obj instanceof GroupOperation) {
+            return new OperationInfo(ReadMethod.GROUP.getName(), ((GroupOperation) obj).getFilter().toString());
+        } else if (obj instanceof ListCollectionsOperation) {
+            return new OperationInfo(ReadMethod.LIST_COLLECTIONS.getName(), ((ListCollectionsOperation) obj).getFilter().toString());
+        } else if (obj instanceof MapReduceWithInlineResultsOperation) {
+            return new OperationInfo(ReadMethod.MAPREDUCE_WITHINLINE_RESULTS.getName(), ((ListCollectionsOperation) obj).getFilter().toString());
+        } else  if (obj instanceof DeleteOperation) {
+            return new OperationInfo(WriteMethod.DELETE.getName(), ((DeleteOperation) obj).getDeleteRequests().toString());
+        } else if (obj instanceof InsertOperation) {
+            return new OperationInfo(WriteMethod.INSERT.getName(), ((InsertOperation) obj).getInsertRequests().toString());
+        } else if (obj instanceof UpdateOperation) {
+            return new OperationInfo(WriteMethod.UPDATE.getName(), ((UpdateOperation) obj).getUpdateRequests().toString());
+        } else if (obj instanceof CreateCollectionOperation) {
+            return new OperationInfo(WriteMethod.CREATECOLLECTION.getName(), ((CreateCollectionOperation) obj).getCollectionName());
+        } else if (obj instanceof CreateIndexesOperation) {
+            return new OperationInfo(WriteMethod.CREATEINDEXES.getName(), ((CreateIndexesOperation) obj).getIndexNames().toString());
+        } else if (obj instanceof CreateViewOperation) {
+            return new OperationInfo(WriteMethod.CREATEVIEW.getName(), ((CreateViewOperation) obj).getViewName());
+        } else if (obj instanceof FindAndDeleteOperation) {
+            return new OperationInfo(WriteMethod.FINDANDDELETE.getName(), ((FindAndDeleteOperation) obj).getFilter().toString());
+        } else if (obj instanceof FindAndReplaceOperation) {
+            return new OperationInfo(WriteMethod.FINDANDREPLACE.getName(), ((FindAndReplaceOperation) obj).getFilter().toString());
+        } else if (obj instanceof FindAndUpdateOperation) {
+            return new OperationInfo(WriteMethod.FINDANDUPDATE.getName(), ((FindAndUpdateOperation) obj).getFilter().toString());
+        } else if (obj instanceof MapReduceToCollectionOperation) {
+            return new OperationInfo(WriteMethod.MAPREDUCETOCOLLECTION.getName(), ((MapReduceToCollectionOperation) obj).getFilter().toString());
+        } else if (obj instanceof MixedBulkWriteOperation) {","[{'comment': 'The bulk api will be transfer large data, make sure about you need every document in this bulk operate.', 'commenter': 'peng-yongsheng'}, {'comment': ""@bai-yang , I also have a little performance concern about this. Two points:\r\n1. Too many `if..else..`\r\n1. Same as @pengys5 , **Bulk** means multi-rows of records, can we afford these?\r\n\r\nAnd another question is about `Filter`, what is that for? I can't find out in your screenshot."", 'commenter': 'wu-sheng'}, {'comment': '@pengys5 @wu-sheng \r\nI think, I can limit the length of records to solve large data problem.\r\n\r\nToo many `if..else..` , I don\'t have a good idea at the moment.\r\n\r\n Here are some filter examples：\r\n1、`{ ""name"" : ""limei"", ""age"" : 40, ""_id"" : { ""$oid"" : ""58f723fb354b1910e0fb6298"" } }`\r\n2、`{ ""name"" : ""by"" }`', 'commenter': 'bai-yang'}]"
163,.travis.yml,"@@ -13,3 +13,4 @@ script:
 
 after_success:
   - mvn clean cobertura:cobertura coveralls:report
+  - bash ./travis/deploy_image.sh","[{'comment': 'You are pushing image, not deploy image. Please choose the right word.', 'commenter': 'wu-sheng'}]"
163,travis/deploy_image.sh,"@@ -0,0 +1,24 @@
+#!/bin/sh
+
+check_pull_is_tag_or_release() {
+  if [ ""${TRAVIS_TAG}"" = """" ]; then
+    return 1
+  else
+    echo ""[Deploying] deploy tag ${TRAVIS_TAG}.""","[{'comment': 'Same, `Deploy` and `Deploying`.', 'commenter': 'wu-sheng'}]"
163,travis/deploy_image.sh,"@@ -0,0 +1,24 @@
+#!/bin/sh
+
+check_pull_is_tag_or_release() {
+  if [ ""${TRAVIS_TAG}"" = """" ]; then
+    return 1
+  else
+    echo ""[Deploying] deploy tag ${TRAVIS_TAG}.""
+    return 0
+  fi
+
+}
+
+deploy_collector_image() {
+  docker login -u=""$DOCKER_USERNAME"" -p=""$DOCKER_PASSWORD""
+  mvn clean package docker:build
+  docker push skywalking/skywalking-collector:latest
+  docker push skywalking/skywalking-collector:${TRAVIS_TAG}
+}
+
+
+if check_pull_is_tag_or_release; then
+    deploy_collector_image
+    echo ""[Deploying] deploy Done!""","[{'comment': 'Same, `Deploy` and `Deploying`.', 'commenter': 'wu-sheng'}]"
163,travis/push_image.sh,"@@ -0,0 +1,24 @@
+#!/bin/sh
+
+check_pull_is_release() {
+  if [ ""${TRAVIS_TAG}"" = """" ]; then
+    return 1
+  else
+    echo ""[Pushing] pushing docker image of ${TRAVIS_TAG}.""","[{'comment': '`[Pushing] pushing` vs `[Pushing] push`(line 23), why?', 'commenter': 'wu-sheng'}]"
163,travis/push_image.sh,"@@ -0,0 +1,24 @@
+#!/bin/sh
+
+check_pull_is_release() {
+  if [ ""${TRAVIS_TAG}"" = """" ]; then
+    return 1
+  else
+    echo ""[Pushing] pushing docker image of ${TRAVIS_TAG}.""
+    return 0
+  fi
+
+}
+
+push_collector_image() {
+  docker login -u=""$DOCKER_USERNAME"" -p=""$DOCKER_PASSWORD""","[{'comment': 'I assume we must config these two variables in travis-ci pages, right?', 'commenter': 'wu-sheng'}, {'comment': 'Please see the description of pull request.', 'commenter': 'ascrutae'}]"
165,skywalking-collector/skywalking-collector-cluster/src/main/java/com/a/eye/skywalking/collector/AkkaSystem.java,"@@ -17,10 +18,12 @@
     private Logger logger = LogManager.getFormatterLogger(AkkaSystem.class);
 
     public ActorSystem create() {
+        Level logLevel = logger.getLevel();
+
         final Config config = ConfigFactory.parseString(""akka.remote.netty.tcp.HOSTNAME="" + ClusterConfig.Cluster.Current.HOSTNAME).
                 withFallback(ConfigFactory.parseString(""akka.remote.netty.tcp.PORT="" + ClusterConfig.Cluster.Current.PORT)).
                 withFallback(ConfigFactory.parseString(""akka.loggers=[\""akka.event.slf4j.Slf4jLogger\""]"")).
-                withFallback(ConfigFactory.parseString(""akka.loglevel=\""ERROR\"""")).
+                withFallback(ConfigFactory.parseString(""akka.loglevel=\"""" + logLevel.name() + ""\"""")).","[{'comment': '+1, Good to have this.', 'commenter': 'wu-sheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/MergeAnalysisData.java,"@@ -0,0 +1,23 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import java.util.LinkedHashMap;
+import java.util.Map;
+
+/**
+ * @author pengys5
+ */
+public class MergeAnalysisData {
+
+    private WindowData<MergeData> windowData = new WindowData(new LinkedHashMap<String, MergeData>());
+
+    public MergeData getElseCreate(String id) {","[{'comment': 'I think your meaning is `getOrCreate`? I think your full statement is `get by id, if not exist, create one`, right?', 'commenter': 'wu-sheng'}, {'comment': 'fixed.', 'commenter': 'peng-yongsheng'}, {'comment': 'You can see from the sentence, there is no `else`. I prefer `getOrCreate`.', 'commenter': 'wu-sheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/MergePersistenceData.java,"@@ -1,51 +1,25 @@
 package com.a.eye.skywalking.collector.worker.storage;
 
-import java.util.HashMap;
-import java.util.Iterator;
-import java.util.Map;
-import java.util.Spliterator;
-import java.util.function.Consumer;
-
 /**
  * @author pengys5
  */
-public class MergePersistenceData implements Iterable {
+public class MergePersistenceData extends Window<MergeData> implements PersistenceData<MergeData> {
 
-    private Map<String, MergeData> persistenceData = new HashMap<>();
+    private WindowData<MergeData> lockedWindowData;
 
     public MergeData getElseCreate(String id) {
-        if (!persistenceData.containsKey(id)) {
-            persistenceData.put(id, new MergeData(id));
+        if (!lockedWindowData.containsKey(id)) {
+            lockedWindowData.put(id, new MergeData(id));
         }
-        return persistenceData.get(id);
-    }
-
-    public int size() {
-        return persistenceData.size();
-    }
-
-    public void clear() {
-        persistenceData.clear();
-    }
-
-    public MergeData pushOne() {
-        MergeData one = persistenceData.entrySet().iterator().next().getValue();
-        persistenceData.remove(one.getId());
-        return one;
-    }
-
-    @Override
-    public void forEach(Consumer action) {
-        throw new UnsupportedOperationException(""forEach"");
+        return lockedWindowData.get(id);
     }
 
-    @Override
-    public Spliterator spliterator() {
-        throw new UnsupportedOperationException(""spliterator"");
+    public void holdData() {
+        lockedWindowData = getCurrentAndHold();
     }
 
-    @Override
-    public Iterator<Map.Entry<String, MergeData>> iterator() {
-        return persistenceData.entrySet().iterator();
+    public void releaseData() {","[{'comment': '`reset` may be better than `releaseData`. First, this is a data class, named `MergePersistenceData`, no need add `Data` as part of method name. Then, `release` is talking something about resources, in here, no resource.\r\n\r\nSo, as a data window, I prefer `reset`.', 'commenter': 'wu-sheng'}, {'comment': 'the data operational process:\r\n1. holdData\r\n2. releaseData\r\nso, it means release the hold data.', 'commenter': 'peng-yongsheng'}, {'comment': 'You should remove the suffix. This is already a data object.', 'commenter': 'wu-sheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/MetricAnalysisData.java,"@@ -0,0 +1,23 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import java.util.LinkedHashMap;
+import java.util.Map;
+
+/**
+ * @author pengys5
+ */
+public class MetricAnalysisData {
+
+    private WindowData<MetricData> windowData = new WindowData(new LinkedHashMap<String, MetricData>());
+
+    public MetricData getElseCreate(String id) {","[{'comment': 'Same naming concern.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceData.java,"@@ -0,0 +1,13 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+/**
+ * @author pengys5
+ */
+public interface PersistenceData<T extends Data> {
+
+    T getElseCreate(String id);
+
+    void releaseData();
+
+    void holdData();","[{'comment': 'Also, no need of `Data` suffix.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceTimer.java,"@@ -0,0 +1,53 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import com.a.eye.skywalking.collector.actor.AbstractLocalSyncWorker;
+import com.a.eye.skywalking.collector.worker.config.EsConfig;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author pengys5
+ */
+public enum PersistenceTimer {
+    INSTANCE;
+
+    private Logger logger = LogManager.getFormatterLogger(PersistenceTimer.class);
+
+    public void boot() {
+        logger.info(""persistence timer start"");
+        final long timeInterval = EsConfig.Es.Persistence.Timer.VALUE * 1000;
+
+        Runnable runnable = () -> {
+            while (true) {
+                try {
+                    extractDataAndSave();
+                    Thread.sleep(timeInterval);
+                } catch (Exception e) {","[{'comment': 'Please **catch** `Throwable`, if you just want to prevent bad things happened.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceTimer.java,"@@ -0,0 +1,53 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import com.a.eye.skywalking.collector.actor.AbstractLocalSyncWorker;
+import com.a.eye.skywalking.collector.worker.config.EsConfig;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author pengys5
+ */
+public enum PersistenceTimer {
+    INSTANCE;
+
+    private Logger logger = LogManager.getFormatterLogger(PersistenceTimer.class);
+
+    public void boot() {
+        logger.info(""persistence timer start"");
+        final long timeInterval = EsConfig.Es.Persistence.Timer.VALUE * 1000;
+
+        Runnable runnable = () -> {
+            while (true) {
+                try {
+                    extractDataAndSave();
+                    Thread.sleep(timeInterval);
+                } catch (Exception e) {
+                    e.printStackTrace();","[{'comment': 'Why print to console?', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceTimer.java,"@@ -0,0 +1,53 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import com.a.eye.skywalking.collector.actor.AbstractLocalSyncWorker;
+import com.a.eye.skywalking.collector.worker.config.EsConfig;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author pengys5
+ */
+public enum PersistenceTimer {
+    INSTANCE;
+
+    private Logger logger = LogManager.getFormatterLogger(PersistenceTimer.class);
+
+    public void boot() {
+        logger.info(""persistence timer start"");
+        final long timeInterval = EsConfig.Es.Persistence.Timer.VALUE * 1000;
+
+        Runnable runnable = () -> {
+            while (true) {
+                try {
+                    extractDataAndSave();
+                    Thread.sleep(timeInterval);
+                } catch (Exception e) {
+                    e.printStackTrace();
+                }
+            }
+        };
+        Thread thread = new Thread(runnable);","[{'comment': 'You should set a thread name.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceTimer.java,"@@ -0,0 +1,53 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import com.a.eye.skywalking.collector.actor.AbstractLocalSyncWorker;
+import com.a.eye.skywalking.collector.worker.config.EsConfig;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author pengys5
+ */
+public enum PersistenceTimer {
+    INSTANCE;
+
+    private Logger logger = LogManager.getFormatterLogger(PersistenceTimer.class);
+
+    public void boot() {
+        logger.info(""persistence timer start"");
+        final long timeInterval = EsConfig.Es.Persistence.Timer.VALUE * 1000;
+
+        Runnable runnable = () -> {
+            while (true) {
+                try {
+                    extractDataAndSave();
+                    Thread.sleep(timeInterval);
+                } catch (Exception e) {
+                    e.printStackTrace();
+                }
+            }
+        };
+        Thread thread = new Thread(runnable);
+        thread.start();
+    }
+
+    private void extractDataAndSave() {
+        List<IndexRequestBuilder> dataList = new LinkedList<>();
+
+        List<AbstractLocalSyncWorker> workers = PersistenceWorkerListener.INSTANCE.getWorkers();
+        for (AbstractLocalSyncWorker worker : workers) {
+            logger.info(""worker role name: %s"", worker.getRole().roleName());
+            try {
+                worker.allocateJob(new FlushAndSwitch(), dataList);
+            } catch (Exception e) {
+                logger.error(""flush persistence worker data error, worker role name: %s"", worker.getRole().roleName());
+                e.printStackTrace();","[{'comment': 'You have already log, why print again, and to console?', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceTimer.java,"@@ -0,0 +1,53 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import com.a.eye.skywalking.collector.actor.AbstractLocalSyncWorker;
+import com.a.eye.skywalking.collector.worker.config.EsConfig;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author pengys5
+ */
+public enum PersistenceTimer {
+    INSTANCE;
+
+    private Logger logger = LogManager.getFormatterLogger(PersistenceTimer.class);
+
+    public void boot() {
+        logger.info(""persistence timer start"");
+        final long timeInterval = EsConfig.Es.Persistence.Timer.VALUE * 1000;
+
+        Runnable runnable = () -> {
+            while (true) {
+                try {
+                    extractDataAndSave();
+                    Thread.sleep(timeInterval);
+                } catch (Exception e) {
+                    e.printStackTrace();
+                }
+            }
+        };
+        Thread thread = new Thread(runnable);
+        thread.start();
+    }
+
+    private void extractDataAndSave() {
+        List<IndexRequestBuilder> dataList = new LinkedList<>();
+
+        List<AbstractLocalSyncWorker> workers = PersistenceWorkerListener.INSTANCE.getWorkers();
+        for (AbstractLocalSyncWorker worker : workers) {
+            logger.info(""worker role name: %s"", worker.getRole().roleName());
+            try {
+                worker.allocateJob(new FlushAndSwitch(), dataList);
+            } catch (Exception e) {
+                logger.error(""flush persistence worker data error, worker role name: %s"", worker.getRole().roleName());","[{'comment': 'This is an error log, why not log Exception?', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/PersistenceWorkerListener.java,"@@ -0,0 +1,23 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import com.a.eye.skywalking.collector.actor.AbstractLocalSyncWorker;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * @author pengys5
+ */
+public enum PersistenceWorkerListener {
+    INSTANCE;
+
+    private List<AbstractLocalSyncWorker> workers = new ArrayList<>();","[{'comment': 'A discussion, do you `ArrayList` for sure? not `LinkedList`?', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/WindowData.java,"@@ -0,0 +1,52 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import java.util.Map;
+
+/**
+ * @author pengys5
+ */
+public class WindowData<T extends Data> {
+    private Map<String, T> data;
+    private boolean isHold;","[{'comment': 'You are processing data across-thread, please set `volatile` key word for your fields.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
165,skywalking-collector/skywalking-collector-worker/src/main/java/com/a/eye/skywalking/collector/worker/storage/Window.java,"@@ -0,0 +1,50 @@
+package com.a.eye.skywalking.collector.worker.storage;
+
+import java.util.HashMap;
+
+/**
+ * @author pengys5
+ */
+public abstract class Window<T extends Data> {
+
+    private Pointer current;","[{'comment': 'Why need `Pointer`? You only need a filed, type of `WindowData`. And you can use `==` to judge. Better performance, Easier codes.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'peng-yongsheng'}]"
171,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java,"@@ -30,6 +38,32 @@ else if (value instanceof Integer)
             ContextManager.activeSpan().setTag(key, value.toString());
     }
 
+    /**
+     * Fetch tag key of {@link Span#setTag}.
+     *
+     * @return tag key
+     */
+    private String fetchTagKeyFromArguments(Object[] arguments) {
+        String key = (String)arguments[0];
+
+        if (isPeerHostPrefix(key)) {
+            key = KEY_OF_PEER_HOST_TAG;
+        }
+
+        return key;
+    }
+
+    /**
+     * Skywalking put the tag value of {@link Tags#PEER_HOSTNAME}, {@link Tags#PEER_HOST_IPV4} and
+     * {@link Tags#PEER_HOST_IPV6} into {@link com.a.eye.skywalking.trace.tag.Tags#PEER_HOST} which
+     * facilitate analysis.
+     *
+     * @param key tag key
+     */
+    private boolean isPeerHostPrefix(String key) {","[{'comment': 'This judgement is not about prefix, instead, it is about the whole **key**.', 'commenter': 'wu-sheng'}]"
171,skywalking-sniffer/skywalking-toolkit-activation/skywalking-toolkit-opentracing-activation/src/main/java/com/a/eye/skywalking/toolkit/activation/opentracing/span/interceptor/SpanSetTagInterceptor.java,"@@ -30,6 +38,32 @@ else if (value instanceof Integer)
             ContextManager.activeSpan().setTag(key, value.toString());
     }
 
+    /**
+     * Fetch tag key of {@link Span#setTag}.
+     *
+     * @return tag key
+     */
+    private String fetchTagKeyFromArguments(Object[] arguments) {","[{'comment': 'This method do not just fetch the tag key, you are changing it by specific circumstances. So wrong method name.', 'commenter': 'wu-sheng'}]"
187,apm-sniffer/apm-sdk-plugin/resin-3.x-4.x-plugin/src/main/java/org/skywalking/apm/plugin/resin/v3x/v4x/ResinInterceptor.java,"@@ -0,0 +1,65 @@
+package org.skywalking.apm.plugin.resin.v3x.v4x;","[{'comment': ""The package name didn't fit the Java Package Tradition. In Java, `*.v3x.v4x` means **3** is major version and **4** is minor version. But, according from my understanding, **3** and **4** are all major versions.\r\n\r\nSo I prefer the package name is `org.skywalking.apm.plugin.resin34x`.  `TomcatInterceptor` class under package `org.skywalking.apm.plugin.tomcat78x` is for your reference."", 'commenter': 'wu-sheng'}]"
187,apm-sniffer/apm-sdk-plugin/resin-3.x-4.x-plugin/src/main/java/org/skywalking/apm/plugin/resin34x/ResinInterceptor.java,"@@ -0,0 +1,65 @@
+package org.skywalking.apm.plugin.resin34x;
+
+import javax.servlet.http.HttpServletRequest;
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.plugin.interceptor.EnhancedClassInstanceContext;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.trace.Span;
+import org.skywalking.apm.trace.tag.Tags;
+import org.skywalking.apm.util.StringUtil;
+
+/**
+ * {@link ResinInterceptor} intercept method of{@link com.caucho.server.dispatch.ServletInvocation#service(javax.servlet.ServletRequest,
+ * javax.servlet.ServletResponse)} record the resin host, port ,url.
+ *
+ * @author baiyang
+ */
+public class ResinInterceptor implements InstanceMethodsAroundInterceptor {
+    /**
+     * Header name that the serialized context data stored in
+     * {@link HttpServletRequest#getHeader(String)}.
+     */
+    public static final String HEADER_NAME_OF_CONTEXT_DATA = ""SWTraceContext"";
+    /**
+     * Resin component.
+     */
+    public static final String RESIN_COMPONENT = ""Resin"";
+
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+        MethodInterceptResult result) {
+        Object[] args = interceptorContext.allArguments();
+        HttpServletRequest request = (HttpServletRequest)args[0];
+        Span span = ContextManager.createSpan(request.getRequestURI());
+        Tags.COMPONENT.set(span, RESIN_COMPONENT);
+        Tags.PEER_HOST.set(span, request.getServerName());
+        Tags.PEER_PORT.set(span, request.getServerPort());
+        Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_SERVER);
+        Tags.URL.set(span, request.getRequestURL().toString());
+        Tags.SPAN_LAYER.asHttp(span);
+
+        String tracingHeaderValue = request.getHeader(HEADER_NAME_OF_CONTEXT_DATA);
+        if (!StringUtil.isEmpty(tracingHeaderValue)) {
+            ContextManager.extract(new ContextCarrier().deserialize(tracingHeaderValue));
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,","[{'comment': 'Current span need to record status code. and also check the status code, Please see [Tomcat plugin](https://github.com/wu-sheng/sky-walking/blob/master/apm-sniffer/apm-sdk-plugin/tomcat-7.x-8.x-plugin/src/main/java/org/skywalking/apm/plugin/tomcat78x/TomcatInterceptor.java#L65-#L70)', 'commenter': 'ascrutae'}]"
187,apm-sniffer/apm-sdk-plugin/resin-3.x-4.x-plugin/src/main/java/org/skywalking/apm/plugin/resin34x/ResinInterceptor.java,"@@ -0,0 +1,65 @@
+package org.skywalking.apm.plugin.resin34x;
+
+import javax.servlet.http.HttpServletRequest;
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.plugin.interceptor.EnhancedClassInstanceContext;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodInvokeContext;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.trace.Span;
+import org.skywalking.apm.trace.tag.Tags;
+import org.skywalking.apm.util.StringUtil;
+
+/**
+ * {@link ResinInterceptor} intercept method of{@link com.caucho.server.dispatch.ServletInvocation#service(javax.servlet.ServletRequest,
+ * javax.servlet.ServletResponse)} record the resin host, port ,url.
+ *
+ * @author baiyang
+ */
+public class ResinInterceptor implements InstanceMethodsAroundInterceptor {
+    /**
+     * Header name that the serialized context data stored in
+     * {@link HttpServletRequest#getHeader(String)}.
+     */
+    public static final String HEADER_NAME_OF_CONTEXT_DATA = ""SWTraceContext"";
+    /**
+     * Resin component.
+     */
+    public static final String RESIN_COMPONENT = ""Resin"";
+
+    @Override
+    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
+        MethodInterceptResult result) {
+        Object[] args = interceptorContext.allArguments();
+        HttpServletRequest request = (HttpServletRequest)args[0];
+        Span span = ContextManager.createSpan(request.getRequestURI());
+        Tags.COMPONENT.set(span, RESIN_COMPONENT);
+        Tags.PEER_HOST.set(span, request.getServerName());","[{'comment': 'Request#getServerName() cannot get the correct client host if Resin is behind a reverse proxy or load balancer.  You may need to use HttpServletRequest.getHeader(""x-forwarded-proto"") instead.', 'commenter': 'ascrutae'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -12,15 +13,29 @@
 public enum PluginCfg {
     INSTANCE;
 
-    private List<String> pluginClassList = new ArrayList<String>();
+    private List<PluginDefine> pluginClassList = new ArrayList<PluginDefine>();
+    protected List<String> disabledPlugins = new ArrayList<String>();
+
+    PluginCfg() {","[{'comment': 'Using the contructor for initialization should very careful, if this enum is used before config initialization, the disable mechanism will fail.\r\n\r\nSo I prefer to make the initialization as a boot service, rather than this.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -12,15 +13,29 @@
 public enum PluginCfg {
     INSTANCE;
 
-    private List<String> pluginClassList = new ArrayList<String>();
+    private List<PluginDefine> pluginClassList = new ArrayList<PluginDefine>();
+    protected List<String> disabledPlugins = new ArrayList<String>();","[{'comment': ""DisableList is only used in plugin initialization, shouldn't set it as a class field."", 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -29,6 +44,55 @@ void load(InputStream input) throws IOException {
     }
 
     public List<String> getPluginClassList() {
-        return pluginClassList;
+        List<String> pluginClasses = new ArrayList<String>();","[{'comment': 'Why need this new list? Just a list copy?', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -29,6 +44,55 @@ void load(InputStream input) throws IOException {
     }
 
     public List<String> getPluginClassList() {
-        return pluginClassList;
+        List<String> pluginClasses = new ArrayList<String>();
+        for (PluginDefine plugin : pluginClassList) {
+            pluginClasses.add(plugin.defineClass);
+        }
+        return pluginClasses;
+    }
+
+    private static class PluginDefine {
+
+
+        private static final PluginDefine NOOP_PLUGIN = new PluginDefine() {","[{'comment': 'This is not a Noop. It always set a empty plugin define.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -29,6 +44,55 @@ void load(InputStream input) throws IOException {
     }
 
     public List<String> getPluginClassList() {
-        return pluginClassList;
+        List<String> pluginClasses = new ArrayList<String>();
+        for (PluginDefine plugin : pluginClassList) {
+            pluginClasses.add(plugin.defineClass);
+        }
+        return pluginClasses;
+    }
+
+    private static class PluginDefine {
+
+
+        private static final PluginDefine NOOP_PLUGIN = new PluginDefine() {
+            @Override public boolean disabled(List<String> disablePlugins) {
+                return true;
+            }
+        };
+        /**
+         * Plugin name.
+         */
+        String name;
+
+        /**
+         * The class name of plugin defined.
+         */
+        String defineClass;
+
+        private PluginDefine() {
+        }
+
+        private PluginDefine(String name, String defineClass) {
+            this.name = name;
+            this.defineClass = defineClass;
+        }
+
+        public static PluginDefine build(String define) {
+            if (StringUtil.isEmpty(define)) {
+                return NOOP_PLUGIN;","[{'comment': 'Did not like the design of retuning noop plugin define. Hard to understand and make no sense.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/conf/Config.java,"@@ -83,12 +83,23 @@
     }
 
     public static class Plugin {
+
+        /**
+         * Name of disabled plugin, The value spilt by <code>,</code>
+         * if you have multiple plugins need to disable.
+         *
+         * Here are the plugin names :
+         * TOMCAT, DUBBO, JEDIS, MOTAN, HTTPCLIENT, JDBC, MONGODB.","[{'comment': 'All existed config items are in lower case, why choose upper case this time?', 'commenter': 'wu-sheng'}, {'comment': 'Some plugin names should include version, I think', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-sdk-plugin/tomcat-7.x-8.x-plugin/src/main/resources/skywalking-plugin.def,"@@ -1 +1 @@
-org.skywalking.apm.plugin.tomcat78x.define.TomcatInstrumentation
+tomcat-7.x=org.skywalking.apm.plugin.tomcat78x.define.TomcatInstrumentation","[{'comment': 'IMO, the key should be `tomcat-7.x/8.x`, if.f `/` is legal.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -12,23 +10,30 @@
 public enum PluginCfg {
     INSTANCE;
 
-    private List<String> pluginClassList = new ArrayList<String>();
+    private List<PluginDefine> pluginClassList = new ArrayList<PluginDefine>();
+    private List<String> disabledPlugins = new ArrayList<String>();
 
     void load(InputStream input) throws IOException {
         try {
             BufferedReader reader = new BufferedReader(new InputStreamReader(input));
-            String pluginDefineClassName = null;
-            while ((pluginDefineClassName = reader.readLine()) != null) {
-                if (!StringUtil.isEmpty(pluginDefineClassName)) {
-                    pluginClassList.add(pluginDefineClassName.trim());
+            String pluginDefine = null;
+            while ((pluginDefine = reader.readLine()) != null) {
+                PluginDefine plugin = PluginDefine.build(pluginDefine);
+                if (!plugin.disabled(disabledPlugins)) {","[{'comment': 'Are you sure this is going to work? \r\n\r\nAccording to `premain`\r\n```java\r\n    public static void premain(String agentArgs, Instrumentation instrumentation) throws PluginException {\r\n        SnifferConfigInitializer.initialize();\r\n\r\n        final PluginFinder pluginFinder = new PluginFinder(new PluginBootstrap().loadPlugins());\r\n\r\n        ServiceManager.INSTANCE.boot();\r\n```\r\n\r\n`load(InputStream input)` invokes before `ServiceManager.boot`. **disabledPlugins**(initialize in `DisabledPluginInitService`) must be empty every time, how does this pr work?', 'commenter': 'wu-sheng'}]"
191,apm-commons/apm-util/src/main/java/org/skywalking/apm/util/ConfigInitializer.java,"@@ -46,6 +50,19 @@ else if (type.isEnum())
             parentDesc.removeLastDesc();
         }
     }
+
+    private static List convert2List(String value) {
+        List result = new ArrayList();","[{'comment': 'I think `LinkedList` is better choice for performance.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/conf/Config.java,"@@ -83,12 +85,23 @@
     }
 
     public static class Plugin {
+
+        /**
+         * Name of disabled plugin, The value spilt by <code>,</code>
+         * if you have multiple plugins need to disable.
+         *
+         * Here are the plugin names :
+         * tomcat-7.x/8.x, dubbo, jedis-2.x, motan, httpclient-4.x, jdbc, mongodb-3.x.
+         */
+        public static List DISABLED_PLUGINS = new ArrayList();","[{'comment': 'Same performance concern. Prefer `LinkedList`.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginBootstrap.java,"@@ -42,18 +42,18 @@
             }
         }
 
-        List<String> pluginClassList = PluginCfg.INSTANCE.getPluginClassList();
+        List<PluginDefine> pluginClassList = PluginCfg.INSTANCE.getPluginClassList();
 
         List<AbstractClassEnhancePluginDefine> plugins = new ArrayList<AbstractClassEnhancePluginDefine>();
-        for (String pluginClassName : pluginClassList) {
+        for (PluginDefine pluginDefine : pluginClassList) {
             try {
-                logger.debug(""loading plugin class {}."", pluginClassName);
+                logger.debug(""loading plugin class {}."", pluginDefine.getDefineClass());
                 AbstractClassEnhancePluginDefine plugin =
-                    (AbstractClassEnhancePluginDefine) Class.forName(pluginClassName).newInstance();
+                    (AbstractClassEnhancePluginDefine) Class.forName(pluginDefine.getDefineClass()).newInstance();
                 plugin.setClassTypePool(classTypePool);
                 plugins.add(plugin);
             } catch (Throwable t) {
-                logger.error(t, ""load plugin [{}] failure."", pluginClassName);
+                logger.error(t, ""loade plugin [{}] failure."", pluginDefine.getDefineClass());","[{'comment': '`loade`, typo.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -1,34 +1,36 @@
 package org.skywalking.apm.agent.core.plugin;
 
-import org.skywalking.apm.util.StringUtil;
-
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.util.ArrayList;
 import java.util.List;
+import org.skywalking.apm.agent.core.conf.Config;
 
 public enum PluginCfg {
     INSTANCE;
 
-    private List<String> pluginClassList = new ArrayList<String>();
+    private List<PluginDefine> pluginClassList = new ArrayList<PluginDefine>();
 
     void load(InputStream input) throws IOException {
         try {
             BufferedReader reader = new BufferedReader(new InputStreamReader(input));
-            String pluginDefineClassName = null;
-            while ((pluginDefineClassName = reader.readLine()) != null) {
-                if (!StringUtil.isEmpty(pluginDefineClassName)) {
-                    pluginClassList.add(pluginDefineClassName.trim());
+            String pluginDefine = null;
+            while ((pluginDefine = reader.readLine()) != null) {
+                PluginDefine plugin = PluginDefine.build(pluginDefine);
+                if (!plugin.disabled(Config.Plugin.DISABLED_PLUGINS)) {","[{'comment': 'You are using a static field as a parameter, why? You can use is in `disabled` method, no parameter is needed.\r\n\r\nAnd I prefer the method name should be `boolean enable()`.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginDefine.java,"@@ -0,0 +1,57 @@
+package org.skywalking.apm.agent.core.plugin;
+
+import java.util.List;
+import org.skywalking.apm.util.StringUtil;
+
+public class PluginDefine {
+    /**
+     * Plugin name.
+     */
+    private String name;
+
+    /**
+     * The class name of plugin defined.
+     */
+    private String defineClass;
+
+    private PluginDefine() {
+    }
+
+    private PluginDefine(String name, String defineClass) {
+        this.name = name;
+        this.defineClass = defineClass;
+    }
+
+    public static PluginDefine build(String define) {
+        if (StringUtil.isEmpty(define)) {
+            return IllegalPluginDefine.INSTANCE;","[{'comment': ""Still don't understand this enum class, also strange name `IllegalPluginDefine`. If it is illegal, why don't throw exception?"", 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginDefine.java,"@@ -0,0 +1,57 @@
+package org.skywalking.apm.agent.core.plugin;
+
+import java.util.List;
+import org.skywalking.apm.util.StringUtil;
+
+public class PluginDefine {
+    /**
+     * Plugin name.
+     */
+    private String name;
+
+    /**
+     * The class name of plugin defined.
+     */
+    private String defineClass;
+
+    private PluginDefine() {
+    }
+
+    private PluginDefine(String name, String defineClass) {
+        this.name = name;
+        this.defineClass = defineClass;
+    }
+
+    public static PluginDefine build(String define) {
+        if (StringUtil.isEmpty(define)) {
+            return IllegalPluginDefine.INSTANCE;
+        }
+
+        String[] pluginDefine = define.split(""="");
+        if (pluginDefine.length != 2) {
+            return IllegalPluginDefine.INSTANCE;
+        }
+
+        return new PluginDefine(pluginDefine[0], pluginDefine[1]);
+    }
+
+    public boolean disabled(List<String> disablePlugins) {
+        return disablePlugins.contains(name);
+    }
+
+    public String getDefineClass() {
+        return defineClass;
+    }
+
+    static class IllegalPluginDefine extends PluginDefine {","[{'comment': ""Again and again, don't accept this design."", 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-sdk-plugin/jedis-2.x-plugin/src/main/resources/skywalking-plugin.def,"@@ -1,2 +1,2 @@
-org.skywalking.apm.plugin.jedis.v2.define.JedisClusterInstrumentation
-org.skywalking.apm.plugin.jedis.v2.define.JedisInstrumentation
+jedis=org.skywalking.apm.plugin.jedis.v2.define.JedisClusterInstrumentation
+jedis=org.skywalking.apm.plugin.jedis.v2.define.JedisInstrumentation","[{'comment': '`jedis-2.x`, I think', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-sdk-plugin/motan-plugin/src/main/resources/skywalking-plugin.def,"@@ -1,2 +1,2 @@
-org.skywalking.apm.plugin.motan.define.MotanConsumerInstrumentation
-org.skywalking.apm.plugin.motan.define.MotanProviderInstrumentation
+motan=org.skywalking.apm.plugin.motan.define.MotanConsumerInstrumentation","[{'comment': '`motan-0.x`, I think.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginCfg.java,"@@ -1,34 +1,44 @@
 package org.skywalking.apm.agent.core.plugin;
 
-import org.skywalking.apm.util.StringUtil;
-
 import java.io.BufferedReader;
 import java.io.IOException;
 import java.io.InputStream;
 import java.io.InputStreamReader;
 import java.util.ArrayList;
 import java.util.List;
+import org.skywalking.apm.agent.core.conf.Config;
+import org.skywalking.apm.agent.core.plugin.exception.IllegalPluginDefineException;
+import org.skywalking.apm.logging.ILog;
+import org.skywalking.apm.logging.LogManager;
 
 public enum PluginCfg {
     INSTANCE;
 
-    private List<String> pluginClassList = new ArrayList<String>();
+    private static final ILog logger = LogManager.getLogger(PluginCfg.class);
+
+    private List<PluginDefine> pluginClassList = new ArrayList<PluginDefine>();
 
     void load(InputStream input) throws IOException {
         try {
             BufferedReader reader = new BufferedReader(new InputStreamReader(input));
-            String pluginDefineClassName = null;
-            while ((pluginDefineClassName = reader.readLine()) != null) {
-                if (!StringUtil.isEmpty(pluginDefineClassName)) {
-                    pluginClassList.add(pluginDefineClassName.trim());
+            String pluginDefine = null;
+            while ((pluginDefine = reader.readLine()) != null) {
+                try {
+                    PluginDefine plugin = PluginDefine.build(pluginDefine);
+                    if (!plugin.disabled()) {","[{'comment': 'You never used `disabled`, just want to know `enable` or not.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginDefine.java,"@@ -0,0 +1,49 @@
+package org.skywalking.apm.agent.core.plugin;
+
+import java.util.List;
+import org.skywalking.apm.agent.core.conf.Config;
+import org.skywalking.apm.agent.core.plugin.exception.IllegalPluginDefineException;
+import org.skywalking.apm.util.StringUtil;
+
+public class PluginDefine {
+    /**
+     * Plugin name.
+     */
+    private String name;
+
+    /**
+     * The class name of plugin defined.
+     */
+    private String defineClass;
+
+    private PluginDefine() {
+    }
+
+    private PluginDefine(String name, String defineClass) {
+        this.name = name;
+        this.defineClass = defineClass;
+    }
+
+    public static PluginDefine build(String define) throws IllegalPluginDefineException {
+        if (StringUtil.isEmpty(define)) {
+            throw new IllegalPluginDefineException();","[{'comment': 'Not constructor parameter, why?', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginDefine.java,"@@ -0,0 +1,49 @@
+package org.skywalking.apm.agent.core.plugin;
+
+import java.util.List;
+import org.skywalking.apm.agent.core.conf.Config;
+import org.skywalking.apm.agent.core.plugin.exception.IllegalPluginDefineException;
+import org.skywalking.apm.util.StringUtil;
+
+public class PluginDefine {
+    /**
+     * Plugin name.
+     */
+    private String name;
+
+    /**
+     * The class name of plugin defined.
+     */
+    private String defineClass;
+
+    private PluginDefine() {
+    }
+
+    private PluginDefine(String name, String defineClass) {
+        this.name = name;
+        this.defineClass = defineClass;
+    }
+
+    public static PluginDefine build(String define) throws IllegalPluginDefineException {
+        if (StringUtil.isEmpty(define)) {
+            throw new IllegalPluginDefineException();
+        }
+
+        String[] pluginDefine = define.split(""="");
+        if (pluginDefine.length != 2) {
+            throw new IllegalPluginDefineException();","[{'comment': 'Not constructor parameter, why?', 'commenter': 'wu-sheng'}]"
191,apm-commons/apm-util/src/main/java/org/skywalking/apm/util/ConfigInitializer.java,"@@ -46,6 +49,19 @@ else if (type.isEnum())
             parentDesc.removeLastDesc();
         }
     }
+
+    private static List convert2List(String value) {
+        List result = new LinkedList();
+        if (StringUtil.isEmpty(value)) {
+            return result;
+        }
+
+        String[] segments = value.split("","");
+        for (String segment : segments) {
+            result.add(segment);","[{'comment': 'You miss `segment.trim()` and avoid empty string.', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/exception/IllegalPluginDefineException.java,"@@ -0,0 +1,11 @@
+package org.skywalking.apm.agent.core.plugin.exception;
+
+/**
+ * {@link IllegalPluginDefineException} present that the value of plugin define can
+ * not be formatted.","[{'comment': ""Can't understand the comments....."", 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/resources/skywalking-plugin.def,"@@ -1,2 +1,2 @@
-org.skywalking.apm.toolkit.activation.opentracing.span.SkyWalkingSpanActivation
-org.skywalking.apm.toolkit.activation.opentracing.tracer.SkyWalkingTracerActivation
+opentracing-0.20.x=org.skywalking.apm.toolkit.activation.opentracing.span.SkyWalkingSpanActivation
+opentracing-0.20.x=org.skywalking.apm.toolkit.activation.opentracing.tracer.SkyWalkingTracerActivation","[{'comment': '`opentracing` activation is based on our application toolkit, so the name should not include version, especially ot version. Keep the name just `opentracing`', 'commenter': 'wu-sheng'}]"
191,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-context-activation/src/main/resources/skywalking-plugin.def,"@@ -1 +1 @@
-org.skywalking.apm.toolkit.activation.trace.TraceContextActivation
\ No newline at end of file
+tracecontext-3.x=org.skywalking.apm.toolkit.activation.trace.TraceContextActivation","[{'comment': 'Where does `3.x` comes from? Our project version?  Same as opentracing-toolkit-activation, just `tracecontext` is enough.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/httpserver/AbstractPost.java,"@@ -40,35 +42,66 @@ final public void onWork(Object message) throws Exception {
             this.ownerWorkerRef = ownerWorkerRef;
         }
 
-        @Override
-        final protected void doPost(HttpServletRequest request,
-                                    HttpServletResponse response) throws ServletException, IOException {
+        /**
+         * Get segment's buffer from request then execute deserialize operation.
+         *
+         * @param request an {@link HttpServletRequest} object that contains the request the client has made of the
+         * servlet
+         * @param response {@link HttpServletResponse} object that contains the response the servlet sends to the
+         * client
+         * @throws ServletException if the request for the POST could not be handled
+         * @throws IOException if an input or output error is detected when the servlet handles the request
+         */
+        @Override final protected void doPost(HttpServletRequest request,
+            HttpServletResponse response) throws ServletException, IOException {
             JsonObject resJson = new JsonObject();
             try {
                 BufferedReader bufferedReader = request.getReader();
                 streamReader(bufferedReader);
                 reply(response, resJson, HttpServletResponse.SC_OK);
             } catch (Exception e) {
-                logger.error(e);
+                logger.error(e, e);
                 resJson.addProperty(""error"", e.getMessage());
                 reply(response, resJson, HttpServletResponse.SC_INTERNAL_SERVER_ERROR);
             }
         }
 
+        /**
+         * Read segment's buffer from buffer reader by stream mode. when finish read one segment then send to analysis.
+         * This method in there, so post servlet just can receive segments data.","[{'comment': ""Read segments from buffer in streaming mode. Send to analysis after each one of segments deserialized. \r\n\r\nI can't understand about `This method in there, so post servlet just can receive segments data.`.\r\n"", 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/httpserver/AbstractPost.java,"@@ -40,35 +42,66 @@ final public void onWork(Object message) throws Exception {
             this.ownerWorkerRef = ownerWorkerRef;
         }
 
-        @Override
-        final protected void doPost(HttpServletRequest request,
-                                    HttpServletResponse response) throws ServletException, IOException {
+        /**
+         * Get segment's buffer from request then execute deserialize operation.
+         *
+         * @param request an {@link HttpServletRequest} object that contains the request the client has made of the
+         * servlet
+         * @param response {@link HttpServletResponse} object that contains the response the servlet sends to the
+         * client
+         * @throws ServletException if the request for the POST could not be handled
+         * @throws IOException if an input or output error is detected when the servlet handles the request
+         */
+        @Override final protected void doPost(HttpServletRequest request,
+            HttpServletResponse response) throws ServletException, IOException {
             JsonObject resJson = new JsonObject();
             try {
                 BufferedReader bufferedReader = request.getReader();
                 streamReader(bufferedReader);
                 reply(response, resJson, HttpServletResponse.SC_OK);
             } catch (Exception e) {
-                logger.error(e);
+                logger.error(e, e);
                 resJson.addProperty(""error"", e.getMessage());
                 reply(response, resJson, HttpServletResponse.SC_INTERNAL_SERVER_ERROR);
             }
         }
 
+        /**
+         * Read segment's buffer from buffer reader by stream mode. when finish read one segment then send to analysis.
+         * This method in there, so post servlet just can receive segments data.
+         *
+         * @param bufferedReader an {@link BufferedReader} object that contains the segment's data using the construct of chars.
+         * @throws Exception
+         */
         private void streamReader(BufferedReader bufferedReader) throws Exception {
-            try (JsonReader reader = new JsonReader(bufferedReader)) {
-                readSegmentArray(reader);
-            }
-        }
+            Segment segment;
+            do {
+                int character;
+                StringBuilder builder = new StringBuilder();
+                while ((character = bufferedReader.read()) != ' ') {
+                    if (character == -1) {
+                        return;
+                    }
+                    builder.append((char)character);
+                }
+
+                int length = Integer.valueOf(builder.toString());
+                builder = new StringBuilder();
+
+                char[] buffer = new char[length];
+                int readLength = bufferedReader.read(buffer, 0, length);
+                if (readLength != length) {
+                    logger.error(""The actual data length was different from the length in data head! "");","[{'comment': 'I highly recommend logging these part of segment string!', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/httpserver/AbstractPost.java,"@@ -40,35 +42,66 @@ final public void onWork(Object message) throws Exception {
             this.ownerWorkerRef = ownerWorkerRef;
         }
 
-        @Override
-        final protected void doPost(HttpServletRequest request,
-                                    HttpServletResponse response) throws ServletException, IOException {
+        /**
+         * Get segment's buffer from request then execute deserialize operation.
+         *
+         * @param request an {@link HttpServletRequest} object that contains the request the client has made of the
+         * servlet
+         * @param response {@link HttpServletResponse} object that contains the response the servlet sends to the
+         * client
+         * @throws ServletException if the request for the POST could not be handled
+         * @throws IOException if an input or output error is detected when the servlet handles the request
+         */
+        @Override final protected void doPost(HttpServletRequest request,
+            HttpServletResponse response) throws ServletException, IOException {
             JsonObject resJson = new JsonObject();
             try {
                 BufferedReader bufferedReader = request.getReader();
                 streamReader(bufferedReader);
                 reply(response, resJson, HttpServletResponse.SC_OK);
             } catch (Exception e) {
-                logger.error(e);
+                logger.error(e, e);
                 resJson.addProperty(""error"", e.getMessage());
                 reply(response, resJson, HttpServletResponse.SC_INTERNAL_SERVER_ERROR);","[{'comment': 'Reply for?  The agent will not do anything.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/segment/entity/SegmentDeserialize.java,"@@ -1,45 +1,54 @@
 package org.skywalking.apm.collector.worker.segment.entity;
 
-import com.google.gson.stream.JsonReader;
-
+import com.google.gson.Gson;
+import com.google.gson.JsonArray;
 import java.io.FileReader;
 import java.io.IOException;
-import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
+ * The <code>SegmentDeserialize</code> provides single segment json string deserialize and segment array file
+ * deserialize.
+ *
  * @author pengys5
+ * @since v3.0-2017","[{'comment': ""Why has `since`? Even you want to add this, actually shouldn't, we are not in `v3.0-2017`"", 'commenter': 'wu-sheng'}, {'comment': 'I want to see the life cycle about the class which i written.', 'commenter': 'peng-yongsheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/segment/entity/SegmentDeserialize.java,"@@ -1,45 +1,54 @@
 package org.skywalking.apm.collector.worker.segment.entity;
 
-import com.google.gson.stream.JsonReader;
-
+import com.google.gson.Gson;
+import com.google.gson.JsonArray;
 import java.io.FileReader;
 import java.io.IOException;
-import java.io.StringReader;
 import java.util.ArrayList;
 import java.util.List;
 
 /**
+ * The <code>SegmentDeserialize</code> provides single segment json string deserialize and segment array file
+ * deserialize.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
 public enum SegmentDeserialize {","[{'comment': '`SegmentDeserialize` is part of official src class, and reading segments from file is definitely part of testing. You should define your class carefully.', 'commenter': 'wu-sheng'}, {'comment': 'Now this class would use to deserialize the segment data loaded from es.', 'commenter': 'peng-yongsheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.","[{'comment': ' The <code>AbstractLocalSyncWorker</code> defines workers who receive data from jvm inside call and response in real time.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.
+ *
+ * <p> The implementation class is same as normal class, it make the framework be similar to the asynchronous
+ * workers inside jvm and outside jvm.","[{'comment': 'it **makes** the framework be similar with other local/remote asynchronous workers.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.
+ *
+ * <p> The implementation class is same as normal class, it make the framework be similar to the asynchronous
+ * workers inside jvm and outside jvm.
+ *
  * @author pengys5
+ * @since v3.0-2017","[{'comment': 'All collector code are since v3.0. Just putting these comments in some of them, is strange.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.
+ *
+ * <p> The implementation class is same as normal class, it make the framework be similar to the asynchronous
+ * workers inside jvm and outside jvm.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
 public abstract class AbstractLocalSyncWorker extends AbstractLocalWorker {
     public AbstractLocalSyncWorker(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
+    /**
+     * Called by the worker reference to execute the worker service.
+     *
+     * @param request {@link Object} is a in parameter
+     * @param response {@link Object} is a out parameter","[{'comment': 'I assume your comments mean **an input/output paramter**?', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.
+ *
+ * <p> The implementation class is same as normal class, it make the framework be similar to the asynchronous
+ * workers inside jvm and outside jvm.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
 public abstract class AbstractLocalSyncWorker extends AbstractLocalWorker {
     public AbstractLocalSyncWorker(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
+    /**
+     * Called by the worker reference to execute the worker service.
+     *
+     * @param request {@link Object} is a in parameter
+     * @param response {@link Object} is a out parameter
+     * @throws Exception
+     */
     final public void allocateJob(Object request, Object response) throws Exception {
         onWork(request, response);
     }
 
+    /**
+     * Override this method to implementing business logic.","[{'comment': '`to implement` or `for implementing`', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.
+ *
+ * <p> The implementation class is same as normal class, it make the framework be similar to the asynchronous
+ * workers inside jvm and outside jvm.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
 public abstract class AbstractLocalSyncWorker extends AbstractLocalWorker {
     public AbstractLocalSyncWorker(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
+    /**
+     * Called by the worker reference to execute the worker service.
+     *
+     * @param request {@link Object} is a in parameter
+     * @param response {@link Object} is a out parameter
+     * @throws Exception","[{'comment': 'If you want to add comments about `@thorws`, your comments should be about when and why.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-cluster/src/main/java/org/skywalking/apm/collector/actor/AbstractLocalSyncWorker.java,"@@ -1,19 +1,46 @@
 package org.skywalking.apm.collector.actor;
 
 /**
+ * The <code>AbstractLocalSyncWorker</code> use to define workers that receive data from jvm inside call and the
+ * workers response result in real time.
+ *
+ * <p> The implementation class is same as normal class, it make the framework be similar to the asynchronous
+ * workers inside jvm and outside jvm.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
 public abstract class AbstractLocalSyncWorker extends AbstractLocalWorker {
     public AbstractLocalSyncWorker(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
+    /**
+     * Called by the worker reference to execute the worker service.
+     *
+     * @param request {@link Object} is a in parameter
+     * @param response {@link Object} is a out parameter
+     * @throws Exception
+     */
     final public void allocateJob(Object request, Object response) throws Exception {
         onWork(request, response);
     }
 
+    /**
+     * Override this method to implementing business logic.
+     *
+     * @param request {@link Object} is a in parameter
+     * @param response {@link Object} is a out parameter
+     * @throws Exception
+     */
     protected abstract void onWork(Object request, Object response) throws Exception;
 
+    /**
+     * Called by the worker on start.","[{'comment': 'Prepare methods before this work starts to work. The comments shoule be about purposes, not codes logic.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/globaltrace/GlobalTraceGetWithGlobalId.java,"@@ -33,14 +32,13 @@ public void preStart() throws ProviderNotFoundException {
         getClusterContext().findProvider(GlobalTraceSearchWithGlobalId.WorkerRole.INSTANCE).create(this);
     }
 
-    @Override
-    protected void onSearch(Map<String, String[]> request, JsonObject response) throws Exception {
-        if (!request.containsKey(""globalId"")) {
+    @Override protected void onReceive(Map<String, String[]> parameter, JsonObject response) throws Exception {
+        if (!parameter.containsKey(""globalId"")) {
             throw new IllegalArgumentException(""the request parameter must contains globalId"");
         }
-        logger.debug(""globalId: %s"", Arrays.toString(request.get(""globalId"")));
+        logger.debug(""globalId: %s"", Arrays.toString(parameter.get(""globalId"")));","[{'comment': '`Arrays.toString(parameter.get(""globalId"")` has too much cost. You should add an `isDebug` enable before `logger.debug` for considering perfomance.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/httpserver/AbstractGet.java,"@@ -1,56 +1,73 @@
 package org.skywalking.apm.collector.worker.httpserver;
 
 import com.google.gson.JsonObject;
-import org.skywalking.apm.collector.actor.*;
-
+import java.io.IOException;
+import java.util.Map;
 import javax.servlet.ServletException;
+import javax.servlet.http.HttpServlet;
 import javax.servlet.http.HttpServletRequest;
 import javax.servlet.http.HttpServletResponse;
-import java.io.IOException;
-import java.util.Map;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalSyncWorkerRef;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.Role;
 
 /**
+ * The <code>AbstractGet</code> implementations represent workers, which called by the server to allow a servlet to
+ * handle a GET request.
+ *
+ * <p>verride the {@link #onReceive(Map, JsonObject)} method to support a search service.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
-public abstract class AbstractGet extends AbstractLocalSyncWorker {
+public abstract class AbstractGet extends AbstractServlet {
 
     protected AbstractGet(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
-    @Override
-    final public void onWork(Object request, Object response) throws Exception {
-        Map<String, String[]> parameterMap = (Map<String, String[]>) request;
-        try {
-            onSearch(parameterMap, (JsonObject) response);
-        } catch (Exception e) {
-            ((JsonObject) response).addProperty(""isSuccess"", false);
-            ((JsonObject) response).addProperty(""reason"", e.getMessage());
-        }
+    /**
+     * Add final modifier to avoid the subclass override this method.","[{'comment': ""`final` signature already meands can't override. Shouldn't add comments about it."", 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/segment/SegmentTopGetWithGlobalTraceId.java,"@@ -33,29 +32,28 @@ public void preStart() throws ProviderNotFoundException {
         getClusterContext().findProvider(SegmentTopSearchWithGlobalTraceId.WorkerRole.INSTANCE).create(this);
     }
 
-    @Override
-    protected void onSearch(Map<String, String[]> request, JsonObject response) throws Exception {
-        if (!request.containsKey(""globalTraceId"") || !request.containsKey(""from"") || !request.containsKey(""limit"")) {
+    @Override protected void onReceive(Map<String, String[]> parameter, JsonObject response) throws Exception {
+        if (!parameter.containsKey(""globalTraceId"") || !parameter.containsKey(""from"") || !parameter.containsKey(""limit"")) {
             throw new IllegalArgumentException(""the request parameter must contains globalTraceId, from, limit"");
         }
-        logger.debug(""globalTraceId: %s, from: %s, limit: %s"", Arrays.toString(request.get(""globalTraceId"")),
-            Arrays.toString(request.get(""from"")), Arrays.toString(request.get(""limit"")));
+        logger.debug(""globalTraceId: %s, from: %s, limit: %s"", Arrays.toString(parameter.get(""globalTraceId"")),
+            Arrays.toString(parameter.get(""from"")), Arrays.toString(parameter.get(""limit"")));","[{'comment': 'Same concern about performance when no need of debug logging.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/segment/SegmentTopGetWithTimeSlice.java,"@@ -33,49 +32,48 @@ public void preStart() throws ProviderNotFoundException {
         getClusterContext().findProvider(SegmentTopSearchWithTimeSlice.WorkerRole.INSTANCE).create(this);
     }
 
-    @Override
-    protected void onSearch(Map<String, String[]> request, JsonObject response) throws Exception {
-        if (!request.containsKey(""startTime"") || !request.containsKey(""endTime"") || !request.containsKey(""from"") || !request.containsKey(""limit"")) {
+    @Override protected void onReceive(Map<String, String[]> parameter, JsonObject response) throws Exception {
+        if (!parameter.containsKey(""startTime"") || !parameter.containsKey(""endTime"") || !parameter.containsKey(""from"") || !parameter.containsKey(""limit"")) {
             throw new IllegalArgumentException(""the request parameter must contains startTime, endTime, from, limit"");
         }
-        logger.debug(""startTime: %s, endTime: %s, from: %s"", Arrays.toString(request.get(""startTime"")),
-            Arrays.toString(request.get(""endTime"")), Arrays.toString(request.get(""from"")));
+        logger.debug(""startTime: %s, endTime: %s, from: %s"", Arrays.toString(parameter.get(""startTime"")),
+            Arrays.toString(parameter.get(""endTime"")), Arrays.toString(parameter.get(""from"")));","[{'comment': 'Same concern about array and debug.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/segment/SegmentTopGetWithGlobalTraceId.java,"@@ -33,29 +32,28 @@ public void preStart() throws ProviderNotFoundException {
         getClusterContext().findProvider(SegmentTopSearchWithGlobalTraceId.WorkerRole.INSTANCE).create(this);
     }
 
-    @Override
-    protected void onSearch(Map<String, String[]> request, JsonObject response) throws Exception {
-        if (!request.containsKey(""globalTraceId"") || !request.containsKey(""from"") || !request.containsKey(""limit"")) {
+    @Override protected void onReceive(Map<String, String[]> parameter, JsonObject response) throws Exception {
+        if (!parameter.containsKey(""globalTraceId"") || !parameter.containsKey(""from"") || !parameter.containsKey(""limit"")) {
             throw new IllegalArgumentException(""the request parameter must contains globalTraceId, from, limit"");
         }
-        logger.debug(""globalTraceId: %s, from: %s, limit: %s"", Arrays.toString(request.get(""globalTraceId"")),
-            Arrays.toString(request.get(""from"")), Arrays.toString(request.get(""limit"")));
+        logger.debug(""globalTraceId: %s, from: %s, limit: %s"", Arrays.toString(parameter.get(""globalTraceId"")),
+            Arrays.toString(parameter.get(""from"")), Arrays.toString(parameter.get(""limit"")));
 
         int from;
         try {
-            from = Integer.valueOf(ParameterTools.INSTANCE.toString(request, ""from""));
+            from = Integer.valueOf(ParameterTools.INSTANCE.toString(parameter, ""from""));
         } catch (NumberFormatException e) {
             throw new IllegalArgumentException(""the request parameter from must numeric with int type"");
         }
 
         int limit;
         try {
-            limit = Integer.valueOf(ParameterTools.INSTANCE.toString(request, ""limit""));
+            limit = Integer.valueOf(ParameterTools.INSTANCE.toString(parameter, ""limit""));
         } catch (NumberFormatException e) {
             throw new IllegalArgumentException(""the request parameter from must numeric with int type"");","[{'comment': 'The request parameter is `limit`, not ` from`.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/tracedag/TraceDagGetWithTimeSlice.java,"@@ -40,29 +39,28 @@ public void preStart() throws ProviderNotFoundException {
         getClusterContext().findProvider(NodeRefResSumSearchWithTimeSlice.WorkerRole.INSTANCE).create(this);
     }
 
-    @Override
-    protected void onSearch(Map<String, String[]> request, JsonObject response) throws Exception {
-        if (!request.containsKey(""startTime"") || !request.containsKey(""endTime"") || !request.containsKey(""timeSliceType"")) {
+    @Override protected void onReceive(Map<String, String[]> parameter, JsonObject response) throws Exception {
+        if (!parameter.containsKey(""startTime"") || !parameter.containsKey(""endTime"") || !parameter.containsKey(""timeSliceType"")) {
             throw new IllegalArgumentException(""the request parameter must contains startTime,endTime,timeSliceType"");
         }
-        logger.debug(""startTime: %s, endTime: %s, timeSliceType: %s"", Arrays.toString(request.get(""startTime"")),
-            Arrays.toString(request.get(""endTime"")), Arrays.toString(request.get(""timeSliceType"")));
+        logger.debug(""startTime: %s, endTime: %s, timeSliceType: %s"", Arrays.toString(parameter.get(""startTime"")),
+            Arrays.toString(parameter.get(""endTime"")), Arrays.toString(parameter.get(""timeSliceType"")));","[{'comment': 'Debug and array again.', 'commenter': 'wu-sheng'}]"
215,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/httpserver/AbstractPost.java,"@@ -1,74 +1,74 @@
 package org.skywalking.apm.collector.worker.httpserver;
 
 import com.google.gson.JsonObject;
-import com.google.gson.stream.JsonReader;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
-import org.skywalking.apm.collector.actor.*;
-import org.skywalking.apm.collector.worker.segment.entity.Segment;
-
+import java.io.IOException;
+import java.util.Map;
 import javax.servlet.ServletException;
+import javax.servlet.http.HttpServlet;
 import javax.servlet.http.HttpServletRequest;
 import javax.servlet.http.HttpServletResponse;
-import java.io.BufferedReader;
-import java.io.IOException;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalSyncWorkerRef;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.Role;
 
 /**
+ * The <code>AbstractGet</code> implementations represent workers, which called by the server to allow a servlet to
+ * handle a POST request.
+ *
+ * <p>verride the {@link #onReceive(Map, JsonObject)} method to support a search service.
+ *
  * @author pengys5
+ * @since v3.0-2017
  */
-
-public abstract class AbstractPost extends AbstractLocalAsyncWorker {
+public abstract class AbstractPost extends AbstractServlet {
 
     public AbstractPost(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
         super(role, clusterContext, selfContext);
     }
 
-    @Override
-    final public void onWork(Object message) throws Exception {
-        onReceive(message);
+    /**
+     * Add final modifier to avoid the subclass override this method.
+     *
+     * @param parameter {@link Object} data structure of the map
+     * @param response {@link Object} is a out parameter
+     * @throws Exception
+     */
+    @Override final protected void onWork(Object parameter, Object response) throws Exception {
+        super.onWork(parameter, response);
     }
 
-    protected abstract void onReceive(Object message) throws Exception;
-
-    static class PostWithHttpServlet extends AbstractHttpServlet {
+    static class PostWithHttpServlet extends HttpServlet {
 
         private Logger logger = LogManager.getFormatterLogger(PostWithHttpServlet.class);
 
-        private final LocalAsyncWorkerRef ownerWorkerRef;
+        private final LocalSyncWorkerRef ownerWorkerRef;
 
-        PostWithHttpServlet(LocalAsyncWorkerRef ownerWorkerRef) {
+        PostWithHttpServlet(LocalSyncWorkerRef ownerWorkerRef) {
             this.ownerWorkerRef = ownerWorkerRef;
         }
 
-        @Override
-        final protected void doPost(HttpServletRequest request,
-                                    HttpServletResponse response) throws ServletException, IOException {
-            JsonObject resJson = new JsonObject();
+        /**
+         * Override the {@link HttpServlet#doPost(HttpServletRequest, HttpServletResponse)} method, receive the
+         * parameter from request then send parameter to the owner worker.
+         *
+         * @param request an {@link HttpServletRequest} object that contains the request the client has made of the
+         * servlet
+         * @param response {@link HttpServletResponse} object that contains the response the servlet sends to the
+         * client
+         * @throws ServletException if the request for the POST could not be handled
+         * @throws IOException if an input or output error is detected when the servlet handles the request
+         */
+        @Override final protected void doPost(HttpServletRequest request,
+            HttpServletResponse response) throws ServletException, IOException {
             try {
-                BufferedReader bufferedReader = request.getReader();
-                streamReader(bufferedReader);
-                reply(response, resJson, HttpServletResponse.SC_OK);
+                Map<String, String[]> parameter = request.getParameterMap();","[{'comment': 'Should we process the request body context ? because `Request#getParameterMap()` only fetch parameters are contained in the query string or posted form data.', 'commenter': 'ascrutae'}, {'comment': ""@ascrutae  IMO, you have a little over-design. Most POST and GET requests are based on parameterMap, at least right now, didn't see the requirements. At the same time, he has provided the stream-mode to process the body.\r\n\r\n@pengys5 thoughts?"", 'commenter': 'wu-sheng'}]"
221,apm-commons/apm-trace/src/main/java/org/skywalking/apm/trace/Span.java,"@@ -293,18 +293,29 @@ public Span log(Throwable t) {
     private enum ThrowableTransformer {
         INSTANCE;
 
+        private static final int MAX_STACK_ELEMENT_LENGTH = 120;
+
         private String convert2String(Throwable e, int maxLength) {
             ByteArrayOutputStream buf = null;
             StringBuilder expMessage = new StringBuilder();
             try {
                 buf = new ByteArrayOutputStream();
                 Throwable causeException = e;
+                int currentAppendStackLength = 0;
                 while (expMessage.length() < maxLength && causeException != null) {
+                    int causeExceptionStackLength = causeException.getStackTrace().length;
+                    if (currentAppendStackLength + causeExceptionStackLength > MAX_STACK_ELEMENT_LENGTH) {
+                        break;
+                    }
+
                     causeException.printStackTrace(new java.io.PrintWriter(buf, true));
                     expMessage.append(buf.toString());
                     causeException = causeException.getCause();
+                    currentAppendStackLength += causeExceptionStackLength;
                 }
 
+            } catch (Throwable ee) {
+                expMessage.append(""Failed to execute org.skywalking.apm.trace.ThrowableTransformer#convert2String, Exception message : "" + ee.getMessage());","[{'comment': ""This is safe mechanism, and the message will be at user UI. So I don't like `Failed to execute org.skywalking.apm.trace.ThrowableTransformer#convert2String,`, please remove them.\r\n\r\nIf you want add some comments, you can add these `Stack isn't avaible, message is:`"", 'commenter': 'wu-sheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/httpserver/AbstractPost.java,"@@ -2,60 +2,46 @@
 
 import com.google.gson.JsonObject;
 import com.google.gson.stream.JsonReader;
-import org.apache.logging.log4j.LogManager;
-import org.apache.logging.log4j.Logger;
-import org.skywalking.apm.collector.actor.*;
-import org.skywalking.apm.collector.worker.segment.entity.Segment;
-
-import javax.servlet.ServletException;
-import javax.servlet.http.HttpServletRequest;
-import javax.servlet.http.HttpServletResponse;
 import java.io.BufferedReader;
-import java.io.IOException;
+import org.skywalking.apm.collector.actor.AbstractLocalSyncWorker;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalSyncWorkerRef;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.Role;
+import org.skywalking.apm.collector.actor.WorkerRef;
+import org.skywalking.apm.collector.worker.instance.entity.RegistryInfo;
+import org.skywalking.apm.collector.worker.instance.entity.HeartBeat;
+import org.skywalking.apm.collector.worker.segment.entity.Segment;
 
 /**
  * @author pengys5
  */
 
-public abstract class AbstractPost extends AbstractLocalAsyncWorker {
+public abstract class AbstractPost extends AbstractLocalSyncWorker {","[{'comment': '@pengys5 , I think this class has been refactor in your new version collector. Please send your pr first.', 'commenter': 'wu-sheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/IdentificationCache.java,"@@ -0,0 +1,57 @@
+package org.skywalking.apm.collector.worker.instance;
+
+class IdentificationCache {
+    private static final IdentificationCache INSTANCE = new IdentificationCache();
+
+    State state;
+    IdentificationSegment segment;
+
+    private IdentificationCache() {
+        state = State.NORMAL;
+    }
+
+    public synchronized long fetchInstanceId() {
+        if (state == State.ABNORMAL) {
+            return -1;
+        }
+
+        if (!segment.hasNext()) {
+            IdentificationSegmentFetcher.INSTANCE.fetchSegment(new IdentificationSegmentFetcher.Listener() {
+                @Override
+                public void failed() {
+                    state = State.ABNORMAL;
+                    IdentificationSegmentFetcher.INSTANCE.fetchSegmentInBackGround(INSTANCE);
+                }
+
+                @Override
+                public void success(IdentificationSegment idSegment) {
+                    segment = idSegment;
+                }
+            });
+        }
+
+        return segment.nextInstanceId();
+    }
+
+    public static IdentificationCache initCache() {
+        IdentificationSegmentFetcher.INSTANCE.fetchSegment(new IdentificationSegmentFetcher.Listener() {
+            @Override
+            public void failed() {
+                INSTANCE.state = State.ABNORMAL;
+                IdentificationSegmentFetcher.INSTANCE.fetchSegmentInBackGround(INSTANCE);","[{'comment': 'I think you are facing the concurrency situation here. IMO, your `fetchSegmentInBackGround` is not good enough.', 'commenter': 'wu-sheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/IdentificationSegmentFetcher.java,"@@ -0,0 +1,67 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import java.util.Random;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.worker.instance.util.ESLock;
+
+public enum IdentificationSegmentFetcher {
+    INSTANCE;
+
+    private ScheduledFuture task;
+    private Logger logger = LogManager.getLogger(IdentificationSegmentFetcher.class);
+    private ESLock esLock = new ESLock();
+
+    public void fetchSegment(Listener listener) {
+        for (int index = 0; index < 3; index++) {
+            boolean updateSuccess = esLock.tryLock((start, end) -> {
+                listener.success(new IdentificationSegment(start, end));
+            });
+
+            if (updateSuccess) {
+                return;
+            } else {
+                try {
+                    Thread.sleep(new Random().nextInt(1000));
+                } catch (InterruptedException e) {
+                }
+            }
+        }
+
+        listener.failed();
+    }
+
+    public void fetchSegmentInBackGround(final IdentificationCache cache) {
+        if (task != null) {
+            logger.info(""Fetch segment task already running."");
+            return;
+        }
+
+        task = Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -> fetchSegment(new Listener() {","[{'comment': ""Create a thread task for without any lock. When your cache fails, maybe more than one request ask for `fetchSegmentInBackGround`, the `task != null` can't guarantee the task is initialized once."", 'commenter': 'wu-sheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/IdentificationSegmentFetcher.java,"@@ -0,0 +1,67 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import java.util.Random;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.worker.instance.util.ESLock;
+
+public enum IdentificationSegmentFetcher {
+    INSTANCE;
+
+    private ScheduledFuture task;
+    private Logger logger = LogManager.getLogger(IdentificationSegmentFetcher.class);
+    private ESLock esLock = new ESLock();
+
+    public void fetchSegment(Listener listener) {
+        for (int index = 0; index < 3; index++) {
+            boolean updateSuccess = esLock.tryLock((start, end) -> {
+                listener.success(new IdentificationSegment(start, end));
+            });
+
+            if (updateSuccess) {
+                return;
+            } else {
+                try {
+                    Thread.sleep(new Random().nextInt(1000));","[{'comment': ""Why need `random.nextInt`? Why can't use a constant value?"", 'commenter': 'wu-sheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/config/WorkerConfig.java,"@@ -76,6 +80,10 @@
             public static class SegmentExceptionAnalysis {
                 public static int SIZE = 4096;
             }
+
+            public class PingTimeAnalysis {","[{'comment': 'not belong to NodeRef, create Instance class and belong to it', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/config/WorkerConfig.java,"@@ -48,6 +48,10 @@
             public static class NodeRefResSumMinuteAgg {
                 public static int VALUE = 2;
             }
+
+            public static class PingTimeAgg {","[{'comment': 'not belong to NodeRef, create Instance class and belong to it', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/PingPost.java,"@@ -0,0 +1,85 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import com.google.gson.JsonObject;
+import java.io.BufferedReader;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.Role;
+import org.skywalking.apm.collector.actor.WorkerInvokeException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPost;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPostProvider;
+import org.skywalking.apm.collector.worker.httpserver.ArgumentsParseException;
+import org.skywalking.apm.collector.worker.instance.analysis.PingTimeAnalysis;
+import org.skywalking.apm.collector.worker.instance.entity.InstanceDeserialize;
+import org.skywalking.apm.collector.worker.instance.entity.PingInfo;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class PingPost extends AbstractStreamPost {
+
+    private Logger logger = LogManager.getFormatterLogger(PingPost.class);
+
+    public PingPost(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    protected void onReceive(BufferedReader reader,
+        JsonObject response) throws ArgumentsParseException, WorkerInvokeException, WorkerNotFoundException {
+        try {
+            PingInfo pingInfo = InstanceDeserialize.INSTANCE.deserializePingInfo(reader.readLine());
+            validatePingInfo(pingInfo);
+            getSelfContext().lookup(PingTimeAnalysis.Role.INSTANCE).tell(new PingTimeAnalysis.Ping(pingInfo.getInstanceId()));
+        } catch (Exception e) {
+            logger.error(""Failed to save ping data."", e);
+        }
+    }
+
+    private void validatePingInfo(PingInfo info) {","[{'comment': 'create abstract method in super class and modify all post and get class', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/PingPost.java,"@@ -0,0 +1,85 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import com.google.gson.JsonObject;
+import java.io.BufferedReader;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.Role;
+import org.skywalking.apm.collector.actor.WorkerInvokeException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPost;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPostProvider;
+import org.skywalking.apm.collector.worker.httpserver.ArgumentsParseException;
+import org.skywalking.apm.collector.worker.instance.analysis.PingTimeAnalysis;
+import org.skywalking.apm.collector.worker.instance.entity.InstanceDeserialize;
+import org.skywalking.apm.collector.worker.instance.entity.PingInfo;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class PingPost extends AbstractStreamPost {
+
+    private Logger logger = LogManager.getFormatterLogger(PingPost.class);
+
+    public PingPost(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    protected void onReceive(BufferedReader reader,
+        JsonObject response) throws ArgumentsParseException, WorkerInvokeException, WorkerNotFoundException {
+        try {
+            PingInfo pingInfo = InstanceDeserialize.INSTANCE.deserializePingInfo(reader.readLine());
+            validatePingInfo(pingInfo);
+            getSelfContext().lookup(PingTimeAnalysis.Role.INSTANCE).tell(new PingTimeAnalysis.Ping(pingInfo.getInstanceId()));
+        } catch (Exception e) {
+            logger.error(""Failed to save ping data."", e);
+        }
+    }
+
+    private void validatePingInfo(PingInfo info) {
+        if (info == null || info.getInstanceId() == -1) {
+            throw new IllegalArgumentException(""Cannot serialize ping info."");","[{'comment': 'use ArgumentsParseException', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/RegistryPost.java,"@@ -0,0 +1,92 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import com.google.gson.JsonObject;
+import java.io.BufferedReader;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.Role;
+import org.skywalking.apm.collector.actor.WorkerInvokeException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPost;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPostProvider;
+import org.skywalking.apm.collector.worker.httpserver.ArgumentsParseException;
+import org.skywalking.apm.collector.worker.instance.analysis.InstanceAnalysis;
+import org.skywalking.apm.collector.worker.instance.entity.InstanceDeserialize;
+import org.skywalking.apm.collector.worker.instance.entity.RegistryInfo;
+import org.skywalking.apm.collector.worker.instance.util.IDSequenceCache;
+import org.skywalking.apm.util.StringUtil;
+
+public class RegistryPost extends AbstractStreamPost {
+
+    private Logger logger = LogManager.getFormatterLogger(RegistryPost.class);
+
+    public RegistryPost(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    protected void onReceive(BufferedReader reader,
+        JsonObject response) throws ArgumentsParseException, WorkerInvokeException, WorkerNotFoundException {
+        try {
+            long instanceId = IDSequenceCache.INSTANCE.fetchInstanceId();
+            RegistryInfo registryInfo = InstanceDeserialize.INSTANCE.deserializeRegistryInfo(reader.readLine());
+
+            validateRegistryInfo(registryInfo);
+
+            InstanceAnalysis.InstanceInfo instanceInfo = new InstanceAnalysis.InstanceInfo(registryInfo.getApplicationCode(), instanceId);
+            getSelfContext().lookup(InstanceAnalysis.Role.INSTANCE).tell(instanceInfo);
+            response.addProperty(""ii"", instanceInfo.getInstanceId());
+            response.addProperty(""pt"", instanceInfo.getRegistryTime());
+        } catch (Exception e) {
+            logger.error(""Register failure."", e);
+            response.addProperty(""ii"", ""-1"");
+        }
+    }
+
+    private void validateRegistryInfo(RegistryInfo info) throws ArgumentsParseException {","[{'comment': 'create abstract method in super class and modify all post and get class', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/analysis/InstanceAnalysis.java,"@@ -0,0 +1,115 @@
+package org.skywalking.apm.collector.worker.instance.analysis;
+
+import com.google.gson.JsonObject;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.AbstractLocalAsyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerRefs;
+import org.skywalking.apm.collector.actor.selector.HashCodeSelector;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordAnalysisMember;
+import org.skywalking.apm.collector.worker.config.WorkerConfig;
+import org.skywalking.apm.collector.worker.instance.persistence.InstanceSave;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class InstanceAnalysis extends RecordAnalysisMember {
+    private Logger logger = LogManager.getFormatterLogger(InstanceAnalysis.class);
+
+    public InstanceAnalysis(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public void preStart() throws ProviderNotFoundException {
+        getClusterContext().findProvider(InstanceSave.Role.INSTANCE).create(this);
+    }
+
+    @Override
+    public void analyse(Object message) {
+        if (message instanceof InstanceInfo) {","[{'comment': 'else and log error', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/analysis/InstanceAnalysis.java,"@@ -0,0 +1,115 @@
+package org.skywalking.apm.collector.worker.instance.analysis;
+
+import com.google.gson.JsonObject;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.AbstractLocalAsyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerRefs;
+import org.skywalking.apm.collector.actor.selector.HashCodeSelector;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordAnalysisMember;
+import org.skywalking.apm.collector.worker.config.WorkerConfig;
+import org.skywalking.apm.collector.worker.instance.persistence.InstanceSave;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class InstanceAnalysis extends RecordAnalysisMember {
+    private Logger logger = LogManager.getFormatterLogger(InstanceAnalysis.class);
+
+    public InstanceAnalysis(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public void preStart() throws ProviderNotFoundException {
+        getClusterContext().findProvider(InstanceSave.Role.INSTANCE).create(this);
+    }
+
+    @Override
+    public void analyse(Object message) {
+        if (message instanceof InstanceInfo) {
+            InstanceInfo registryInfo = (InstanceInfo)message;
+            JsonObject jsonObject = new JsonObject();
+            jsonObject.addProperty(""ac"", registryInfo.getApplicationCode());
+            jsonObject.addProperty(""ii"", registryInfo.getInstanceId());
+            jsonObject.addProperty(""rt"", registryInfo.getRegistryTime());
+            jsonObject.addProperty(""pt"", registryInfo.getLastPingTime());
+            set(String.valueOf(registryInfo.getInstanceId()), jsonObject);
+        }
+    }
+
+    public static class InstanceInfo {
+        private String applicationCode;
+        private long instanceId;
+        private long registryTime;
+        private long lastPingTime;
+
+        public InstanceInfo(String applicationCode, long instanceId) {","[{'comment': 'why this logic in here\r\nregistryTime = DateTools.getMinuteSlice(System.currentTimeMillis());\r\nmove to analyse method', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/analysis/InstanceAnalysis.java,"@@ -0,0 +1,115 @@
+package org.skywalking.apm.collector.worker.instance.analysis;
+
+import com.google.gson.JsonObject;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.AbstractLocalAsyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerRefs;
+import org.skywalking.apm.collector.actor.selector.HashCodeSelector;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordAnalysisMember;
+import org.skywalking.apm.collector.worker.config.WorkerConfig;
+import org.skywalking.apm.collector.worker.instance.persistence.InstanceSave;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class InstanceAnalysis extends RecordAnalysisMember {
+    private Logger logger = LogManager.getFormatterLogger(InstanceAnalysis.class);
+
+    public InstanceAnalysis(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public void preStart() throws ProviderNotFoundException {
+        getClusterContext().findProvider(InstanceSave.Role.INSTANCE).create(this);
+    }
+
+    @Override
+    public void analyse(Object message) {
+        if (message instanceof InstanceInfo) {
+            InstanceInfo registryInfo = (InstanceInfo)message;
+            JsonObject jsonObject = new JsonObject();
+            jsonObject.addProperty(""ac"", registryInfo.getApplicationCode());
+            jsonObject.addProperty(""ii"", registryInfo.getInstanceId());
+            jsonObject.addProperty(""rt"", registryInfo.getRegistryTime());
+            jsonObject.addProperty(""pt"", registryInfo.getLastPingTime());
+            set(String.valueOf(registryInfo.getInstanceId()), jsonObject);
+        }
+    }
+
+    public static class InstanceInfo {
+        private String applicationCode;
+        private long instanceId;
+        private long registryTime;
+        private long lastPingTime;
+
+        public InstanceInfo(String applicationCode, long instanceId) {
+            this.applicationCode = applicationCode;
+            this.instanceId = instanceId;
+            registryTime = DateTools.getMinuteSlice(System.currentTimeMillis());
+            lastPingTime = registryTime;
+        }
+
+        public long getRegistryTime() {
+            return registryTime;
+        }
+
+        public String getApplicationCode() {
+            return applicationCode;
+        }
+
+        public long getLastPingTime() {
+            return lastPingTime;
+        }
+
+        public long getInstanceId() {
+            return instanceId;
+        }
+    }
+
+    @Override
+    protected WorkerRefs aggWorkRefs() {
+        try {
+            return getSelfContext().lookup(InstanceSave.Role.INSTANCE);
+        } catch (WorkerNotFoundException e) {
+            logger.error(""The role of %s worker not found"", InstanceSave.Role.INSTANCE.roleName());
+        }
+        return null;
+    }
+
+    public static class Factory extends AbstractLocalAsyncWorkerProvider<InstanceAnalysis> {
+        @Override
+        public InstanceAnalysis.Role role() {
+            return InstanceAnalysis.Role.INSTANCE;
+        }
+
+        @Override
+        public InstanceAnalysis workerInstance(ClusterWorkerContext clusterContext) {
+            return new InstanceAnalysis(role(), clusterContext, new LocalWorkerContext());
+        }
+
+        @Override
+        public int queueSize() {
+            return WorkerConfig.Queue.Segment.SegmentAnalysis.SIZE;","[{'comment': ""what's this? "", 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/analysis/PingTimeAnalysis.java,"@@ -0,0 +1,98 @@
+package org.skywalking.apm.collector.worker.instance.analysis;
+
+import com.google.gson.JsonObject;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.AbstractLocalAsyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerRefs;
+import org.skywalking.apm.collector.actor.selector.HashCodeSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordAnalysisMember;
+import org.skywalking.apm.collector.worker.config.WorkerConfig;
+import org.skywalking.apm.collector.worker.instance.persistence.PingTimeSave;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class PingTimeAnalysis extends RecordAnalysisMember {
+    private Logger logger = LogManager.getFormatterLogger(PingTimeAnalysis.class);
+
+    public PingTimeAnalysis(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public void analyse(Object message) {
+        if (message instanceof Ping) {","[{'comment': 'else.......', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/analysis/PingTimeAnalysis.java,"@@ -0,0 +1,98 @@
+package org.skywalking.apm.collector.worker.instance.analysis;
+
+import com.google.gson.JsonObject;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.AbstractLocalAsyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.WorkerRefs;
+import org.skywalking.apm.collector.actor.selector.HashCodeSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordAnalysisMember;
+import org.skywalking.apm.collector.worker.config.WorkerConfig;
+import org.skywalking.apm.collector.worker.instance.persistence.PingTimeSave;
+import org.skywalking.apm.collector.worker.tools.DateTools;
+
+public class PingTimeAnalysis extends RecordAnalysisMember {
+    private Logger logger = LogManager.getFormatterLogger(PingTimeAnalysis.class);
+
+    public PingTimeAnalysis(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public void analyse(Object message) {
+        if (message instanceof Ping) {
+            Ping ping = (Ping)message;
+            JsonObject jsonObject = new JsonObject();
+            jsonObject.addProperty(""pt"", ping.getPingTime());
+            set(String.valueOf(ping.getInstanceId()), jsonObject);
+        }
+    }
+
+    @Override
+    protected WorkerRefs aggWorkRefs() {
+        try {
+            return getClusterContext().lookup(PingTimeSave.Role.INSTANCE);
+        } catch (WorkerNotFoundException e) {
+            logger.error(""The role of %s worker not found"", PingTimeSave.Role.INSTANCE.roleName());
+        }
+        return null;
+    }
+
+    public static class Ping {
+        private long instanceId;
+        private long pingTime;
+
+        public Ping(int instanceId) {
+            this.instanceId = instanceId;
+            this.pingTime = DateTools.getMinuteSlice(System.currentTimeMillis());","[{'comment': 'move to analyse method', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/entity/PingInfo.java,"@@ -0,0 +1,13 @@
+package org.skywalking.apm.collector.worker.instance.entity;
+
+import com.google.gson.annotations.SerializedName;
+
+public class PingInfo {","[{'comment': 'why Info....', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/entity/RegistryInfo.java,"@@ -0,0 +1,13 @@
+package org.skywalking.apm.collector.worker.instance.entity;
+
+import com.google.gson.annotations.SerializedName;
+
+public class RegistryInfo {","[{'comment': 'why Info....', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/persistence/InstanceSave.java,"@@ -0,0 +1,70 @@
+package org.skywalking.apm.collector.worker.instance.persistence;
+
+import com.google.gson.Gson;
+import org.skywalking.apm.collector.actor.AbstractLocalSyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordPersistenceMember;
+import org.skywalking.apm.collector.worker.instance.InstanceIndex;
+import org.skywalking.apm.collector.worker.storage.EsClient;
+import org.skywalking.apm.collector.worker.storage.PersistenceWorkerListener;
+import org.skywalking.apm.collector.worker.storage.RecordData;
+
+public class InstanceSave extends RecordPersistenceMember {
+
+    public InstanceSave(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public String esIndex() {
+        return InstanceIndex.INDEX;
+    }
+
+    @Override
+    public String esType() {
+        return InstanceIndex.TYPE_RECORD;
+    }
+
+    @Override
+    public void analyse(Object message) {","[{'comment': 'why override analyse method, should refer to SegmentCostSave', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/persistence/InstanceSave.java,"@@ -0,0 +1,70 @@
+package org.skywalking.apm.collector.worker.instance.persistence;
+
+import com.google.gson.Gson;
+import org.skywalking.apm.collector.actor.AbstractLocalSyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordPersistenceMember;
+import org.skywalking.apm.collector.worker.instance.InstanceIndex;
+import org.skywalking.apm.collector.worker.storage.EsClient;
+import org.skywalking.apm.collector.worker.storage.PersistenceWorkerListener;
+import org.skywalking.apm.collector.worker.storage.RecordData;
+
+public class InstanceSave extends RecordPersistenceMember {
+
+    public InstanceSave(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public String esIndex() {
+        return InstanceIndex.INDEX;
+    }
+
+    @Override
+    public String esType() {
+        return InstanceIndex.TYPE_RECORD;
+    }
+
+    @Override
+    public void analyse(Object message) {
+        if (message instanceof RecordData) {
+            persistence((RecordData)message);
+        }
+    }
+
+    private void persistence(RecordData message) {
+        String recordDataStr = new Gson().toJson(message.get());
+        EsClient.INSTANCE.getClient().prepareIndex(esIndex(), esType(), message.getId()).setSource(recordDataStr).get();
+    }
+
+    public static class Factory extends AbstractLocalSyncWorkerProvider<InstanceSave> {
+        @Override
+        public InstanceSave.Role role() {
+            return InstanceSave.Role.INSTANCE;
+        }
+
+        @Override
+        public InstanceSave workerInstance(ClusterWorkerContext clusterContext) {
+            InstanceSave worker = new InstanceSave(role(), clusterContext, new LocalWorkerContext());
+            PersistenceWorkerListener.INSTANCE.register(worker);
+            return worker;
+        }
+    }
+
+    public enum Role implements org.skywalking.apm.collector.actor.Role {
+        INSTANCE;
+
+        @Override
+        public String roleName() {
+            return InstanceSave.class.getSimpleName();
+        }
+
+        @Override
+        public WorkerSelector workerSelector() {
+            return new RollingSelector();","[{'comment': 'Hash', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/persistence/PingTimeSave.java,"@@ -0,0 +1,73 @@
+package org.skywalking.apm.collector.worker.instance.persistence;
+
+import java.util.List;
+import java.util.Map;
+import org.elasticsearch.action.update.UpdateRequestBuilder;
+import org.elasticsearch.client.Client;
+import org.skywalking.apm.collector.actor.AbstractLocalSyncWorkerProvider;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.RecordPersistenceMember;
+import org.skywalking.apm.collector.worker.instance.InstanceIndex;
+import org.skywalking.apm.collector.worker.storage.EsClient;
+import org.skywalking.apm.collector.worker.storage.PersistenceWorkerListener;
+import org.skywalking.apm.collector.worker.storage.RecordData;
+
+public class PingTimeSave extends RecordPersistenceMember {
+
+    public PingTimeSave(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    public String esIndex() {
+        return InstanceIndex.INDEX;
+    }
+
+    @Override
+    public String esType() {
+        return InstanceIndex.TYPE_RECORD;
+    }
+
+    @Override
+    protected void prepareUpdateIndex(List<UpdateRequestBuilder> updateRequestBuilderList) {
+        Map<String, RecordData> lastData = getPersistenceData().getLast().asMap();
+
+        Client client = EsClient.INSTANCE.getClient();
+        lastData.forEach((key, value) -> {
+            UpdateRequestBuilder builder = client.prepareUpdate(esIndex(), esType(), key).setDoc(value.get().toString());
+            updateRequestBuilderList.add(builder);
+        });
+        lastData.clear();
+    }
+
+    public static class Factory extends AbstractLocalSyncWorkerProvider<PingTimeSave> {
+        @Override
+        public PingTimeSave.Role role() {
+            return PingTimeSave.Role.INSTANCE;
+        }
+
+        @Override
+        public PingTimeSave workerInstance(ClusterWorkerContext clusterContext) {
+            PingTimeSave worker = new PingTimeSave(role(), clusterContext, new LocalWorkerContext());
+            PersistenceWorkerListener.INSTANCE.register(worker);
+            return worker;
+        }
+    }
+
+    public enum Role implements org.skywalking.apm.collector.actor.Role {
+        INSTANCE;
+
+        @Override
+        public String roleName() {
+            return PingTimeSave.class.getSimpleName();
+        }
+
+        @Override
+        public WorkerSelector workerSelector() {
+            return new RollingSelector();","[{'comment': 'hash', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/util/IDSequenceCache.java,"@@ -0,0 +1,54 @@
+package org.skywalking.apm.collector.worker.instance.util;
+
+public enum IDSequenceCache {
+    INSTANCE;
+
+    State state;
+    IDSequence segment;","[{'comment': 'segment ?????', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/util/IDSequenceCache.java,"@@ -0,0 +1,54 @@
+package org.skywalking.apm.collector.worker.instance.util;
+
+public enum IDSequenceCache {
+    INSTANCE;
+
+    State state;
+    IDSequence segment;
+
+    static {
+        IdentificationSegmentFetcher.INSTANCE.fetchSegment(new IdentificationSegmentFetcher.Listener() {","[{'comment': 'segment ????', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/util/IDSequenceCache.java,"@@ -0,0 +1,54 @@
+package org.skywalking.apm.collector.worker.instance.util;
+
+public enum IDSequenceCache {
+    INSTANCE;
+
+    State state;
+    IDSequence segment;
+
+    static {
+        IdentificationSegmentFetcher.INSTANCE.fetchSegment(new IdentificationSegmentFetcher.Listener() {
+            @Override
+            public void failed() {
+                INSTANCE.state = State.ABNORMAL;
+                IdentificationSegmentFetcher.INSTANCE.fetchSegmentInBackGround(INSTANCE);
+            }
+
+            @Override
+            public void success(IDSequence idSegment) {
+                INSTANCE.segment = idSegment;","[{'comment': 'segment check all', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/storage/IndexBuilder.java,"@@ -0,0 +1,28 @@
+package org.skywalking.apm.collector.worker.storage;
+
+import java.util.ArrayList;
+import java.util.List;
+import org.elasticsearch.action.index.IndexRequestBuilder;
+import org.elasticsearch.action.update.UpdateRequestBuilder;
+
+public class IndexBuilder {
+    private List<IndexRequestBuilder> indexRequestBuilders;
+    private List<UpdateRequestBuilder> updateRequestBuilders;
+
+    public IndexBuilder() {
+        this.indexRequestBuilders = new ArrayList<>();","[{'comment': 'linked list', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/PingPost.java,"@@ -0,0 +1,82 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import com.google.gson.JsonObject;
+import java.io.BufferedReader;
+import java.io.IOException;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.Role;
+import org.skywalking.apm.collector.actor.WorkerInvokeException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPost;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPostProvider;
+import org.skywalking.apm.collector.worker.httpserver.ArgumentsParseException;
+import org.skywalking.apm.collector.worker.instance.analysis.PingTimeAnalysis;
+import org.skywalking.apm.collector.worker.instance.entity.InstanceDeserialize;
+import org.skywalking.apm.collector.worker.instance.entity.Ping;
+
+public class PingPost extends AbstractStreamPost {
+
+    private Logger logger = LogManager.getFormatterLogger(PingPost.class);
+
+    public PingPost(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    protected void onReceive(BufferedReader reader,
+        JsonObject response) throws ArgumentsParseException, WorkerInvokeException, WorkerNotFoundException {
+        try {
+            Ping ping = InstanceDeserialize.INSTANCE.deserializePingInfo(reader.readLine());
+            if (ping == null || ping.getInstanceId() == -1) {
+                throw new ArgumentsParseException(""instance id required."");
+            }
+
+            getSelfContext().lookup(PingTimeAnalysis.Role.INSTANCE).tell(new PingTimeAnalysis.Ping(ping.getInstanceId()));
+        } catch (IOException e) {
+            logger.error(""Failed to read Ping from BufferedReader."", e);","[{'comment': 'throw ArgumentsParseException', 'commenter': 'peng-yongsheng'}]"
223,apm-collector/apm-collector-worker/src/main/java/org/skywalking/apm/collector/worker/instance/RegistryPost.java,"@@ -0,0 +1,93 @@
+package org.skywalking.apm.collector.worker.instance;
+
+import com.google.gson.JsonObject;
+import java.io.BufferedReader;
+import java.io.IOException;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.skywalking.apm.collector.actor.ClusterWorkerContext;
+import org.skywalking.apm.collector.actor.LocalWorkerContext;
+import org.skywalking.apm.collector.actor.ProviderNotFoundException;
+import org.skywalking.apm.collector.actor.Role;
+import org.skywalking.apm.collector.actor.WorkerInvokeException;
+import org.skywalking.apm.collector.actor.WorkerNotFoundException;
+import org.skywalking.apm.collector.actor.selector.RollingSelector;
+import org.skywalking.apm.collector.actor.selector.WorkerSelector;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPost;
+import org.skywalking.apm.collector.worker.httpserver.AbstractStreamPostProvider;
+import org.skywalking.apm.collector.worker.httpserver.ArgumentsParseException;
+import org.skywalking.apm.collector.worker.instance.analysis.InstanceAnalysis;
+import org.skywalking.apm.collector.worker.instance.entity.InstanceDeserialize;
+import org.skywalking.apm.collector.worker.instance.entity.RegistryInfo;
+import org.skywalking.apm.collector.worker.instance.util.IDSequenceCache;
+import org.skywalking.apm.util.StringUtil;
+
+public class RegistryPost extends AbstractStreamPost {
+
+    private Logger logger = LogManager.getFormatterLogger(RegistryPost.class);
+
+    public RegistryPost(Role role, ClusterWorkerContext clusterContext, LocalWorkerContext selfContext) {
+        super(role, clusterContext, selfContext);
+    }
+
+    @Override
+    protected void onReceive(BufferedReader reader,
+        JsonObject response) throws ArgumentsParseException, WorkerInvokeException, WorkerNotFoundException {
+        try {
+            long instanceId = IDSequenceCache.INSTANCE.fetchInstanceId();
+            RegistryInfo registryInfo = InstanceDeserialize.INSTANCE.deserializeRegistryInfo(reader.readLine());
+
+            if (StringUtil.isEmpty(registryInfo.getApplicationCode())) {
+                throw new ArgumentsParseException(""application code required."");
+            }
+
+            InstanceAnalysis.InstanceInfo instanceInfo = new InstanceAnalysis.InstanceInfo(registryInfo.getApplicationCode(), instanceId);
+            getSelfContext().lookup(InstanceAnalysis.Role.INSTANCE).tell(instanceInfo);
+            response.addProperty(""ii"", instanceInfo.getInstanceId());
+            response.addProperty(""pt"", instanceInfo.getRegistryTime());
+        } catch (IOException e) {","[{'comment': 'throw ArgumentsParseException', 'commenter': 'peng-yongsheng'}]"
245,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginDefine.java,"@@ -30,16 +36,31 @@ public static PluginDefine build(String define) throws IllegalPluginDefineExcept
             throw new IllegalPluginDefineException(define);
         }
 
-        return new PluginDefine(pluginDefine[0], pluginDefine[1]);
+        String pluginName = pluginDefine[0];
+        String defineClass = pluginDefine[1];
+        if (pluginName.toUpperCase().startsWith(""[OFF]"")) {","[{'comment': 'Set ""[OFF]"" as a static field.', 'commenter': 'wu-sheng'}]"
245,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/plugin/PluginDefine.java,"@@ -30,16 +36,31 @@ public static PluginDefine build(String define) throws IllegalPluginDefineExcept
             throw new IllegalPluginDefineException(define);
         }
 
-        return new PluginDefine(pluginDefine[0], pluginDefine[1]);
+        String pluginName = pluginDefine[0];
+        String defineClass = pluginDefine[1];
+        if (pluginName.toUpperCase().startsWith(""[OFF]"")) {
+            return new PluginDefine(pluginName.substring(5), defineClass, State.OFF);","[{'comment': '`5` should be replaced by the length of new field. ^^^', 'commenter': 'wu-sheng'}]"
259,apm-sniffer/apm-sdk-plugin/dubbo-plugin/src/main/java/org/skywalking/apm/plugin/dubbo/DubboInterceptor.java,"@@ -39,26 +40,23 @@
      * {@link RpcContext#attachments}. current trace segment will ref if the serialize context data is not null.
      */
     @Override
-    public void beforeMethod(EnhancedClassInstanceContext context, InstanceMethodInvokeContext interceptorContext,
-                             MethodInterceptResult result) {
-        Object[] arguments = interceptorContext.allArguments();
-        Invoker invoker = (Invoker) arguments[0];
-        Invocation invocation = (Invocation) arguments[1];
+    public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invoker invoker = (Invoker)allArguments[0];
+        Invocation invocation = (Invocation)allArguments[1];
         RpcContext rpcContext = RpcContext.getContext();
         boolean isConsumer = rpcContext.isConsumerSide();
         URL requestURL = invoker.getUrl();
 
-        AbstractSpan span = ContextManager.createSpan(generateOperationName(requestURL, invocation));
-        Tags.URL.set(span, generateRequestURL(requestURL, invocation));
-        Tags.COMPONENT.set(span, DUBBO_COMPONENT);
-        Tags.SPAN_LAYER.asRPCFramework(span);
-        span.setPeerHost(requestURL.getHost());
-        span.setPort(requestURL.getPort());
+        AbstractSpan span;
 
+        final String host = requestURL.getHost();
+        final int port = requestURL.getPort();
+        objInst.setSkyWalkingDynamicField(""aa"");
+        objInst.getSkyWalkingDynamicField();","[{'comment': 'These two lines should be removed.', 'commenter': 'wu-sheng'}, {'comment': 'OK，', 'commenter': 'ascrutae'}]"
259,apm-sniffer/apm-sdk-plugin/httpClient-4.x-plugin/src/main/java/org/skywalking/apm/plugin/httpClient/v4/HttpClientExecuteInterceptor.java,"@@ -12,68 +12,47 @@
 import org.skywalking.apm.agent.core.context.ContextManager;
 import org.skywalking.apm.agent.core.context.tag.Tags;
 import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.network.trace.component.ComponentsDefine;
 
 /**
  * {@link HttpClientExecuteInterceptor} transport the trace context by call {@link HttpRequest#setHeader(Header)},
- * The current span tag the {@link Tags#ERROR} if {@link StatusLine#getStatusCode()} is not equals 200.
+ * The {@link Tags#STATUS_CODE} will be set if {@link StatusLine#getStatusCode()} is not equals 200.
  *
  * @author zhangxin
  */
 public class HttpClientExecuteInterceptor implements InstanceMethodsAroundInterceptor {
-    private static final String COMPONENT_NAME = ""HttpClient"";
 
-    @Override
-    public void beforeMethod(EnhancedClassInstanceContext context,
-        InstanceMethodInvokeContext interceptorContext, MethodInterceptResult result) {
-        Object[] allArguments = interceptorContext.allArguments();
+    @Override public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
         if (allArguments[0] == null || allArguments[1] == null) {
             // illegal args, can't trace. ignore.
             return;
         }
-        HttpHost httpHost = (HttpHost)allArguments[0];
+        final HttpHost httpHost = (HttpHost)allArguments[0];
         HttpRequest httpRequest = (HttpRequest)allArguments[1];
-        AbstractSpan span = createSpan(httpRequest);
-        span.setPeerHost(httpHost.getHostName());
-        span.setPort(httpHost.getPort());
-        Tags.SPAN_KIND.set(span, Tags.SPAN_KIND_CLIENT);
-        Tags.COMPONENT.set(span, COMPONENT_NAME);
-        Tags.URL.set(span, generateURL(httpRequest));
-        Tags.SPAN_LAYER.asHttp(span);
-
-        ContextCarrier contextCarrier = new ContextCarrier();
-        ContextManager.inject(contextCarrier);
-        httpRequest.setHeader(Config.Plugin.Propagation.HEADER_NAME, contextCarrier.serialize());
-    }
-
-    /**
-     * Format request URL.
-     *
-     * @return request URL
-     */
-    private String generateURL(HttpRequest httpRequest) {
-        return httpRequest.getRequestLine().getUri();
-    }
-
-    /**
-     * Create span.
-     */
-    private AbstractSpan createSpan(HttpRequest httpRequest) {
+        final ContextCarrier contextCarrier = new ContextCarrier();
         AbstractSpan span;
+        String remotePeer = httpHost.getHostName() + "":"" + httpHost.getPort();
         try {
             URL url = new URL(httpRequest.getRequestLine().getUri());
-            span = ContextManager.createSpan(url.getPath());
+            span = ContextManager.createExitSpan(url.getPath(), contextCarrier, remotePeer);
         } catch (MalformedURLException e) {
-            span = ContextManager.createSpan(httpRequest.getRequestLine().getUri());
+            span = ContextManager.createExitSpan(httpRequest.getRequestLine().getUri(), contextCarrier, remotePeer);","[{'comment': 'Why do the nearly same thing in `catch` block? What is the difference between URL and URI?', 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/java/org/skywalking/apm/toolkit/activation/opentracing/span/SkywalkingSpanActivation.java,"@@ -0,0 +1,105 @@
+package org.skywalking.apm.toolkit.activation.opentracing.span;
+
+import java.util.Map;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.skywalking.apm.toolkit.opentracing.SkywalkingSpanBuilder;
+import org.skywalking.apm.toolkit.opentracing.SkywalkingTracer;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.takesArgument;
+
+/**
+ * Created by xin on 2017/7/10.
+ */
+public class SkywalkingSpanActivation extends ClassInstanceMethodsEnhancePluginDefine {
+    @Override
+    protected String enhanceClassName() {
+        return ""org.skywalking.apm.toolkit.opentracing.SkywalkingSpan"";
+    }
+
+    @Override
+    protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[] {
+            new ConstructorInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                    return takesArgument(0, SkywalkingSpanBuilder.class);","[{'comment': 'Potential class loader issue.', 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/java/org/skywalking/apm/toolkit/activation/opentracing/span/SkywalkingSpanActivation.java,"@@ -0,0 +1,105 @@
+package org.skywalking.apm.toolkit.activation.opentracing.span;
+
+import java.util.Map;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.skywalking.apm.toolkit.opentracing.SkywalkingSpanBuilder;
+import org.skywalking.apm.toolkit.opentracing.SkywalkingTracer;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.takesArgument;
+
+/**
+ * Created by xin on 2017/7/10.
+ */
+public class SkywalkingSpanActivation extends ClassInstanceMethodsEnhancePluginDefine {
+    @Override
+    protected String enhanceClassName() {
+        return ""org.skywalking.apm.toolkit.opentracing.SkywalkingSpan"";
+    }
+
+    @Override
+    protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[] {
+            new ConstructorInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                    return takesArgument(0, SkywalkingSpanBuilder.class);
+                }
+
+                @Override
+                public String getConstructorInterceptor() {
+                    return ""org.skywalking.apm.toolkit.activation.opentracing.span.ConstructorWithSpanBuilderInterceptor"";
+                }
+            },
+            new ConstructorInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                    return takesArgument(0, SkywalkingTracer.class);","[{'comment': 'Potential class loader issue.', 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/java/org/skywalking/apm/toolkit/activation/opentracing/span/SpanFinishInterceptor.java,"@@ -0,0 +1,31 @@
+package org.skywalking.apm.toolkit.activation.opentracing.span;
+
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+public class SpanFinishInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        AbstractTracingSpan abstractSpan = (AbstractTracingSpan)objInst.getSkyWalkingDynamicField();","[{'comment': ""You can't guarantee to get `AbstractTracingSpan`, if this trace isn't sampled."", 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/java/org/skywalking/apm/toolkit/activation/opentracing/span/ConstructorWithSpanBuilderInterceptor.java,"@@ -0,0 +1,42 @@
+package org.skywalking.apm.toolkit.activation.opentracing.span;
+
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.skywalking.apm.toolkit.opentracing.SkywalkingSpanBuilder;
+import org.skywalking.apm.toolkit.opentracing.Tag;
+import org.skywalking.apm.util.StringUtil;
+
+public class ConstructorWithSpanBuilderInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        SkywalkingSpanBuilder spanBuilder = (SkywalkingSpanBuilder)allArguments[0];
+
+        if (spanBuilder.isEntry()) {
+            ContextManager.createEntrySpan(spanBuilder.getOperationName(), null);
+        } else if (spanBuilder.isExit() && (!StringUtil.isEmpty(spanBuilder.getPeer()))) {
+            ContextManager.createExitSpan(spanBuilder.getOperationName(),
+                new ContextCarrier(), buildRemotePeer(spanBuilder));
+        } else {
+            ContextManager.createLocalSpan(spanBuilder.getOperationName());
+        }
+
+        AbstractSpan span = ContextManager.activeSpan();","[{'comment': 'No need to use `activeSpan()` method, `create*Span` method returns the `AbstractSpan`.', 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/java/org/skywalking/apm/toolkit/activation/opentracing/span/SpanLogInterceptor.java,"@@ -0,0 +1,34 @@
+package org.skywalking.apm.toolkit.activation.opentracing.span;
+
+import java.util.Map;
+import org.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+/**
+ * Created by xin on 2017/7/10.
+ */
+public class SpanLogInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        AbstractTracingSpan abstractSpan = (AbstractTracingSpan)objInst.getSkyWalkingDynamicField();","[{'comment': ""You can't guarantee to get AbstractTracingSpan, if this trace isn't sampled."", 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-toolkit-activation/apm-toolkit-opentracing-activation/src/main/java/org/skywalking/apm/toolkit/activation/opentracing/span/SpanSetOperationNameInterceptor.java,"@@ -0,0 +1,30 @@
+package org.skywalking.apm.toolkit.activation.opentracing.span;
+
+import org.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+public class SpanSetOperationNameInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        AbstractTracingSpan tracingSpan = (AbstractTracingSpan)objInst.getSkyWalkingDynamicField();","[{'comment': ""You can't guarantee to get AbstractTracingSpan, if this trace isn't sampled."", 'commenter': 'wu-sheng'}]"
279,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/context/trace/AbstractTracingSpan.java,"@@ -147,7 +147,7 @@ public AbstractSpan errorOccurred() {
      * @param operationName
      * @return span instance, for chaining.
      */
-    public AbstractTracingSpan setOperationName(String operationName) {
+    public AbstractSpan setOperationName(String operationName) {","[{'comment': 'Why change this return type?', 'commenter': 'wu-sheng'}]"
333,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/cache/ComponentCache.java,"@@ -0,0 +1,26 @@
+package org.skywalking.apm.collector.agentstream.worker.cache;
+
+import com.google.common.cache.Cache;
+import com.google.common.cache.CacheBuilder;
+import org.skywalking.apm.collector.agentstream.worker.Const;
+import org.skywalking.apm.collector.agentstream.worker.node.component.dao.INodeComponentDAO;
+import org.skywalking.apm.collector.storage.dao.DAOContainer;
+
+/**
+ * @author pengys5
+ */
+public class ComponentCache {
+
+    private static Cache<String, Integer> CACHE = CacheBuilder.newBuilder().maximumSize(1000).build();
+
+    public static int get(int applicationId, String componentName) {
+        INodeComponentDAO dao = (INodeComponentDAO)DAOContainer.INSTANCE.get(INodeComponentDAO.class.getName());","[{'comment': ""This isn't efficiency to get **dao** instance everytime."", 'commenter': 'wu-sheng'}]"
333,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/storage/IDNameExchangeTimer.java,"@@ -0,0 +1,50 @@
+package org.skywalking.apm.collector.agentstream.worker.storage;
+
+import java.util.List;
+import org.skywalking.apm.collector.core.framework.Starter;
+import org.skywalking.apm.collector.stream.worker.WorkerException;
+import org.skywalking.apm.collector.stream.worker.impl.ExchangeWorker;
+import org.skywalking.apm.collector.stream.worker.impl.ExchangeWorkerContainer;
+import org.skywalking.apm.collector.stream.worker.impl.FlushAndSwitch;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author pengys5
+ */
+public class IDNameExchangeTimer implements Starter {
+
+    private final Logger logger = LoggerFactory.getLogger(IDNameExchangeTimer.class);
+
+    public void start() {
+        logger.info(""id and name exchange timer start"");
+        //TODO timer value config
+//        final long timeInterval = EsConfig.Es.Persistence.Timer.VALUE * 1000;
+        final long timeInterval = 3 * 1000;
+
+        Thread exchangeThread = new Thread(() -> {
+            while (true) {
+                try {
+                    exchangeLastData();
+                    Thread.sleep(timeInterval);
+                } catch (Throwable e) {
+                    logger.error(e.getMessage(), e);
+                }
+            }
+        });
+        exchangeThread.setName(""timerExchange"");
+        exchangeThread.start();","[{'comment': 'Using ` Executors.newSingleThreadScheduledExecutor()` will give you better performance and more precise.', 'commenter': 'wu-sheng'}]"
333,apm-network/src/main/java/org/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -29,4 +29,34 @@
     public static final OfficialComponent FEIGN = new OfficialComponent(11, ""Feign"");
 
     public static final OfficialComponent OKHTTP = new OfficialComponent(12, ""OKHttp"");
+
+    public static String getComponentName(int componentId) {
+        if (TOMCAT.getId() == componentId) {","[{'comment': 'As the given parameter of this method is an integer, you should use `switch-case` to avoid too many `if-else` blocks.', 'commenter': 'wu-sheng'}]"
333,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/node/component/dao/NodeComponentEsDAO.java,"@@ -18,12 +25,34 @@
         List<IndexRequestBuilder> indexRequestBuilders = new ArrayList<>();
         dataMap.forEach((id, data) -> {
             Map<String, Object> source = new HashMap();
-            source.put(NodeComponentTable.COLUMN_AGG, data.getDataString(1));
-            source.put(NodeComponentTable.COLUMN_TIME_BUCKET, data.getDataLong(0));
+            source.put(NodeComponentTable.COLUMN_APPLICATION_ID, data.getDataInteger(0));","[{'comment': 'Did you really need a hashmap, rather than a  linkedlist, which has better performance. IMO, you only need to iterate.', 'commenter': 'wu-sheng'}, {'comment': 'Elasticsearch source must Map or XContentBuilder and this map is a row data, like json object. why use list?', 'commenter': 'peng-yongsheng'}]"
335,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/cache/ServiceNameCache.java,"@@ -0,0 +1,26 @@
+package org.skywalking.apm.collector.agentstream.worker.cache;
+
+import com.google.common.cache.Cache;
+import com.google.common.cache.CacheBuilder;
+import org.skywalking.apm.collector.agentstream.worker.Const;
+import org.skywalking.apm.collector.agentstream.worker.register.servicename.dao.IServiceNameDAO;
+import org.skywalking.apm.collector.storage.dao.DAOContainer;
+
+/**
+ * @author pengys5
+ */
+public class ServiceNameCache {
+
+    private static Cache<String, Integer> CACHE = CacheBuilder.newBuilder().maximumSize(2000).build();","[{'comment': 'Max size = 2000? Is this enough for service name?', 'commenter': 'wu-sheng'}]"
335,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/noderef/reference/define/NodeRefDataDefine.java,"@@ -14,10 +14,8 @@
  */
 public class NodeRefDataDefine extends DataDefine {
 
-    public static final int DEFINE_ID = 201;
-
     @Override public int defineId() {
-        return DEFINE_ID;
+        return 201;","[{'comment': 'What does 201 stand for?', 'commenter': 'wu-sheng'}]"
335,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/noderef/reference/dao/NodeReferenceH2DAO.java,"@@ -1,15 +1,24 @@
 package org.skywalking.apm.collector.agentstream.worker.noderef.reference.dao;
 
-import java.util.List;
-import java.util.Map;
 import org.skywalking.apm.collector.storage.h2.dao.H2DAO;
+import org.skywalking.apm.collector.stream.worker.impl.dao.IPersistenceDAO;
+import org.skywalking.apm.collector.stream.worker.impl.data.Data;
+import org.skywalking.apm.collector.stream.worker.impl.data.DataDefine;
 
 /**
  * @author pengys5
  */
-public class NodeReferenceH2DAO extends H2DAO implements INodeReferenceDAO {
+public class NodeReferenceH2DAO extends H2DAO implements INodeReferenceDAO, IPersistenceDAO<String, String> {","[{'comment': ""H2 didn't support to save node reference? Not finish yet?"", 'commenter': 'wu-sheng'}]"
335,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/node/component/NodeComponentSpanListener.java,"@@ -3,85 +3,89 @@
 import java.util.ArrayList;
 import java.util.List;
 import org.skywalking.apm.collector.agentstream.worker.Const;
-import org.skywalking.apm.collector.agentstream.worker.cache.ComponentCache;
 import org.skywalking.apm.collector.agentstream.worker.node.component.define.NodeComponentDataDefine;
 import org.skywalking.apm.collector.agentstream.worker.segment.EntrySpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.ExitSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.segment.FirstSpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.LocalSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.util.ExchangeMarkUtils;
+import org.skywalking.apm.collector.agentstream.worker.util.TimeBucketUtils;
 import org.skywalking.apm.collector.core.framework.CollectorContextHelper;
 import org.skywalking.apm.collector.stream.StreamModuleContext;
 import org.skywalking.apm.collector.stream.StreamModuleGroupDefine;
 import org.skywalking.apm.collector.stream.worker.WorkerInvokeException;
 import org.skywalking.apm.collector.stream.worker.WorkerNotFoundException;
 import org.skywalking.apm.network.proto.SpanObject;
-import org.skywalking.apm.network.trace.component.ComponentsDefine;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * @author pengys5
  */
-public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, LocalSpanListener {
+public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, FirstSpanListener, LocalSpanListener {
 
     private final Logger logger = LoggerFactory.getLogger(NodeComponentSpanListener.class);
 
-    private List<NodeComponentDataDefine.NodeComponent> nodeComponents = new ArrayList<>();
+    private List<String> nodeComponents = new ArrayList<>();
+    private long timeBucket;
 
     @Override
     public void parseExit(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        String componentName = ComponentsDefine.getInstance().getComponentName(spanObject.getComponentId());
-        createNodeComponent(spanObject, applicationId, componentName);
+        String componentName = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getComponentId());","[{'comment': '`#buildMarkedID` method always returns a new String. But, in fact, this is necessary when **componentId > 1**. This is an extra cost.', 'commenter': 'wu-sheng'}]"
335,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/node/component/NodeComponentSpanListener.java,"@@ -3,85 +3,89 @@
 import java.util.ArrayList;
 import java.util.List;
 import org.skywalking.apm.collector.agentstream.worker.Const;
-import org.skywalking.apm.collector.agentstream.worker.cache.ComponentCache;
 import org.skywalking.apm.collector.agentstream.worker.node.component.define.NodeComponentDataDefine;
 import org.skywalking.apm.collector.agentstream.worker.segment.EntrySpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.ExitSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.segment.FirstSpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.LocalSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.util.ExchangeMarkUtils;
+import org.skywalking.apm.collector.agentstream.worker.util.TimeBucketUtils;
 import org.skywalking.apm.collector.core.framework.CollectorContextHelper;
 import org.skywalking.apm.collector.stream.StreamModuleContext;
 import org.skywalking.apm.collector.stream.StreamModuleGroupDefine;
 import org.skywalking.apm.collector.stream.worker.WorkerInvokeException;
 import org.skywalking.apm.collector.stream.worker.WorkerNotFoundException;
 import org.skywalking.apm.network.proto.SpanObject;
-import org.skywalking.apm.network.trace.component.ComponentsDefine;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * @author pengys5
  */
-public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, LocalSpanListener {
+public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, FirstSpanListener, LocalSpanListener {
 
     private final Logger logger = LoggerFactory.getLogger(NodeComponentSpanListener.class);
 
-    private List<NodeComponentDataDefine.NodeComponent> nodeComponents = new ArrayList<>();
+    private List<String> nodeComponents = new ArrayList<>();
+    private long timeBucket;
 
     @Override
     public void parseExit(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        String componentName = ComponentsDefine.getInstance().getComponentName(spanObject.getComponentId());
-        createNodeComponent(spanObject, applicationId, componentName);
+        String componentName = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getComponentId());
+        if (spanObject.getComponentId() == 0) {
+            componentName = spanObject.getComponent();
+        }
+        String peer = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getPeerId());","[{'comment': 'Same extra cost.', 'commenter': 'wu-sheng'}]"
335,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/node/component/NodeComponentSpanListener.java,"@@ -3,85 +3,89 @@
 import java.util.ArrayList;
 import java.util.List;
 import org.skywalking.apm.collector.agentstream.worker.Const;
-import org.skywalking.apm.collector.agentstream.worker.cache.ComponentCache;
 import org.skywalking.apm.collector.agentstream.worker.node.component.define.NodeComponentDataDefine;
 import org.skywalking.apm.collector.agentstream.worker.segment.EntrySpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.ExitSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.segment.FirstSpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.LocalSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.util.ExchangeMarkUtils;
+import org.skywalking.apm.collector.agentstream.worker.util.TimeBucketUtils;
 import org.skywalking.apm.collector.core.framework.CollectorContextHelper;
 import org.skywalking.apm.collector.stream.StreamModuleContext;
 import org.skywalking.apm.collector.stream.StreamModuleGroupDefine;
 import org.skywalking.apm.collector.stream.worker.WorkerInvokeException;
 import org.skywalking.apm.collector.stream.worker.WorkerNotFoundException;
 import org.skywalking.apm.network.proto.SpanObject;
-import org.skywalking.apm.network.trace.component.ComponentsDefine;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * @author pengys5
  */
-public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, LocalSpanListener {
+public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, FirstSpanListener, LocalSpanListener {
 
     private final Logger logger = LoggerFactory.getLogger(NodeComponentSpanListener.class);
 
-    private List<NodeComponentDataDefine.NodeComponent> nodeComponents = new ArrayList<>();
+    private List<String> nodeComponents = new ArrayList<>();
+    private long timeBucket;
 
     @Override
     public void parseExit(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        String componentName = ComponentsDefine.getInstance().getComponentName(spanObject.getComponentId());
-        createNodeComponent(spanObject, applicationId, componentName);
+        String componentName = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getComponentId());
+        if (spanObject.getComponentId() == 0) {
+            componentName = spanObject.getComponent();
+        }
+        String peer = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getPeerId());
+        if (spanObject.getPeerId() == 0) {
+            peer = spanObject.getPeer();
+        }
+
+        String agg = componentName + Const.ID_SPLIT + peer;
+        nodeComponents.add(agg);
     }
 
     @Override
     public void parseEntry(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        String componentName = ComponentsDefine.getInstance().getComponentName(spanObject.getComponentId());
-        createNodeComponent(spanObject, applicationId, componentName);
+        buildEntryOrLocal(spanObject, applicationId);
     }
 
     @Override
     public void parseLocal(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        int componentId = ComponentCache.get(applicationId, spanObject.getComponent());
-
-        NodeComponentDataDefine.NodeComponent nodeComponent = new NodeComponentDataDefine.NodeComponent();
-        nodeComponent.setApplicationId(applicationId);
-        nodeComponent.setComponentId(componentId);
-        nodeComponent.setComponentName(spanObject.getComponent());
+        buildEntryOrLocal(spanObject, applicationId);
+    }
 
-        if (componentId == 0) {
-            StreamModuleContext context = (StreamModuleContext)CollectorContextHelper.INSTANCE.getContext(StreamModuleGroupDefine.GROUP_NAME);
+    private void buildEntryOrLocal(SpanObject spanObject, int applicationId) {
+        String componentName = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getComponentId());","[{'comment': 'Still Same extra cost.', 'commenter': 'wu-sheng'}]"
337,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/jetty/handler/reader/ReferenceJsonReader.java,"@@ -0,0 +1,70 @@
+package org.skywalking.apm.collector.agentstream.jetty.handler.reader;
+
+import com.google.gson.stream.JsonReader;
+import java.io.IOException;
+import org.skywalking.apm.network.proto.TraceSegmentReference;
+
+/**
+ * @author pengys5
+ */
+public class ReferenceJsonReader implements StreamJsonReader<TraceSegmentReference> {
+
+    private UniqueIdJsonReader uniqueIdJsonReader = new UniqueIdJsonReader();
+
+    private static final String TS = ""ts"";
+    private static final String AI = ""ai"";
+    private static final String SI = ""si"";
+    private static final String VI = ""vi"";
+    private static final String VN = ""vn"";
+    private static final String NI = ""ni"";
+    private static final String NN = ""nn"";
+    private static final String EI = ""ei"";
+    private static final String EN = ""en"";
+    private static final String RV = ""rv"";","[{'comment': 'I prefer to use the full name for these static fields, also same suggestion in other Json Reader, for better readability.', 'commenter': 'wu-sheng'}]"
337,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/node/component/NodeComponentSpanListener.java,"@@ -3,85 +3,89 @@
 import java.util.ArrayList;
 import java.util.List;
 import org.skywalking.apm.collector.agentstream.worker.Const;
-import org.skywalking.apm.collector.agentstream.worker.cache.ComponentCache;
 import org.skywalking.apm.collector.agentstream.worker.node.component.define.NodeComponentDataDefine;
 import org.skywalking.apm.collector.agentstream.worker.segment.EntrySpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.ExitSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.segment.FirstSpanListener;
 import org.skywalking.apm.collector.agentstream.worker.segment.LocalSpanListener;
+import org.skywalking.apm.collector.agentstream.worker.util.ExchangeMarkUtils;
+import org.skywalking.apm.collector.agentstream.worker.util.TimeBucketUtils;
 import org.skywalking.apm.collector.core.framework.CollectorContextHelper;
 import org.skywalking.apm.collector.stream.StreamModuleContext;
 import org.skywalking.apm.collector.stream.StreamModuleGroupDefine;
 import org.skywalking.apm.collector.stream.worker.WorkerInvokeException;
 import org.skywalking.apm.collector.stream.worker.WorkerNotFoundException;
 import org.skywalking.apm.network.proto.SpanObject;
-import org.skywalking.apm.network.trace.component.ComponentsDefine;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
  * @author pengys5
  */
-public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, LocalSpanListener {
+public class NodeComponentSpanListener implements EntrySpanListener, ExitSpanListener, FirstSpanListener, LocalSpanListener {
 
     private final Logger logger = LoggerFactory.getLogger(NodeComponentSpanListener.class);
 
-    private List<NodeComponentDataDefine.NodeComponent> nodeComponents = new ArrayList<>();
+    private List<String> nodeComponents = new ArrayList<>();
+    private long timeBucket;
 
     @Override
     public void parseExit(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        String componentName = ComponentsDefine.getInstance().getComponentName(spanObject.getComponentId());
-        createNodeComponent(spanObject, applicationId, componentName);
+        String componentName = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getComponentId());
+        if (spanObject.getComponentId() == 0) {
+            componentName = spanObject.getComponent();
+        }
+        String peer = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getPeerId());
+        if (spanObject.getPeerId() == 0) {
+            peer = spanObject.getPeer();
+        }
+
+        String agg = peer + Const.ID_SPLIT + componentName;
+        nodeComponents.add(agg);
     }
 
     @Override
     public void parseEntry(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        String componentName = ComponentsDefine.getInstance().getComponentName(spanObject.getComponentId());
-        createNodeComponent(spanObject, applicationId, componentName);
+        buildEntryOrLocal(spanObject, applicationId);
     }
 
     @Override
     public void parseLocal(SpanObject spanObject, int applicationId, int applicationInstanceId, String segmentId) {
-        int componentId = ComponentCache.get(applicationId, spanObject.getComponent());
-
-        NodeComponentDataDefine.NodeComponent nodeComponent = new NodeComponentDataDefine.NodeComponent();
-        nodeComponent.setApplicationId(applicationId);
-        nodeComponent.setComponentId(componentId);
-        nodeComponent.setComponentName(spanObject.getComponent());
+        buildEntryOrLocal(spanObject, applicationId);
+    }
 
-        if (componentId == 0) {
-            StreamModuleContext context = (StreamModuleContext)CollectorContextHelper.INSTANCE.getContext(StreamModuleGroupDefine.GROUP_NAME);
+    private void buildEntryOrLocal(SpanObject spanObject, int applicationId) {
+        String componentName = ExchangeMarkUtils.INSTANCE.buildMarkedID(spanObject.getComponentId());","[{'comment': ""Only build component name by component id, if and only if componentId isn't 0."", 'commenter': 'wu-sheng'}]"
342,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/context/TracingContext.java,"@@ -102,6 +102,7 @@ public void inject(ContextCarrier carrier) {
             AbstractTracingSpan firstSpan = first();
             operationId = firstSpan.getOperationId();
             operationName = firstSpan.getOperationName();
+            carrier.setEntryApplicationInstanceId(this.segment.getApplicationInstanceId());","[{'comment': 'You only set the entryApplicationInstanceId by using current segment, how to propagation through ref?', 'commenter': 'wu-sheng'}]"
342,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/context/ContextCarrier.java,"@@ -74,6 +77,7 @@ public ContextCarrier deserialize(String text) {
                     this.entryOperationName = parts[4];
                     this.parentOperationName = parts[5];
                     this.primaryDistributedTraceId = new PropagatedTraceId(parts[6]);
+                    this.entryApplicationInstanceId = Integer.parseInt(parts[7]);","[{'comment': 'serialize and deserialize shoule be ordered as same as the proto said.', 'commenter': 'wu-sheng'}]"
342,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/context/TracingContext.java,"@@ -98,10 +98,12 @@ public void inject(ContextCarrier carrier) {
             TraceSegmentRef ref = refs.get(0);
             operationId = ref.getEntryOperationId();
             operationName = ref.getEntryOperationName();
+            carrier.setEntryApplicationInstanceId(ref.getEntryApplicationInstanceId());","[{'comment': 'Please follow the same coding style like this:\r\n1. assign to a local variable first\r\n1. call `carrier#setEntryApplicationInstanceId`', 'commenter': 'wu-sheng'}]"
342,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/context/TracingContext.java,"@@ -145,14 +147,17 @@ public ContextSnapshot capture() {
             segment.getRelatedGlobalTraces());
         int entryOperationId;
         String entryOperationName;
+        snapshot.setParentApplicationInstanceId(segment.getApplicationInstanceId());
         AbstractTracingSpan firstSpan = first();
         if (refs != null && refs.size() > 0) {
             TraceSegmentRef ref = refs.get(0);
             entryOperationId = ref.getEntryOperationId();
             entryOperationName = ref.getEntryOperationName();
+            snapshot.setEntryApplicationInstanceId(ref.getEntryApplicationInstanceId());","[{'comment': 'Same coding style concern.', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/concurrent-util-plugin/src/main/java/org/skywalking/apm/plugin/spring/concurrent/match/AbstractCallBackMatch.java,"@@ -0,0 +1,72 @@
+package org.skywalking.apm.plugin.spring.concurrent.match;
+
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.hasSuperType;
+import static net.bytebuddy.matcher.ElementMatchers.nameStartsWith;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.not;
+
+public abstract class AbstractCallBackMatch implements IndirectMatch {
+
+    private static final String MATCH_INTERFACE = ""org.springframework.util.concurrent.FailureCallback"";","[{'comment': 'Is this useful?', 'commenter': 'wu-sheng'}, {'comment': 'I checked you defined these two in your subclasses.', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/concurrent-util-plugin/src/main/java/org/skywalking/apm/plugin/spring/concurrent/match/AbstractCallBackMatch.java,"@@ -0,0 +1,72 @@
+package org.skywalking.apm.plugin.spring.concurrent.match;
+
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.hasSuperType;
+import static net.bytebuddy.matcher.ElementMatchers.nameStartsWith;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.not;
+
+public abstract class AbstractCallBackMatch implements IndirectMatch {
+
+    private static final String MATCH_INTERFACE = ""org.springframework.util.concurrent.FailureCallback"";
+    private static final String MUTEX_INTERFACE = ""org.springframework.util.concurrent.SuccessCallback"";
+    private static final String SPRING_PACKAGE_PREFIX = ""org.springframework"";
+
+    protected AbstractCallBackMatch() {
+
+    }
+
+    @Override
+    public ElementMatcher.Junction buildJunction() {
+        return not(nameStartsWith(SPRING_PACKAGE_PREFIX)).
+            and(hasSuperType(named(MATCH_INTERFACE)))","[{'comment': 'Use `getMatchInterface` instead of string.\r\n', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/concurrent-util-plugin/src/main/java/org/skywalking/apm/plugin/spring/concurrent/match/AbstractCallBackMatch.java,"@@ -0,0 +1,72 @@
+package org.skywalking.apm.plugin.spring.concurrent.match;
+
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.hasSuperType;
+import static net.bytebuddy.matcher.ElementMatchers.nameStartsWith;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.not;
+
+public abstract class AbstractCallBackMatch implements IndirectMatch {
+
+    private static final String MATCH_INTERFACE = ""org.springframework.util.concurrent.FailureCallback"";
+    private static final String MUTEX_INTERFACE = ""org.springframework.util.concurrent.SuccessCallback"";
+    private static final String SPRING_PACKAGE_PREFIX = ""org.springframework"";
+
+    protected AbstractCallBackMatch() {
+
+    }
+
+    @Override
+    public ElementMatcher.Junction buildJunction() {
+        return not(nameStartsWith(SPRING_PACKAGE_PREFIX)).
+            and(hasSuperType(named(MATCH_INTERFACE)))
+            .and(not(hasSuperType(named(MUTEX_INTERFACE))));","[{'comment': 'Use `getMutexInterface` instead of string.', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/concurrent-util-plugin/src/main/java/org/skywalking/apm/plugin/spring/concurrent/match/AbstractCallBackMatch.java,"@@ -0,0 +1,72 @@
+package org.skywalking.apm.plugin.spring.concurrent.match;
+
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.hasSuperType;
+import static net.bytebuddy.matcher.ElementMatchers.nameStartsWith;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.not;
+
+public abstract class AbstractCallBackMatch implements IndirectMatch {","[{'comment': '`AbstractCallBackMatch` should be renamed to ** EitherInterfaceMatch**.', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/concurrent-util-plugin/src/main/java/org/skywalking/apm/plugin/spring/concurrent/match/ListenableFutureCallbackMatch.java,"@@ -0,0 +1,60 @@
+package org.skywalking.apm.plugin.spring.concurrent.match;
+
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.hasSuperType;
+import static net.bytebuddy.matcher.ElementMatchers.nameStartsWith;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.not;
+
+public class ListenableFutureCallbackMatch implements IndirectMatch {
+
+    private static final String LISTENABLE_FUTURE_CALLBACK_CLASS_NAME = ""org.springframework.util.concurrent.ListenableFutureCallback"";
+
+    private ListenableFutureCallbackMatch() {
+
+    }
+
+    @Override
+    public ElementMatcher.Junction buildJunction() {
+        return not(nameStartsWith(""org.springframework"")).
+            and(hasSuperType(named(LISTENABLE_FUTURE_CALLBACK_CLASS_NAME)));
+    }
+
+    @Override
+    public boolean isMatch(TypeDescription typeDescription) {
+        boolean isMatch = false;
+        for (TypeDescription.Generic generic : typeDescription.getInterfaces()) {
+            isMatch = isMatch || matchExactClass(generic);
+        }
+
+        return isMatch || matchExactClass(typeDescription.getSuperClass());
+    }
+
+    private boolean matchExactClass(TypeDescription.Generic clazz) {
+        if (clazz.asRawType().getTypeName().equals(LISTENABLE_FUTURE_CALLBACK_CLASS_NAME)) {
+            return true;
+        }
+
+        boolean isMatch = false;
+        for (TypeDescription.Generic generic : clazz.getInterfaces()) {
+            isMatch = isMatch || matchExactClass(generic);
+        }
+
+        if (!isMatch) {
+            TypeDescription.Generic superClazz = clazz.getSuperClass();
+            if (superClazz != null && !clazz.getTypeName().equals(""java.lang.Object"")) {","[{'comment': '`""java.lang.Object""` is still a string.', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/concurrent-util-plugin/src/main/resources/skywalking-plugin.def,"@@ -0,0 +1,3 @@
+resttemplate=org.skywalking.apm.plugin.spring.concurrent.define.FailureCallbackInstrumentation
+resttemplate=org.skywalking.apm.plugin.spring.concurrent.define.SuccessCallbackInstrumentation
+resttemplate=org.skywalking.apm.plugin.spring.concurrent.define.ListenableFutureCallbackInstrumentation","[{'comment': 'You define this without any version number.', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/resttemplate-plugin/src/main/java/org/skywalking/apm/plugin/spring/resttemplate/async/RestExecuteInterceptor.java,"@@ -0,0 +1,51 @@
+package org.skywalking.apm.plugin.spring.resttemplate.async;
+
+import java.net.URI;
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.springframework.http.HttpMethod;
+
+public class RestExecuteInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        final URI requestURL = (URI)allArguments[0];
+        final HttpMethod httpMethod = (HttpMethod)allArguments[1];
+        final ContextCarrier contextCarrier = new ContextCarrier();
+        String remotePeer = requestURL.getHost() + "":"" + requestURL.getPort();
+        AbstractSpan span = ContextManager.createExitSpan(requestURL.getPath(), contextCarrier, remotePeer);
+
+        span.setComponent(ComponentsDefine.REST_TEMPLATE);
+        Tags.URL.set(span, requestURL.getScheme() + ""://"" + requestURL.getHost() + "":"" + requestURL.getPort() + requestURL.getPath());
+        Tags.HTTP.METHOD.set(span, httpMethod.toString());
+        SpanLayer.asHttp(span);
+        Object[] cacheValues = new Object[3];
+        cacheValues[0] = requestURL;
+        cacheValues[1] = contextCarrier.serialize();
+        objInst.setSkyWalkingDynamicField(cacheValues);
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        Object[] cacheValues = (Object[])objInst.getSkyWalkingDynamicField();
+        cacheValues[3] = ContextManager.capture();
+        ((EnhancedInstance)ret).setSkyWalkingDynamicField(cacheValues);
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+","[{'comment': 'Do nothing when exception happened?', 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/resttemplate-plugin/src/main/java/org/skywalking/apm/plugin/spring/resttemplate/async/ResponseCallBackInterceptor.java,"@@ -0,0 +1,29 @@
+package org.skywalking.apm.plugin.spring.resttemplate.async;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+public class ResponseCallBackInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        EnhancedInstance successCallBak = (EnhancedInstance)allArguments[0];
+        successCallBak.setSkyWalkingDynamicField(objInst.getSkyWalkingDynamicField());
+
+        if (allArguments.length == 2) {
+            EnhancedInstance failedCallBack = (EnhancedInstance)allArguments[1];
+            failedCallBack.setSkyWalkingDynamicField(objInst.getSkyWalkingDynamicField());
+        }
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        return ret;
+    }
+
+    @Override public void handleMethodException(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+","[{'comment': ""Didn't handle anything when callback exit with exception?"", 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/resttemplate-plugin/src/main/java/org/skywalking/apm/plugin/spring/resttemplate/async/FutureGetInterceptor.java,"@@ -0,0 +1,31 @@
+package org.skywalking.apm.plugin.spring.resttemplate.async;
+
+import java.net.URI;
+import java.util.List;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+public class FutureGetInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        List<Object> cacheValues = (List<Object>)objInst.getSkyWalkingDynamicField();
+        ContextManager.createLocalSpan(""future/get:"" + ((URI)cacheValues.get(0)).getPath());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+","[{'comment': ""Didn't handle anything when **get** exit with exception?"", 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/resttemplate-plugin/src/main/java/org/skywalking/apm/plugin/spring/resttemplate/sync/RestExecuteInterceptor.java,"@@ -0,0 +1,43 @@
+package org.skywalking.apm.plugin.spring.resttemplate.sync;
+
+import java.net.URI;
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.springframework.http.HttpMethod;
+
+public class RestExecuteInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+        final URI requestURL = (URI)allArguments[0];
+        final HttpMethod httpMethod = (HttpMethod)allArguments[1];
+        final ContextCarrier contextCarrier = new ContextCarrier();
+        String remotePeer = requestURL.getHost() + "":"" + requestURL.getPort();
+        AbstractSpan span = ContextManager.createExitSpan(requestURL.getPath(), contextCarrier, remotePeer);
+
+        span.setComponent(ComponentsDefine.REST_TEMPLATE);
+        Tags.URL.set(span, requestURL.getScheme() + ""://"" + requestURL.getHost() + "":"" + requestURL.getPort() + requestURL.getPath());
+        Tags.HTTP.METHOD.set(span, httpMethod.toString());
+        SpanLayer.asHttp(span);
+
+        objInst.setSkyWalkingDynamicField(contextCarrier.serialize());
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override public void handleMethodException(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+","[{'comment': ""Didn't handle anything when **execute** exit with exception?"", 'commenter': 'wu-sheng'}]"
348,apm-sniffer/apm-sdk-plugin/spring-plugins/resttemplate-plugin/src/main/java/org/skywalking/apm/plugin/spring/resttemplate/sync/RestRequestInterceptor.java,"@@ -0,0 +1,30 @@
+package org.skywalking.apm.plugin.spring.resttemplate.sync;
+
+import org.skywalking.apm.agent.core.conf.Config;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.springframework.http.client.AbstractClientHttpRequest;
+import org.springframework.http.client.ClientHttpRequest;
+
+public class RestRequestInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override public void beforeMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        ClientHttpRequest clientHttpRequest = (ClientHttpRequest)ret;
+        if (clientHttpRequest instanceof AbstractClientHttpRequest) {
+            AbstractClientHttpRequest httpRequest = (AbstractClientHttpRequest)clientHttpRequest;
+            httpRequest.getHeaders().set(Config.Plugin.Propagation.HEADER_NAME, String.valueOf(objInst.getSkyWalkingDynamicField()));
+        }
+        return ret;
+    }
+
+    @Override public void handleMethodException(EnhancedInstance objInst, String methodName, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+","[{'comment': ""Didn't handle anything when execute exit with exception?"", 'commenter': 'wu-sheng'}]"
362,apm-application-toolkit/apm-toolkit-trace-annotation/pom.xml,"@@ -0,0 +1,45 @@
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-application-toolkit</artifactId>
+        <groupId>org.skywalking</groupId>
+        <version>3.2-2017</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-toolkit-trace-annotation</artifactId>","[{'comment': 'The artifactId should be **apm-toolkit-trace**.', 'commenter': 'wu-sheng'}]"
362,apm-application-toolkit/apm-toolkit-trace-annotation/pom.xml,"@@ -0,0 +1,45 @@
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-application-toolkit</artifactId>
+        <groupId>org.skywalking</groupId>
+        <version>3.2-2017</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-toolkit-trace-annotation</artifactId>
+    <packaging>jar</packaging>
+
+    <url>http://maven.apache.org</url>
+
+    <build>
+        <plugins>
+            <plugin>
+                <!-- 源码插件 -->
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-source-plugin</artifactId>
+                <!-- 发布时自动将源码同时发布的配置 -->
+                <executions>
+                    <execution>
+                        <id>attach-sources</id>
+                        <goals>
+                            <goal>jar</goal>
+                        </goals>
+                    </execution>
+                </executions>
+                <version>2.4</version>
+            </plugin>
+        </plugins>
+    </build>
+
+    <distributionManagement>
+        <repository>
+            <id>bintray-wu-sheng-sky-walking-repository</id>
+            <name>wu-sheng-sky-walking-repository</name>
+            <url>
+                https://api.bintray.com/maven/wu-sheng/skywalking/org.skywalking.apm-toolkit-trace-context/;publish=1","[{'comment': 'url should be https://api.bintray.com/maven/wu-sheng/skywalking/org.skywalking.apm-toolkit-trace/;publish=1', 'commenter': 'wu-sheng'}]"
362,apm-application-toolkit/pom.xml,"@@ -19,5 +19,6 @@
         <module>apm-toolkit-logback-1.x</module>
         <module>apm-toolkit-trace-context</module>
         <module>apm-toolkit-opentracing</module>
+        <module>apm-toolkit-trace-annotation</module>","[{'comment': 'Rename to **apm-toolkit-trace** too.', 'commenter': 'wu-sheng'}]"
362,apm-sniffer/apm-agent/pom.xml,"@@ -126,6 +126,12 @@
             <version>${project.version}</version>
         </dependency>
 
+        <dependency>
+            <groupId>org.skywalking</groupId>
+            <artifactId>apm-toolkit-trace-annotation-activation</artifactId>","[{'comment': 'Rename to **apm-toolkit-trace-activation**.', 'commenter': 'wu-sheng'}]"
362,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-annotation-activation/pom.xml,"@@ -0,0 +1,22 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-toolkit-activation</artifactId>
+        <groupId>org.skywalking</groupId>
+        <version>3.2-2017</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-toolkit-trace-annotation-activation</artifactId>","[{'comment': 'Rename to **apm-toolkit-trace-activation**.', 'commenter': 'wu-sheng'}]"
362,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-annotation-activation/pom.xml,"@@ -0,0 +1,22 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-toolkit-activation</artifactId>
+        <groupId>org.skywalking</groupId>
+        <version>3.2-2017</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-toolkit-trace-annotation-activation</artifactId>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.skywalking</groupId>
+            <artifactId>apm-toolkit-trace-annotation</artifactId>","[{'comment': 'Rename to **Rename to apm-toolkit-trace**.', 'commenter': 'wu-sheng'}]"
362,apm-application-toolkit/apm-toolkit-trace-annotation/src/main/java/org/skywalking/apm/toolkit/trace/annotation/Trace.java,"@@ -0,0 +1,22 @@
+package org.skywalking.apm.toolkit.trace.annotation;","[{'comment': 'Rename package', 'commenter': 'wu-sheng'}]"
362,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-annotation-activation/src/main/java/org/skywalking/apm/toolkit/activation/trace/TraceAnnotationMethodInterceptor.java,"@@ -0,0 +1,54 @@
+package org.skywalking.apm.toolkit.activation.trace;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.toolkit.trace.annotation.Trace;
+
+/**
+ * {@link TraceAnnotationMethodInterceptor} create a local span and set the operation name which fetch from
+ * <code>org.skywalking.apm.toolkit.trace.annotation.Trace.operationName</code>. if the fetch value is blank string, and
+ * the operation name will be the method name.","[{'comment': 'The operation name will be the class name + method name.', 'commenter': 'wu-sheng'}]"
362,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-annotation-activation/src/main/java/org/skywalking/apm/toolkit/activation/trace/TraceAnnotationMethodInterceptor.java,"@@ -0,0 +1,54 @@
+package org.skywalking.apm.toolkit.activation.trace;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.toolkit.trace.annotation.Trace;
+
+/**
+ * {@link TraceAnnotationMethodInterceptor} create a local span and set the operation name which fetch from
+ * <code>org.skywalking.apm.toolkit.trace.annotation.Trace.operationName</code>. if the fetch value is blank string, and
+ * the operation name will be the method name.
+ *
+ * @author zhangxin
+ */
+public class TraceAnnotationMethodInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        Trace trace = method.getAnnotation(Trace.class);
+        String operationName = trace.operationName();
+        if (operationName.length() == 0) {
+            operationName = generateOperationName(method);
+        }
+
+        ContextManager.createLocalSpan(operationName);
+    }
+
+    private String generateOperationName(Method method) {
+        StringBuilder operationName = new StringBuilder(method.getDeclaringClass().getName() + ""."" + method.getName() + ""("");
+        Class<?>[] parameterTypes = method.getParameterTypes();
+        for (int i = 0; i < parameterTypes.length; i++) {","[{'comment': 'Will this cost too much? Add parameter list as part of operation name.', 'commenter': 'wu-sheng'}]"
362,apm-sniffer/apm-toolkit-activation/pom.xml,"@@ -15,6 +15,7 @@
         <module>apm-toolkit-logback-1.x-activation</module>
         <module>apm-toolkit-trace-context-activation</module>
         <module>apm-toolkit-opentracing-activation</module>
+        <module>apm-toolkit-trace-annotation-activation</module>","[{'comment': 'Rename it.', 'commenter': 'wu-sheng'}]"
398,apm-collector/apm-collector-core/src/main/java/org/skywalking/apm/collector/core/util/TimeBucketUtils.java,"@@ -88,6 +88,18 @@ public long changeToUTCTimeBucket(long timeBucket) {
         }
     }
 
+    private long addSecondForTimeBucket(String sliceType, long timeBucket, int second) {","[{'comment': 'just need a general method to add second for all time bucket type。So this method is public and change the parameter name  sliceType to timeBucketType.', 'commenter': 'peng-yongsheng'}]"
398,apm-collector/apm-collector-core/src/main/java/org/skywalking/apm/collector/core/util/TimeBucketUtils.java,"@@ -88,6 +88,18 @@ public long changeToUTCTimeBucket(long timeBucket) {
         }
     }
 
+    private long addSecondForTimeBucket(String sliceType, long timeBucket, int second) {
+        Calendar calendar = Calendar.getInstance();
+        calendar.setTimeInMillis(changeTimeBucket2TimeStamp(sliceType, timeBucket));
+        calendar.add(Calendar.SECOND, second);
+
+        return getSecondTimeBucket(calendar.getTimeInMillis());
+    }
+
+    public long addSeconds(long timeBucket, int second) {","[{'comment': 'delete.....', 'commenter': 'peng-yongsheng'}]"
468,apm-sniffer/apm-sdk-plugin/jetty-plugin/jetty-client-9.x-plugin/src/main/java/org/skywalking/apm/plugin/jetty/v9/client/CompleteListenerInterceptor.java,"@@ -0,0 +1,70 @@
+package org.skywalking.apm.plugin.jetty.v9.client;
+
+import java.lang.reflect.Method;
+import org.eclipse.jetty.client.api.Result;
+import org.eclipse.jetty.http.HttpFields;
+import org.skywalking.apm.agent.core.context.CarrierItem;
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.network.trace.component.ComponentsDefine;
+
+public class CompleteListenerInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        ContextSnapshot contextSnapshot = (ContextSnapshot)objInst.getSkyWalkingDynamicField();
+        if (contextSnapshot != null) {
+            Result callBackResult = (Result)allArguments[0];
+            HttpFields httpFields = callBackResult.getResponse().getHeaders();","[{'comment': ""We don't have any mechanism about response right now. Please remove the related codes."", 'commenter': 'wu-sheng'}]"
497,apm-sniffer/apm-sdk-plugin/sharding-jdbc-1.5.x-plugin/src/main/java/org/skywalking/apm/plugin/sjdbc/define/AsyncExecuteInterceptor.java,"@@ -0,0 +1,51 @@
+package org.skywalking.apm.plugin.sjdbc.define;
+
+import com.dangdang.ddframe.rdb.sharding.constant.SQLType;
+import com.dangdang.ddframe.rdb.sharding.executor.ExecuteCallback;
+import com.dangdang.ddframe.rdb.sharding.executor.threadlocal.ExecutorDataMap;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+import java.lang.reflect.Method;
+
+/**
+ * {@link AsyncExecuteInterceptor} enhances {@link com.dangdang.ddframe.rdb.sharding.executor.ExecutorEngine#asyncExecute(SQLType, Collection, List, ExecuteCallback)} 
+ * so that the sql executor can get a {@link ContextSnapshot} of main thread when it is executed asynchronously.
+ * 
+ * @author gaohongtao
+ */
+public class AsyncExecuteInterceptor implements InstanceMethodsAroundInterceptor {
+    
+    public static final String SNAPSHOT_DATA_KEY = ""APM_SKYWALKING_SNAPSHOT_DATA"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        ExecutorDataMap.getDataMap().put(SNAPSHOT_DATA_KEY, ContextManager.capture());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        Map<String, Object> oldMap = ExecutorDataMap.getDataMap();
+        Map<String, Object> newMap = new HashMap<>(oldMap.size() - 1);
+        for (Map.Entry<String, Object> each : oldMap.entrySet()) {
+            if (!each.getKey().equals(SNAPSHOT_DATA_KEY)) {
+                newMap.put(each.getKey(), each.getValue());
+            }
+        }","[{'comment': 'Do you have any choice to avoid using new map to propagate `Snapshot`? This is a performance leak in high throughputs scenario.', 'commenter': 'wu-sheng'}]"
497,apm-sniffer/apm-sdk-plugin/sharding-jdbc-1.5.x-plugin/src/main/java/org/skywalking/apm/plugin/sjdbc/define/ExecutorInstrumentation.java,"@@ -0,0 +1,75 @@
+package org.skywalking.apm.plugin.sjdbc.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.skywalking.apm.plugin.sjdbc.ExecuteEventListener;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link ExecutorInstrumentation} presents that skywalking intercepts {@link com.dangdang.ddframe.rdb.sharding.executor.ExecutorEngine}.
+ * 
+ * @author gaohongtao
+ */
+public class ExecutorInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+    
+    private static final String ENHANCE_CLASS = ""com.dangdang.ddframe.rdb.sharding.executor.ExecutorEngine"";
+
+    private static final String EXECUTE_INTERCEPTOR_CLASS = ""org.skywalking.apm.plugin.sjdbc.define.ExecuteInterceptor"";
+    
+    private static final String ASYNC_EXECUTE_INTERCEPTOR_CLASS = ""org.skywalking.apm.plugin.sjdbc.define.AsyncExecuteInterceptor"";
+
+    @Override
+    protected ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return null;
+    }
+    
+    @Override
+    protected InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[]{
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(""execute"");
+                }
+
+                @Override
+                public String getMethodsInterceptor() {
+                    return EXECUTE_INTERCEPTOR_CLASS;
+                }
+
+                @Override
+                public boolean isOverrideArgs() {
+                    return false;
+                }
+            },
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(""asyncExecute"");
+                }
+
+                @Override
+                public String getMethodsInterceptor() {
+                    return ASYNC_EXECUTE_INTERCEPTOR_CLASS;
+                }
+
+                @Override
+                public boolean isOverrideArgs() {
+                    return false;
+                }
+            }
+        };
+    }
+    
+    @Override
+    protected ClassMatch enhanceClass() {
+        ExecuteEventListener.init();","[{'comment': 'This definitely trigger **ClassLoader** failure, when you are facing Tomcat or middleware.', 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/test/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedMethodInterceptorTest.java,"@@ -0,0 +1,141 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import static junit.framework.TestCase.assertNotNull;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.mockito.Mockito.when;
+
+import java.lang.reflect.Method;
+import java.util.List;
+
+import org.hamcrest.CoreMatchers;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+import org.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.skywalking.apm.agent.core.context.trace.LogDataEntity;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.skywalking.apm.agent.core.context.util.KeyValuePair;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.skywalking.apm.agent.test.helper.SpanHelper;
+import org.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+
+import net.rubyeye.xmemcached.XMemcachedClient;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class XMemcachedMethodInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+    private XMemcachedMethodInterceptor interceptor;
+
+    private Object[] allArgument;
+    private Class[] argumentType;
+ 
+    @Before
+    public void setUp() throws Exception {
+        allArgument = new Object[] {""OperationKey"", ""OperationValue""};
+        argumentType = new Class[] {String.class, String.class};
+
+        interceptor = new XMemcachedMethodInterceptor();
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(""127.0.0.1:11211"");
+    } 
+
+    @Test
+    public void testIntercept() throws Throwable {
+        interceptor.beforeMethod(enhancedInstance, getMockSetMethod(), allArgument, argumentType, null);
+        interceptor.afterMethod(enhancedInstance, getMockGetMethod(), allArgument, argumentType, null);
+
+        TraceSegment traceSegment = segmentStorage.getTraceSegments().get(0);
+        List<AbstractTracingSpan> spans = SegmentHelper.getSpans(traceSegment);
+        assertThat(spans.size(), is(1));
+        assertMemcacheSpan(spans.get(0));
+    }
+
+    @Test
+    public void testInterceptWithException() throws Throwable {
+        interceptor.beforeMethod(enhancedInstance, getMockSetMethod(), allArgument, argumentType, null);
+        interceptor.handleMethodException(enhancedInstance, getMockSetMethod(), allArgument, argumentType, new RuntimeException());
+        interceptor.afterMethod(enhancedInstance, getMockSetMethod(), allArgument, argumentType, null);
+
+        TraceSegment traceSegment = segmentStorage.getTraceSegments().get(0);
+        List<AbstractTracingSpan> spans = SegmentHelper.getSpans(traceSegment);
+        assertThat(spans.size(), is(1));
+        assertMemcacheSpan(spans.get(0));
+
+        assertLogData(SpanHelper.getLogs(spans.get(0)));
+    }
+
+    private void assertLogData(List<LogDataEntity> logDataEntities) {
+        assertThat(logDataEntities.size(), is(1));
+        LogDataEntity logData = logDataEntities.get(0);
+        Assert.assertThat(logData.getLogs().size(), is(4));
+        Assert.assertThat(logData.getLogs().get(0).getValue(), CoreMatchers.<Object>is(""error""));
+        Assert.assertThat(logData.getLogs().get(1).getValue(), CoreMatchers.<Object>is(RuntimeException.class.getName()));
+        Assert.assertNull(logData.getLogs().get(2).getValue());
+        assertNotNull(logData.getLogs().get(3).getValue());
+    }
+
+    private void assertMemcacheSpan(AbstractTracingSpan span) {
+        assertThat(span.getOperationName(), is(""XMemcached/set""));
+        assertThat(span.isExit(), is(true));
+        assertThat(SpanHelper.getComponentId(span), is(20));
+        List<KeyValuePair> tags = SpanHelper.getTags(span);
+        assertThat(tags.get(0).getValue(), is(""Memcache""));
+        assertThat(tags.get(1).getValue(), is(""set OperationKey""));
+        assertThat(SpanHelper.getLayer(span), is(SpanLayer.DB));
+    }
+    
+    private Method getMockSetMethod() {
+        try {
+            return XMemcachedClient.class.getMethod(""set"", String.class, int.class, Object.class);
+        } catch (NoSuchMethodException e) {
+            e.printStackTrace();
+            return null;
+        }
+    }
+    
+    private Method getMockGetMethod() {
+        try {
+            return XMemcachedClient.class.getMethod(""get"", String.class);
+        } catch (NoSuchMethodException e) {
+            e.printStackTrace();","[{'comment': 'remove e.printStackTrace()', 'commenter': 'ascrutae'}, {'comment': 'In a test case, I think you can remove the try/catch instead of `e.printStackTrace`. The error should not happen if the test case is right.', 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/test/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedMethodInterceptorTest.java,"@@ -0,0 +1,141 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import static junit.framework.TestCase.assertNotNull;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.mockito.Mockito.when;
+
+import java.lang.reflect.Method;
+import java.util.List;
+
+import org.hamcrest.CoreMatchers;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+import org.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.skywalking.apm.agent.core.context.trace.LogDataEntity;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.skywalking.apm.agent.core.context.util.KeyValuePair;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.skywalking.apm.agent.test.helper.SpanHelper;
+import org.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+
+import net.rubyeye.xmemcached.XMemcachedClient;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class XMemcachedMethodInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+    private XMemcachedMethodInterceptor interceptor;
+
+    private Object[] allArgument;
+    private Class[] argumentType;
+ 
+    @Before
+    public void setUp() throws Exception {
+        allArgument = new Object[] {""OperationKey"", ""OperationValue""};
+        argumentType = new Class[] {String.class, String.class};
+
+        interceptor = new XMemcachedMethodInterceptor();
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(""127.0.0.1:11211"");
+    } 
+
+    @Test
+    public void testIntercept() throws Throwable {
+        interceptor.beforeMethod(enhancedInstance, getMockSetMethod(), allArgument, argumentType, null);
+        interceptor.afterMethod(enhancedInstance, getMockGetMethod(), allArgument, argumentType, null);
+
+        TraceSegment traceSegment = segmentStorage.getTraceSegments().get(0);
+        List<AbstractTracingSpan> spans = SegmentHelper.getSpans(traceSegment);
+        assertThat(spans.size(), is(1));
+        assertMemcacheSpan(spans.get(0));
+    }
+
+    @Test
+    public void testInterceptWithException() throws Throwable {
+        interceptor.beforeMethod(enhancedInstance, getMockSetMethod(), allArgument, argumentType, null);
+        interceptor.handleMethodException(enhancedInstance, getMockSetMethod(), allArgument, argumentType, new RuntimeException());
+        interceptor.afterMethod(enhancedInstance, getMockSetMethod(), allArgument, argumentType, null);
+
+        TraceSegment traceSegment = segmentStorage.getTraceSegments().get(0);
+        List<AbstractTracingSpan> spans = SegmentHelper.getSpans(traceSegment);
+        assertThat(spans.size(), is(1));
+        assertMemcacheSpan(spans.get(0));
+
+        assertLogData(SpanHelper.getLogs(spans.get(0)));
+    }
+
+    private void assertLogData(List<LogDataEntity> logDataEntities) {
+        assertThat(logDataEntities.size(), is(1));
+        LogDataEntity logData = logDataEntities.get(0);
+        Assert.assertThat(logData.getLogs().size(), is(4));
+        Assert.assertThat(logData.getLogs().get(0).getValue(), CoreMatchers.<Object>is(""error""));
+        Assert.assertThat(logData.getLogs().get(1).getValue(), CoreMatchers.<Object>is(RuntimeException.class.getName()));
+        Assert.assertNull(logData.getLogs().get(2).getValue());
+        assertNotNull(logData.getLogs().get(3).getValue());
+    }
+
+    private void assertMemcacheSpan(AbstractTracingSpan span) {
+        assertThat(span.getOperationName(), is(""XMemcached/set""));
+        assertThat(span.isExit(), is(true));
+        assertThat(SpanHelper.getComponentId(span), is(20));
+        List<KeyValuePair> tags = SpanHelper.getTags(span);
+        assertThat(tags.get(0).getValue(), is(""Memcache""));
+        assertThat(tags.get(1).getValue(), is(""set OperationKey""));
+        assertThat(SpanHelper.getLayer(span), is(SpanLayer.DB));
+    }
+    
+    private Method getMockSetMethod() {
+        try {
+            return XMemcachedClient.class.getMethod(""set"", String.class, int.class, Object.class);
+        } catch (NoSuchMethodException e) {
+            e.printStackTrace();","[{'comment': 'remove e.printStackTrace()', 'commenter': 'ascrutae'}, {'comment': 'In a test case, I think you can remove the try/catch instead of `e.printStackTrace`. The error should not happen if the test case is right.', 'commenter': 'wu-sheng'}, {'comment': 'OK! Thank you for your advice: \r\nprivate Method getMockGetMethod() throws Exception {', 'commenter': 'IluckySi'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,64 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        Map<InetSocketAddress, InetSocketAddress> inetSocketAddressMap = (Map<InetSocketAddress, InetSocketAddress>)allArguments[6];
+        StringBuilder master = new StringBuilder();
+        for (Entry<InetSocketAddress, InetSocketAddress> entry : inetSocketAddressMap.entrySet()) {
+            if (master.length() <= 0) {","[{'comment': ""`length` can't be negative."", 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,64 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        Map<InetSocketAddress, InetSocketAddress> inetSocketAddressMap = (Map<InetSocketAddress, InetSocketAddress>)allArguments[6];
+        StringBuilder master = new StringBuilder();
+        for (Entry<InetSocketAddress, InetSocketAddress> entry : inetSocketAddressMap.entrySet()) {
+            if (master.length() <= 0) {
+                master = append(master,entry.getKey());
+            }
+            memcachConnInfo = append(memcachConnInfo, entry.getValue());
+        }
+        memcachConnInfo =  master.append(memcachConnInfo);
+        int l = memcachConnInfo.length();","[{'comment': 'You should name the Integer `l`. ', 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,64 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        Map<InetSocketAddress, InetSocketAddress> inetSocketAddressMap = (Map<InetSocketAddress, InetSocketAddress>)allArguments[6];
+        StringBuilder master = new StringBuilder();
+        for (Entry<InetSocketAddress, InetSocketAddress> entry : inetSocketAddressMap.entrySet()) {","[{'comment': 'In this iteration, why use the entry#key of first element and entry#value of all as the peer? Can you demonstrate the data in the `inetSocketAddressMap`? I can be sure this is right or not.', 'commenter': 'wu-sheng'}, {'comment': ""For parameter addressMap, every k-v is a master standby mode. \r\nThere's something wrong with my understanding， I will fix it."", 'commenter': 'IluckySi'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,64 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        Map<InetSocketAddress, InetSocketAddress> inetSocketAddressMap = (Map<InetSocketAddress, InetSocketAddress>)allArguments[6];
+        StringBuilder master = new StringBuilder();
+        for (Entry<InetSocketAddress, InetSocketAddress> entry : inetSocketAddressMap.entrySet()) {
+            if (master.length() <= 0) {
+                master = append(master,entry.getKey());
+            }
+            memcachConnInfo = append(memcachConnInfo, entry.getValue());
+        }
+        memcachConnInfo =  master.append(memcachConnInfo);
+        int l = memcachConnInfo.length();
+        if (l > 1) {
+            memcachConnInfo = new StringBuilder(memcachConnInfo.substring(0, l - 1));
+        }
+        objInst.setSkyWalkingDynamicField(memcachConnInfo.toString());
+    }
+
+    /**
+     * Parse InetSocketAddress
+     * @param sb
+     * @param inetSocketAddress
+     * @return
+     */","[{'comment': 'If you write the comments, please finish them.', 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,64 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {","[{'comment': 'Add author info and comments for each class.', 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithInetSocketAddressListArgInterceptor.java,"@@ -0,0 +1,45 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class XMemcachedConstructorWithInetSocketAddressListArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        List<InetSocketAddress> inetSocketAddressList = (List<InetSocketAddress>)allArguments[0];
+        for (InetSocketAddress inetSocketAddress : inetSocketAddressList) {
+            String host = inetSocketAddress.getAddress().getHostAddress();
+            int port = inetSocketAddress.getPort();
+            memcachConnInfo.append(host).append("":"").append(port).append("";"");
+        }
+        int l = memcachConnInfo.length();","[{'comment': 'You should name the Integer `l`.', 'commenter': 'wu-sheng'}, {'comment': '@IluckySi you missed this. :P', 'commenter': 'wu-sheng'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+/**
+ * {@link XMemcachedConstructorWithComplexArgInterceptor} intercept constructor of 
+ * {@link XMemcachedClient(MemcachedSessionLocator locator,BufferAllocator allocator, Configuration conf,
+ * Map<SocketOption, Object> socketOptions, CommandFactory commandFactory, Transcoder transcoder,
+ * Map<InetSocketAddress, InetSocketAddress> addressMap, List<MemcachedClientStateListener> stateListeners,
+ * Map<InetSocketAddress, AuthInfo> map, int poolSize, long connectTimeout, String name, boolean failureMode)} or
+ * {@link XMemcachedClient(MemcachedSessionLocator locator, BufferAllocator allocator, Configuration conf,
+ * Map<SocketOption, Object> socketOptions, CommandFactory commandFactory, Transcoder transcoder,
+ * Map<InetSocketAddress, InetSocketAddress> addressMap, int[] weights, List<MemcachedClientStateListener> stateListeners,
+ * Map<InetSocketAddress, AuthInfo> infoMap, int poolSize, long connectTimeout, final String name, boolean failureMode)}.
+ * For parameter addressMap, every k-v is a master standby mode.
+ * 
+ * @author IluckySi
+ */
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        Map<InetSocketAddress, InetSocketAddress> inetSocketAddressMap = (Map<InetSocketAddress, InetSocketAddress>)allArguments[6];
+        for (Entry<InetSocketAddress, InetSocketAddress> entry : inetSocketAddressMap.entrySet()) {
+            memcachConnInfo = append(memcachConnInfo, entry.getKey());
+            memcachConnInfo = append(memcachConnInfo, entry.getValue());","[{'comment': 'Can you explain a little about when should use a Map as a memcached client parameters.', 'commenter': 'wu-sheng'}, {'comment': 'I add it in comment For parameter addressMap, every k-v is a master standby mode.', 'commenter': 'IluckySi'}]"
518,apm-sniffer/apm-sdk-plugin/xmemcached-2.x-plugin/src/main/java/org/skywalking/apm/plugin/xmemcached/v2/XMemcachedConstructorWithComplexArgInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.xmemcached.v2;
+
+import java.net.InetSocketAddress;
+import java.util.Map;
+import java.util.Map.Entry;
+
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+/**
+ * {@link XMemcachedConstructorWithComplexArgInterceptor} intercept constructor of 
+ * {@link XMemcachedClient(MemcachedSessionLocator locator,BufferAllocator allocator, Configuration conf,
+ * Map<SocketOption, Object> socketOptions, CommandFactory commandFactory, Transcoder transcoder,
+ * Map<InetSocketAddress, InetSocketAddress> addressMap, List<MemcachedClientStateListener> stateListeners,
+ * Map<InetSocketAddress, AuthInfo> map, int poolSize, long connectTimeout, String name, boolean failureMode)} or
+ * {@link XMemcachedClient(MemcachedSessionLocator locator, BufferAllocator allocator, Configuration conf,
+ * Map<SocketOption, Object> socketOptions, CommandFactory commandFactory, Transcoder transcoder,
+ * Map<InetSocketAddress, InetSocketAddress> addressMap, int[] weights, List<MemcachedClientStateListener> stateListeners,
+ * Map<InetSocketAddress, AuthInfo> infoMap, int poolSize, long connectTimeout, final String name, boolean failureMode)}.
+ * For parameter addressMap, every k-v is a master standby mode.
+ * 
+ * @author IluckySi
+ */
+public class XMemcachedConstructorWithComplexArgInterceptor implements InstanceConstructorInterceptor {
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        StringBuilder memcachConnInfo = new StringBuilder();
+        @SuppressWarnings(""unchecked"")
+        Map<InetSocketAddress, InetSocketAddress> inetSocketAddressMap = (Map<InetSocketAddress, InetSocketAddress>)allArguments[6];
+        for (Entry<InetSocketAddress, InetSocketAddress> entry : inetSocketAddressMap.entrySet()) {
+            memcachConnInfo = append(memcachConnInfo, entry.getKey());
+            memcachConnInfo = append(memcachConnInfo, entry.getValue());
+        }
+        Integer l = memcachConnInfo.length();","[{'comment': ""You missed this variable naming suggestion. `l` isn't a good name."", 'commenter': 'wu-sheng'}, {'comment': 'OK! I name it ""length""', 'commenter': 'IluckySi'}]"
519,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -31,3 +31,9 @@ storage:
     cluster_nodes: localhost:9300
     index_shards_number: 2
     index_replicas_number: 0
+# uncomment to enable h2 storage
+#storage:
+#    h2:
+#      url: jdbc:h2:~/collector
+#      user_name: sa
+#      password: sa","[{'comment': ""@peng-yongsheng @clevertension  I prefer use h2 as default storage, in order to start up collector easier. What do you think? And I recommend don't use zookeeper as default. By these two, our collector quick start is pretty easy. \r\n\r\n```yml\r\n# Uncomment to make collector running in cluster mode, by zookeeper as a coordinator.\r\n# cluster:\r\n#   zookeeper:\r\n#     hostPort: localhost:2181\r\n#     sessionTimeout: 100000\r\n```"", 'commenter': 'wu-sheng'}, {'comment': ""two thumbs up， i can't agree more!\r\nwe need to configure easy, run as quickly as possible to show the demos to users"", 'commenter': 'clevertension'}, {'comment': '+1, Now, The mechanism of cluster module is this: \r\nWhen collector start up with no config about the cluster module, the cluster will choose the h2 module.', 'commenter': 'peng-yongsheng'}]"
519,apm-collector/apm-collector-agentregister/src/main/java/org/skywalking/apm/collector/agentregister/worker/application/dao/ApplicationH2DAO.java,"@@ -18,29 +18,51 @@
 
 package org.skywalking.apm.collector.agentregister.worker.application.dao;
 
+
 import org.skywalking.apm.collector.client.h2.H2Client;
+import org.skywalking.apm.collector.client.h2.H2ClientException;
 import org.skywalking.apm.collector.storage.define.register.ApplicationDataDefine;
+import org.skywalking.apm.collector.storage.define.register.ApplicationTable;
+import org.skywalking.apm.collector.storage.h2.SqlBuilder;
 import org.skywalking.apm.collector.storage.h2.dao.H2DAO;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 /**
- * @author pengys5
+ * @author pengys5, clevertension
  */
 public class ApplicationH2DAO extends H2DAO implements IApplicationDAO {
+    private final Logger logger = LoggerFactory.getLogger(ApplicationH2DAO.class);
+    private static final String INSERT_APPLICATION_SQL = ""insert into {0}({1}, {2}) values(?, ?)"";
+    @Override
+    public int getApplicationId(String applicationCode) {
+        logger.info(""get the application id with application code = {}"", applicationCode);
+        String sql = ""select "" + ApplicationTable.COLUMN_APPLICATION_ID + "" from "" +","[{'comment': 'Why only this sql built by String append, instead of sqlBuilder?', 'commenter': 'wu-sheng'}]"
519,apm-collector/apm-collector-client/src/main/java/org/skywalking/apm/collector/client/h2/H2Client.java,"@@ -34,43 +33,89 @@
 
     private final Logger logger = LoggerFactory.getLogger(H2Client.class);
 
+    private JdbcConnectionPool cp;
     private Connection conn;
+    private String url;
+    private String userName;
+    private String password;
+
+    public H2Client() {
+        this.url = ""jdbc:h2:mem:collector"";
+        this.userName = """";
+        this.password = """";
+    }
+
+    public H2Client(String url, String userName, String password) {
+        this.url = url;
+        this.userName = userName;
+        this.password = password;
+    }
 
     @Override public void initialize() throws H2ClientException {
         try {
-            Class.forName(""org.h2.Driver"");
-            conn = DriverManager.getConnection(""jdbc:h2:mem:collector"");
-        } catch (ClassNotFoundException | SQLException e) {
+            cp = JdbcConnectionPool.
+                    create(this.url, this.userName, this.password);
+            conn = cp.getConnection();
+        } catch (Exception e) {
             throw new H2ClientException(e.getMessage(), e);
         }
     }
 
     @Override public void shutdown() {
+        if (cp != null) {
+            cp.dispose();
+        }
+        IOUtils.closeSilently(conn);
+    }
 
+    public Connection getConnection() throws H2ClientException {
+        return conn;
     }
 
     public void execute(String sql) throws H2ClientException {
-        Statement statement = null;
-        try {
-            statement = conn.createStatement();
+        try (Statement statement = getConnection().createStatement()) {
             statement.execute(sql);
             statement.closeOnCompletion();
         } catch (SQLException e) {
             throw new H2ClientException(e.getMessage(), e);
         }
     }
 
-    public void executeQuery(String sql) throws H2ClientException {
-        Statement statement = null;
+    public ResultSet executeQuery(String sql, Object[] params) throws H2ClientException {
+        logger.debug(""execute query with result: {}"", sql);
+        ResultSet rs;
+        PreparedStatement statement;
         try {
-            statement = conn.createStatement();
-            ResultSet rs = statement.executeQuery(sql);
-            while (rs.next()) {
-                logger.debug(rs.getString(""ADDRESS"") + "","" + rs.getString(""DATA""));
+            statement = getConnection().prepareStatement(sql);
+            if (params != null) {
+                for (int i = 0; i < params.length; i++) {
+                    statement.setObject(i + 1, params[i]);
+                }
             }
+            rs = statement.executeQuery();
             statement.closeOnCompletion();
         } catch (SQLException e) {
             throw new H2ClientException(e.getMessage(), e);
         }
+        return rs;
+    }
+
+    public boolean execute(String sql, Object[] params) throws H2ClientException {
+        logger.debug(""execute insert/update/delete: {}"", sql);
+        boolean flag;
+        Connection conn = getConnection();
+        try (PreparedStatement statement = conn.prepareStatement(sql)) {
+            conn.setAutoCommit(false);","[{'comment': 'I suggest auto commit to be true.', 'commenter': 'peng-yongsheng'}]"
519,apm-collector/apm-collector-storage/src/main/java/org/skywalking/apm/collector/storage/h2/dao/BatchH2DAO.java,"@@ -18,15 +18,75 @@
 
 package org.skywalking.apm.collector.storage.h2.dao;
 
-import java.util.List;
+import org.skywalking.apm.collector.client.h2.H2ClientException;
 import org.skywalking.apm.collector.storage.dao.IBatchDAO;
+import org.skywalking.apm.collector.storage.h2.define.H2SqlEntity;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
 /**
  * @author pengys5
  */
 public class BatchH2DAO extends H2DAO implements IBatchDAO {
+    private final Logger logger = LoggerFactory.getLogger(BatchH2DAO.class);
 
-    @Override public void batchPersistence(List<?> batchCollection) {
+    @Override
+    public void batchPersistence(List<?> batchCollection) {
+        if (batchCollection != null && batchCollection.size() > 0) {
+            logger.debug(""the batch collection size is {}"", batchCollection.size());
+            Connection conn = null;
+            final Map<String, PreparedStatement> batchSqls = new HashMap<>();
+            try {
+                conn = getClient().getConnection();
+                conn.setAutoCommit(false);","[{'comment': 'I suggest auto commit to be true.', 'commenter': 'peng-yongsheng'}]"
519,apm-collector/apm-collector-storage/src/main/java/org/skywalking/apm/collector/storage/h2/dao/BatchH2DAO.java,"@@ -18,15 +18,75 @@
 
 package org.skywalking.apm.collector.storage.h2.dao;
 
-import java.util.List;
+import org.skywalking.apm.collector.client.h2.H2ClientException;
 import org.skywalking.apm.collector.storage.dao.IBatchDAO;
+import org.skywalking.apm.collector.storage.h2.define.H2SqlEntity;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
 
 /**
  * @author pengys5
  */
 public class BatchH2DAO extends H2DAO implements IBatchDAO {
+    private final Logger logger = LoggerFactory.getLogger(BatchH2DAO.class);
 
-    @Override public void batchPersistence(List<?> batchCollection) {
+    @Override
+    public void batchPersistence(List<?> batchCollection) {
+        if (batchCollection != null && batchCollection.size() > 0) {
+            logger.debug(""the batch collection size is {}"", batchCollection.size());
+            Connection conn = null;
+            final Map<String, PreparedStatement> batchSqls = new HashMap<>();
+            try {
+                conn = getClient().getConnection();
+                conn.setAutoCommit(false);
+                PreparedStatement ps;
+                for (Object entity : batchCollection) {
+                    H2SqlEntity e = getH2SqlEntity(entity);
+                    String sql = e.getSql();
+                    if (batchSqls.containsKey(sql)) {
+                        ps = batchSqls.get(sql);
+                    } else {
+                        ps = conn.prepareStatement(sql);
+                        batchSqls.put(sql, ps);
+                    }
+
+                    Object[] params = e.getParams();
+                    if (params != null) {
+                        logger.debug(""the sql is {}, params size is {}"", e.getSql(), params.length);
+                        for (int i = 0; i < params.length; i++) {
+                            ps.setObject(i + 1, params[i]);
+                        }
+                    }
+                    ps.addBatch();
+                }
+
+                for (String k : batchSqls.keySet()) {
+                    batchSqls.get(k).executeBatch();
+                }
+                conn.commit();
+            } catch (SQLException | H2ClientException e) {
+                logger.error(e.getMessage(), e);
+                try {","[{'comment': 'When auto commit has been true, rollback need to be removed. ', 'commenter': 'peng-yongsheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/vo/CachedObjects.java,"@@ -0,0 +1,83 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1.vo;
+
+import io.grpc.Metadata;
+import io.grpc.MethodDescriptor;
+import org.skywalking.apm.agent.core.context.ContextSnapshot;
+
+public class CachedObjects {","[{'comment': 'Why named `CachedObjects`? Any object with status can be named this.', 'commenter': 'wu-sheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/vo/ServiceDescriptor.java,"@@ -0,0 +1,52 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1.vo;
+
+import io.grpc.MethodDescriptor;
+
+public class ServiceDescriptor {
+    private MethodDescriptor.MethodType methodType;
+    private String serviceName;
+
+    public ServiceDescriptor(MethodDescriptor descriptor) {
+        this.methodType = descriptor.getType();
+        String fullMethodName = descriptor.getFullMethodName();
+        this.serviceName = dealWithServiceName(fullMethodName) + ""."" + dealWithMethodName(fullMethodName);
+    }
+
+    private String dealWithServiceName(String requestMethodName) {","[{'comment': '`dealWith` is too abstract, it is more likely a format.', 'commenter': 'wu-sheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/vo/ServiceDescriptor.java,"@@ -0,0 +1,52 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1.vo;
+
+import io.grpc.MethodDescriptor;
+
+public class ServiceDescriptor {
+    private MethodDescriptor.MethodType methodType;
+    private String serviceName;
+
+    public ServiceDescriptor(MethodDescriptor descriptor) {
+        this.methodType = descriptor.getType();
+        String fullMethodName = descriptor.getFullMethodName();
+        this.serviceName = dealWithServiceName(fullMethodName) + ""."" + dealWithMethodName(fullMethodName);
+    }
+
+    private String dealWithServiceName(String requestMethodName) {
+        int splitIndex = requestMethodName.lastIndexOf(""/"");
+        return requestMethodName.substring(0, splitIndex);
+    }
+
+    private String dealWithMethodName(String requestMethodName) {","[{'comment': '`dealWith` is too abstract, it is more likely a format.', 'commenter': 'wu-sheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/StreamClientOnCloseInterceptor.java,"@@ -0,0 +1,49 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.grpc.v1.vo.CachedObjects;
+
+public class StreamClientOnCloseInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        AbstractSpan abstractSpan = ContextManager.activeSpan();
+        abstractSpan.tag(""onNext.count"", String.valueOf(((CachedObjects)objInst.getSkyWalkingDynamicField()).getOnNextCount()));","[{'comment': 'Why no use constant/staticField?', 'commenter': 'wu-sheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/ServerCallOnReadyInterceptor.java,"@@ -0,0 +1,75 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1;
+
+import io.grpc.Metadata;
+import io.grpc.MethodDescriptor;
+import java.lang.reflect.Method;
+import java.util.HashMap;
+import java.util.Map;
+import org.skywalking.apm.agent.core.context.CarrierItem;
+import org.skywalking.apm.agent.core.context.ContextCarrier;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.skywalking.apm.plugin.grpc.v1.vo.CachedObjects;
+import org.skywalking.apm.util.StringUtil;
+
+public class ServerCallOnReadyInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        CachedObjects cachedObjects = (CachedObjects)objInst.getSkyWalkingDynamicField();
+        Metadata headers = cachedObjects.getMetadata();
+        Map<String, String> headerMap = new HashMap<String, String>();
+        for (String key : headers.keys()) {
+            if (!key.endsWith(Metadata.BINARY_HEADER_SUFFIX)) {
+                String value = headers.get(Metadata.Key.of(key, Metadata.ASCII_STRING_MARSHALLER));
+                headerMap.put(key, value);
+            }
+        }
+
+        ContextCarrier contextCarrier = new ContextCarrier();
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            String contextValue = headerMap.get(next.getHeadKey());
+            if (!StringUtil.isEmpty(contextValue)) {
+                next.setHeadValue(contextValue);
+            }
+        }
+
+        final AbstractSpan span = ContextManager.createEntrySpan(cachedObjects.getRequestMethodName() + (cachedObjects.getMethodType() != MethodDescriptor.MethodType.UNARY ? ""/StreamCall"" : ""/UnaryCall""), contextCarrier);","[{'comment': 'Why no use constant/staticField?', 'commenter': 'wu-sheng'}, {'comment': 'Is `UnaryCall` a gRPC inside name? I think it is from here: `MethodDescriptor.MethodType.UNARY`, right? But why do you choose this name? It is hard to understand. for normal user.', 'commenter': 'wu-sheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/ServerCallOnMessageInterceptor.java,"@@ -0,0 +1,52 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.grpc.v1.vo.CachedObjects;
+
+public class ServerCallOnMessageInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        CachedObjects cachedObjects = (CachedObjects)objInst.getSkyWalkingDynamicField();
+        ContextManager.createLocalSpan(cachedObjects.getRequestMethodName() + ""/ResponseStreamObserver/OnNext"");","[{'comment': 'Why no use constant/staticField?', 'commenter': 'wu-sheng'}]"
521,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/skywalking/apm/plugin/grpc/v1/ServerCallOnCloseInterceptor.java,"@@ -0,0 +1,49 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.grpc.v1;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.grpc.v1.vo.CachedObjects;
+
+public class ServerCallOnCloseInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        AbstractSpan abstractSpan = ContextManager.activeSpan();
+        abstractSpan.tag(""onNext.count"", String.valueOf(((CachedObjects)objInst.getSkyWalkingDynamicField()).getOnNextCount()));","[{'comment': 'Why no use constant/staticField?', 'commenter': 'wu-sheng'}]"
529,apm-sniffer/apm-sdk-plugin/nutz-plugins/mvc-annotation-1.x-plugin/src/main/java/org/skywalking/apm/plugin/nutz/mvc/ActionMethodInterceptor.java,"@@ -76,7 +78,7 @@ public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allA
         HttpServletResponse response = Mvcs.getResp();
 
         AbstractSpan span = ContextManager.activeSpan();
-        if (response.getStatus() >= 400) {
+        if (ServletApiTool.isResponseGetStatusAvailable() && response.getStatus() >= 400) {","[{'comment': 'How can I get the status when `getStatus` is not available?', 'commenter': 'wu-sheng'}]"
529,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/tool/ServletApiTool.java,"@@ -0,0 +1,45 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.agent.core.tool;
+
+import javax.servlet.http.HttpServletResponse;
+
+/**
+ * 
+ * @author wendal
+ *
+ */
+public class ServletApiTool {
+
+    // HttpServletResponse.getStatus() is available since Servlet API 3.0
+    protected static boolean RGSA;","[{'comment': ""* What does RGSA stand for? I suppose `Response Get Status Available`? I think this isn't a normal short term. You should use a more explicit field name, such as `isSupportGetStatus` or `isServlet3`. What do you think?\r\n"", 'commenter': 'wu-sheng'}]"
529,apm-sniffer/apm-agent-core/src/main/java/org/skywalking/apm/agent/core/tool/ServletApiTool.java,"@@ -0,0 +1,45 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.agent.core.tool;
+
+import javax.servlet.http.HttpServletResponse;
+
+/**
+ * 
+ * @author wendal
+ *
+ */
+public class ServletApiTool {
+
+    // HttpServletResponse.getStatus() is available since Servlet API 3.0
+    protected static boolean RGSA;
+    protected static boolean INITED;","[{'comment': ""* Use `volatile` keyword for these two fields. Because you can't be sure the thread module, this field value could be cached by thread, and every thread must cost CPU to initialize the value."", 'commenter': 'wu-sheng'}]"
533,apm-collector/apm-collector-agentregister/src/main/java/org/skywalking/apm/collector/agentregister/worker/application/ApplicationRegisterSerialWorker.java,"@@ -55,8 +55,10 @@ public ApplicationRegisterSerialWorker(Role role, ClusterWorkerContext clusterCo
             ApplicationDataDefine.Application application = (ApplicationDataDefine.Application)message;
             logger.debug(""register application, application code: {}"", application.getApplicationCode());
 
+            org.skywalking.apm.collector.cache.dao.IApplicationDAO cacheDao = (org.skywalking.apm.collector.cache.dao.IApplicationDAO)DAOContainer.INSTANCE.get(org.skywalking.apm.collector.cache.dao.IApplicationDAO.class.getName());","[{'comment': 'Why use the full name instead of `import`?', 'commenter': 'wu-sheng'}]"
533,apm-collector/apm-collector-agentregister/src/main/java/org/skywalking/apm/collector/agentregister/worker/servicename/ServiceNameRegisterSerialWorker.java,"@@ -55,9 +55,10 @@ public ServiceNameRegisterSerialWorker(Role role, ClusterWorkerContext clusterCo
             ServiceNameDataDefine.ServiceName serviceName = (ServiceNameDataDefine.ServiceName)message;
             logger.debug(""register service name: {}, application id: {}"", serviceName.getServiceName(), serviceName.getApplicationId());
 
-            IServiceNameDAO dao = (IServiceNameDAO)DAOContainer.INSTANCE.get(IServiceNameDAO.class.getName());
-            int serviceId = dao.getServiceId(serviceName.getApplicationId(), serviceName.getServiceName());
+            org.skywalking.apm.collector.cache.dao.IServiceNameDAO cacheDao = (org.skywalking.apm.collector.cache.dao.IServiceNameDAO)DAOContainer.INSTANCE.get(IServiceNameDAO.class.getName());","[{'comment': 'Same, Why use the full name instead of import?', 'commenter': 'wu-sheng'}]"
533,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/segment/buffer/OffsetManager.java,"@@ -0,0 +1,152 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.collector.agentstream.worker.segment.buffer;
+
+import java.io.File;
+import java.io.FilenameFilter;
+import java.io.IOException;
+import java.io.RandomAccessFile;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import org.skywalking.apm.collector.agentstream.config.BufferFileConfig;
+import org.skywalking.apm.collector.agentstream.worker.util.FileUtils;
+import org.skywalking.apm.collector.core.util.CollectionUtils;
+import org.skywalking.apm.collector.core.util.Const;
+import org.skywalking.apm.collector.core.util.TimeBucketUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author pengys5
+ */
+public enum OffsetManager {
+    INSTANCE;
+
+    private final Logger logger = LoggerFactory.getLogger(OffsetManager.class);
+
+    private static final String OFFSET_FILE_PREFIX = ""offset"";
+    private File offsetFile;
+    private Offset offset;
+    private boolean initialized = false;
+    private RandomAccessFile randomAccessFile = null;
+    private String lastOffsetRecord = Const.EMPTY_STRING;
+
+    public synchronized void initialize() throws IOException {
+        if (!initialized) {
+            this.offset = new Offset();
+            File dataPath = new File(SegmentBufferConfig.BUFFER_PATH);
+            if (dataPath.mkdirs()) {
+                createOffsetFile();
+            } else {
+                File[] offsetFiles = dataPath.listFiles(new PrefixFileNameFilter());
+                if (CollectionUtils.isNotEmpty(offsetFiles) && offsetFiles.length > 0) {
+                    for (int i = 0; i < offsetFiles.length; i++) {
+                        if (i != offsetFiles.length - 1) {
+                            offsetFiles[i].delete();
+                        } else {
+                            offsetFile = offsetFiles[i];
+                        }
+                    }
+                } else {
+                    createOffsetFile();
+                }
+            }
+            String offsetRecord = FileUtils.INSTANCE.readLastLine(offsetFile);
+            offset.deserialize(offsetRecord);
+            initialized = true;
+
+            Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(() -> flush(), 10, 3, TimeUnit.SECONDS);
+        }
+    }
+
+    private void createOffsetFile() throws IOException {
+        String timeBucket = String.valueOf(TimeBucketUtils.INSTANCE.getSecondTimeBucket(System.currentTimeMillis()));
+        String offsetFileName = OFFSET_FILE_PREFIX + ""_"" + timeBucket + ""."" + Const.FILE_SUFFIX;
+        offsetFile = new File(SegmentBufferConfig.BUFFER_PATH + offsetFileName);
+        this.offset.getWriteOffset().setWriteFileName(Const.EMPTY_STRING);
+        this.offset.getWriteOffset().setWriteFileOffset(0);
+        this.offset.getReadOffset().setReadFileName(Const.EMPTY_STRING);
+        this.offset.getReadOffset().setReadFileOffset(0);
+        this.flush();
+    }
+
+    public void flush() {
+        String offsetRecord = offset.serialize();
+        if (!lastOffsetRecord.equals(offsetRecord)) {
+            if (offsetFile.length() >= BufferFileConfig.BUFFER_OFFSET_MAX_FILE_SIZE) {
+                exchangeFile();
+            }
+            FileUtils.INSTANCE.writeAppendToLast(offsetFile, randomAccessFile, offsetRecord);
+            lastOffsetRecord = offsetRecord;
+        }
+    }
+
+    private void exchangeFile() {","[{'comment': 'I think your name should be `nextFile()`, right? Exchange means using one file to get other file.', 'commenter': 'wu-sheng'}, {'comment': 'For data file, your name is `newDataFile`.', 'commenter': 'wu-sheng'}]"
533,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/segment/buffer/SegmentBufferReader.java,"@@ -0,0 +1,151 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.collector.agentstream.worker.segment.buffer;
+
+import com.google.protobuf.CodedOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FilenameFilter;
+import java.io.IOException;
+import java.io.InputStream;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import org.skywalking.apm.collector.agentstream.worker.segment.SegmentParse;
+import org.skywalking.apm.collector.core.util.CollectionUtils;
+import org.skywalking.apm.collector.core.util.Const;
+import org.skywalking.apm.collector.core.util.StringUtils;
+import org.skywalking.apm.network.proto.UpstreamSegment;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author pengys5
+ */
+public enum SegmentBufferReader {
+    INSTANCE;
+
+    private final Logger logger = LoggerFactory.getLogger(SegmentBufferReader.class);
+    private InputStream inputStream;
+
+    public void initialize() {
+        Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(this::preRead, 3, 3, TimeUnit.SECONDS);
+    }
+
+    private void preRead() {
+        String readFileName = OffsetManager.INSTANCE.getReadFileName();
+        if (StringUtils.isNotEmpty(readFileName)) {
+            File readFile = new File(SegmentBufferConfig.BUFFER_PATH + readFileName);
+            if (readFile.exists()) {
+                deleteTheDataFilesBeforeReadFile(readFileName);
+                long readFileOffset = OffsetManager.INSTANCE.getReadFileOffset();
+                read(readFile, readFileOffset);
+                readEarliestCreateDataFile();
+            } else {
+                deleteTheDataFilesBeforeReadFile(readFileName);
+                readEarliestCreateDataFile();
+            }
+        } else {
+            readEarliestCreateDataFile();
+        }
+    }
+
+    private void deleteTheDataFilesBeforeReadFile(String readFileName) {
+        File[] dataFiles = new File(SegmentBufferConfig.BUFFER_PATH).listFiles(new PrefixFileNameFilter());
+
+        long readFileCreateTime = getFileCreateTime(readFileName);
+        for (File dataFile : dataFiles) {
+            long fileCreateTime = getFileCreateTime(dataFile.getName());
+            if (fileCreateTime < readFileCreateTime) {
+                dataFile.delete();
+            } else if (fileCreateTime == readFileCreateTime) {
+                break;
+            }
+        }
+    }
+
+    private long getFileCreateTime(String fileName) {","[{'comment': 'A suggestion only, is using long as a time representation a good idea? In my olde time, I prefer, `YYYYMMDDHHmmSS` to represent time.', 'commenter': 'wu-sheng'}]"
533,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/segment/standardization/SpanIdExchanger.java,"@@ -0,0 +1,64 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.collector.agentstream.worker.segment.standardization;
+
+import org.skywalking.apm.collector.cache.ApplicationCache;
+import org.skywalking.apm.collector.cache.ServiceIdCache;
+import org.skywalking.apm.collector.core.util.Const;
+import org.skywalking.apm.collector.core.util.StringUtils;
+
+/**
+ * @author pengys5
+ */
+public class SpanIdExchanger implements IdExchanger<SpanDecorator> {
+
+    private static SpanIdExchanger exchanger;","[{'comment': ""Why don't use an enum? I think this is our style for singleton."", 'commenter': 'wu-sheng'}]"
533,apm-collector/apm-collector-agentstream/src/main/java/org/skywalking/apm/collector/agentstream/worker/service/entry/dao/ServiceEntryH2DAO.java,"@@ -42,10 +41,11 @@
  */
 public class ServiceEntryH2DAO extends H2DAO implements IServiceEntryDAO, IPersistenceDAO<H2SqlEntity, H2SqlEntity> {
     private final Logger logger = LoggerFactory.getLogger(ServiceEntryH2DAO.class);
-    private static final String GET_SERIVCE_ENTRY_SQL = ""select * from {0} where {1} = ?"";
+    private static final String GET_SERVICE_ENTRY_SQL = ""select * from {0} where {1} = ?"";
+
     @Override public Data get(String id, DataDefine dataDefine) {
         H2Client client = getClient();
-        String sql = SqlBuilder.buildSql(ServiceEntryTable.TABLE, ""id"");
+        String sql = SqlBuilder.buildSql(GET_SERVICE_ENTRY_SQL, ServiceEntryTable.TABLE, ""id"");","[{'comment': ':( I think I have to refactor all these codes in 3.3... since you are using a variable instead of a method to get the table....', 'commenter': 'wu-sheng'}, {'comment': '^_^', 'commenter': 'peng-yongsheng'}]"
533,apm-collector/apm-collector-agentstream/src/test/java/org/skywalking/apm/collector/agentstream/mock/SegmentPost.java,"@@ -121,4 +135,8 @@ private static JsonObject osInfo(String hostName) {
 
         return osInfoJson;
     }
+
+    private void newDao() {","[{'comment': 'Useless method?', 'commenter': 'wu-sheng'}, {'comment': 'delete...', 'commenter': 'peng-yongsheng'}]"
533,apm-collector/apm-collector-agentstream/src/test/java/org/skywalking/apm/collector/agentstream/worker/segment/buffer/OffsetManagerTestCase.java,"@@ -16,17 +16,16 @@
  * Project repository: https://github.com/OpenSkywalking/skywalking
  */
 
-package org.skywalking.apm.collector.agentstream.worker.util;
+package org.skywalking.apm.collector.agentstream.worker.segment.buffer;
+
+import org.junit.Test;
 
 /**
  * @author pengys5
  */
-public enum ExchangeMarkUtils {
-    INSTANCE;
-
-    private static final String MARK_TAG = ""M"";
+public class OffsetManagerTestCase {
 
-    public String buildMarkedID(int id) {
-        return MARK_TAG + id;
+    @Test
+    public void test() {","[{'comment': 'Useless and empty method?', 'commenter': 'wu-sheng'}, {'comment': 'delete....', 'commenter': 'peng-yongsheng'}]"
533,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -1,7 +1,7 @@
-cluster:
-  zookeeper:
-    hostPort: localhost:2181
-    sessionTimeout: 100000
+#cluster:","[{'comment': 'Add comment about the config.', 'commenter': 'wu-sheng'}, {'comment': 'The description of this config in Wiki.', 'commenter': 'peng-yongsheng'}]"
533,apm-collector/apm-collector-cache/src/main/java/org/skywalking/apm/collector/cache/ServiceIdCache.java,"@@ -16,39 +16,41 @@
  * Project repository: https://github.com/OpenSkywalking/skywalking
  */
 
-package org.skywalking.apm.collector.ui.cache;
+package org.skywalking.apm.collector.cache;
 
 import com.google.common.cache.Cache;
 import com.google.common.cache.CacheBuilder;
+import org.skywalking.apm.collector.cache.dao.IServiceNameDAO;
 import org.skywalking.apm.collector.core.util.Const;
 import org.skywalking.apm.collector.storage.dao.DAOContainer;
-import org.skywalking.apm.collector.ui.dao.IServiceNameDAO;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 /**
  * @author pengys5
  */
 public class ServiceIdCache {
 
+    private static final Logger logger = LoggerFactory.getLogger(ServiceIdCache.class);
+
     //TODO size configuration
-    private static Cache<String, Integer> CACHE = CacheBuilder.newBuilder().maximumSize(1000).build();
+    private static Cache<String, Integer> SERVICE_CACHE = CacheBuilder.newBuilder().maximumSize(1000).build();","[{'comment': 'Set a new config? FIx a TODO?', 'commenter': 'wu-sheng'}, {'comment': 'Plan to support that set the size config in a single file.', 'commenter': 'peng-yongsheng'}]"
533,apm-collector/apm-collector-cache/src/main/java/org/skywalking/apm/collector/cache/dao/ApplicationH2DAO.java,"@@ -37,18 +36,27 @@
 
     private final Logger logger = LoggerFactory.getLogger(ApplicationH2DAO.class);
     private static final String GET_APPLICATION_CODE_SQL = ""select {0} from {1} where {2} = ?"";
+
+    @Override
+    public int getApplicationId(String applicationCode) {
+        logger.info(""get the application id with application code = {}"", applicationCode);
+        String sql = ""select "" + ApplicationTable.COLUMN_APPLICATION_ID + "" from "" +","[{'comment': ""Why don't use SQLBuilder Here?"", 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/vo/StatementEnhanceRequireCacheObject.java,"@@ -0,0 +1,51 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql.vo;
+
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+
+/**
+ * {@link StatementEnhanceRequireCacheObject} contain the {@link org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo}
+ * and <code>sql</code> for enhance.
+ *
+ * @author zhangxin
+ */
+public class StatementEnhanceRequireCacheObject {","[{'comment': ""I don't agree `StatementEnhanceRequireCacheObject` is a good name. These is nothing about `cache` first, every JavaBean is about keeping some values, and you can't call every JavaBean as `*CacheObject`. I think the name should be `StatementMetricNameKeyInfos`.\r\n\r\nAnd you should add new package ` org.skywalking.apm.plugin.jdbc.mysql.vo` for it. Because only one class in a separated package is a strange thing, specially unlikely you are not going to add more classes in that package. Right?"", 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/define/JDBC42PreparedStatementInstrumentation.java,"@@ -0,0 +1,37 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql.define;
+
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static org.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link JDBC42PreparedStatementInstrumentation} define intercept {@link com.mysql.jdbc.JDBC42PreparedStatement}","[{'comment': '* `define` -> `defines`\r\n* `intercept` -> `the interceptor for`', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/ServiceMethodInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+import org.skywalking.apm.util.StringUtil;
+
+/**
+ * {@link ServiceMethodInterceptor} create the exit span when the client call the interceptor methods.
+ *
+ * @author zhangxin
+ */
+public class ServiceMethodInterceptor implements InstanceMethodsAroundInterceptor {","[{'comment': 'Why call it `ServiceMethodInterceptor`, specially the `Service*` part. Clearly from your instrument define, it is about `execute*` method.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/CreateStatementInterceptor.java,"@@ -0,0 +1,54 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+
+/**
+ * {@link CreateStatementInterceptor} intercept the {@link com.mysql.jdbc.ConnectionImpl#createStatement()} method in","[{'comment': '* `intercept` -> `intercepts`.', 'commenter': 'wu-sheng'}, {'comment': '* `intercept` -> `intercepts`.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/CreatePreparedStatementInterceptor.java,"@@ -0,0 +1,54 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+
+/**
+ * {@link CreateStatementInterceptor} intercept the {@link com.mysql.jdbc.ConnectionImpl#prepareStatement()} method in","[{'comment': '* `intercept` -> `intercepts`.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/ServiceMethodInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+import org.skywalking.apm.util.StringUtil;
+
+/**
+ * {@link ServiceMethodInterceptor} create the exit span when the client call the interceptor methods.
+ *
+ * @author zhangxin
+ */
+public class ServiceMethodInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        StatementEnhanceRequireCacheObject cacheObject = (StatementEnhanceRequireCacheObject)objInst.getSkyWalkingDynamicField();
+        ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+        if (connectInfo != null) {
+            String remotePeer;
+            if (!StringUtil.isEmpty(connectInfo.getHosts())) {
+                remotePeer = connectInfo.getHosts();
+            } else {
+                remotePeer = connectInfo.getHost() + "":"" + connectInfo.getPort();
+            }","[{'comment': ""`Line 46-51` don't need to execute every time. As you can see, the ConnectionInfo can't be changed. So you should provide a `getRemotePeer` method with a cache mechanism to improve the performance."", 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/ServiceMethodInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+import org.skywalking.apm.util.StringUtil;
+
+/**
+ * {@link ServiceMethodInterceptor} create the exit span when the client call the interceptor methods.
+ *
+ * @author zhangxin
+ */
+public class ServiceMethodInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        StatementEnhanceRequireCacheObject cacheObject = (StatementEnhanceRequireCacheObject)objInst.getSkyWalkingDynamicField();
+        ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+        if (connectInfo != null) {","[{'comment': 'I think `connectInfo == null` only happens in in constructor stage, right? you miss the comments about that.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/ServiceMethodInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+import org.skywalking.apm.util.StringUtil;
+
+/**
+ * {@link ServiceMethodInterceptor} create the exit span when the client call the interceptor methods.
+ *
+ * @author zhangxin
+ */
+public class ServiceMethodInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        StatementEnhanceRequireCacheObject cacheObject = (StatementEnhanceRequireCacheObject)objInst.getSkyWalkingDynamicField();
+        ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+        if (connectInfo != null) {
+            String remotePeer;
+            if (!StringUtil.isEmpty(connectInfo.getHosts())) {
+                remotePeer = connectInfo.getHosts();
+            } else {
+                remotePeer = connectInfo.getHost() + "":"" + connectInfo.getPort();
+            }
+
+            AbstractSpan span = ContextManager.createExitSpan(buildOperationName(connectInfo, method.getName(), cacheObject.getStatementName()), remotePeer);
+            Tags.DB_TYPE.set(span, connectInfo.getDBType());
+            Tags.DB_INSTANCE.set(span, connectInfo.getDatabaseName());
+            Tags.DB_STATEMENT.set(span, cacheObject.getSql());
+            span.setComponent(connectInfo.getComponent());
+
+            SpanLayer.asDB(span);
+        }
+    }
+
+    @Override
+    public final Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        StatementEnhanceRequireCacheObject cacheObject = (StatementEnhanceRequireCacheObject)objInst.getSkyWalkingDynamicField();
+        if (cacheObject.getConnectionInfo() != null) {","[{'comment': 'I think `connectInfo == null` only happens in in constructor stage, right? you miss the comments about that.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/test/java/org/skywalking/apm/plugin/jdbc/mysql/ServiceMethodInterceptorTest.java,"@@ -0,0 +1,95 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+import org.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.skywalking.apm.agent.test.tools.SpanAssert;
+import org.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.skywalking.apm.plugin.jdbc.mysql.vo.StatementEnhanceRequireCacheObject;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.junit.Assert.assertThat;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class ServiceMethodInterceptorTest {","[{'comment': 'Same naming issue as `ServiceMethodInterceptor`', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/define/MultiClassNameMatch.java,"@@ -0,0 +1,67 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql.define;
+
+import java.util.Arrays;
+import java.util.List;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+
+/**
+ * Match multiple classes name with an explicit class name.","[{'comment': 'Match class with a given set of classes.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/define/MultiClassNameMatch.java,"@@ -0,0 +1,67 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql.define;
+
+import java.util.Arrays;
+import java.util.List;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.skywalking.apm.agent.core.plugin.match.IndirectMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+
+/**
+ * Match multiple classes name with an explicit class name.
+ *
+ * @author zhangxin
+ */
+public class MultiClassNameMatch implements IndirectMatch {
+
+    private List<String> matchClassNames;
+
+    private MultiClassNameMatch(String[] classNames) {
+        if (classNames == null || classNames.length == 0) {
+            throw new IllegalArgumentException(""match class names is null"");
+        }
+        this.matchClassNames = Arrays.asList(classNames);
+    }
+
+    @Override
+    public ElementMatcher.Junction buildJunction() {
+        ElementMatcher.Junction junction = null;
+        for (String name : matchClassNames) {
+            if (junction == null) {
+                junction = named(name);
+            } else {
+                junction = junction.or(named(name));
+            }
+        }
+        return junction;
+    }
+
+    @Override
+    public boolean isMatch(TypeDescription typeDescription) {
+        return matchClassNames.contains(typeDescription.getTypeName());
+    }
+
+    public static ClassMatch byMultiClassMath(String... classNames) {","[{'comment': 'byMultiClassMath, `math`, typo I suppose.', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/skywalking/apm/plugin/jdbc/ConnectionServiceMethodInterceptor.java,"@@ -27,15 +27,11 @@
 import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
 import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
-import org.skywalking.apm.util.StringUtil;
 
 /**
- * {@link ConnectionServiceMethodInterceptor} create an exit span when the client call the following methods in the class
- * that extend {@link java.sql.Connection}.
- * 1. close
- * 2. rollback
- * 3. releaseSavepoint
- * 4. commit
+ * {@link ConnectionServiceMethodInterceptor} create an exit span when the client call the following methods in the
+ * class that extend {@link java.sql.Connection}. 1. close 2. rollback 3. releaseSavepoint 4. commit","[{'comment': '* when the following methods execute\r\n* No need of `that extend` words. Just `:`', 'commenter': 'wu-sheng'}]"
562,apm-sniffer/apm-sdk-plugin/mysql-2.x-plugin/src/main/java/org/skywalking/apm/plugin/jdbc/mysql/StatementExecuteMethodsInterceptor.java,"@@ -0,0 +1,78 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.context.ContextManager;
+import org.skywalking.apm.agent.core.context.tag.Tags;
+import org.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.skywalking.apm.plugin.jdbc.mysql.define.StatementEnhanceInfos;
+import org.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+
+/**
+ * {@link StatementExecuteMethodsInterceptor} create the exit span when the client call the interceptor methods.
+ *
+ * @author zhangxin
+ */
+public class StatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        StatementEnhanceInfos cacheObject = (StatementEnhanceInfos)objInst.getSkyWalkingDynamicField();
+        ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+        if (connectInfo != null) {","[{'comment': 'You still miss the comments!!!!', 'commenter': 'wu-sheng'}]"
595,apm-sniffer/apm-sdk-plugin/spring-plugins/core-patch/pom.xml,"@@ -0,0 +1,48 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Copyright 2017, OpenSkywalking Organization All rights reserved.
+  ~
+  ~ Licensed under the Apache License, Version 2.0 (the ""License"");
+  ~ you may not use this file except in compliance with the License.
+  ~ You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  ~ Project repository: https://github.com/OpenSkywalking/skywalking
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>spring-plugins</artifactId>
+        <groupId>org.skywalking</groupId>
+        <version>3.2.5-2017</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-spring-core-patch</artifactId>
+    <name>core-patch</name>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.springframework</groupId>
+            <artifactId>spring-aop</artifactId>
+            <version>3.2.9.RELEASE</version>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.springframework</groupId>
+            <artifactId>spring-aop</artifactId>
+            <version>4.0.0.RELEASE</version>
+            <scope>provided</scope>
+        </dependency>","[{'comment': ""Why do you depend on the same artifactId with different version? What's the purpose?"", 'commenter': 'wu-sheng'}]"
595,apm-sniffer/apm-sdk-plugin/spring-plugins/core-patch/src/main/java/org/skywalking/apm/plugin/spring/patch/CreateAopProxyInterceptor.java,"@@ -0,0 +1,59 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.spring.patch;
+
+import java.lang.reflect.Method;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.springframework.aop.framework.AdvisedSupport;
+
+/**
+ * {@link CreateAopProxyInterceptor} check that the bean has been implement {@link EnhancedInstance}. <p/>
+ * if yes, true will be returned.
+ *
+ * @author zhang xin
+ */
+public class CreateAopProxyInterceptor implements InstanceMethodsAroundInterceptor {
+    private static final String ENHANCE_INSTANCE_INTERFACE_NAME = EnhancedInstance.class.getName();
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        AdvisedSupport advisedSupport = (AdvisedSupport)allArguments[0];
+        Class[] interfaces = advisedSupport.getTargetClass().getInterfaces();","[{'comment': 'You should use `Class#isAssignableFrom` to make sure this class implement the `EnhancedInstance` interface.', 'commenter': 'wu-sheng'}]"
624,apm-sniffer/apm-sdk-plugin/spring-plugins/core-patch/src/main/java/org/skywalking/apm/plugin/spring/patch/AutowiredAnnotationProcessorInterceptor.java,"@@ -0,0 +1,110 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.spring.patch;
+
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+/**
+ * {@link AutowiredAnnotationProcessorInterceptor} return the correct constructor when the bean class is enhanced by
+ * skywalking.
+ *
+ * @author zhangxin
+ */
+public class AutowiredAnnotationProcessorInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        Class<?> beanClass = (Class<?>)allArguments[0];
+        if (EnhancedInstance.class.isAssignableFrom(beanClass)) {
+            Map<Class<?>, Constructor<?>[]> candidateConstructorsCache = (Map<Class<?>, Constructor<?>[]>)objInst.getSkyWalkingDynamicField();
+
+            Constructor<?>[] candidateConstructors = candidateConstructorsCache.get(beanClass);
+            if (candidateConstructors == null) {
+                Constructor<?>[] returnCandidateConstructors = (Constructor<?>[])ret;
+
+                /**
+                 * The return for the method {@link org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor#determineCandidateConstructors(Class, String)
+                 * contains three cases:
+                 * 1. Constructors with annotation {@link org.springframework.beans.factory.annotation.Autowired}
+                 * 2. The bean class only has one constructor with parameters
+                 * 3. The bean has constructor without parameters
+                 *
+                 * The interceptor does the following actions for the above three cases:
+                 * Case 1: Do nothing
+                 * Case 2: All the class that constrcutor enhance by skywalking will cannot in this case. because the manipulate mechanism generates another private constructor
+                 * in the enhance class.
+                 * Case 3: The interceptor fill out the private constructor when the class is enhanced by skywalking, and check if the remainder constructors size is equals one,
+                 * if yes, return the constructor. or return constructor without parameters.","[{'comment': 'I can understand your points reluctantly, but I suggest you put the cases in this way:\r\n\r\n1. What happened in each case after skywalking did the instrument by byte buddy?  Not influence or do the harm in which way.\r\n1. What are the consequences?  \r\n1. What are we going to do in this patch in order to fix?', 'commenter': 'wu-sheng'}]"
624,apm-sniffer/apm-sdk-plugin/spring-plugins/core-patch/src/main/java/org/skywalking/apm/plugin/spring/patch/define/AutowiredAnnotationProcessorInstrumentation.java,"@@ -0,0 +1,79 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.spring.patch.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.any;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link AutowiredAnnotationProcessorInstrumentation} indicate that the spring core patch enhance the method","[{'comment': 'Suggest comments:\r\n\r\n{@link AutowiredAnnotationProcessorInstrumentation} indicates a spring core class patch for making sure the <code>determineCandidateConstructors</code> method, in the class {@link org.springframework.beans.factory.annotation.AutowiredAnnotationBeanPostProcessor} , works in spring designed ways.', 'commenter': 'wu-sheng'}]"
624,apm-sniffer/apm-sdk-plugin/spring-plugins/core-patch/src/main/java/org/skywalking/apm/plugin/spring/patch/AutowiredAnnotationProcessorInterceptor.java,"@@ -0,0 +1,110 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.spring.patch;
+
+import java.lang.reflect.Constructor;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+/**
+ * {@link AutowiredAnnotationProcessorInterceptor} return the correct constructor when the bean class is enhanced by
+ * skywalking.
+ *
+ * @author zhangxin
+ */
+public class AutowiredAnnotationProcessorInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        Class<?> beanClass = (Class<?>)allArguments[0];
+        if (EnhancedInstance.class.isAssignableFrom(beanClass)) {
+            Map<Class<?>, Constructor<?>[]> candidateConstructorsCache = (Map<Class<?>, Constructor<?>[]>)objInst.getSkyWalkingDynamicField();","[{'comment': ""I don't like you do the cached for every class. This costs perm memory, and I am sure Spring will do the cache things. Please check this, don't do the global class cache, unless it is necessary."", 'commenter': 'wu-sheng'}, {'comment': 'I think that the cache object is necessary in this case.  It spend more time to find the constructor when the class has more  bean define in spring framework configuration file or the scope of bean  is not single. ', 'commenter': 'ascrutae'}]"
627,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-3.x-plugin/src/main/java/org/skywalking/apm/plugin/spring/mvc/v3/define/HandlerMethodInvokerInstrumentation.java,"@@ -0,0 +1,67 @@
+/*
+ * Copyright 2017, OpenSkywalking Organization All rights reserved.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ * Project repository: https://github.com/OpenSkywalking/skywalking
+ */
+
+package org.skywalking.apm.plugin.spring.mvc.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+/**
+ * {@link HandlerMethodInvokerInstrumentation} intercept the <code>invokeHandlerMethod</code> method in the
+ * <code>org.springframework.web.bind.annotation.support.HandlerMethodInvoker</code> class.
+ *
+ * @author zhangxin
+ */
+public class HandlerMethodInvokerInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {","[{'comment': ""Why don't extend `AbstractSpring3Instrumentation` for safe?"", 'commenter': 'wu-sheng'}]"
663,apm-sniffer/apm-sdk-plugin/mysql-5.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementExecuteMethodsInterceptor.java,"@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.jdbc.mysql;
+
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.jdbc.define.StatementEnhanceInfos;
+import org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
+
+/**
+ * @author zhang xin
+ */
+public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        StatementEnhanceInfos cacheObject = (StatementEnhanceInfos)objInst.getSkyWalkingDynamicField();
+        ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+        /**
+         * To protected the code occur NullPointException. because mysql execute system sql when constructor method in
+         * {@link com.mysql.jdbc.ConnectionImpl} class executed. but the interceptor set the connection Info after
+         * the constructor method executed.","[{'comment': 'For avoid NPE. In this particular case, execute sql inside the {@link com.mysql.jdbc.ConnectionImpl} constructor, but the interceptor sets the connectionInfo after it.', 'commenter': 'wu-sheng'}]"
683,NOTICE.txt,"@@ -0,0 +1,21 @@
+Apache SkyWalking
+Copyright 2015-2017 The Apache Software Foundation
+
+This product includes software developed by The Apache Software
+Foundation (http://www.apache.org/).
+
+The binary distribution contains software developed by:
+
+raphw (byte-buddy): http://bytebuddy.net/
+INRIA, France Telecom (asm): http://asm.ow2.org/
+Google:
+- grpc: https://grpc.io/
+- guava: https://github.com/google/guava
+- gson: https://github.com/google/gson
+Elasticsearch BV (Elasticsearch): https://www.elastic.co/products/elasticsearch
+H2 Database: http://www.h2database.com/html/main.html
+LMAX Ltd.(disruptor): https://github.com/LMAX-Exchange/disruptor
+mockito: http://site.mockito.org/
+QOS.ch (slf4j): https://www.slf4j.org/
+powermock: https://github.com/powermock/powermock
+Eclipse (Jetty): https://www.eclipse.org/jetty/","[{'comment': 'for each of the dependencies you need to say which license they use.', 'commenter': 'michaelsembwever'}]"
707,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/application-layer.graphqls,"@@ -0,0 +1,37 @@
+# ApplicationNode represents this node is under monitoring by agent.
+type ApplicationNode implements Node {
+    id: ID!
+    name: String!
+    type: String
+    # Success rate of all incoming requests.
+    # Max value is 100.
+    # 2 Digits after floating point.
+    sla: Float!
+    # The number of incoming calls
+    calls: Long!
+    # ref: http://www.apdex.org/
+    # Max value is 1
+    # 2 Digits after floating point.
+    apdex: Float!
+    # The number of servers in the application code
+    numOfServer: Int!
+    # The number of servers alerting
+    numOfServerAlarm: Int!
+    # The number of services alerting
+    numOfServiceAlarm: Int!
+}
+
+# The conjectural node generated by exit span
+type ConjecturalNode implements Node {
+    id: ID!
+    name: String!
+    type: String
+}
+
+
+extend type Query {
+  getAllApplication(duration: Duration!): [ApplicationNode]
+  getApplicationTopology(appId: ID!, duration: Duration!): Topology
+  getSlowService(appId: ID!, duration: Duration!): [DurationItem]","[{'comment': 'The return object name (DurationItem) of this method is an abstractly name. I think SlowService is better suits than DurationItem.', 'commenter': 'peng-yongsheng'}]"
707,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/application-layer.graphqls,"@@ -0,0 +1,37 @@
+# ApplicationNode represents this node is under monitoring by agent.
+type ApplicationNode implements Node {
+    id: ID!
+    name: String!
+    type: String
+    # Success rate of all incoming requests.
+    # Max value is 100.
+    # 2 Digits after floating point.
+    sla: Float!
+    # The number of incoming calls
+    calls: Long!
+    # ref: http://www.apdex.org/
+    # Max value is 1
+    # 2 Digits after floating point.
+    apdex: Float!
+    # The number of servers in the application code
+    numOfServer: Int!
+    # The number of servers alerting
+    numOfServerAlarm: Int!
+    # The number of services alerting
+    numOfServiceAlarm: Int!
+}
+
+# The conjectural node generated by exit span
+type ConjecturalNode implements Node {
+    id: ID!
+    name: String!
+    type: String
+}
+
+
+extend type Query {
+  getAllApplication(duration: Duration!): [ApplicationNode]
+  getApplicationTopology(appId: ID!, duration: Duration!): Topology
+  getSlowService(appId: ID!, duration: Duration!): [DurationItem]
+  getServerThroughput(appId: ID!, duration: Duration!): [ThroughputItem]","[{'comment': 'Ditto. ServerThroughput.', 'commenter': 'peng-yongsheng'}]"
707,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/common.graphqls,"@@ -0,0 +1,100 @@
+schema {
+    query: Query
+}
+
+#Root node
+type Query {
+    version: String
+}
+
+# The Duration defines the start and end time for each query operation.
+# Fields: `start` and `end`
+#   represents the time span. And each of them matches the step.
+#   ref https://www.ietf.org/rfc/rfc3339.txt
+#   The time formats are
+#       `SECOND` step: yyyy-MM-dd HHmmss
+#       `MINUTE` step: yyyy-MM-dd HHmm
+#       `HOUR` step: yyyy-MM-dd HH
+#       `DAY` step: yyyy-MM-dd
+#       `MONTH` step: yyyy-MM
+# Field: `step`
+#   represents the accurate time point.
+# e.g.
+#   if step==HOUR , start=2017-11-08 09, end=2017-11-08 19","[{'comment': 'In the section  of 5.8. Examples of https://www.ietf.org/rfc/rfc3339.txt. \r\n```\r\nHere are some examples of Internet date/time format.\r\n\r\n      1985-04-12T23:20:50.52Z\r\n```\r\nNow, we did not support the time zone. So, 1985-04-12T23:20:50 is better than 2017-11-08 9:00.', 'commenter': 'peng-yongsheng'}, {'comment': 'The specific says:\r\n```\r\nNOTE: ISO 8601 defines date and time separated by ""T"".\r\n      Applications using this syntax may choose, for the sake of\r\n      readability, to specify a full-date and full-time separated by\r\n      (say) a space character.\r\n```\r\n\r\nI assume the \' \'(whitespace) is OK.', 'commenter': 'wu-sheng'}, {'comment': 'I prefer to use ""T"" for separated character', 'commenter': 'hanahmily'}, {'comment': ""In my perspective, **T** is not a tradition. We never use this char in Java application, when we need to format a time. So I want to keep it in that way. @peng-yongsheng argues with this, because he miss the `NOTE`.\r\n\r\nSo, let's keep the time format, OK?"", 'commenter': 'wu-sheng'}, {'comment': 'OK', 'commenter': 'peng-yongsheng'}]"
707,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/overview-layer.graphqls,"@@ -0,0 +1,37 @@
+# Query the cluster brief based on the given duration
+type ClusterBrief {
+    numOfApplication: Int
+    numOfService: Int
+    numOfDatabase: Int
+    numOfCache: Int
+    numOfMQ: Int
+}
+
+# Query the trend of alarm rate based on the given duration
+type AlarmTrend {
+    numOfAlarmRate: [Int]!
+}
+
+# Query all conjectural applications based on the given duration
+# All applications here are not installed agent.
+type ConjecturalAppBrief {
+    apps: [ConjecturalApp!]
+}
+
+# The basic info of the conjectural application,
+# includes the type and num of same type application
+type ConjecturalApp {
+    # The display name of the application
+    # e.g. MySQL, RocketMQ, Kafka, Nginx
+    name: String!
+    num: Int!
+}
+
+extend type Query {
+    getClusterTopology(duration: Duration!): Topology","[{'comment': 'Topology changed to ApplicationTopology. Topology to be a abstract object.', 'commenter': 'peng-yongsheng'}, {'comment': '@peng-yongsheng I prefer to keep the `Topology`. The inheritance happens in Node, rather than Topology type.', 'commenter': 'wu-sheng'}, {'comment': ' I agree with @wu-sheng', 'commenter': 'hanahmily'}]"
707,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/application-layer.graphqls,"@@ -0,0 +1,37 @@
+# ApplicationNode represents this node is under monitoring by agent.
+type ApplicationNode implements Node {
+    id: ID!
+    name: String!
+    type: String
+    # Success rate of all incoming requests.
+    # Max value is 100.
+    # 2 Digits after floating point.
+    sla: Float!
+    # The number of incoming calls
+    calls: Long!
+    # ref: http://www.apdex.org/
+    # Max value is 1
+    # 2 Digits after floating point.
+    apdex: Float!
+    # The number of servers in the application code
+    numOfServer: Int!
+    # The number of servers alerting
+    numOfServerAlarm: Int!
+    # The number of services alerting
+    numOfServiceAlarm: Int!
+}
+
+# The conjectural node generated by exit span
+type ConjecturalNode implements Node {
+    id: ID!
+    name: String!
+    type: String
+}
+
+
+extend type Query {
+  getAllApplication(duration: Duration!): [ApplicationNode]
+  getApplicationTopology(appId: ID!, duration: Duration!): Topology","[{'comment': 'applicationId is better than appId.', 'commenter': 'peng-yongsheng'}, {'comment': '+1', 'commenter': 'hanahmily'}]"
707,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/README.md,"@@ -0,0 +1,34 @@
+# Abstract
+**apm-ui-protocol** declares all services, using GraphQL API style, which provide by Collector UI module.
+
+## Services
+### [Common](common.graphqls)
+
+Include common objects, which used in global
+
+### [Overview Layer Service](overview-layer.graphqls)
+
+Query data without specific application, server or service. It includes info for overview the whole cluster.
+
+### [Application Layer Service](application-layer.graphqls)
+
+Query application related data with specific application code.
+
+### [Server Layer Service](server-layer.graphqls)
+
+Query server related data with specific server id.
+
+### [Service Layer Service](service-layer.graphqls)
+
+Query service related data with specific service id
+
+### [Trace Service](trace.graphqls)
+
+Query trace by some conditions.
+
+### [Alarm Service](alarm.graphqls)
+
+Query alarm info.
+
+## Version
+1.0-alpha","[{'comment': 'With reference to [REST API Versioning](https://restfulapi.net/versioning/) , I prefer to use `v1alpha` ', 'commenter': 'hanahmily'}, {'comment': '@hanahmily Can you address the directly link? or provide a screenshot?', 'commenter': 'wu-sheng'}, {'comment': 'For instance `http://collector.host/graphql/v1alpha/`,`http://collector.host/graphql/v1alpha1/`,`http://collector.host/graphql/v1beta/`,`http://collector.host/graphql/v1beta2/`,`http://collector.host/graphql/v1/`', 'commenter': 'hanahmily'}, {'comment': '@hanahmily The **REST API Versioning** document provides nothing about how to version.\r\n\r\n![image](https://user-images.githubusercontent.com/5441976/34454420-15463f42-eda6-11e7-9bd5-9e25e2fb18ba.png)\r\n\r\n', 'commenter': 'wu-sheng'}, {'comment': 'For the `*.graphqls` file name format ,I prefer to use [k8s style](https://github.com/kubernetes/kubernetes/tree/master/api/swagger-spec) @wu-sheng ', 'commenter': 'hanahmily'}]"
709,apm-sniffer/apm-sdk-plugin/okhttp-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/okhttp/v3/EnqueueInterceptor.java,"@@ -18,54 +18,32 @@
 
 package org.apache.skywalking.apm.plugin.okhttp.v3;
 
-import java.lang.reflect.Field;
 import java.lang.reflect.Method;
-import java.lang.reflect.Modifier;
-import okhttp3.Headers;
-import okhttp3.HttpUrl;
 import okhttp3.Request;
-import org.apache.skywalking.apm.agent.core.context.CarrierItem;
-import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
 import org.apache.skywalking.apm.agent.core.context.ContextManager;
-import org.apache.skywalking.apm.agent.core.context.tag.Tags;
-import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
-import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
-import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
 
 public class EnqueueInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
     @Override
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
         MethodInterceptResult result) throws Throwable {
-
+        EnhancedInstance callbackInstance = (EnhancedInstance)allArguments[0];
         Request request = (Request)objInst.getSkyWalkingDynamicField();
+        ContextManager.createLocalSpan(""Async"" + request.url().uri().getPath());
 
-        ContextCarrier contextCarrier = new ContextCarrier();
-        HttpUrl requestUrl = request.url();
-        AbstractSpan span = ContextManager.createExitSpan(requestUrl.uri().getPath(), contextCarrier, requestUrl.host() + "":"" + requestUrl.port());
-        span.setComponent(ComponentsDefine.OKHTTP);
-        Tags.HTTP.METHOD.set(span, request.method());
-        Tags.URL.set(span, requestUrl.uri().toString());
-        SpanLayer.asHttp(span);
-
-        Field headersField = Request.class.getDeclaredField(""headers"");
-        Field modifiersField = Field.class.getDeclaredField(""modifiers"");
-        modifiersField.setAccessible(true);
-        modifiersField.setInt(headersField, headersField.getModifiers() & ~Modifier.FINAL);
-
-        headersField.setAccessible(true);
-        Headers.Builder headerBuilder = request.headers().newBuilder();
-        CarrierItem next = contextCarrier.items();
-        while (next.hasNext()) {
-            next = next.next();
-            headerBuilder.add(next.getHeadKey(), next.getHeadValue());
-        }
-        headersField.set(request, headerBuilder.build());
+        /**
+         * Here is the process how to buried the point of async function.","[{'comment': 'Change the comments to:\r\n*  Here is the process about how to trace the async function.', 'commenter': 'wu-sheng'}]"
709,apm-sniffer/apm-sdk-plugin/okhttp-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/okhttp/v3/EnqueueInterceptor.java,"@@ -18,54 +18,32 @@
 
 package org.apache.skywalking.apm.plugin.okhttp.v3;
 
-import java.lang.reflect.Field;
 import java.lang.reflect.Method;
-import java.lang.reflect.Modifier;
-import okhttp3.Headers;
-import okhttp3.HttpUrl;
 import okhttp3.Request;
-import org.apache.skywalking.apm.agent.core.context.CarrierItem;
-import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
 import org.apache.skywalking.apm.agent.core.context.ContextManager;
-import org.apache.skywalking.apm.agent.core.context.tag.Tags;
-import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
-import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
-import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
 
 public class EnqueueInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
     @Override
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
         MethodInterceptResult result) throws Throwable {
-
+        EnhancedInstance callbackInstance = (EnhancedInstance)allArguments[0];
         Request request = (Request)objInst.getSkyWalkingDynamicField();
+        ContextManager.createLocalSpan(""Async"" + request.url().uri().getPath());
 
-        ContextCarrier contextCarrier = new ContextCarrier();
-        HttpUrl requestUrl = request.url();
-        AbstractSpan span = ContextManager.createExitSpan(requestUrl.uri().getPath(), contextCarrier, requestUrl.host() + "":"" + requestUrl.port());
-        span.setComponent(ComponentsDefine.OKHTTP);
-        Tags.HTTP.METHOD.set(span, request.method());
-        Tags.URL.set(span, requestUrl.uri().toString());
-        SpanLayer.asHttp(span);
-
-        Field headersField = Request.class.getDeclaredField(""headers"");
-        Field modifiersField = Field.class.getDeclaredField(""modifiers"");
-        modifiersField.setAccessible(true);
-        modifiersField.setInt(headersField, headersField.getModifiers() & ~Modifier.FINAL);
-
-        headersField.setAccessible(true);
-        Headers.Builder headerBuilder = request.headers().newBuilder();
-        CarrierItem next = contextCarrier.items();
-        while (next.hasNext()) {
-            next = next.next();
-            headerBuilder.add(next.getHeadKey(), next.getHeadValue());
-        }
-        headersField.set(request, headerBuilder.build());
+        /**
+         * Here is the process how to buried the point of async function.
+         *
+         * 1. Storage `Request` object into `RealCall` instance when the constructor of `RealCall` called.
+         * 2. Put the `RealCall` instance to `CallBack` instance
+         * 3. Get the `RealCall` instance into `AsyncCall` instance when the constructor of `RealCall` called.","[{'comment': 'Put or Get?', 'commenter': 'wu-sheng'}]"
709,apm-sniffer/apm-sdk-plugin/okhttp-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/okhttp/v3/EnqueueInterceptor.java,"@@ -18,54 +18,32 @@
 
 package org.apache.skywalking.apm.plugin.okhttp.v3;
 
-import java.lang.reflect.Field;
 import java.lang.reflect.Method;
-import java.lang.reflect.Modifier;
-import okhttp3.Headers;
-import okhttp3.HttpUrl;
 import okhttp3.Request;
-import org.apache.skywalking.apm.agent.core.context.CarrierItem;
-import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
 import org.apache.skywalking.apm.agent.core.context.ContextManager;
-import org.apache.skywalking.apm.agent.core.context.tag.Tags;
-import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
-import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
-import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
 
 public class EnqueueInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
     @Override
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
         MethodInterceptResult result) throws Throwable {
-
+        EnhancedInstance callbackInstance = (EnhancedInstance)allArguments[0];
         Request request = (Request)objInst.getSkyWalkingDynamicField();
+        ContextManager.createLocalSpan(""Async"" + request.url().uri().getPath());
 
-        ContextCarrier contextCarrier = new ContextCarrier();
-        HttpUrl requestUrl = request.url();
-        AbstractSpan span = ContextManager.createExitSpan(requestUrl.uri().getPath(), contextCarrier, requestUrl.host() + "":"" + requestUrl.port());
-        span.setComponent(ComponentsDefine.OKHTTP);
-        Tags.HTTP.METHOD.set(span, request.method());
-        Tags.URL.set(span, requestUrl.uri().toString());
-        SpanLayer.asHttp(span);
-
-        Field headersField = Request.class.getDeclaredField(""headers"");
-        Field modifiersField = Field.class.getDeclaredField(""modifiers"");
-        modifiersField.setAccessible(true);
-        modifiersField.setInt(headersField, headersField.getModifiers() & ~Modifier.FINAL);
-
-        headersField.setAccessible(true);
-        Headers.Builder headerBuilder = request.headers().newBuilder();
-        CarrierItem next = contextCarrier.items();
-        while (next.hasNext()) {
-            next = next.next();
-            headerBuilder.add(next.getHeadKey(), next.getHeadValue());
-        }
-        headersField.set(request, headerBuilder.build());
+        /**
+         * Here is the process how to buried the point of async function.
+         *
+         * 1. Storage `Request` object into `RealCall` instance when the constructor of `RealCall` called.
+         * 2. Put the `RealCall` instance to `CallBack` instance
+         * 3. Get the `RealCall` instance into `AsyncCall` instance when the constructor of `RealCall` called.
+         * 4. Create the exist span by using the `RealCall` instance when `AsyncCall` method called.","[{'comment': '`exitst` -> `exit`', 'commenter': 'wu-sheng'}]"
732,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/application-layer.graphqls,"@@ -35,6 +34,6 @@ type ConjecturalNode implements Node {
 extend type Query {
   getAllApplication(duration: Duration!): [ApplicationNode]
   getApplicationTopology(applicationId: ID!, duration: Duration!): Topology
-  getSlowService(applicationId: ID!, duration: Duration!): [ServiceInfo!]
-  getServerThroughput(applicationId: ID!, duration: Duration!): [AppServerInfo!]
+  getSlowService(applicationId: ID!, duration: Duration, top: Int!): [ServiceInfo!]","[{'comment': 'The parameter of duration must contains value.', 'commenter': 'peng-yongsheng'}]"
732,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/alarm.graphqls,"@@ -10,6 +15,11 @@ enum AlarmType {
     SERVICE
 }
 
+enum CauseType {
+    LOW_SUCCESS_RATE,
+    SLOW_RESPONSE
+}
+
 extend type Query {
-    loadAlertList(keyword: String, alertType: AlarmType, duration:Duration!):[AlarmItem]
+    loadAlertList(keyword: String, alertType: AlarmType, duration:Duration!, paging: Pagination!):[AlarmItem!]!","[{'comment': 'The parameter in this method contains paging, but no count parameter in return object.', 'commenter': 'peng-yongsheng'}]"
732,apm-protocol/apm-ui-protocol/src/main/resources/ui-graphql/application-layer.graphqls,"@@ -19,9 +21,6 @@ type ApplicationNode implements Node {
     numOfServerAlarm: Int!","[{'comment': ""Adding 'isAlarm' property that represents application alarm."", 'commenter': 'hanahmily'}, {'comment': '@hanahmily Done.', 'commenter': 'wu-sheng'}]"
738,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/EnhanceRequireObjectCache.java,"@@ -18,25 +18,26 @@
 
 package org.apache.skywalking.apm.plugin.spring.mvc.commons;
 
-import java.lang.reflect.Method;
-import javax.servlet.http.HttpServletResponse;
 import org.springframework.web.context.request.NativeWebRequest;
 
+import javax.servlet.http.HttpServletResponse;
+import java.lang.reflect.Method;
+
 public class EnhanceRequireObjectCache {
     private PathMappingCache pathMappingCache;
-    private NativeWebRequest nativeWebRequest;
-    private HttpServletResponse httpResponse;
+    private ThreadLocal<NativeWebRequest> nativeWebRequest = new ThreadLocal<NativeWebRequest>();
+    private ThreadLocal<HttpServletResponse> httpResponse = new ThreadLocal<HttpServletResponse>();
 
     public void setPathMappingCache(PathMappingCache pathMappingCache) {
         this.pathMappingCache = pathMappingCache;
     }
 
     public HttpServletResponse getHttpServletResponse() {
-        return httpResponse == null ? (HttpServletResponse)nativeWebRequest.getNativeResponse() : httpResponse;
+        return httpResponse.get() == null ? (HttpServletResponse) nativeWebRequest.get().getNativeResponse() : httpResponse.get();","[{'comment': 'You should clear the two `ThreadLocal`s after the get operation.', 'commenter': 'wu-sheng'}, {'comment': 'done 。', 'commenter': 'YunaiV'}]"
738,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/EnhanceRequireObjectCache.java,"@@ -52,10 +53,11 @@ public PathMappingCache getPathMappingCache() {
     }
 
     public void setHttpResponse(HttpServletResponse httpResponse) {
-        this.httpResponse = httpResponse;
+        this.httpResponse.set(httpResponse);
     }
 
     public HttpServletResponse getHttpResponse() {","[{'comment': 'This method is never used. Recommend remove it.', 'commenter': 'wu-sheng'}]"
738,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/interceptor/AbstractMethodInteceptor.java,"@@ -80,6 +81,8 @@ public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allA
             Tags.STATUS_CODE.set(span, Integer.toString(response.getStatus()));
         }
         ContextManager.stopSpan();
+
+        ((EnhanceRequireObjectCache)objInst.getSkyWalkingDynamicField()).setNativeWebRequest(null);","[{'comment': 'I think that you should add some comment so that anyone can understand it', 'commenter': 'ascrutae'}]"
738,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/interceptor/InvokeHandlerMethodInterceptor.java,"@@ -37,11 +38,13 @@ public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allAr
     @Override
     public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
         Object ret) throws Throwable {
+        if (allArguments[2] instanceof EnhancedInstance) {","[{'comment': 'I think that you should add some comment so that anyone can understand it', 'commenter': 'ascrutae'}]"
770,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/connectionurl/parser/URLParser.java,"@@ -29,22 +33,36 @@
  */
 public class URLParser {
 
-    private static final String MYSQL_JDBC_URL_PREFIX = ""jdbc:mysql"";
-    private static final String ORACLE_JDBC_URL_PREFIX = ""jdbc:oracle"";
-    private static final String H2_JDBC_URL_PREFIX = ""jdbc:h2"";
-    private static final String POSTGRESQL_JDBC_URL_PREFIX = ""jdbc:postgresql"";
+    private static ServiceLoader<ConnectionURLParser> JDBCPARSERS
+        = ServiceLoader.load(ConnectionURLParser.class, URLParser.class
+        .getClassLoader());","[{'comment': ""I have concern about using ServiceLoader by `URLParser.class.getClassLoader()`. I think this didn't work in real world. Because the parser implementations, including service define files are in plugin-*.jar, which can't access by any default or webapp classloader.\r\n\r\nI think the only way is using ClassLoader from `AgentClassLoader#getDefault` could work."", 'commenter': 'wu-sheng'}, {'comment': 'At the same time, I prefer init `JDBCPARSERS` used in `#parser` method at the first time.', 'commenter': 'wu-sheng'}, {'comment': '@ascrutae For safe, please run auto tests ( at least DB, Spring and Tomcat related ) to make sure this pr would break the whole database plugin system.', 'commenter': 'wu-sheng'}, {'comment': 'I use a standalone java app with the agent to test and if I use `AgentClassLoader#getDefault` it will result loading a URLparser implementation which is not compatible with URLParser', 'commenter': 'zone1511'}, {'comment': 'what is your meaning? can you provide more details?', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/ProducerOperationHandlerInterceptor.java,"@@ -48,16 +48,28 @@ public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allAr
             next = next.next();
             next.setHeadValue(invocation.getContext().get(next.getHeadKey()));
         }
+        if (null == invocation.getOperationMeta()) {
+            return;
+        }
         String operationName = invocation.getMicroserviceQualifiedName();
         AbstractSpan span = ContextManager.createEntrySpan(operationName, contextCarrier);
-        String url = invocation.getOperationMeta().getOperationPath();
-        Tags.URL.set(span, url);
+        if (null != invocation.getOperationMeta() && null != invocation.getOperationMeta().getOperationPath()) {","[{'comment': '`(null == invocation.getOperationMeta()` has been invoked in line 51.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/ProducerOperationHandlerInterceptor.java,"@@ -48,16 +48,28 @@ public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allAr
             next = next.next();
             next.setHeadValue(invocation.getContext().get(next.getHeadKey()));
         }
+        if (null == invocation.getOperationMeta()) {
+            return;
+        }
         String operationName = invocation.getMicroserviceQualifiedName();
         AbstractSpan span = ContextManager.createEntrySpan(operationName, contextCarrier);
-        String url = invocation.getOperationMeta().getOperationPath();
-        Tags.URL.set(span, url);
+        if (null != invocation.getOperationMeta() && null != invocation.getOperationMeta().getOperationPath()) {
+            String url = invocation.getOperationMeta().getOperationPath();
+            Tags.URL.set(span, url);
+        }
         span.setComponent(ComponentsDefine.SERVICECOMB);
         SpanLayer.asRPCFramework(span);
     }
 
     @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
         Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];","[{'comment': ""If NO span  created, you can't guarantee active span exists."", 'commenter': 'wu-sheng'}, {'comment': ""And stop span can't be expected."", 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/TransportClientHandlerInterceptor.java,"@@ -43,10 +43,14 @@
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
         Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
         Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {","[{'comment': 'You should adjust stop span ,too.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/ProducerOperationHandlerInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {org.apache.skywalking.apm.plugin.servicecomb.} define how to enhance class {@link Invocation#getHandlerContext()}.
+ *
+ * @author lytscu
+ */
+public class ProducerOperationHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        ContextCarrier contextCarrier = new ContextCarrier();
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            next.setHeadValue(invocation.getContext().get(next.getHeadKey()));
+        }
+        if (null == invocation.getOperationMeta()) {","[{'comment': 'When does Producer side face `null == invocation.getOperationMeta()`? Entry span requires nothing additional. You could create EntrySpan every time.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/ProducerOperationHandlerInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {org.apache.skywalking.apm.plugin.servicecomb.} define how to enhance class {@link Invocation#getHandlerContext()}.
+ *
+ * @author lytscu
+ */
+public class ProducerOperationHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        ContextCarrier contextCarrier = new ContextCarrier();
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            next.setHeadValue(invocation.getContext().get(next.getHeadKey()));
+        }
+        if (null == invocation.getOperationMeta()) {
+            return;
+        }
+        String operationName = invocation.getMicroserviceQualifiedName();
+        AbstractSpan span = ContextManager.createEntrySpan(operationName, contextCarrier);
+        String url = invocation.getOperationMeta().getOperationPath();
+        Tags.URL.set(span, url);
+        span.setComponent(ComponentsDefine.SERVICECOMB);
+        SpanLayer.asRPCFramework(span);
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta()) {","[{'comment': 'When does Producer side face null == invocation.getOperationMeta()? Entry span requires nothing additional. You could create EntrySpan every time.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/TransportClientHandlerInterceptor.java,"@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import java.net.URI;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {@link TransportClientHandlerInterceptor} define how to enhance class {@link Invocation#next(io.servicecomb.swagger.invocation.AsyncResponse)}.
+ *
+ * @author lytscu
+ */
+public class TransportClientHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {","[{'comment': '`if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {` should be in a separated method.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/TransportClientHandlerInterceptor.java,"@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import java.net.URI;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {@link TransportClientHandlerInterceptor} define how to enhance class {@link Invocation#next(io.servicecomb.swagger.invocation.AsyncResponse)}.
+ *
+ * @author lytscu
+ */
+public class TransportClientHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {
+            return;
+        }
+        URI uri = new URI(invocation.getEndpoint().toString());
+        String peer = uri.getHost() + "":"" + uri.getPort();
+        String operationName = invocation.getMicroserviceQualifiedName();
+        final ContextCarrier contextCarrier = new ContextCarrier();
+        AbstractSpan span = ContextManager.createExitSpan(operationName, contextCarrier, peer);
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            invocation.getContext().put(next.getHeadKey(), next.getHeadValue());
+        }
+        String url = invocation.getOperationMeta().getOperationPath();
+        Tags.URL.set(span, url);
+        span.setComponent(ComponentsDefine.SERVICECOMB);
+        SpanLayer.asRPCFramework(span);
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {
+            return ret;
+        }
+        AbstractSpan span = ContextManager.activeSpan();
+        int statusCode = invocation.getStatus().getStatusCode();
+        if (statusCode >= 400) {
+            span.errorOccurred();
+            Tags.STATUS_CODE.set(span, Integer.toString(statusCode));
+        }
+        ContextManager.stopSpan();
+
+        return ret;
+    }
+
+    @Override public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+        AbstractSpan span = ContextManager.activeSpan();","[{'comment': '`#active` is not safe in exception handling, also need the `if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {`', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/TransportClientHandlerInterceptor.java,"@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import java.net.URI;
+import java.net.URISyntaxException;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {@link TransportClientHandlerInterceptor} define how to enhance class {@link Invocation#next(io.servicecomb.swagger.invocation.AsyncResponse)}.
+ *
+ * @author lytscu
+ */
+public class TransportClientHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        String peer = AsserRegister(invocation);
+        if (null == peer) {
+            return;
+        }
+        String operationName = invocation.getMicroserviceQualifiedName();
+        final ContextCarrier contextCarrier = new ContextCarrier();
+        AbstractSpan span = ContextManager.createExitSpan(operationName, contextCarrier, peer);
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            invocation.getContext().put(next.getHeadKey(), next.getHeadValue());
+        }
+        String url = invocation.getOperationMeta().getOperationPath();
+        Tags.URL.set(span, url);
+        span.setComponent(ComponentsDefine.SERVICECOMB);
+        SpanLayer.asRPCFramework(span);
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        String peer = AsserRegister(invocation);
+        if (null == peer) {
+            return ret;
+        }
+        AbstractSpan span = ContextManager.activeSpan();
+        int statusCode = invocation.getStatus().getStatusCode();
+        if (statusCode >= 400) {
+            span.errorOccurred();
+            Tags.STATUS_CODE.set(span, Integer.toString(statusCode));
+        }
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+        Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {
+            return;
+        }
+        AbstractSpan span = ContextManager.activeSpan();
+        span.errorOccurred();
+        span.log(t);
+    }
+
+    /**
+     * Serviecomb chissis Consumers and providers need to register at the service center. If the consumer is not","[{'comment': '`chissis` change to `chassis`', 'commenter': 'ascrutae'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/ProducerOperationHandlerInterceptor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {org.apache.skywalking.apm.plugin.servicecomb.} define how to enhance class {@link Invocation#getHandlerContext()}.","[{'comment': 'The comments is incorrect, please adjust it', 'commenter': 'ascrutae'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/ProducerOperationHandlerInterceptor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {org.apache.skywalking.apm.plugin.servicecomb.} define how to enhance class {@link Invocation#getHandlerContext()}.
+ *
+ * @author lytscu
+ */
+public class ProducerOperationHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        ContextCarrier contextCarrier = new ContextCarrier();
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            next.setHeadValue(invocation.getContext().get(next.getHeadKey()));
+        }
+        String operationName = ""servicecomb/chassis"" + method.getName();","[{'comment': 'Default name should be `className` + `methodName`, and only execute in `else`.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/TransportClientHandlerInterceptor.java,"@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import java.net.URI;
+import java.net.URISyntaxException;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {@link TransportClientHandlerInterceptor} define how to enhance class {@link Invocation#next(io.servicecomb.swagger.invocation.AsyncResponse)}.
+ *
+ * @author lytscu
+ */
+public class TransportClientHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        String peer = AsserRegister(invocation);","[{'comment': 'Why does a method start up an upper case char?', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/TransportClientHandlerInterceptor.java,"@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb;
+
+import io.servicecomb.core.Invocation;
+import java.lang.reflect.Method;
+import java.net.URI;
+import java.net.URISyntaxException;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {@link TransportClientHandlerInterceptor} define how to enhance class {@link Invocation#next(io.servicecomb.swagger.invocation.AsyncResponse)}.
+ *
+ * @author lytscu
+ */
+public class TransportClientHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        String peer = AsserRegister(invocation);
+        if (null == peer) {
+            return;
+        }
+        String operationName = invocation.getMicroserviceQualifiedName();
+        final ContextCarrier contextCarrier = new ContextCarrier();
+        AbstractSpan span = ContextManager.createExitSpan(operationName, contextCarrier, peer);
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            invocation.getContext().put(next.getHeadKey(), next.getHeadValue());
+        }
+        String url = invocation.getOperationMeta().getOperationPath();
+        Tags.URL.set(span, url);
+        span.setComponent(ComponentsDefine.SERVICECOMB);
+        SpanLayer.asRPCFramework(span);
+    }
+
+    @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        Invocation invocation = (Invocation)allArguments[0];
+        String peer = AsserRegister(invocation);
+        if (null == peer) {
+            return ret;
+        }
+        AbstractSpan span = ContextManager.activeSpan();
+        int statusCode = invocation.getStatus().getStatusCode();
+        if (statusCode >= 400) {
+            span.errorOccurred();
+            Tags.STATUS_CODE.set(span, Integer.toString(statusCode));
+        }
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+        Invocation invocation = (Invocation)allArguments[0];
+        if (null == invocation.getOperationMeta() || null == invocation.getEndpoint()) {
+            return;
+        }
+        AbstractSpan span = ContextManager.activeSpan();
+        span.errorOccurred();
+        span.log(t);
+    }
+
+    /**
+     * Serviecomb chissis Consumers and providers need to register at the service center. If the consumer is not
+     * registered then return
+     */
+    private String AsserRegister(Invocation invocation) throws URISyntaxException {","[{'comment': 'You misunderstand what I mean about this method. This method should be `#checkRegisterStatus` and return true/false. The method will make the codes more clear.', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/define/TransportClientHandlerInstrumentation.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb.define;
+
+import io.servicecomb.core.handler.impl.TransportClientHandler;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.agent.core.plugin.match.NameMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+
+/**
+ * {@link TransportClientHandlerInstrumentation} presents that skywalking intercept {@link TransportClientHandler}by","[{'comment': '`presents` to `represents`', 'commenter': 'wu-sheng'}]"
771,apm-sniffer/apm-sdk-plugin/servicecomb-plugin/servicecomb-java-chassis-0.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/servicecomb/define/ProducerOperationHandlerInstrumentation.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.servicecomb.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.agent.core.plugin.match.NameMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+
+/**
+ * {@link ProducerOperationHandlerInstrumentation} presents that skywalking intercept {@link","[{'comment': '`represents` to `represents`', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/KafkaConsumerInterceptor.java,"@@ -0,0 +1,94 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11;
+
+import java.lang.reflect.Method;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import org.apache.kafka.clients.consumer.ConsumerRecord;
+import org.apache.kafka.common.TopicPartition;
+import org.apache.kafka.common.header.Header;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * @autor zhang xin
+ */
+public class KafkaConsumerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Kafka/"";
+    public static final String CONSUMER_OPERATE_NAME_SUFFIX = ""/Consumer"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo)objInst.getSkyWalkingDynamicField();
+        requiredInfo.setStartTime(System.currentTimeMillis());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        Map<TopicPartition, List<ConsumerRecord<?, ?>>> records = (Map<TopicPartition, List<ConsumerRecord<?, ?>>>)ret;
+        //
+        // The entry span will create when the consumer fetch anyone message from kafka cluster, or the span will not create.","[{'comment': 'Change comments to:\r\n> The entry span will only be created when the consumer received at least one message.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/KafkaProducerInterceptor.java,"@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11;
+
+import java.lang.reflect.Method;
+import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * @author zhang xin
+ */
+public class KafkaProducerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Kafka/"";
+    public static final String PRODUCER_OPERATE_NAME_SUFFIX = ""/Producer"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+        ContextCarrier contextCarrier = new ContextCarrier();
+
+        ProducerRecord record = (ProducerRecord)allArguments[0];
+        String topicName = (String)((EnhancedInstance)record).getSkyWalkingDynamicField();
+
+        AbstractSpan activeSpan = ContextManager.createExitSpan(OPERATE_NAME_PREFIX + topicName + PRODUCER_OPERATE_NAME_SUFFIX, contextCarrier, (String)objInst.getSkyWalkingDynamicField());
+
+        //set tags","[{'comment': 'Please remove these meaningless comments.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/KafkaProducerInterceptor.java,"@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11;
+
+import java.lang.reflect.Method;
+import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * @author zhang xin
+ */
+public class KafkaProducerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Kafka/"";
+    public static final String PRODUCER_OPERATE_NAME_SUFFIX = ""/Producer"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+
+        ContextCarrier contextCarrier = new ContextCarrier();
+
+        ProducerRecord record = (ProducerRecord)allArguments[0];
+        String topicName = (String)((EnhancedInstance)record).getSkyWalkingDynamicField();
+
+        AbstractSpan activeSpan = ContextManager.createExitSpan(OPERATE_NAME_PREFIX + topicName + PRODUCER_OPERATE_NAME_SUFFIX, contextCarrier, (String)objInst.getSkyWalkingDynamicField());
+
+        //set tags
+        Tags.MQ_BROKER.set(activeSpan, (String)objInst.getSkyWalkingDynamicField());
+        Tags.MQ_TOPIC.set(activeSpan, topicName);
+        SpanLayer.asMQ(activeSpan);
+        activeSpan.setComponent(ComponentsDefine.KAFKA);
+
+        // set headers","[{'comment': 'Same story, no need.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/ProducerConstructorInterceptor.java,"@@ -0,0 +1,33 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11;
+
+import org.apache.kafka.clients.producer.ProducerConfig;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.util.StringUtil;
+
+public class ProducerConstructorInterceptor implements InstanceConstructorInterceptor {
+
+    @Override public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        ProducerConfig config = (ProducerConfig)allArguments[0];
+        // set the bootstrap server address","[{'comment': 'The comments are exact same as codes.', 'commenter': 'wu-sheng'}, {'comment': 'No need either.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/ProducerRecordConstructorInterceptor.java,"@@ -0,0 +1,30 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11;
+
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class ProducerRecordConstructorInterceptor implements InstanceConstructorInterceptor {
+    @Override public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        String topic = (String)allArguments[0];
+        // set the topic","[{'comment': '`Topic` already is the variable name.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaConsumerInstrumentation.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class","[{'comment': ""*Instrument didn't intercept anything.They just define interceptors."", 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/CallbackInstrumentation.java,"@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.match.HierarchyMatch.byHierarchyMatch;
+
+/**
+ * {@link CallbackInstrumentation} intercept the method onCompletion in the class <code>org.apache.kafka.clients.producer.Callback</code>.","[{'comment': ""*Instrument didn't intercept anything.They just define interceptors."", 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaConsumerInstrumentation.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the topic when the client call <code>subscribed</code>","[{'comment': 'Is `subscribed` a method? If so, should `xxxx invoked`.', 'commenter': 'wu-sheng'}, {'comment': 'And where is No **2**?', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaConsumerInstrumentation.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the topic when the client call <code>subscribed</code>
+ *  3. Create the entry span when the client call the method <code>pollOnce</code>.","[{'comment': 'Same as ^^^', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaConsumerInstrumentation.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the topic when the client call <code>subscribed</code>
+ *  3. Create the entry span when the client call the method <code>pollOnce</code>.
+ *  4. Inject all the <code>Trace Context</code> by iterate all <code>ConsumerRecord</code>
+ *  5. Stop the entry span when end the <code>pollOnce</code> method.","[{'comment': 'when `pollOnce` method finish.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaConsumerInstrumentation.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the topic when the client call <code>subscribed</code>
+ *  3. Create the entry span when the client call the method <code>pollOnce</code>.
+ *  4. Inject all the <code>Trace Context</code> by iterate all <code>ConsumerRecord</code>","[{'comment': 'At consumer side, I think should extract context from the messages.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaConsumerInstrumentation.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the topic when the client call <code>subscribed</code>
+ *  3. Create the entry span when the client call the method <code>pollOnce</code>.
+ *  4. Inject all the <code>Trace Context</code> by iterate all <code>ConsumerRecord</code>
+ *  5. Stop the entry span when end the <code>pollOnce</code> method.
+ * </pre>
+ *
+ * @author zhang xin
+ */
+public class KafkaConsumerInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    public static final String CONSTRUCTOR_INTERCEPT_FLAG = ""org.apache.kafka.clients.consumer.ConsumerConfig"";
+    public static final String CONSTRUCTOR_INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.kafka.v11.ConsumerConstructorInterceptor"";
+    public static final String INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.kafka.v11.KafkaConsumerInterceptor"";
+    public static final String ENHANCE_METHOD = ""pollOnce"";
+    public static final String ENHANCE_CLASS = ""org.apache.kafka.clients.consumer.KafkaConsumer"";
+    public static final String SUBSCRIBE_METHOD = ""subscribe"";
+    public static final String SUBSCRIBE_INTERCEPT_FLAG = ""org.apache.kafka.clients.consumer.ConsumerRebalanceListener"";","[{'comment': 'Why a listener is a flag?', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaProducerInstrumentation.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the broker address when the client create the <code>org.apache.kafka.clients.producer.KafkaProducer</code>
+ * instance
+ *  2. Fetch the topic name from <code>org.apache.kafka.clients.producer.ProducerRecord</code> when the client call","[{'comment': ""Same, don't say, client call method. The method is inside the client. Method should be invoked."", 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaProducerInstrumentation.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the broker address when the client create the <code>org.apache.kafka.clients.producer.KafkaProducer</code>
+ * instance
+ *  2. Fetch the topic name from <code>org.apache.kafka.clients.producer.ProducerRecord</code> when the client call
+ * <code>send</code> method.
+ *  3. Create the exit span when the client call <code>send</code> method
+ *  4. Set the <code>Context</code> into the <code>org.apache.kafka.clients.producer.ProducerRecord#headers</code>","[{'comment': 'At here, you should say `Inject`. Please follow our core concepts.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/KafkaProducerInstrumentation.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link KafkaProducerInstrumentation} intercept the method <code>send</code> in the class
+ * <code>org.apache.kafka.clients.producer.KafkaProducer</code>. Here is the intercept process steps.
+ *
+ *
+ * <pre>
+ *  1. Record the broker address when the client create the <code>org.apache.kafka.clients.producer.KafkaProducer</code>
+ * instance
+ *  2. Fetch the topic name from <code>org.apache.kafka.clients.producer.ProducerRecord</code> when the client call
+ * <code>send</code> method.
+ *  3. Create the exit span when the client call <code>send</code> method
+ *  4. Set the <code>Context</code> into the <code>org.apache.kafka.clients.producer.ProducerRecord#headers</code>
+ *  5. Stop the exit span when end the <code>send</code> method.","[{'comment': 'Change the sentence too.', 'commenter': 'wu-sheng'}]"
772,apm-sniffer/apm-sdk-plugin/kafka-0.11.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/v11/define/ProducerRecordInstrumentation.java,"@@ -0,0 +1,64 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kafka.v11.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link ProducerRecordInstrumentation} intercept the constructor in the class <code>org.apache.kafka.clients.producer.ProducerRecord</code>","[{'comment': ""*Instrument didn't intercept anything.They just define interceptors."", 'commenter': 'wu-sheng'}]"
775,apm-collector/apm-collector-agent/agent-jetty/agent-jetty-provider/src/test/resources/json/dubbox-provider.json,"@@ -26,7 +26,7 @@
               ""pii"": 2, //上级的实例编号","[{'comment': ""Please don't write Chinese characters in the source codes."", 'commenter': 'wu-sheng'}]"
790,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/grpc/v1/AbstractServerImplBuilderInterceptor.java,"@@ -16,37 +16,36 @@
  *
  */
 
-
 package org.apache.skywalking.apm.plugin.grpc.v1;
 
-import io.grpc.internal.ManagedChannelImpl;
+import io.grpc.ServerInterceptors;
+import io.grpc.ServerServiceDefinition;
 import java.lang.reflect.Method;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
-import org.apache.skywalking.apm.plugin.grpc.v1.vo.GRPCDynamicFields;
 
 /**
- * {@link ManagedChannelInterceptor} record the IP address of the GRPC server into {@link GRPCDynamicFields} for build
- * span.
+ * {@link AbstractServerImplBuilderInterceptor} add the {@link CallServerInterceptor} interceptor for each the","[{'comment': 'For `every` ServerSerivce?', 'commenter': 'wu-sheng'}]"
790,apm-sniffer/apm-sdk-plugin/grpc-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/grpc/v1/AbstractStubInterceptor.java,"@@ -16,24 +16,27 @@
  *
  */
 
-
 package org.apache.skywalking.apm.plugin.grpc.v1;
 
+import io.grpc.Channel;
+import io.grpc.ClientInterceptors;
 import java.lang.reflect.Method;
-import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
-import org.apache.skywalking.apm.plugin.grpc.v1.define.Constants;
-import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
-import org.apache.skywalking.apm.plugin.grpc.v1.vo.GRPCDynamicFields;
 
 /**
- * {@link ServerCallOnCancelInterceptor} stop the active span when the call cancelled.
+ * {@link AbstractStubInterceptor} add the interceptor for each ClientCall.","[{'comment': 'for `every` ClientCall', 'commenter': 'wu-sheng'}]"
796,apm-sniffer/apm-sdk-plugin/rocketMQ-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/rocketMQ/v3/define/MQClientAPIImplInstrumentation.java,"@@ -0,0 +1,90 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.rocketMQ.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.plugin.rocketMQ.v3.MessageSendInterceptor;","[{'comment': 'This `import` should not be existed. I think your comments cause this.', 'commenter': 'wu-sheng'}]"
796,apm-sniffer/apm-sdk-plugin/rocketMQ-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/rocketMQ/v3/define/MQClientAPIImplInstrumentation.java,"@@ -0,0 +1,90 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.rocketMQ.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.plugin.rocketMQ.v3.MessageSendInterceptor;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link MQClientAPIImplInstrumentation} intercepts the {@link com.alibaba.rocketmq.client.impl.MQClientAPIImpl#sendMessage(String,
+ * String, com.alibaba.rocketmq.common.message.Message, com.alibaba.rocketmq.common.protocol.header.SendMessageRequestHeader,
+ * long, com.alibaba.rocketmq.client.impl.CommunicationMode, com.alibaba.rocketmq.client.producer.SendCallback,
+ * com.alibaba.rocketmq.client.impl.producer.TopicPublishInfo, com.alibaba.rocketmq.client.impl.factory.MQClientInstance,
+ * int, com.alibaba.rocketmq.client.hook.SendMessageContext, com.alibaba.rocketmq.client.impl.producer.DefaultMQProducerImpl)}
+ * method by using {@link MessageSendInterceptor}.","[{'comment': 'Remove the link or use full name of `MessageSendInterceptor`', 'commenter': 'wu-sheng'}]"
796,apm-sniffer/apm-sdk-plugin/rocketMQ-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/rocketMQ/v3/define/SendCallbackInstrumentation.java,"@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.rocketMQ.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.plugin.rocketMQ.v3.OnSuccessInterceptor;","[{'comment': 'Same issue.', 'commenter': 'wu-sheng'}]"
796,apm-sniffer/apm-sdk-plugin/rocketMQ-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/rocketMQ/v3/define/SendCallbackInstrumentation.java,"@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.rocketMQ.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.plugin.rocketMQ.v3.OnSuccessInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.HierarchyMatch.byHierarchyMatch;
+
+/**
+ * {@link SendCallbackInstrumentation} intercepts {@link com.alibaba.rocketmq.client.producer.SendCallback#onSuccess(com.alibaba.rocketmq.client.producer.SendResult sendResult)}
+ * method by using {@link OnSuccessInterceptor} and also intercepts {@link","[{'comment': 'Same issue.', 'commenter': 'wu-sheng'}]"
845,apm-application-toolkit/apm-toolkit-trace/src/main/java/org/apache/skywalking/apm/toolkit/trace/CallableWrapper.java,"@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.toolkit.trace;
+
+import java.util.concurrent.Callable;
+
+/**
+ * @author carlvine500
+ */
+@TraceCrossThread
+public class CallableWrapper<V> implements Callable<V> {
+    Callable<V> callable;","[{'comment': 'I suggest that  this field should be final, this can avoid multi-thread security issues.', 'commenter': 'ascrutae'}, {'comment': ""This field could be `final`, but I doubt it is thread security issue related. CallableWrapper is only created in parent thread, and didn't provide any way to update it. I can't see the thread issue."", 'commenter': 'wu-sheng'}, {'comment': 'This problem occurs when someone maliciously manipulates the `callable` field in the same package.  so I suggest that the field should be `final`. The best way to resolve this problem is that this field be `final` and `private`', 'commenter': 'ascrutae'}, {'comment': ""`final Callable<V> callable;` is efficient . I'll change it"", 'commenter': 'carlvine500'}]"
845,apm-sniffer/apm-sdk-plugin/jdk-cross-thread-plugin/src/main/java/org/apache/skywalking/apm/plugin/jdk/thread/CallableOrRunnableConstructInterceptor.java,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.jdk.thread;
+
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+/**
+ * @author carlvine500
+ */
+public class CallableOrRunnableConstructInterceptor implements InstanceConstructorInterceptor {
+    @Override public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        ContextCarrier contextCarrier = new ContextCarrier();
+        AbstractSpan span = ContextManager.createExitSpan(""JDK/Thread/run"", contextCarrier, Thread.currentThread().getName());","[{'comment': ""The third parameter of the `createExitSpan` method is IP address,  and the `Thread.currentThread().getName()` isn't the IP address. I suggest that you should call `createLocalSpan`. \r\nAlso, I suggest that the operation name of this span cloud be like `Thread/{CALLABLE_CLASS_NAME}`."", 'commenter': 'ascrutae'}, {'comment': 'I will try to change to \r\n`ContextManager.createLocalSpan(""Thread/"" + objInst.getClass().getName())`', 'commenter': 'carlvine500'}]"
845,apm-sniffer/apm-sdk-plugin/jdk-cross-thread-plugin/src/main/java/org/apache/skywalking/apm/plugin/jdk/thread/CallableOrRunnableInvokeInterceptor.java,"@@ -0,0 +1,50 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.jdk.thread;
+
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+
+/**
+ * @author carlvine500
+ */
+public class CallableOrRunnableInvokeInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        ContextManager.createLocalSpan(""Thread/run"");","[{'comment': 'I suggest that the operation name of this span cloud be like `Thread/{CALLABLE_CLASS_NAME}`.', 'commenter': 'ascrutae'}, {'comment': 'I will try to change to \r\n`ContextManager.createLocalSpan(""Thread/"" + objInst.getClass().getName())`', 'commenter': 'carlvine500'}, {'comment': '@ascrutae\r\ndo you think it\'s better , this code is diffrent from CallableOrRunnableConstructInterceptor:\r\nContextManager.createLocalSpan(""Thread/"" + objInst.getClass().getName() + ""/"" + method.getName())', 'commenter': 'carlvine500'}, {'comment': '@carlvine500 `method#getName` always return **run** right?', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng \r\nmethod#getName return run or call ', 'commenter': 'carlvine500'}, {'comment': 'Then I am OK with that.', 'commenter': 'wu-sheng'}]"
871,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -34,18 +34,27 @@ ui:
     host: localhost
     port: 12800
     context_path: /
-storage:
-  elasticsearch:
-    cluster_name: CollectorDBCluster
-    cluster_transport_sniffer: true
-    cluster_nodes: localhost:9300
-    index_shards_number: 2
-    index_replicas_number: 0
-    ttl: 7
 #storage:
-#  h2:
-#    url: jdbc:h2:tcp://localhost/~/test
-#    user_name: sa
+#  elasticsearch:
+#    cluster_name: elasticsearch
+#    cluster_transport_sniffer: true
+#    cluster_nodes: 10.126.94.37:9300
+#    index_shards_number: 2
+#    index_replicas_number: 0
+#    ttl: 7
+#storage:
+#  elasticsearch-http:
+#    cluster_name: elasticsearch
+#    cluster_nodes: 10.126.94.37:9200
+#    index_shards_number: 2
+#    ssl : false
+#    index_replicas_number: 0
+#    username : admin
+#    password : admin
+storage:
+  h2:
+    url: jdbc:h2:tcp://localhost/~/test
+    user_name: sa","[{'comment': ""h2 is not provided in alpha, so we can't use this as default."", 'commenter': 'wu-sheng'}]"
871,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -34,18 +34,27 @@ ui:
     host: localhost
     port: 12800
     context_path: /
-storage:
-  elasticsearch:
-    cluster_name: CollectorDBCluster
-    cluster_transport_sniffer: true
-    cluster_nodes: localhost:9300
-    index_shards_number: 2
-    index_replicas_number: 0
-    ttl: 7
 #storage:
-#  h2:
-#    url: jdbc:h2:tcp://localhost/~/test
-#    user_name: sa
+#  elasticsearch:
+#    cluster_name: elasticsearch
+#    cluster_transport_sniffer: true
+#    cluster_nodes: 10.126.94.37:9300
+#    index_shards_number: 2
+#    index_replicas_number: 0
+#    ttl: 7
+#storage:
+#  elasticsearch-http:","[{'comment': 'Add comment here, to mention this is an incubating feature, and no product use for now.', 'commenter': 'wu-sheng'}, {'comment': 'Setting about this should not stay in documents. Please add this as a part of `Advanced Features` at here: https://github.com/apache/incubator-skywalking/blob/master/docs/README.md  \r\n\r\nEnglish document is required, Chinese is optional for now.', 'commenter': 'wu-sheng'}, {'comment': ""Make sure your title includes `incubating`, but doc file name didn't need that."", 'commenter': 'wu-sheng'}]"
871,apm-collector/apm-collector-component/client-component/pom.xml,"@@ -17,94 +17,99 @@
   ~
   -->
 
-<project xmlns=""http://maven.apache.org/POM/4.0.0""
-         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
-         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
-    <parent>
-        <artifactId>apm-collector-component</artifactId>
-        <groupId>org.apache.skywalking</groupId>
-        <version>5.0.0-alpha-SNAPSHOT</version>
-    </parent>
-    <modelVersion>4.0.0</modelVersion>
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+	xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+	<parent>
+		<artifactId>apm-collector-component</artifactId>
+		<groupId>org.apache.skywalking</groupId>
+		<version>5.0.0-alpha-SNAPSHOT</version>
+	</parent>
+	<modelVersion>4.0.0</modelVersion>
 
-    <artifactId>client-component</artifactId>
-    <packaging>jar</packaging>
 
-    <dependencies>
-        <dependency>
-            <groupId>com.h2database</groupId>
-            <artifactId>h2</artifactId>
-            <version>1.4.196</version>
-        </dependency>
-        <dependency>
-            <groupId>redis.clients</groupId>
-            <artifactId>jedis</artifactId>
-            <version>2.9.0</version>
-        </dependency>
-        <dependency>
-            <groupId>org.elasticsearch.client</groupId>
-            <artifactId>transport</artifactId>
-            <version>5.5.0</version>
-            <exclusions>
-                <exclusion>
-                    <artifactId>snakeyaml</artifactId>
-                    <groupId>org.yaml</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-common</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-transport</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-codec</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-codec-http</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-buffer</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-handler</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>netty-resolver</artifactId>
-                    <groupId>io.netty</groupId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.zookeeper</groupId>
-            <artifactId>zookeeper</artifactId>
-            <version>3.4.10</version>
-            <exclusions>
-                <exclusion>
-                    <artifactId>slf4j-api</artifactId>
-                    <groupId>org.slf4j</groupId>
-                </exclusion>
-                <exclusion>
-                    <artifactId>slf4j-log4j12</artifactId>
-                    <groupId>org.slf4j</groupId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-        <dependency>
-            <groupId>org.apache.skywalking</groupId>
-            <artifactId>apm-network</artifactId>
-            <version>${project.version}</version>
-            <exclusions>
-                <exclusion>
-                    <artifactId>guava</artifactId>
-                    <groupId>com.google.guava</groupId>
-                </exclusion>
-            </exclusions>
-        </dependency>
-    </dependencies>
+	<artifactId>client-component</artifactId>
+	<packaging>jar</packaging>
+
+	<dependencies>
+		<dependency>
+			<groupId>com.h2database</groupId>
+			<artifactId>h2</artifactId>
+			<version>1.4.196</version>
+		</dependency>
+		<dependency>
+			<groupId>redis.clients</groupId>
+			<artifactId>jedis</artifactId>
+			<version>2.9.0</version>
+		</dependency>
+		<dependency>
+			<groupId>org.elasticsearch.client</groupId>
+			<artifactId>transport</artifactId>
+			<version>5.5.0</version>
+			<exclusions>
+				<exclusion>
+					<artifactId>snakeyaml</artifactId>
+					<groupId>org.yaml</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-common</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-transport</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-codec</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-codec-http</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-buffer</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-handler</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>netty-resolver</artifactId>
+					<groupId>io.netty</groupId>
+				</exclusion>
+			</exclusions>
+		</dependency>
+		<dependency>
+			<groupId>org.apache.zookeeper</groupId>
+			<artifactId>zookeeper</artifactId>
+			<version>3.4.10</version>
+			<exclusions>
+				<exclusion>
+					<artifactId>slf4j-api</artifactId>
+					<groupId>org.slf4j</groupId>
+				</exclusion>
+				<exclusion>
+					<artifactId>slf4j-log4j12</artifactId>
+					<groupId>org.slf4j</groupId>
+				</exclusion>
+			</exclusions>
+		</dependency>
+		<dependency>
+			<groupId>org.apache.skywalking</groupId>
+			<artifactId>apm-network</artifactId>
+			<version>${project.version}</version>
+			<exclusions>
+				<exclusion>
+					<artifactId>guava</artifactId>
+					<groupId>com.google.guava</groupId>
+				</exclusion>
+			</exclusions>
+		</dependency>
+		<dependency>
+			<groupId>io.searchbox</groupId>
+			<artifactId>jest</artifactId>
+			<version>5.3.3</version>
+		</dependency>
+	</dependencies>","[{'comment': 'Why is this file format so different?', 'commenter': 'wu-sheng'}]"
1001,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/GRPCChannel.java,"@@ -0,0 +1,127 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.remote;
+
+import io.grpc.Channel;
+import io.grpc.ManagedChannel;
+import io.grpc.ManagedChannelBuilder;
+import io.grpc.NameResolverProvider;
+import io.grpc.internal.DnsNameResolverProvider;
+import io.grpc.netty.NettyChannelBuilder;
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author zhangxin
+ */
+public class GRPCChannel {
+    /**
+     * origin channel
+     */
+    private final ManagedChannel originChannel;
+    private final Channel channelWithInterceptors;
+
+    private GRPCChannel(String host, int port, List<ChannelBuilder> channelBuilders,
+        List<Interceptor> interceptors, int maxInboundMessageSize, boolean usePlaintext,
+        NameResolverProvider nameResolverFactory) throws Exception {","[{'comment': 'I prefer  these three should be in a ChannelBuilder called StandardChannelBuilder\r\n- int maxInboundMessageSize\r\n- boolean usePlaintext\r\n- NameResolverProvider nameResolverFactory', 'commenter': 'wu-sheng'}]"
1001,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/Interceptor.java,"@@ -0,0 +1,10 @@
+package org.apache.skywalking.apm.agent.core.remote;
+
+import io.grpc.Channel;
+
+/**
+ * @author zhang xin
+ */
+public interface Interceptor {
+    Channel intercept(Channel channel);","[{'comment': 'Based on Channel as input and output args, this class is a `ChannelDecorator` ', 'commenter': 'wu-sheng'}, {'comment': 'Method can also be named as `build`', 'commenter': 'wu-sheng'}]"
1014,docs/en/TLS.md,"@@ -0,0 +1,46 @@
+# Support Transport Layer Security (TLS)
+Transport Layer Security (TLS) is a very common security way when transport data through Internet.
+In some use cases, end users report the background:
+
+> Target(under monitoring) applications are in a region, which also named VPC,
+at the same time, the SkyWalking backend is in another region (VPC).
+> 
+> Because of that, security requirement is very obvious.
+
+## Requirement
+Enable **direct uplink**, by following this [document](direct-uplink.md).
+
+Because of uplink through internet, with security concern, the naming mechanism didn't fit. 
+So we didn't support TLS in naming service of HTTP service.
+
+## Supported version
+5.0.0-beta +
+
+## Mutual Auth","[{'comment': 'The authority is not mutual.', 'commenter': 'hanahmily'}]"
1014,docs/en/TLS.md,"@@ -0,0 +1,46 @@
+# Support Transport Layer Security (TLS)
+Transport Layer Security (TLS) is a very common security way when transport data through Internet.
+In some use cases, end users report the background:
+
+> Target(under monitoring) applications are in a region, which also named VPC,
+at the same time, the SkyWalking backend is in another region (VPC).
+> 
+> Because of that, security requirement is very obvious.
+
+## Requirement
+Enable **direct uplink**, by following this [document](direct-uplink.md).
+
+Because of uplink through internet, with security concern, the naming mechanism didn't fit. 
+So we didn't support TLS in naming service of HTTP service.
+
+## Supported version
+5.0.0-beta +
+
+## Mutual Auth
+Only support **no mutual auth**.
+- Use this [script](../../tools/TLS/tls_key_generate.sh) if you are not familiar with how to generate key files.
+- Find `ca.srt`, and use it at client side
+- Find `server.crt` and `server.pem`. Use them at server side.
+
+## Open and config TLS
+
+### Agent config
+- Place `ca.srt` into `/ca` folder in agent package. Notice, `/ca` is not created in distribution, please create it by yourself.","[{'comment': 'Typo: ca.crt, not ca.srt', 'commenter': 'hanahmily'}, {'comment': 'It is not fixed', 'commenter': 'hanahmily'}]"
1014,docs/en/TLS.md,"@@ -0,0 +1,46 @@
+# Support Transport Layer Security (TLS)
+Transport Layer Security (TLS) is a very common security way when transport data through Internet.
+In some use cases, end users report the background:
+
+> Target(under monitoring) applications are in a region, which also named VPC,
+at the same time, the SkyWalking backend is in another region (VPC).
+> 
+> Because of that, security requirement is very obvious.
+
+## Requirement
+Enable **direct uplink**, by following this [document](direct-uplink.md).
+
+Because of uplink through internet, with security concern, the naming mechanism didn't fit. 
+So we didn't support TLS in naming service of HTTP service.
+
+## Supported version
+5.0.0-beta +
+
+## Authentication Mode
+Only support **no mutual auth**.
+- Use this [script](../../tools/TLS/tls_key_generate.sh) if you are not familiar with how to generate key files.
+- Find `ca.crt`, and use it at client side
+- Find `server.crt` and `server.pem`. Use them at server side.
+
+## Open and config TLS
+
+### Agent config
+- Place `ca.srt` into `/ca` folder in agent package. Notice, `/ca` is not created in distribution, please create it by yourself.
+
+Agent open TLS automatically after the `/ca/ca.srt` file detected.","[{'comment': 'Typo', 'commenter': 'hanahmily'}]"
1018,apm-collector/apm-collector-ui/collector-ui-jetty-provider/src/main/java/org/apache/skywalking/apm/collector/ui/service/ServiceTopologyService.java,"@@ -86,7 +86,11 @@ public Topology getServiceTopology(Step step, int serviceId, long startTimeBucke
             Call call = new Call();
             call.setSource(referenceMetric.getSource());
             call.setTarget(referenceMetric.getTarget());
-            call.setAvgResponseTime((referenceMetric.getDurations() - referenceMetric.getErrorDurations()) / (referenceMetric.getCalls() - referenceMetric.getErrorCalls()));
+            if (referenceMetric.getCalls() == referenceMetric.getErrorCalls()) {
+                call.setAvgResponseTime(referenceMetric.getDurations() / referenceMetric.getCalls());","[{'comment': 'This process way has conflicts with other. If all requests are error, the avg response time should be 0.', 'commenter': 'wu-sheng'}, {'comment': 'fixed.avg time has been set to 0', 'commenter': 'candyleer'}]"
1048,docs/cn/Setting-override-CN.md,"@@ -0,0 +1,38 @@
+# 自定义设置
+## 支持版本
+5.0.0-beta + 
+
+_Agent 自定义设置 从 3.2.5_ 版本开始支持。
+
+## 什么是自定义设置?
+ SkyWalking 默认为客户端提供 `agent.config`和 `application.yml` 文件用于服务端设置. 
+
+自定义设置是指终端用户可以在一些配置文件里使用内置属性自定义相关配置。
+
+## 自定义优先级
+系统属性(-D) > 配置文件
+ 
+## 自定义
+### 代理
+在配置文件里使用 `skywalking.` + key 作为系统属性和环境变量去自定义对应的值.
+
+- 为什么要使用`skywalking.`这个前缀?
+
+ 代理系统和目标应用会共享属性和环境变量,所以使用这个前缀避免同名变量冲突。","[{'comment': '`代理系统和目标应用` 应修改为 `探针和目标系统`', 'commenter': 'wu-sheng'}]"
1048,docs/cn/Setting-override-CN.md,"@@ -0,0 +1,38 @@
+# 自定义设置
+## 支持版本
+5.0.0-beta + 
+
+_Agent 自定义设置 从 3.2.5_ 版本开始支持。
+
+## 什么是自定义设置?
+ SkyWalking 默认为客户端提供 `agent.config`和 `application.yml` 文件用于服务端设置. 
+
+自定义设置是指终端用户可以在一些配置文件里使用内置属性自定义相关配置。
+
+## 自定义优先级
+系统属性(-D) > 配置文件
+ 
+## 自定义
+### 代理","[{'comment': '请保留Agent名称', 'commenter': 'wu-sheng'}]"
1048,docs/cn/Setting-override-CN.md,"@@ -0,0 +1,38 @@
+# 自定义设置
+## 支持版本
+5.0.0-beta + 
+
+_Agent 自定义设置 从 3.2.5_ 版本开始支持。
+
+## 什么是自定义设置?
+ SkyWalking 默认为客户端提供 `agent.config`和 `application.yml` 文件用于服务端设置. 
+
+自定义设置是指终端用户可以在一些配置文件里使用内置属性自定义相关配置。
+
+## 自定义优先级
+系统属性(-D) > 配置文件
+ 
+## 自定义
+### 代理
+在配置文件里使用 `skywalking.` + key 作为系统属性和环境变量去自定义对应的值.
+
+- 为什么要使用`skywalking.`这个前缀?
+
+ 代理系统和目标应用会共享属性和环境变量,所以使用这个前缀避免同名变量冲突。
+  
+### 收集器","[{'comment': '请保留Collector名称', 'commenter': 'wu-sheng'}]"
1048,docs/cn/Setting-override-CN.md,"@@ -0,0 +1,38 @@
+# 自定义设置
+## 支持版本
+5.0.0-beta + 
+
+_Agent 自定义设置 从 3.2.5_ 版本开始支持。
+
+## 什么是自定义设置?
+ SkyWalking 默认为客户端提供 `agent.config`和 `application.yml` 文件用于服务端设置. 
+
+自定义设置是指终端用户可以在一些配置文件里使用内置属性自定义相关配置。
+
+## 自定义优先级
+系统属性(-D) > 配置文件
+ 
+## 自定义
+### 代理
+在配置文件里使用 `skywalking.` + key 作为系统属性和环境变量去自定义对应的值.
+
+- 为什么要使用`skywalking.`这个前缀?
+
+ 代理系统和目标应用会共享属性和环境变量,所以使用这个前缀避免同名变量冲突。
+  
+### 收集器
+在配置文件里使用 key 作为系统属性和环境变量去自定义对应的值.
+
+例如:
+- 在 `application.yml`文件里设置
+```yaml
+agent_gRPC:
+  gRPC:
+    host: localhost
+    port: 11800
+```
+
+- 使用系统属性重写端口到 31200,并且把下面这行代码添加到 startup 脚本里.","[{'comment': '`并且`修改为`需要`', 'commenter': 'wu-sheng'}]"
1053,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/dao/ui/SegmentDurationEsUIDAO.java,"@@ -57,8 +58,9 @@ public TraceBrief loadTop(long startSecondTimeBucket, long endSecondTimeBucket,
         List<QueryBuilder> mustQueryList = boolQueryBuilder.must();
 
         if (startSecondTimeBucket != 0 && endSecondTimeBucket != 0) {
-            //TODO second
-            mustQueryList.add(QueryBuilders.rangeQuery(SegmentDurationTable.COLUMN_TIME_BUCKET).gte(startSecondTimeBucket).lte(endSecondTimeBucket));
+            mustQueryList.add(QueryBuilders.rangeQuery(SegmentDurationTable.COLUMN_TIME_BUCKET)
+                    .gte(TimeBucketUtils.INSTANCE.secondToMinute(startSecondTimeBucket))","[{'comment': 'This time format should already done in `TraceQuery#queryBasicTraces#L71`. And the query works in our demo env and product env.', 'commenter': 'wu-sheng'}]"
1099,apm-collector/apm-collector-cache/collector-cache-guava-provider/src/main/java/org/apache/skywalking/apm/collector/cache/guava/CacheUtils.java,"@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.collector.cache.guava;
+
+
+import com.google.common.cache.Cache;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.Optional;
+import java.util.function.Supplier;
+
+import static java.util.Objects.isNull;
+import static java.util.Objects.nonNull;
+
+/**
+ * @author nikitap492
+ */
+public class CacheUtils {
+    private static final Logger logger = LoggerFactory.getLogger(CacheUtils.class);
+
+    public static <K, V> V retrieve(Cache<K, V> cache, K key, Supplier<V> supplier) {
+        V value = null;
+        try {
+            value = cache.get(key, supplier::get);
+        } catch (Throwable e) {
+            logger.error(e.getMessage(), e);
+        }
+
+        if (isNull(value)) {","[{'comment': '@nikitap492 isNull is not enough, I add a test case for you.\r\nIf we want to retrieve a registered object id from DB before register. Guava will cache it, but  retrieve it again after register, guava cache did not refresh.', 'commenter': 'peng-yongsheng'}, {'comment': ""Yes, It is because the compiler initializite primitive class fields with 0. I don't consider that. If it is `Integer` and not `int` it is alright. But adding more checks as `instance of` or write  more methods for primitives it looks like workaround.\r\n And now I understood why cache was written that way.\r\n"", 'commenter': 'nikitap492'}]"
1102,apm-collector/apm-collector-boot/src/main/resources/component-libraries.yml,"@@ -122,9 +122,30 @@ Jedis:
   languages: Java
 
 
+# .NET/.NET Core components
+AspNetCore:
+  id: 1001
+  languages: C#
+EntityFrameworkCore:
+  id: 1002
+  languages: C#
+SqlClient:
+  id: 1003
+  languages: C#
+CAP:
+  id: 1004
+  languages: C#
+StackExchange.Redis:
+  id: 1005
+  languages: C#
+
+
+
 # Component Server mapping defines the server display names of some components
 # e.g.
 # Jedis is a client library in Java for Redis server
 Component-Server-Mappings:
   Jedis: Redis
+  StackExchange.Redis: Redis
+  SqlClient: SqlServer","[{'comment': 'Good to have these mapping.', 'commenter': 'wu-sheng'}]"
1102,apm-collector/apm-collector-boot/src/main/resources/component-libraries.yml,"@@ -122,9 +122,30 @@ Jedis:
   languages: Java
 
 
+# .NET/.NET Core components
+AspNetCore:
+  id: 1001","[{'comment': 'I prefer to keep  [0, 3000) for Java and across language frameworks. So please use [3000, 4000) for C#/.NET only.', 'commenter': 'wu-sheng'}]"
1109,CHANGES.md,"@@ -1,19 +1,79 @@
  Changes by Version
  ==================
  Release Notes.
+  
+ 5.0.0-beta
+ ------------------
+ 
+#### UI -> Collector GraphQL query protocol
+  - Replace all tps to throughtput/cpm(calls per min)
+  - Add `getThermodynamic` service
+  - Update version to beta
+ 
+#### Agent Changes
+  - Support TLS.
+  - Support namespace.
+  - Support direct link.
+  - Support token.
+  - Add across thread toolkit.
+  - Add new plugin extend machenism to override agent core implementations.
+  - Fix an agent start up sequence bug.
+  - Fix wrong gc count.
+  - Remove system env override.
+  - Add Spring AOP aspect patch to avoid aop conflicts.
+ 
+#### Collector Changes
+  - Trace query based on timeline.
+  - Delete JVM aggregation in second.
+  - Support TLS.
+  - Support namespace.
+  - Support token auth.
+  - Group and aggregate requests based on reponse time and timeline, support Thermodynamic chart query
+  - Support component librariy setting through yml file for better extendibility.
+  - Optimize performance.
+  - Support short column name in ES or other storage implementor.
+  - Add a new cache module implementor, based on **Caffeine**.
+  - Support system property override settings.
+  - Refactor settings initialization.
+  - Provide collector instrumentation agent.
+  - Support .NET core component libraries.
+  - Fix `divide zero` in query.
+  - Fix `Data don't remove as expected` in ES implementor.
+  - Add some checks in collector modulization core.
+  - Add some test cases.
+ 
+#### UI Changes
+  - New trace query UI.
+  - New Application UI, merge server tab(removed) into applciation as sub page.
+  - Add Thermodynamic chart in overview page.
+  - Change all tps to cpm(calls per minutes).
+  - Fix wrong osName in server view.
+  - Fix wrong startTime in trace view.
+  - Fix some icons internet requirements.","[{'comment': 'Missing issues:\r\nNew Topology UI.\r\nNew response time / throughput TopN list.', 'commenter': 'hanahmily'}, {'comment': '@hanahmily Updated.', 'commenter': 'wu-sheng'}]"
1142,apm-collector/apm-collector-boot/src/main/resources/component-libraries.yml,"@@ -83,7 +83,7 @@ NutzHttp:
   languages: Java
 JettyClient:
   id: 18
-  languages: Java
+  languages: Javaƒ","[{'comment': 'I think this is not your purpose.', 'commenter': 'wu-sheng'}]"
1210,apm-sniffer/apm-sdk-plugin/sofarpc-plugin/src/main/java/org/apache/skywalking/apm/plugin/sofarpc/SofaRpcProviderInterceptor.java,"@@ -0,0 +1,117 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.sofarpc;
+
+import com.alipay.sofa.rpc.context.RpcInternalContext;
+import com.alipay.sofa.rpc.core.request.SofaRequest;
+import com.alipay.sofa.rpc.core.response.SofaResponse;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author leizhiyuan
+ */
+public class SofaRpcProviderInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                             Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        SofaRequest sofaRequest = (SofaRequest) allArguments[0];
+        RpcInternalContext rpcContext = RpcInternalContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+
+        AbstractSpan span = null;
+
+        if (!isConsumer) {
+            ContextCarrier contextCarrier = new ContextCarrier();
+            CarrierItem next = contextCarrier.items();
+            while (next.hasNext()) {
+                next = next.next();
+                final Object attachment = rpcContext.getAttachment(next.getHeadKey());
+                if (attachment != null) {
+                    next.setHeadValue(attachment.toString());
+                } else {
+                    next.setHeadValue("""");
+                }
+            }
+            span = ContextManager.createEntrySpan(generateViewPoint(sofaRequest), contextCarrier);
+
+        }
+
+        span.setComponent(ComponentsDefine.SOFARPC);","[{'comment': 'This line maybe cause NullPointException when the `isConsumer` equals `true`. Or remove the judgment if you are sure this instrumentation only call by provide side.', 'commenter': 'ascrutae'}, {'comment': 'ok,I can make true this call by provide side,I will remove it', 'commenter': 'leizhiyuan'}]"
1210,apm-sniffer/apm-sdk-plugin/sofarpc-plugin/src/main/java/org/apache/skywalking/apm/plugin/sofarpc/SofaRpcConsumerInterceptor.java,"@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.sofarpc;
+
+import com.alipay.sofa.rpc.client.ProviderInfo;
+import com.alipay.sofa.rpc.context.RpcInternalContext;
+import com.alipay.sofa.rpc.core.request.SofaRequest;
+import com.alipay.sofa.rpc.core.response.SofaResponse;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author leizhiyuan
+ */
+public class SofaRpcConsumerInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                             Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        SofaRequest sofaRequest = (SofaRequest) allArguments[0];
+        RpcInternalContext rpcContext = RpcInternalContext.getContext();
+        boolean isConsumer = rpcContext.isConsumerSide();
+        ProviderInfo providerInfo = rpcContext.getProviderInfo();
+
+        AbstractSpan span = null;
+
+        final String host = providerInfo.getHost();
+        final int port = providerInfo.getPort();
+        if (isConsumer) {
+            final ContextCarrier contextCarrier = new ContextCarrier();
+            span = ContextManager.createExitSpan(generateOperationName(providerInfo, sofaRequest), contextCarrier, host + "":"" + port);
+            CarrierItem next = contextCarrier.items();
+            while (next.hasNext()) {
+                next = next.next();
+                rpcContext.getAttachments().put(next.getHeadKey(), next.getHeadValue());
+            }
+        }
+        Tags.URL.set(span, generateRequestURL(providerInfo, sofaRequest));
+        span.setComponent(ComponentsDefine.SOFARPC);","[{'comment': 'This line maybe cause NullPointException when the isConsumer equals false. Or remove the judgment if you are sure this instrumentation only call by consumer side', 'commenter': 'ascrutae'}]"
1210,apm-collector/apm-collector-configuration/collector-configuration-provider/src/test/resources/component-libraries.yml,"@@ -124,6 +124,9 @@ Hystrix:
 Jedis:
   id: 30
   languages: Java
+SOFARPC:
+  id: 31","[{'comment': ""the id isn't equals `ComponentsDefine` define's."", 'commenter': 'ascrutae'}, {'comment': '@ascrutae I found  that test  component-libraries.yml \r\n\r\nJedis has used 30 ,cloud I use 30 too?', 'commenter': 'leizhiyuan'}, {'comment': 'No, the id must unique', 'commenter': 'ascrutae'}, {'comment': '@ascrutae It is test file ,seems no one use It, I will remove this line', 'commenter': 'leizhiyuan'}, {'comment': ""Sorry, it's my fault. "", 'commenter': 'ascrutae'}]"
1210,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -84,6 +84,8 @@
 
     public static final OfficialComponent HYSTRIX =  new OfficialComponent(29, ""Hystrix"");
 
+    public static final OfficialComponent SOFARPC =  new OfficialComponent(30, ""SOFARPC"");","[{'comment': ""the value that it define in `component-libraries.yml`file isn't equals the value define in `ComponentsDefine.java` file"", 'commenter': 'ascrutae'}, {'comment': ""@ascrutae They are all 30, only In test's component-libraries.yml ,I can not set it to 30, because jedis used It"", 'commenter': 'leizhiyuan'}, {'comment': 'You can set the value to `32`, because the value define in `component-libraries.yml` is `32`. and more you also should change length of `components` filed to `33`', 'commenter': 'ascrutae'}, {'comment': '@ascrutae I removed this settings ', 'commenter': 'leizhiyuan'}, {'comment': 'all production code ,I need to set it as 30. last plugin is 29. I removed test settings, I did not use it in test project', 'commenter': 'leizhiyuan'}, {'comment': ""The component id must equals the `ComponentsDefine.java` defined's, or the component in topology will incorrect"", 'commenter': 'ascrutae'}, {'comment': '@ascrutae Ok,I will set it 32, SQLite(31) is wrong before? It has no defination in \r\nComponentsDefine', 'commenter': 'leizhiyuan'}]"
1213,apm-sniffer/optional-plugins/trace-ignore-plugin/README.md,"@@ -0,0 +1,2 @@
+###How to use trace ignore plugin
+Please just copy or move the apm-trace-ignore-plugin-x.jar to agent/plugins, then you can set you need ignore paths in trace-ignore-plugin.config(this config file don't need to move)","[{'comment': 'In any case, we should let setting file active in optional-plugins folder. Please ask users to copy the setting file too.', 'commenter': 'wu-sheng'}, {'comment': 'Setting file should be in `/conf` folder. ', 'commenter': 'wu-sheng'}, {'comment': 'I agree that. ', 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/pom.xml,"@@ -98,11 +100,26 @@
                         <configuration>
                             <tasks>
                                 <taskdef resource=""net/sf/antcontrib/antcontrib.properties"" classpathref=""maven.runtime.classpath"" />
+                                <mkdir dir=""${plugin.dest.dir}"" />","[{'comment': 'Please read the pom.xml in `apm-sdk-plugin` module and plugins in it. Create pom properties `agent.package.dest.dir` and `optional.agent.package.dest.dir` to do the copy, and let copy op could be override by the plugin pom.\r\n\r\nOnly copy jar file is required, the setting file and readme are optional.  \r\n\r\n', 'commenter': 'wu-sheng'}, {'comment': 'I get it', 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/trace-ignore-plugin/src/main/java/org/apache/skywalking/apm/plugin/trace/ignore/TraceIgnoreExtendService.java,"@@ -0,0 +1,59 @@
+package org.apache.skywalking.apm.plugin.trace.ignore;
+
+import org.apache.skywalking.apm.agent.core.boot.AgentPackageNotFoundException;
+import org.apache.skywalking.apm.agent.core.boot.OverrideImplementor;
+import org.apache.skywalking.apm.agent.core.conf.ConfigNotFoundException;
+import org.apache.skywalking.apm.agent.core.context.AbstractTracerContext;
+import org.apache.skywalking.apm.agent.core.context.ContextManagerExtendService;
+import org.apache.skywalking.apm.agent.core.context.IgnoredTracerContext;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.plugin.trace.ignore.conf.IgnoreConfig;
+import org.apache.skywalking.apm.plugin.trace.ignore.conf.IgnoreConfigInitializer;
+import org.apache.skywalking.apm.plugin.trace.ignore.matcher.SpringAntPathMatcher;
+import org.apache.skywalking.apm.plugin.trace.ignore.matcher.TracePathMatcher;
+import org.apache.skywalking.apm.util.StringUtil;
+
+/**
+ *
+ * @author liujc [liujunc1993@163.com]
+ * @date 2018/5/11 11:27","[{'comment': ""Don't put the date in Java file. No one will change it."", 'commenter': 'wu-sheng'}, {'comment': ""Ok, I'll remove the date"", 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/trace-ignore-plugin/src/main/java/org/apache/skywalking/apm/plugin/trace/ignore/matcher/TracePathMatcher.java,"@@ -0,0 +1,6 @@
+package org.apache.skywalking.apm.plugin.trace.ignore.matcher;
+
+public interface TracePathMatcher {","[{'comment': ""I can't find this matcher used in any place. What is the purpose of this interface?"", 'commenter': 'wu-sheng'}, {'comment': 'I think there may be a variety of path matching rules. This interface is designed to support this extension', 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/trace-ignore-plugin/src/main/java/org/apache/skywalking/apm/plugin/trace/ignore/matcher/SpringAntPathMatcher.java,"@@ -0,0 +1,14 @@
+package org.apache.skywalking.apm.plugin.trace.ignore.matcher;
+
+import org.springframework.util.AntPathMatcher;
+import org.springframework.util.PathMatcher;
+
+public class SpringAntPathMatcher implements TracePathMatcher {
+
+    private PathMatcher pathMatcher = new AntPathMatcher();","[{'comment': 'If you are using the Spring matcher, then the plugin has to include the Spring jar into it. And you put `<artifactId>spring-core</artifactId>` provided in your pom. So who can make the spring core jar in the agent class loader?', 'commenter': 'wu-sheng'}, {'comment': 'The further question is, is using spring core matcher a good idea? Include such a large library to solve this feature.', 'commenter': 'wu-sheng'}, {'comment': ""I've had this thought too, I will not depend on the spring framework"", 'commenter': 'liu-junchi'}, {'comment': 'I will add a simple version of AntPathMatcher', 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/optional-spring-plugins/spring-annotation-plugin/pom.xml,"@@ -28,6 +28,10 @@
 
     <artifactId>apm-spring-annotation-plugin</artifactId>
 
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <sdk.plugin.related.dir>/..</sdk.plugin.related.dir>","[{'comment': 'This could be the default in `optional-plugins/pom.xml`, which will make people easier to understand.', 'commenter': 'wu-sheng'}, {'comment': 'I think the `sdk.plugin.related.dir`  should in `optional-plugins/pom.xml`, because it needs to cover the path of the copy', 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/pom.xml,"@@ -31,11 +31,15 @@
         <shade.net.bytebuddy.source>net.bytebuddy</shade.net.bytebuddy.source>
         <shade.net.bytebuddy.target>${shade.package}.${shade.net.bytebuddy.source}</shade.net.bytebuddy.target>
 
-        <plugin.dest.dir>${project.build.directory}/../../../../skywalking-agent/optional-plugins</plugin.dest.dir>
+        <sdk.plugin.related.dir />","[{'comment': 'Set default value', 'commenter': 'wu-sheng'}, {'comment': ""I add  `<sdk.plugin.related.dir />` follow `apm-sdk-plugin/pom`  \r\n![image](https://user-images.githubusercontent.com/12181207/39991540-7ab090c4-57a2-11e8-9f71-74d6f527b550.png)\r\nIt's just a statement, the sub pom if need this properties should override it,  then act on `${agent.package.dest.dir}`"", 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/trace-ignore-plugin/README.md,"@@ -0,0 +1,2 @@
+###How to use trace ignore plugin
+Please copy the apm-trace-ignore-plugin-x.jar to `agent/plugins`, this plugin support reading config from environment variables(The env key must start with `skywalking.`, the reuslt should be as same as in `apm-trace-ignore-plugin.config`), or you can copy the `apm-trace-ignore-plugin.config` to `agent/config` then you'll set you need ignore paths in `apm-trace-ignore-plugin.config`","[{'comment': ""See here: https://github.com/SevenPointOld/incubator-skywalking/blob/18790363b3ba50738ea3e577b63506fce16a4e77/apm-sniffer/optional-plugins/trace-ignore-plugin/README.md\r\n\r\nYour markdown don't look good. Please provide sections about two usages.\r\n```\r\n# title\r\nAbstrct\r\n\r\n## Usage\r\n1. ...... use config file.....\r\n2. ...... through env, and examples\r\n```"", 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/pom.xml,"@@ -31,11 +31,15 @@
         <shade.net.bytebuddy.source>net.bytebuddy</shade.net.bytebuddy.source>
         <shade.net.bytebuddy.target>${shade.package}.${shade.net.bytebuddy.source}</shade.net.bytebuddy.target>
 
-        <plugin.dest.dir>${project.build.directory}/../../../../skywalking-agent/optional-plugins</plugin.dest.dir>
+        <sdk.plugin.related.dir />
+        <agent.package.dest.dir>${project.build.directory}${sdk.plugin.related.dir}/../../../../skywalking-agent</agent.package.dest.dir>
+        <optional.agent.package.dest.dir>${agent.package.dest.dir}/optional-plugins</optional.agent.package.dest.dir>
+        <directory.plugins>apm-trace-ignore-plugin</directory.plugins>","[{'comment': '`directory.plugins` should not in root pom.xml', 'commenter': 'wu-sheng'}, {'comment': ""What's the better way to do that,  I need to determine which plugins are folders"", 'commenter': 'liu-junchi'}]"
1213,apm-sniffer/optional-plugins/pom.xml,"@@ -98,11 +102,22 @@
                         <configuration>
                             <tasks>
                                 <taskdef resource=""net/sf/antcontrib/antcontrib.properties"" classpathref=""maven.runtime.classpath"" />
+                                <mkdir dir=""${optional.agent.package.dest.dir}"" />
                                 <if>
                                     <equals arg1=""${project.packaging}"" arg2=""jar"" />
                                     <then>
-                                        <mkdir dir=""${plugin.dest.dir}"" />
-                                        <copy file=""${project.build.directory}/${project.artifactId}-${project.version}.jar"" tofile=""${plugin.dest.dir}/${project.artifactId}-${project.version}.jar"" overwrite=""true"" />
+                                        <if>
+                                            <!-- if the plugin is a directory -->","[{'comment': 'I am wondering, whether be better if put conf and jar in the `optional-plugins` dictionary directly? I feel strange about this part. Or do you have any suggestion?', 'commenter': 'wu-sheng'}, {'comment': ""Well, I think the meaning of this plugin may be somewhat confusing,\r\nOne is to integrate other components to achieve link tracking.\r\nThe other is to extend SPI's own behavior."", 'commenter': 'liu-junchi'}, {'comment': 'If there is a standard example of an extension to SPI, it may be clear.', 'commenter': 'liu-junchi'}, {'comment': 'I am not following. I just have concerns about this pom. Too many your plugin details expose to root pom.', 'commenter': 'wu-sheng'}]"
1213,apm-sniffer/optional-plugins/trace-ignore-plugin/pom.xml,"@@ -0,0 +1,78 @@
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>optional-plugins</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>5.0.0-beta-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-trace-ignore-plugin</artifactId>
+    <packaging>jar</packaging>
+
+    <name>apm-trace-ignore-plugin</name>
+    <url>http://maven.apache.org</url>
+
+
+    <build>
+        <plugins>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-antrun-plugin</artifactId>
+                <executions>
+                    <execution>
+                        <phase>package</phase>
+                        <goals>
+                            <goal>run</goal>
+                        </goals>
+                        <configuration>
+                            <tasks>
+                                <taskdef resource=""net/sf/antcontrib/antcontrib.properties"" classpathref=""maven.runtime.classpath"" />
+                                    <!-- copy config file -->
+                                    <copy file=""${project.basedir}/${project.name}.config"" tofile=""${optional.agent.package.dest.dir}/${project.name}/${project.name}.config"" overwrite=""true"" />
+                                    <!-- copy introduction -->
+                                    <copy file=""${project.basedir}/README.md"" tofile=""${optional.agent.package.dest.dir}/${project.name}/README.md"" overwrite=""true"" />
+                            </tasks>
+                        </configuration>
+                    </execution>
+                </executions>
+                <dependencies>
+                    <dependency>
+                        <groupId>ant-contrib</groupId>
+                        <artifactId>ant-contrib</artifactId>
+                        <version>1.0b3</version>
+                        <exclusions>
+                            <exclusion>
+                                <groupId>ant</groupId>
+                                <artifactId>ant</artifactId>
+                            </exclusion>
+                        </exclusions>
+                    </dependency>
+                    <dependency>
+                        <groupId>org.apache.ant</groupId>
+                        <artifactId>ant-nodeps</artifactId>
+                        <version>1.8.1</version>
+                    </dependency>","[{'comment': 'Would these two will in your optional jar? Could you provide a screenshot to show me what are in it?', 'commenter': 'wu-sheng'}, {'comment': 'If not, there should be a problem.\r\n\r\nIf so, you need to learn the policies about redistribution jars in Apache project.', 'commenter': 'wu-sheng'}, {'comment': ""My mistake, I'll fix that"", 'commenter': 'liu-junchi'}]"
1220,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -1,84 +1,90 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# ""License""); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-
-#cluster:
-#  zookeeper:
-#    hostPort: localhost:2181
-#    sessionTimeout: 100000
-naming:
-  jetty:
-    host: localhost
-    port: 10800
-    contextPath: /
-cache:
-#  guava:
-  caffeine:
-remote:
-  gRPC:
-    host: localhost
-    port: 11800
-agent_gRPC:
-  gRPC:
-    host: localhost
-    port: 11800
-    #Set these two setting to open ssl
-    #sslCertChainFile: $path
-    #sslPrivateKeyFile: $path
-
-    #Set your own token to active auth
-    #authentication: xxxxxx
-agent_jetty:
-  jetty:
-    host: localhost
-    port: 12800
-    contextPath: /
-analysis_register:
-  default:
-analysis_jvm:
-  default:
-analysis_segment_parser:
-  default:
-    bufferFilePath: ../buffer/
-    bufferOffsetMaxFileSize: 10M
-    bufferSegmentMaxFileSize: 500M
-ui:
-  jetty:
-    host: localhost
-    port: 12800
-    contextPath: /
-storage:
-  elasticsearch:
-    clusterName: CollectorDBCluster
-    clusterTransportSniffer: true
-    clusterNodes: localhost:9300
-    indexShardsNumber: 2
-    indexReplicasNumber: 0
-    highPerformanceMode: true
-    ttl: 7
-#storage:
-#  h2:
-#    url: jdbc:h2:~/memorydb
-#    userName: sa
-configuration:
-  default:
-#     namespace: xxxxx
-    applicationApdexThreshold: 2000
-    serviceErrorRateThreshold: 10.00
-    serviceAverageResponseTimeThreshold: 2000
-    instanceErrorRateThreshold: 10.00
-    instanceAverageResponseTimeThreshold: 2000
-    applicationErrorRateThreshold: 10.00
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#cluster:
+#  zookeeper:
+#    hostPort: localhost:2181
+#    sessionTimeout: 100000
+naming:
+  jetty:
+    host: localhost
+    port: 10800
+    contextPath: /
+cache:
+#  guava:
+  caffeine:
+remote:
+  gRPC:
+    host: localhost
+    port: 11800
+agent_gRPC:
+  gRPC:
+    host: localhost
+    port: 11800
+    #Set these two setting to open ssl
+    #sslCertChainFile: $path
+    #sslPrivateKeyFile: $path
+
+    #Set your own token to active auth
+    #authentication: xxxxxx
+agent_jetty:
+  jetty:
+    host: localhost
+    port: 12800
+    contextPath: /
+analysis_register:
+  default:
+analysis_jvm:
+  default:
+analysis_segment_parser:
+  default:
+    bufferFilePath: ../buffer/
+    bufferOffsetMaxFileSize: 10M
+    bufferSegmentMaxFileSize: 500M
+ui:
+  jetty:
+    host: localhost
+    port: 12800
+    contextPath: /
+storage:
+  elasticsearch:
+    clusterName: CollectorDBCluster
+    clusterTransportSniffer: true
+    clusterNodes: localhost:9300
+    indexShardsNumber: 2
+    indexReplicasNumber: 0
+    highPerformanceMode: true
+    ttl: 7
+#storage:
+#  h2:
+#    url: jdbc:h2:~/memorydb
+#    userName: sa
+#storage:
+#  shardingjdbc:","[{'comment': ""ShardingJDBC is an incubating feature, no use cases yet. And none of the contributors are committer yet. So, by that, please don't put Sharding JDBC in default application.yml. Even it is under comments."", 'commenter': 'wu-sheng'}]"
1220,apm-dist/release-docs/LICENSE,"@@ -255,6 +256,7 @@ The text of each license is also included at licenses/LICENSE-[project].txt.
     Apache: commons-configuration 1.8: https://github.com/apache/commons-configuration, Apache 2.0
     Apache: commons-io 2.4: https://github.com/apache/commons-io, Apache 2.0
     Apache: tomcat 8.5.27: https://github.com/apache/tomcat/tree/trunk, Apache 2.0
+    Apache: groovy 2.4.5-indy: https://github.com/apache/groovy, Apache 2.0","[{'comment': 'Groovy has a NOTICE file. Please change NOTICE in same folder. And follow the file structure. Ref here: https://github.com/apache/groovy/blob/master/NOTICE', 'commenter': 'wu-sheng'}]"
1220,docs/README.md,"@@ -1,45 +1,46 @@
-## Documents
-[![cn doc](https://img.shields.io/badge/document-中文-blue.svg)](README_ZH.md)
-
-  * Getting Started
-    * [Quick start](en/Quick-start.md)
-    * [Supported middlewares, frameworks and libraries](Supported-list.md)
-      * [How to disable plugins?](en/How-to-disable-plugin.md)
-  * Advanced Features
-    * [Override settings through System.properties or System.env](en/Setting-override.md)
-    * [Direct uplink and disable naming discovery](en/Direct-uplink.md)
-    * [Open TLS](en/TLS.md)
-    * [Namespace Isolation](en/Namespace.md)
-    * [Token Authentication](en/Token-auth.md)
-  * Incubating Features
-    * Abstract
-  * Application Toolkit
-    * [Overview](en/Applicaton-toolkit.md)
-    * [OpenTracing Tracer](en/Opentracing.md)
-    * Logging
-      * [log4j](en/Application-toolkit-log4j-1.x.md)
-      * [log4j2](en/Application-toolkit-log4j-2.x.md)
-      * [logback](en/Application-toolkit-logback-1.x.md)
-    * [Trace](en/Application-toolkit-trace.md)
-    * [Propagate Context across Thread](en/Application-toolkit-trace-cross-thread.md)
-  * Testing
-    * [Plugin Test](https://github.com/SkywalkingTest/agent-integration-test-report)
-    * [Java Agent Performance Test](https://skywalkingtest.github.io/Agent-Benchmarks/)
-  * Development Guides
-    * [How to build project](en/How-to-build.md)
-    * [Plugin development guide](en/Plugin-Development-Guide.md)
-    * Protocol
-      * [Cross Process Propagation Headers Protocol, v1.0](en/Skywalking-Cross-Process-Propagation-Headers-Protocol-v1.md)
-      * [SkyWalking Trace Data Protocol](en/Trace-Data-Protocol.md)
-    * [Release Guide](en/How-to-release.md)
-  * [Roadmap](ROADMAP.md)
-  * Resources provided by community
-    * [Public speakings](https://github.com/OpenSkywalking/Community#public-speakings)
-    * [Videos](https://github.com/OpenSkywalking/Community#videos)
-    * [Articles](https://github.com/OpenSkywalking/Community#articles)
-  * FAQ
-    * [Why only traces in UI?](en/FAQ/Why-have-traces-no-others.md)
-    * [Too many GRPC logs in the console](en/FAQ/Too-many-gRPC-logs.md)
-    * [The trace doesn't continue in kafka consumer side](en/FAQ/kafka-plugin.md)
-    * [Agent or collector version upgrade](en/FAQ/Upgrade.md)
-    
+## Documents
+[![cn doc](https://img.shields.io/badge/document-中文-blue.svg)](README_ZH.md)
+
+  * Getting Started
+    * [Quick start](en/Quick-start.md)
+    * [Supported middlewares, frameworks and libraries](Supported-list.md)
+      * [How to disable plugins?](en/How-to-disable-plugin.md)
+  * Advanced Features
+    * [Override settings through System.properties or System.env](en/Setting-override.md)
+    * [Direct uplink and disable naming discovery](en/Direct-uplink.md)
+    * [Open TLS](en/TLS.md)
+    * [Namespace Isolation](en/Namespace.md)
+    * [Token Authentication](en/Token-auth.md)
+    * [Open Database Sharding Storage](en/Shardingjdbc.md)","[{'comment': 'This should a section in `Incubating Features`. named: `Use Sharding JDBC as storage implementor`.', 'commenter': 'wu-sheng'}]"
1220,docs/en/Shardingjdbc.md,"@@ -0,0 +1,13 @@
+# Supported Database Sharding Storage
+Beside the default Elasticsearch storage, it also support the database sharding storage, it allow the users to store data in multiple databases.
+Note: it only supported MYSQL database sharding, and due to the license restrictions, the users need to import MYSQL Driver manually.
+
+## Supported version
+5.0.0-beta +
+
+## Requirement
+- Manually import MySQL Driver package mysql-connector-java-5.1.36.jar to collector-libs directory.","[{'comment': '`collector-libs` is not the directory name.', 'commenter': 'wu-sheng'}]"
1220,docs/en/Shardingjdbc.md,"@@ -0,0 +1,13 @@
+# Supported Database Sharding Storage
+Beside the default Elasticsearch storage, it also support the database sharding storage, it allow the users to store data in multiple databases.
+Note: it only supported MYSQL database sharding, and due to the license restrictions, the users need to import MYSQL Driver manually.
+
+## Supported version
+5.0.0-beta +
+
+## Requirement
+- Manually import MySQL Driver package mysql-connector-java-5.1.36.jar to collector-libs directory.
+- In config/application.yml, close the elasticsearch configuration and open the shardingjdbc configuration, multiple data source configurations should be separated by Half Comma.","[{'comment': 'Considering the sharding settings have been remove from application.yml. please add the settings in here.', 'commenter': 'wu-sheng'}]"
1220,docs/README_ZH.md,"@@ -1,42 +1,46 @@
-## 中文文档
-[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](README.md)
-
-  * 快速入门
-    * [快速入门](cn/Quick-start-CN.md)
-    * [中间件，框架与类库支持列表](Supported-list.md)
-        * [如何关闭特定插件](cn/How-to-disable-plugin-CN.md)
-  * 高级特性
-    * [通过系统启动参数进行覆盖配置](cn/Setting-override-CN.md)
-    * [服务直连(Direct uplink)及禁用名称服务(naming service)](cn/Direct-uplink-CN.md)
-    * [开启TLS](cn/TLS-CN.md)
-    * [命名空间隔离](cn/Namespace-CN.md)
-    * [基于Token认证](cn/Token-auth-CN.md)
-  * APM相关介绍资料
-    * [OpenTracing中文版](https://github.com/opentracing-contrib/opentracing-specification-zh)
-  * Application Toolkit，应用程序工具包
-    * [概述](cn/Application-toolkit-CN.md)
-    * [OpenTracing Tracer](cn/Opentracing-CN.md)
-    * 日志组件
-      * [log4j组件](cn/Application-toolkit-log4j-1.x-CN.md)
-      * [log4j2组件](cn/Application-toolkit-log4j-2.x-CN.md)
-      * [logback组件](cn/Application-toolkit-logback-1.x-CN.md)
-    * [Trace](cn/Application-toolkit-trace-CN.md)
-    * [调用链跨线程传递](cn/Application-toolkit-trace-cross-thread-CN.md) 
-  * 测试用例
-    * [插件测试](https://github.com/SkywalkingTest/agent-integration-test-report)
-    * [Java 探针性能测试](https://skywalkingtest.github.io/Agent-Benchmarks/README_zh.html)
-  * 开发指南
-    * [工程编译指南](cn/How-to-build-CN.md)
-    * [插件开发指南](cn/Plugin-Development-Guide-CN.md)
-    * 交互协议
-        * [Cross Process Propagation Headers Protocol, v1.0  跨进程追踪上下文传递协议](cn/Skywalking-Cross-Process-Propagation-Headers-Protocol-CN-v1.md)
-        * [SkyWalking Trace Data Protocol 探针与Collector间网络协议](cn/Trace-Data-Protocol-CN.md)
-  * [Roadmap](ROADMAP.md)
-  * 社区提供的共享资源
-    * [公开演讲](https://github.com/OpenSkywalking/Community#public-speakings)
-    * [视频](https://github.com/OpenSkywalking/Community#videos)
-    * [文章](https://github.com/OpenSkywalking/Community#articles)
-  * FAQ
-    * [Trace查询有数据，但是没有拓扑图和JVM数据?](cn/FAQ/Why-have-traces-no-others-CN.md)
-    * [加载探针，Console被GRPC日志刷屏](cn/FAQ/Too-many-gRPC-logs-CN.md)
-    * [Kafka消息消费端链路断裂](cn/FAQ/Kafka-plugin-CN.md)
+## 中文文档
+[![EN doc](https://img.shields.io/badge/document-English-blue.svg)](README.md)
+
+  * 快速入门
+    * [快速入门](cn/Quick-start-CN.md)
+    * [中间件，框架与类库支持列表](Supported-list.md)
+        * [如何关闭特定插件](cn/How-to-disable-plugin-CN.md)
+        * [可选插件](cn/Optional-plugins-CN.md)
+  * 高级特性
+    * [通过系统启动参数进行覆盖配置](cn/Setting-override-CN.md)
+    * [服务直连(Direct uplink)及禁用名称服务(naming service)](cn/Direct-uplink-CN.md)
+    * [开启TLS](cn/TLS-CN.md)
+    * [命名空间隔离](cn/Namespace-CN.md)
+    * [基于Token认证](cn/Token-auth-CN.md)
+    * [使用Shardingjdbc作为存储实现](cn/Shardingjdbc-CN.md)","[{'comment': 'In CN doc, also need an `孵化功能` section.', 'commenter': 'wu-sheng'}, {'comment': 'File name should not be shardingJDBC.  Should be: Use-ShardingJDBC-as-storage-implementor.md', 'commenter': 'wu-sheng'}]"
1220,docs/cn/Shardingjdbc-CN.md,"@@ -0,0 +1,21 @@
+# 支持数据库分片存储
+除了默认的Elasticsearch存储外，还支持数据库分片存储，允许用户将数据存储在多个数据库中。
+注意：目前仅支持MYSQL数据库的分片存储，且由于license限制，需要用户手动引入mysql驱动包。
+
+## 版本支持
+5.0.0-beta +","[{'comment': 'beta2? beta is under release process now.', 'commenter': 'wu-sheng'}]"
1220,docs/en/Shardingjdbc.md,"@@ -0,0 +1,21 @@
+# Supported Database Sharding Storage
+Beside the default Elasticsearch storage, it also support the database sharding storage, it allow the users to store data in multiple databases.
+Note: it only supported MYSQL database sharding, and due to the license restrictions, the users need to import MYSQL Driver manually.
+
+## Supported version
+5.0.0-beta +","[{'comment': 'beta2? beta is under release process now.', 'commenter': 'wu-sheng'}]"
1220,docs/en/Shardingjdbc.md,"@@ -0,0 +1,21 @@
+# Supported Database Sharding Storage
+Beside the default Elasticsearch storage, it also support the database sharding storage, it allow the users to store data in multiple databases.
+Note: it only supported MYSQL database sharding, and due to the license restrictions, the users need to import MYSQL Driver manually.
+
+## Supported version
+5.0.0-beta +
+
+## Requirement
+- Manually import MySQL Driver package mysql-connector-java-5.1.36.jar to collector libs directory.
+- In config/application.yml, close the elasticsearch configuration and open the shardingjdbc configuration, multiple data source configurations should be separated by Half Comma.
+``` javascript","[{'comment': 'It is a yml, not a javascript.', 'commenter': 'wu-sheng'}]"
1220,docs/cn/Shardingjdbc-CN.md,"@@ -0,0 +1,21 @@
+# 支持数据库分片存储
+除了默认的Elasticsearch存储外，还支持数据库分片存储，允许用户将数据存储在多个数据库中。
+注意：目前仅支持MYSQL数据库的分片存储，且由于license限制，需要用户手动引入mysql驱动包。
+
+## 版本支持
+5.0.0-beta +
+
+## 配置要求
+- 手工导入MYSQL的驱动包mysql-connector-java-5.1.36.jar到collector libs目录下。
+- config/application.yml中，关闭elasticsearch配置，打开shardingjdbc配置，多个数据源配置用半角逗号隔开。
+``` javascript","[{'comment': 'It is a yml, not a javascript.', 'commenter': 'wu-sheng'}]"
1220,apm-collector/apm-collector-storage/collector-storage-define/src/main/java/org/apache/skywalking/apm/collector/storage/dao/ui/IServiceReferenceMetricUIDAO.java,"@@ -1,142 +1,142 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-package org.apache.skywalking.apm.collector.storage.dao.ui;
-
-import java.util.List;
-import org.apache.skywalking.apm.collector.storage.base.dao.DAO;
-import org.apache.skywalking.apm.collector.storage.table.MetricSource;
-import org.apache.skywalking.apm.collector.storage.ui.common.Step;
-
-/**
- * Interface to be implemented for execute database query operation
- * from {@link org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable#TABLE}.
- *
- * @author peng-yongsheng
- * @see org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable
- * @see org.apache.skywalking.apm.collector.storage.StorageModule
- */
-public interface IServiceReferenceMetricUIDAO extends DAO {
-
-    /**
-     * Returns the service reference metrics which call the given service id
-     * that collected between start time bucket and end time bucket.
-     *
-     * <p>SQL as: select FRONT_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),
-     * sum(TRANSACTION_DURATION_SUM), sum(TRANSACTION_ERROR_DURATION_SUM)
-     * from SERVICE_REFERENCE_METRIC
-     * where TIME_BUCKET ge ${startTimeBucket} and TIME_BUCKET le ${endTimeBucket}
-     * and SOURCE_VALUE = ${metricSource}
-     * and BEHIND_SERVICE_ID = ${behindServiceId}
-     * group by FRONT_SERVICE_ID
-     *
-     * <p>Use {@link org.apache.skywalking.apm.collector.storage.utils.TimePyramidTableNameBuilder#build(Step, String)}
-     * to generate table name which mixed with step name.
-     *
-     * @param step the step which represent time formats
-     * @param startTimeBucket start time bucket
-     * @param endTimeBucket end time bucket
-     * @param metricSource source of this metric, server side or client side
-     * @param behindServiceId the callee service id
-     * @return not nullable result list
-     */
-    List<ServiceReferenceMetric> getFrontServices(Step step, long startTimeBucket, long endTimeBucket,
-        MetricSource metricSource, int behindServiceId);
-
-    /**
-     * Returns the service reference metrics which call from the given service id
-     * that collected between start time bucket and end time bucket.
-     *
-     * <p>SQL as: select FRONT_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),
-     * sum(TRANSACTION_DURATION_SUM), sum(TRANSACTION_ERROR_DURATION_SUM)
-     * from SERVICE_REFERENCE_METRIC
-     * where TIME_BUCKET ge ${startTimeBucket} and TIME_BUCKET le ${endTimeBucket}
-     * and SOURCE_VALUE = ${metricSource}
-     * and BEHIND_SERVICE_ID = ${frontServiceId}
-     * group by BEHIND_SERVICE_ID
-     *
-     * <p>Use {@link org.apache.skywalking.apm.collector.storage.utils.TimePyramidTableNameBuilder#build(Step, String)}
-     * to generate table name which mixed with step name.
-     *
-     * @param step the step which represent time formats
-     * @param startTimeBucket start time bucket
-     * @param endTimeBucket end time bucket
-     * @param metricSource source of this metric, server side or client side
-     * @param frontServiceId the caller service id
-     * @return not nullable result list
-     */
-    List<ServiceReferenceMetric> getBehindServices(Step step, long startTimeBucket, long endTimeBucket,
-        MetricSource metricSource, int frontServiceId);
-
-    class ServiceReferenceMetric {
-        private int source;
-        private int target;
-        private long calls;
-        private long errorCalls;
-        private long durations;
-        private long errorDurations;
-
-        public int getSource() {
-            return source;
-        }
-
-        public void setSource(int source) {
-            this.source = source;
-        }
-
-        public int getTarget() {
-            return target;
-        }
-
-        public void setTarget(int target) {
-            this.target = target;
-        }
-
-        public long getCalls() {
-            return calls;
-        }
-
-        public void setCalls(long calls) {
-            this.calls = calls;
-        }
-
-        public long getErrorCalls() {
-            return errorCalls;
-        }
-
-        public void setErrorCalls(long errorCalls) {
-            this.errorCalls = errorCalls;
-        }
-
-        public long getDurations() {
-            return durations;
-        }
-
-        public void setDurations(long durations) {
-            this.durations = durations;
-        }
-
-        public long getErrorDurations() {
-            return errorDurations;
-        }
-
-        public void setErrorDurations(long errorDurations) {
-            this.errorDurations = errorDurations;
-        }
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.collector.storage.dao.ui;
+
+import java.util.List;
+import org.apache.skywalking.apm.collector.storage.base.dao.DAO;
+import org.apache.skywalking.apm.collector.storage.table.MetricSource;
+import org.apache.skywalking.apm.collector.storage.ui.common.Step;
+
+/**
+ * Interface to be implemented for execute database query operation
+ * from {@link org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable#TABLE}.
+ *
+ * @author peng-yongsheng
+ * @see org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable
+ * @see org.apache.skywalking.apm.collector.storage.StorageModule
+ */
+public interface IServiceReferenceMetricUIDAO extends DAO {
+
+    /**
+     * Returns the service reference metrics which call the given service id
+     * that collected between start time bucket and end time bucket.
+     *
+     * <p>SQL as: select BEHIND_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),","[{'comment': ""This method's definition is query front services and their metrics by passing parameter which named behind service id. The sample sql is correct."", 'commenter': 'peng-yongsheng'}]"
1220,apm-collector/apm-collector-storage/collector-storage-define/src/main/java/org/apache/skywalking/apm/collector/storage/dao/ui/IServiceReferenceMetricUIDAO.java,"@@ -1,142 +1,142 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *     http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- *
- */
-
-package org.apache.skywalking.apm.collector.storage.dao.ui;
-
-import java.util.List;
-import org.apache.skywalking.apm.collector.storage.base.dao.DAO;
-import org.apache.skywalking.apm.collector.storage.table.MetricSource;
-import org.apache.skywalking.apm.collector.storage.ui.common.Step;
-
-/**
- * Interface to be implemented for execute database query operation
- * from {@link org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable#TABLE}.
- *
- * @author peng-yongsheng
- * @see org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable
- * @see org.apache.skywalking.apm.collector.storage.StorageModule
- */
-public interface IServiceReferenceMetricUIDAO extends DAO {
-
-    /**
-     * Returns the service reference metrics which call the given service id
-     * that collected between start time bucket and end time bucket.
-     *
-     * <p>SQL as: select FRONT_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),
-     * sum(TRANSACTION_DURATION_SUM), sum(TRANSACTION_ERROR_DURATION_SUM)
-     * from SERVICE_REFERENCE_METRIC
-     * where TIME_BUCKET ge ${startTimeBucket} and TIME_BUCKET le ${endTimeBucket}
-     * and SOURCE_VALUE = ${metricSource}
-     * and BEHIND_SERVICE_ID = ${behindServiceId}
-     * group by FRONT_SERVICE_ID
-     *
-     * <p>Use {@link org.apache.skywalking.apm.collector.storage.utils.TimePyramidTableNameBuilder#build(Step, String)}
-     * to generate table name which mixed with step name.
-     *
-     * @param step the step which represent time formats
-     * @param startTimeBucket start time bucket
-     * @param endTimeBucket end time bucket
-     * @param metricSource source of this metric, server side or client side
-     * @param behindServiceId the callee service id
-     * @return not nullable result list
-     */
-    List<ServiceReferenceMetric> getFrontServices(Step step, long startTimeBucket, long endTimeBucket,
-        MetricSource metricSource, int behindServiceId);
-
-    /**
-     * Returns the service reference metrics which call from the given service id
-     * that collected between start time bucket and end time bucket.
-     *
-     * <p>SQL as: select FRONT_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),
-     * sum(TRANSACTION_DURATION_SUM), sum(TRANSACTION_ERROR_DURATION_SUM)
-     * from SERVICE_REFERENCE_METRIC
-     * where TIME_BUCKET ge ${startTimeBucket} and TIME_BUCKET le ${endTimeBucket}
-     * and SOURCE_VALUE = ${metricSource}
-     * and BEHIND_SERVICE_ID = ${frontServiceId}
-     * group by BEHIND_SERVICE_ID
-     *
-     * <p>Use {@link org.apache.skywalking.apm.collector.storage.utils.TimePyramidTableNameBuilder#build(Step, String)}
-     * to generate table name which mixed with step name.
-     *
-     * @param step the step which represent time formats
-     * @param startTimeBucket start time bucket
-     * @param endTimeBucket end time bucket
-     * @param metricSource source of this metric, server side or client side
-     * @param frontServiceId the caller service id
-     * @return not nullable result list
-     */
-    List<ServiceReferenceMetric> getBehindServices(Step step, long startTimeBucket, long endTimeBucket,
-        MetricSource metricSource, int frontServiceId);
-
-    class ServiceReferenceMetric {
-        private int source;
-        private int target;
-        private long calls;
-        private long errorCalls;
-        private long durations;
-        private long errorDurations;
-
-        public int getSource() {
-            return source;
-        }
-
-        public void setSource(int source) {
-            this.source = source;
-        }
-
-        public int getTarget() {
-            return target;
-        }
-
-        public void setTarget(int target) {
-            this.target = target;
-        }
-
-        public long getCalls() {
-            return calls;
-        }
-
-        public void setCalls(long calls) {
-            this.calls = calls;
-        }
-
-        public long getErrorCalls() {
-            return errorCalls;
-        }
-
-        public void setErrorCalls(long errorCalls) {
-            this.errorCalls = errorCalls;
-        }
-
-        public long getDurations() {
-            return durations;
-        }
-
-        public void setDurations(long durations) {
-            this.durations = durations;
-        }
-
-        public long getErrorDurations() {
-            return errorDurations;
-        }
-
-        public void setErrorDurations(long errorDurations) {
-            this.errorDurations = errorDurations;
-        }
-    }
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.collector.storage.dao.ui;
+
+import java.util.List;
+import org.apache.skywalking.apm.collector.storage.base.dao.DAO;
+import org.apache.skywalking.apm.collector.storage.table.MetricSource;
+import org.apache.skywalking.apm.collector.storage.ui.common.Step;
+
+/**
+ * Interface to be implemented for execute database query operation
+ * from {@link org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable#TABLE}.
+ *
+ * @author peng-yongsheng
+ * @see org.apache.skywalking.apm.collector.storage.table.service.ServiceReferenceMetricTable
+ * @see org.apache.skywalking.apm.collector.storage.StorageModule
+ */
+public interface IServiceReferenceMetricUIDAO extends DAO {
+
+    /**
+     * Returns the service reference metrics which call the given service id
+     * that collected between start time bucket and end time bucket.
+     *
+     * <p>SQL as: select BEHIND_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),
+     * sum(TRANSACTION_DURATION_SUM), sum(TRANSACTION_ERROR_DURATION_SUM)
+     * from SERVICE_REFERENCE_METRIC
+     * where TIME_BUCKET ge ${startTimeBucket} and TIME_BUCKET le ${endTimeBucket}
+     * and SOURCE_VALUE = ${metricSource}
+     * and FRONT_SERVICE_ID = ${behindServiceId}
+     * group by FRONT_SERVICE_ID
+     *
+     * <p>Use {@link org.apache.skywalking.apm.collector.storage.utils.TimePyramidTableNameBuilder#build(Step, String)}
+     * to generate table name which mixed with step name.
+     *
+     * @param step the step which represent time formats
+     * @param startTimeBucket start time bucket
+     * @param endTimeBucket end time bucket
+     * @param metricSource source of this metric, server side or client side
+     * @param behindServiceId the callee service id
+     * @return not nullable result list
+     */
+    List<ServiceReferenceMetric> getFrontServices(Step step, long startTimeBucket, long endTimeBucket,
+        MetricSource metricSource, int behindServiceId);
+
+    /**
+     * Returns the service reference metrics which call from the given service id
+     * that collected between start time bucket and end time bucket.
+     *
+     * <p>SQL as: select BEHIND_SERVICE_ID, sum(TRANSACTION_CALLS), sum(TRANSACTION_ERROR_CALLS),","[{'comment': 'Ditto', 'commenter': 'peng-yongsheng'}]"
1255,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/dao/ui/SegmentDurationEsUIDAO.java,"@@ -73,16 +75,30 @@ public TraceBrief loadTop(long startSecondTimeBucket, long endSecondTimeBucket,
             boolQueryBuilder.must().add(rangeQueryBuilder);
         }
         if (StringUtils.isNotEmpty(operationName)) {
-            mustQueryList.add(QueryBuilders.matchPhraseQuery(SegmentDurationTable.SERVICE_NAME.getName(), operationName));
+            mustQueryList.add(QueryBuilders.matchQuery(SegmentDurationTable.SERVICE_NAME.getName(), operationName));
         }
         if (CollectionUtils.isNotEmpty(segmentIds)) {
             boolQueryBuilder.must().add(QueryBuilders.termsQuery(SegmentDurationTable.SEGMENT_ID.getName(), segmentIds));
         }
         if (applicationId != 0) {
             boolQueryBuilder.must().add(QueryBuilders.termQuery(SegmentDurationTable.APPLICATION_ID.getName(), applicationId));
         }
-
-        searchRequestBuilder.addSort(SegmentDurationTable.START_TIME.getName(), SortOrder.DESC);
+        switch (traceState) {
+            case ERROR:
+                mustQueryList.add(QueryBuilders.matchQuery(SegmentDurationTable.IS_ERROR.getName(), 1));","[{'comment': '1  -> BooleanUtils.TRUE', 'commenter': 'peng-yongsheng'}, {'comment': 'Changed it.', 'commenter': 'ajanthan'}]"
1255,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/dao/ui/SegmentDurationEsUIDAO.java,"@@ -73,16 +75,30 @@ public TraceBrief loadTop(long startSecondTimeBucket, long endSecondTimeBucket,
             boolQueryBuilder.must().add(rangeQueryBuilder);
         }
         if (StringUtils.isNotEmpty(operationName)) {
-            mustQueryList.add(QueryBuilders.matchPhraseQuery(SegmentDurationTable.SERVICE_NAME.getName(), operationName));
+            mustQueryList.add(QueryBuilders.matchQuery(SegmentDurationTable.SERVICE_NAME.getName(), operationName));
         }
         if (CollectionUtils.isNotEmpty(segmentIds)) {
             boolQueryBuilder.must().add(QueryBuilders.termsQuery(SegmentDurationTable.SEGMENT_ID.getName(), segmentIds));
         }
         if (applicationId != 0) {
             boolQueryBuilder.must().add(QueryBuilders.termQuery(SegmentDurationTable.APPLICATION_ID.getName(), applicationId));
         }
-
-        searchRequestBuilder.addSort(SegmentDurationTable.START_TIME.getName(), SortOrder.DESC);
+        switch (traceState) {
+            case ERROR:
+                mustQueryList.add(QueryBuilders.matchQuery(SegmentDurationTable.IS_ERROR.getName(), 1));
+                break;
+            case SUCCESS:
+                mustQueryList.add(QueryBuilders.matchQuery(SegmentDurationTable.IS_ERROR.getName(), 0));","[{'comment': '0 -> BooleanUtils.FALSE', 'commenter': 'peng-yongsheng'}, {'comment': 'Changed it.', 'commenter': 'ajanthan'}]"
1255,apm-collector/apm-collector-storage/collector-storage-h2-provider/src/main/java/org/apache/skywalking/apm/collector/storage/h2/dao/ui/SegmentDurationH2UIDAO.java,"@@ -90,8 +92,30 @@ public TraceBrief loadTop(long startSecondTimeBucket, long endSecondTimeBucket,
             params.add(applicationId);
             columns.add(SegmentDurationTable.APPLICATION_ID.getName());
         }
+        if (traceState != null) {
+            paramIndex++;
+            sql = sql + "" and {"" + paramIndex + ""} = ?"";
+            switch (traceState) {
+                case ERROR:
+                    params.add(1);","[{'comment': 'ditto', 'commenter': 'peng-yongsheng'}]"
1255,apm-collector/apm-collector-storage/collector-storage-h2-provider/src/main/java/org/apache/skywalking/apm/collector/storage/h2/dao/ui/SegmentDurationH2UIDAO.java,"@@ -90,8 +92,30 @@ public TraceBrief loadTop(long startSecondTimeBucket, long endSecondTimeBucket,
             params.add(applicationId);
             columns.add(SegmentDurationTable.APPLICATION_ID.getName());
         }
+        if (traceState != null) {
+            paramIndex++;
+            sql = sql + "" and {"" + paramIndex + ""} = ?"";
+            switch (traceState) {
+                case ERROR:
+                    params.add(1);
+                    break;
+                case SUCCESS:
+                    params.add(0);","[{'comment': 'ditto', 'commenter': 'peng-yongsheng'}]"
1255,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/dao/ui/SegmentDurationEsUIDAO.java,"@@ -73,16 +75,30 @@ public TraceBrief loadTop(long startSecondTimeBucket, long endSecondTimeBucket,
             boolQueryBuilder.must().add(rangeQueryBuilder);
         }
         if (StringUtils.isNotEmpty(operationName)) {
-            mustQueryList.add(QueryBuilders.matchPhraseQuery(SegmentDurationTable.SERVICE_NAME.getName(), operationName));
+            mustQueryList.add(QueryBuilders.matchQuery(SegmentDurationTable.SERVICE_NAME.getName(), operationName));","[{'comment': 'I forgot why chose the method matchPhraseQuery before. Please ensure these two service names can be searched by the method  matchQuery.\r\n1. org.skywaking.apm.testcase.dubbo.services.GreetService.doBusiness()\r\n2. /dubbox-case/case/dubbox-rest', 'commenter': 'peng-yongsheng'}, {'comment': '`matchPhraseQuery` is from #1194 . @ajanthan Why do you use `matchQuery`?', 'commenter': 'wu-sheng'}, {'comment': 'It is a mistake. Fixed it in the latest pull request.', 'commenter': 'ajanthan'}]"
1264,docs/en/FAQ/Import-Project-Eclipse-RequireItems-Exception.md,"@@ -0,0 +1,16 @@
+### Problem
+- import skywalking project to eclipse,below error occurs:
+- Cannot complete the install because one or more required items could not be found.
+  Software being installed: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group 
+  1.0.0.201705301746)
+  Missing requirement: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group  
+  1.0.0.201705301746) requires 'net.sf.eclipsecs.core 5.2.0' but it could not be found
+
+### reason
+uninstall Eclipse Checkstyle Plug-in","[{'comment': ""Haven't installed...."", 'commenter': 'wu-sheng'}]"
1264,docs/README.md,"@@ -47,5 +47,6 @@
     * [Agent or collector version upgrade](en/FAQ/Upgrade.md)
     * [Protoc plugin fails in maven build](en/FAQ/Protoc-Plugin-Fails-When-Build.md)
     * [EnhanceRequireObjectCache class cast exception](en/FAQ/EnhanceRequireObjectCache-Cast-Exception.md)
+    * [Import Project Eclipse requireItems exception ](en/FAQ/Import-Project-Eclipse-RequireItems-Exception.md) ","[{'comment': 'Required items could not be found, when import project into Eclipse.', 'commenter': 'wu-sheng'}]"
1264,docs/en/FAQ/Import-Project-Eclipse-RequireItems-Exception.md,"@@ -0,0 +1,16 @@
+### Problem
+- import skywalking project to eclipse,below error occurs:","[{'comment': 'Import..... into Eclipse. Occur following errors', 'commenter': 'wu-sheng'}]"
1264,docs/en/FAQ/Import-Project-Eclipse-RequireItems-Exception.md,"@@ -0,0 +1,16 @@
+### Problem
+- import skywalking project to eclipse,below error occurs:
+- Cannot complete the install because one or more required items could not be found.
+  Software being installed: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group 
+  1.0.0.201705301746)
+  Missing requirement: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group  
+  1.0.0.201705301746) requires 'net.sf.eclipsecs.core 5.2.0' but it could not be found","[{'comment': 'Use markdown code section to tag these errors. Use this ```', 'commenter': 'wu-sheng'}]"
1264,docs/en/FAQ/Import-Project-Eclipse-RequireItems-Exception.md,"@@ -0,0 +1,16 @@
+### Problem
+- import skywalking project to eclipse,below error occurs:
+- Cannot complete the install because one or more required items could not be found.
+  Software being installed: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group 
+  1.0.0.201705301746)
+  Missing requirement: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group  
+  1.0.0.201705301746) requires 'net.sf.eclipsecs.core 5.2.0' but it could not be found
+
+### reason
+uninstall Eclipse Checkstyle Plug-in
+
+### Resolve
+download the plugin by the link:https://sourceforge.net/projects/eclipse-cs/?source=typ_redirect，Eclipse Checkstyle Plug-in version:8.7.0.201801131309 slove the problem。","[{'comment': 'Download .... through the link .....\r\nEclipse ... plugin required.', 'commenter': 'wu-sheng'}]"
1264,docs/en/FAQ/Import-Project-Eclipse-RequireItems-Exception.md,"@@ -1,16 +1,15 @@
 ### Problem
-- import skywalking project to eclipse,below error occurs:
-- Cannot complete the install because one or more required items could not be found.
-  Software being installed: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group 
-  1.0.0.201705301746)
-  Missing requirement: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group  
-  1.0.0.201705301746) requires 'net.sf.eclipsecs.core 5.2.0' but it could not be found
+- Import skywalking project to Eclipse,Occur following errors:
++  Software being installed: Checkstyle configuration plugin for M2Eclipse 1.0.0.201705301746 (com.basistech.m2e.code.quality.checkstyle.feature.feature.group ","[{'comment': 'You still miss using markdown style to quote the errors.', 'commenter': 'wu-sheng'}]"
1265,docs/README.md,"@@ -15,6 +15,7 @@
     * [Add your own component library settings in collector](en/Component-libraries-extend.md)
   * Incubating Features
     * [Abstract](en/Incubating/Abstract.md)
+    * [Trace Ignore Enhance](en/Incubating/trace-ignore-enhance.md)","[{'comment': 'Support custom trace ignore', 'commenter': 'wu-sheng'}]"
1265,docs/README_ZH.md,"@@ -12,6 +12,8 @@
     * [开启TLS](cn/TLS-CN.md)
     * [命名空间隔离](cn/Namespace-CN.md)
     * [基于Token认证](cn/Token-auth-CN.md)
+  * 孵化特性
+    * [追踪忽略增强](cn/Incubating/trace-ignore-enhance-CN.md)","[{'comment': '个性化服务过滤', 'commenter': 'wu-sheng'}]"
1265,docs/en/Incubating/trace-ignore-enhance.md,"@@ -0,0 +1,8 @@
+# Trace ignore enhance
+Here is an optional plugin `apm-trace-ignore-plugin`
+
+## Introduce
+- It's provided to enhance the tracing ignores.
+- You can set multiple paths then these paths will be ignored, means the `agent` won't send the `TraceContext` to `collector`.","[{'comment': ""won't send traces to collector."", 'commenter': 'wu-sheng'}]"
1265,docs/en/Incubating/trace-ignore-enhance.md,"@@ -0,0 +1,8 @@
+# Trace ignore enhance
+Here is an optional plugin `apm-trace-ignore-plugin`
+
+## Introduce
+- It's provided to enhance the tracing ignores.
+- You can set multiple paths then these paths will be ignored, means the `agent` won't send the `TraceContext` to `collector`.
+- The current matching rule follow `Ant Path Match` , like `/path/*`, `/path/**`, `/path/?`.","[{'comment': 'follows .....match style.', 'commenter': 'wu-sheng'}]"
1265,apm-sniffer/optional-plugins/trace-ignore-plugin/README.md,"@@ -1,6 +1,19 @@
-#How to use trace ignore plugin
-Please copy the apm-trace-ignore-plugin-x.jar to `agent/plugins`
+## Support custom trace ignore
+Here is an optional plugin `apm-trace-ignore-plugin`
+
+## Introduce
+- The role of this plugin is to filter personalized services that are tracked.
+- You can set up a number of paths that need to be ignored, means the `agent` won't send the traces to `collector`.
+- The current matching rule follows `Ant Path` match style , like `/path/*`, `/path/**`, `/path/?`.
+- Copy `apm-trace-ignore-plugin-x.jar` to `agent/plugins`, restarting the `agent` can take effect.
+- [Skywalking-使用可选插件 apm-trace-ignore-plugin](https://blog.csdn.net/u013095337/article/details/80452088) have a detailed introduction.","[{'comment': ""Don't put the Chinese article in English docs. Remove it unless you have or want to write an En version."", 'commenter': 'wu-sheng'}, {'comment': ' OK~~', 'commenter': 'liu-junchi'}]"
1268,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -68,7 +68,11 @@ storage:
     indexShardsNumber: 2
     indexReplicasNumber: 0
     highPerformanceMode: true
-    ttl: 7
+    # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted.","[{'comment': 'Set TTL(time to live) for metrics. Metrics will be deleted after expired.', 'commenter': 'wu-sheng'}, {'comment': 'Same meaning. ', 'commenter': 'peng-yongsheng'}, {'comment': 'I mentioned this for English only.', 'commenter': 'wu-sheng'}]"
1268,apm-collector/apm-collector-boot/src/main/resources/application.yml,"@@ -68,7 +68,11 @@ storage:
     indexShardsNumber: 2
     indexReplicasNumber: 0
     highPerformanceMode: true
-    ttl: 7
+    # Set a timeout on metric data. After the timeout has expired, the metric data will automatically be deleted.
+    minuteMetricDataTTL: 45 # Unit is minute
+    hourMetricDataTTL: 36 # Unit is hour
+    dayMetricDataTTL: 45 # Unit is day
+    monthMetricDataTTL: 18 # Unit is month","[{'comment': 'I suggest you remove `Data` from the key. Because metric is data related only.', 'commenter': 'wu-sheng'}, {'comment': 'From my code review, remove trace based on `minuteMetricDataTTL`. Then I recommend you to provide a traceTTL.', 'commenter': 'wu-sheng'}, {'comment': ""> I suggest you remove Data from the key. Because metric is data related only.\r\n\r\nI'm not sure who is correct? I search `metric data` in Baidu and Google, The `metric data` and `metric` in articles are on the same frequency."", 'commenter': 'peng-yongsheng'}, {'comment': 'Because almost all settings in storage is data related.  Your decision.', 'commenter': 'wu-sheng'}]"
1268,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/DataTTLKeeperTimer.java,"@@ -51,190 +50,181 @@
     private final ModuleManager moduleManager;
     private final StorageModuleEsNamingListener namingListener;
     private final String selfAddress;
-    private final int daysBefore;
+    private int minuteMetricDataTTL = 45;
+    private int hourMetricDataTTL = 36;
+    private int dayMetricDataTTL = 45;
+    private int monthMetricDataTTL = 18;
 
     DataTTLKeeperTimer(ModuleManager moduleManager,
-        StorageModuleEsNamingListener namingListener, String selfAddress, int daysBefore) {
+        StorageModuleEsNamingListener namingListener, String selfAddress) {
         this.moduleManager = moduleManager;
         this.namingListener = namingListener;
         this.selfAddress = selfAddress;
-        this.daysBefore = daysBefore;
     }
 
     void start() {
         Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(
             new RunnableWithExceptionProtection(this::delete,
-                t -> logger.error(""Remove data in background failure."", t)), 1, 8, TimeUnit.HOURS);
+                t -> logger.error(""Remove data in background failure."", t)), 1, 5, TimeUnit.MINUTES);
     }
 
     private void delete() {
-        if (!namingListener.getAddresses().iterator().next().equals(selfAddress)) {
+        String firstAddressInCluster = namingListener.getAddresses().iterator().next();
+        if (!firstAddressInCluster.equals(selfAddress)) {
+            logger.info(""Self address is {}, first address in cluster is {}, not same, skip."", selfAddress, firstAddressInCluster);","[{'comment': ""Current address {} isn't same with the selected first address is {}. Skip."", 'commenter': 'wu-sheng'}]"
1268,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/DataTTLKeeperTimer.java,"@@ -51,190 +50,181 @@
     private final ModuleManager moduleManager;
     private final StorageModuleEsNamingListener namingListener;
     private final String selfAddress;
-    private final int daysBefore;
+    private int minuteMetricDataTTL = 45;
+    private int hourMetricDataTTL = 36;
+    private int dayMetricDataTTL = 45;
+    private int monthMetricDataTTL = 18;
 
     DataTTLKeeperTimer(ModuleManager moduleManager,
-        StorageModuleEsNamingListener namingListener, String selfAddress, int daysBefore) {
+        StorageModuleEsNamingListener namingListener, String selfAddress) {
         this.moduleManager = moduleManager;
         this.namingListener = namingListener;
         this.selfAddress = selfAddress;
-        this.daysBefore = daysBefore;
     }
 
     void start() {
         Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(
             new RunnableWithExceptionProtection(this::delete,
-                t -> logger.error(""Remove data in background failure."", t)), 1, 8, TimeUnit.HOURS);
+                t -> logger.error(""Remove data in background failure."", t)), 1, 5, TimeUnit.MINUTES);
     }
 
     private void delete() {
-        if (!namingListener.getAddresses().iterator().next().equals(selfAddress)) {
+        String firstAddressInCluster = namingListener.getAddresses().iterator().next();
+        if (!firstAddressInCluster.equals(selfAddress)) {
+            logger.info(""Self address is {}, first address in cluster is {}, not same, skip."", selfAddress, firstAddressInCluster);
             return;
         }
 
-        TimeBuckets timeBuckets = convertTimeBucket();
+        TimeBuckets timeBuckets = convertTimeBucket(new DateTime());
+        logger.info(""Beginning automatically removed metric data from the storage which they were expires"");","[{'comment': 'Beginning to remove expired metrics from the storage.', 'commenter': 'wu-sheng'}, {'comment': 'for always\r\n` Beginning to remove expired metrics from the storage.\r\n Metrics in minute dimension before 201811290715, are going to be removed.\r\nMetrics in hour dimension before 2018112720, are going to be removed.\r\nMetrics in day dimension before 20181015, are going to be removed.\r\n Metrics in month dimension before 201705, are going to be removed.`', 'commenter': 'liliang8858'}]"
1268,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/DataTTLKeeperTimer.java,"@@ -51,190 +50,181 @@
     private final ModuleManager moduleManager;
     private final StorageModuleEsNamingListener namingListener;
     private final String selfAddress;
-    private final int daysBefore;
+    private int minuteMetricDataTTL = 45;
+    private int hourMetricDataTTL = 36;
+    private int dayMetricDataTTL = 45;
+    private int monthMetricDataTTL = 18;
 
     DataTTLKeeperTimer(ModuleManager moduleManager,
-        StorageModuleEsNamingListener namingListener, String selfAddress, int daysBefore) {
+        StorageModuleEsNamingListener namingListener, String selfAddress) {
         this.moduleManager = moduleManager;
         this.namingListener = namingListener;
         this.selfAddress = selfAddress;
-        this.daysBefore = daysBefore;
     }
 
     void start() {
         Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(
             new RunnableWithExceptionProtection(this::delete,
-                t -> logger.error(""Remove data in background failure."", t)), 1, 8, TimeUnit.HOURS);
+                t -> logger.error(""Remove data in background failure."", t)), 1, 5, TimeUnit.MINUTES);
     }
 
     private void delete() {
-        if (!namingListener.getAddresses().iterator().next().equals(selfAddress)) {
+        String firstAddressInCluster = namingListener.getAddresses().iterator().next();
+        if (!firstAddressInCluster.equals(selfAddress)) {
+            logger.info(""Self address is {}, first address in cluster is {}, not same, skip."", selfAddress, firstAddressInCluster);
             return;
         }
 
-        TimeBuckets timeBuckets = convertTimeBucket();
+        TimeBuckets timeBuckets = convertTimeBucket(new DateTime());
+        logger.info(""Beginning automatically removed metric data from the storage which they were expires"");
+        logger.info(""The expires minute time bucket is: {}"", timeBuckets.minuteTimeBucketBefore);","[{'comment': 'Metrics in minute dimension before {},  are going to be removed.', 'commenter': 'wu-sheng'}]"
1268,apm-collector/apm-collector-storage/collector-storage-es-provider/src/main/java/org/apache/skywalking/apm/collector/storage/es/DataTTLKeeperTimer.java,"@@ -51,190 +50,181 @@
     private final ModuleManager moduleManager;
     private final StorageModuleEsNamingListener namingListener;
     private final String selfAddress;
-    private final int daysBefore;
+    private int minuteMetricDataTTL = 45;
+    private int hourMetricDataTTL = 36;
+    private int dayMetricDataTTL = 45;
+    private int monthMetricDataTTL = 18;
 
     DataTTLKeeperTimer(ModuleManager moduleManager,
-        StorageModuleEsNamingListener namingListener, String selfAddress, int daysBefore) {
+        StorageModuleEsNamingListener namingListener, String selfAddress) {
         this.moduleManager = moduleManager;
         this.namingListener = namingListener;
         this.selfAddress = selfAddress;
-        this.daysBefore = daysBefore;
     }
 
     void start() {
         Executors.newSingleThreadScheduledExecutor().scheduleAtFixedRate(
             new RunnableWithExceptionProtection(this::delete,
-                t -> logger.error(""Remove data in background failure."", t)), 1, 8, TimeUnit.HOURS);
+                t -> logger.error(""Remove data in background failure."", t)), 1, 5, TimeUnit.MINUTES);
     }
 
     private void delete() {
-        if (!namingListener.getAddresses().iterator().next().equals(selfAddress)) {
+        String firstAddressInCluster = namingListener.getAddresses().iterator().next();
+        if (!firstAddressInCluster.equals(selfAddress)) {
+            logger.info(""Self address is {}, first address in cluster is {}, not same, skip."", selfAddress, firstAddressInCluster);
             return;
         }
 
-        TimeBuckets timeBuckets = convertTimeBucket();
+        TimeBuckets timeBuckets = convertTimeBucket(new DateTime());
+        logger.info(""Beginning automatically removed metric data from the storage which they were expires"");
+        logger.info(""The expires minute time bucket is: {}"", timeBuckets.minuteTimeBucketBefore);
+        logger.info(""The expires hour time bucket is: {}"", timeBuckets.hourTimeBucketBefore);
+        logger.info(""The expires day time bucket is: {}"", timeBuckets.dayTimeBucketBefore);
+        logger.info(""The expires month time bucket is: {}"", timeBuckets.monthTimeBucketBefore);","[{'comment': 'hour/day/month should be in same log style.', 'commenter': 'wu-sheng'}]"
1325,apm-sniffer/apm-sdk-plugin/tomcat-7.x-8.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/tomcat78x/define/TomcatInstrumentation.java,"@@ -37,7 +37,7 @@
     /**
      * Enhance class.
      */
-    private static final String ENHANCE_CLASS = ""org.apache.catalina.core.StandardWrapperValve"";
+    private static final String ENHANCE_CLASS = ""org.apache.catalina.core.StandardHostValve"";","[{'comment': '`exception` method may not exist in `org.apache.catalina.core.StandardHostValve`', 'commenter': 'candyleer'}, {'comment': 'Done!', 'commenter': 'ascrutae'}]"
1329,docs/cn/Deploy-skywalking-agent-CN.md,"@@ -70,13 +70,13 @@ logging.level=DEBUG
 - Log默认使用文件输出，输出到`/logs`目录中
 
 # Tomcat配置探针FAQ
-- Tomcat 7
+- Linux Tomcat 7, Tomcat 8
 修改`tomcat/bin/catalina.sh`，在首行加入如下信息
 ```shell
 CATALINA_OPTS=""$CATALINA_OPTS -javaagent:/path/to/skywalking-agent/skywalking-agent.jar""; export CATALINA_OPTS
 ```
 
-- Tomcat 8
+- Windows Tomcat7, Tomcat 8
 修改`tomcat/bin/catalina.sh`，在首行加入如下信息","[{'comment': ""Windows haven't `*.sh`"", 'commenter': 'wu-sheng'}]"
1329,docs/en/Deploy-skywalking-agent.md,"@@ -30,13 +30,13 @@ New agent package looks like this：
 - The default logging output folder is `/logs`.
 
 # Deploy agent in Tomcat FAQ
-- Tomcat 7
+- Linux Tomcat 7, Tomcat 8
 Change the first line of `tomcat/bin/catalina.sh`.
 ```shell
 CATALINA_OPTS=""$CATALINA_OPTS -javaagent:/path/to/skywalking-agent/skywalking-agent.jar""; export CATALINA_OPTS
 ```
 
-- Tomcat 8
+- Windows Tomcat7, Tomcat 8
 Change the first line of `tomcat/bin/catalina.sh`.","[{'comment': ""Windows haven't `*.sh`"", 'commenter': 'wu-sheng'}]"
1448,apm-sniffer/apm-sdk-plugin/httpClient-4.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/httpClient/v4/HttpClientExecuteInterceptor.java,"@@ -69,7 +60,7 @@
 
     @Override public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
         Class<?>[] argumentsTypes, Object ret) throws Throwable {
-        if (allArguments[0] == null || allArguments[1] == null) {
+        if (allArguments[0] == null || allArguments[1] == null || ret == null) {","[{'comment': ""You can't just simply return. This will cause a leak of context. In `before`, span created. So you need to close it before return.\r\n\r\nI understood you didn't want to tag for avoiding to read `ret`, but please do `stopSpan` at least."", 'commenter': 'wu-sheng'}]"
1480,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/RuntimeContext.java,"@@ -20,19 +20,28 @@
 
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
 
 /**
  * RuntimeContext is alive during the tracing context.
  * It will not be serialized to the collector, and always stays in the same context only.
  *
  * In most cases, it means it only stays in a single thread for context propagation.
  *
- * @author wusheng
+ * @author wusheng, ascrutae
  */
 public class RuntimeContext {
+    private ILog logger = LogManager.getLogger(RuntimeContext.class);
+    private final ThreadLocal<RuntimeContext> contextThreadLocal;
     private Map context = new ConcurrentHashMap(0);
 
+    public RuntimeContext(ThreadLocal<RuntimeContext> contextThreadLocal) {
+        this.contextThreadLocal = contextThreadLocal;
+    }
+
     public void put(Object key, Object value) {
+        logger.debug(""Storage Key[{}] into runtime context."", key);","[{'comment': 'Why do you need to debug this? Our release agent config log.level=debug. I can see this would be very dangerous, which affects our performance in default mode.', 'commenter': 'wu-sheng'}]"
1480,apm-sniffer/apm-sdk-plugin/hystrix-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/hystrix/v1/SWHystrixConcurrencyStrategyWrapper.java,"@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.hystrix.v1;
+
+import com.netflix.hystrix.strategy.concurrency.HystrixConcurrencyStrategy;
+import java.util.Map;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import org.apache.skywalking.apm.agent.core.conf.RuntimeContextConfiguration;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.RuntimeContext;
+
+public class SWHystrixConcurrencyStrategyWrapper extends HystrixConcurrencyStrategy {
+
+    private final HystrixConcurrencyStrategy delegate;
+
+    public SWHystrixConcurrencyStrategyWrapper(
+        HystrixConcurrencyStrategy delegate) {
+        this.delegate = delegate;
+    }
+
+    @Override
+    public <T> Callable<T> wrapCallable(Callable<T> callable) {
+        RuntimeContext runtimeContext = ContextManager.getRuntimeContext();
+        Map runtimeContextMap = new ConcurrentHashMap();
+        for (String key : RuntimeContextConfiguration.NEED_PROPAGATE_CONTEXT_KEY) {","[{'comment': 'Please provide a separated method to do this. Return an `RuntimeContextSnapshot`.', 'commenter': 'wu-sheng'}]"
1480,apm-sniffer/apm-sdk-plugin/hystrix-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/hystrix/v1/SWHystrixConcurrencyStrategyWrapper.java,"@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.hystrix.v1;
+
+import com.netflix.hystrix.strategy.concurrency.HystrixConcurrencyStrategy;
+import java.util.Map;
+import java.util.concurrent.Callable;
+import java.util.concurrent.ConcurrentHashMap;
+import org.apache.skywalking.apm.agent.core.conf.RuntimeContextConfiguration;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.RuntimeContext;
+
+public class SWHystrixConcurrencyStrategyWrapper extends HystrixConcurrencyStrategy {
+
+    private final HystrixConcurrencyStrategy delegate;
+
+    public SWHystrixConcurrencyStrategyWrapper(
+        HystrixConcurrencyStrategy delegate) {
+        this.delegate = delegate;
+    }
+
+    @Override
+    public <T> Callable<T> wrapCallable(Callable<T> callable) {
+        RuntimeContext runtimeContext = ContextManager.getRuntimeContext();
+        Map runtimeContextMap = new ConcurrentHashMap();
+        for (String key : RuntimeContextConfiguration.NEED_PROPAGATE_CONTEXT_KEY) {
+            Object value = runtimeContext.get(key);
+            if (value != null) {
+                runtimeContextMap.put(key, value);
+            }
+        }
+
+        return new WrappedCallable<T>(runtimeContextMap, super.wrapCallable(callable));
+    }
+
+    static class WrappedCallable<T> implements Callable<T> {
+
+        private final Map<String, Object> runtimeContext;
+        private final Callable<T> target;
+
+        WrappedCallable(Map<String, Object> runtimeContext, Callable<T> target) {
+            this.runtimeContext = runtimeContext;
+            this.target = target;
+        }
+
+        @Override public T call() throws Exception {
+            try {
+                for (Map.Entry<String, Object> entry : runtimeContext.entrySet()) {","[{'comment': 'Use a separated method, `ContextManager.getRuntimeContext().accept(RuntimeContextSnapshot)`', 'commenter': 'wu-sheng'}]"
1480,apm-sniffer/apm-sdk-plugin/hystrix-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/hystrix/v1/define/HystrixPluginsInstrumentation.java,"@@ -54,6 +56,19 @@
                 @Override public boolean isOverrideArgs() {
                     return false;
                 }
+            },
+            new InstanceMethodsInterceptPoint() {
+                @Override public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(GET_CONCURRENCY_STRATEGY_METHOD);
+                }
+
+                @Override public String getMethodsInterceptor() {
+                    return GET_CONCURRENCY_STRATEGY_INTERCEPT_CLASS;
+                }
+
+                @Override public boolean isOverrideArgs() {
+                    return true;","[{'comment': 'Override=`true`? Are you sure? why? I just saw you wrap the result, not override argument.', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。","[{'comment': '对于APM来说，自动探针和手动探针，只是如果实现监控的技术细节。这些和架构设计无关。因此在本文档中，我们将它们仅视为客户端库。', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。","[{'comment': '流式处理', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。","[{'comment': '后端集群发现机制。', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。","[{'comment': '技术实现人员-》技术库', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。","[{'comment': '`实现人员`->`模块实现`', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。
+
+每个模块都可以在Java接口中定义它们的服务，每个模块的提供者都必须为这些服务提供实现者。
+提供者应该基于自己的实现定义依赖模块。这意味着，即使两个不同的模块实现者，也可以依赖不同的模块。
+
+此外，收集器模块化核心还检查启动序列，如果没有发现周期依赖或依赖，收集器应该被core终止。","[{'comment': '`收集器`-> `后端`', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。
+
+每个模块都可以在Java接口中定义它们的服务，每个模块的提供者都必须为这些服务提供实现者。
+提供者应该基于自己的实现定义依赖模块。这意味着，即使两个不同的模块实现者，也可以依赖不同的模块。
+
+此外，收集器模块化核心还检查启动序列，如果没有发现周期依赖或依赖，收集器应该被core终止。
+
+collector启动所有模块，这些模块在`application.yml`中是分离的。在这个yaml文件中：","[{'comment': '请同意说法，后端或者保留`collector`', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。
+
+每个模块都可以在Java接口中定义它们的服务，每个模块的提供者都必须为这些服务提供实现者。
+提供者应该基于自己的实现定义依赖模块。这意味着，即使两个不同的模块实现者，也可以依赖不同的模块。
+
+此外，收集器模块化核心还检查启动序列，如果没有发现周期依赖或依赖，收集器应该被core终止。
+
+collector启动所有模块，这些模块在`application.yml`中是分离的。在这个yaml文件中：
+- 根级别是模块名称，例如`群集`、`命名`。","[{'comment': '引号分布不需要翻译。', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。
+
+每个模块都可以在Java接口中定义它们的服务，每个模块的提供者都必须为这些服务提供实现者。
+提供者应该基于自己的实现定义依赖模块。这意味着，即使两个不同的模块实现者，也可以依赖不同的模块。
+
+此外，收集器模块化核心还检查启动序列，如果没有发现周期依赖或依赖，收集器应该被core终止。
+
+collector启动所有模块，这些模块在`application.yml`中是分离的。在这个yaml文件中：
+- 根级别是模块名称，例如`群集`、`命名`。
+- 辅助级别是模块的实现者名称，例如`zookeeper`是`集群`模块。
+- 第三级是实现者的属性。例如`hostPort`和`sessionTimeout`是`zookepper`的必需属性。
+
+_yaml文件的一部分举例_
+```yml
+cluster:
+  zookeeper:
+    hostPort: localhost:2181
+    sessionTimeout: 100000
+naming:
+  jetty:
+    #OS real network IP(binding required), for agent to find collector cluster
+    host: localhost
+    port: 10800
+    contextPath: /
+```
+
+## 多种连接方式
+首先，收集器提供两种类型的连接，也提供两种协议（HTTP和gRPC）。这两个是
+1. HTTP中的命名服务，它返回后端群集中的所有可用collector。
+1. 在gRPC(SkyWalking native agents的主要部分)和HTTP中使用上行链路服务(上行链路服务)，
+它将跟踪和度量数据上载到收集器。每个客户端将只向单个collector发送监视数据(跟踪和度量)。尝试连接其他的如果连接的离线。
+
+比如在SkyWalking Java代理中
+1. collector.servers means the naming service, which maps to naming/jetty/ip:port of collector, in HTTP.","[{'comment': '未翻译？', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。
+
+每个模块都可以在Java接口中定义它们的服务，每个模块的提供者都必须为这些服务提供实现者。
+提供者应该基于自己的实现定义依赖模块。这意味着，即使两个不同的模块实现者，也可以依赖不同的模块。
+
+此外，收集器模块化核心还检查启动序列，如果没有发现周期依赖或依赖，收集器应该被core终止。
+
+collector启动所有模块，这些模块在`application.yml`中是分离的。在这个yaml文件中：
+- 根级别是模块名称，例如`群集`、`命名`。
+- 辅助级别是模块的实现者名称，例如`zookeeper`是`集群`模块。
+- 第三级是实现者的属性。例如`hostPort`和`sessionTimeout`是`zookepper`的必需属性。
+
+_yaml文件的一部分举例_
+```yml
+cluster:
+  zookeeper:
+    hostPort: localhost:2181
+    sessionTimeout: 100000
+naming:
+  jetty:
+    #OS real network IP(binding required), for agent to find collector cluster
+    host: localhost
+    port: 10800
+    contextPath: /
+```
+
+## 多种连接方式
+首先，收集器提供两种类型的连接，也提供两种协议（HTTP和gRPC）。这两个是
+1. HTTP中的命名服务，它返回后端群集中的所有可用collector。
+1. 在gRPC(SkyWalking native agents的主要部分)和HTTP中使用上行链路服务(上行链路服务)，
+它将跟踪和度量数据上载到收集器。每个客户端将只向单个collector发送监视数据(跟踪和度量)。尝试连接其他的如果连接的离线。
+
+比如在SkyWalking Java代理中","[{'comment': 'Agent一般翻译成 探针', 'commenter': 'wu-sheng'}]"
1499,docs/cn/Architecture-CN.md,"@@ -0,0 +1,106 @@
+# 架构设计
+## 背景
+对于APM，代理或SDK只是有关如何检测lib的技术细节。手动或自动与架构无关，因此在本文档中，我们将它们仅视为客户端库。
+
+<img src=""https://skywalkingtest.github.io/page-resources/5.0/architecture.png""/>
+
+## 基本原则
+SkyWalking架构的基本设计原则**易于维护、可控和流式传输**。
+
+为了实现这些目标，SkyWalking后端采用以下设计。
+1. 模块化设计。
+1. 客户端的多种连接方式。
+1. 收集器集群发现机制。
+1. 流模式。
+1. 可切换的存储。
+
+## 模块化
+SkyWalking收集器基于纯**模块化设计**。最终用户可以根据自己的需求切换或组装收集器功能。
+
+### 模块
+
+模块定义了一组特性，这些特性可以包括技术实现人员(如:gRPC/Jetty服务器管理)、跟踪分析(如:跟踪段或zipkin span解析器)或聚合特性。
+完全由模块定义及其实现人员决定。
+
+每个模块都可以在Java接口中定义它们的服务，每个模块的提供者都必须为这些服务提供实现者。
+提供者应该基于自己的实现定义依赖模块。这意味着，即使两个不同的模块实现者，也可以依赖不同的模块。
+
+此外，收集器模块化核心还检查启动序列，如果没有发现周期依赖或依赖，收集器应该被core终止。
+
+collector启动所有模块，这些模块在`application.yml`中是分离的。在这个yaml文件中：
+- 根级别是模块名称，例如`群集`、`命名`。
+- 辅助级别是模块的实现者名称，例如`zookeeper`是`集群`模块。
+- 第三级是实现者的属性。例如`hostPort`和`sessionTimeout`是`zookepper`的必需属性。
+
+_yaml文件的一部分举例_
+```yml
+cluster:
+  zookeeper:
+    hostPort: localhost:2181
+    sessionTimeout: 100000
+naming:
+  jetty:
+    #OS real network IP(binding required), for agent to find collector cluster
+    host: localhost
+    port: 10800
+    contextPath: /
+```
+
+## 多种连接方式
+首先，收集器提供两种类型的连接，也提供两种协议（HTTP和gRPC）。这两个是
+1. HTTP中的命名服务，它返回后端群集中的所有可用collector。
+1. 在gRPC(SkyWalking native agents的主要部分)和HTTP中使用上行链路服务(上行链路服务)，
+它将跟踪和度量数据上载到收集器。每个客户端将只向单个collector发送监视数据(跟踪和度量)。尝试连接其他的如果连接的离线。
+
+比如在SkyWalking Java代理中
+1. collector.servers means the naming service, which maps to naming/jetty/ip:port of collector, in HTTP.
+   中文(简体)
+   `collector.servers`表示命名服务，它在HTTP中映射到`naming/jetty/ipcollector`的端口。
+2. `collector.direct_servers` 表示直接设置上行服务，并使用gRPC发送监控数据。
+
+
+_客户端lib和收集器集群之间的进程流示例_
+```
+         Client lib                         Collector1             Collector2              Collector3
+ (Set collector.servers=Collector2)              (Collector 1,2,3 constitute the cluster)
+             |
+             +-----------> naming service ---------------------------->|
+                                                                       |
+             |<------- receive gRPC IP:Port(s) of Collector 1,2,3---<--|
+             |
+             |Select a random gRPC service
+             |For example collector 3
+             |
+             |------------------------->Uplink gRPC service----------------------------------->|
+```
+
+
+## Collector 集群发现
+当Collector以群集模式运行时，收集器必须以某种方式相互发现。默认情况下，SkyWalking使用Zookeeper进行协调，并作为实例发现的注册中心。
+
+通过以上部分([多个连接方式](#多种连接方式))，客户端库将不会使用Zookeeper来查找集群。我们建议客户不要这么做。因为集群发现机制是可切换的，由模块化核心提供。依赖它会破坏可切换能力。
+我们希望社区提供更多的实现者来进行集群发现，例如Eureka，Consul，Kubernate。
+
+
+## 流模式
+流模式类似轻量级storm/spark的实现，它允许使用API​​构建流处理图（DAG）以及每个节点的输入/输出数据协定。
+
+新模块可以查找和扩展现有的流程图。
+
+处理中有三种情况
+1. 同步过程，传统方法调用。
+2. 异步过程，又叫做基于队列缓冲区的批处理。
+3. 远程过程，汇总收集器的汇总。以这种方式，在节点中定义选择器以决定如何在集群中找到collector。（HashCode，Rolling，ForeverFirst是支持的三种方式）
+
+通过具有这些功能，collector集群像流式网络一样运行，以聚合度量标准，并且不依赖于存储实现器来支持同时写入相同的度量标准ID。
+
+## 可切换存储实现器
+由于流模式负责并发，因此存储实现者的职责是提供高速写入和组查询。
+
+目前，我们支持ElasticSearch作为主要实现者，H2用于预览，以及由ShardingShpere项目管理的MySQL关系数据库集群。
+
+# Web 界面
+除了收集器设计的原则，UI是SkyWalking的另一个核心组件。它基于React，Antd和Zuul代理，提供收集器集群发现，查询调度和可视化。
+
+Web UI以[多连接方式](#多种连接方式)中的相似的流程机制作为客户端的`1.命名 2.上行`。唯一的区别是，在`ui/jetty/yaml`定义(默认值:localhost:12800)下的主机和端口上用HTTP绑定中的GraphQL查询协议替换上行。","[{'comment': '引号的翻译和上文对不上', 'commenter': 'wu-sheng'}]"
1501,docs/cn/Incubating/Abstract-CN.md,"@@ -0,0 +1,11 @@
+# 孵化特性
+孵化的功能特性是由SkyWalking社区人员开发和贡献代码.
+但目前SkyWalking仍然是雏形或预览版本, 社区希望有更多的开发者参与，给SkyWalking主分支贡献代码。","[{'comment': '这句话不通顺。应该是目前代码还是原型，或者预览版本，并已经提交到主干代码，并进行发布。同时，功能开发者希望社区更多的开发者参与，对功能进行完善。', 'commenter': 'wu-sheng'}]"
1501,docs/cn/Incubating/Abstract-CN.md,"@@ -0,0 +1,11 @@
+# 孵化特性
+孵化的功能特性是由SkyWalking社区人员开发和贡献代码.
+但目前SkyWalking仍然是雏形或预览版本, 社区希望有更多的开发者参与，给SkyWalking主分支贡献代码。
+
+PMC和主开发团队会评估提交的特性，确保它是否具有移植性，是否兼容当前版本.","[{'comment': '应该是PMC和Committor团队', 'commenter': 'wu-sheng'}]"
1501,docs/cn/Incubating/Abstract-CN.md,"@@ -0,0 +1,11 @@
+# 孵化特性
+孵化的功能特性是由SkyWalking社区人员开发和贡献代码.
+但目前SkyWalking仍然是雏形或预览版本, 社区希望有更多的开发者参与，给SkyWalking主分支贡献代码。
+
+PMC和主开发团队会评估提交的特性，确保它是否具有移植性，是否兼容当前版本.
+
+列举一些典型的孵化功能特性","[{'comment': '下面是已知的，可能存在的孵化功能：', 'commenter': 'wu-sheng'}]"
1501,apm-collector/apm-collector-thirdparty-receiver/receiver-zipkin/docs/README-CN.md,"@@ -0,0 +1,24 @@
+# Zipkin接收器
+[Zipkin](http://zipkin.io/)接收器提供了接受Zipkin格式的span数据功能.SkyWalking可以分析、聚合并且将数据展示到可视化界面.因此,用户不需要了解SkyWalking的自动采集探针(Java, .NET, node.js)是如何工作的,或者这些用户因为某些原因不想改变已有的采集方式，例如Zipkin的集成工作已经完成.
+
+Zipkin接受器在SkyWalking中仅仅只是一个可选特性,即使到目前为止它依然是[孵化特性]
+(../../../../docs/cn/Incubating/Abstract-CN.md).
+
+## 局限性
+作为孵化功能,它仍是一个原型.所以它包含以下几点局限：
+
+1. 不要在同一分布式系统中使用SkyWalking原生探针和Zipkin的类库。考虑到Zipkin和SkyWalking的HEADER不是共享/可互操作的，它们的两个不会相互传播context.这会导致已跟踪的链接中断
+1. 不支持集群模式.
+1. 基于链路跟踪的分析将在特定时间内完成的.默认是不能超过2分钟.在分析阶段SkyWalking使用了更复杂的header和context来兼容处理Zipkin格式的数据.","[{'comment': '在进行链路分析时，基于链路会在制定时间内结束。默认链路执行时间不超过2分钟。SkyWalking使用了更复杂的header和context结构，来避免zipkin分析时的这个问题。', 'commenter': 'wu-sheng'}]"
1610,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/interceptor/enhance/ClassEnhancePluginDefine.java,"@@ -115,7 +116,7 @@
          *
          */
         if (!context.isObjectExtended()) {
-            newClassBuilder = newClassBuilder.defineField(CONTEXT_ATTR_NAME, Object.class, ACC_PRIVATE)
+            newClassBuilder = newClassBuilder.defineField(CONTEXT_ATTR_NAME, Object.class, ACC_PRIVATE | ACC_VOLATILE)","[{'comment': 'This needs to be in another PR.', 'commenter': 'wu-sheng'}, {'comment': 'Define dynamicField volatile flag #1611', 'commenter': 'chenpengfei'}]"
1610,apm-sniffer/apm-sdk-plugin/hystrix-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/hystrix/v1/HystrixConcurrencyStrategyInterceptor.java,"@@ -34,8 +34,20 @@ public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allAr
 
     @Override
     public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
-        Object ret) throws Throwable {
-        return new SWHystrixConcurrencyStrategyWrapper((HystrixConcurrencyStrategy)ret);
+                              Object ret) throws Throwable {
+        SWHystrixPluginsWrapperCache wrapperCache = (SWHystrixPluginsWrapperCache) objInst.getSkyWalkingDynamicField();
+        if (wrapperCache == null) {
+            synchronized (objInst) {
+                if (wrapperCache == null) {
+                    wrapperCache = new SWHystrixPluginsWrapperCache();
+                    objInst.setSkyWalkingDynamicField(wrapperCache);
+                }
+            }
+        }
+
+        wrapperCache.getSwHystrixConcurrencyStrategyWrapper().compareAndSet(null, new SWHystrixConcurrencyStrategyWrapper((HystrixConcurrencyStrategy) ret));","[{'comment': '1. This compareAndSet executes every time, I have a performance concern because of `AtomicReference` includes lock.\r\n2. The `swHystrixConcurrencyStrategyWrapper` could be inited inside double-check, no `AtomicReference` required. Only a `volatile` key word should be enough.', 'commenter': 'wu-sheng'}]"
1921,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/MetadataQueryEsDAO.java,"@@ -75,7 +75,6 @@ public MetadataQueryEsDAO(ElasticSearchClient client) {
         SearchSourceBuilder sourceBuilder = SearchSourceBuilder.searchSource();
 
         BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
-        boolQueryBuilder.must().add(timeRangeQueryBuild(startTimestamp, endTimestamp));
         boolQueryBuilder.must().add(QueryBuilders.termQuery(NetworkAddressInventory.SRC_LAYER, srcLayer));
 
         sourceBuilder.query(boolQueryBuilder);","[{'comment': 'Boolean query builder is use for two query condition, but when you delete one of them, you can set query directly.\r\n\r\nsourceBuilder.query(QueryBuilders.termQuery(NetworkAddressInventory.SRC_LAYER, srcLayer));', 'commenter': 'peng-yongsheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/listener/Reseter.java,"@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.listener;
+
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.nio.channels.FileChannel;
+import java.nio.channels.FileLock;
+import java.util.Properties;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.dictionary.EndpointNameDictionary;
+import org.apache.skywalking.apm.agent.core.dictionary.NetworkAddressDictionary;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.TraceSegmentServiceClient;
+
+/**
+ * @author liu-xinyuan
+ **/
+public enum Reseter {
+    INSTANCE;
+    private static final ILog logger = LogManager.getLogger(Reseter.class);
+    private static final String APPLICATION_ID_NAM = ""application_id"";
+    private static final String INSTANCE_ID_NAME = ""instance_id"";
+    private static final String STATUS_NAME = ""status"";
+    private static final String RESET_CHILD_DIR = ""/reset.status"";
+    private static final String COMMENT = ""#Status has three values: ON (trigger reset), DONE(reset complete), OFF(agent fist boot).\n"" +
+        ""Application_id: application_id of the current agent.\n"" +
+        ""Instance_id: the instanceid of the current agent."";
+    private volatile Properties properties = new Properties();
+    private String resetPath;
+    private ResetStatus status = ResetStatus.OFF;
+    private int isFirstRun = 0;
+    private int detectDuration = 5;
+
+    public Reseter setStatus(ResetStatus status) {
+        this.status = status;
+        return this;
+    }
+
+    public String getResetPath() throws IOException {
+        if (isFirstRun == 0) {
+            File statusDir = new File(Config.Agent.REGISTER_STATUS_DIR);
+            if (!statusDir.exists() || !statusDir.isDirectory()) {
+                statusDir.mkdir();
+            }
+            resetPath = statusDir.getAbsolutePath() + RESET_CHILD_DIR;
+            init();
+            isFirstRun = 1;
+        }
+        return resetPath;
+    }
+
+    public void reportToRegisterFile() throws IOException {
+        FileOutputStream outputStream = null;
+        try {
+            File configFile = new File(resetPath);
+            properties.setProperty(APPLICATION_ID_NAM, RemoteDownstreamConfig.Agent.SERVICE_ID + """");
+            properties.setProperty(INSTANCE_ID_NAME, RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID + """");
+            properties.setProperty(STATUS_NAME, status.value());
+            outputStream = new FileOutputStream(configFile);
+            properties.store(outputStream, COMMENT);
+        } finally {
+            closeFileStream(outputStream);
+        }
+    }
+
+    public Reseter clearID() {
+        RemoteDownstreamConfig.Agent.SERVICE_ID = DictionaryUtil.nullValue();
+        RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID = DictionaryUtil.nullValue();
+        EndpointNameDictionary.INSTANCE.clearEndpointNameDictionary();
+        NetworkAddressDictionary.INSTANCE.clearNetworkAddressDictionary();
+        ServiceManager.INSTANCE.findService(TraceSegmentServiceClient.class).clearCache();
+        status = ResetStatus.DONE;
+        logger.info(""clear id successfully,begin trigger reset."");
+        return this;
+    }
+
+    public Boolean predicateReset() throws IOException {
+        File resetFile = new File(getResetPath());
+        FileInputStream inputStream = null;
+        FileLock fileLock = null;
+        FileChannel fileChannel = null;
+        if (System.currentTimeMillis() - resetFile.lastModified() < detectDuration * 1000) {","[{'comment': 'If `detectDuration` is set to 5 only, why multiply 1000 here? Suggest set to 5000.', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/SnifferConfigInitializer.java,"@@ -47,6 +47,8 @@
     private static String SPECIFIED_CONFIG_PATH = ""skywalking_config"";
     private static String DEFAULT_CONFIG_FILE_NAME = ""/config/agent.config"";
     private static String ENV_KEY_PREFIX = ""skywalking."";
+    private static final String INSTANCE_UUID_NAME = ""agent.instance_uuid"";
+    private static final String REGISTER_STATUS_DIR = ""agent.register_status_dir"";","[{'comment': ""What need these two fields?  Don't find you use these in any place."", 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/listener/Reseter.java,"@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.listener;
+
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.nio.channels.FileChannel;
+import java.nio.channels.FileLock;
+import java.util.Properties;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.dictionary.EndpointNameDictionary;
+import org.apache.skywalking.apm.agent.core.dictionary.NetworkAddressDictionary;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.TraceSegmentServiceClient;
+
+/**
+ * @author liu-xinyuan
+ **/
+public enum Reseter {
+    INSTANCE;
+    private static final ILog logger = LogManager.getLogger(Reseter.class);
+    private static final String APPLICATION_ID_NAM = ""application_id"";","[{'comment': 'application id is not used now. Service code and id replaced the old ones.', 'commenter': 'wu-sheng'}]"
1929,oap-server/server-receiver-plugin/skywalking-register-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/register/provider/handler/v5/ServiceInstancePingPkgHandler.java,"@@ -0,0 +1,61 @@
+/*
+ *
+ *  * Licensed to the Apache Software Foundation (ASF) under one or more
+ *  * contributor license agreements.  See the NOTICE file distributed with
+ *  * this work for additional information regarding copyright ownership.
+ *  * The ASF licenses this file to You under the Apache License, Version 2.0
+ *  * (the ""License""); you may not use this file except in compliance with
+ *  * the License.  You may obtain a copy of the License at
+ *  *
+ *  *     http://www.apache.org/licenses/LICENSE-2.0
+ *  *
+ *  * Unless required by applicable law or agreed to in writing, software
+ *  * distributed under the License is distributed on an ""AS IS"" BASIS,
+ *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  * See the License for the specific language governing permissions and
+ *  * limitations under the License.
+ *  *
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.register.provider.handler.v5;
+
+import io.grpc.stub.StreamObserver;
+import org.apache.skywalking.apm.network.common.Commands;
+
+import org.apache.skywalking.apm.network.register.v2.ServiceInstancePingGrpc;
+import org.apache.skywalking.apm.network.register.v2.ServiceInstancePingPkg;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;
+import org.apache.skywalking.oap.server.core.register.service.IServiceInstanceInventoryRegister;
+import org.apache.skywalking.oap.server.core.storage.StorageModule;
+import org.apache.skywalking.oap.server.core.storage.cache.IServiceInstanceInventoryCacheDAO;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.server.grpc.GRPCHandler;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class ServiceInstancePingPkgHandler extends ServiceInstancePingGrpc.ServiceInstancePingImplBase implements GRPCHandler {","[{'comment': '`org.apache.skywalking.oap.server.receiver.register.provider.handler.v6.grpc.ServiceInstancePingServiceHandler` is already existed now.', 'commenter': 'wu-sheng'}]"
1929,oap-server/server-receiver-plugin/skywalking-register-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/register/provider/handler/v5/ServiceInstancePingPkgHandler.java,"@@ -0,0 +1,61 @@
+/*
+ *
+ *  * Licensed to the Apache Software Foundation (ASF) under one or more
+ *  * contributor license agreements.  See the NOTICE file distributed with
+ *  * this work for additional information regarding copyright ownership.
+ *  * The ASF licenses this file to You under the Apache License, Version 2.0
+ *  * (the ""License""); you may not use this file except in compliance with
+ *  * the License.  You may obtain a copy of the License at
+ *  *
+ *  *     http://www.apache.org/licenses/LICENSE-2.0
+ *  *
+ *  * Unless required by applicable law or agreed to in writing, software
+ *  * distributed under the License is distributed on an ""AS IS"" BASIS,
+ *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  * See the License for the specific language governing permissions and
+ *  * limitations under the License.
+ *  *
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.register.provider.handler.v5;
+
+import io.grpc.stub.StreamObserver;
+import org.apache.skywalking.apm.network.common.Commands;
+
+import org.apache.skywalking.apm.network.register.v2.ServiceInstancePingGrpc;
+import org.apache.skywalking.apm.network.register.v2.ServiceInstancePingPkg;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;
+import org.apache.skywalking.oap.server.core.register.service.IServiceInstanceInventoryRegister;
+import org.apache.skywalking.oap.server.core.storage.StorageModule;
+import org.apache.skywalking.oap.server.core.storage.cache.IServiceInstanceInventoryCacheDAO;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.server.grpc.GRPCHandler;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class ServiceInstancePingPkgHandler extends ServiceInstancePingGrpc.ServiceInstancePingImplBase implements GRPCHandler {
+    private static final Logger logger = LoggerFactory.getLogger(ServiceInstancePingPkgHandler.class);
+
+    private final IServiceInstanceInventoryCacheDAO instanceInventoryCacheDAO;
+    private final IServiceInstanceInventoryRegister serviceInstanceInventoryRegister;
+
+    public ServiceInstancePingPkgHandler(ModuleManager moduleManager) {
+        this.instanceInventoryCacheDAO = moduleManager.find(StorageModule.NAME).provider().getService(IServiceInstanceInventoryCacheDAO.class);
+        this.serviceInstanceInventoryRegister = moduleManager.find(CoreModule.NAME).provider().getService(IServiceInstanceInventoryRegister.class);
+
+    }
+
+    @Override public void doPing(ServiceInstancePingPkg request, StreamObserver<Commands> responseObserver) {
+
+        ServiceInstanceInventory serviceInstanceInventory = instanceInventoryCacheDAO.get(request.getServiceInstanceId());
+        if (request.getServiceInstanceUUID().equals(serviceInstanceInventory.getName()) || serviceInstanceInventory.getServiceId() == Const.NONE) {","[{'comment': 'This logic is not right. ServiceInstanceInventory would be expected **NULL**. This would trigger a NPE.', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -71,6 +71,21 @@
          */
         public static boolean IS_OPEN_DEBUGGING_CLASS = false;
 
+        /**
+         * Specify register.status dir ,This is an option, the default is AGENT_HOME/option/reset.status.
+         */
+        public static String REGISTER_STATUS_DIR = ""skywalking-agent/option"";
+
+        /**
+         * Specify instance_uuid to ensure that the whole show is unique, for example: applicationName_ip_12
+         */
+        public static String INSTANCE_UUID = """";","[{'comment': ""I haven't found any place using this `INSTANCE_UUID`. I remember the design doc said, it should replace `ServiceAndEndpointRegisterClient#PROCESS_UUID` if this field is not empty."", 'commenter': 'wu-sheng'}, {'comment': 'this INSTANCE_UUID has be used', 'commenter': 'Liu-XinYuan'}]"
1929,oap-server/server-receiver-plugin/skywalking-register-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/register/provider/handler/v5/ServiceInstancePingPkgHandler.java,"@@ -0,0 +1,61 @@
+/*
+ *
+ *  * Licensed to the Apache Software Foundation (ASF) under one or more
+ *  * contributor license agreements.  See the NOTICE file distributed with
+ *  * this work for additional information regarding copyright ownership.
+ *  * The ASF licenses this file to You under the Apache License, Version 2.0
+ *  * (the ""License""); you may not use this file except in compliance with
+ *  * the License.  You may obtain a copy of the License at
+ *  *
+ *  *     http://www.apache.org/licenses/LICENSE-2.0
+ *  *
+ *  * Unless required by applicable law or agreed to in writing, software
+ *  * distributed under the License is distributed on an ""AS IS"" BASIS,
+ *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  * See the License for the specific language governing permissions and
+ *  * limitations under the License.
+ *  *
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.register.provider.handler.v5;
+
+import io.grpc.stub.StreamObserver;
+import org.apache.skywalking.apm.network.common.Commands;
+
+import org.apache.skywalking.apm.network.register.v2.ServiceInstancePingGrpc;
+import org.apache.skywalking.apm.network.register.v2.ServiceInstancePingPkg;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;
+import org.apache.skywalking.oap.server.core.register.service.IServiceInstanceInventoryRegister;
+import org.apache.skywalking.oap.server.core.storage.StorageModule;
+import org.apache.skywalking.oap.server.core.storage.cache.IServiceInstanceInventoryCacheDAO;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.server.grpc.GRPCHandler;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class ServiceInstancePingPkgHandler extends ServiceInstancePingGrpc.ServiceInstancePingImplBase implements GRPCHandler {
+    private static final Logger logger = LoggerFactory.getLogger(ServiceInstancePingPkgHandler.class);
+
+    private final IServiceInstanceInventoryCacheDAO instanceInventoryCacheDAO;
+    private final IServiceInstanceInventoryRegister serviceInstanceInventoryRegister;
+
+    public ServiceInstancePingPkgHandler(ModuleManager moduleManager) {
+        this.instanceInventoryCacheDAO = moduleManager.find(StorageModule.NAME).provider().getService(IServiceInstanceInventoryCacheDAO.class);
+        this.serviceInstanceInventoryRegister = moduleManager.find(CoreModule.NAME).provider().getService(IServiceInstanceInventoryRegister.class);
+
+    }
+
+    @Override public void doPing(ServiceInstancePingPkg request, StreamObserver<Commands> responseObserver) {
+
+        ServiceInstanceInventory serviceInstanceInventory = instanceInventoryCacheDAO.get(request.getServiceInstanceId());
+        if (request.getServiceInstanceUUID().equals(serviceInstanceInventory.getName()) || serviceInstanceInventory.getServiceId() == Const.NONE) {
+            logger.error(""Your metadata loss,please set the status in reset.status in the agent {} to ON to trigger a reset!"", request.getServiceInstanceUUID());","[{'comment': 'Please add the UUID to log in `org.apache.skywalking.oap.server.receiver.register.provider.handler.v6.grpc.ServiceInstancePingServiceHandler#L61`\r\n>             logger.warn(""Can\'t found service by service instance id from cache, service instance id is: {}"", serviceInstanceId);\r\n', 'commenter': 'wu-sheng'}, {'comment': 'The log statement is not right. Because, if `RESETER_LISTENER=disable` as default, there is nothing user can do, just could reboot the agent, or ref #1973 . ', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/listener/Reseter.java,"@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.listener;
+
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.nio.channels.FileChannel;
+import java.nio.channels.FileLock;
+import java.util.Properties;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.dictionary.EndpointNameDictionary;
+import org.apache.skywalking.apm.agent.core.dictionary.NetworkAddressDictionary;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.TraceSegmentServiceClient;
+
+/**
+ * @author liu-xinyuan
+ **/
+public enum Reseter {
+    INSTANCE;
+    private static final ILog logger = LogManager.getLogger(Reseter.class);
+    private static final String APPLICATION_ID_NAM = ""application_id"";
+    private static final String INSTANCE_ID_NAME = ""instance_id"";
+    private static final String STATUS_NAME = ""status"";
+    private static final String RESET_CHILD_DIR = ""/reset.status"";
+    private static final String COMMENT = ""#Status has three values: ON (trigger reset), DONE(reset complete), OFF(agent fist boot).\n"" +
+        ""Application_id: application_id of the current agent.\n"" +
+        ""Instance_id: the instanceid of the current agent."";
+    private volatile Properties properties = new Properties();
+    private String resetPath;
+    private ResetStatus status = ResetStatus.OFF;
+    private int isFirstRun = 0;
+    private int detectDuration = 5;
+
+    public Reseter setStatus(ResetStatus status) {
+        this.status = status;
+        return this;
+    }
+
+    public String getResetPath() throws IOException {
+        if (isFirstRun == 0) {
+            File statusDir = new File(Config.Agent.REGISTER_STATUS_DIR);
+            if (!statusDir.exists() || !statusDir.isDirectory()) {
+                statusDir.mkdir();
+            }
+            resetPath = statusDir.getAbsolutePath() + RESET_CHILD_DIR;
+            init();
+            isFirstRun = 1;
+        }
+        return resetPath;
+    }
+
+    public void reportToRegisterFile() throws IOException {
+        FileOutputStream outputStream = null;
+        try {
+            File configFile = new File(resetPath);
+            properties.setProperty(APPLICATION_ID_NAM, RemoteDownstreamConfig.Agent.SERVICE_ID + """");
+            properties.setProperty(INSTANCE_ID_NAME, RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID + """");
+            properties.setProperty(STATUS_NAME, status.value());
+            outputStream = new FileOutputStream(configFile);
+            properties.store(outputStream, COMMENT);
+        } finally {
+            closeFileStream(outputStream);
+        }
+    }
+
+    public Reseter clearID() {","[{'comment': 'Rename `clearID` to `resetRegisterStatus`', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/ServiceAndEndpointRegisterClient.java,"@@ -46,14 +48,15 @@
 import org.apache.skywalking.apm.network.register.v2.ServiceRegisterMapping;
 import org.apache.skywalking.apm.network.register.v2.Services;
 import org.apache.skywalking.apm.util.RunnableWithExceptionProtection;
+import org.apache.skywalking.apm.util.StringUtil;
 
 /**
  * @author wusheng
  */
 @DefaultImplementor
 public class ServiceAndEndpointRegisterClient implements BootService, Runnable, GRPCChannelListener {
     private static final ILog logger = LogManager.getLogger(ServiceAndEndpointRegisterClient.class);
-    private static final String PROCESS_UUID = UUID.randomUUID().toString().replaceAll(""-"", """");
+    private static final String PROCESS_UUID = StringUtil.isEmpty(Config.Agent.PROCESS_UUID) ? UUID.randomUUID().toString().replaceAll(""-"", """") : Config.Agent.PROCESS_UUID;","[{'comment': 'This depends on Class load sequence, I am not sure, is this good at your test?', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/ServiceAndEndpointRegisterClient.java,"@@ -114,6 +117,7 @@ public void run() {
                             for (KeyIntValuePair registered : serviceRegisterMapping.getServicesList()) {
                                 if (Config.Agent.SERVICE_NAME.equals(registered.getKey())) {
                                     RemoteDownstreamConfig.Agent.SERVICE_ID = registered.getValue();
+                                    Reseter.INSTANCE.reportToRegisterFile();","[{'comment': 'When reset is disable, this looks like causing NPE. ', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/ServiceAndEndpointRegisterClient.java,"@@ -136,6 +140,8 @@ public void run() {
                                     int serviceInstanceId = serviceInstance.getValue();
                                     if (serviceInstanceId != DictionaryUtil.nullValue()) {
                                         RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID = serviceInstanceId;
+                                        Reseter.INSTANCE.setStatus(ResetStatus.OFF).reportToRegisterFile();","[{'comment': 'Same here causing potential NPE', 'commenter': 'wu-sheng'}]"
1929,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/listener/Reseter.java,"@@ -0,0 +1,168 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.listener;
+
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.nio.channels.FileChannel;
+import java.nio.channels.FileLock;
+import java.util.Properties;
+import org.apache.skywalking.apm.agent.core.boot.AgentPackageNotFoundException;
+import org.apache.skywalking.apm.agent.core.boot.AgentPackagePath;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.dictionary.EndpointNameDictionary;
+import org.apache.skywalking.apm.agent.core.dictionary.NetworkAddressDictionary;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.TraceSegmentServiceClient;
+import org.apache.skywalking.apm.util.StringUtil;
+
+/**
+ * @author liu-xinyuan
+ **/
+public enum Reseter {
+    INSTANCE;
+    private static final ILog logger = LogManager.getLogger(Reseter.class);
+    private static final String SERVICE_ID_NAME = ""service_id"";
+    private static final String INSTANCE_ID_NAME = ""instance_id"";
+    private static final String STATUS_NAME = ""status"";
+    private static final String RESET_CHILD_DIR = ""/reset.status"";
+    private static final String COMMENT = ""#Status has three values: ON (trigger reset), DONE(reset complete), OFF(agent fist boot).\n"" +
+        ""service_id: the service_id of the current agent.\n"" +
+        ""Instance_id: the instance_id of the current agent."";
+    private volatile Properties properties = new Properties();
+    private String resetPath;
+    private ResetStatus status = ResetStatus.OFF;
+    private boolean isFirstRun = true;
+    private int detectDuration = 5000;
+
+    public Reseter setStatus(ResetStatus status) {
+        this.status = status;
+        return this;
+    }
+
+    public String getResetPath() throws IOException, SecurityException {
+        if (isFirstRun) {
+            if (StringUtil.isEmpty(Config.Agent.REGISTER_STATUS_DIR)) {
+                try {
+                    Config.Agent.REGISTER_STATUS_DIR = AgentPackagePath.getPath() + ""/option"";
+                } catch (AgentPackageNotFoundException e) {
+                    e.printStackTrace();
+                }
+            }
+            File statusDir = new File(Config.Agent.REGISTER_STATUS_DIR);
+
+            if (!statusDir.exists() || !statusDir.isDirectory()) {
+                statusDir.mkdir();
+            }
+            resetPath = statusDir.getAbsolutePath() + RESET_CHILD_DIR;
+            init();
+            isFirstRun = false;
+        }
+        return resetPath;
+    }
+
+    public void reportToRegisterFile() throws IOException {
+        FileOutputStream outputStream = null;
+        try {
+            File configFile = new File(resetPath);","[{'comment': 'In disable status, resetPath is not initialized.', 'commenter': 'wu-sheng'}]"
2048,docs/powered-by.md,"@@ -55,3 +55,10 @@ or providing commercial products including Apache SkyWalking.
 1. Yinji(shenzhen)Network Technology Co.,Ltd. 印记. http://www.yinjiyun.cn/
 1. Yonghui Superstores Co., Ltd. 永辉超市 http://www.yonghui.com.cn
 
+# User Cases
+## ke.com","[{'comment': 'This use case seems exists in the list in line #`27 Ke.com. 贝壳找房. https://www.ke.com .`', 'commenter': 'JaredTan95'}, {'comment': 'This is user case, not just user inform. I am encouraging people to do this. Including daocloud customer. It will be much helpful for the community.', 'commenter': 'wu-sheng'}, {'comment': 'yes, it helps people to adjust their deployment configuration for better user experience', 'commenter': 'IanCao'}, {'comment': 'ok, got it. :-D', 'commenter': 'JaredTan95'}]"
2064,apm-sniffer/optional-plugins/pom.xml,"@@ -43,6 +43,7 @@
     <modules>
         <module>optional-spring-plugins</module>
         <module>trace-ignore-plugin</module>
+        <module>dubbo-patch</module>","[{'comment': '`dubbo-patch` looks like a strange name. Does this plugin try to resolve dubbo-springmvc conflict? If I am right, please name it `dubbo-springmvc-confict-patch`', 'commenter': 'wu-sheng'}, {'comment': 'This plugin is not only resolve spring-mvc conflict. it resolve all the conflict that the class enhance by Skywalking and Dubbo. I suggest that plugin named `dubbo-conflict patch`', 'commenter': 'ascrutae'}]"
2064,apm-sniffer/apm-sdk-plugin/pom.xml,"@@ -60,7 +60,8 @@
         <module>activemq-5.x-plugin</module>
         <module>elasticsearch-5.x-plugin</module>
         <module>undertow-plugins</module>
-        <module>rabbitmq-5.x-plugin</module>
+	<module>rabbitmq-5.x-plugin</module>","[{'comment': 'Format looks like not right.', 'commenter': 'wu-sheng'}]"
2064,apm-sniffer/apm-sdk-plugin/dubbo-conflict-patch/src/main/java/org/apache/skywalking/apm/plugin/dubbo/patch/MakeWrapperInterceptor.java,"@@ -0,0 +1,268 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dubbo.patch;
+
+import com.alibaba.dubbo.common.bytecode.ClassGenerator;
+import com.alibaba.dubbo.common.bytecode.NoSuchPropertyException;
+import com.alibaba.dubbo.common.bytecode.Wrapper;
+import com.alibaba.dubbo.common.utils.ClassHelper;
+import com.alibaba.dubbo.common.utils.ReflectUtils;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.regex.Matcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.StaticMethodsAroundInterceptor;
+
+public class MakeWrapperInterceptor implements StaticMethodsAroundInterceptor {
+    private static final AtomicLong WRAPPER_CLASS_COUNTER = new AtomicLong(0);
+
+    @Override
+    public void beforeMethod(Class clazz, Method method, Object[] allArguments, Class<?>[] parameterTypes,
+        MethodInterceptResult result) {
+        Class wrapperClass = (Class<?>)allArguments[0];
+        if (EnhancedInstance.class.isAssignableFrom(wrapperClass)) {
+            result.defineReturnValue(makeWrapper(wrapperClass));
+        }
+    }
+
+    @Override public Object afterMethod(Class clazz, Method method, Object[] allArguments, Class<?>[] parameterTypes,
+        Object ret) {
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(Class clazz, Method method, Object[] allArguments, Class<?>[] parameterTypes,
+        Throwable t) {
+    }
+
+    private static Wrapper makeWrapper(Class<?> c) {","[{'comment': 'Add a comment linking to the original class and method?', 'commenter': 'wu-sheng'}]"
2064,apm-sniffer/apm-sdk-plugin/dubbo-conflict-patch/src/main/java/org/apache/skywalking/apm/plugin/dubbo/patch/MakeWrapperInterceptor.java,"@@ -0,0 +1,268 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dubbo.patch;
+
+import com.alibaba.dubbo.common.bytecode.ClassGenerator;
+import com.alibaba.dubbo.common.bytecode.NoSuchPropertyException;
+import com.alibaba.dubbo.common.bytecode.Wrapper;
+import com.alibaba.dubbo.common.utils.ClassHelper;
+import com.alibaba.dubbo.common.utils.ReflectUtils;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicLong;
+import java.util.regex.Matcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.StaticMethodsAroundInterceptor;
+
+public class MakeWrapperInterceptor implements StaticMethodsAroundInterceptor {","[{'comment': 'Add comments about why do you need this interceptor?', 'commenter': 'wu-sheng'}]"
2075,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2RegisterDAO.java,"@@ -46,15 +46,16 @@ public H2RegisterDAO(JDBCHikariCPClient h2Client,
         this.storageBuilder = storageBuilder;
     }
 
-    @Override public int max(String modelName) throws IOException {
+    @Override public int registerId(String modelName,
+        RegisterSource registerSource) throws IOException {
         try (Connection connection = h2Client.getConnection()) {
-            try (ResultSet rs = h2Client.executeQuery(connection, ""SELECT max(sequence) max_id FROM "" + modelName)) {
+            try (ResultSet rs = h2Client.executeQuery(connection, ""SELECT registerId(sequence) max_id FROM "" + modelName)) {","[{'comment': ""^_^, Mysql haven't registerId function. It must be renamed by IntelliJ."", 'commenter': 'peng-yongsheng'}, {'comment': 'Yes. I will fix this', 'commenter': 'wu-sheng'}]"
2237,docker/docker-compose.yml,"@@ -37,7 +37,7 @@ services:
       - 11800:11800
       - 12800:12800
     volumes:
-      - ./config:/apache-skywalking-apm-incubating/config:ro
+      - ./config:/skywalking/config:ro","[{'comment': 'should be `./config:/apache-skywalking-apm-incubating-bin/config:ro` according to [OAP Dockerfile](https://github.com/apache/incubator-skywalking/blob/master/docker/oap/Dockerfile)', 'commenter': 'hanahmily'}]"
2300,docs/en/setup/service-agent/java-agent/README.md,"@@ -89,6 +89,7 @@ Now, we have the following known optional plugins.
 * Gson serialization lib in optional plugin folder
 * Lettuce 5.x(JRE1.8+) in optional plugin folder 
 * Zookeeper 3.4.x in optional plugin folder. The reason of being optional plugin is, many business irrelevant traces are generated, which cause extra payload to agents and backends. At the same time, those traces may be just heartbeat(s).
+* [Customize enhance](agent-optional-plugins/customize-enhance-plugin.md) Implement non-intrusive custom method enhancements through description file.","[{'comment': 'Trace methods based on description files, rather than write plugin or change source codes.', 'commenter': 'wu-sheng'}, {'comment': 'Move this to feature, and in plugin folder.', 'commenter': 'wu-sheng'}, {'comment': 'Ok', 'commenter': 'zhaoyuguang'}]"
2300,docs/en/setup/service-agent/java-agent/Supported-list.md,"@@ -62,6 +62,8 @@
 * [Canal: Alibaba mysql database binlog incremental subscription & consumer components](https://github.com/alibaba/canal) 1.0.25 -> 1.1.2
 * JSON
   * [GSON](https://github.com/google/gson) 2.8.x (Optional²)
+* Customize Enhance","[{'comment': ""This don't need to be in this list. This is a feature."", 'commenter': 'wu-sheng'}, {'comment': 'Ok', 'commenter': 'zhaoyuguang'}]"
2300,docs/en/setup/service-agent/java-agent/customize-enhance-trace.md,"@@ -0,0 +1,59 @@
+## Support custom enhance 
+Here is an optional plugin `apm-customize-enhance-plugin`
+
+## Introduce
+- The purpose of this plugin is to achieve Class enhancements to some extent through non-intrusive forms.
+- The core idea is that there is no intrusion, so that no code related to this project appears in the project code.
+- Implemented a custom enhancement of the custom languages, it looks more like [@Trace](Application-toolkit-trace.md) non-intrusive implementation,
+internal tag records need to be used, ActiveSpan.tag to achieve, of course, it is to support static methods, 
+you can use the custom languages to extend the operationName suffix, already log, and tag extension.                                                                                                      
+
+## How to configure
+Implementing enhancements to custom classes requires two steps.
+ 1. Set through the system environment variable, you need to add `skywalking.customize.enhance_file`.
+ 2. Configure your configuration file according to the demo below.
+```xml
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<enhanced>
+    <class class_name=""test.apache.skywalking.testcase.customize.service.TestService1"">
+        <method method=""staticMethod()"" operation_name=""/is_static_method"" static=""true""></method>
+        <method method=""staticMethod(java.lang.String,int.class,java.util.Map,java.util.List,[Ljava.lang.Object;)"" operation_name=""/is_static_method_args"" static=""true"">
+            <operation_name_suffix>arg[0]</operation_name_suffix>
+            <operation_name_suffix>arg[1]</operation_name_suffix>
+            <operation_name_suffix>arg[3].[0]</operation_name_suffix>","[{'comment': 'Is the express `arg[3].[0]` means that to get the first element from the third arguments?', 'commenter': 'ascrutae'}, {'comment': 'Get the first element from the fourth arguments.', 'commenter': 'zhaoyuguang'}]"
2300,docs/en/setup/service-agent/java-agent/customize-enhance-trace.md,"@@ -0,0 +1,59 @@
+## Support custom enhance 
+Here is an optional plugin `apm-customize-enhance-plugin`
+
+## Introduce
+- The purpose of this plugin is to achieve Class enhancements to some extent through non-intrusive forms.
+- The core idea is that there is no intrusion, so that no code related to this project appears in the project code.
+- Implemented a custom enhancement of the custom languages, it looks more like [@Trace](Application-toolkit-trace.md) non-intrusive implementation,
+internal tag records need to be used, ActiveSpan.tag to achieve, of course, it is to support static methods, 
+you can use the custom languages to extend the operationName suffix, already log, and tag extension.                                                                                                      
+
+## How to configure
+Implementing enhancements to custom classes requires two steps.
+ 1. Set through the system environment variable, you need to add `skywalking.customize.enhance_file`.
+ 2. Configure your configuration file according to the demo below.
+```xml
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<enhanced>
+    <class class_name=""test.apache.skywalking.testcase.customize.service.TestService1"">
+        <method method=""staticMethod()"" operation_name=""/is_static_method"" static=""true""></method>
+        <method method=""staticMethod(java.lang.String,int.class,java.util.Map,java.util.List,[Ljava.lang.Object;)"" operation_name=""/is_static_method_args"" static=""true"">
+            <operation_name_suffix>arg[0]</operation_name_suffix>
+            <operation_name_suffix>arg[1]</operation_name_suffix>
+            <operation_name_suffix>arg[3].[0]</operation_name_suffix>
+            <tag key=""tag_1"">arg[2].['k1']</tag>","[{'comment': ""Is the express `arg[2].['k1']` means that to get the value of element key equals `k1` from the second arguments?"", 'commenter': 'ascrutae'}, {'comment': 'Look like get k1 from a hashmap field.', 'commenter': 'wu-sheng'}, {'comment': 'Get the value of element key equals k1 from the third arguments', 'commenter': 'zhaoyuguang'}, {'comment': 'I suggest that you should add more detail about those operation express in the document', 'commenter': 'ascrutae'}, {'comment': 'Yes', 'commenter': 'zhaoyuguang'}]"
2300,docs/en/setup/service-agent/java-agent/customize-enhance-trace.md,"@@ -0,0 +1,59 @@
+## Support custom enhance 
+Here is an optional plugin `apm-customize-enhance-plugin`
+
+## Introduce
+- The purpose of this plugin is to achieve Class enhancements to some extent through non-intrusive forms.
+- The core idea is that there is no intrusion, so that no code related to this project appears in the project code.
+- Implemented a custom enhancement of the custom languages, it looks more like [@Trace](Application-toolkit-trace.md) non-intrusive implementation,
+internal tag records need to be used, ActiveSpan.tag to achieve, of course, it is to support static methods, 
+you can use the custom languages to extend the operationName suffix, already log, and tag extension.                                                                                                      
+
+## How to configure
+Implementing enhancements to custom classes requires two steps.
+ 1. Set through the system environment variable, you need to add `skywalking.customize.enhance_file`.
+ 2. Configure your configuration file according to the demo below.
+```xml
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<enhanced>
+    <class class_name=""test.apache.skywalking.testcase.customize.service.TestService1"">
+        <method method=""staticMethod()"" operation_name=""/is_static_method"" static=""true""></method>
+        <method method=""staticMethod(java.lang.String,int.class,java.util.Map,java.util.List,[Ljava.lang.Object;)"" operation_name=""/is_static_method_args"" static=""true"">
+            <operation_name_suffix>arg[0]</operation_name_suffix>
+            <operation_name_suffix>arg[1]</operation_name_suffix>
+            <operation_name_suffix>arg[3].[0]</operation_name_suffix>
+            <tag key=""tag_1"">arg[2].['k1']</tag>
+            <tag key=""tag_2"">arg[4].[1]</tag>
+            <log key=""log_1"">arg[4].[2]</log>
+        </method>
+        <method method=""method()"" static=""false""></method>
+        <method method=""method(java.lang.String,int.class)"" operation_name=""/method_2"" static=""false"">
+            <operation_name_suffix>arg[0]</operation_name_suffix>
+            <tag key=""tag_1"">arg[0]</tag>
+            <log key=""log_1"">arg[1]</log>
+        </method>
+        <method method=""method(test.apache.skywalking.testcase.customize.model.Model0,java.lang.String,int.class)"" operation_name=""/method_3"" static=""false"">
+            <operation_name_suffix>arg[0].id</operation_name_suffix>
+            <operation_name_suffix>arg[0].model1.name</operation_name_suffix>
+            <operation_name_suffix>arg[0].model1.getId()</operation_name_suffix>
+            <tag key=""tag_os"">arg[0].os.[1]</tag>
+            <log key=""log_map"">arg[0].getM().['k1']</log>
+        </method>
+    </class>
+    <class class_name=""test.apache.skywalking.testcase.customize.service.TestService2"">
+        <method method=""staticMethod(java.lang.String,int.class)"" operation_name=""/is_2_static_method"" static=""true"">
+            <tag key=""tag_2_1"">arg[0]</tag>
+            <log key=""log_1_1"">arg[1]</log>
+        </method>
+        <method method=""method([Ljava.lang.Object;)"" operation_name=""/method_4"" static=""false"">
+            <tag key=""tag_4_1"">arg[0].[0]</tag>CustomizeController","[{'comment': 'Is the `CustomizeController` is useless? if yes, please remove it.', 'commenter': 'ascrutae'}, {'comment': 'Yes, I fixed it.', 'commenter': 'zhaoyuguang'}]"
2300,apm-commons/apm-util/src/main/java/org/apache/skywalking/apm/util/MethodUtil.java,"@@ -0,0 +1,45 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.util;
+
+import java.lang.reflect.Method;
+
+/**
+ * According to the input parameter,
+ * return the OperationName for the span record,
+ * It can determine the unique method
+ *
+ * @author zhaoyuguang
+ */
+
+public class MethodUtil {","[{'comment': 'This is not SkyWalking util. It is an agent util. Please move it into your plugin', 'commenter': 'wu-sheng'}, {'comment': 'It was originally used org.apache.skywalking.apm.toolkit.activation.trace.TraceAnnotationMethodInterceptor', 'commenter': 'zhaoyuguang'}, {'comment': 'Then, let us move it into agent-core/util', 'commenter': 'wu-sheng'}]"
2300,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -164,4 +167,16 @@
             public static boolean TRACE_DSL = false;
         }
     }
+
+    public static class Customize {","[{'comment': 'Customize plugin config should be an inner class of Plugin. Take `Plugin#Elasticsearch` as an example', 'commenter': 'wu-sheng'}, {'comment': 'Agree. It looks better.', 'commenter': 'zhaoyuguang'}]"
2300,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -164,4 +167,16 @@
             public static boolean TRACE_DSL = false;
         }
     }
+
+    public static class Customize {
+        /**
+         * Custom enhancement class configuration file path, recommended to use an absolute path.
+         */
+        public static String ENHANCE_FILE = """";
+
+        /**
+         * Some information after custom enhancements, this configuration is used by the custom enhancement plugin.
+         */
+        public static Map<String, Object> CONTEXT = new HashMap<String, Object>();","[{'comment': 'The reason you put the CONTEXT here, is this for avoiding classloader isolation issue? If SO, add this to comments.', 'commenter': 'wu-sheng'}, {'comment': 'As you said for avoiding classloader isolation. ', 'commenter': 'zhaoyuguang'}]"
2300,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/PluginSpiFactory.java,"@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.plugin;
+
+import org.apache.skywalking.apm.agent.core.plugin.loader.AgentClassLoader;
+import org.apache.skywalking.apm.agent.core.plugin.loader.InstrumentationServiceLoader;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.ServiceLoader;
+
+/**
+ * The plugin can be inserted into the kernel by implementing this spi return PluginDefine list.
+ *
+ * @author zhaoyuguang
+ */
+
+public enum PluginSpiFactory {","[{'comment': '`PluginSpiFactory` -> `DynamicPluginLoader`', 'commenter': 'wu-sheng'}, {'comment': 'Agree. It looks better.', 'commenter': 'zhaoyuguang'}]"
2300,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/PluginSpiFactory.java,"@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.plugin;
+
+import org.apache.skywalking.apm.agent.core.plugin.loader.AgentClassLoader;
+import org.apache.skywalking.apm.agent.core.plugin.loader.InstrumentationServiceLoader;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.ServiceLoader;
+
+/**
+ * The plugin can be inserted into the kernel by implementing this spi return PluginDefine list.
+ *
+ * @author zhaoyuguang
+ */
+
+public enum PluginSpiFactory {
+
+    INSTANCE;
+
+    public List<AbstractClassEnhancePluginDefine> load(AgentClassLoader classLoader) {
+        List<AbstractClassEnhancePluginDefine> all = new ArrayList<AbstractClassEnhancePluginDefine>();
+        for (InstrumentationServiceLoader instrumentationServiceLoader : ServiceLoader.load(InstrumentationServiceLoader.class, classLoader)) {","[{'comment': '`InstrumentationServiceLoader` -> `InstrumentationLoader`', 'commenter': 'wu-sheng'}, {'comment': 'Agree. It looks better.', 'commenter': 'zhaoyuguang'}]"
2300,apm-sniffer/optional-plugins/customize-enhance-plugin/src/test/java/org/apache/skywalking/apm/plugin/customize/util/CustomizeExpressionTest.java,"@@ -0,0 +1,172 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.customize.util;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * @author zhaoyuguang
+ */
+
+public class CustomizeExpressionTest {
+
+    @Test
+    public void testExpression() {","[{'comment': 'What happens if the list index out of bounds? Do we have a test for that?', 'commenter': 'wu-sheng'}, {'comment': 'If the expression causes an exception, will be return String ""null"" and logger.error(e, ""parse expression error, expression is {}"", expression).\r\nThis is the case now, can it?', 'commenter': 'zhaoyuguang'}, {'comment': 'List and array add index out of bounds judgment, and logger.error ==> logger.debug', 'commenter': 'zhaoyuguang'}]"
2395,docs/en/setup/backend/metric-exporter.md,"@@ -0,0 +1,46 @@
+# Metric Exporter
+SkyWalking provides basic and most important metric aggregation, alarm and analysis. 
+In real world, people may want to forward the data to their 3rd party system, for deeper analysis or anything else.
+**Metric Exporter** makes that possible.
+
+Metric exporter is an independent module, you need manually active it.
+
+Right now, we provide the following exporters
+1. gRPC exporter
+
+## gRPC exporter
+gRPC exporter uses SkyWalking native exporter service definition. Here is proto definition.
+```proto
+service MetricExportService {
+    rpc export (stream ExportMetricValue) returns (ExportResponse) {
+    }
+}
+
+message ExportMetricValue {
+    string metricName = 1;
+    string entityName = 2;
+    string entityId = 3;
+    ValueType type = 5;","[{'comment': 'Number 4 is absent.', 'commenter': 'peng-yongsheng'}]"
2395,oap-server/exporter/src/main/proto/metric-exporter.proto,"@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+syntax = ""proto3"";
+
+option java_multiple_files = true;
+option java_package = ""org.apache.skywalking.oap.server.exporter.grpc"";
+
+
+service MetricExportService {
+    rpc export (stream ExportMetricValue) returns (ExportResponse) {
+    }
+}
+
+message ExportMetricValue {
+    string metricName = 1;
+    string entityName = 2;
+    string entityId = 3;
+    ValueType type = 5;","[{'comment': 'Number 4 is absent.', 'commenter': 'peng-yongsheng'}]"
2409,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/command/CommandSerializer.java,"@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.network.trace.component.command;
+
+import java.util.HashMap;
+import java.util.Map;
+import org.apache.skywalking.apm.network.common.Command;
+
+/**
+ *
+ * @author Zhang Xin
+ */
+public class CommandSerializer {
+
+    public final static Map<String, Deserializable> COMMAND_SERIALIZE_MAPPING = new HashMap<String, Deserializable>(5);
+
+    static {
+        COMMAND_SERIALIZE_MAPPING.put(""EndpointMetadataReset"", new EndpointResetCommand(""FOR_DESERIALIZE""));
+        COMMAND_SERIALIZE_MAPPING.put(""InstanceMetadataReset"", new InstanceResetCommand(""FOR_DESERIALIZE""));
+        COMMAND_SERIALIZE_MAPPING.put(""NetworkAddressMetadataReset"", new NetworkResetCommand(""FOR_DESERIALIZE""));
+        COMMAND_SERIALIZE_MAPPING.put(""ServiceMetadataReset"", new ServiceResetCommand(""FOR_DESERIALIZE""));
+        COMMAND_SERIALIZE_MAPPING.put(""TraceIgnore"", new TraceIgnoreCommand(""FOR_DESERIALIZE""));","[{'comment': ""I am totally confused about these. All command construct arguments say `serialNumber`. What are you trying to do here?\r\n\r\nI don't think you should use this construct. @peng-yongsheng suggestion?"", 'commenter': 'wu-sheng'}]"
2409,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/commands/CommandService.java,"@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.agent.core.commands;
+
+import java.util.ArrayList;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+import org.apache.skywalking.apm.agent.core.boot.BootService;
+import org.apache.skywalking.apm.agent.core.boot.DefaultImplementor;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.network.common.Command;
+import org.apache.skywalking.apm.network.common.Commands;
+import org.apache.skywalking.apm.network.trace.component.command.BaseCommand;
+import org.apache.skywalking.apm.network.trace.component.command.CommandSerializer;
+import org.apache.skywalking.apm.network.trace.component.command.UnsupportedCommandException;
+
+@DefaultImplementor
+public class CommandService implements BootService {
+
+    private static final ILog logger = LogManager.getLogger(CommandService.class);
+    private ExecutorService executorService = Executors.newSingleThreadExecutor();
+    private LinkedBlockingQueue<BaseCommand> commands = new LinkedBlockingQueue<BaseCommand>(64);
+    private CommandSerialNumberCache serialNumberCache = new CommandSerialNumberCache();
+
+    @Override
+    public void prepare() throws Throwable {
+    }
+
+    @Override
+    public void boot() throws Throwable {
+        executorService.submit(new Runnable() {
+            @Override
+            public void run() {
+                while (!Thread.currentThread().isInterrupted()) {
+                    try {
+                        BaseCommand command = commands.take();
+
+                        if (!executeAtFirstTime(command.getSerialNumber())) {
+                            continue;
+                        }
+
+                        try {
+                            CommandExecutors.newCommandExecutor(command).execute();
+                            serialNumberCache.add(command.getSerialNumber());","[{'comment': 'You have no debug log for command execution, which makes the command execute result unclear.', 'commenter': 'wu-sheng'}]"
2409,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/TracingContext.java,"@@ -460,6 +461,11 @@ private void finish() {
                 finishedSegment.setIgnore(true);
             }
         }
+
+        if (segment.createTime() < RemoteDownstreamConfig.Agent.INSTANCE_REGISTED_TIME) {","[{'comment': 'You need to create a method for this. This is also required when inject/extract and segment send to oap-server.', 'commenter': 'wu-sheng'}]"
2409,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/commands/executor/InstanceResetCommandExecutor.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.agent.core.commands.executor;
+
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.network.trace.component.command.InstanceResetCommand;
+
+/**
+ * @author Zhang Xin
+ */
+public class InstanceResetCommandExecutor extends AbstractCommandExecutor<InstanceResetCommand> {
+
+    public InstanceResetCommandExecutor(InstanceResetCommand baseCommand) {
+        super(baseCommand);
+    }
+
+    @Override
+    public void execute() {
+        RemoteDownstreamConfig.Agent.SERVICE_ID = DictionaryUtil.nullValue();
+        RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID = DictionaryUtil.nullValue();
+        RemoteDownstreamConfig.Agent.INSTANCE_REGISTED_TIME = DictionaryUtil.nullValue();","[{'comment': ""Why don't you clear other caches?"", 'commenter': 'wu-sheng'}]"
2498,oap-server/exporter/pom.xml,"@@ -35,6 +35,10 @@
             <artifactId>server-core</artifactId>
             <version>${project.version}</version>
         </dependency>
+        <dependency>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-testing</artifactId>","[{'comment': 'I think you miss dependency scope. This is a test dependency.', 'commenter': 'wu-sheng'}, {'comment': 'I found the scope was declared as test in the parent pom', 'commenter': 'flycash'}, {'comment': 'Yes, this should be fine', 'commenter': 'wu-sheng'}]"
2498,oap-server/exporter/src/test/java/org/apache/skywalking/oap/server/exporter/provider/grpc/MockLongValueIndicator.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.exporter.provider.grpc;
+
+import org.apache.skywalking.oap.server.core.analysis.indicator.IntValueHolder;
+
+/**
+ * Created by dengming, 2019.04.20
+ */
+public class MockLongValueIndicator extends MockIndicator implements IntValueHolder {","[{'comment': 'A Mock Long value indicator implement IntValueHolder? Is this true?', 'commenter': 'wu-sheng'}]"
2498,oap-server/exporter/src/test/java/org/apache/skywalking/oap/server/exporter/provider/grpc/MockIntValueIndicatior.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.exporter.provider.grpc;
+
+import org.apache.skywalking.oap.server.core.analysis.indicator.LongValueHolder;
+
+/**
+ * Created by dengming, 2019.04.20
+ */
+public class MockIntValueIndicatior extends MockIndicator implements LongValueHolder {","[{'comment': 'A Mock Int value indicator implement LongValueHolder? Is this true?', 'commenter': 'wu-sheng'}, {'comment': 'It was a mistake and now I fixed it.', 'commenter': 'flycash'}]"
2640,apm-dist/release-docs/NOTICE,"@@ -831,3 +831,61 @@ from and not be held liable to the user for any such damages as noted
 above as far as the program is concerned.
 
 ------
+
+===========================================================================
+nacos-1.0.0 Notice
+===========================================================================
+Nacos
+Copyright 2018-2019 The Apache Software Foundation
+
+This product includes software developed at
+The Alibaba MiddleWare Group.
+
+------
+This product has a bundle Spring Boot:
+                            The Spring Boot Project
+                            =================
+
+Please visit the Spring Boot web site for more information:
+
+  * https://spring.io/projects/spring-boot
+
+Copyright 2014 The Spring Boot Project
+
+The Spring Boot Project licenses this file to you under the Apache License,
+version 2.0 (the ""License""); you may not use this file except in compliance
+with the License. You may obtain a copy of the License at:
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS, WITHOUT
+WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
+License for the specific language governing permissions and limitations
+under the License.
+
+Also, please refer to each LICENSE.<component>.txt file, which is located in
+the 'license' directory of the distribution file, for the license terms of the
+components that this product depends on.
+
+------
+
+===========================================================================
+fastjson-1.2.47 Notice
+===========================================================================","[{'comment': ""fastjson notice should be removed. It doesn't include more things than its license file."", 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'IanCao'}]"
2640,apm-dist/release-docs/licenses/LICENSE-nacos.txt,"@@ -0,0 +1,201 @@
+  Apache License","[{'comment': 'This looks like a standard Apache license, which could not include the text. If I am right, please remove this file.', 'commenter': 'wu-sheng'}, {'comment': 'i just found the okhttp license is same as nacos.\r\nand okhttp license appear in apm-dist/release-docs/licenses/\r\nso i put nacos license into there', 'commenter': 'IanCao'}, {'comment': ""This is a suggestion, we don't need to copy all LICENSE when it is standard Apache 2.0."", 'commenter': 'wu-sheng'}]"
2640,docs/en/setup/backend/backend-cluster.md,"@@ -73,6 +73,18 @@ cluster:
     hostPort: ${SW_CLUSTER_CONSUL_HOST_PORT:localhost:8500}
 ```
 
+## Nacos","[{'comment': 'Why do you add document inside `Consul` paragraph? ', 'commenter': 'wu-sheng'}, {'comment': 'consul contains hostPort and serviceName, nacos also contains hostPort and serviceName,so i just copy it and change the cluster Name and default port', 'commenter': 'IanCao'}, {'comment': ""I am talking about the document, the following document is part of Consul document, if your Nacos document needs this too, please copy it in your paragraph. \r\n> Same as Zookeeper coordinator, in some cases, oap default gRPC host and port in core are not suitable for internal communication among the oap nodes. The following setting are provided to set the hot and port manually, based on your own LAN env.\r\ninternalComHost, the host registered and other oap node use this to communicate with current node.\r\ninternalComPort, the port registered and other oap node use this to communicate with current node.\r\n\r\nRight now, it looks like Consule doesn't support his, see at https://github.com/apache/skywalking/blob/dc39825a74ad31df0c1ab2736d3fed4a2f31382d/docs/en/setup/backend/backend-cluster.md#consul"", 'commenter': 'wu-sheng'}, {'comment': '`internalComHost` and `internalComPort` things are not supported in Nacos. Suggest to add.', 'commenter': 'wu-sheng'}, {'comment': ""oo..its my fault.\r\nI have not noticed that.\r\ni'll fix "", 'commenter': 'IanCao'}]"
2665,apm-sniffer/apm-sdk-plugin/resteasy-plugin/resteasy-server-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/resteasy/v3/server/SynchronousDispatcherInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.resteasy.v3.server;
+
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.jboss.resteasy.spi.HttpRequest;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author yan-fucheng
+ */
+public class SynchronousDispatcherInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        HttpRequest request = (HttpRequest) allArguments[0];
+        if (request != null) {
+            ContextCarrier contextCarrier = new ContextCarrier();
+            CarrierItem next = contextCarrier.items();
+            while (next.hasNext()) {
+                next = next.next();
+                next.setHeadValue(request.getHttpHeaders().getHeaderString(next.getHeadKey()));
+            }
+
+            AbstractSpan span = ContextManager.createEntrySpan(request.getUri().getPath(), contextCarrier);
+            Tags.URL.set(span, request.getUri().getRequestUri().toString());
+            Tags.HTTP.METHOD.set(span, request.getHttpMethod());
+            span.setComponent(ComponentsDefine.RESTEASY);
+            SpanLayer.asHttp(span);
+
+            objInst.setSkyWalkingDynamicField(span);
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        ContextManager.stopSpan();","[{'comment': 'i find this entrySpan maybe not created in beforeMethod ,but also stopSpan in afterMethod.\r\n', 'commenter': 'IanCao'}, {'comment': ""Sorry. Can you describe it in detail? I didn't find another place to create entrySpan."", 'commenter': 'yanfch'}]"
2665,apm-sniffer/apm-sdk-plugin/resteasy-plugin/resteasy-server-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/resteasy/v3/server/SynchronousDispatcherInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.resteasy.v3.server;
+
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.jboss.resteasy.spi.HttpRequest;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author yan-fucheng
+ */
+public class SynchronousDispatcherInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        HttpRequest request = (HttpRequest) allArguments[0];
+        if (request != null) {
+            ContextCarrier contextCarrier = new ContextCarrier();
+            CarrierItem next = contextCarrier.items();
+            while (next.hasNext()) {
+                next = next.next();
+                next.setHeadValue(request.getHttpHeaders().getHeaderString(next.getHeadKey()));
+            }
+
+            AbstractSpan span = ContextManager.createEntrySpan(request.getUri().getPath(), contextCarrier);
+            Tags.URL.set(span, request.getUri().getRequestUri().toString());
+            Tags.HTTP.METHOD.set(span, request.getHttpMethod());
+            span.setComponent(ComponentsDefine.RESTEASY);
+            SpanLayer.asHttp(span);
+
+            objInst.setSkyWalkingDynamicField(span);
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        Object ret) throws Throwable {
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+        Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);","[{'comment': 'same as above', 'commenter': 'IanCao'}]"
2665,apm-sniffer/apm-sdk-plugin/resteasy-plugin/resteasy-server-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/resteasy/v3/server/SynchronousDispatcherInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.resteasy.v3.server;
+
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.jboss.resteasy.spi.HttpRequest;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author yan-fucheng
+ */
+public class SynchronousDispatcherInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        HttpRequest request = (HttpRequest) allArguments[0];
+        if (request != null) {
+            ContextCarrier contextCarrier = new ContextCarrier();
+            CarrierItem next = contextCarrier.items();
+            while (next.hasNext()) {
+                next = next.next();
+                next.setHeadValue(request.getHttpHeaders().getHeaderString(next.getHeadKey()));
+            }
+
+            AbstractSpan span = ContextManager.createEntrySpan(request.getUri().getPath(), contextCarrier);","[{'comment': 'u createEntrySpan here, but  this is in `if (request != null) {`', 'commenter': 'IanCao'}]"
2665,apm-sniffer/apm-sdk-plugin/resteasy-plugin/resteasy-server-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/resteasy/v3/server/SynchronousDispatcherInterceptor.java,"@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.resteasy.v3.server;
+
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.jboss.resteasy.spi.HttpRequest;
+import org.jboss.resteasy.spi.HttpResponse;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author yan-fucheng
+ */
+public class SynchronousDispatcherInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+        MethodInterceptResult result) throws Throwable {
+        HttpRequest request = (HttpRequest) allArguments[0];
+
+        ContextCarrier contextCarrier = new ContextCarrier();
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            next.setHeadValue(request.getHttpHeaders().getHeaderString(next.getHeadKey()));
+        }
+
+        AbstractSpan span = ContextManager.createEntrySpan(request.getUri().getPath(), contextCarrier);
+        Tags.URL.set(span, request.getUri().getRequestUri().toString());
+        Tags.HTTP.METHOD.set(span, request.getHttpMethod());
+        span.setComponent(ComponentsDefine.RESTEASY);
+        SpanLayer.asHttp(span);
+        objInst.setSkyWalkingDynamicField(span);","[{'comment': 'If this request runs in sync mode, does it necessary to `#setSkyWalkingDynamicField`, because I noticed, all places of using `#getSkyWalkingDynamicField` are async interceptors, at the same time, `ContextManager.activeSpan().prepareForAsync();` called in another place. \r\n\r\nIs this the only way you could make plugin works?\r\n\r\nIn my mind, I prefer only set dynamic field if necessary, and make sure the `ContextManager.activeSpan().prepareForAsync();` result is set into the dynamic field(at the same place, if possible)\r\n\r\nI am not familiar with RESTEasy lib, so I could be wrong. I just comment from the perspective of improving codes readability.', 'commenter': 'wu-sheng'}, {'comment': 'Is there any way I can get the span directly from the `AsynchronousResponseInjectorInterceptor#beforeMethod` EnhancedInstance? How can I pass it through the dynamic field? would appreciate your guidance. 🥺', 'commenter': 'yanfch'}, {'comment': 'I am thinking about is this the right case of using asyncFinish APIs. In most case, when callback is async, we usually create a snapshot and start a new segment for the callback. Because, in some scenarios, people have further spans in callback, such as accessing the database.\r\n\r\n`#asyncFinish` API is designed for vert.x originaly, for making sure the span duration is right. Is that your design?', 'commenter': 'wu-sheng'}, {'comment': 'And also, my intention of this review is making sure the plugin is right. You save the span in sync(`SynchronousDispatcherInterceptor`) interceptor for the potential AsynchronousResponse.', 'commenter': 'wu-sheng'}, {'comment': 'Again, I may be wrong. I am just talking based on your interceptor name and code styles. Please correct me if I am wrong.', 'commenter': 'wu-sheng'}, {'comment': ""The resteasy async request separates the request and response in different threads. At this point, the connection is still waiting for this response. I think this should also be included in the span finsh time. If the snapshot finsh time is used, it may be 0ms. So I used `prepareForAsync()`, I don't know if it is the same as vert.x, I don't know if I am doing this right?"", 'commenter': 'yanfch'}, {'comment': 'If you think this response time makes sense, then I am good with that. I just remind you that, people could do further works in response callback(Am I right?), so even you use async finish to make the duration longer, still recommend you to do capture/continued.', 'commenter': 'wu-sheng'}, {'comment': ""\r\n![image](https://user-images.githubusercontent.com/10338055/58087822-ed4c9800-7bf3-11e9-886e-9bfa584db366.png)\r\n\r\nI have a problem. In this case, I don't want to enhance Runnable. Can I directly let the user solve it by using the toolkit?\r\n\r\nIs there still a better way? I have no idea now. "", 'commenter': 'yanfch'}, {'comment': ""`Don't enhance Runnable` is 100% a good idea. Don't do that. If the user wants a runnable, let him do it by himself."", 'commenter': 'wu-sheng'}, {'comment': 'I modified it and deleted the extra async part. waiting for test case.', 'commenter': 'yanfch'}]"
2725,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -0,0 +1,48 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-cluster-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>cluster-etcd-plugin</artifactId>
+
+    <name>cluster-etcd-plugin</name>
+    <!-- FIXME change it to the project's website -->
+    <url>http://www.example.com</url>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <maven.compiler.source>1.7</maven.compiler.source>
+        <maven.compiler.target>1.7</maven.compiler.target>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>junit</groupId>
+            <artifactId>junit</artifactId>
+            <version>4.11</version>
+            <scope>test</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>server-core</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+
+        <!-- https://mvnrepository.com/artifact/org.mousio/etcd4j -->","[{'comment': 'What is this comment for?', 'commenter': 'wu-sheng'}, {'comment': 'i copy from the maven repository, i will remove it .', 'commenter': 'wayilau'}]"
2725,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -0,0 +1,48 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-cluster-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>cluster-etcd-plugin</artifactId>
+
+    <name>cluster-etcd-plugin</name>
+    <!-- FIXME change it to the project's website -->
+    <url>http://www.example.com</url>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <maven.compiler.source>1.7</maven.compiler.source>
+        <maven.compiler.target>1.7</maven.compiler.target>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>junit</groupId>
+            <artifactId>junit</artifactId>
+            <version>4.11</version>","[{'comment': 'Test has been included. ', 'commenter': 'wu-sheng'}, {'comment': 'removed.', 'commenter': 'wayilau'}]"
2725,oap-server/server-cluster-plugin/cluster-etcd-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/etcd/EtcdCoordinator.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.cluster.plugin.etcd;
+
+import com.google.common.base.Strings;
+import com.google.gson.Gson;
+import com.google.gson.reflect.TypeToken;
+import java.util.ArrayList;
+import java.util.List;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.oap.server.core.cluster.ClusterNodesQuery;
+import org.apache.skywalking.oap.server.core.cluster.ClusterRegister;
+import org.apache.skywalking.oap.server.core.cluster.RemoteInstance;
+import org.apache.skywalking.oap.server.core.cluster.ServiceRegisterException;
+import org.apache.skywalking.oap.server.core.remote.client.Address;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdCoordinator implements ClusterRegister, ClusterNodesQuery {
+
+    private ClusterModuleEtcdConfig config;
+
+    private EtcdClient client;
+
+    private volatile Address selfAddress;
+
+    private final String serviceName;
+
+    public EtcdCoordinator(ClusterModuleEtcdConfig config, EtcdClient client) {
+        this.config = config;
+        this.client = client;
+        this.serviceName = config.getServiceName();
+    }
+
+    @Override public List<RemoteInstance> queryRemoteNodes() {
+
+        List<RemoteInstance> res = new ArrayList<>();
+        try {
+            EtcdKeysResponse response = client.get(serviceName).send().get();
+            String json = response.getNode().getValue();
+            Gson gson = new Gson();
+            List<EtcdEndpoint> list = gson.fromJson(json, new TypeToken<List<EtcdEndpoint>>() {
+            }.getType());
+
+            if (CollectionUtils.isNotEmpty(list)) {
+                list.forEach(node -> {
+                    res.add(new RemoteInstance(new Address(node.getHost(), node.getPort(), true)));
+                });
+
+            }
+
+        } catch (Exception e) {
+            throw new RuntimeException(e);
+        }
+
+        return res;
+    }
+
+    @Override public void registerRemote(RemoteInstance remoteInstance) throws ServiceRegisterException {
+
+        if (needUsingInternalAddr()) {
+            remoteInstance = new RemoteInstance(new Address(config.getInternalComHost(), config.getInternalComPort(), true));
+        }
+
+        this.selfAddress = remoteInstance.getAddress();
+
+        EtcdEndpoint endpoint = new EtcdEndpoint.Builder().serviceId(serviceName).host(selfAddress.getHost()).port(selfAddress.getPort()).build();","[{'comment': 'Does the serviceId here need to be unique?', 'commenter': 'JaredTan95'}, {'comment': 'yes, in the same cluster serviceId must be unique.', 'commenter': 'wayilau'}, {'comment': 'So, In my opinion, we also need to provide the `serviceId` configurable like https://github.com/apache/skywalking/blob/master/oap-server/server-starter/src/main/resources/application.yml#L31 ?', 'commenter': 'JaredTan95'}, {'comment': 'I think etcd is like consul does.  serviceName actually is the serviceId which already configured. ', 'commenter': 'wayilau'}, {'comment': 'Have you tested in Cluster mode? like deployment 2 or more skywalking-oap instance?', 'commenter': 'JaredTan95'}, {'comment': 'emm.., i just test the etcd docker. i will do this tomorrow.', 'commenter': 'wayilau'}, {'comment': 'Why you name the config `serviceName`, but set to `serviceId` in etcd API? What is different?', 'commenter': 'wu-sheng'}, {'comment': 'I will move the serviceId to Service Name. the same as them.', 'commenter': 'wayilau'}]"
2725,apm-dist/release-docs/LICENSE,"@@ -330,6 +332,7 @@ The text of each license is also included at licenses/LICENSE-[project].txt.
     jopt-simple 5.0.2: https://github.com/jopt-simple/jopt-simple , MIT
     bcpkix-jdk15on 1.55: http://www.bouncycastle.org/licence.html , MIT
     bcprov-jdk15on 1.55: http://www.bouncycastle.org/licence.html , MIT
+    minimao-json 0.9.5:  https://github.com/ralfstx/minimal-json, MIT","[{'comment': 'You need to copy the MIT license into the license folder, like others.', 'commenter': 'wu-sheng'}, {'comment': 'resolved.', 'commenter': 'wayilau'}]"
2725,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -0,0 +1,177 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-cluster-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>cluster-etcd-plugin</artifactId>
+
+    <name>cluster-etcd-plugin</name>
+    <!-- FIXME change it to the project's website -->
+    <url>http://www.example.com</url>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <maven.compiler.source>1.8</maven.compiler.source>
+        <maven.compiler.target>1.8</maven.compiler.target>","[{'comment': ""compile level should be set in 1.8 already. Don't need this."", 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'wayilau'}]"
2725,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -0,0 +1,177 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-cluster-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>cluster-etcd-plugin</artifactId>
+
+    <name>cluster-etcd-plugin</name>
+    <!-- FIXME change it to the project's website -->
+    <url>http://www.example.com</url>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <maven.compiler.source>1.8</maven.compiler.source>
+        <maven.compiler.target>1.8</maven.compiler.target>
+        <etcd4j.version>2.17.0</etcd4j.version>
+        <etcd.version>v3.2.3</etcd.version>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>server-core</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-dns</artifactId>
+            <version>4.1.27.Final</version>
+            <scope>provided</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-http</artifactId>
+            <version>4.1.27.Final</version>
+            <scope>provided</scope>","[{'comment': 'What is this `provided` dependency for?', 'commenter': 'wu-sheng'}, {'comment': 'I will remove this dependency.', 'commenter': 'wayilau'}]"
2725,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -0,0 +1,177 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-cluster-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>cluster-etcd-plugin</artifactId>
+
+    <name>cluster-etcd-plugin</name>
+    <!-- FIXME change it to the project's website -->
+    <url>http://www.example.com</url>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <maven.compiler.source>1.8</maven.compiler.source>
+        <maven.compiler.target>1.8</maven.compiler.target>
+        <etcd4j.version>2.17.0</etcd4j.version>
+        <etcd.version>v3.2.3</etcd.version>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>server-core</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-dns</artifactId>
+            <version>4.1.27.Final</version>
+            <scope>provided</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-http</artifactId>
+            <version>4.1.27.Final</version>
+            <scope>provided</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-handler</artifactId>
+            <version>4.1.27.Final</version>
+        </dependency>","[{'comment': 'Netty should already be included. Do you need anything differently? I have concerns about conflict.', 'commenter': 'wu-sheng'}, {'comment': 'I was busy these days . I will fix the pom.xml quickly.  since use 4.1.27.Final that provided from the dist tar is fine.', 'commenter': 'wayilau'}, {'comment': 'I mean,are netty libs included before this pr? Or not', 'commenter': 'wu-sheng'}, {'comment': ""not all netty jars included before this pr. I add netty-handler and netty-resolver-dns. If i didn't, ClassNotFoundException will be occurd."", 'commenter': 'wayilau'}]"
2725,docker/oap/docker-entrypoint.sh,"@@ -49,14 +49,24 @@ EOT
 }
 
 generateClusterConsul() {
-    cat <<EOT >> ${var_application_file}
-cluster:
-  consul:
-    serviceName: \${SW_SERVICE_NAME:""SkyWalking_OAP_Cluster""}
-    # Consul cluster nodes, example: 10.0.0.1:8500,10.0.0.2:8500,10.0.0.3:8500
-    hostPort: \${SW_CLUSTER_CONSUL_HOST_PORT:localhost:8500}
-EOT
-}
+     cat <<EOT >> ${var_application_file}
+ cluster:
+   consul:
+     serviceName: \${SW_SERVICE_NAME:""SkyWalking_OAP_Cluster""}
+     # Consul cluster nodes, example: 10.0.0.1:8500,10.0.0.2:8500,10.0.0.3:8500
+     hostPort: \${SW_CLUSTER_CONSUL_HOST_PORT:localhost:8500}
+ EOT
+ }
+
+ generateClusterEtcd() {
+      cat <<EOT >> ${var_application_file}
+  cluster:
+    consul:","[{'comment': '```yaml\r\ncluster:\r\n  etcd:\r\n```', 'commenter': 'JaredTan95'}, {'comment': '> ```yaml\r\n> cluster:\r\n>   etcd:\r\n>     serviceName: \\${SW_SERVICE_NAME:""SkyWalking_OAP_Cluster""}\r\n>     # etcd cluster nodes, example: 10.0.0.1:2379,10.0.0.2:2379,10.0.0.3:2379\r\n>     hostPort: \\${SW_CLUSTER_ETCD_HOST_PORT:localhost:2379}\r\n> ```\r\n\r\nwhat is the problem? I change this from the consul config.\r\n', 'commenter': 'wayilau'}, {'comment': 'yeah, `consul `--> `etcd`.', 'commenter': 'JaredTan95'}, {'comment': ""Why this be resolved in review status, but actually it isn't."", 'commenter': 'wu-sheng'}]"
2725,oap-server/server-starter/src/main/resources/application.yml,"@@ -36,6 +36,10 @@ cluster:
 #  nacos:
 #    serviceName: ${SW_SERVICE_NAME:""SkyWalking_OAP_Cluster""}
 #    hostPort: ${SW_CLUSTER_NACOS_HOST_PORT:localhost:8848}
+#  etcd:","[{'comment': 'There are two application.yml needed to be changed. I think you miss one#', 'commenter': 'wu-sheng'}, {'comment': ""I've added.  why only one from the server-starter used after package. what about another one?"", 'commenter': 'wayilau'}]"
2725,oap-server/server-configuration/configuration-etcd/pom.xml,"@@ -0,0 +1,115 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-configuration</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>configuration-etcd</artifactId>
+
+    <name>configuration-etcd</name>
+    <!-- FIXME change it to the project's website -->
+    <url>http://www.example.com</url>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>configuration-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>library-client</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.mousio</groupId>
+            <artifactId>etcd4j</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>cluster-etcd-plugin</artifactId>
+            <version>6.2.0-SNAPSHOT</version>","[{'comment': '${project.version}', 'commenter': 'JaredTan95'}]"
2725,oap-server/server-configuration/configuration-etcd/pom.xml,"@@ -0,0 +1,115 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-configuration</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>configuration-etcd</artifactId>
+
+    <name>configuration-etcd</name>
+    <!-- FIXME change it to the project's website -->","[{'comment': 'remove this ?', 'commenter': 'JaredTan95'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,198 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+//
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null)
+                instance.setCollection(matcher.group(6));
+        }
+        objInst.setSkyWalkingDynamicField(instance);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SolrRequest<?> request = (SolrRequest<?>) allArguments[0];
+        SolrjInstance instance = (SolrjInstance) objInst.getSkyWalkingDynamicField();
+
+        String collection = instance.getCollection();
+        Object ocollection = allArguments[2];
+        if (ocollection != null) {
+            collection = ocollection.toString();
+        }
+        if (collection == null || """".equals(collection)) {
+            collection = ""<empty>"";
+        }
+
+        SolrParams params = request.getParams();
+        if (params == null) {
+            params = new ModifiableSolrParams();
+        }
+
+
+        AbstractSpan span = null;
+        if (request instanceof AbstractUpdateRequest) {
+            AbstractUpdateRequest update = (AbstractUpdateRequest) request;
+            String action = ""ADD"";
+            if (update.getAction() != null) {
+                action = update.getAction().name();
+
+                if (update.getAction() == AbstractUpdateRequest.ACTION.COMMIT) {","[{'comment': 'i think update.getAction may exec so many times.  ', 'commenter': 'wayilau'}, {'comment': '@dmsolr Please recheck, if so, then tag is very dangerous, which cost too much memory and network bandwidth. ', 'commenter': 'wu-sheng'}, {'comment': 'I will review, thanks.', 'commenter': 'dmsolr'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,198 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+//
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));","[{'comment': 'I noticed that you are using group names, but why not use it in the extraction? like:\r\n\r\n```suggestion\r\n            instance.setRemotePeer(matcher.group(""domain""));\r\n```\r\n\r\nwould be more semantic ', 'commenter': 'kezhenxu94'}, {'comment': 'That is why Java not support group names before JDK8.\r\nIt is a mistake because it must be used  in JDK8.', 'commenter': 'dmsolr'}, {'comment': ""I've forgotten, BTW, group names are supported since JDK7"", 'commenter': 'kezhenxu94'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,198 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+//
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null)
+                instance.setCollection(matcher.group(6));","[{'comment': '```suggestion\r\n                instance.setCollection(matcher.group(""collection""));\r\n```', 'commenter': 'kezhenxu94'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,198 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+//
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null)
+                instance.setCollection(matcher.group(6));
+        }
+        objInst.setSkyWalkingDynamicField(instance);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SolrRequest<?> request = (SolrRequest<?>) allArguments[0];
+        SolrjInstance instance = (SolrjInstance) objInst.getSkyWalkingDynamicField();
+
+        String collection = instance.getCollection();
+        Object ocollection = allArguments[2];
+        if (ocollection != null) {
+            collection = ocollection.toString();
+        }
+        if (collection == null || """".equals(collection)) {
+            collection = ""<empty>"";
+        }
+
+        SolrParams params = request.getParams();
+        if (params == null) {
+            params = new ModifiableSolrParams();
+        }
+
+
+        AbstractSpan span = null;
+        if (request instanceof AbstractUpdateRequest) {
+            AbstractUpdateRequest update = (AbstractUpdateRequest) request;
+            String action = ""ADD"";
+            if (update.getAction() != null) {
+                action = update.getAction().name();
+
+                if (update.getAction() == AbstractUpdateRequest.ACTION.COMMIT) {
+                    span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_COMMIT, params.get(UpdateParams.COMMIT, ""true""));
+                    span.tag(SolrjTags.TAG_SOFT_COMMIT, params.get(UpdateParams.SOFT_COMMIT, """"));
+                } else if (update.getAction() == AbstractUpdateRequest.ACTION.OPTIMIZE) {
+                    span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_OPTIMIZE, params.get(UpdateParams.OPTIMIZE, ""true""));
+                    span.tag(SolrjTags.TAG_MAX_OPTIMIZE_SEGMENTS, params.get(UpdateParams.MAX_OPTIMIZE_SEGMENTS, ""1""));
+                }
+            } else {
+                if (update instanceof UpdateRequest) {
+                    UpdateRequest ur = (UpdateRequest) update;
+                    List<SolrInputDocument> documents = ur.getDocuments();
+                    if (documents == null) {
+                        action = ""DELETE"";
+
+                        span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+                        List<String> deleteBy = ur.getDeleteById();
+                        if (deleteBy != null && !deleteBy.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByIds"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteBy.toString());
+                        }
+                        List<String> deleteQuery = ur.getDeleteQuery();
+                        if (deleteQuery != null && !deleteQuery.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByQuery"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteQuery.toString());
+                        }
+                    } else {
+                        span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+                        span.tag(SolrjTags.TAG_DOCS_SIZE, String.valueOf(documents.size()));
+                        span.tag(SolrjTags.TAG_COMMIT_WITHIN, String.valueOf(update.getCommitWithin()));
+                    }
+                }
+            }
+            span.tag(SolrjTags.TAG_QT, params.get(CommonParams.QT, ""/update""));
+            span.tag(SolrjTags.TAG_ACTION, action);
+        } else if (request instanceof QueryRequest) {
+            String operatorName = String.format(""solrJ/%s%s"", collection, request.getPath());
+            span = ContextManager.createExitSpan(operatorName, instance.getRemotePeer())
+                    .setComponent(ComponentsDefine.SOLRJ)
+                    .setLayer(SpanLayer.DB);
+            span.tag(SolrjTags.TAG_QT, params.get(CommonParams.QT, ""/select""));
+        }
+","[{'comment': 'Above codes include a lot of `instanceof`, which would be an impact for performance, especially in JRE 6-8. If possible, please consider a better way to do this.', 'commenter': 'wu-sheng'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,198 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+//
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null)
+                instance.setCollection(matcher.group(6));
+        }
+        objInst.setSkyWalkingDynamicField(instance);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SolrRequest<?> request = (SolrRequest<?>) allArguments[0];
+        SolrjInstance instance = (SolrjInstance) objInst.getSkyWalkingDynamicField();
+
+        String collection = instance.getCollection();
+        Object ocollection = allArguments[2];
+        if (ocollection != null) {
+            collection = ocollection.toString();
+        }
+        if (collection == null || """".equals(collection)) {
+            collection = ""<empty>"";
+        }
+
+        SolrParams params = request.getParams();
+        if (params == null) {
+            params = new ModifiableSolrParams();
+        }
+
+
+        AbstractSpan span = null;
+        if (request instanceof AbstractUpdateRequest) {
+            AbstractUpdateRequest update = (AbstractUpdateRequest) request;
+            String action = ""ADD"";
+            if (update.getAction() != null) {
+                action = update.getAction().name();
+
+                if (update.getAction() == AbstractUpdateRequest.ACTION.COMMIT) {
+                    span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_COMMIT, params.get(UpdateParams.COMMIT, ""true""));
+                    span.tag(SolrjTags.TAG_SOFT_COMMIT, params.get(UpdateParams.SOFT_COMMIT, """"));
+                } else if (update.getAction() == AbstractUpdateRequest.ACTION.OPTIMIZE) {
+                    span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_OPTIMIZE, params.get(UpdateParams.OPTIMIZE, ""true""));
+                    span.tag(SolrjTags.TAG_MAX_OPTIMIZE_SEGMENTS, params.get(UpdateParams.MAX_OPTIMIZE_SEGMENTS, ""1""));
+                }
+            } else {
+                if (update instanceof UpdateRequest) {
+                    UpdateRequest ur = (UpdateRequest) update;
+                    List<SolrInputDocument> documents = ur.getDocuments();
+                    if (documents == null) {
+                        action = ""DELETE"";
+
+                        span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+                        List<String> deleteBy = ur.getDeleteById();
+                        if (deleteBy != null && !deleteBy.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByIds"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteBy.toString());
+                        }
+                        List<String> deleteQuery = ur.getDeleteQuery();
+                        if (deleteQuery != null && !deleteQuery.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByQuery"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteQuery.toString());
+                        }
+                    } else {
+                        span = getSpan(collection, request.getPath(), action, instance.getRemotePeer());
+                        span.tag(SolrjTags.TAG_DOCS_SIZE, String.valueOf(documents.size()));
+                        span.tag(SolrjTags.TAG_COMMIT_WITHIN, String.valueOf(update.getCommitWithin()));
+                    }
+                }
+            }
+            span.tag(SolrjTags.TAG_QT, params.get(CommonParams.QT, ""/update""));
+            span.tag(SolrjTags.TAG_ACTION, action);
+        } else if (request instanceof QueryRequest) {
+            String operatorName = String.format(""solrJ/%s%s"", collection, request.getPath());
+            span = ContextManager.createExitSpan(operatorName, instance.getRemotePeer())
+                    .setComponent(ComponentsDefine.SOLRJ)
+                    .setLayer(SpanLayer.DB);
+            span.tag(SolrjTags.TAG_QT, params.get(CommonParams.QT, ""/select""));
+        }
+
+        span.tag(SolrjTags.TAG_PATH, request.getPath());
+        span.tag(SolrjTags.TAG_COLLECTION, collection);
+        span.tag(SolrjTags.TAG_METHOD, request.getMethod().name());
+
+        ContextManager.getRuntimeContext().put(""instance"", instance);
+        ContextManager.getRuntimeContext().put(""request.start"", Long.valueOf(System.currentTimeMillis()));","[{'comment': 'What do you use `RuntimeContext`? This API is just designed for particular cases, please explain the reason.', 'commenter': 'wu-sheng'}, {'comment': 'do we need boxing the long value manually? there is auto boxing', 'commenter': 'kezhenxu94'}, {'comment': 'No particular reason. just why it is more convenient than ThreadLocal. \r\nI get it now, I can use ThreadLocal.', 'commenter': 'dmsolr'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/resources/skywalking-plugin.def,"@@ -0,0 +1,18 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+solrj=org.apache.skywalking.apm.plugin.solrj.define.SolrClientInstrumentation
+solrj=org.apache.skywalking.apm.plugin.solrj.define.HttpClientInstrumentation","[{'comment': '`version` needs to be included.', 'commenter': 'wu-sheng'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,194 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.Context;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null) {
+                instance.setCollection(matcher.group(6));
+            }
+        }
+        objInst.setSkyWalkingDynamicField(instance);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SolrRequest<?> request = (SolrRequest<?>) allArguments[0];
+        SolrjInstance instance = (SolrjInstance) objInst.getSkyWalkingDynamicField();
+
+        SolrParams params = getParams(request.getParams());
+        String collection = getCollection(instance, allArguments[2]);
+
+        AbstractSpan span = null;
+        if (""/update"".equals(request.getPath())) {
+            AbstractUpdateRequest update = (AbstractUpdateRequest) request;
+
+            String actionName = ""ADD"";
+            AbstractUpdateRequest.ACTION action = update.getAction();
+            if (action == null) {
+                if (update instanceof UpdateRequest) {
+                    UpdateRequest ur = (UpdateRequest) update;
+                    List<SolrInputDocument> documents = ur.getDocuments();
+                    if (documents == null) {
+                        actionName = ""DELETE"";
+
+                        span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+                        List<String> deleteBy = ur.getDeleteById();
+                        if (deleteBy != null && !deleteBy.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByIds"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteBy.toString());
+                        }
+                        List<String> deleteQuery = ur.getDeleteQuery();
+                        if (deleteQuery != null && !deleteQuery.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByQuery"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteQuery.toString());
+                        }
+                    } else {
+                        span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+                        span.tag(SolrjTags.TAG_DOCS_SIZE, String.valueOf(documents.size()));
+                        span.tag(SolrjTags.TAG_COMMIT_WITHIN, String.valueOf(update.getCommitWithin()));
+                    }
+                }
+            } else {
+                actionName = action.name();
+                if (action == AbstractUpdateRequest.ACTION.COMMIT) {
+                    span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_COMMIT, ""true"");
+                    span.tag(SolrjTags.TAG_SOFT_COMMIT, params.get(UpdateParams.SOFT_COMMIT, """"));
+                } else {
+                    span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_OPTIMIZE, ""true"");
+                    span.tag(SolrjTags.TAG_MAX_OPTIMIZE_SEGMENTS, params.get(UpdateParams.MAX_OPTIMIZE_SEGMENTS, ""1""));
+                }
+            }
+            span.tag(SolrjTags.TAG_ACTION, actionName);
+        } else if (request instanceof QueryRequest) { // It failed to spot that through 'path' when it had defined QueryType.
+            String operatorName = String.format(""solrJ/%s%s"", collection, request.getPath());
+            span = ContextManager.createExitSpan(operatorName, instance.getRemotePeer())
+                    .setComponent(ComponentsDefine.SOLRJ)
+                    .setLayer(SpanLayer.DB);
+        } else { // No admin API
+            return;
+        }
+
+        span.tag(SolrjTags.TAG_PATH, request.getPath());
+        span.tag(SolrjTags.TAG_COLLECTION, collection);","[{'comment': 'span is maybe null here ?', 'commenter': 'IanCao'}, {'comment': '+1', 'commenter': 'wu-sheng'}, {'comment': '@dmsolr Any reply here?', 'commenter': 'wu-sheng'}, {'comment': 'I see it right now. yes, I will fix.', 'commenter': 'dmsolr'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,194 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.Context;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null) {
+                instance.setCollection(matcher.group(6));
+            }
+        }
+        objInst.setSkyWalkingDynamicField(instance);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SolrRequest<?> request = (SolrRequest<?>) allArguments[0];
+        SolrjInstance instance = (SolrjInstance) objInst.getSkyWalkingDynamicField();
+
+        SolrParams params = getParams(request.getParams());
+        String collection = getCollection(instance, allArguments[2]);
+
+        AbstractSpan span = null;
+        if (""/update"".equals(request.getPath())) {
+            AbstractUpdateRequest update = (AbstractUpdateRequest) request;
+
+            String actionName = ""ADD"";
+            AbstractUpdateRequest.ACTION action = update.getAction();
+            if (action == null) {
+                if (update instanceof UpdateRequest) {
+                    UpdateRequest ur = (UpdateRequest) update;
+                    List<SolrInputDocument> documents = ur.getDocuments();
+                    if (documents == null) {
+                        actionName = ""DELETE"";
+
+                        span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+                        List<String> deleteBy = ur.getDeleteById();
+                        if (deleteBy != null && !deleteBy.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByIds"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteBy.toString());
+                        }
+                        List<String> deleteQuery = ur.getDeleteQuery();
+                        if (deleteQuery != null && !deleteQuery.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByQuery"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteQuery.toString());
+                        }
+                    } else {
+                        span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+                        span.tag(SolrjTags.TAG_DOCS_SIZE, String.valueOf(documents.size()));
+                        span.tag(SolrjTags.TAG_COMMIT_WITHIN, String.valueOf(update.getCommitWithin()));
+                    }
+                }
+            } else {
+                actionName = action.name();
+                if (action == AbstractUpdateRequest.ACTION.COMMIT) {
+                    span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_COMMIT, ""true"");
+                    span.tag(SolrjTags.TAG_SOFT_COMMIT, params.get(UpdateParams.SOFT_COMMIT, """"));
+                } else {
+                    span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_OPTIMIZE, ""true"");
+                    span.tag(SolrjTags.TAG_MAX_OPTIMIZE_SEGMENTS, params.get(UpdateParams.MAX_OPTIMIZE_SEGMENTS, ""1""));
+                }
+            }
+            span.tag(SolrjTags.TAG_ACTION, actionName);
+        } else if (request instanceof QueryRequest) { // It failed to spot that through 'path' when it had defined QueryType.
+            String operatorName = String.format(""solrJ/%s%s"", collection, request.getPath());
+            span = ContextManager.createExitSpan(operatorName, instance.getRemotePeer())
+                    .setComponent(ComponentsDefine.SOLRJ)
+                    .setLayer(SpanLayer.DB);
+        } else { // No admin API
+            return;
+        }
+
+        span.tag(SolrjTags.TAG_PATH, request.getPath());
+        span.tag(SolrjTags.TAG_COLLECTION, collection);
+        span.tag(SolrjTags.TAG_METHOD, request.getMethod().name());
+        span.tag(SolrjTags.TAG_QT, params.get(CommonParams.QT, request.getPath()));
+
+        Context.get().start();
+    }
+
+    @Override
+    @SuppressWarnings(""unchecked"")
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                              Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        if (!ContextManager.isActive()) return ret;
+
+        final Context context = Context.remove();
+        final long elapse = System.currentTimeMillis() - context.getStartTime();
+
+        AbstractSpan span = ContextManager.activeSpan();
+        NamedList<Object> response = (NamedList<Object>) ret;
+        if (response != null) {
+            NamedList<Object> header = (NamedList<Object>) response.get(""responseHeader"");
+            if (header != null) { // common
+                span.tag(SolrjTags.TAG_STATUS, header.get(""status"").toString());
+                span.tag(SolrjTags.TAG_Q_TIME, header.get(""QTime"").toString());
+            }
+            SolrDocumentList list = (SolrDocumentList) response.get(""response"");
+            if (list != null) { // query
+                span.tag(SolrjTags.TAG_NUM_FOUND, String.valueOf(list.getNumFound()));
+            }
+        }
+        SolrjTags.addHttpResponse(span, context);
+        SolrjTags.addElapseTime(span, elapse);
+
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);","[{'comment': 'span is maybe not the solr span', 'commenter': 'IanCao'}, {'comment': 'Suggest adding`if (!ContextManager.isActive()) return ret;` to avoid NPE.', 'commenter': 'wu-sheng'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,194 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.Context;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)","[{'comment': 'Comment should be removed.', 'commenter': 'wu-sheng'}, {'comment': 'need to remove all of comments?', 'commenter': 'dmsolr'}, {'comment': 'This looks like unnecessary, right? We need comments to explain codes.', 'commenter': 'wu-sheng'}, {'comment': 'Yes, you are right. : )', 'commenter': 'dmsolr'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,194 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.Context;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+//      HttpSolrClient(HttpSolrClient.Builder builder)
+        SolrjInstance instance = new SolrjInstance();
+        HttpSolrClient client = (HttpSolrClient) objInst;
+
+        Matcher matcher = URL_REGEX.matcher(client.getBaseURL());
+        if (matcher.find()) {
+            instance.setRemotePeer(matcher.group(3));
+            if (matcher.group(6) != null) {
+                instance.setCollection(matcher.group(6));
+            }
+        }
+        objInst.setSkyWalkingDynamicField(instance);
+    }
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SolrRequest<?> request = (SolrRequest<?>) allArguments[0];
+        SolrjInstance instance = (SolrjInstance) objInst.getSkyWalkingDynamicField();
+
+        SolrParams params = getParams(request.getParams());
+        String collection = getCollection(instance, allArguments[2]);
+
+        AbstractSpan span = null;
+        if (""/update"".equals(request.getPath())) {
+            AbstractUpdateRequest update = (AbstractUpdateRequest) request;
+
+            String actionName = ""ADD"";
+            AbstractUpdateRequest.ACTION action = update.getAction();
+            if (action == null) {
+                if (update instanceof UpdateRequest) {
+                    UpdateRequest ur = (UpdateRequest) update;
+                    List<SolrInputDocument> documents = ur.getDocuments();
+                    if (documents == null) {
+                        actionName = ""DELETE"";
+
+                        span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+                        List<String> deleteBy = ur.getDeleteById();
+                        if (deleteBy != null && !deleteBy.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByIds"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteBy.toString());
+                        }
+                        List<String> deleteQuery = ur.getDeleteQuery();
+                        if (deleteQuery != null && !deleteQuery.isEmpty()) {
+                            span.tag(SolrjTags.TAG_DELETE_TYPE, ""deleteByQuery"");
+                            span.tag(SolrjTags.TAG_DELETE_VALUE, deleteQuery.toString());
+                        }
+                    } else {
+                        span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+                        span.tag(SolrjTags.TAG_DOCS_SIZE, String.valueOf(documents.size()));
+                        span.tag(SolrjTags.TAG_COMMIT_WITHIN, String.valueOf(update.getCommitWithin()));
+                    }
+                }
+            } else {
+                actionName = action.name();
+                if (action == AbstractUpdateRequest.ACTION.COMMIT) {
+                    span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_COMMIT, ""true"");
+                    span.tag(SolrjTags.TAG_SOFT_COMMIT, params.get(UpdateParams.SOFT_COMMIT, """"));
+                } else {
+                    span = getSpan(collection, request.getPath(), actionName, instance.getRemotePeer());
+
+                    span.tag(SolrjTags.TAG_OPTIMIZE, ""true"");
+                    span.tag(SolrjTags.TAG_MAX_OPTIMIZE_SEGMENTS, params.get(UpdateParams.MAX_OPTIMIZE_SEGMENTS, ""1""));
+                }
+            }
+            span.tag(SolrjTags.TAG_ACTION, actionName);
+        } else if (request instanceof QueryRequest) { // It failed to spot that through 'path' when it had defined QueryType.
+            String operatorName = String.format(""solrJ/%s%s"", collection, request.getPath());
+            span = ContextManager.createExitSpan(operatorName, instance.getRemotePeer())
+                    .setComponent(ComponentsDefine.SOLRJ)
+                    .setLayer(SpanLayer.DB);
+        } else { // No admin API
+            return;
+        }
+
+        span.tag(SolrjTags.TAG_PATH, request.getPath());
+        span.tag(SolrjTags.TAG_COLLECTION, collection);
+        span.tag(SolrjTags.TAG_METHOD, request.getMethod().name());
+        span.tag(SolrjTags.TAG_QT, params.get(CommonParams.QT, request.getPath()));
+
+        Context.get().start();
+    }
+
+    @Override
+    @SuppressWarnings(""unchecked"")
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                              Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        if (!ContextManager.isActive()) return ret;
+
+        final Context context = Context.remove();
+        final long elapse = System.currentTimeMillis() - context.getStartTime();
+
+        AbstractSpan span = ContextManager.activeSpan();
+        NamedList<Object> response = (NamedList<Object>) ret;
+        if (response != null) {
+            NamedList<Object> header = (NamedList<Object>) response.get(""responseHeader"");
+            if (header != null) { // common
+                span.tag(SolrjTags.TAG_STATUS, header.get(""status"").toString());","[{'comment': 'could u confirm `header.get(""status"")` isn\'t null ?', 'commenter': 'IanCao'}, {'comment': 'Yes, it cannot be null. Just like status code in http response.', 'commenter': 'dmsolr'}, {'comment': 'Thanks for your suggestion.\r\nI change to String.valueOf(...).', 'commenter': 'dmsolr'}]"
2730,apm-sniffer/apm-sdk-plugin/pom.xml,"@@ -28,50 +28,7 @@
 
     <artifactId>apm-sdk-plugin</artifactId>
     <modules>
-        <module>dubbo-plugin</module>
-        <module>jdbc-commons</module>
-        <module>httpClient-4.x-plugin</module>
-        <module>jedis-2.x-plugin</module>
-        <module>redisson-3.x-plugin</module>
-        <module>tomcat-7.x-8.x-plugin</module>
-        <module>motan-plugin</module>
-        <module>mongodb-3.x-plugin</module>
-        <module>feign-default-http-9.x-plugin</module>
-        <module>okhttp-3.x-plugin</module>
-        <module>spring-plugins</module>
-        <module>struts2-2.x-plugin</module>
-        <module>nutz-plugins</module>
-        <module>jetty-plugin</module>
-        <module>spymemcached-2.x-plugin</module>
-        <module>sharding-jdbc-1.5.x-plugin</module>
-        <module>sharding-sphere-3.x-plugin</module>
-        <module>xmemcached-2.x-plugin</module>
-        <module>grpc-1.x-plugin</module>
-        <module>mysql-5.x-plugin</module>
-        <module>mysql-6.x-plugin</module>
-        <module>mysql-8.x-plugin</module>
-        <module>mysql-common</module>
-        <module>h2-1.x-plugin</module>
-        <module>postgresql-8.x-plugin</module>
-        <module>rocketMQ-3.x-plugin</module>
-        <module>rocketMQ-4.x-plugin</module>
-        <module>elastic-job-2.x-plugin</module>
-        <module>mongodb-2.x-plugin</module>
-        <module>httpasyncclient-4.x-plugin</module>
-        <module>kafka-v1-plugin</module>
-        <module>servicecomb-plugin</module>
-        <module>hystrix-1.x-plugin</module>
-        <module>sofarpc-plugin</module>
-        <module>activemq-5.x-plugin</module>
-        <module>elasticsearch-5.x-plugin</module>
-        <module>undertow-plugins</module>
-        <module>rabbitmq-5.x-plugin</module>
-        <module>dubbo-conflict-patch</module>
-        <module>canal-1.x-plugin</module>
-        <module>dubbo-2.7.x-plugin</module>
-        <module>dubbo-2.7.x-conflict-patch</module>
-        <module>vertx-plugins</module>
-        <module>resteasy-plugin</module>
+        <module>solrj-7.x-plugin</module>","[{'comment': 'Look like you merge incorrectly. Please fix.', 'commenter': 'wu-sheng'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/pom.xml,"@@ -0,0 +1,50 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-sdk-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.2.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-solrj-7.x-plugin</artifactId>
+    <packaging>jar</packaging>
+
+    <name>solrj-7.x-plugin</name>
+    <url>http://maven.apache.org</url>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <java.version>1.8</java.version>","[{'comment': '**Do all solr-7.x client jars(not plugin codes, original Apache solr jars) need to compile in 1.8? If so, put this in the optional plugin.** All default plugin must work in JRE 1.6 right now.', 'commenter': 'wu-sheng'}]"
2730,apm-sniffer/apm-sdk-plugin/solrj-7.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/solrj/SolrClientInterceptor.java,"@@ -0,0 +1,195 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.solrj;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.solrj.commons.Context;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjInstance;
+import org.apache.skywalking.apm.plugin.solrj.commons.SolrjTags;
+import org.apache.solr.client.solrj.SolrRequest;
+import org.apache.solr.client.solrj.impl.HttpSolrClient;
+import org.apache.solr.client.solrj.request.AbstractUpdateRequest;
+import org.apache.solr.client.solrj.request.QueryRequest;
+import org.apache.solr.client.solrj.request.UpdateRequest;
+import org.apache.solr.common.SolrDocumentList;
+import org.apache.solr.common.SolrInputDocument;
+import org.apache.solr.common.params.CommonParams;
+import org.apache.solr.common.params.ModifiableSolrParams;
+import org.apache.solr.common.params.SolrParams;
+import org.apache.solr.common.params.UpdateParams;
+import org.apache.solr.common.util.NamedList;
+
+import java.lang.reflect.Method;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+public class SolrClientInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+    private static final Pattern URL_REGEX = Pattern.compile(""(?<pref>http(s)?://)*(?<domain>[\\w_.\\-\\d]+(:\\d+)?)?/(?<path>solr/(?<collection>[\\w_]+))?(/.*)?"");","[{'comment': 'Could you put a benchmark test case about this REGEX? And put a result in comment? In our experiences, REGEX is powerful, but cause performance issues in many scenarios.', 'commenter': 'wu-sheng'}, {'comment': ""If it's too expensive to use regexp, maybe you can have a try with the java.net.URL class , perhaps you can extract the path and parameters from it @dmsolr I'm not perfectly sure"", 'commenter': 'kezhenxu94'}, {'comment': 'I think do benchmark tests with these two options should be better. Then we could choose easily.', 'commenter': 'wu-sheng'}]"
2828,oap-server/server-receiver-plugin/skywalking-trace-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/trace/provider/parser/SegmentParseV2.java,"@@ -82,10 +82,11 @@ public boolean parse(BufferData<UpstreamSegment> bufferData, SegmentSource sourc
 
             List<UniqueId> traceIds = upstreamSegment.getGlobalTraceIdsList();
 
+            SegmentObject segmentObject = parseBinarySegment(upstreamSegment);","[{'comment': '`SegmentParseV2#parse` will be invoked multiple times, due to `SegmentParseV2#Producer#call` triggered by `DataStreamReader#L159-L161`. So, the `#parseBinarySegment` should be called only when `bufferData.getV2Segment() == null` from my perspective', 'commenter': 'wu-sheng'}, {'comment': 'After the debug, as you said, read from the file and go back to this judgment.', 'commenter': 'zhaoyuguang'}]"
2846,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/define/StatementEnhanceInfos.java,"@@ -31,11 +34,13 @@
     private ConnectionInfo connectionInfo;
     private String statementName;
     private String sql;
+    private Map<Integer, Object> parametersKeyedByIndex;
 
     public StatementEnhanceInfos(ConnectionInfo connectionInfo, String sql, String statementName) {
         this.connectionInfo = connectionInfo;
         this.sql = sql;
         this.statementName = statementName;
+        this.parametersKeyedByIndex = new TreeMap<Integer, Object>();","[{'comment': ""1. Why treeMap?\r\n2. Don't create the map if no parameter tracing. Map creation is a high payload. You could test 😄"", 'commenter': 'wu-sheng'}, {'comment': 'Treemap to keep order? User may not using the 1-n order. You need to bw careful.', 'commenter': 'wu-sheng'}, {'comment': '1. We need to keep the parameters\' order, because user may invoke `ps.setString(2, ""val2"");` before `ps.setString(1, ""val1"")`, and we need to print `val2, val1`.\r\n2. Got it, will improve this later', 'commenter': 'kezhenxu94'}, {'comment': '> We need to keep the parameters\' order, because user may invoke ps.setString(2, ""val2""); before ps.setString(1, ""val1""), and we need to print val2, val1.\r\n\r\nNo, we don\'t. Think in this way, dev or ops team doesn\'t know the codes, and saw `select xx from yyy where a=? and b=?` and you put `val2(i = 1), val1(i = 2)`, how they think?', 'commenter': 'wu-sheng'}, {'comment': 'I think people thought `a = val2 and b = val1`, right? But the reality is `a = val1 and b = val2` right?\r\nTracing is not really all about codes, it is for observability, a.k.a. understandable for the system.', 'commenter': 'wu-sheng'}, {'comment': '> > We need to keep the parameters\' order, because user may invoke ps.setString(2, ""val2""); before ps.setString(1, ""val1""), and we need to print val2, val1.\r\n> \r\n> No, we don\'t. Think in this way, dev or ops team doesn\'t know the codes, and saw `select xx from yyy where a=? and b=?` and you put `val2(i = 1), val1(i = 2)`, how they think?\r\n\r\nby saying ""keep the parameters\' order"", I didn\'t mean to keep the **order of the code**, I meant keep the **index order of the code**, and since the `index` is the key of the `TreeSet`, therefore the values are sorted by the keys (index here), ', 'commenter': 'kezhenxu94'}, {'comment': ""Then why don't use an Array list? Look like much more efficiency, right?\r\n ```\r\nlist = new ArrayList;\r\nlist,checkRange(i)\r\nlist.set(i, value)\r\n``` "", 'commenter': 'wu-sheng'}, {'comment': ""we don't know the parameters' size in advance, `checkRange` manually may need to enlarge the capacity, and copying elements, I'm not sure which one is better, did I miss anything about `ArrayList`?"", 'commenter': 'kezhenxu94'}, {'comment': ""First of all, even in today's agent codes, we have an unsolved issue. In many practices, introduced by Google, ArrayList has better performance than LinkedList, even with enlarge the capacity and copy elements. We can build a benchmark. Clearly, LinkedList should similar or better than TreeMap in complexity, right? Also, the benchmark is welcome.\r\n\r\nBesides above, let's think in this way. ArrayList with 20 as initial size, then how many of parameters a SQL will have? 40 - 60 is a big one, right? Especially in micro-service and less Oracle today.\r\nThe ArrayList will enlarge twice mostly, others just set, I think that should be much quicker.\r\n\r\nLet's do multiple tests to confirm this."", 'commenter': 'wu-sheng'}, {'comment': ""make sense, I'll try to do some benchmark tests to make this clear and for future reference"", 'commenter': 'kezhenxu94'}, {'comment': 'Benchmark and result are here: https://github.com/apache/skywalking/pull/2846/files#diff-c79b0eaced528877516f9cbf5a4ddb7c', 'commenter': 'kezhenxu94'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementExecuteMethodsInterceptor.java,"@@ -29,29 +32,59 @@
 import org.apache.skywalking.apm.plugin.jdbc.trace.ConnectionInfo;
 
 import java.lang.reflect.Method;
+import java.util.Map;
+
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.DISPLAYABLE_TYPES;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_IGNORED_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETER_PLACE_HOLDER;
 
 public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
+    private final Gson gson = new Gson();
 
     @Override
     public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
         Class<?>[] argumentsTypes,
         MethodInterceptResult result) throws Throwable {
         StatementEnhanceInfos cacheObject = (StatementEnhanceInfos)objInst.getSkyWalkingDynamicField();
         ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+
+        final String methodName = method.getName();
+        final boolean traceSqlParameters = Config.Plugin.MySQL.TRACE_SQL_PARAMETERS;","[{'comment': 'Why need this line?', 'commenter': 'wu-sheng'}, {'comment': ""Oh we don't need this when `methodName` is under consideration, will remove"", 'commenter': 'kezhenxu94'}]"
2846,.gitmodules,"@@ -1,9 +1,12 @@
 [submodule ""apm-protocol/apm-network/src/main/proto""]
 	path = apm-protocol/apm-network/src/main/proto
-	url = https://github.com/apache/skywalking-data-collect-protocol.git
+	url = file:///data/developer/git/java/skywalking/apm-protocol/apm-network/src/main/proto
+	#url = https://github.com/apache/skywalking-data-collect-protocol.git
 [submodule ""oap-server/server-query-plugin/query-graphql-plugin/src/main/resources/query-protocol""]
 	path = oap-server/server-query-plugin/query-graphql-plugin/src/main/resources/query-protocol
-	url = https://github.com/apache/skywalking-query-protocol.git
+	url = file:///data/developer/git/java/skywalking/oap-server/server-query-plugin/query-graphql-plugin/src/main/resources/query-protocol
+	#url = https://github.com/apache/skywalking-query-protocol.git
 [submodule ""skywalking-ui""]
 	path = skywalking-ui
-	url = https://github.com/apache/skywalking-rocketbot-ui.git
+	#url = https://github.com/apache/skywalking-rocketbot-ui.git
+	url = file:///data/developer/git/java/skywalking/skywalking-ui","[{'comment': 'This is unexpected changes', 'commenter': 'wu-sheng'}, {'comment': ""> This is unexpected changes\r\n\r\nYes, for local testing, will revert and recheck, once done, I'll ping you, thanks :)"", 'commenter': 'kezhenxu94'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementExecuteMethodsInterceptor.java,"@@ -30,28 +31,55 @@
 
 import java.lang.reflect.Method;
 
-public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
+import static org.apache.skywalking.apm.plugin.jdbc.define.Constants.PARAMETER_PLACEHOLDER;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.DISPLAYABLE_TYPES;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_IGNORED_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETER_PLACEHOLDER;
 
+public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
     @Override
     public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
         Class<?>[] argumentsTypes,
         MethodInterceptResult result) throws Throwable {
         StatementEnhanceInfos cacheObject = (StatementEnhanceInfos)objInst.getSkyWalkingDynamicField();
         ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+
+        final String methodName = method.getName();
+
+        if (PS_SETTERS.contains(methodName) || PS_IGNORED_SETTERS.contains(methodName)) {
+            final int index = (Integer) allArguments[0];
+            final Object parameter = getDisplayedParameter(method, argumentsTypes, allArguments);
+            cacheObject.setParameter(index, parameter);
+        }
+
         /**
          * For avoid NPE. In this particular case, Execute sql inside the {@link com.mysql.jdbc.ConnectionImpl} constructor,
          * before the interceptor sets the connectionInfo.
          *
          * @see JDBCDriverInterceptor#afterMethod(EnhancedInstance, Method, Object[], Class[], Object)
          */
-        if (connectInfo != null) {
+        if (connectInfo != null && !PS_SETTERS.contains(methodName) && !PS_IGNORED_SETTERS.contains(methodName)) {","[{'comment': 'This should be in `else if` and remove `!PS_SETTERS.contains(methodName) && !PS_IGNORED_SETTERS.contains(methodName)`, right?', 'commenter': 'wu-sheng'}, {'comment': 'You should use tracing parameter config to judge first, for performance when it is off.', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-test-tools/src/test/java/org/apache/skywalking/apm/plugin/ArbitrarySetTest.java,"@@ -0,0 +1,238 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin;
+
+import org.openjdk.jmh.annotations.Benchmark;
+import org.openjdk.jmh.annotations.BenchmarkMode;
+import org.openjdk.jmh.annotations.Fork;
+import org.openjdk.jmh.annotations.Measurement;
+import org.openjdk.jmh.annotations.Mode;
+import org.openjdk.jmh.annotations.OutputTimeUnit;
+import org.openjdk.jmh.annotations.Scope;
+import org.openjdk.jmh.annotations.State;
+import org.openjdk.jmh.annotations.Warmup;
+import org.openjdk.jmh.runner.Runner;
+import org.openjdk.jmh.runner.RunnerException;
+import org.openjdk.jmh.runner.options.Options;
+import org.openjdk.jmh.runner.options.OptionsBuilder;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.Map;
+import java.util.TreeMap;
+import java.util.concurrent.TimeUnit;
+
+/**
+ * # JMH version: 1.21
+ * # VM version: JDK 10.0.1, Java HotSpot(TM) 64-Bit Server VM, 10.0.1+10
+ * # VM invoker: /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/java
+ * # VM options: -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=50729:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8
+ * # Warmup: 4 iterations, 10 s each
+ * # Measurement: 5 iterations, 10 s each
+ * # Timeout: 10 min per iteration
+ * # Threads: 1 thread, will synchronize iterations
+ * # Benchmark mode: Throughput, ops/time
+ * # Benchmark: org.apache.skywalking.apm.plugin.ArbitrarySetTest.array
+ * <p>
+ * # Run progress: 0.00% complete, ETA 00:09:00
+ * # Fork: 1 of 2
+ * # Warmup Iteration   1: 1227.556 ops/ms
+ * # Warmup Iteration   2: 1710.387 ops/ms
+ * # Warmup Iteration   3: 1692.754 ops/ms
+ * # Warmup Iteration   4: 1779.140 ops/ms
+ * Iteration   1: 1833.746 ops/ms
+ * Iteration   2: 1862.485 ops/ms
+ * Iteration   3: 1827.150 ops/ms
+ * Iteration   4: 1693.042 ops/ms
+ * Iteration   5: 1643.173 ops/ms
+ * <p>
+ * # Run progress: 16.67% complete, ETA 00:07:39
+ * # Fork: 2 of 2
+ * # Warmup Iteration   1: 1455.851 ops/ms
+ * # Warmup Iteration   2: 1629.368 ops/ms
+ * # Warmup Iteration   3: 1729.879 ops/ms
+ * # Warmup Iteration   4: 1790.962 ops/ms
+ * Iteration   1: 1681.082 ops/ms
+ * Iteration   2: 1557.253 ops/ms
+ * Iteration   3: 1510.295 ops/ms
+ * Iteration   4: 1559.166 ops/ms
+ * Iteration   5: 1615.465 ops/ms
+ * <p>
+ * <p>
+ * Result ""org.apache.skywalking.apm.plugin.ArbitrarySetTest.array"":
+ * 1678.286 ±(99.9%) 190.386 ops/ms [Average]
+ * (min, avg, max) = (1510.295, 1678.286, 1862.485), stdev = 125.929
+ * CI (99.9%): [1487.900, 1868.672] (assumes normal distribution)
+ * <p>
+ * <p>
+ * # JMH version: 1.21
+ * # VM version: JDK 10.0.1, Java HotSpot(TM) 64-Bit Server VM, 10.0.1+10
+ * # VM invoker: /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/java
+ * # VM options: -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=50729:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8
+ * # Warmup: 4 iterations, 10 s each
+ * # Measurement: 5 iterations, 10 s each
+ * # Timeout: 10 min per iteration
+ * # Threads: 1 thread, will synchronize iterations
+ * # Benchmark mode: Throughput, ops/time
+ * # Benchmark: org.apache.skywalking.apm.plugin.ArbitrarySetTest.arrayList
+ * <p>
+ * # Run progress: 33.33% complete, ETA 00:06:05
+ * # Fork: 1 of 2
+ * # Warmup Iteration   1: 575.365 ops/ms
+ * # Warmup Iteration   2: 627.217 ops/ms
+ * # Warmup Iteration   3: 611.638 ops/ms
+ * # Warmup Iteration   4: 584.694 ops/ms
+ * Iteration   1: 593.597 ops/ms
+ * Iteration   2: 582.952 ops/ms
+ * Iteration   3: 586.201 ops/ms
+ * Iteration   4: 668.791 ops/ms
+ * Iteration   5: 668.208 ops/ms
+ * <p>
+ * # Run progress: 50.00% complete, ETA 00:04:34
+ * # Fork: 2 of 2
+ * # Warmup Iteration   1: 567.132 ops/ms
+ * # Warmup Iteration   2: 619.129 ops/ms
+ * # Warmup Iteration   3: 719.696 ops/ms
+ * # Warmup Iteration   4: 734.769 ops/ms
+ * Iteration   1: 731.429 ops/ms
+ * Iteration   2: 684.019 ops/ms
+ * Iteration   3: 645.475 ops/ms
+ * Iteration   4: 634.259 ops/ms
+ * Iteration   5: 681.604 ops/ms
+ * <p>
+ * <p>
+ * Result ""org.apache.skywalking.apm.plugin.ArbitrarySetTest.arrayList"":
+ * 647.654 ±(99.9%) 73.776 ops/ms [Average]
+ * (min, avg, max) = (582.952, 647.654, 731.429), stdev = 48.799
+ * CI (99.9%): [573.877, 721.430] (assumes normal distribution)
+ * <p>
+ * <p>
+ * # JMH version: 1.21
+ * # VM version: JDK 10.0.1, Java HotSpot(TM) 64-Bit Server VM, 10.0.1+10
+ * # VM invoker: /Library/Java/JavaVirtualMachines/jdk-10.0.1.jdk/Contents/Home/bin/java
+ * # VM options: -javaagent:/Applications/IntelliJ IDEA.app/Contents/lib/idea_rt.jar=50729:/Applications/IntelliJ IDEA.app/Contents/bin -Dfile.encoding=UTF-8
+ * # Warmup: 4 iterations, 10 s each
+ * # Measurement: 5 iterations, 10 s each
+ * # Timeout: 10 min per iteration
+ * # Threads: 1 thread, will synchronize iterations
+ * # Benchmark mode: Throughput, ops/time
+ * # Benchmark: org.apache.skywalking.apm.plugin.ArbitrarySetTest.treeMap
+ * <p>
+ * # Run progress: 66.67% complete, ETA 00:03:02
+ * # Fork: 1 of 2
+ * # Warmup Iteration   1: 149.772 ops/ms
+ * # Warmup Iteration   2: 164.658 ops/ms
+ * # Warmup Iteration   3: 181.832 ops/ms
+ * # Warmup Iteration   4: 181.535 ops/ms
+ * Iteration   1: 178.571 ops/ms
+ * Iteration   2: 135.320 ops/ms
+ * Iteration   3: 152.644 ops/ms
+ * Iteration   4: 166.896 ops/ms
+ * Iteration   5: 167.542 ops/ms
+ * <p>
+ * # Run progress: 83.33% complete, ETA 00:01:31
+ * # Fork: 2 of 2
+ * # Warmup Iteration   1: 171.791 ops/ms
+ * # Warmup Iteration   2: 178.640 ops/ms
+ * # Warmup Iteration   3: 167.416 ops/ms
+ * # Warmup Iteration   4: 171.610 ops/ms
+ * Iteration   1: 179.966 ops/ms
+ * Iteration   2: 187.318 ops/ms
+ * Iteration   3: 183.934 ops/ms
+ * Iteration   4: 181.388 ops/ms
+ * Iteration   5: 186.286 ops/ms
+ * <p>
+ * <p>
+ * Result ""org.apache.skywalking.apm.plugin.ArbitrarySetTest.treeMap"":
+ * 171.986 ±(99.9%) 25.408 ops/ms [Average]
+ * (min, avg, max) = (135.320, 171.986, 187.318), stdev = 16.806
+ * CI (99.9%): [146.578, 197.394] (assumes normal distribution)
+ * <p>
+ * <p>
+ * # Run complete. Total time: 00:09:07
+ * <p>
+ * REMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on
+ * why the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial
+ * experiments, perform baseline and negative tests that provide experimental control, make sure
+ * the benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.
+ * Do not assume the numbers tell you what you want them to tell.
+ * <p>
+ * Benchmark                    Mode  Cnt     Score     Error   Units
+ * ArbitrarySetTest.array      thrpt   10  1678.286 ± 190.386  ops/ms
+ * ArbitrarySetTest.arrayList  thrpt   10   647.654 ±  73.776  ops/ms
+ * ArbitrarySetTest.treeMap    thrpt   10   171.986 ±  25.408  ops/ms
+ *
+ * @author kezhenxu94
+ */
+@BenchmarkMode(Mode.Throughput)
+@OutputTimeUnit(TimeUnit.MILLISECONDS)
+@State(Scope.Thread)
+@Fork(2)
+@Warmup(iterations = 4)
+@Measurement(iterations = 5)
+public class ArbitrarySetTest {
+    private static final Object PLACEHOLDER = new Object();
+
+    @Benchmark
+    public void arrayList() {
+        ArrayList<Object> list = new ArrayList<Object>(Collections.nCopies(20, PLACEHOLDER));
+        for (int i = 0; i < 100; i++) {
+            int oldSize = list.size();
+            if (i >= oldSize) {
+                int newSize = Math.max(oldSize * 2, i);
+                ArrayList<Object> newList = new ArrayList<Object>(newSize);
+                newList.addAll(list);
+                newList.addAll(oldSize, Collections.nCopies(newSize - oldSize, PLACEHOLDER));
+                list = newList;
+            }
+            list.set(i, i);
+        }
+    }
+
+    @Benchmark
+    public void array() {","[{'comment': 'You should use a LinkedList as compare testing.', 'commenter': 'wu-sheng'}, {'comment': 'Added', 'commenter': 'kezhenxu94'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementExecuteMethodsInterceptor.java,"@@ -78,4 +108,39 @@ public final Object afterMethod(EnhancedInstance objInst, Method method, Object[
     private String buildOperationName(ConnectionInfo connectionInfo, String methodName, String statementName) {
         return connectionInfo.getDBType() + ""/JDBI/"" + statementName + ""/"" + methodName;
     }
+
+    private Object getDisplayedParameter(final Method method, final Class<?>[] argumentTypes, final Object[] allArguments) {
+        final String methodName = method.getName();
+        if (""setNull"".equals(methodName)) {
+            return ""null"";
+        }
+        if (""setObject"".equals(methodName)) {
+            final Object parameter = allArguments[0];
+            final Class<?> parameterType = argumentTypes[1];
+
+            if (DISPLAYABLE_TYPES.contains(parameterType)) {
+                return parameter;
+            }
+        } else if (PS_SETTERS.contains(methodName)) {
+            return allArguments[1];
+        }
+        return SQL_PARAMETER_PLACEHOLDER;
+    }
+
+    private String buildParameterString(Object[] parameters) {","[{'comment': ""Why don't use GSON Array `#toString`?"", 'commenter': 'wu-sheng'}, {'comment': ""We cannot use Gson because the target application don't necessary include it"", 'commenter': 'kezhenxu94'}, {'comment': 'Yes, ignore this.', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementExecuteMethodsInterceptor.java,"@@ -30,28 +31,55 @@
 
 import java.lang.reflect.Method;
 
-public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
+import static org.apache.skywalking.apm.plugin.jdbc.define.Constants.PARAMETER_PLACEHOLDER;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.DISPLAYABLE_TYPES;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_IGNORED_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETER_PLACEHOLDER;
 
+public class PreparedStatementExecuteMethodsInterceptor implements InstanceMethodsAroundInterceptor {
     @Override
     public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
         Class<?>[] argumentsTypes,
         MethodInterceptResult result) throws Throwable {
         StatementEnhanceInfos cacheObject = (StatementEnhanceInfos)objInst.getSkyWalkingDynamicField();
         ConnectionInfo connectInfo = cacheObject.getConnectionInfo();
+
+        final String methodName = method.getName();
+
+        if (PS_SETTERS.contains(methodName) || PS_IGNORED_SETTERS.contains(methodName)) {","[{'comment': 'You should use tracing parameter config to judge first, for performance when it is off.', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementExecuteMethodsInterceptor.java,"@@ -61,7 +89,9 @@ public final Object afterMethod(EnhancedInstance objInst, Method method, Object[
         Class<?>[] argumentsTypes,
         Object ret) throws Throwable {
         StatementEnhanceInfos cacheObject = (StatementEnhanceInfos)objInst.getSkyWalkingDynamicField();
-        if (cacheObject.getConnectionInfo() != null) {
+        ConnectionInfo connectionInfo = cacheObject.getConnectionInfo();
+        String methodName = method.getName();
+        if (connectionInfo != null && !PS_SETTERS.contains(methodName) && !PS_IGNORED_SETTERS.contains(methodName)) {","[{'comment': 'You should use tracing parameter config to judge first, for performance when it is off.', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/Constants.java,"@@ -29,4 +40,62 @@
     public static final String SET_CATALOG_INTERCEPTOR = ""org.apache.skywalking.apm.plugin.jdbc.mysql.SetCatalogInterceptor"";
     public static final String STATEMENT_EXECUTE_METHODS_INTERCEPTOR = ""org.apache.skywalking.apm.plugin.jdbc.mysql.StatementExecuteMethodsInterceptor"";
     public static final String DRIVER_CONNECT_INTERCEPTOR = ""org.apache.skywalking.apm.plugin.jdbc.mysql.DriverConnectInterceptor"";
+
+    public static final StringTag SQL_PARAMETERS = new StringTag(""db.sql.parameters"");
+    public static final String SQL_PARAMETER_PLACEHOLDER = ""?"";
+    public static final Set<String> PS_SETTERS = new HashSet<String>(Arrays.asList(","[{'comment': 'I still have performance concerns for these naming match. You should set a explicit instrumentation for get parameter, rather than using string match.\r\nInstrumentation name match filter happens in startup amd class loading stage.', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-6.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/v6/define/PreparedStatementInstrumentation.java,"@@ -53,10 +56,19 @@
         return new InstanceMethodsInterceptPoint[] {
             new InstanceMethodsInterceptPoint() {
                 @Override public ElementMatcher<MethodDescription> getMethodsMatcher() {
-                    return named(""execute"")
+                    ElementMatcher.Junction<MethodDescription> matcher = named(""execute"")
                         .or(named(""executeQuery""))
                         .or(named(""executeUpdate""))
                         .or(named(""executeLargeUpdate""));
+                    if (Config.Plugin.MySQL.TRACE_SQL_PARAMETERS) {
+                        for (String setter : PS_SETTERS) {
+                            matcher = matcher.or(named(setter));
+                        }
+                        for (String setter : PS_IGNORED_SETTERS) {
+                            matcher = matcher.or(named(setter));
+                        }
+                    }
+                    return matcher;","[{'comment': 'Same to\r\n>I still have performance concerns for these naming match. You should set a explicit instrumentation for get parameter, rather than using string match.\r\nInstrumentation name match filter happens in startup amd class loading stage.', 'commenter': 'wu-sheng'}]"
2846,docs/en/setup/service-agent/java-agent/README.md,"@@ -82,9 +82,13 @@ property key | Description | Default |
 `plugin.elasticsearch.trace_dsl`|If true, trace all the DSL(Domain Specific Language) in ElasticSearch access, default is false.|`false`|
 `plugin.springmvc.use_qualified_name_as_endpoint_name`|If true, the fully qualified method name will be used as the endpoint name instead of the request URL, default is false.|`false`|
 `plugin.toolit.use_qualified_name_as_operation_name`|If true, the fully qualified method name will be used as the operation name instead of the given operation name, default is false.|`false`|
+`plugin.solrj.trace_statement`|If true, trace all the query parameters(include deleteByIds and deleteByQuery) in Solr query request, default is false.|`false`|
+`plugin.solrj.trace_ops_params`|If true, trace all the operation parameters in Solr request, default is false.|`false`|","[{'comment': 'You mis-add these', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-sdk-plugin/mysql-common/src/main/java/org/apache/skywalking/apm/plugin/jdbc/mysql/PreparedStatementSetterMethodsInterceptor.java,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.jdbc.mysql;
+
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.jdbc.define.StatementEnhanceInfos;
+
+import java.lang.reflect.Method;
+
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.DISPLAYABLE_TYPES;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.PS_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.mysql.Constants.SQL_PARAMETER_PLACEHOLDER;
+
+/**
+ * @author kezhenxu94
+ */
+public class PreparedStatementSetterMethodsInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                                   Class<?>[] argumentsTypes,
+                                   MethodInterceptResult result) throws Throwable {
+        final StatementEnhanceInfos statementEnhanceInfos = (StatementEnhanceInfos) objInst.getSkyWalkingDynamicField();
+        final int index = (Integer) allArguments[0];
+        final Object parameter = getDisplayedParameter(method, argumentsTypes, allArguments);
+        statementEnhanceInfos.setParameter(index, parameter);
+    }
+
+    @Override
+    public final Object afterMethod(EnhancedInstance objInst,
+                                    Method method,
+                                    Object[] allArguments,
+                                    Class<?>[] argumentsTypes,
+                                    Object ret) throws Throwable {
+        return ret;
+    }
+
+    @Override
+    public final void handleMethodException(EnhancedInstance objInst,
+                                            Method method,
+                                            Object[] allArguments,
+                                            Class<?>[] argumentsTypes,
+                                            Throwable t) {
+    }
+
+    private Object getDisplayedParameter(final Method method, final Class<?>[] argumentTypes, final Object[] allArguments) {
+        final String methodName = method.getName();
+        if (""setNull"".equals(methodName)) {
+            return ""null"";
+        }
+        if (""setObject"".equals(methodName)) {
+            final Object parameter = allArguments[0];
+            final Class<?> parameterType = argumentTypes[1];
+
+            if (DISPLAYABLE_TYPES.contains(parameterType)) {","[{'comment': 'For higher performance, you should totally avoid contains, especially contain a long list and high frequency op. Separate it to different interceptors.\r\n\r\nAnd notice, these inteceptor should be placed in jdbc common, you would notice other jdbc driver plugin could reuse all these, right? Only instrumentation definitions are mysql related.', 'commenter': 'wu-sheng'}]"
2846,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/JDBCPreparedStatementSetterInstanceMethodsInterceptPoint.java,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.jdbc;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.plugin.jdbc.define.Constants;
+
+import java.util.Set;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.none;
+import static org.apache.skywalking.apm.plugin.jdbc.define.Constants.PS_IGNORABLE_SETTERS;
+import static org.apache.skywalking.apm.plugin.jdbc.define.Constants.PS_SETTERS;
+
+/**
+ * @author kezhenxu94
+ */
+public class JDBCPreparedStatementSetterInstanceMethodsInterceptPoint implements InstanceMethodsInterceptPoint {","[{'comment': 'Could you rename these, such as  `PreparedStatementSetterInstanceMethodsInterceptPointOfJDBCInstrumentation`. Because only `Instrumentation` suffix could be checked by CI scripts of instrumentation definition.', 'commenter': 'wu-sheng'}, {'comment': 'Yes sure', 'commenter': 'kezhenxu94'}]"
2874,apm-commons/apm-datacarrier/src/test/java/org/apache/skywalking/apm/commons/datacarrier/common/AtomicRangeIntegerTest.java,"@@ -39,4 +48,95 @@ public void testGetAndIncrement() {
         Assert.assertEquals(1, (int)atomicI.floatValue());
         Assert.assertEquals(1, (int)atomicI.doubleValue());
     }
+
+    @Test
+    @Benchmark
+    public void testOriGetAndIncrementPerformance() {
+        ATOMIC_ORI.oriGetAndIncrement();
+    }
+
+    @Test
+    @Benchmark
+    public void testNewGetAndIncrementPerformance() {
+        ATOMIC_NEW.getAndIncrement();
+    }
+
+    public static void main(String[] args) throws RunnerException {
+        Options opt = new OptionsBuilder()
+                .include(AtomicRangeIntegerTest.class.getSimpleName())
+                .forks(1)
+                .threads(4)
+                .output(""/tmp/jmh.log"")
+                .warmupIterations(0)","[{'comment': 'Add warmup to make the result more stable, at least 3.', 'commenter': 'wu-sheng'}, {'comment': 'I have added, and add syncIterations false.', 'commenter': 'lkxiaolou'}]"
2874,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/common/AtomicRangeInteger.java,"@@ -37,7 +37,7 @@ public AtomicRangeInteger(int startValue, int maxValue) {
         this.endValue = maxValue - 1;
     }
 
-    public final int getAndIncrement() {
+    public final int oriGetAndIncrement() {","[{'comment': 'This method should move to test, as the original method and test baseline.', 'commenter': 'wu-sheng'}]"
2874,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/common/AtomicRangeInteger.java,"@@ -49,6 +49,18 @@ public final int getAndIncrement() {
         return current;
     }
 
+    public final int getAndIncrement() {
+        int next;
+        do {
+            next = this.value.incrementAndGet();","[{'comment': ""From my understanding, you are using the `conflict abandon mechanism`, trade off more throughput. Because this line invokes, when comareAndSet fail, you can't get the index in this loop.\r\n\r\nPlease share with me, why you think this is better?  I think this is two sides of the coin\r\n1. **[OLD]**, lower throughput, higher cache queue usage rate, less blank element.\r\n1. **[NEW]**, opposite."", 'commenter': 'wu-sheng'}, {'comment': '> From my understanding, you are using the `conflict abandon mechanism`, trade off more throughput. Because this line invokes, when comareAndSet fail, you can\'t get the index in this loop.\r\n> \r\n> Please share with me, why you think this is better? I think this is two sides of the coin\r\n> \r\n> 1. **[OLD]**, lower throughput, higher cache queue usage rate, less blank element.\r\n> 2. **[NEW]**, opposite.\r\n\r\nThe conflict in the New implementation only happens on the edge of the buffer, so the loop count in New implementation is less than the Old one for the edge-off after abandoning conflict. It will produce less blank element than the old one.\r\nI can\'t understand what is ""higher cache queue usage rate"" in this case, could you please explain it ?\r\n', 'commenter': 'lkxiaolou'}, {'comment': 'Sorry, my fault, I misread the codes. Yes, the conflict only happens at the edge.', 'commenter': 'wu-sheng'}]"
2881,PluginImportedCheck.sh,"@@ -0,0 +1,10 @@
+plugin_dir=$1
+for dir in `ls ""./apm-sniffer/$plugin_dir/""`; do
+	for f in `find ./apm-sniffer/$plugin_dir/$dir -name *Instrumentation.java `; do
+		NUM=`head -400 $f | grep import |grep -v net.bytebuddy. | grep -v org.apache.skywalking. |grep -v java.| wc -l`;","[{'comment': '`grep import` => `grep ^import` should be more accurately', 'commenter': 'kezhenxu94'}, {'comment': 'Yes', 'commenter': 'dmsolr'}]"
2881,Jenkinsfile,"@@ -56,7 +56,15 @@ pipeline {
                                 sh 'ls'
                                 sh 'git status'
                             }
-                        }    
+                        }
+
+                        stage('Check 3rd-party classes imported') {","[{'comment': 'Named as Check agent plugin instrumentation imports', 'commenter': 'wu-sheng'}]"
2881,apm-sniffer/apm-sdk-plugin/motan-plugin/src/main/java/org/apache/skywalking/apm/plugin/motan/define/MotanConsumerInstrumentation.java,"@@ -41,7 +40,7 @@
      */
     private static final String CONSTRUCTOR_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.motan.MotanConsumerInterceptor"";
     /**
-     * Class that intercept {@link com.weibo.api.motan.rpc.AbstractProvider#call(Request)}.
+     * Class that intercept {@link com.weibo.api.motan.rpc.AbstractProvider#call(com.weibo.api.motan.rpc.Request)}.","[{'comment': ""Don't use @link, use iteral string only."", 'commenter': 'wu-sheng'}, {'comment': ""I think both are safe for class loader. I recommend remove link because this class wouldn't exist in agent."", 'commenter': 'wu-sheng'}]"
2881,tools/check/agent/plugin/PluginImportedCheck.sh,"@@ -0,0 +1,30 @@
+#!/bin/sh
+# ----------------------------------------------------------------------------
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+# ----------------------------------------------------------------------------
+
+plugin_dir=$1
+for dir in `ls ""./apm-sniffer/$plugin_dir/""`; do
+	for f in `find ./apm-sniffer/$plugin_dir/$dir -name *Instrumentation.java `; do
+		NUM=`head -400 $f | grep ^import |grep -v net.bytebuddy. | grep -v org.apache.skywalking. |grep -v java.| wc -l`;
+		if [ $NUM -gt 0 ] ; then
+			echo ""Plugin: $dir, never import any class unless JDK and ByteBuddy!"";","[{'comment': 'Change to, only allow to import JDK and ByteBuddy classes', 'commenter': 'wu-sheng'}]"
2881,tools/check/agent/plugin/PluginImportedCheck.sh,"@@ -0,0 +1,30 @@
+#!/bin/sh
+# ----------------------------------------------------------------------------
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+# ----------------------------------------------------------------------------
+
+plugin_dir=$1
+for dir in `ls ""./apm-sniffer/$plugin_dir/""`; do","[{'comment': 'Is this path still working after you moved it?', 'commenter': 'wu-sheng'}]"
2881,tools/check/agent/plugin/PluginImportedCheck.sh,"@@ -0,0 +1,30 @@
+#!/bin/sh
+# ----------------------------------------------------------------------------
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+# ----------------------------------------------------------------------------
+
+plugin_dir=$1
+for dir in `ls ""./apm-sniffer/$plugin_dir/""`; do
+	for f in `find ./apm-sniffer/$plugin_dir/$dir -name *Instrumentation.java `; do
+		NUM=`head -400 $f | grep ^import |grep -v net.bytebuddy. | grep -v org.apache.skywalking. |grep -v java.| wc -l`;","[{'comment': 'I think we should output the class file name and path to log. We could show explicitly which file has illegal import.', 'commenter': 'wu-sheng'}, {'comment': 'I mean output all instrumentation class list.', 'commenter': 'wu-sheng'}, {'comment': ""The regexp is not perfect, I tried that I can import `import javassist.ClassMap;` and the script did not catch this, it's matched by `java.`, at least you should escape the `.`"", 'commenter': 'kezhenxu94'}]"
2881,tools/check/agent/plugin/PluginImportedCheck.sh,"@@ -0,0 +1,32 @@
+#!/bin/sh
+# ----------------------------------------------------------------------------
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing,
+# software distributed under the License is distributed on an
+# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+# KIND, either express or implied.  See the License for the
+# specific language governing permissions and limitations
+# under the License.
+# ----------------------------------------------------------------------------
+
+plugin_dir=$1
+for dir in `ls ""./apm-sniffer/$plugin_dir/""`; do
+	echo ""Scanning $dir""
+	for f in `find ./apm-sniffer/$plugin_dir/$dir -name *Instrumentation.java `; do
+		NUM=`head -400 $f | grep ^import |grep -Ev ""^import\s+(static\s+)*net.bytebuddy\\."" \
+			| grep -Ev ""^import\s+(static\s+)*org.apache.skywalking\\."" |grep -Ev ""^import\s+(static\s+)*java(x)*\\."" | wc -l`","[{'comment': ""I don't think `javax` is allowed here, there are so many third-party libraries whose name contains `javax`\r\n![image](https://user-images.githubusercontent.com/15965696/59560613-c729e480-9047-11e9-9bf8-19dd45ecd00c.png)\r\n "", 'commenter': 'kezhenxu94'}, {'comment': 'I am not sure whether we need javax.sql. ', 'commenter': 'dmsolr'}, {'comment': ""We don't need javax"", 'commenter': 'wu-sheng'}, {'comment': 'In instrumentation definition.', 'commenter': 'wu-sheng'}, {'comment': 'I got it. thx.', 'commenter': 'dmsolr'}, {'comment': 'OK. I will wait your new commit.', 'commenter': 'wu-sheng'}]"
2888,oap-server/server-core/src/test/resources/component-libraries.yml,"@@ -198,6 +198,12 @@ spring-cloud-gateway:
 RESTEasy:
   id: 62
   languages: Java
+SolrJ:
+  id: 63
+  languages: Java
+Solr:","[{'comment': 'Is this what you will have in the other PR #2853 ? If so, leave it to where it should be', 'commenter': 'kezhenxu94'}, {'comment': 'This is for both server plugin and server mapping. So it makes sense to be here from I known.', 'commenter': 'wu-sheng'}]"
2888,oap-server/server-starter/src/main/resources/component-libraries.yml,"@@ -216,6 +216,13 @@ spring-cloud-gateway:
 RESTEasy:
   id: 62
   languages: Java
+SolrJ:
+  id: 63
+  languages: Java
+Solr:","[{'comment': 'Is this what you will have in the other PR #2853 ? If so, leave it to where it should be\r\n\r\n', 'commenter': 'kezhenxu94'}]"
2962,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/AlarmModuleProvider.java,"@@ -49,19 +53,26 @@
         }
         RulesReader reader = new RulesReader(applicationReader);
         Rules rules = reader.readRules();
+        alarmRulesWatcher = new AlarmRulesWatcher(rules, this, this::reload);
+    }
+
+    private void reload(final Rules rules) {","[{'comment': ""This `reload` is a hijack to existing code. `ModuleProvider#registerServiceImplementation` didn't expect runtime change in the design. So you could see `Map<Class<? extends Service>, Service> services` for service register, which is not thread-safe.\r\n\r\nWe need to reconsider this, even whether do we need to approve the service hot-switch "", 'commenter': 'wu-sheng'}]"
2973,oap-server/server-configuration/configuration-etcd/pom.xml,"@@ -39,10 +39,76 @@
             <version>${project.version}</version>
         </dependency>
         <dependency>
-            <groupId>org.apache.skywalking</groupId>
-            <artifactId>cluster-etcd-plugin</artifactId>
-            <version>${project.version}</version>
+            <groupId>org.projectlombok</groupId>","[{'comment': 'etcd4j is existing in dependency management. You should not add it here.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'wayilau'}, {'comment': 'here, i should add the dependency, or it will compile failed.', 'commenter': 'wayilau'}, {'comment': ""@wayilau he means the `projectlombok`, it's included in `oap-server/pom.xml` already, am I right? @wu-sheng "", 'commenter': 'kezhenxu94'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdConfigWatcherRegister.java,"@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.io.IOException;
+import java.net.URI;
+import java.util.Set;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdException;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdConfigWatcherRegister extends ConfigWatcherRegister {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdConfigWatcherRegister.class);
+
+    private EtcdServerSettings settings;
+
+    private EtcdClient client;
+
+    @Override public ConfigTable readConfig(Set<String> keys) {
+
+        if (client == null) {
+            try {
+                client = new EtcdClient(EtcdUtils.parse(settings).toArray(new URI[] {}));
+            } catch (ModuleStartException e) {
+                logger.error(e.getMessage(), e);
+            }
+
+            EtcdResponsePromise promise;","[{'comment': ""generic type? I don't like warnings but it's not big deal"", 'commenter': 'kezhenxu94'}, {'comment': '```suggestion\r\n            EtcdResponsePromise<EtcdKeysResponse> promise;\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'ok, i will add the type. done!', 'commenter': 'wayilau'}, {'comment': 'done', 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdServerSettings.java,"@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import lombok.Getter;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdServerSettings extends ModuleConfig {","[{'comment': ""```suggestion\r\n@ToString\r\npublic class EtcdServerSettings extends ModuleConfig {\r\n```\r\n\r\nsince you're using lombok `@Getter`, `@ToString` should free you from writing boilerplate code (`toString` below)"", 'commenter': 'kezhenxu94'}, {'comment': 'Thanks for you review. I got it.', 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdUtils.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.net.URI;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Properties;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.util.Address;
+import org.apache.skywalking.oap.server.library.util.ConnectStringParseException;
+import org.apache.skywalking.oap.server.library.util.ConnectUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdUtils {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdUtils.class);
+
+    public EtcdUtils() {
+    }
+
+    public static List<URI> parse(EtcdServerSettings settings) throws ModuleStartException {
+        List<URI> uris = new ArrayList<>();
+        try {
+            logger.info(""etcd settings is {}"", settings);
+            List<Address> addressList = ConnectUtils.parse(settings.getServerAddr());
+            for (Address address : addressList) {
+                uris.add(URI.create(new StringBuilder(""http://"").append(address.getHost()).append("":"").append(address.getPort()).toString()));","[{'comment': ""string concatenation is error-prone, I'll suggest using `java.net.URI#URI(java.lang.String, java.lang.String, java.lang.String, int, java.lang.String, java.lang.String, java.lang.String)`."", 'commenter': 'kezhenxu94'}, {'comment': ""not a `etcd` expert, perhaps you need to deal with the [authorization](https://github.com/etcd-io/etcd/blob/master/Documentation/op-guide/authentication.md), I'm not sure"", 'commenter': 'kezhenxu94'}, {'comment': 'while open the tls, may be needed authorization.', 'commenter': 'wayilau'}, {'comment': 'I have modified it.', 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdUtils.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.net.URI;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Properties;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.util.Address;
+import org.apache.skywalking.oap.server.library.util.ConnectStringParseException;
+import org.apache.skywalking.oap.server.library.util.ConnectUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdUtils {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdUtils.class);
+
+    public EtcdUtils() {
+    }
+
+    public static List<URI> parse(EtcdServerSettings settings) throws ModuleStartException {
+        List<URI> uris = new ArrayList<>();
+        try {
+            logger.info(""etcd settings is {}"", settings);
+            List<Address> addressList = ConnectUtils.parse(settings.getServerAddr());
+            for (Address address : addressList) {
+                uris.add(URI.create(new StringBuilder(""http://"").append(address.getHost()).append("":"").append(address.getPort()).toString()));
+            }
+        } catch (ConnectStringParseException e) {
+            throw new ModuleStartException(e.getMessage(), e);
+        }
+
+        return uris;
+    }
+
+
+    public static List<URI> parseProp(Properties properties) throws ModuleStartException {
+        List<URI> uris = new ArrayList<>();
+        try {
+            logger.info(""etcd server addr is {}"", properties);
+            List<Address> addressList = ConnectUtils.parse(properties.getProperty(""serverAddr""));
+            for (Address address : addressList) {
+                uris.add(URI.create(new StringBuilder(""http://"").append(address.getHost()).append("":"").append(address.getPort()).toString()));","[{'comment': 'same here', 'commenter': 'kezhenxu94'}]"
2973,oap-server/server-configuration/configuration-etcd/src/test/java/org/apache/skywalking/oap/server/configuration/etcd/ITEtcdConfigurationTest.java,"@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.io.FileNotFoundException;
+import java.io.Reader;
+import java.net.URI;
+import java.util.List;
+import java.util.Map;
+import java.util.Properties;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.apm.util.PropertyPlaceholderHelper;
+import org.apache.skywalking.oap.server.library.module.ApplicationConfiguration;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.library.util.ResourceUtils;
+import org.junit.Before;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.yaml.snakeyaml.Yaml;
+
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.assertTrue;
+
+/**
+ * @author Alan Lau
+ */
+public class ITEtcdConfigurationTest {
+
+    private static final Logger logger = LoggerFactory.getLogger(ITEtcdConfigurationTest.class);
+
+    private final Yaml yaml = new Yaml();
+
+    private EtcdServerSettings settings;
+
+    private EtcdConfigurationTestProvider provider;
+
+    private EtcdClient client;
+
+    @Before
+    public void setUp() throws Exception {
+        final ApplicationConfiguration applicationConfiguration = new ApplicationConfiguration();
+        loadConfig(applicationConfiguration);
+
+        final ModuleManager moduleManager = new ModuleManager();
+        moduleManager.init(applicationConfiguration);
+
+        final String etcdHost = System.getProperty(""etcd.host"");
+        final String etcdPort = System.getProperty(""etcd.port"");
+        logger.info(""etcdHost: {}, etcdPort: {}"", etcdHost, etcdPort);
+        Properties properties = new Properties();
+        properties.setProperty(""serverAddr"", etcdHost + "":"" + etcdPort);
+
+        List<URI> uris = EtcdUtils.parseProp(properties);
+        client = new EtcdClient(uris.toArray(new URI[] {}));
+
+        provider =
+            (EtcdConfigurationTestProvider)moduleManager
+                .find(EtcdConfigurationTestModule.NAME)
+                .provider();
+
+        assertNotNull(provider);
+    }
+
+    @Test(timeout = 2000000)","[{'comment': ""`2000000 ms ~= 33 minutes`, does it take so long in reality? if not I'll suggest choosing a reasonable threshold, otherwise the build job will hang for a long time"", 'commenter': 'kezhenxu94'}, {'comment': 'yes, i forget to change this. i am working on this.', 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdConfigWatcherRegister.java,"@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.io.IOException;
+import java.net.URI;
+import java.util.Set;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdException;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdConfigWatcherRegister extends ConfigWatcherRegister {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdConfigWatcherRegister.class);
+
+    private EtcdServerSettings settings;
+
+    private EtcdClient client;
+
+    @Override public ConfigTable readConfig(Set<String> keys) {
+
+        if (client == null) {
+            try {
+                client = new EtcdClient(EtcdUtils.parse(settings).toArray(new URI[] {}));
+            } catch (ModuleStartException e) {
+                logger.error(e.getMessage(), e);
+            }
+
+            EtcdResponsePromise<EtcdKeysResponse> promise;
+            try {
+                promise = client.get(settings.getClusterName()).waitForChange().send();
+                promise.addListener(responsePromise -> {
+                    onDataValueChanged();
+                });
+
+            } catch (IOException e) {
+                logger.error(e.getMessage(), e);
+            }
+        }
+
+        final ConfigTable table = new ConfigTable();
+        keys.forEach(registryKey -> {
+            String key = new StringBuilder(""/"").append(settings.getGroup()).append(""/"").append(registryKey).toString();
+            try {
+                EtcdResponsePromise<EtcdKeysResponse> promise = client.get(key).send();
+                EtcdKeysResponse response = promise.get();
+                table.add(new ConfigTable.ConfigItem(getRealKey(key, settings.getGroup()), response.getNode().getValue()));
+            } catch (EtcdException e) {
+                if (e.getErrorCode() == 100) {","[{'comment': ""don't use magic number :) use `mousio.etcd4j.responses.EtcdErrorCode#KeyNotFound` instead"", 'commenter': 'kezhenxu94'}, {'comment': 'ok', 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdConfigWatcherRegister.java,"@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.io.IOException;
+import java.net.URI;
+import java.util.Set;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdException;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdConfigWatcherRegister extends ConfigWatcherRegister {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdConfigWatcherRegister.class);
+
+    private EtcdServerSettings settings;
+
+    private EtcdClient client;
+
+    @Override public ConfigTable readConfig(Set<String> keys) {
+
+        if (client == null) {
+            try {
+                client = new EtcdClient(EtcdUtils.parse(settings).toArray(new URI[] {}));","[{'comment': ""may need some synchronization and double check here? `readConfig` is invoked in a scheduled executor at fixed rate (`org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister#start`), in an extreme situation, there may be two or more threads that run into this piece of code simultaneously. I'm not sure whether it's worthy to lazy initialize the `EtcdClient` or not."", 'commenter': 'kezhenxu94'}, {'comment': ""I saw only one thread do the sync operation. @kezhenxu94  so i didn't add the sync. am i wrong ? if so, i will modify this."", 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/pom.xml,"@@ -0,0 +1,214 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-configuration</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.3.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>configuration-etcd</artifactId>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>configuration-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>library-client</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-handler</artifactId>
+            <version>4.1.27.Final</version>
+        </dependency>
+
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-resolver-dns</artifactId>
+            <version>4.1.27.Final</version>
+        </dependency>
+        <dependency>
+            <artifactId>netty-codec-http</artifactId>
+            <groupId>io.netty</groupId>
+            <version>4.1.27.Final</version>
+        </dependency>
+
+
+        <dependency>
+            <groupId>org.mousio</groupId>
+            <artifactId>etcd4j</artifactId>
+            <exclusions>
+                <exclusion>
+                    <artifactId>netty-codec-dns</artifactId>
+                    <groupId>io.netty</groupId>
+                </exclusion>
+
+                <exclusion>
+                    <artifactId>netty-codec-dns</artifactId>
+                    <groupId>io.netty</groupId>
+                </exclusion>
+
+                <exclusion>
+                    <artifactId>netty-codec-http</artifactId>
+                    <groupId>io.netty</groupId>
+                </exclusion>
+
+                <exclusion>
+                    <artifactId>netty-handler</artifactId>
+                    <groupId>io.netty</groupId>
+                </exclusion>
+
+                <exclusion>
+                    <artifactId>netty-resolver-dns</artifactId>
+                    <groupId>io.netty</groupId>
+                </exclusion>
+
+                <exclusion>
+                    <groupId>com.fasterxml.jackson.module</groupId>
+                    <artifactId>jackson-module-afterburner</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+
+        <dependency>
+            <groupId>com.fasterxml.jackson.module</groupId>
+            <artifactId>jackson-module-afterburner</artifactId>
+            <version>2.9.5</version>
+        </dependency>
+        <dependency>
+            <groupId>org.yaml</groupId>
+            <artifactId>snakeyaml</artifactId>
+            <version>1.18</version>
+        </dependency>","[{'comment': 'For all dependencies, we have etcd cluster management implementation, we should have all the dependencies we need, why we add more here? What is the difference?', 'commenter': 'wu-sheng'}, {'comment': 'FYI @kezhenxu94 This is the most important thing, we should treat dependency very serious, accept reasonable and necessary new dependencies.', 'commenter': 'wu-sheng'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdConfigWatcherRegister.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.io.IOException;
+import java.net.URI;
+import java.util.Set;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdErrorCode;
+import mousio.etcd4j.responses.EtcdException;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdConfigWatcherRegister extends ConfigWatcherRegister {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdConfigWatcherRegister.class);
+
+    private EtcdServerSettings settings;
+
+    private EtcdClient client;
+
+    @Override public ConfigTable readConfig(Set<String> keys) {
+
+        if (client == null) {
+            try {
+                client = new EtcdClient(EtcdUtils.parse(settings).toArray(new URI[] {}));
+            } catch (ModuleStartException e) {
+                logger.error(e.getMessage(), e);
+            }
+
+            EtcdResponsePromise<EtcdKeysResponse> promise;
+            try {
+                promise = client.get(settings.getClusterName()).waitForChange().send();
+                promise.addListener(responsePromise -> {
+                    onDataValueChanged();
+                });
+
+            } catch (IOException e) {
+                logger.error(e.getMessage(), e);
+            }
+        }
+
+        final ConfigTable table = new ConfigTable();
+        keys.forEach(registryKey -> {
+            String key = new StringBuilder(""/"").append(settings.getGroup()).append(""/"").append(registryKey).toString();","[{'comment': 'Use `+` instead of `#append`. There is compiler optimization there, no need to use this. ', 'commenter': 'wu-sheng'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdConfigWatcherRegister.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import java.io.IOException;
+import java.net.URI;
+import java.util.Set;
+import mousio.etcd4j.EtcdClient;
+import mousio.etcd4j.promises.EtcdResponsePromise;
+import mousio.etcd4j.responses.EtcdErrorCode;
+import mousio.etcd4j.responses.EtcdException;
+import mousio.etcd4j.responses.EtcdKeysResponse;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdConfigWatcherRegister extends ConfigWatcherRegister {
+
+    private final static Logger logger = LoggerFactory.getLogger(EtcdConfigWatcherRegister.class);
+
+    private EtcdServerSettings settings;
+
+    private EtcdClient client;
+
+    @Override public ConfigTable readConfig(Set<String> keys) {
+
+        if (client == null) {
+            try {
+                client = new EtcdClient(EtcdUtils.parse(settings).toArray(new URI[] {}));
+            } catch (ModuleStartException e) {
+                logger.error(e.getMessage(), e);
+            }
+
+            EtcdResponsePromise<EtcdKeysResponse> promise;
+            try {
+                promise = client.get(settings.getClusterName()).waitForChange().send();
+                promise.addListener(responsePromise -> {
+                    onDataValueChanged();
+                });
+
+            } catch (IOException e) {
+                logger.error(e.getMessage(), e);
+            }
+        }
+
+        final ConfigTable table = new ConfigTable();
+        keys.forEach(registryKey -> {
+            String key = new StringBuilder(""/"").append(settings.getGroup()).append(""/"").append(registryKey).toString();
+            try {
+                EtcdResponsePromise<EtcdKeysResponse> promise = client.get(key).send();
+                EtcdKeysResponse response = promise.get();
+                table.add(new ConfigTable.ConfigItem(getRealKey(key, settings.getGroup()), response.getNode().getValue()));
+            } catch (EtcdException e) {
+                if (e.getErrorCode() == EtcdErrorCode.KeyNotFound) {
+                    table.add(new ConfigTable.ConfigItem(getRealKey(key, settings.getGroup()), null));
+                } else {
+                    logger.error(e.getMessage(), e);
+                }
+            } catch (Exception e1) {
+                logger.error(e1.getMessage(), e1);
+            }
+        });
+
+        return table;
+    }
+
+    public EtcdConfigWatcherRegister(EtcdServerSettings settings) {
+        this.settings = settings;
+    }
+
+    private void onDataValueChanged() {","[{'comment': 'What is this empty method for?', 'commenter': 'wu-sheng'}, {'comment': ""Actually, it is unused now. Maybe use to monitor the value changed some time for some thing. But i didn't impl that at this time."", 'commenter': 'wayilau'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdConfigurationProvider.java,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import com.google.common.base.Strings;
+import org.apache.skywalking.oap.server.configuration.api.AbstractConfigurationProvider;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * @author Alan Lau
+ */
+public class EtcdConfigurationProvider extends AbstractConfigurationProvider {
+
+    private final static Logger LOG = LoggerFactory.getLogger(EtcdConfigurationProvider.class);","[{'comment': 'LOG -> logger', 'commenter': 'wu-sheng'}]"
2973,oap-server/server-configuration/configuration-etcd/src/main/java/org/apache/skywalking/oap/server/configuration/etcd/EtcdServerSettings.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.etcd;
+
+import lombok.Getter;
+import lombok.Setter;
+import lombok.ToString;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+
+/**
+ * @author Alan Lau
+ */
+@ToString
+@Getter
+@Setter
+public class EtcdServerSettings extends ModuleConfig {
+
+    private String clusterName = ""default"";
+    private String serverAddr;
+    private String group;
+    private int period = 5;","[{'comment': ""default is 5, unit? If unit=second, I think it is too short for timeout, try 30 for configuration center, because in most case, people don't treat performance and latency very seriously for it."", 'commenter': 'wu-sheng'}, {'comment': ""For the config\r\n```yaml\r\n#    period : 60 # Unit seconds, sync period. Default fetch every 60 seconds.\r\n```\r\n\r\nWhy don't use 60 in codes?"", 'commenter': 'wu-sheng'}, {'comment': 'ok, i will fix this.', 'commenter': 'wayilau'}]"
3004,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/worker/RegisterPersistentWorker.java,"@@ -80,43 +92,80 @@ private void onWork(RegisterSource registerSource) {
         } else {
             sources.get(registerSource).combine(registerSource);
         }
-
         if (sources.size() > 1000 || registerSource.getEndOfBatchContext().isEndOfBatch()) {
             sources.values().forEach(source -> {
+                RegisterSource cacheSource = null;
                 try {
-                    RegisterSource dbSource = registerDAO.get(modelName, source.id());
+                    RegisterSource dbSource = this.getRegisterSourceCache(source.id());
                     if (Objects.nonNull(dbSource)) {
                         if (dbSource.combine(source)) {
-                            registerDAO.forceUpdate(modelName, dbSource);","[{'comment': 'forceUpdate means update immediately. I am not sure that it can be change to batch. Because the data will be delay to visible to others.', 'commenter': 'dmsolr'}, {'comment': ""I've used the IMMEDIATE RefreshPolicy in my code, and you can find it in ElasticSearchClient. "", 'commenter': 'lt964709769'}, {'comment': 'I means cache could cause dirty read in cluster mode. As @wu-sheng say.', 'commenter': 'dmsolr'}]"
3004,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/worker/RegisterPersistentWorker.java,"@@ -93,78 +91,49 @@ private void onWork(RegisterSource registerSource) {
             sources.get(registerSource).combine(registerSource);
         }
         if (sources.size() > 1000 || registerSource.getEndOfBatchContext().isEndOfBatch()) {
-            sources.values().forEach(source -> {
-                RegisterSource cacheSource = null;
-                try {
-                    RegisterSource dbSource = this.getRegisterSourceCache(source.id());
-                    if (Objects.nonNull(dbSource)) {
-                        if (dbSource.combine(source)) {
-                            batchPersistenList.add(registerDAO.prepareBatchUpdate(modelName, dbSource));
-                            cacheSource = dbSource;
-                        }
-                    } else {
-                        int sequence;
-                        if ((sequence = registerLockDAO.getId(scopeId, source)) != Const.NONE) {
-                            try {
-                                dbSource = this.getRegisterSourceCache(source.id());
-                                if (Objects.nonNull(dbSource)) {
-                                    if (dbSource.combine(source)) {
-                                        batchPersistenList.add(registerDAO.prepareBatchUpdate(modelName, dbSource));
-                                        cacheSource = dbSource;
+            try {
+                List<String> ids = sources.values().stream().map(value -> value.id()).collect(Collectors.toList());
+                final Map<String, RegisterSource> map = registerDAO.batchGet(modelName, ids.toArray(new String[0]));","[{'comment': ""We don't need to convert array, right?"", 'commenter': 'dmsolr'}, {'comment': 'This problem has now been modified.', 'commenter': 'lt964709769'}]"
3004,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2RegisterDAO.java,"@@ -47,6 +49,18 @@ public H2RegisterDAO(JDBCHikariCPClient h2Client, StorageBuilder<RegisterSource>
         return (RegisterSource)getByID(h2Client, modelName, id, storageBuilder);
     }
 
+    @Override
+    public Map<String, RegisterSource> batchGet(String modelName, String... ids) throws IOException {
+        Map<String, RegisterSource> map = new HashMap<>(ids.length);
+        for (String id : ids) {
+            RegisterSource registerSource = this.get(modelName, id);","[{'comment': 'We can do real batch queries as ES do here. ', 'commenter': 'dmsolr'}, {'comment': '@peng-yongsheng what do you think?', 'commenter': 'wu-sheng'}, {'comment': 'Now, this has been modified to be a real batch query.', 'commenter': 'lt964709769'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -146,7 +146,13 @@ public JsonObject getIndex(String indexName) throws IOException {
     }
 
     public boolean deleteIndex(String indexName) throws IOException {
-        indexName = formatIndexName(indexName);
+        return deleteIndex(indexName, true);
+    }
+
+    public boolean deleteIndex(String indexName, boolean formatIndexName) throws IOException {","[{'comment': 'These two delete methods will make people very confused.', 'commenter': 'wu-sheng'}, {'comment': ""> I suggest you move the whole code block inside `ElasticSearchClient` as method `#deleteTimeSeriesData(modelName, timeBefore)`. Then the delete codes without `formatIndexName` could ba placed inside method directly.\r\n> \r\n> ```java\r\n> List<String> indexes = client.retrievalIndexByAliases(model.getName());\r\n> \r\n>             List<String> prepareDeleteIndexes = new ArrayList<>();\r\n>             for (String index : indexes) {\r\n>                 long timeSeries = TimeSeriesUtils.indexTimeSeries(index);\r\n>                 if (timeBefore >= timeSeries) {\r\n>                     prepareDeleteIndexes.add(index);\r\n>                 }\r\n>             }\r\n> \r\n>             if (indexes.size() == prepareDeleteIndexes.size()) {\r\n>                 client.createIndex(TimeSeriesUtils.timeSeries(model));\r\n>             }\r\n> \r\n>             for (String prepareDeleteIndex : prepareDeleteIndexes) {\r\n>                 client.deleteIndex(prepareDeleteIndex);\r\n>             }\r\n> ```\r\n> \r\n> I think don't mixe these two kinds of OP(s) together should be much better.\r\n\r\nThis code block needs to use ```TimeSeriesUtils```, but ```TimeSeriesUtils``` is located in``` storage-elasticsearch-plugin```\r\n\r\n"", 'commenter': 'arugal'}, {'comment': 'or delete the ```namespace``` in the ```#retrievalIndexByAliases```return result.', 'commenter': 'arugal'}, {'comment': 'Then build List ESTimeSeriesIndex, in each element, keep namespace and name in two fields. Then add a new delete method accepting ESTimeSeriesIndex', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -292,7 +300,14 @@ public int delete(String indexName, String timeBucketColumnName, long endTimeBuc
 
     public String formatIndexName(String indexName) {
         if (StringUtils.isNotEmpty(namespace)) {
-            return namespace + ""_"" + indexName;
+            return namespacePrefix + indexName;
+        }
+        return indexName;
+    }
+
+    public String undoFormatIndexName(String indexName) {","[{'comment': 'This should be private.', 'commenter': 'wu-sheng'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -292,7 +300,14 @@ public int delete(String indexName, String timeBucketColumnName, long endTimeBuc
 
     public String formatIndexName(String indexName) {
         if (StringUtils.isNotEmpty(namespace)) {
-            return namespace + ""_"" + indexName;
+            return namespacePrefix + indexName;
+        }
+        return indexName;
+    }
+
+    public String undoFormatIndexName(String indexName) {
+        if (StringUtils.isNotEmpty(namespace) && indexName.startsWith(namespacePrefix)) {","[{'comment': 'If `!startWith(namespace`, then you should raise an exception.', 'commenter': 'wu-sheng'}]"
3017,oap-server/server-library/library-client/src/test/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ITElasticSearchClient.java,"@@ -183,4 +183,14 @@ public void bulk() throws InterruptedException {
         bulkProcessor.flush();
         bulkProcessor.awaitClose(2, TimeUnit.SECONDS);
     }
+
+    @Test
+    public void undoFormatIndexName() {","[{'comment': 'This is an IT test, Integration Test. You should test `retrievalIndexByAliases` with real Elastic, create indexes with namespace, then test `#retrievalIndexByAliases` result', 'commenter': 'wu-sheng'}, {'comment': 'Take an example with other tests in this class.', 'commenter': 'wu-sheng'}]"
3017,oap-server/server-library/library-client/src/test/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ITElasticSearchClient.java,"@@ -51,7 +52,10 @@
     @Before
     public void before() throws IOException {
         final String esAddress = System.getProperty(""elastic.search.address"");
-        client = new ElasticSearchClient(esAddress, """", ""test"", ""test"");
+        final String esNamespace = System.getProperty(""elastic.search.namespace"", """");
+        final String esUser = System.getProperty(""elastic.search.user"", ""test"");
+        final String esPassword = System.getProperty(""elastic.search.password"", ""test"");","[{'comment': 'One question, who will set these properties?', 'commenter': 'wu-sheng'}, {'comment': ""If not, then,  namespace feature hasn't been tested."", 'commenter': 'wu-sheng'}, {'comment': 'Can I use the ```maven-failsafe-plugin```, as follows\r\n```\r\n                    <plugin>\r\n                        <groupId>org.apache.maven.plugins</groupId>\r\n                        <artifactId>maven-failsafe-plugin</artifactId>\r\n                        <configuration>\r\n                            <systemPropertyVariables>\r\n                                <elastic.search.address>\r\n                                    ${docker.hostname}:${es-port}\r\n                                </elastic.search.address>\r\n                                <elastic.search.namespace>\r\n                                    test\r\n                                </elastic.search.namespace>\r\n                            </systemPropertyVariables>\r\n                        </configuration>\r\n                        <executions>\r\n                            <execution>\r\n                                <goals>\r\n                                    <goal>integration-test</goal>\r\n                                    <goal>verify</goal>\r\n                                </goals>\r\n                            </execution>\r\n                        </executions>\r\n                    </plugin>\r\n```', 'commenter': 'arugal'}, {'comment': 'After adding ```namespace```,```getIndex``` has the same problem, which I will modify together\r\nhttps://github.com/apache/skywalking/blob/b21db17148df12f34a13a2b1693e009e11e8d7a2/oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java#L138-L146', 'commenter': 'arugal'}, {'comment': ""System properties are used for uncertain variables, because of docker env. You don't need this, actually, you could add it to test codes directly, which will be more clear."", 'commenter': 'wu-sheng'}, {'comment': ""Also, @Arugal `#getIndex` is not used in codes anymore, we only use it in IT test, let's move it to ITElasticSearchClient? That will make us has fewer codes concern of index name."", 'commenter': 'wu-sheng'}, {'comment': ""> Also, @Arugal `#getIndex` is not used in codes anymore, we only use it in IT test, let's move it to ITElasticSearchClient? That will make us has fewer codes concern of index name.\r\n\r\n```#getIndex``` needs to invoker ```RestHighLevelClient#getLowLevelClient``` ,unless we can get a ```RestHighLevelClient``` instance via ```ElasticSearchClient```"", 'commenter': 'arugal'}, {'comment': ""> System properties are used for uncertain variables, because of docker env. You don't need this, actually, you could add it to test codes directly, which will be more clear.\r\n\r\ndone"", 'commenter': 'arugal'}, {'comment': ""> > Also, @Arugal `#getIndex` is not used in codes anymore, we only use it in IT test, let's move it to ITElasticSearchClient? That will make us has fewer codes concern of index name.\r\n> \r\n> `#getIndex` needs to invoker `RestHighLevelClient#getLowLevelClient` ,unless we can get a `RestHighLevelClient` instance via `ElasticSearchClient`\r\n\r\n\r\n\r\n> getIndex method is still there. I think no ine uses it, should remove, right?\r\n\r\nCan I do what I said above?"", 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/test/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ITElasticSearchClient.java,"@@ -183,4 +187,51 @@ public void bulk() throws InterruptedException {
         bulkProcessor.flush();
         bulkProcessor.awaitClose(2, TimeUnit.SECONDS);
     }
+
+    @Test
+    public void timeSeriesOperate() throws IOException {
+        String indexName = ""test_time_series_operate"";
+        String timeSeriesIndexName = indexName + ""-2019"";
+
+        try {
+            if (client.isExistsTemplate(indexName)) {","[{'comment': ""Why these is an chance existing? If other case doesn't remove, set a finally there."", 'commenter': 'wu-sheng'}, {'comment': ""Because my local tests don't create a new es container every time, I delete it"", 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/test/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ITElasticSearchClient.java,"@@ -183,4 +187,51 @@ public void bulk() throws InterruptedException {
         bulkProcessor.flush();
         bulkProcessor.awaitClose(2, TimeUnit.SECONDS);
     }
+
+    @Test
+    public void timeSeriesOperate() throws IOException {
+        String indexName = ""test_time_series_operate"";
+        String timeSeriesIndexName = indexName + ""-2019"";
+
+        try {
+            if (client.isExistsTemplate(indexName)) {
+                client.deleteTemplate(indexName);
+            }
+
+            JsonObject mapping = new JsonObject();
+            mapping.add(""type"", new JsonObject());
+            JsonObject doc = mapping.getAsJsonObject(""type"");
+
+            JsonObject properties = new JsonObject();
+            doc.add(""properties"", properties);
+
+            JsonObject column = new JsonObject();
+            column.addProperty(""type"", ""text"");
+            properties.add(""name"", column);
+
+            client.createTemplate(indexName, new JsonObject(), mapping);
+
+            XContentBuilder builder = XContentFactory.jsonBuilder().startObject()
+                .field(""name"", ""pengys"")
+                .endObject();
+            client.forceInsert(timeSeriesIndexName, ""testid"", builder);
+
+            List<ElasticSearchTimeSeriesIndex> indexes = client.retrievalIndexByAliases(indexName);
+            Assert.assertEquals(1, indexes.size());
+            ElasticSearchTimeSeriesIndex index = indexes.get(0);
+            Assert.assertEquals(index.getNamespace(), System.getProperty(""elastic.search.namespace"", """"));","[{'comment': 'Same question where does the property come from?', 'commenter': 'wu-sheng'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -292,7 +300,34 @@ public int delete(String indexName, String timeBucketColumnName, long endTimeBuc
 
     public String formatIndexName(String indexName) {
         if (StringUtils.isNotEmpty(namespace)) {
-            return namespace + ""_"" + indexName;
+            return namespacePrefix + indexName;
+        }
+        return indexName;
+    }
+
+    private JsonObject undoFormatIndexName(JsonObject index) {
+        if (StringUtils.isNotEmpty(namespace) && index != null && index.size() > 0) {
+            Set<Map.Entry<String, JsonElement>> entrySet = index.entrySet();
+            for (Map.Entry<String, JsonElement> entry : entrySet) {","[{'comment': 'Change this to `index.foreach -> `', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -119,20 +123,20 @@ public boolean createIndex(String indexName, JsonObject settings, JsonObject map
         return response.isAcknowledged();
     }
 
-    public List<String> retrievalIndexByAliases(String aliases) throws IOException {
+    public List<ElasticSearchTimeSeriesIndex> retrievalIndexByAliases(String aliases) throws IOException {
         aliases = formatIndexName(aliases);
-
         Response response = client.getLowLevelClient().performRequest(HttpGet.METHOD_NAME, ""/_alias/"" + aliases);
-
-        List<String> indexes = new ArrayList<>();
         if (HttpStatus.SC_OK == response.getStatusLine().getStatusCode()) {
             Gson gson = new Gson();
             InputStreamReader reader = new InputStreamReader(response.getEntity().getContent());
             JsonObject responseJson = gson.fromJson(reader, JsonObject.class);
             logger.debug(""retrieval indexes by aliases {}, response is {}"", aliases, responseJson);
-            indexes.addAll(responseJson.keySet());
+            Set<String> keySet = responseJson.keySet();
+            if (!keySet.isEmpty()) {
+                return keySet.stream().map(this::undoFormatIndexName).map(index -> new ElasticSearchTimeSeriesIndex(namespace, index)).collect(Collectors.toList());
+            }
         }
-        return indexes;
+        return Collections.EMPTY_LIST;
     }
 
     public JsonObject getIndex(String indexName) throws IOException {","[{'comment': '`getIndex` method needs to move to `ITElasticSearchClient` with `undoFormatIndexName(JsonObject index)` method.', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/test/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ITElasticSearchClientOfNamespace.java,"@@ -0,0 +1,30 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.library.client.elasticsearch;
+
+/**
+ * @author: zhangwei
+ */
+public class ITElasticSearchClientOfNamespace extends ITElasticSearchClient {
+
+
+    public ITElasticSearchClientOfNamespace() {","[{'comment': ""Has this run? I haven't used this kind of test before. Please confirm in the log."", 'commenter': 'wu-sheng'}, {'comment': 'confirm, [This is my local compile log](https://github.com/Arugal/skywalking-install-log/blob/066ffa9a2b42bbef1c86d5544eaeba9b1109356b/install.txt#L2421-L2458) \r\n', 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -292,7 +300,34 @@ public int delete(String indexName, String timeBucketColumnName, long endTimeBuc
 
     public String formatIndexName(String indexName) {
         if (StringUtils.isNotEmpty(namespace)) {
-            return namespace + ""_"" + indexName;
+            return namespacePrefix + indexName;
+        }
+        return indexName;
+    }
+
+    private JsonObject undoFormatIndexName(JsonObject index) {","[{'comment': ""We don't need this method, this should move to test class only. Right?"", 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'arugal'}]"
3017,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -57,13 +60,15 @@
     public static final String TYPE = ""type"";
     private final String clusterNodes;
     private final String namespace;
+    private final String namespacePrefix;
     private final String user;
     private final String password;
-    private RestHighLevelClient client;
+    @Getter(value = AccessLevel.PACKAGE) private RestHighLevelClient client;","[{'comment': 'Use whitebox get from powermock to get this.', 'commenter': 'wu-sheng'}]"
3021,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/consumer/ConsumerThread.java,"@@ -36,7 +37,7 @@
         super(threadName);
         this.consumer = consumer;
         running = false;
-        dataSources = new LinkedList<DataSource>();
+        dataSources = new ArrayList<DataSource>(1);","[{'comment': 'ArrayList size 1? Why?', 'commenter': 'wu-sheng'}, {'comment': 'Because I think the default value(10) is large. It will only grow at initialization. Could you give some suggestion?', 'commenter': 'dmsolr'}, {'comment': ""This is why we use LinkedList. From several Google articles, we should always use ArrayList(no LinkedList)\r\n\r\nBut in this case, we can't be sure which is the right size for ArrayList, and how to be sure ArrayList is better in all scenario.\r\n\r\nI used to think about use ArrayList in TracingContext, another core using LinkedList today. But I find out it is hard to make a reasonable decision."", 'commenter': 'wu-sheng'}, {'comment': 'In DataCarrier Consumer, there are two\r\n1. ConsumerThread(agent used today)\r\n1. MultipleChannelsConsumer(OAP used today)\r\n\r\nIn the queue, it is much easier than TracingContext, you need to tests the performance in different initial sizes and different max sizes.\r\n\r\nSuch as in `MultipleChannelsConsumer`\r\n1. Init=10, Expected list size=40000. In 16CPU VM, 32 Threads deal with 100 queues,  meaning max list size = 10000 * 4(queue size). Read `MultipleChannelsConsumer`\r\n1. Init=1, Max data size=40000\r\n1. Init = 40000, Max = 40000\r\n1. Init = 8000, Max = 40000\r\n\r\nAnother optimization option is, hold the consumer list, just set the element to `null`, to avoid the size extension, but cost more GC potentially.', 'commenter': 'wu-sheng'}, {'comment': 'Anyway, if you want to do this, I think we should work on a test blog first, work on different scenarios, then back to this PR. If this makes sense to you.\r\n\r\ncc @zhaoyuguang @kezhenxu94 @ascrutae @JaredTan95   in case you are interested in this core optimization.', 'commenter': 'wu-sheng'}, {'comment': 'Thanks for your comments. I will think more and provide more completely benchmark cases later.\r\nWelcome to join.', 'commenter': 'dmsolr'}, {'comment': 'Feel free to create a new repo for set up benchmarks, if that is easier to create  benchmarks before change codes.', 'commenter': 'wu-sheng'}, {'comment': ""I had tested the performance of the ArrayList and LinkedList. But the report was lost. I just remember that LinkedList is faster than ArrayList if the size is below 5w.\r\nA very important thing you must know is Datacarrier sends it's data to the consumer every 20ms. So, if the queue size more than 5w, that means the TPS is 5w * (1000ms / 20ms) = 250w. This is a not reachable TPS.\r\n\r\n@dmsolr "", 'commenter': 'peng-yongsheng'}]"
3048,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -210,7 +210,8 @@ public void afterBulk(long executionId, BulkRequest request, Throwable failure)
         return BulkProcessor.builder(client::bulkAsync, listener)
             .setBulkActions(bulkActions)
             .setBulkSize(new ByteSizeValue(bulkSize, ByteSizeUnit.MB))
-            .setFlushInterval(TimeValue.timeValueSeconds(flushInterval))
+            // modified by zhaoze, if set auto flush, there will cause deadlock with bulk commit.","[{'comment': ""You can't set this comment in the repo, remove it"", 'commenter': 'wu-sheng'}, {'comment': 'Make comment without yout name, just why.', 'commenter': 'wu-sheng'}, {'comment': 'OK, i got it', 'commenter': 'coki230'}]"
3093,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/consumer/ConsumerThread.java,"@@ -77,31 +77,26 @@ public void run() {
 
         // consumer thread is going to stop
         // consume the last time
-        consume();
+        consume(consumeList);
 
         consumer.onExit();
     }
 
-    private boolean consume() {
-        boolean hasData = false;
-        LinkedList<T> consumeList = new LinkedList<T>();
+    private boolean consume(List<T> consumeList) {
         for (DataSource dataSource : dataSources) {
-            LinkedList<T> data = dataSource.obtain();
-            if (data.size() == 0) {
-                continue;
-            }
-            consumeList.addAll(data);
-            hasData = true;
+            dataSource.obtain(consumeList);
         }
 
-        if (consumeList.size() > 0) {
+        if (!consumeList.isEmpty()) {
             try {
                 consumer.consume(consumeList);
             } catch (Throwable t) {
                 consumer.onError(consumeList, t);
             }
+            consumeList.clear();","[{'comment': 'All clear need in final. In case `#onError` fails.', 'commenter': 'wu-sheng'}]"
3093,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/consumer/MultipleChannelsConsumer.java,"@@ -55,34 +59,33 @@ public void run() {
                 } catch (InterruptedException e) {
                 }
             }
-
         }
 
         // consumer thread is going to stop
         // consume the last time
         for (Group target : consumeTargets) {
-            consume(target);
+            consume(target, consumeList);
 
             target.consumer.onExit();
         }
     }
 
-    private boolean consume(Group target) {
-        boolean hasData;
-        LinkedList consumeList = new LinkedList();
+    private boolean consume(Group target, List consumeList) {
         for (int i = 0; i < target.channels.getChannelSize(); i++) {
             Buffer buffer = target.channels.getBuffer(i);
-            consumeList.addAll(buffer.obtain());
+            buffer.obtain(consumeList);
         }
 
-        if (hasData = consumeList.size() > 0) {
+        if (!consumeList.isEmpty()) {
             try {
                 target.consumer.consume(consumeList);
             } catch (Throwable t) {
                 target.consumer.onError(consumeList, t);
             }
+            consumeList.clear();","[{'comment': 'Same as above. Keep clear in final.', 'commenter': 'wu-sheng'}]"
3093,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/consumer/MultipleChannelsConsumer.java,"@@ -43,10 +46,11 @@ public MultipleChannelsConsumer(String threadName, long consumeCycle) {
     public void run() {
         running = true;
 
+        final List consumeList = new ArrayList(2000);
         while (running) {
             boolean hasData = false;
             for (Group target : consumeTargets) {
-                hasData = hasData || consume(target);
+                hasData |= consume(target, consumeList);","[{'comment': 'You change `||` to `|`', 'commenter': 'wu-sheng'}, {'comment': 'They are the same here, right? ', 'commenter': 'dmsolr'}, {'comment': ""> They are the same here, right?\r\n\r\nNot realy, it's `short circuit` operation (`consume` won't be called if `hasData == true`) before your changes and the `consume` would always be called after your changes"", 'commenter': 'kezhenxu94'}, {'comment': ""> Not realy, it's short circuit operation (consume won't be called if hasData == true) before your changes and the consume would always be called after your changes\r\n\r\nLet's make it clear, it should consume even hasData. If old codes didn't, that is a bug by me  :( I was not expecting this before. \r\nLet's remove the `|` and `||`, change it to normal codes \r\n```java\r\nboolean consumeResult = consume(target);\r\nhasData = hasData || consumeResult;\r\n```"", 'commenter': 'wu-sheng'}, {'comment': 'I got it.', 'commenter': 'dmsolr'}, {'comment': 'Checked. Old codes did `short circuit`, which is wrong. \r\nWe should consume all group in one loop\r\nI think this will improve performance.\r\n\r\n@kezhenxu94 Thanks for pointing this out.', 'commenter': 'wu-sheng'}, {'comment': 'I have a test, `||` is shor circuit.', 'commenter': 'dmsolr'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/RoutingHandlerInterceptor.java,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x;
+
+import io.undertow.server.ExchangeCompletionListener;
+import io.undertow.server.HttpHandler;
+import io.undertow.server.HttpServerExchange;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.undertow.v2x.util.TraceContextUtils;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author AI
+ * 2019-07-25
+ */
+public class RoutingHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        int httpHandlerIndex = -1;
+        for (int index = 0; index < allArguments.length; index++) {
+            Object any = allArguments[index];
+            if (any instanceof HttpHandler) {
+                httpHandlerIndex = index;
+                break;
+            }
+        }
+        if (httpHandlerIndex > -1) {
+            HttpHandler handler = (HttpHandler) allArguments[httpHandlerIndex];
+            String template = (String) allArguments[1];
+            allArguments[httpHandlerIndex] = new TracingHandler(template, handler);
+            TraceContextUtils.enabledRoutingHandlerTracing();
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);
+    }
+
+    private static class TracingHandler implements HttpHandler {
+        private final String template;
+        private final HttpHandler next;
+
+        TracingHandler(String template, HttpHandler handler) {
+            this.next = handler;
+            this.template = template;
+        }
+
+        @Override
+        public void handleRequest(HttpServerExchange exchange) throws Exception {
+            final AbstractSpan span = TraceContextUtils.buildUndertowEntrySpan(exchange, template);
+            exchange.addExchangeCompleteListener(new ExchangeCompletionListener() {
+                @Override
+                public void exchangeEvent(HttpServerExchange httpServerExchange, NextListener nextListener) {
+                    if (httpServerExchange.getStatusCode() >= 400) {
+                        span.errorOccurred();
+                        Tags.STATUS_CODE.set(span, Integer.toString(httpServerExchange.getStatusCode()));
+                    }
+                    span.asyncFinish();
+                    nextListener.proceed();
+                }
+            });
+            next.handleRequest(exchange);
+            span.prepareForAsync();","[{'comment': '`span.prepareForAsync();` should call before `next.handleRequest(exchange)` because in some low latency request, when `span.asyncFinish();` execute the `prepareForAsync` may not execute which may cause error.', 'commenter': 'candyleer'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/util/TraceContextUtils.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x.util;
+
+import io.undertow.server.HttpServerExchange;
+import io.undertow.util.HeaderMap;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.util.concurrent.atomic.AtomicBoolean;
+
+/**
+ * @author AI
+ * 2019-07-26
+ */
+public class TraceContextUtils {
+
+    private static final AtomicBoolean IS_IN_ROUTING_HANDLER_TRACE = new AtomicBoolean(false);","[{'comment': 'This is a static final field, what happens in the concurrency case?', 'commenter': 'wu-sheng'}, {'comment': 'This is a private field, When the agent was bind `RoutingHandlerInterceptor` to method `io.undertow.server.RoutingHandler.add` the field will be set to `true`.\r\n\r\nWhy need the flag(`IS_IN_ROUTING_HANDLER_TRACE`) ?\r\nThe `ExecuteRootHandlerInterceptor`(it is a static method plugin) will be bind to method `io.undertow.server.Connectors.executeRootHandler` also in agent started. When undertow handling user request. `io.undertow.server.Connectors.executeRootHandler` and `io.undertow.server.HttpHandler.handleRequest` will be invoked both and request will be traced twice (it will create two EntrySpan).\r\n\r\nWe need a flag avoid a request traced twice. So when the agent was binded `RoutingHandlerInterceptor` it not trace in `ExecuteRootHandlerInterceptor` no more.', 'commenter': 'aiyanbo'}, {'comment': '> When undertow handling user request. io.undertow.server.Connectors.executeRootHandler and io.undertow.server.HttpHandler.handleRequest will be invoked both and request will be traced twice\r\n\r\nCould we make the binding happens once? Or this keeps in uncertain status.\r\n\r\n> it will create two EntrySpan\r\n\r\nThese two in different threads? If in the same thread, these two should be merged automatically.', 'commenter': 'wu-sheng'}, {'comment': '> Could we make the binding happens once? Or this keeps in uncertain status.\r\n\r\nNo, we cannot.\r\n\r\nWhen undertow using `RoutingHandler` it will binding to `RoutingHandlerInterceptor`\r\n```\r\nRoutingHandler handler = new RoutingHandler();\r\n// RoutingHandlerInterceptor\'s cutpoint is add method\r\nhandler.add(Methods.GET, ""/projects/{projectId}"", exchange -> {\r\n    exchange.getResponseHeaders().put(Headers.CONTENT_TYPE, ""text/plain"");\r\n    exchange.getResponseSender().send(""Hello World"");\r\n });\r\nUndertow server = Undertow.builder().setHandler(handler)...\r\n```\r\nor using `HttpHandler` it will binding to `ExecuteRootHandlerInterceptor`\r\n```\r\nio.undertow.server.Connectors.executeRootHandler\r\n Undertow.builder().setHandler(new HttpHandler() {\r\n    @Override\r\n    public void handleRequest(HttpServerExchange httpServerExchange) throws Exception {\r\n        //\r\n    }\r\n});\r\n```\r\nWe cannot detected user how to use `undertow`. So we need keep `ExecuteRootHandlerInterceptor` and `RoutingHandlerInterceptor` both.\r\n\r\n> These two in different threads? \r\n\r\nMaybe, `HttpServerExchange` can dispatched to other `Executor`.\r\n\r\n> If in the same thread, these two should be merged automatically.\r\n\r\nEntrySpan 1: /projects/1\r\nEntrySpan 2: /projects/{projectId} \r\n\r\nit can merged automatically?\r\n\r\n', 'commenter': 'aiyanbo'}, {'comment': 'If EntrySpan2 happens after EntrySpan1, and both of them in the same thread, then yes. it will merge automatically. You could try.', 'commenter': 'wu-sheng'}, {'comment': 'Thanks', 'commenter': 'aiyanbo'}, {'comment': 'What is the progress here? Is merge working? Even not, there is still an issue. Think in this way, what happens in user set up two `Undertow` servers w/ different handler? The value will be changed in the wrong way.', 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/RoutingHandlerInterceptor.java,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x;
+
+import io.undertow.server.ExchangeCompletionListener;
+import io.undertow.server.HttpHandler;
+import io.undertow.server.HttpServerExchange;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.undertow.v2x.util.TraceContextUtils;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author AI
+ * 2019-07-25
+ */
+public class RoutingHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        int httpHandlerIndex = -1;
+        for (int index = 0; index < allArguments.length; index++) {
+            Object any = allArguments[index];
+            if (any instanceof HttpHandler) {
+                httpHandlerIndex = index;
+                break;
+            }
+        }
+        if (httpHandlerIndex > -1) {
+            HttpHandler handler = (HttpHandler) allArguments[httpHandlerIndex];
+            String template = (String) allArguments[1];
+            allArguments[httpHandlerIndex] = new TracingHandler(template, handler);
+            TraceContextUtils.enabledRoutingHandlerTracing();
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);
+    }
+
+    static class TracingHandler implements HttpHandler {
+        private final String template;
+        private final HttpHandler next;
+
+        TracingHandler(String template, HttpHandler handler) {
+            this.next = handler;
+            this.template = template;
+        }
+
+        @Override
+        public void handleRequest(HttpServerExchange exchange) throws Exception {
+            final AbstractSpan span = TraceContextUtils.buildUndertowEntrySpan(exchange, template);
+            span.prepareForAsync();
+            exchange.addExchangeCompleteListener(new ExchangeCompletionListener() {
+                @Override
+                public void exchangeEvent(HttpServerExchange httpServerExchange, NextListener nextListener) {
+                    if (httpServerExchange.getStatusCode() >= 400) {
+                        span.errorOccurred();
+                        Tags.STATUS_CODE.set(span, Integer.toString(httpServerExchange.getStatusCode()));
+                    }
+                    span.asyncFinish();
+                    nextListener.proceed();
+                }
+            });
+            next.handleRequest(exchange);","[{'comment': ""There are possibilities that the lines before `next.handleRequest(exchange);` throw exception(s) (see the call stack of `span.prepareForAsync()`), and the `next` won't handle the request?"", 'commenter': 'kezhenxu94'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/handler/TracingHandler.java,"@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x.handler;
+
+import io.undertow.server.ExchangeCompletionListener;
+import io.undertow.server.HttpHandler;
+import io.undertow.server.HttpServerExchange;
+import io.undertow.util.HeaderMap;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.undertow.v2x.Constants;
+
+/**
+ * @author AI
+ * 2019-08-06
+ */
+public class TracingHandler implements HttpHandler {
+    private final String template;
+    private final HttpHandler next;
+
+    public TracingHandler(HttpHandler handler) {
+        this(null, handler);
+    }
+
+
+    public TracingHandler(String template, HttpHandler handler) {
+        this.next = handler;
+        this.template = template;
+    }
+
+    @Override
+    public void handleRequest(HttpServerExchange exchange) throws Exception {
+        final HeaderMap headers = exchange.getRequestHeaders();
+        final ContextCarrier carrier = new ContextCarrier();
+        CarrierItem items = carrier.items();
+        while (items.hasNext()) {
+            items = items.next();
+            items.setHeadValue(headers.getFirst(items.getHeadKey()));
+        }
+        String operationName;
+        if (null == template) {
+            operationName = exchange.getRequestPath();
+        } else {
+            operationName = template;
+        }
+        final AbstractSpan span = ContextManager.createEntrySpan(operationName, carrier);
+        Tags.URL.set(span, exchange.getRequestURL());
+        Tags.HTTP.METHOD.set(span, exchange.getRequestMethod().toString());
+        span.setComponent(ComponentsDefine.UNDERTOW);
+        SpanLayer.asHttp(span);
+        span.prepareForAsync();
+        exchange.addExchangeCompleteListener(new ExchangeCompletionListener() {
+            @Override
+            public void exchangeEvent(HttpServerExchange httpServerExchange, NextListener nextListener) {
+                if (httpServerExchange.getStatusCode() >= 400) {
+                    span.errorOccurred();
+                    Tags.STATUS_CODE.set(span, Integer.toString(httpServerExchange.getStatusCode()));
+                }
+                span.asyncFinish();
+                nextListener.proceed();
+            }
+        });
+        next.handleRequest(exchange);","[{'comment': ""We cannot guarantee that there is no bug in the plugin, and we try our best to avoid effecting the target application, that's why we have so many `try-catch`s in the core of the agent,\r\n\r\nhttps://github.com/apache/skywalking/blob/5e8410834de20254c2bdab2d86cdbfd79d600904/apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/interceptor/enhance/InstMethodsInter.java#L81-L111\r\n\r\nBut there is no protection here and if `span.prepareForAsync();` throws (introduced in #3201 ), the handler chain breaks and the handlers of the target application won't work (`next.handleRequest` won't be called)"", 'commenter': 'kezhenxu94'}, {'comment': ""I think this exception should be a development stage protection, don't need runtime check. Do you agree? Or do you have any scenario could make this undetected in dev stage? "", 'commenter': 'wu-sheng'}, {'comment': ""That's what I'm not sure about,  maybe I overreact on the exception :)"", 'commenter': 'kezhenxu94'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/RootHandlerInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.undertow.v2x;
+
+import io.undertow.Undertow;
+import io.undertow.server.HttpHandler;
+import io.undertow.server.RoutingHandler;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.undertow.v2x.handler.TracingHandler;
+
+import java.lang.reflect.Field;
+import java.lang.reflect.Method;
+
+/**
+ * @author chenpengfei
+ */
+public class RootHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        final String methodName = method.getName();
+        if (""addListener"".equals(methodName)) {","[{'comment': 'If you want separated method, you should separated them in instrumentation. It has much better performance there. This is runtime.', 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/RootHandlerInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.undertow.v2x;
+
+import io.undertow.Undertow;
+import io.undertow.server.HttpHandler;
+import io.undertow.server.RoutingHandler;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.undertow.v2x.handler.TracingHandler;
+
+import java.lang.reflect.Field;
+import java.lang.reflect.Method;
+
+/**
+ * @author chenpengfei
+ */
+public class RootHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        final String methodName = method.getName();
+        if (""addListener"".equals(methodName)) {
+            final Undertow.ListenerBuilder builder = (Undertow.ListenerBuilder) allArguments[0];
+            final Field rootHandlerField = Undertow.ListenerBuilder.class.getDeclaredField(""rootHandler"");
+            rootHandlerField.setAccessible(true);
+            final Object handler = rootHandlerField.get(builder);
+            if (null != handler && !(handler instanceof RoutingHandler)) {
+                rootHandlerField.set(builder, new TracingHandler((HttpHandler) handler));
+            }
+        } else {
+            int handlerIndex = -1;
+            for (int i = 0; i < allArguments.length; i++) {
+                final Object argument = allArguments[i];
+                if (argument instanceof HttpHandler) {
+                    handlerIndex = i;
+                    break;
+                }
+            }
+            if (handlerIndex > -1 && !(allArguments[handlerIndex] instanceof RoutingHandler)) {
+                allArguments[handlerIndex] = new TracingHandler((HttpHandler) allArguments[handlerIndex]);","[{'comment': ""Also, you just need to change arguments value here, so don't need `isOverrideArgs` always be true."", 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/RoutingHandlerInterceptor.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x;
+
+import io.undertow.server.HttpHandler;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.undertow.v2x.handler.TracingHandler;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author AI
+ * 2019-07-25
+ */
+public class RoutingHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        int httpHandlerIndex = -1;
+        for (int index = 0; index < allArguments.length; index++) {
+            Object any = allArguments[index];
+            if (any instanceof HttpHandler) {","[{'comment': 'Could any argument to be `HttpHandler` every time? Instanceof is not a good practice. I saw you are using it in many unnecessary places, and in unlimited conditions.', 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/RoutingHandlerInterceptor.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x;
+
+import io.undertow.server.HttpHandler;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.plugin.undertow.v2x.handler.TracingHandler;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author AI
+ * 2019-07-25
+ */
+public class RoutingHandlerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        int httpHandlerIndex = -1;
+        for (int index = 0; index < allArguments.length; index++) {
+            Object any = allArguments[index];
+            if (any instanceof HttpHandler) {
+                httpHandlerIndex = index;
+                break;
+            }
+        }
+        if (httpHandlerIndex > -1) {","[{'comment': 'You simply could use different matchers and interceptor to avoid this.', 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/handler/TracingHandler.java,"@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x.handler;
+
+import io.undertow.server.ExchangeCompletionListener;
+import io.undertow.server.HttpHandler;
+import io.undertow.server.HttpServerExchange;
+import io.undertow.util.HeaderMap;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.undertow.v2x.Constants;
+
+/**
+ * @author AI
+ * 2019-08-06
+ */
+public class TracingHandler implements HttpHandler {
+    private final String template;
+    private final HttpHandler next;
+
+    public TracingHandler(HttpHandler handler) {
+        this(null, handler);
+    }
+
+
+    public TracingHandler(String template, HttpHandler handler) {
+        this.next = handler;
+        this.template = template;
+    }
+
+    @Override
+    public void handleRequest(HttpServerExchange exchange) throws Exception {
+        final HeaderMap headers = exchange.getRequestHeaders();
+        final ContextCarrier carrier = new ContextCarrier();
+        CarrierItem items = carrier.items();
+        while (items.hasNext()) {
+            items = items.next();
+            items.setHeadValue(headers.getFirst(items.getHeadKey()));
+        }
+        String operationName;
+        if (null == template) {
+            operationName = exchange.getRequestPath();
+        } else {
+            operationName = template;
+        }
+        final AbstractSpan span = ContextManager.createEntrySpan(operationName, carrier);
+        Tags.URL.set(span, exchange.getRequestURL());
+        Tags.HTTP.METHOD.set(span, exchange.getRequestMethod().toString());
+        span.setComponent(ComponentsDefine.UNDERTOW);
+        SpanLayer.asHttp(span);
+        span.prepareForAsync();
+        exchange.addExchangeCompleteListener(new ExchangeCompletionListener() {
+            @Override
+            public void exchangeEvent(HttpServerExchange httpServerExchange, NextListener nextListener) {
+                if (httpServerExchange.getStatusCode() >= 400) {
+                    span.errorOccurred();
+                    Tags.STATUS_CODE.set(span, Integer.toString(httpServerExchange.getStatusCode()));
+                }
+                span.asyncFinish();
+                nextListener.proceed();","[{'comment': 'Is this order right? Should span duration include nextListener? If YES, you need to consider try/finally, because, nextListener could be failure.', 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/define/RoutingHandlerInstrumentation.java,"@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.undertow.v2x.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+
+/**
+ * @author AI
+ * 2019-07-26
+ */
+public class RoutingHandlerInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_METHOD = ""add"";
+    private static final String ENHANCE_CLASS = ""io.undertow.server.RoutingHandler"";
+    private static final String INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.undertow.v2x.RoutingHandlerInterceptor"";
+
+    @Override
+    public ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[0];
+    }
+
+    @Override
+    public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[]{
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(ENHANCE_METHOD)
+                        .and(takesArgumentWithType(0, ""io.undertow.util.HttpString""))
+                        .and(takesArgumentWithType(1, ""java.lang.String""))
+                        .and(takesArguments(io.undertow.server.HttpHandler.class));","[{'comment': 'Should not use `class` type, and you are using full name to avoid the import check, which is there because this is not allowed.', 'commenter': 'wu-sheng'}]"
3173,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/undertow/v2x/define/UndertowRootHandlerInstrumentation.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.undertow.v2x.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * @author chenpengfei
+ * @author AI
+ */
+public class UndertowRootHandlerInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_METHOD = ""setHandler"";
+    private static final String ENHANCE_CLASS = ""io.undertow.Undertow$Builder"";
+    private static final String INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.undertow.v2x.RootHandlerInterceptor"";
+
+    @Override
+    public ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[0];
+    }
+
+    @Override
+    public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+
+        return new InstanceMethodsInterceptPoint[]{
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(ENHANCE_METHOD).and(takesArguments(io.undertow.server.HttpHandler.class));","[{'comment': 'Same issue here.', 'commenter': 'wu-sheng'}]"
3207,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/bytebuddy/AnnotationTypeNameMatch.java,"@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.bytebuddy;
+
+import net.bytebuddy.description.annotation.AnnotationDescription;
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.matcher.CollectionItemMatcher;
+import net.bytebuddy.matcher.DeclaringAnnotationMatcher;
+import net.bytebuddy.matcher.ElementMatcher;
+
+/**
+ * @author AI
+ * 2019-08-15
+ */
+public class AnnotationTypeNameMatch<T extends AnnotationDescription> implements ElementMatcher<T> {","[{'comment': ""Why need this? Doesn't `net.bytebuddy.matcher.ElementMatchers.isAnnotatedWith` meet your requirement?"", 'commenter': 'kezhenxu94'}, {'comment': '`net.bytebuddy.matcher.ElementMatchers.isAnnotatedWith` required `Class` or `TypeDescription`, but `AnnotationTypeNameMatch` can accept a `String`.', 'commenter': 'aiyanbo'}, {'comment': 'Core API requires comments.', 'commenter': 'wu-sheng'}]"
3207,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/bytebuddy/ReturnTypeNameMatch.java,"@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.bytebuddy;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+
+
+/**
+ * @author AI
+ * 2019-08-15
+ */
+public class ReturnTypeNameMatch implements ElementMatcher<MethodDescription> {","[{'comment': 'Same here, there is already `net.bytebuddy.matcher.ElementMatchers#returns(net.bytebuddy.matcher.ElementMatcher<? super net.bytebuddy.description.type.TypeDescription>)`', 'commenter': 'kezhenxu94'}, {'comment': 'In same', 'commenter': 'aiyanbo'}, {'comment': 'Core API requires comments.', 'commenter': 'wu-sheng'}]"
3207,apm-sniffer/apm-agent-core/src/test/java/org/apache/skywalking/apm/agent/core/plugin/bytebuddy/Inject.java,"@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.bytebuddy;
+
+import java.lang.annotation.Documented;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import java.lang.annotation.Target;
+
+/**
+ * @author AI
+ * 2019-08-15
+ */
+@Target({ElementType.METHOD, ElementType.CONSTRUCTOR, ElementType.FIELD})
+@Retention(RetentionPolicy.RUNTIME)
+@Documented
+public @interface Inject {","[{'comment': 'Is it only used in test cases?', 'commenter': 'kezhenxu94'}, {'comment': 'The class `Person` should be move to `test` scope if it is only used in test (and it is I think)', 'commenter': 'kezhenxu94'}, {'comment': ""The `Person.java` is already in `test` scope. It's full path is `skywalking/apm-sniffer/apm-agent-core/src/test/java/org/apache/skywalking/apm/agent/core/plugin/bytebuddy/Person.java` "", 'commenter': 'aiyanbo'}]"
3207,docs/en/setup/service-agent/java-agent/Supported-list.md,"@@ -12,6 +12,7 @@
   * [Spring Webflux](https://docs.spring.io/spring/docs/current/spring-framework-reference/web-reactive.html) 5.x
   * [Undertow](http://undertow.io/)  2.0.0.Final -> 2.0.13.Final
   * [RESTEasy](https://resteasy.github.io/)  3.1.0.Final -> 3.7.0.Final
+  * [Playframework](https://www.playframework.com/) 2.6.x -> 2.7.x","[{'comment': 'Play Framework are two words.', 'commenter': 'wu-sheng'}]"
3207,docs/powered-by.md,"@@ -94,6 +94,7 @@ or providing commercial products including Apache SkyWalking.
 1. Yonghui Superstores Co., Ltd. 永辉超市 http://www.yonghui.com.cn
 1. Youzan.com 杭州有赞科技有限公司 http://www.youzan.com/
 1. zjs.com.cn 北京宅急送快运股份有限公司 http://www.zjs.com.cn/
+1. GrowingIO 北京易数科技有限公司 https://www.growingio.com/","[{'comment': 'Please the list in alphabetic order, please', 'commenter': 'wu-sheng'}]"
3207,apm-sniffer/optional-plugins/play-2.x-plugin/pom.xml,"@@ -0,0 +1,63 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.skywalking</groupId>
+        <artifactId>apm-sdk-plugin</artifactId>
+        <version>6.4.0-SNAPSHOT</version>
+    </parent>
+
+    <artifactId>apm-play-2.x-plugin</artifactId>
+    <name>play-2.x-plugin</name>
+    <packaging>jar</packaging>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <play2.version>2.7.3</play2.version>
+        <java.version>1.8</java.version>
+        <maven.compiler.source>${java.version}</maven.compiler.source>
+        <maven.compiler.target>${java.version}</maven.compiler.target>
+    </properties>","[{'comment': 'I remember that `<compiler.version>1.8</compiler.version>` is enough to compile with 1.8\r\nCan you try and test, this may be a simpler `pom.xml` file..', 'commenter': 'zhaoyuguang'}, {'comment': 'https://maven.apache.org/plugins/maven-compiler-plugin/examples/set-compiler-source-and-target.html', 'commenter': 'aiyanbo'}, {'comment': 'https://github.com/apache/skywalking/blob/cadaab03ae4f01aa983f3f3f157253f17719adc0/apm-sniffer/optional-plugins/lettuce-5.x-plugin/pom.xml#L35\r\nlike this may enough', 'commenter': 'zhaoyuguang'}, {'comment': '@aiyanbo see here 👀', 'commenter': 'zhaoyuguang'}, {'comment': ""@aiyanbo I think, @zhaoyuguang 's point is, one you just need one property, two the following plugin could be removed, because it is already there."", 'commenter': 'wu-sheng'}, {'comment': ""@wu-sheng @zhaoyuguang I'm sorry. I lost your comment."", 'commenter': 'aiyanbo'}]"
3207,apm-sniffer/optional-plugins/play-2.x-plugin/pom.xml,"@@ -0,0 +1,63 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.skywalking</groupId>
+        <artifactId>apm-sdk-plugin</artifactId>","[{'comment': '`<artifactId>optional-plugins</artifactId>`', 'commenter': 'zhaoyuguang'}]"
3207,docs/en/setup/service-agent/java-agent/Supported-list.md,"@@ -81,3 +82,5 @@
  go to [SkyAPM java plugin extension repository](https://github.com/SkyAPM/java-plugin-extensions) to get these.
 
 ²These plugins affect the performance or must be used under some conditions, from experiences. So only released in `/optional-plugins`, copy to `/plugins` in order to make them work.
+
+³JDK 8 Required. So only released in `/optional-plugins`, copy to `/plugins` in order to make them work.","[{'comment': ""We don't need this. Option 2 is clear. I think you still miss `docs/en/setup/service-agent/java-agent/README.md#Optional Plugins`, could you recheck?"", 'commenter': 'wu-sheng'}]"
3207,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -130,4 +130,6 @@
 
     public static final OfficialComponent SPRING_WEBFLUX = new OfficialComponent(67, ""spring-webflux"");
 
+    public static final OfficialComponent PLAY = new OfficialComponent(68, ""Play"");","[{'comment': 'Do you submit Play icon to UI repo? Or do you need one there?', 'commenter': 'wu-sheng'}, {'comment': 'Add icon to `skywalking-ui/public/img/node/`? Why all logos is gray?', 'commenter': 'aiyanbo'}, {'comment': 'It is required to gray. If your could show good in black background, it is good. Solr icon is red.', 'commenter': 'wu-sheng'}, {'comment': 'Check other pull request, and test locally. You could post the screenshot here.', 'commenter': 'wu-sheng'}, {'comment': 'https://github.com/apache/skywalking-rocketbot-ui/pull/142\r\n\r\n![image](https://user-images.githubusercontent.com/1162070/63910033-afafa480-ca57-11e9-8d37-4a9f8e2b22af.png)\r\n', 'commenter': 'aiyanbo'}]"
3207,apm-sniffer/optional-plugins/play-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/play/v2x/TracingFilter.java,"@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.play.v2x;
+
+import akka.stream.Materializer;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import play.api.routing.HandlerDef;
+import play.mvc.Filter;
+import play.mvc.Http;
+import play.mvc.Result;
+import play.routing.Router;
+
+import javax.inject.Inject;
+import javax.inject.Singleton;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.concurrent.CompletionStage;
+import java.util.function.Function;
+import java.util.regex.Pattern;
+
+/**
+ * @author AI
+ * 2019-08-01
+ */
+@Singleton
+public class TracingFilter extends Filter {
+
+    private final Pattern routePattern = Pattern.compile(""\\$(\\w+)\\<\\[\\^/\\]\\+\\>"", Pattern.DOTALL);
+
+    @Inject
+    public TracingFilter(Materializer mat) {
+        super(mat);
+    }
+
+    @Override
+    public CompletionStage<Result> apply(Function<Http.RequestHeader, CompletionStage<Result>> next, Http.RequestHeader request) {
+        HandlerDef def = null;
+        try {
+            def = request.attrs().get(Router.Attrs.HANDLER_DEF);
+        } catch (Throwable t) {
+            // ignore get HandlerDef exception
+        }
+        if (Objects.nonNull(def)) {
+            final ContextCarrier carrier = new ContextCarrier();
+            CarrierItem items = carrier.items();
+            while (items.hasNext()) {
+                items = items.next();
+                Optional<String> value = request.getHeaders().get(items.getHeadKey());
+                if (value.isPresent()) {
+                    items.setHeadValue(value.get());
+                }
+            }
+            final String operationName = routePattern.matcher(def.path()).replaceAll(""{$1}"");
+            final AbstractSpan span = ContextManager.createEntrySpan(operationName, carrier);
+            final String url = request.host() + request.uri();
+            Tags.URL.set(span, url);
+            Tags.HTTP.METHOD.set(span, request.method());
+            span.setComponent(ComponentsDefine.PLAY);
+            SpanLayer.asHttp(span);
+            try {
+                span.prepareForAsync();","[{'comment': 'Why could `#prepareForAsync` trigger exception?', 'commenter': 'wu-sheng'}]"
3207,apm-sniffer/optional-plugins/play-2.x-plugin/pom.xml,"@@ -0,0 +1,63 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.skywalking</groupId>
+        <artifactId>optional-plugins</artifactId>
+        <version>6.4.0-SNAPSHOT</version>
+    </parent>
+
+    <artifactId>apm-play-2.x-plugin</artifactId>
+    <name>play-2.x-plugin</name>
+    <packaging>jar</packaging>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <play2.version>2.7.3</play2.version>
+        <java.version>1.8</java.version>
+        <maven.compiler.source>${java.version}</maven.compiler.source>
+        <maven.compiler.target>${java.version}</maven.compiler.target>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>com.typesafe.play</groupId>
+            <artifactId>play_2.12</artifactId>
+            <version>${play2.version}</version>
+            <scope>provided</scope>
+        </dependency>
+    </dependencies>
+
+    <build>
+        <plugins>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-compiler-plugin</artifactId>","[{'comment': 'This one could be removed.', 'commenter': 'wu-sheng'}, {'comment': 'It is compile failed when we removed `maven-compiler-plugin`. So i removed properties `maven.compiler.source` and `maven.compiler.target`. \r\n\r\nAnd assign java version in `maven-compiler-plugin`', 'commenter': 'aiyanbo'}]"
3225,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/grpc/GRPCServer.java,"@@ -90,12 +93,26 @@ public String serverClassify() {
     @Override
     public void initialize() {
         InetSocketAddress address = new InetSocketAddress(host, port);
-
+        ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue(10000);
+        ExecutorService executor = new ThreadPoolExecutor(500, 500, 60,","[{'comment': 'All these parameters require configurable, and default values should be reasonable, such as calculated from CPU core number. Such as take a look at `MetricsAggregateWorker#L52`\r\n```JAVA\r\nBulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, BulkConsumePool.Creator.recommendMaxSize() * 2, 20);\r\n```', 'commenter': 'wu-sheng'}]"
3225,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/grpc/GRPCServer.java,"@@ -90,12 +93,26 @@ public String serverClassify() {
     @Override
     public void initialize() {
         InetSocketAddress address = new InetSocketAddress(host, port);
-
+        ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue(10000);
+        ExecutorService executor = new ThreadPoolExecutor(500, 500, 60,
+                TimeUnit.SECONDS, blockingQueue, new CustomThreadFactory(""grpcServerPool""), new CustomRejectedExecutionHandler());
         nettyServerBuilder = NettyServerBuilder.forAddress(address);
-        nettyServerBuilder = nettyServerBuilder.maxConcurrentCallsPerConnection(maxConcurrentCallsPerConnection).maxMessageSize(maxMessageSize);
+        nettyServerBuilder = nettyServerBuilder.maxConcurrentCallsPerConnection(maxConcurrentCallsPerConnection).maxMessageSize(maxMessageSize).executor(executor);
         logger.info(""Server started, host {} listening on {}"", host, port);
     }
 
+    static class CustomRejectedExecutionHandler implements RejectedExecutionHandler {
+        private final AtomicInteger rejectNumber = new AtomicInteger(1);
+
+        @Override
+        public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) {
+            if (rejectNumber.getAndIncrement() == 100) {
+                logger.warn(""Grpc server thread pool is full, rejecting the task"");
+                rejectNumber.set(1);","[{'comment': 'If the rejectNumber is just for logging, no need to keep it so accurate. A simple int w/ volatile is enough. `AtomicInteger` causes unnecessary CPU.', 'commenter': 'wu-sheng'}, {'comment': 'good idea', 'commenter': 'yantaowu'}]"
3225,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/grpc/GRPCServer.java,"@@ -90,12 +103,22 @@ public String serverClassify() {
     @Override
     public void initialize() {
         InetSocketAddress address = new InetSocketAddress(host, port);
-
+        ArrayBlockingQueue blockingQueue = new ArrayBlockingQueue(threadPoolQueueSize);","[{'comment': 'Is this queue used by gRPC in default?', 'commenter': 'wu-sheng'}, {'comment': 'GRPC uses SyncronousQueue by defalult.', 'commenter': 'yantaowu'}]"
3240,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -100,6 +100,13 @@
          * after receiving reset command
          */
         public static int COOL_DOWN_THRESHOLD = 10;
+
+        /**
+         * Max wait grpc channel auto connect count for same channel.
+         * If count of check grpc channel status more than this number.
+         * The channel check will call channel.getState(true) to requestConnection.
+         */
+        public static long MAX_WAIT_CHANNEL_AUTO_CONNECT_COUNT = 1;","[{'comment': 'Default should be 10.', 'commenter': 'wu-sheng'}]"
3240,apm-sniffer/config/agent.config,"@@ -46,3 +46,6 @@ logging.file_name=${SW_LOGGING_FILE_NAME:skywalking-api.log}
 
 # Logging level
 logging.level=${SW_LOGGING_LEVEL:DEBUG}
+
+# Max wait grpc channel auto connect count for same channel.
+agent.max_wait_channel_auto_connect_count=${SW_AGENT_MAX_WAIT_CHANNEL_AUTO_CONNECT_COUNT:1}","[{'comment': ""Most users don't need this. Remove it."", 'commenter': 'wu-sheng'}]"
3240,apm-sniffer/config/agent.config,"@@ -45,4 +45,4 @@ collector.backend_service=${SW_AGENT_COLLECTOR_BACKEND_SERVICES:127.0.0.1:11800}
 logging.file_name=${SW_LOGGING_FILE_NAME:skywalking-api.log}
 
 # Logging level
-logging.level=${SW_LOGGING_LEVEL:DEBUG}
+logging.level=${SW_LOGGING_LEVEL:DEBUG","[{'comment': 'Unexpected change ', 'commenter': 'kezhenxu94'}]"
3250,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/WriterFactory.java,"@@ -40,4 +40,8 @@ public static IWriter getLogWriter() {
             return SystemOutWriter.INSTANCE;
         }
     }
+
+    private static boolean useSystemOut() {
+        return ""system.out"".equals(Config.Logging.DIR);","[{'comment': 'This is not a good one. `Config.Logging.Output` should be a better choice, value options are `file` and `console`', 'commenter': 'wu-sheng'}, {'comment': 'OK. Got it. ', 'commenter': 'sN0wpeak'}]"
3250,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/PatternLogger.java,"@@ -0,0 +1,77 @@
+/*
+ * Copyright 2011 the original author or authors.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.skywalking.apm.agent.core.logging.core;
+
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.util.PropertyPlaceholderHelper;
+import org.apache.skywalking.apm.util.StringUtil;
+
+import java.text.SimpleDateFormat;
+import java.util.Date;
+import java.util.Properties;
+
+/**
+ * @author alvin
+ */
+public class PatternLogger extends EasyLogger {","[{'comment': 'Why do we need two? Do you have performance concern? Because I have for the pattern mode.\r\n\r\nOne further question, who will be interested in setting this pattern?', 'commenter': 'wu-sheng'}, {'comment': '1. I think the EasyLogger is a default choice. The default is concat Strings.\r\n```\r\nString format(LogLevel level, String message, Throwable t) {\r\n        return StringUtil.join(\' \', level.name(),\r\n            new SimpleDateFormat(""yyyy-MM-dd HH:mm:ss:SSS"").format(new Date()),\r\n            Thread.currentThread().getName(),\r\n            targetClass,\r\n            "": "",\r\n            message,\r\n            t == null ? """" : format(t)\r\n        );\r\n    }\r\n```\r\nIt has hard to changeing the order. You mentioned pattern means \'{}\'? But how can i change the above the order?\r\nUse `%{level} %{timestamp} %{thread} %{class} : %{msg} %{throwable}` this method to express the format of the log is more clear.\r\n\r\n2. \r\n* If we use system.out to println log. It will be print together with agented Progress. Some log-collector collect log need use same logformat.\r\nFor example, we often collect log use Fluentd in the k8s which collect the stdout of container.  \r\n* More flexible. We can log something which we want.', 'commenter': 'sN0wpeak'}]"
3250,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/PatternLogger.java,"@@ -0,0 +1,77 @@
+/*
+ * Copyright 2011 the original author or authors.
+ *
+ * Licensed under the Apache License, Version 2.0 (the ""License"");
+ * you may not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.skywalking.apm.agent.core.logging.core;
+
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.util.PropertyPlaceholderHelper;
+import org.apache.skywalking.apm.util.StringUtil;
+
+import java.text.SimpleDateFormat;
+import java.util.Date;
+import java.util.Properties;
+
+/**
+ * @author alvin
+ */
+public class PatternLogger extends EasyLogger {
+
+    public static final String DEFAULT_PATTERN = ""%{level} %{timestamp} %{thread} %{class} : %{msg} %{throwable}"";
+
+    private String pattern;
+
+    public PatternLogger(Class targetClass, String pattern) {
+        this(targetClass.getSimpleName(), pattern);
+    }
+
+    public PatternLogger(String targetClass, String pattern) {
+        super(targetClass);
+        this.setPattern(pattern);
+    }
+
+    public String getPattern() {
+        return pattern;
+    }
+
+    public void setPattern(String pattern) {
+        if (StringUtil.isEmpty(pattern)) {
+            pattern = DEFAULT_PATTERN;
+        }
+        this.pattern = pattern;
+    }
+
+    @Override
+    String format(LogLevel level, String message, Throwable t) {
+        Properties props = buildContext(level, message, t);
+        return PropertyPlaceholderHelper.LOGGER.replacePlaceholders(getPattern(), props);
+    }
+
+    private Properties buildContext(LogLevel level, String message, Throwable t) {","[{'comment': 'You should test performance by the benchmark. @kezhenxu94 Do you remember a PR to give an example?', 'commenter': 'wu-sheng'}, {'comment': 'Yes, @mm23504570 please refer to https://github.com/apache/skywalking/pull/2766#issuecomment-496240702 for how to write a benchmark show the performance result ', 'commenter': 'kezhenxu94'}]"
3250,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/WriterFactory.java,"@@ -27,7 +27,7 @@
 
 public class WriterFactory {
     public static IWriter getLogWriter() {
-        if (SnifferConfigInitializer.isInitCompleted() && AgentPackagePath.isPathFound()) {
+        if (SnifferConfigInitializer.isInitCompleted() && AgentPackagePath.isPathFound() && !useConsole()) {","[{'comment': 'Static config, `!useConsole()`, should be first.', 'commenter': 'wu-sheng'}]"
3250,docs/en/setup/service-agent/java-agent/README.md,"@@ -82,7 +82,9 @@ property key | Description | Default |
 `collector.backend_service`|Collector SkyWalking trace receiver service addresses.|`127.0.0.1:11800`|
 `logging.level`|The log level. Default is debug.|`DEBUG`|
 `logging.file_name`|Log file name.|`skywalking-api.log`|
+`logging.output`| Log output. Default is FILE. Use CONSOLE means output to stdout. |`FILE`|
 `logging.dir`|Log files directory. Default is blank string, means, use ""system.out"" to output logs.|`""""`|
+`logging.pattern `|logging format. Default is blank string, means, use EasyLogger who pattern is `%level %timestamp %thread %class : %msg %throwable` |`""""`|","[{'comment': 'Add document about pattern options. Are these(%level %timestamp %thread %class : %msg %throwable) all options? If so, make it clear in the document.', 'commenter': 'wu-sheng'}]"
3250,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -169,6 +170,16 @@
          * The log level. Default is debug.
          */
         public static LogLevel LEVEL = LogLevel.DEBUG;
+
+        /**
+         * The log output. Default is FILE.
+         */
+        public static LogOutput OUTPUT = LogOutput.FILE;
+
+        /**
+         * The log patten. Default is """", means use EasyLogger.
+         */
+        public static String PATTERN = """";","[{'comment': 'Default should be the pattern in the document.', 'commenter': 'wu-sheng'}]"
3250,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/PatternLogger.java,"@@ -1,51 +1,86 @@
 /*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Copyright 2011 the original author or authors.","[{'comment': 'The license is not right. This should be Apache foundation header.', 'commenter': 'wu-sheng'}]"
3250,docs/en/setup/service-agent/java-agent/README.md,"@@ -82,7 +82,9 @@ property key | Description | Default |
 `collector.backend_service`|Collector SkyWalking trace receiver service addresses.|`127.0.0.1:11800`|
 `logging.level`|The log level. Default is debug.|`DEBUG`|
 `logging.file_name`|Log file name.|`skywalking-api.log`|
+`logging.output`| Log output. Default is FILE. Use CONSOLE means output to stdout. |`FILE`|
 `logging.dir`|Log files directory. Default is blank string, means, use ""system.out"" to output logs.|`""""`|
+`logging.pattern `|logging format. Default is blank string, means, use EasyLogger who pattern is `%level %timestamp %thread %class : %msg %throwable` . There are `%level %timestamp %thread %class %msg %throwable %agent_name` converters.  |`""""`|","[{'comment': 'Default is not empty. You have default value in Config class, right?', 'commenter': 'wu-sheng'}, {'comment': 'There is no EasyLogger', 'commenter': 'wu-sheng'}, {'comment': 'We need the explanations of each converter here too.', 'commenter': 'wu-sheng'}]"
3250,apm-sniffer/apm-agent-core/src/test/java/org/apache/skywalking/apm/agent/core/logging/core/PatternLoggerTest.java,"@@ -1,59 +1,67 @@
 /*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
+ * Copyright 2011 the original author or authors.","[{'comment': 'The license header is still not right. @kezhenxu94 Look like our class header check is unavailable to test? Becuase CI passed in this definitely wrong case.', 'commenter': 'wu-sheng'}, {'comment': ""> The license header is still not right. @kezhenxu94 Look like our class header check is unavailable to test? Becuase CI passed in this definitely wrong case.\r\n\r\nI noticed that this morning. It is the `apache-rat` plugin that is responsible to check the license header, but it didn't complain about anything, and I searched around to find that this form of license header is valid in some projects (that are not ASF TLP).\r\n\r\nI'll try to make the check strictly, by using the checkstyle header, which is obviously not working now"", 'commenter': 'kezhenxu94'}, {'comment': 'rat is just checking the Apache acceptable header, so this one is good.\r\n\r\nBut as Apache source codes, I think we need our header style check to make it strictly. Thanks for taking care of this. Expect your PR.', 'commenter': 'wu-sheng'}]"
3250,apm-sniffer/apm-agent-core/src/test/java/org/apache/skywalking/apm/agent/core/logging/core/WriterFactoryTest.java,"@@ -0,0 +1,67 @@
+/*
+ * Copyright 2011 the original author or authors.","[{'comment': 'Same wrong header too.', 'commenter': 'wu-sheng'}]"
3286,docs/en/setup/backend/backend-cluster.md,"@@ -90,4 +90,17 @@ cluster:
     serviceName: ${SW_SERVICE_NAME:""SkyWalking_OAP_Cluster""}
     # Nacos cluster nodes, example: 10.0.0.1:8848,10.0.0.2:8848,10.0.0.3:8848
     hostPort: ${SW_CLUSTER_NACOS_HOST_PORT:localhost:8848}
+```
+
+## Etcd
+Set the **cluster** module's implementor to **etcd** in
+the yml to active.
+
+```yaml
+cluster:","[{'comment': 'If you\'re adding docs of Etcd implementation of cluster plugin, then I think the snippet here is wrong, it\'s for dynamic configuration, I think those configuration for etcd cluster is:\r\n\r\n```yml\r\n  etcd:\r\n    serviceName: ${SW_SERVICE_NAME:""SkyWalking_OAP_Cluster""}\r\n#     etcd cluster nodes, example: 10.0.0.1:2379,10.0.0.2:2379,10.0.0.3:2379\r\n    hostPort: ${SW_CLUSTER_ETCD_HOST_PORT:localhost:2379}\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'sorry, i copied the wrong file. ', 'commenter': 'wayilau'}, {'comment': ""Hi, i've changed this."", 'commenter': 'wayilau'}]"
3292,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/ttl/RecordTTLCalculator.java,"@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.storage.ttl;
+
+import org.apache.skywalking.oap.server.core.DataTTLConfig;
+import org.joda.time.DateTime;
+
+/**
+ * Calculate TTL for record.
+ *
+ * @author wusheng
+ */
+public class RecordTTLCalculator implements TTLCalculator {
+
+    @Override public long timeBefore(DateTime currentTime, DataTTLConfig dataTTLConfig) {
+        return Long.valueOf(currentTime.plusMinutes(0 - dataTTLConfig.getRecordDataTTL()).toString(""yyyyMMddHHmm""));","[{'comment': 'Segment time bucket is the second time format.', 'commenter': 'peng-yongsheng'}, {'comment': 'Fixed, w/ wrong in EsRecordTTLCalculator too, we should use `#plusDays` there, right?', 'commenter': 'wu-sheng'}, {'comment': 'Alarm record time bucket is also the second time format.\r\n\r\nAlarm\r\n```\r\nrecord.setStartTime(message.getStartTime());\r\nrecord.setTimeBucket(TimeBucket.getSecondTimeBucket(message.getStartTime()));\r\n``` \r\n\r\nSegment\r\n```\r\nlong timeBucket = TimeBucket.getSecondTimeBucket(segmentCoreInfo.getStartTime());\r\nsegment.setTimeBucket(timeBucket);\r\n```\r\n\r\nSuggest that, rename the getSecondTimeBucket to getRecordTimeBucket or create an alias name of getRecordTimeBucket, it will make it clear.', 'commenter': 'peng-yongsheng'}, {'comment': '> Fixed, w/ wrong in EsRecordTTLCalculator too, we should use `#plusDays` there, right?\r\n\r\nEn, En.', 'commenter': 'peng-yongsheng'}, {'comment': 'toString(""yyyyMMddHHmm"") is wrong, modify to  toString(""yyyyMMddHHmmss"").', 'commenter': 'peng-yongsheng'}, {'comment': 'Plus minute is for the config item in application.yml. \r\n `recordDataTTL: ${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute`\r\n\r\ntoString(""yyyyMMddHHmmss"") if for the database, the `timeBucket` column in database is second data format.', 'commenter': 'peng-yongsheng'}]"
3308,oap-server/server-receiver-plugin/skywalking-trace-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/trace/gateway/IGatewayService.java,"@@ -0,0 +1,29 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.trace.gateway;
+
+import org.apache.skywalking.oap.server.library.module.Service;
+
+/**
+ * @author kezhenxu94
+ */
+public interface IGatewayService extends Service {","[{'comment': 'Why this is a service? Who would use it? Service is for inter-module.', 'commenter': 'wu-sheng'}, {'comment': ""You could create a class to do all these things, but it is not a module service, actually. receiver usually doesn't include service definition. `ISegmentParserService` service exists because the zipkin receiver is going to use it."", 'commenter': 'wu-sheng'}]"
3308,oap-server/server-receiver-plugin/skywalking-trace-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/trace/module/TraceModule.java,"@@ -32,6 +33,9 @@ public TraceModule() {
     }
 
     @Override public Class[] services() {
-        return new Class[] {ISegmentParserService.class};
+        return new Class[] {
+            ISegmentParserService.class,
+            IGatewayService.class","[{'comment': 'Remove this service please.', 'commenter': 'wu-sheng'}]"
3308,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/ServiceInventory.java,"@@ -187,7 +194,7 @@ public ServiceInventory getClone() {
         if (serviceInventory.getLastUpdateTime() >= this.getLastUpdateTime()) {
             this.nodeType = serviceInventory.getNodeType();
             setProp(serviceInventory.getProp());
-            if (Const.NONE != serviceInventory.getMappingServiceId()) {
+            if (serviceInventory.isForceResetServiceMapping() || Const.NONE != serviceInventory.getMappingServiceId()) {","[{'comment': '`#forceResetServiceMapping` should be combined, otherwise, if some combine merge happens in streaming, rather than memory-db merge, this field lost, as a result, the database would update `mappingServiceId` anymore.', 'commenter': 'wu-sheng'}]"
3308,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/service/IServiceInventoryRegister.java,"@@ -35,5 +35,5 @@
 
     void heartbeat(int serviceId, long heartBeatTime);
 
-    void updateMapping(int serviceId, int mappingServiceId);
+    void updateMapping(int serviceId, int mappingServiceId, boolean force);","[{'comment': 'I would recommend you to provide a `#resetMapping` method. Because in that case, there is no need to provide `#mappingServiceId`. This method only should be called when you want to mappingServiceId back to 0. In other cases, this update works w/o `force==true`.\r\n\r\nThis change seems to misguide the API user, if `force` usually means, update even the value is there(not null/0), but here, your meaning is, mappingServiceId could be set as 0 when the mappingServiceId != 0.', 'commenter': 'wu-sheng'}]"
3308,oap-server/server-receiver-plugin/skywalking-trace-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/trace/provider/parser/listener/service/ServiceMappingSpanListener.java,"@@ -58,14 +71,20 @@ private ServiceMappingSpanListener(ModuleManager moduleManager) {
         if (!spanDecorator.getSpanLayer().equals(SpanLayer.MQ)) {
             if (spanDecorator.getRefsCount() > 0) {
                 for (int i = 0; i < spanDecorator.getRefsCount(); i++) {
-                    int serviceId = serviceInventoryCache.getServiceId(spanDecorator.getRefs(i).getNetworkAddressId());
-                    int mappingServiceId = serviceInventoryCache.get(serviceId).getMappingServiceId();
-                    if (mappingServiceId != segmentCoreInfo.getServiceId()) {
-                        ServiceMapping serviceMapping = new ServiceMapping();
-                        serviceMapping.setServiceId(serviceId);
+                    int networkAddressId = spanDecorator.getRefs(i).getNetworkAddressId();
+                    String address = networkAddressInventoryCache.get(networkAddressId).getName();
+                    int serviceId = serviceInventoryCache.getServiceId(networkAddressId);
+                    ServiceMapping serviceMapping = new ServiceMapping();
+                    serviceMapping.setServiceId(serviceId);
+
+                    if (config.getStaticGatewaysConfig().isAddressConfiguredAsGateway(address)) {
+                        serviceMapping.setMappingServiceId(Const.NONE);
+                        serviceMapping.setForceUpdate(true);
+                    } else {
                         serviceMapping.setMappingServiceId(segmentCoreInfo.getServiceId());
-                        serviceMappings.add(serviceMapping);
+                        serviceMapping.setForceUpdate(false);","[{'comment': 'Keep `serviceMappings` as normal update, and add a list reset mappings for this case.', 'commenter': 'wu-sheng'}]"
3308,oap-server/server-starter/src/main/assembly/gateways.yml,"@@ -0,0 +1,20 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+gateways:
+  - name: proxy0
+    instances:
+      - host: 127.0.0.1 # the host/ip of this gateway instance
+        port: 9099 # the port of this gateway instance, defaults to 80","[{'comment': 'Why does this file include something?', 'commenter': 'wu-sheng'}, {'comment': 'Oops, that must be a mistake 😄 ', 'commenter': 'kezhenxu94'}]"
3308,docs/en/setup/backend/static-gateways.md,"@@ -0,0 +1,22 @@
+# Static Gateways/Proxies","[{'comment': 'I prefer to use `Uninstrumented` to replace static, because gateway is always static :)', 'commenter': 'wu-sheng'}]"
3308,docs/en/setup/backend/static-gateways.md,"@@ -0,0 +1,22 @@
+# Static Gateways/Proxies
+
+The word ""static"" here means that the gateways are not automatically/dynamically registered by SkyWalking agent when they are started,
+but configured statically in `gateways.yml` file or via [Dynamic Configuration](dynamic-config.md). The reason why they can't register","[{'comment': '`The reason of`, not `why`', 'commenter': 'wu-sheng'}, {'comment': ""I remembered that this is not a grammar error, just like `the person who does...`, `the PR that changes...`, `the place where I live...`, `the way how we get here`, if you prefer I'll change to `The reason of that they can't register...`"", 'commenter': 'kezhenxu94'}, {'comment': 'I search for a random webpage, seems that people say like this too https://www.oxfordlearnersdictionaries.com/definition/english/reason_1', 'commenter': 'kezhenxu94'}, {'comment': 'OK. I just feel a little strange, if it is right, keep it.', 'commenter': 'wu-sheng'}]"
3308,docs/en/setup/backend/static-gateways.md,"@@ -0,0 +1,22 @@
+# Static Gateways/Proxies
+
+The word ""static"" here means that the gateways are not automatically/dynamically registered by SkyWalking agent when they are started,
+but configured statically in `gateways.yml` file or via [Dynamic Configuration](dynamic-config.md). The reason why they can't register
+to backend automatically is that there're no suitable agent plugins, for example, there is no agent plugins for Nginx, haproxy, etc.
+So in order to reflect the real topology, we provide a way to configure the gateways/proxies manually.","[{'comment': '`reflect` -> `visualize` ', 'commenter': 'wu-sheng'}]"
3308,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/service/ServiceInventoryRegister.java,"@@ -132,6 +136,19 @@ private ServiceInventoryCache getServiceInventoryCache() {
         }
     }
 
+    @Override public void resetMapping(int serviceId) {","[{'comment': 'You should indicate why we have resetMapping. A short introduction version.', 'commenter': 'wu-sheng'}]"
3308,oap-server/server-receiver-plugin/skywalking-trace-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/trace/provider/StaticGatewaysConfig.java,"@@ -0,0 +1,159 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.trace.provider;
+
+import lombok.Getter;
+import lombok.Setter;
+import lombok.ToString;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.configuration.api.ConfigChangeWatcher;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.library.util.ResourceUtils;
+import org.apache.skywalking.oap.server.receiver.trace.module.TraceModule;
+import org.yaml.snakeyaml.Yaml;
+
+import java.io.FileNotFoundException;
+import java.io.Reader;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Collections;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.atomic.AtomicReference;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+import java.util.stream.StreamSupport;
+
+import static java.util.Objects.isNull;
+
+/**
+ * @author kezhenxu94
+ */
+@Slf4j
+public class StaticGatewaysConfig extends ConfigChangeWatcher {","[{'comment': 'Same name change expected here.', 'commenter': 'wu-sheng'}]"
3308,docs/en/setup/backend/uninstrumented-gateways.md,"@@ -0,0 +1,22 @@
+# Uninstrumented Gateways/Proxies
+
+The word ""static"" here means that the gateways are not automatically/dynamically registered by SkyWalking agent when they are started,","[{'comment': 'You miss `static` here :)', 'commenter': 'wu-sheng'}]"
3350,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/dictionary/NetworkAddressDictionary.java,"@@ -43,6 +43,9 @@
 
     public PossibleFound find(String networkAddress) {
         Integer applicationId = applicationDictionary.get(networkAddress);
+        if (networkAddress == null || (networkAddress.length()) == 0) {","[{'comment': 'Why network address is null when you create exit span?', 'commenter': 'wu-sheng'}]"
3350,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ContextManager.java,"@@ -162,7 +162,9 @@ public static AbstractSpan activeSpan() {
     }
 
     public static void stopSpan() {
-        stopSpan(activeSpan());
+        if (get() != null) {","[{'comment': 'Why call stop when there is not an active span? This should be a plugin bug.', 'commenter': 'wu-sheng'}]"
3367,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -110,6 +110,13 @@
          * Limit the length of the operationName to prevent errors when inserting elasticsearch
          **/
         public static int OPERATION_NAME_THRESHOLD = 500;
+
+        /*
+        * service properties
+        * e.g.
+        *   agent.properties[org]=apache
+        */
+        public static Map<String, String> PROPERTIES = new HashMap<String, String>();","[{'comment': 'The properties should be instance level, according to your latest update. This should be named as `INSTANCE_PROPERTIES`, and documents is required to update.', 'commenter': 'wu-sheng'}, {'comment': 'Also, this config should be next to `INSTANCE_UUID`.', 'commenter': 'wu-sheng'}]"
3367,docs/en/setup/service-agent/java-agent/README.md,"@@ -78,6 +78,7 @@ property key | Description | Default |
 `agent.cool_down_threshold `|How long should the agent wait (in minute) before re-registering to the OAP server after receiving reset command.|`10`|
 `agent.force_reconnection_period `|Force reconnection period of grpc, based on grpc_channel_check_interval.|`1`|
 `agent.operation_name_threshold `|The operationName max length, setting this value > 500 is not recommended.|`500`|
+`agent.properties[key]=value` | Add custom properties. | Not set|","[{'comment': 'The document needs to be more clear about instance level.', 'commenter': 'wu-sheng'}]"
3367,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/ServiceAndEndpointRegisterClient.java,"@@ -58,6 +60,7 @@
 public class ServiceAndEndpointRegisterClient implements BootService, Runnable, GRPCChannelListener {
     private static final ILog logger = LogManager.getLogger(ServiceAndEndpointRegisterClient.class);
     private static String INSTANCE_UUID;
+    private static List<KeyStringValuePair> SERVICE_PROPERTIES;","[{'comment': 'You miss this name. ', 'commenter': 'wu-sheng'}, {'comment': 'aha, thanks to your remind.', 'commenter': 'JaredTan95'}]"
3367,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/MetadataQueryEsDAO.java,"@@ -249,26 +250,32 @@ public Service searchService(String serviceCode) throws IOException {
             String propertiesString = (String)sourceAsMap.get(ServiceInstanceInventory.PROPERTIES);
             if (!Strings.isNullOrEmpty(propertiesString)) {
                 JsonObject properties = GSON.fromJson(propertiesString, JsonObject.class);
-                if (properties.has(LANGUAGE)) {
-                    serviceInstance.setLanguage(LanguageTrans.INSTANCE.value(properties.get(LANGUAGE).getAsString()));
-                } else {
-                    serviceInstance.setLanguage(Language.UNKNOWN);
-                }
+                for (Map.Entry<String, JsonElement> property : properties.entrySet()) {
+                    String key = property.getKey();
+                    String value = property.getValue().getAsString();
+                    if (key.equals(LANGUAGE)) {
+                        serviceInstance.setLanguage(LanguageTrans.INSTANCE.value(value));
+                    } else {
+                        serviceInstance.setLanguage(Language.UNKNOWN);","[{'comment': 'Should not set the language to `Language.UNKNOWN` in the `else` branch **every time** when the `key` is not `LANGUAGE`, because you\'re in the `for` loop, e.g.\r\n\r\n`properties`:\r\n```\r\nLANGUAGE -> ""Java""\r\nwhatever1 -> ""whatever1""\r\nwhatever2 -> ""whatever2""\r\nwhatever3 -> ""whatever3""\r\n```\r\n\r\nafter the `for` loop, the `serviceInstance.getLanguage` is `Language.UNKNOWN`, while expectation is `Java`', 'commenter': 'kezhenxu94'}, {'comment': 'Agree. ', 'commenter': 'wu-sheng'}, {'comment': 'Thank you for review.', 'commenter': 'JaredTan95'}]"
3367,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2MetadataQueryDAO.java,"@@ -280,26 +282,32 @@ public Service searchService(String serviceCode) throws IOException {
                     String propertiesString = resultSet.getString(ServiceInstanceInventory.PROPERTIES);
                     if (!Strings.isNullOrEmpty(propertiesString)) {
                         JsonObject properties = GSON.fromJson(propertiesString, JsonObject.class);
-                        if (properties.has(LANGUAGE)) {
-                            serviceInstance.setLanguage(LanguageTrans.INSTANCE.value(properties.get(LANGUAGE).getAsString()));
-                        } else {
-                            serviceInstance.setLanguage(Language.UNKNOWN);
-                        }
+                        for (Map.Entry<String, JsonElement> property : properties.entrySet()) {
+                            String key = property.getKey();
+                            String value = property.getValue().getAsString();
+                            if (key.equals(LANGUAGE)) {
+                                serviceInstance.setLanguage(LanguageTrans.INSTANCE.value(value));
+                            } else {
+                                serviceInstance.setLanguage(Language.UNKNOWN);","[{'comment': 'Same here', 'commenter': 'kezhenxu94'}]"
3370,docs/en/setup/backend/backend-storage.md,"@@ -54,6 +56,34 @@ storage:
     concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests
 ```
 
+### ElasticSearch 6 With Https SSL Encrypting communications.
+
+example: 
+
+```yaml
+storage:
+  elasticsearch:
+    # nameSpace: ${SW_NAMESPACE:""""}
+    user: ${SW_ES_USER:""""} # User needs to be set when Http Basic authentication is enabled
+    password: ${SW_ES_PASSWORD:""""} # Password to be set when Http Basic authentication is enabled
+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:443}
+    keyStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:""../es_keystore.jks""}
+    keyStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:""dangerous""}","[{'comment': ""seems elasticsearch doesn't support Keystore password according to https://www.elastic.co/guide/en/elasticsearch/reference/6.8/secure-settings.html. But this feature may be added in the future, I agree with your current design, well, just to pick an empty default `password` value would be a better choice though"", 'commenter': 'hanahmily'}, {'comment': 'Why mark this `resolved`?', 'commenter': 'hanahmily'}, {'comment': 'not refresh my page, ignore this.', 'commenter': 'hanahmily'}]"
3370,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -84,30 +95,50 @@
     public static final String TYPE = ""type"";
     private final String clusterNodes;
     private final String protocol;
+    private final String keyStorePath;
+    private final String keyStorePass;
     private final String namespace;
     private final String user;
     private final String password;
     protected RestHighLevelClient client;
 
-    public ElasticSearchClient(String clusterNodes, String protocol, String namespace, String user, String password) {
+    public ElasticSearchClient(String clusterNodes, String protocol, String keyStorePath, String keyStorePass,
+        String namespace, String user, String password) {
         this.clusterNodes = clusterNodes;
         this.protocol = protocol;
         this.namespace = namespace;
         this.user = user;
         this.password = password;
+        this.keyStorePath = keyStorePath;
+        this.keyStorePass = keyStorePass;
     }
 
-    @Override public void connect() throws IOException {
+    @Override
+    public void connect() throws IOException, KeyStoreException, NoSuchAlgorithmException, KeyManagementException, CertificateException {
         List<HttpHost> pairsList = parseClusterNodes(clusterNodes);
         RestClientBuilder builder;
         if (StringUtils.isNotBlank(user) && StringUtils.isNotBlank(password)) {
             final CredentialsProvider credentialsProvider = new BasicCredentialsProvider();
             credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(user, password));
             builder = RestClient.builder(pairsList.toArray(new HttpHost[0]))
                 .setHttpClientConfigCallback(httpClientBuilder -> httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider));
+
+            if (""https"".equals(protocol)) {
+                // more type: https://docs.oracle.com/javase/8/docs/technotes/guides/security/StandardNames.html#KeyStore
+                KeyStore truststore = KeyStore.getInstance(""jks"");
+                try (InputStream is = Files.newInputStream(Paths.get(keyStorePath))) {","[{'comment': 'We should consider a scenario. When the certification is signed by trusted CA such as VeriSign(not self-signed), RestClient should pick up default SslContext instead of a dedicated one. What I mean is the keyStorePath should be empty in that case.', 'commenter': 'hanahmily'}]"
3370,docs/en/setup/backend/backend-storage.md,"@@ -54,6 +56,34 @@ storage:
     concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests
 ```
 
+### ElasticSearch 6 With Https SSL Encrypting communications.
+
+example: 
+
+```yaml
+storage:
+  elasticsearch:
+    # nameSpace: ${SW_NAMESPACE:""""}
+    user: ${SW_ES_USER:""""} # User needs to be set when Http Basic authentication is enabled
+    password: ${SW_ES_PASSWORD:""""} # Password to be set when Http Basic authentication is enabled
+    clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:443}
+    keyStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:""../es_keystore.jks""}","[{'comment': 's/keyStore/trustStore/ ? Since we are client-side, `trustStore` may be a more reasonable name. What do you think about this?', 'commenter': 'hanahmily'}, {'comment': '> @JaredTan95 Look like we need a document update at es storage section.\r\n\r\nYou mean this?', 'commenter': 'JaredTan95'}, {'comment': 'No, I prefer to select `trustStorePath` instead of `keyStorePath`', 'commenter': 'hanahmily'}]"
3370,docs/en/setup/backend/backend-storage.md,"@@ -39,6 +39,8 @@ storage:
     # nameSpace: ${SW_NAMESPACE:""""}
     # user: ${SW_ES_USER:""""} # User needs to be set when Http Basic authentication is enabled
     # password: ${SW_ES_PASSWORD:""""} # Password to be set when Http Basic authentication is enabled
+    #keyStorePath: ${SW_SW_STORAGE_ES_SSL_JKS_PATH:""""}
+    #keyStorePass: ${SW_SW_STORAGE_ES_SSL_JKS_PASS:""""}","[{'comment': 'These two are still using `keyStore*`.', 'commenter': 'wu-sheng'}]"
3370,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -84,30 +95,50 @@
     public static final String TYPE = ""type"";
     private final String clusterNodes;
     private final String protocol;
+    private final String trustStorePath;
+    private final String trustStorePass;
     private final String namespace;
     private final String user;
     private final String password;
     protected RestHighLevelClient client;
 
-    public ElasticSearchClient(String clusterNodes, String protocol, String namespace, String user, String password) {
+    public ElasticSearchClient(String clusterNodes, String protocol, String trustStorePath, String trustStorePass,
+        String namespace, String user, String password) {
         this.clusterNodes = clusterNodes;
         this.protocol = protocol;
         this.namespace = namespace;
         this.user = user;
         this.password = password;
+        this.trustStorePath = trustStorePath;
+        this.trustStorePass = trustStorePass;
     }
 
-    @Override public void connect() throws IOException {
+    @Override
+    public void connect() throws IOException, KeyStoreException, NoSuchAlgorithmException, KeyManagementException, CertificateException {
         List<HttpHost> pairsList = parseClusterNodes(clusterNodes);
         RestClientBuilder builder;
         if (StringUtils.isNotBlank(user) && StringUtils.isNotBlank(password)) {
             final CredentialsProvider credentialsProvider = new BasicCredentialsProvider();
             credentialsProvider.setCredentials(AuthScope.ANY, new UsernamePasswordCredentials(user, password));
             builder = RestClient.builder(pairsList.toArray(new HttpHost[0]))
                 .setHttpClientConfigCallback(httpClientBuilder -> httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider));
+
+            if (""https"".equals(protocol)) {","[{'comment': '`trustStorePaht` may be null in no-self-signed scenario. so we should update this condition.', 'commenter': 'hanahmily'}, {'comment': 'hmmm... what I mean is that, if user picks up default ssl,  lines from 127 ~ 137 should be remove.\r\nFor instance\r\n```java\r\nif (StringUtils.isNotBlank(trustStorePath)) {\r\n   builder = RestClient.builder(pairsList.toArray(new HttpHost[0]))\r\n                    .setHttpClientConfigCallback(httpClientBuilder -> httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider);\r\n} else {\r\n   KeyStore truststore = KeyStore.getInstance(""jks"");\r\n    ....\r\n   builder = RestClient.builder(pairsList.toArray(new HttpHost[0]))\r\n                    .setHttpClientConfigCallback(httpClientBuilder -> httpClientBuilder.setDefaultCredentialsProvider(credentialsProvider).setSSLContext(sslContext));\r\n}\r\n```', 'commenter': 'hanahmily'}, {'comment': ""Thanks for the review. I've updated it."", 'commenter': 'JaredTan95'}]"
3385,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-4.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/v4/define/ControllerForLowVersionInstrumentation.java,"@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.spring.mvc.v4.define;
+
+public class ControllerForLowVersionInstrumentation extends AbstractControllerInstrumentation {
+    public static final String WITNESS_CLASSES_LOW_VERSION = ""org.springframework.web.context.support.ServletContextPropertyPlaceholderConfigurer"";
+
+    public static final String ENHANCE_ANNOTATION = ""org.springframework.stereotype.Controller"";
+
+    @Override
+    protected String[] witnessClasses() {
+        return new String[]{WITHNESS_CLASSES, ""org.springframework.cache.interceptor.DefaultKeyGenerator"", WITNESS_CLASSES_LOW_VERSION};","[{'comment': 'Why `org.springframework.cache.interceptor.DefaultKeyGenerator` exists without class variable? And have `WITNESS_CLASSES_LOW_VERSION` too. Which one is working? ', 'commenter': 'wu-sheng'}, {'comment': '`org.springframework.cache.interceptor.DefaultKeyGenerator` exist in low and high instrumentation definitions, what is the point?', 'commenter': 'wu-sheng'}, {'comment': '`ControllerForLowVersionConstructorInterceptor ` dose not seem to be refered. We need to override `getConstructorsInterceptPoints()` here, right?', 'commenter': 'dmsolr'}]"
3385,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-4.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/v4/define/ControllerInstrumentation.java,"@@ -21,9 +21,17 @@
 
 public class ControllerInstrumentation extends AbstractControllerInstrumentation {
 
+    public static final String WITNESS_CLASSES_HIGH_VERSION = ""org.springframework.http.HttpRange"";
+
     public static final String ENHANCE_ANNOTATION = ""org.springframework.stereotype.Controller"";
 
-    @Override protected String[] getEnhanceAnnotations() {
-        return new String[] {ENHANCE_ANNOTATION};
+    @Override
+    protected String[] getEnhanceAnnotations() {
+        return new String[]{ENHANCE_ANNOTATION};
+    }
+
+    @Override
+    protected String[] witnessClasses() {
+        return new String[]{WITHNESS_CLASSES, ""org.springframework.cache.interceptor.DefaultKeyGenerator"", WITNESS_CLASSES_HIGH_VERSION};","[{'comment': 'Same as above', 'commenter': 'wu-sheng'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/KafkaProducerInterceptor.java,"@@ -41,16 +42,16 @@
 
     @Override
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
-        MethodInterceptResult result) throws Throwable {
+                             MethodInterceptResult result) throws Throwable {
 
         ContextCarrier contextCarrier = new ContextCarrier();
 
-        ProducerRecord record = (ProducerRecord)allArguments[0];
-        String topicName = (String)((EnhancedInstance)record).getSkyWalkingDynamicField();
-
-        AbstractSpan activeSpan = ContextManager.createExitSpan(OPERATE_NAME_PREFIX + topicName + PRODUCER_OPERATE_NAME_SUFFIX, contextCarrier, (String)objInst.getSkyWalkingDynamicField());
+        ProducerRecord record = (ProducerRecord) allArguments[0];
+        String topicName = record.topic();
+        String key = record.key() == null ? null : (String) record.key();
+        AbstractSpan activeSpan = ContextManager.createExitSpan(OPERATE_NAME_PREFIX + topicName + ""/"" + key + PRODUCER_OPERATE_NAME_SUFFIX, contextCarrier, (String) objInst.getSkyWalkingDynamicField());","[{'comment': ""We don't need to add key into OperatorName. Because it will create too many span entry."", 'commenter': 'dmsolr'}, {'comment': 'Yes. Please remove it from the operation name. Operation name is a group, should not relate to business inform.', 'commenter': 'wu-sheng'}, {'comment': ""Ok, I'm going to change that"", 'commenter': 'stalary'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/KafkaConsumerInterceptor.java,"@@ -60,7 +60,7 @@ public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allA
         //
         if (records.size() > 0) {
             ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo)objInst.getSkyWalkingDynamicField();
-            AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX + requiredInfo.getTopics() + CONSUMER_OPERATE_NAME_SUFFIX, null).start(requiredInfo.getStartTime());
+            AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX + requiredInfo.getTopics() + ""/"" + requiredInfo.getGroupId() +  CONSUMER_OPERATE_NAME_SUFFIX, null).start(requiredInfo.getStartTime());","[{'comment': 'I have a little suggest. The OperatorName change to `Kafka/$topic/Consumer/$group.id`. ', 'commenter': 'dmsolr'}, {'comment': '+1', 'commenter': 'wu-sheng'}, {'comment': 'I think the suffix ""Consumer"" can make a clear distinction between Consumer and Producer. How do you feel about that?', 'commenter': 'stalary'}, {'comment': 'I have carefully considered that putting topic and groupId together might cause confusion, so I will listen to your Suggestions and modify the position of groupId.', 'commenter': 'stalary'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/CallbackInterceptor.java,"@@ -16,42 +16,56 @@
  *
  */
 
-package org.apache.skywalking.apm.plugin.kafka.v1;
+package org.apache.skywalking.apm.plugin.kafka;
 
 import java.lang.reflect.Method;
+
+import org.apache.kafka.clients.producer.RecordMetadata;
 import org.apache.skywalking.apm.agent.core.context.ContextManager;
 import org.apache.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
 import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
 
+/**
+ * @author zhang xin, stalary
+ **/
 public class CallbackInterceptor implements InstanceMethodsAroundInterceptor {
+
     @Override
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
-        MethodInterceptResult result) throws Throwable {
-        AbstractSpan abstractSpan = ContextManager.createLocalSpan(""Producer/Callback"");
+                             MethodInterceptResult result) throws Throwable {
+        RecordMetadata metadata = (RecordMetadata) allArguments[0];
+        AbstractSpan activeSpan = ContextManager.createLocalSpan(""Kafka/Producer/Callback"");
+        activeSpan.setComponent(ComponentsDefine.KAFKA_PRODUCER);
+        activeSpan.setLayer(SpanLayer.MQ);","[{'comment': ""Usually, we don't set the layer to local span. Layer is in RPC process."", 'commenter': 'wu-sheng'}, {'comment': 'Sorry, I am not sure about this part at that time, I will modify it', 'commenter': 'stalary'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/resources/skywalking-plugin.def,"@@ -14,7 +14,6 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
-kafka-0.11.x=org.apache.skywalking.apm.plugin.kafka.v1.define.CallbackInstrumentation
-kafka-0.11.x=org.apache.skywalking.apm.plugin.kafka.v1.define.KafkaConsumerInstrumentation
-kafka-0.11.x=org.apache.skywalking.apm.plugin.kafka.v1.define.KafkaProducerInstrumentation
-kafka-0.11.x=org.apache.skywalking.apm.plugin.kafka.v1.define.ProducerRecordInstrumentation","[{'comment': 'Could you tell me why `ProducerRecordInstrumentation` is not required?', 'commenter': 'wu-sheng'}, {'comment': 'From the existing codes, look like it set `dynamicField`, is this not required?', 'commenter': 'wu-sheng'}, {'comment': 'TopicName can be obtained directly from ProducerRecord', 'commenter': 'stalary'}, {'comment': 'Got it, thanks.', 'commenter': 'wu-sheng'}, {'comment': ""We can get the `topic` by `arguments` directly, so we don't need to enhance this. "", 'commenter': 'dmsolr'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/KafkaConsumerInterceptor.java,"@@ -60,7 +60,7 @@ public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allA
         //
         if (records.size() > 0) {
             ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo)objInst.getSkyWalkingDynamicField();
-            AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX + requiredInfo.getTopics() + ""/"" + requiredInfo.getGroupId() +  CONSUMER_OPERATE_NAME_SUFFIX, null).start(requiredInfo.getStartTime());
+            AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX + requiredInfo.getTopics() + CONSUMER_OPERATE_NAME + ""/"" + requiredInfo.getGroupId(), null).start(requiredInfo.getStartTime());","[{'comment': '`/` append into `CONSUMER_OPERATE_NAME` to reduce a string operator.', 'commenter': 'dmsolr'}, {'comment': 'Okay', 'commenter': 'stalary'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/define/KafkaProducerInstrumentation.java,"@@ -46,22 +46,35 @@
     public static final String INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.kafka.KafkaProducerInterceptor"";
     public static final String ENHANCE_CLASS = ""org.apache.kafka.clients.producer.KafkaProducer"";
     public static final String ENHANCE_METHOD = ""doSend"";
-    public static final String CONSTRUCTOR_INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.kafka.ProducerConstructorInterceptor"";
-    public static final String CONSTRUCTOR_INTERCEPTOR_FLAG = ""org.apache.kafka.clients.producer.ProducerConfig"";
-    public static final String METHOD_FLAG = ""org.apache.kafka.clients.producer.Callback"";
+    public static final String CONSTRUCTOR_INTERCEPTOR_CLASS1 = ""org.apache.skywalking.apm.plugin.kafka.ProducerConstructorInterceptor"";","[{'comment': ""I'm not sure if I can divide it into two instrumentations to do it through witness class. Because it dose not look graceful enough. Coud you try it?"", 'commenter': 'dmsolr'}, {'comment': 'I think two instrumentation definitions are better and recommended.', 'commenter': 'wu-sheng'}, {'comment': ""At first I tried to do this by witness classe, but I didn't find any different classes in 2.1.0 and 2.1.1..."", 'commenter': 'stalary'}, {'comment': 'Or I can use two instrumentation definitions enhance two constructors, only hitting one at a time', 'commenter': 'stalary'}, {'comment': '@stalary I think @dmsolr is just asking for separating codes into two classes. Not about the instrumentation logic. Make sense?', 'commenter': 'wu-sheng'}, {'comment': 'Seems to separate code I need to implement two duplicate getInstanceMethodsInterceptPoints to enhance doSend.', 'commenter': 'stalary'}, {'comment': 'Yes, to enhance CONSTRUCTOR_INTERCEPTOR_CLASS and CONSTRUCTOR_INTERCEPTOR_CLASS2.', 'commenter': 'dmsolr'}, {'comment': ""I see. I'll do it"", 'commenter': 'stalary'}, {'comment': '@dmsolr I have modified it. Please check it again', 'commenter': 'stalary'}, {'comment': 'That looks good.', 'commenter': 'dmsolr'}]"
3390,apm-sniffer/apm-sdk-plugin/kafka-plugin/src/main/java/org/apache/skywalking/apm/plugin/kafka/ProducerConstructorMapInterceptor.java,"@@ -16,14 +16,21 @@
  *
  */
 
-package org.apache.skywalking.apm.plugin.kafka.v1;
+package org.apache.skywalking.apm.plugin.kafka;
 
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
 import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.util.StringUtil;
 
-public class ProducerRecordConstructorInterceptor implements InstanceConstructorInterceptor {
-    @Override public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
-        String topic = (String)allArguments[0];
-        objInst.setSkyWalkingDynamicField(topic);
+import java.util.Map;
+
+/**
+ * @author stalary
+ */
+public class ProducerConstructorMapInterceptor implements InstanceConstructorInterceptor {
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        Map<String, Object> config = (Map<String, Object>) allArguments[0];
+        objInst.setSkyWalkingDynamicField(StringUtil.join(';', ((String) config.get(""bootstrap.servers"")).split("","")));","[{'comment': 'The `bootstrap.servers` is just for tagging, right? Do we really need to spilt it with `,` and join them with another delimiter `;` ? What about just setting them **AS IS**', 'commenter': 'kezhenxu94'}, {'comment': 'Here is a compatibility operation. Before 2.1.0 you get a List and then a string, for uniform display', 'commenter': 'stalary'}, {'comment': ""I didn't change the `;` used in previous versions for consistency"", 'commenter': 'stalary'}, {'comment': ""What I meant is the bootstrap.servers is separated by `,` in Kafka, here we can just keep it as is, and when you get a `List`, join them with `,` instead of `;`. Anyway, it's trivial and it's ok to me, thanks"", 'commenter': 'kezhenxu94'}]"
3410,apm-sniffer/apm-sdk-plugin/cassandra-java-driver-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/cassandra/java/driver/v3/ClusterConstructorWithStateListenerArgInterceptor.java,"@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.cassandra.java.driver.v3;
+
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+/**
+ * @author stone.wlg
+ */
+public class ClusterConstructorWithStateListenerArgInterceptor implements InstanceConstructorInterceptor {
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) {
+        List<InetSocketAddress> inetSocketAddresses = (List<InetSocketAddress>) allArguments[1];
+        StringBuilder hosts = new StringBuilder();
+        for (InetSocketAddress inetSocketAddress : inetSocketAddresses) {
+            hosts.append(inetSocketAddress.getHostName() + "":"" + inetSocketAddress.getPort() + "","");","[{'comment': 'It does not matter, but I suggest to do like that.\r\n`hosts.append(inetSocketAddress.getHostName()).append("":"").append(inetSocketAddress.getPort()).append("","");`', 'commenter': 'dmsolr'}, {'comment': 'ok, thanks.', 'commenter': 'stone-wlg'}]"
3410,apm-sniffer/apm-sdk-plugin/cassandra-java-driver-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/cassandra/java/driver/v3/SessionManagerExecuteAndExecuteAsyncWithStatementArgInterceptor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.cassandra.java.driver.v3;
+
+import com.datastax.driver.core.BoundStatement;
+import com.datastax.driver.core.Statement;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author stone.wlg
+ */
+public class SessionManagerExecuteAndExecuteAsyncWithStatementArgInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public final void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                                   Class<?>[] argumentsTypes,
+                                   MethodInterceptResult result) throws Throwable {
+        ConnectionInfo connectionInfo = (ConnectionInfo) objInst.getSkyWalkingDynamicField();
+        if (connectionInfo == null) {
+            return;
+        }
+
+        Statement statement = (Statement) allArguments[0];
+        String remotePeer = statement.getHost() == null ? connectionInfo.getContactPoints() : (statement.getHost().getSocketAddress().getHostName() + "":"" + statement.getHost().getSocketAddress().getPort());
+        String keyspace = statement.getKeyspace() == null ? connectionInfo.getKeyspace() : statement.getKeyspace();
+        String query = statement.toString();
+        if (statement instanceof BoundStatement) {
+            query = ((BoundStatement) statement).preparedStatement().getQueryString();
+        }
+
+        AbstractSpan span = ContextManager.createExitSpan(Constants.CASSANDRA_OP_PREFIX + method.getName(), remotePeer);
+        span.setComponent(ComponentsDefine.CASSANDRA_JAVA_DRIVER);
+        Tags.DB_TYPE.set(span, Constants.CASSANDRA_DB_TYPE);
+        Tags.DB_INSTANCE.set(span, keyspace);
+        Tags.DB_STATEMENT.set(span, query);
+        SpanLayer.asDB(span);
+    }
+
+    @Override
+    public final Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                                    Class<?>[] argumentsTypes,
+                                    Object ret) throws Throwable {
+        ConnectionInfo connectionInfo = (ConnectionInfo) objInst.getSkyWalkingDynamicField();
+        if (connectionInfo != null) {
+            ContextManager.stopSpan();
+        }
+        return ret;
+    }
+
+    @Override
+    public final void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+                                            Class<?>[] argumentsTypes, Throwable t) {
+        AbstractSpan span = ContextManager.activeSpan();
+        span.errorOccurred();
+        span.log(t);","[{'comment': 'We have to make sure the span is exist and created by this interceptor. So we have to double-check in same conditions(`if (connectionInfo != null) {`). \r\nAnd to check `ContenxtManager.isActive()` to make it is be safely. It is the same in others interceptor.', 'commenter': 'dmsolr'}, {'comment': 'Got it, thanks', 'commenter': 'stone-wlg'}]"
3410,apm-sniffer/apm-sdk-plugin/cassandra-java-driver-3.x-plugin/pom.xml,"@@ -0,0 +1,46 @@
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-sdk-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.4.0-SNAPSHOT</version>","[{'comment': 'We shipped 6.4.0, please change version to 6.5.0-snapshot.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'stone-wlg'}]"
3410,apm-sniffer/apm-sdk-plugin/cassandra-java-driver-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/cassandra/java/driver/v3/define/SessionManagerInstrumentation.java,"@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * @author stone.wlg
+ */
+public class SessionManagerInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_CLASS = ""com.datastax.driver.core.SessionManager"";
+    private static final String METHODS_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.SessionManagerExecuteAndExecuteAsyncWithStatementArgInterceptor"";
+
+    @Override
+    protected ClassMatch enhanceClass() {
+        return byName(ENHANCE_CLASS);
+    }
+
+    @Override
+    public ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return null;
+    }
+
+    @Override
+    public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[]{
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(""execute"").and(takesArgumentWithType(0, ""com.datastax.driver.core.Statement""))
+                        .or(named(""executeAsync"").and(takesArgumentWithType(0, ""com.datastax.driver.core.Statement"")));","[{'comment': '`executeAsync` calls `execute` at the bottom, so you should be able to only intercept `execute` (minor issue)\r\n', 'commenter': 'kezhenxu94'}, {'comment': 'i think the key is the **_or_** method. Does it intercept both execute and executeAsync methods, or only intercept execute methods. right ?\r\nbut my test result is both. ', 'commenter': 'stone-wlg'}]"
3410,apm-sniffer/apm-sdk-plugin/cassandra-java-driver-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/cassandra/java/driver/v3/define/SessionManagerInstrumentation.java,"@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * @author stone.wlg
+ */
+public class SessionManagerInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_CLASS = ""com.datastax.driver.core.SessionManager"";
+    private static final String METHODS_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.SessionManagerExecuteAndExecuteAsyncWithStatementArgInterceptor"";
+
+    @Override
+    protected ClassMatch enhanceClass() {
+        return byName(ENHANCE_CLASS);
+    }
+
+    @Override
+    public ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return null;
+    }
+
+    @Override
+    public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[]{
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(""execute"").and(takesArgumentWithType(0, ""com.datastax.driver.core.Statement""))","[{'comment': '`execute` takes `com.datastax.driver.core.Statement` as the second parameter/argument, `void execute(final RequestHandler.Callback callback, final Statement statement)`, so I think it should be\r\n\r\n```suggestion\r\n                    return named(""execute"").and(takesArgumentWithType(1, ""com.datastax.driver.core.Statement""))\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'Sorry, where did you find this code?\r\nThis is what i found in the driver.\r\npublic interface Session extends Closeable {\r\n    ...\r\n    ResultSet execute(String var1);\r\n    ResultSet execute(String var1, Object... var2);\r\n    ResultSet execute(String var1, Map<String, Object> var2);\r\n    ResultSet execute(Statement var1);\r\n    ResultSetFuture executeAsync(String var1);\r\n    ResultSetFuture executeAsync(String var1, Object... var2);\r\n    ResultSetFuture executeAsync(String var1, Map<String, Object> var2);\r\n    ResultSetFuture executeAsync(Statement var1);\r\n    ...\r\n}', 'commenter': 'stone-wlg'}, {'comment': '> Sorry, where did you find this code?\r\n> This is what i found in the driver.\r\n> public interface Session extends Closeable {\r\n> ...\r\n> ResultSet execute(String var1);\r\n> ResultSet execute(String var1, Object... var2);\r\n> ResultSet execute(String var1, Map<String, Object> var2);\r\n> ResultSet execute(Statement var1);\r\n> ResultSetFuture executeAsync(String var1);\r\n> ResultSetFuture executeAsync(String var1, Object... var2);\r\n> ResultSetFuture executeAsync(String var1, Map<String, Object> var2);\r\n> ResultSetFuture executeAsync(Statement var1);\r\n> ...\r\n> }\r\n\r\nWhy do you refer to interface `Session`? Here you\'re intercepting the class `SessionManager`, line 37 and line 42, did I miss anything?\r\n\r\n```java\r\n    private static final String ENHANCE_CLASS = ""com.datastax.driver.core.SessionManager"";\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'oh, i got it. void execute(final RequestHandler.Callback callback, final Statement statement) this method is a internal method in SessionManager. it not for user call. i intercept SessionManager absolutely. SessionManager extends AbstractSession implements Session, actually user will get Session from Cluster.', 'commenter': 'stone-wlg'}, {'comment': ""> SessionManager extends AbstractSession implements Session\r\n\r\nThat's what I missed, thanks for pointing out"", 'commenter': 'kezhenxu94'}]"
3410,apm-sniffer/apm-sdk-plugin/cassandra-java-driver-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/cassandra/java/driver/v3/define/ClusterInstrumentation.java,"@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * @author stone.wlg
+ */
+public class ClusterInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_CLASS = ""com.datastax.driver.core.Cluster"";
+    private static final String CONSTRUCTOR_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.ClusterConstructorWithStateListenerArgInterceptor"";
+    private static final String METHODS_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.cassandra.java.driver.v3.ClusterConnectInterceptor"";
+
+    @Override
+    protected ClassMatch enhanceClass() {
+        return byName(ENHANCE_CLASS);
+    }
+
+    @Override
+    public ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[]{
+            new ConstructorInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                    return takesArguments(4);
+                }
+
+                @Override
+                public String getConstructorInterceptor() {
+                    return CONSTRUCTOR_INTERCEPT_CLASS;
+                }
+            }
+        };
+    }
+
+    @Override
+    public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+        return new InstanceMethodsInterceptPoint[]{
+            new InstanceMethodsInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getMethodsMatcher() {
+                    return named(""connect"");","[{'comment': 'Here is just another similar issue like what I mentioned here: https://github.com/apache/skywalking/pull/3330#pullrequestreview-282051569 , there are methods like `com.datastax.driver.core.Cluster#connectAsync()` and `com.datastax.driver.core.Cluster#connectAsync(java.lang.String)` that are asynchronous, users may call these methods instead of `connect`, please consider this :)', 'commenter': 'kezhenxu94'}, {'comment': ""Let's consider connect first. at here, i just collect keyspace name for database tag as default value and it maybe have or not, it is optional, actually database name should be in statement, let's make it simple at first."", 'commenter': 'stone-wlg'}]"
3410,docs/en/setup/service-agent/java-agent/Supported-list.md,"@@ -56,6 +56,8 @@
     * [transport-client](https://github.com/elastic/elasticsearch/tree/master/client/transport) 5.2.x-5.6.x
   * [Solr](https://github.com/apache/lucene-solr/)
     * [SolrJ](https://github.com/apache/lucene-solr/tree/master/solr/solrj) 7.x
+  * [Cassandra](https://github.com/apache/cassandra) 3.x
+    * [cassandra-java-driver](https://github.com/datastax/java-driver) 3.7.2","[{'comment': ""One nit, we should list all you tested version, don't need to leave 3.7.2 due to test issue."", 'commenter': 'wu-sheng'}, {'comment': 'Ok, done', 'commenter': 'stone-wlg'}]"
3475,apm-sniffer/apm-agent-core/src/test/java/org/apache/skywalking/apm/agent/core/logging/core/FileWriterTest.java,"@@ -50,6 +54,27 @@ public void testWriteFile() throws InterruptedException {
         Thread.sleep(10000L);
     }
 
+    @Test
+    public void testDeleteWhenRollover() throws InterruptedException {","[{'comment': '@kezhenxu94 Last time your told me, file OPs in CI are dangerous, which could trigger CI unstable, right?', 'commenter': 'wu-sheng'}, {'comment': '@wuguangkuo This test case could be run concurrency because of multiple CI tasks. I believe this could break/fail randomly. I thin if you want to test file delete, you need a UUID in log file name.', 'commenter': 'wu-sheng'}, {'comment': '> @wuguangkuo This test case could be run concurrency because of multiple CI tasks. I believe this could break/fail randomly. I thin if you want to test file delete, you need a UUID in log file name.\r\n\r\nI had add UUID string as part of log dir to avoid concurrent problem', 'commenter': 'wuguangkuo'}]"
3475,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/FileWriter.java,"@@ -134,6 +136,41 @@ public Object call() throws Exception {
                     return null;
                 }
             });
+
+            if (Config.Logging.MAX_HISTORY_FILES > 0) {","[{'comment': 'deletes expired logs when agent launch just only? ', 'commenter': 'dmsolr'}, {'comment': 'no, this will be execute every time when log file rollover happen', 'commenter': 'wuguangkuo'}, {'comment': 'i see. Thanks for your comment.', 'commenter': 'dmsolr'}]"
3475,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/logging/core/FileWriter.java,"@@ -134,6 +136,41 @@ public Object call() throws Exception {
                     return null;
                 }
             });
+
+            if (Config.Logging.MAX_HISTORY_FILES > 0) {
+                deleteExpiredFiles();
+            }
+        }
+    }
+
+    private String[] getHistoryFilePath() {
+        File path = new File(Config.Logging.DIR);
+        String[] pathArr = path.list(new FilenameFilter() {
+            @Override
+            public boolean accept(File dir, String name) {
+                return filenamePattern.matcher(name).matches();
+            }
+        });
+
+        if (pathArr != null) {
+            Arrays.sort(pathArr, new Comparator<String>() {","[{'comment': 'I have a little suggestion. we could move Line 156-161 to Line-170.', 'commenter': 'dmsolr'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarConsumerInterceptor.java,"@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.api.Message;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PulsarConsumerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Pulsar/"";
+    public static final String CONSUMER_OPERATE_NAME = ""/Consumer/"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+        requiredInfo.setStartTime(System.currentTimeMillis());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                              Object ret) throws Throwable {
+        if (allArguments.length > 0) {
+            Message msg = (Message) allArguments[0];
+            if (null != msg) {
+                ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+                AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX +
+                        requiredInfo.getTopic() + CONSUMER_OPERATE_NAME + requiredInfo.getSubscriptionName(), null)
+                        .start(requiredInfo.getStartTime());
+                activeSpan.setComponent(ComponentsDefine.PULSAR_CONSUMER);
+                SpanLayer.asMQ(activeSpan);
+                Tags.MQ_BROKER.set(activeSpan, requiredInfo.getServiceUrl());
+                Tags.MQ_TOPIC.set(activeSpan, requiredInfo.getTopic());
+                ContextCarrier contextCarrier = new ContextCarrier();
+                CarrierItem next = contextCarrier.items();
+                while (next.hasNext()) {
+                    next = next.next();
+                    next.setHeadValue(msg.getProperty(next.getHeadKey()));
+                }
+                ContextManager.extract(contextCarrier);
+                ContextManager.stopSpan();
+            }
+        }
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+                                      Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);","[{'comment': 'I notice that Span starts after the method, so we will meet NPE when an exception happens before the Span created.', 'commenter': 'dmsolr'}, {'comment': ""I think we should move create active span logic to the beforeMethod, by the way, shall we need to catch the IllegalStateException here, because if no active span here will throw the IllegalStateException and i can't find a public method to check activeSpanStack is or not empty."", 'commenter': 'codelipenghui'}, {'comment': 'I think you dose not get my points.\r\n\r\nIn usually, We need not catch the `IllegalStateException` and need not check the size of the stack. But we have to make sure that the started and stopped of Span must present in pairs in an interceptor. In other word, which starts a Span must stop it.\r\n', 'commenter': 'dmsolr'}, {'comment': 'Usually, We suggest doing like below.\r\n```\r\nif (ContextManager.isActive()) {\r\n    ContextManager.activeSpan().errorOccurred().log(t);\r\n}\r\n```\r\nThe key point, we have to recheck by the same conditions as a span start when we wanna stop the span.', 'commenter': 'dmsolr'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarProducerInterceptor.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.impl.MessageImpl;
+import org.apache.pulsar.common.api.proto.PulsarApi;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PulsarProducerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Pulsar/"";
+    public static final String PRODUCER_OPERATE_NAME_SUFFIX = ""/Producer"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        ProducerEnhanceRequiredInfo requiredInfo = (ProducerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+        ContextCarrier contextCarrier = new ContextCarrier();
+        String topicName = requiredInfo.getTopic();
+        AbstractSpan activeSpan = ContextManager.createExitSpan(OPERATE_NAME_PREFIX + topicName +
+                PRODUCER_OPERATE_NAME_SUFFIX, contextCarrier, requiredInfo.getServiceUrl());
+        Tags.MQ_BROKER.set(activeSpan, requiredInfo.getServiceUrl());
+        Tags.MQ_TOPIC.set(activeSpan, topicName);
+        SpanLayer.asMQ(activeSpan);
+        activeSpan.setComponent(ComponentsDefine.PULSAR_PRODUCER);
+        CarrierItem next = contextCarrier.items();
+        MessageImpl msg = (MessageImpl) allArguments[0];
+        while (next.hasNext()) {
+            next = next.next();
+            msg.getMessageBuilder().addProperties(PulsarApi.KeyValue.newBuilder()
+                    .setKey(next.getHeadKey())
+                    .setValue(next.getHeadValue()));
+        }
+        EnhancedInstance callbackInstance = (EnhancedInstance) allArguments[1];
+        if (callbackInstance != null) {
+            ContextSnapshot snapshot = ContextManager.capture();
+            if (null != snapshot) {
+                SendCallbackEnhanceRequiredInfo callbackRequiredInfo = new SendCallbackEnhanceRequiredInfo();
+                callbackRequiredInfo.setTopic(topicName);
+                callbackRequiredInfo.setContextSnapshot(snapshot);
+                callbackInstance.setSkyWalkingDynamicField(callbackRequiredInfo);
+            }
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                              Object ret) throws Throwable {
+        ContextManager.stopSpan();","[{'comment': 'I think we need to ensure SPAN has been created will be better.', 'commenter': 'dmsolr'}, {'comment': 'As mentioned above, to catch the IllegalStateException or is their any method to check the span is created', 'commenter': 'codelipenghui'}, {'comment': 'I think if logically you could generate the span created in Pulsar plugin, it is OK to just stop span directly.\r\n\r\nBecause even we do `isActive` check, you could just check the span created by other plugins.', 'commenter': 'wu-sheng'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/SendCallbackInterceptor.java,"@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class SendCallbackInterceptor implements InstanceMethodsAroundInterceptor {
+
+    private static final String OPERATION_NAME = ""Pulsar/Producer/Callback"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        SendCallbackEnhanceRequiredInfo requiredInfo = (SendCallbackEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+        if (null != requiredInfo.getContextSnapshot()) {
+            AbstractSpan activeSpan = ContextManager.createLocalSpan(OPERATION_NAME);","[{'comment': ""I'm not familiar with Pulsar. In my experience, the LocalSpan can not always refer to ExitSpan, or it will miss directly sometimes."", 'commenter': 'dmsolr'}, {'comment': 'If the ExitSpan is closed and LocalSpan is still working, it may happen.', 'commenter': 'dmsolr'}, {'comment': ""In pulsar, i think the span of send callback is always a LocalSpan because in the exit span can guarantee that the callback is complete or complete with exception.\r\n\r\nHere is the source of pulsar producer: https://github.com/apache/pulsar/blob/master/pulsar-client/src/main/java/org/apache/pulsar/client/impl/ProducerImpl.java#L294\r\n\r\nSo, If I don't get it wrong, the SendCallback should create a LocalSpan. If there are any mistakes, please point them out."", 'commenter': 'codelipenghui'}, {'comment': 'I got it. But I am thinking of another thing. In a scenario, `SendCallBack.sendComplete` is block till its parent span closed. At this moment, we call the `ContextManager.continued(requiredInfo.getContextSnapshot())` maybe throw an exception. \r\nMaybe we can use [Asyn API](https://github.com/apache/skywalking/blob/master/docs/en/guides/Java-Plugin-Development-Guide.md#advanced-apis).(I am not sure.)', 'commenter': 'dmsolr'}, {'comment': 'I am missing the context here. Could you show me the thread workflow for your concern?', 'commenter': 'wu-sheng'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/pom.xml,"@@ -0,0 +1,54 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-sdk-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>6.5.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-pulsar-plugin</artifactId>
+    <build>
+        <plugins>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-compiler-plugin</artifactId>
+                <configuration>
+                    <source>8</source>
+                    <target>8</target>","[{'comment': 'Do you need JDK8 for plugin? If so, this has to be placed in optional plugin.', 'commenter': 'wu-sheng'}, {'comment': 'Yes, pulsar-client requires JDK1.8, i will move the pulsar plugin to optional plugin', 'commenter': 'codelipenghui'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/ConsumerConstructorInterceptor.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.impl.PulsarClientImpl;
+import org.apache.pulsar.client.impl.conf.ConsumerConfigurationData;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+
+public class ConsumerConstructorInterceptor implements InstanceConstructorInterceptor {","[{'comment': 'Comments please, with all other classes/methods.', 'commenter': 'wu-sheng'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarConsumerInterceptor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.api.Message;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PulsarConsumerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Pulsar/"";
+    public static final String CONSUMER_OPERATE_NAME = ""/Consumer/"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+        requiredInfo.setStartTime(System.currentTimeMillis());
+        AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX +
+                requiredInfo.getTopic() + CONSUMER_OPERATE_NAME + requiredInfo.getSubscriptionName(), null)
+                .start(requiredInfo.getStartTime());
+        activeSpan.setComponent(ComponentsDefine.PULSAR_CONSUMER);
+        SpanLayer.asMQ(activeSpan);
+        Tags.MQ_BROKER.set(activeSpan, requiredInfo.getServiceUrl());
+        Tags.MQ_TOPIC.set(activeSpan, requiredInfo.getTopic());
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                              Object ret) throws Throwable {
+        if (allArguments.length > 0) {
+            Message msg = (Message) allArguments[0];
+            if (null != msg) {
+                ContextCarrier contextCarrier = new ContextCarrier();
+                CarrierItem next = contextCarrier.items();
+                while (next.hasNext()) {
+                    next = next.next();
+                    next.setHeadValue(msg.getProperty(next.getHeadKey()));
+                }
+                ContextManager.extract(contextCarrier);","[{'comment': 'Why extract in `afterMethod` rather than when creating span?', 'commenter': 'wu-sheng'}, {'comment': 'Move it to beforeMethod', 'commenter': 'codelipenghui'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/define/AbstractPulsarInstrumentation.java,"@@ -0,0 +1,25 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar.define;
+
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+
+public abstract class AbstractPulsarInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {","[{'comment': 'What is an abstract instrumentation for?', 'commenter': 'wu-sheng'}, {'comment': 'Will remove it.', 'commenter': 'codelipenghui'}]"
3476,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -133,7 +133,12 @@
     public static final OfficialComponent PLAY = new OfficialComponent(68, ""Play"");
 
     public static final OfficialComponent CASSANDRA_JAVA_DRIVER = new OfficialComponent(69, ""cassandra-java-driver"");
-
+  
     public static final OfficialComponent LIGHT_4J = new OfficialComponent(71, ""Light4J"");
 
+    public static final OfficialComponent PULSAR = new OfficialComponent(72, ""Pulsar"");","[{'comment': 'Who will use this?', 'commenter': 'wu-sheng'}, {'comment': 'Will remove it.', 'commenter': 'codelipenghui'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarConsumerInterceptor.java,"@@ -0,0 +1,94 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.api.Message;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * Interceptor for pulsar consumer enhanced instance
+ *
+ * Here is the intercept process steps:
+ *
+ * <pre>
+ *  1. Get the @{@link ConsumerEnhanceRequiredInfo} and record the service url, topic name and subscription name
+ *  2. Create the entry span when call <code>messageProcessed</code> method
+ *  3. Extract all the <code>Trace Context</code> when call <code>messageProcessed</code> method
+ *  4. Stop the entry span when <code>messageProcessed</code> method finished.
+ * </pre>
+ *
+ * @author penghui
+ */
+public class PulsarConsumerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Pulsar/"";
+    public static final String CONSUMER_OPERATE_NAME = ""/Consumer/"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        if (allArguments.length > 0 && allArguments[0] != null) {
+            ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+            requiredInfo.setStartTime(System.currentTimeMillis());
+            AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX +
+                    requiredInfo.getTopic() + CONSUMER_OPERATE_NAME + requiredInfo.getSubscriptionName(), null)
+                    .start(requiredInfo.getStartTime());","[{'comment': 'You are putting \r\n> requiredInfo.setStartTime(System.currentTimeMillis());\r\n\r\nand \r\n> .start(requiredInfo.getStartTime());\r\n\r\nIn the same method section, the point is? Is `ConsumerEnhanceRequiredInfo#StartTime` really required?', 'commenter': 'wu-sheng'}, {'comment': 'startTime can remove from `ConsumerEnhanceRequiredInfo`, i moved the section from `afterMethod` to `beforeMethod` but forgot to remove the startTime.', 'commenter': 'codelipenghui'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarProducerInterceptor.java,"@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.api.Message;
+import org.apache.pulsar.client.impl.MessageImpl;
+import org.apache.pulsar.common.api.proto.PulsarApi;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * Interceptor for pulsar producer enhanced instance.
+ *
+ * Here is the intercept process steps:
+ *
+ * <pre>
+ *  1. Get the {@link ProducerEnhanceRequiredInfo} and record the service url, topic name
+ *  2. Create the exit span when the producer invoke <code>sendAsync</code> method
+ *  3. Inject the context to {@link Message#getProperties()}
+ *  4. Create {@link SendCallbackEnhanceRequiredInfo} with <code>ContextManager.capture()</code> and set the
+ *     callback enhanced instance skywalking dynamic field to the created required info.
+ *  5. Stop the exit span when <code>sendAsync</code> method finished.
+ * </pre>
+ *
+ * @author penghui
+ */
+public class PulsarProducerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Pulsar/"";
+    public static final String PRODUCER_OPERATE_NAME_SUFFIX = ""/Producer"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        if (allArguments.length > 0 && allArguments[0] != null) {
+            ProducerEnhanceRequiredInfo requiredInfo = (ProducerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+            ContextCarrier contextCarrier = new ContextCarrier();
+            String topicName = requiredInfo.getTopic();
+            AbstractSpan activeSpan = ContextManager.createExitSpan(OPERATE_NAME_PREFIX + topicName +
+                    PRODUCER_OPERATE_NAME_SUFFIX, contextCarrier, requiredInfo.getServiceUrl());
+            Tags.MQ_BROKER.set(activeSpan, requiredInfo.getServiceUrl());
+            Tags.MQ_TOPIC.set(activeSpan, topicName);
+            SpanLayer.asMQ(activeSpan);
+            activeSpan.setComponent(ComponentsDefine.PULSAR_PRODUCER);
+            CarrierItem next = contextCarrier.items();
+            MessageImpl msg = (MessageImpl) allArguments[0];
+            while (next.hasNext()) {
+                next = next.next();
+                msg.getMessageBuilder().addProperties(PulsarApi.KeyValue.newBuilder()
+                        .setKey(next.getHeadKey())
+                        .setValue(next.getHeadValue()));
+            }
+            if (allArguments.length > 1) {
+                EnhancedInstance callbackInstance = (EnhancedInstance) allArguments[1];
+                if (callbackInstance != null) {
+                    ContextSnapshot snapshot = ContextManager.capture();
+                    if (null != snapshot) {
+                        SendCallbackEnhanceRequiredInfo callbackRequiredInfo = new SendCallbackEnhanceRequiredInfo();
+                        callbackRequiredInfo.setTopic(topicName);
+                        callbackRequiredInfo.setContextSnapshot(snapshot);
+                        callbackInstance.setSkyWalkingDynamicField(callbackRequiredInfo);
+                    }
+                }
+            }
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                              Object ret) throws Throwable {
+        if (allArguments.length > 0 && allArguments[0] != null) {","[{'comment': ""I noticed there is plenty of `if (allArguments.length > 0 && allArguments[0] != null)`. Why do we need this? If we don't want to intercept any arg method, you could use the explicit method arg list in instrumentation definition."", 'commenter': 'wu-sheng'}, {'comment': 'will update the instance method matcher', 'commenter': 'codelipenghui'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarConsumerInterceptor.java,"@@ -54,12 +54,11 @@
     @Override
     public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
                              MethodInterceptResult result) throws Throwable {
-        if (allArguments.length > 0 && allArguments[0] != null) {
+        if (allArguments[0] != null) {
             ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
-            requiredInfo.setStartTime(System.currentTimeMillis());
             AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX +
                     requiredInfo.getTopic() + CONSUMER_OPERATE_NAME + requiredInfo.getSubscriptionName(), null)
-                    .start(requiredInfo.getStartTime());
+                    .start(System.currentTimeMillis());","[{'comment': '`#createEntrySpan` has set start time automatically, you could find it in source does.', 'commenter': 'wu-sheng'}, {'comment': 'Yes, AbstractTracingSpan.start() is already set the startTime', 'commenter': 'codelipenghui'}]"
3476,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -133,7 +133,10 @@
     public static final OfficialComponent PLAY = new OfficialComponent(68, ""Play"");
 
     public static final OfficialComponent CASSANDRA_JAVA_DRIVER = new OfficialComponent(69, ""cassandra-java-driver"");
-
+  
     public static final OfficialComponent LIGHT_4J = new OfficialComponent(71, ""Light4J"");
 
+    public static final OfficialComponent PULSAR_PRODUCER = new OfficialComponent(73, ""pulsar-producer"");","[{'comment': 'Is No.72 reserved for others?', 'commenter': 'dmsolr'}, {'comment': 'Yes. Definition of pulsar server.', 'commenter': 'wu-sheng'}]"
3476,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarConsumerInterceptor.java,"@@ -0,0 +1,92 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.api.Message;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * Interceptor for pulsar consumer enhanced instance
+ *
+ * Here is the intercept process steps:
+ *
+ * <pre>
+ *  1. Get the @{@link ConsumerEnhanceRequiredInfo} and record the service url, topic name and subscription name
+ *  2. Create the entry span when call <code>messageProcessed</code> method
+ *  3. Extract all the <code>Trace Context</code> when call <code>messageProcessed</code> method
+ *  4. Stop the entry span when <code>messageProcessed</code> method finished.
+ * </pre>
+ *
+ * @author penghui
+ */
+public class PulsarConsumerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String OPERATE_NAME_PREFIX = ""Pulsar/"";
+    public static final String CONSUMER_OPERATE_NAME = ""/Consumer/"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        if (allArguments[0] != null) {
+            ConsumerEnhanceRequiredInfo requiredInfo = (ConsumerEnhanceRequiredInfo) objInst.getSkyWalkingDynamicField();
+            AbstractSpan activeSpan = ContextManager.createEntrySpan(OPERATE_NAME_PREFIX +","[{'comment': 'This is quite OK. But I think below better.\r\n```\r\nContextCarrier contextCarrier = new ContextCarrier();\r\nCarrierItem next = contextCarrier.items();\r\n        while (next.hasNext()) {\r\n    next = next.next();\r\n    next.setHeadValue(request.getHeader(next.getHeadKey()));\r\n}\r\n\r\nspan = ContextManager.createEntrySpan(“/span/operation/name”, contextCarrier);\r\n```', 'commenter': 'dmsolr'}]"
3538,apm-sniffer/optional-plugins/optional-spring-plugins/optional-spring-cloud/gateway-2.1.x-plugin/pom.xml,"@@ -34,6 +34,7 @@
 
 <properties>
     <spring-cloud-starter-gateway.version>2.1.1.RELEASE</spring-cloud-starter-gateway.version>
+    <compiler.version>1.8</compiler.version>","[{'comment': 'Are you using jdk8 style api? Why do you change this?', 'commenter': 'wu-sheng'}, {'comment': 'yes, i use Mono.doFinally()', 'commenter': 'xiaoy00'}]"
3561,pom.xml,"@@ -550,6 +550,17 @@
                             <exclude>org/apache/skywalking/oap/server/exporter/grpc/*.class</exclude>
                             <exclude>org/apache/skywalking/oap/server/configuration/service/*.class</exclude>
                             <exclude>grpc/health/v1/*.class</exclude>
+
+                            <exclude>org/apache/skywalking/apm/toolkit/**/*Activation.class</exclude>
+                            <exclude>org/apache/skywalking/apm/plugin/**/*Instrumentation.class</exclude>
+                            <exclude>org/apache/skywalking/apm/plugin/**/*Instrumentation$*.class</exclude>","[{'comment': 'Agent plugin instrumentation definition classes', 'commenter': 'kezhenxu94'}]"
3561,pom.xml,"@@ -550,6 +550,17 @@
                             <exclude>org/apache/skywalking/oap/server/exporter/grpc/*.class</exclude>
                             <exclude>org/apache/skywalking/oap/server/configuration/service/*.class</exclude>
                             <exclude>grpc/health/v1/*.class</exclude>
+
+                            <exclude>org/apache/skywalking/apm/toolkit/**/*Activation.class</exclude>
+                            <exclude>org/apache/skywalking/apm/plugin/**/*Instrumentation.class</exclude>
+                            <exclude>org/apache/skywalking/apm/plugin/**/*Instrumentation$*.class</exclude>
+
+                            <exclude>com/google/api/**/*.class</exclude>
+                            <exclude>io/envoyproxy//**/*.class</exclude>
+                            <exclude>io/istio/**/*.class</exclude>
+                            <exclude>io/prometheus/**/*.class</exclude>
+                            <exclude>io/jaegertracing/**/*.class</exclude>
+                            <exclude>com/lyft/**/*.class</exclude>","[{'comment': 'Receiver proto generated classes', 'commenter': 'kezhenxu94'}]"
3570,oap-server/server-core/src/test/java/org/apache/skywalking/oap/server/core/alarm/AlarmRecordTest.java,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.core.alarm;
+
+import org.apache.skywalking.oap.server.core.Const;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * @author jsbxyyx
+ */
+public class AlarmRecordTest {
+
+    @Test
+    public void idVerify() throws Exception {
+        AlarmRecord alarmRecord = new AlarmRecord();
+        String id = alarmRecord.id();
+        String id1 = alarmRecord.getTimeBucket() + Const.ID_SPLIT
+                + alarmRecord.getScope() + Const.ID_SPLIT
+                + alarmRecord.getId0() + Const.ID_SPLIT
+                + alarmRecord.getId1();
+        Assert.assertEquals(id1, id);
+    }
+
+    @Test
+    public void builderData2MapVerify() throws Exception {
+        AlarmRecord.Builder builder = new AlarmRecord.Builder();
+        Map<String, Object> map = builder.data2Map(new AlarmRecord());
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.SCOPE));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.NAME));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.ID0));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.ID1));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.ALARM_MESSAGE));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.START_TIME));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.TIME_BUCKET));
+    }
+
+    @Test
+    public void builderNPEMap2DataVerify() throws Exception {
+        AlarmRecord.Builder builder = new AlarmRecord.Builder();
+
+        try {
+            builder.map2Data(null);
+        } catch (NullPointerException e) {
+            Assert.assertFalse(false);
+        }","[{'comment': '```java\r\n        try {\r\n            builder.map2Data(null);\r\n            Assert.fail(""Should throw"");\r\n        } catch (NullPointerException e) {\r\n        }\r\n```', 'commenter': 'kezhenxu94'}]"
3570,oap-server/server-core/src/test/java/org/apache/skywalking/oap/server/core/alarm/AlarmRecordTest.java,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.core.alarm;
+
+import org.apache.skywalking.oap.server.core.Const;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ * @author jsbxyyx
+ */
+public class AlarmRecordTest {
+
+    @Test
+    public void idVerify() throws Exception {
+        AlarmRecord alarmRecord = new AlarmRecord();
+        String id = alarmRecord.id();
+        String id1 = alarmRecord.getTimeBucket() + Const.ID_SPLIT
+                + alarmRecord.getScope() + Const.ID_SPLIT
+                + alarmRecord.getId0() + Const.ID_SPLIT
+                + alarmRecord.getId1();
+        Assert.assertEquals(id1, id);
+    }
+
+    @Test
+    public void builderData2MapVerify() throws Exception {
+        AlarmRecord.Builder builder = new AlarmRecord.Builder();
+        Map<String, Object> map = builder.data2Map(new AlarmRecord());
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.SCOPE));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.NAME));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.ID0));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.ID1));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.ALARM_MESSAGE));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.START_TIME));
+        Assert.assertEquals(true, map.containsKey(AlarmRecord.TIME_BUCKET));
+    }
+
+    @Test
+    public void builderNPEMap2DataVerify() throws Exception {
+        AlarmRecord.Builder builder = new AlarmRecord.Builder();
+
+        try {
+            builder.map2Data(null);
+        } catch (NullPointerException e) {
+            Assert.assertFalse(false);
+        }
+
+        Map<String, Object> dbMap = new HashMap<>();
+        try {
+            builder.map2Data(dbMap);
+        } catch (NullPointerException e) {
+            Assert.assertFalse(false);","[{'comment': '```suggestion\r\n            Assert.fail(""Should never happen"");\r\n```', 'commenter': 'kezhenxu94'}]"
3570,oap-server/server-core/src/test/java/org/apache/skywalking/oap/server/core/alarm/AlarmModuleTest.java,"@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.core.alarm;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * @author jsbxyyx
+ */
+public class AlarmModuleTest {
+
+    @Test
+    public void verifyName() throws Exception {
+        AlarmModule alarmModule = new AlarmModule();
+        String name = alarmModule.name();
+        Assert.assertEquals(AlarmModule.NAME, name);
+    }","[{'comment': ""I don't think this is necessary"", 'commenter': 'kezhenxu94'}]"
3614,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -263,7 +263,7 @@
              * If set to true, the parameters of the sql (typically {@link java.sql.PreparedStatement}) would be
              * collected.
              */
-            public static boolean TRACE_SQL_PARAMETERS = false;","[{'comment': ""Let's keep it off by default."", 'commenter': 'JaredTan95'}, {'comment': 'add postgresql config in config file?', 'commenter': 'Unknown'}]"
3618,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -273,6 +273,22 @@
             public static int SQL_PARAMETERS_MAX_LENGTH = 512;
         }
 
+        public static class PostgreSQL {
+            /**
+             * If set to true, the parameters of the sql (typically {@link java.sql.PreparedStatement}) would be
+             * collected.
+             */
+            public static boolean TRACE_SQL_PARAMETERS = true;","[{'comment': 'Default value should be `false` due to possible performance issue', 'commenter': 'kezhenxu94'}, {'comment': 'How much impact on performance？', 'commenter': 'Unknown'}]"
3618,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/PSSetterDefinitionOfJDBCInstrumentation.java,"@@ -52,6 +52,13 @@ public PSSetterDefinitionOfJDBCInstrumentation(boolean ignorable) {
             }
         }
 
+        if (Config.Plugin.PostgreSQL.TRACE_SQL_PARAMETERS) {
+            final Set<String> setters = ignorable ? PS_IGNORABLE_SETTERS : PS_SETTERS;
+            for (String setter : setters) {
+                matcher = matcher.or(named(setter));
+            }
+        }
+","[{'comment': 'Simply collapse this to line 48\r\n\r\n```java\r\n        if (Config.Plugin.MySQL.TRACE_SQL_PARAMETERS || Config.Plugin.PostgreSQL.TRACE_SQL_PARAMETERS) {\r\n            final Set<String> setters = ignorable ? PS_IGNORABLE_SETTERS : PS_SETTERS;\r\n            for (String setter : setters) {\r\n                matcher = matcher.or(named(setter));\r\n             }\r\n         }\r\n```', 'commenter': 'kezhenxu94'}]"
3618,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/define/StatementEnhanceInfos.java,"@@ -73,6 +73,22 @@ public void setParameter(int index, final Object parameter) {
         parameters[index] = parameter;
     }
 
+    public String getFullSql() {
+        StringBuilder resultSql = new StringBuilder();
+        int index = 0;
+        int startPos = 0;
+        int findPos = 0;
+        while ((findPos = sql.indexOf(""?"", startPos)) > 0) {
+            resultSql.append(sql.substring(startPos, findPos));
+            resultSql.append(""'"");
+            resultSql.append(parameters[index++]);","[{'comment': ""It's unsafe to parse the SQL using `?`, are there possibilities when the sql includes `?` itself in the value, not a parameter placeholder?\r\n\r\n`select * from news_table where author=? and title like '%?'`, I know it's a little tricky, just to remind the risk here"", 'commenter': 'kezhenxu94'}, {'comment': 'My point is not to try to parse the SQL, store the parameters in another tag', 'commenter': 'kezhenxu94'}, {'comment': ""Parsing SQL is the next generation after ShardingShpere ( @tristaZero and  @terrymanu ) provides the real SQL Parser.  We don't do this by ourselves."", 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng @kezhenxu94 ACK，i will store the parameters in another tag.', 'commenter': 'Unknown'}]"
3619,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -154,7 +159,7 @@ private void printRemoteClientList() {
     }
 
     public List<RemoteClient> getRemoteClient() {
-        return usingClients;
+        return ImmutableList.copyOf(usingClients);","[{'comment': 'This is heavy op. UsingClient should be immutable list itself.', 'commenter': 'wu-sheng'}, {'comment': 'i got it, will change it', 'commenter': 'yanickxia'}]"
3619,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -181,29 +186,27 @@ private void switchCurrentClients() {
      *
      * @param remoteInstances Remote instance collection by query cluster config.
      */
-    private synchronized void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
-        getFreeClients().clear();
+    private void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
+        final Map<Address, RemoteClientAction> closeRemoteClient = this.usingClients.stream()
+                .collect(Collectors.toMap(RemoteClient::getAddress, client -> new RemoteClientAction(client, Action.Close)));
 
-        Map<Address, RemoteClient> remoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> remoteClients.put(client.getAddress(), client));
+        final Map<Address, RemoteClientAction> createRemoteClient = remoteInstances.stream()
+                .collect(Collectors.toMap(RemoteInstance::getAddress, remote -> new RemoteClientAction(null, Action.Create)));
 
-        Map<Address, Action> tempRemoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> tempRemoteClients.put(client.getAddress(), Action.Close));
+        final Set<Address> unChangeAddresses = Sets.intersection(closeRemoteClient.keySet(), createRemoteClient.entrySet());
 
-        remoteInstances.forEach(remoteInstance -> {
-            if (tempRemoteClients.containsKey(remoteInstance.getAddress())) {
-                tempRemoteClients.put(remoteInstance.getAddress(), Action.Leave);
-            } else {
-                tempRemoteClients.put(remoteInstance.getAddress(), Action.Create);
-            }
-        });
+        unChangeAddresses.stream()
+                .filter(closeRemoteClient::containsKey)
+                .forEach(unChangeAddress -> closeRemoteClient.get(unChangeAddress).setAction(Action.Unchanged));
 
-        tempRemoteClients.forEach((address, action) -> {
-            switch (action) {
-                case Leave:
-                    if (remoteClients.containsKey(address)) {
-                        getFreeClients().add(remoteClients.get(address));
-                    }
+        unChangeAddresses.forEach(createRemoteClient::remove);
+        closeRemoteClient.putAll(createRemoteClient);
+
+        getFreeClients().clear(); //clean free client list, for build a new list","[{'comment': 'If you still use clear, it is not safe. Still could get a chance to have list ref, than cleared by here. Right?', 'commenter': 'wu-sheng'}, {'comment': ""I hope we don't use switch OP, because seems unnecessary, as here, no one really close connection. So, we just need a local varible to prepare the list, make it sorted and immutable, than using as usingClient. \r\n\r\nMake sense? Do I miss anything?"", 'commenter': 'wu-sheng'}, {'comment': 'The key point is, clear and copyOf are not atomic operations. You need to understand that.', 'commenter': 'dmsolr'}, {'comment': '@dmsolr @wu-sheng `clear` or `copyOf` unnecessary atomic operation, in fact, the only refresh thread invoke this function, the raw code has a smart tips, has clientA & ClientB two linkedList, `getFreeClient()` will got a not use linked list, so you can do everything on this `free  linked list` ...\r\nbut that code not easy to understand, if use a temp linked list, the code will be more clearness. ', 'commenter': 'yanickxia'}, {'comment': 'i try a simple way to solve it.. wait a min', 'commenter': 'yanickxia'}]"
3619,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -181,53 +166,49 @@ private void switchCurrentClients() {
      *
      * @param remoteInstances Remote instance collection by query cluster config.
      */
-    private synchronized void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
-        getFreeClients().clear();
+    private void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
+        final Map<Address, RemoteClientAction> closeRemoteClient = this.usingClients.stream()","[{'comment': ""`closeRemoteClient` renamed to `remoteClientCollection`. As in your codes, you didn't just save closed client in it."", 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'yanickxia'}]"
3619,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -181,53 +166,49 @@ private void switchCurrentClients() {
      *
      * @param remoteInstances Remote instance collection by query cluster config.
      */
-    private synchronized void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
-        getFreeClients().clear();
+    private void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
+        final Map<Address, RemoteClientAction> closeRemoteClient = this.usingClients.stream()
+                .collect(Collectors.toMap(RemoteClient::getAddress, client -> new RemoteClientAction(client, Action.Close)));
 
-        Map<Address, RemoteClient> remoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> remoteClients.put(client.getAddress(), client));
+        final Map<Address, RemoteClientAction> createRemoteClient = remoteInstances.stream()","[{'comment': '`createRemoteClient` -> `latestRemoteClients`', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'yanickxia'}]"
3619,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -181,53 +166,49 @@ private void switchCurrentClients() {
      *
      * @param remoteInstances Remote instance collection by query cluster config.
      */
-    private synchronized void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
-        getFreeClients().clear();
+    private void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
+        final Map<Address, RemoteClientAction> closeRemoteClient = this.usingClients.stream()
+                .collect(Collectors.toMap(RemoteClient::getAddress, client -> new RemoteClientAction(client, Action.Close)));
 
-        Map<Address, RemoteClient> remoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> remoteClients.put(client.getAddress(), client));
+        final Map<Address, RemoteClientAction> createRemoteClient = remoteInstances.stream()
+                .collect(Collectors.toMap(RemoteInstance::getAddress, remote -> new RemoteClientAction(null, Action.Create)));
 
-        Map<Address, Action> tempRemoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> tempRemoteClients.put(client.getAddress(), Action.Close));
+        final Set<Address> unChangeAddresses = Sets.intersection(closeRemoteClient.keySet(), createRemoteClient.keySet());","[{'comment': 'This is good name.', 'commenter': 'wu-sheng'}, {'comment': 'thanks', 'commenter': 'yanickxia'}]"
3619,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -181,53 +166,49 @@ private void switchCurrentClients() {
      *
      * @param remoteInstances Remote instance collection by query cluster config.
      */
-    private synchronized void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
-        getFreeClients().clear();
+    private void reBuildRemoteClients(List<RemoteInstance> remoteInstances) {
+        final Map<Address, RemoteClientAction> closeRemoteClient = this.usingClients.stream()
+                .collect(Collectors.toMap(RemoteClient::getAddress, client -> new RemoteClientAction(client, Action.Close)));
 
-        Map<Address, RemoteClient> remoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> remoteClients.put(client.getAddress(), client));
+        final Map<Address, RemoteClientAction> createRemoteClient = remoteInstances.stream()
+                .collect(Collectors.toMap(RemoteInstance::getAddress, remote -> new RemoteClientAction(null, Action.Create)));
 
-        Map<Address, Action> tempRemoteClients = new HashMap<>();
-        getRemoteClient().forEach(client -> tempRemoteClients.put(client.getAddress(), Action.Close));
+        final Set<Address> unChangeAddresses = Sets.intersection(closeRemoteClient.keySet(), createRemoteClient.keySet());
 
-        remoteInstances.forEach(remoteInstance -> {
-            if (tempRemoteClients.containsKey(remoteInstance.getAddress())) {
-                tempRemoteClients.put(remoteInstance.getAddress(), Action.Leave);
-            } else {
-                tempRemoteClients.put(remoteInstance.getAddress(), Action.Create);
-            }
-        });
+        unChangeAddresses.stream()
+                .filter(closeRemoteClient::containsKey)
+                .forEach(unChangeAddress -> closeRemoteClient.get(unChangeAddress).setAction(Action.Unchanged));
 
-        tempRemoteClients.forEach((address, action) -> {
-            switch (action) {
-                case Leave:
-                    if (remoteClients.containsKey(address)) {
-                        getFreeClients().add(remoteClients.get(address));
-                    }
+        unChangeAddresses.forEach(createRemoteClient::remove);","[{'comment': 'Add a comment here to indicate that, make the `latestRemoteClients` including the new clients only.', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'yanickxia'}]"
3633,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-1.x-plugin/readme.md,"@@ -0,0 +1,4 @@
+undertow 1.x 插件
+拷贝skywalking 6.0.0 的undertow-2.x-plugin 插件
+
+在skywalking 6.5.0-SNAPSHOT版本 undertow 1.4.27版本测试通过","[{'comment': 'English Please.', 'commenter': 'JaredTan95'}, {'comment': 'ok，already edited', 'commenter': 'langyan1022'}]"
3633,apm-sniffer/apm-sdk-plugin/undertow-plugins/undertow-1.x-plugin/readme.md,"@@ -0,0 +1,21 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+
+### undertow 1.x plugin
+Copy the undertow-2.x-plugin plugin from skywalking 6.0.0
+
+Passed the test in skywalking 6.5.0-SNAPSHOT version and undertow 1.4.27 version","[{'comment': 'This document is strange, why do we need this? If we accept a plugin for new version, you need to change the existing one. And this plugin must pass the tests for multiple versions.\r\n\r\nRemove this file, please. And submit another pr to move undertow plugin test into this repo. \r\nLast step, make the existing old plugin passed 1.x versions. Notice, onr version is not enough.', 'commenter': 'wu-sheng'}]"
3640,apm-sniffer/apm-sdk-plugin/netty-socketio-plugin/src/main/java/org/apache/skywalking/apm/plugin/netty/socketio/NettySocketIOOnEventInterceptor.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.netty.socketio;
+
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author MrPro
+ */
+public class NettySocketIOOnEventInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        String eventName = (String) allArguments[1];
+
+        // no place to get context carrier
+        ContextCarrier contextCarrier = new ContextCarrier();","[{'comment': 'Could we discuss why there is no place to get context? If no, then trace always breaks here. \r\nI saw you have entry and exit spans both. So, these two should match. Otherwise, there is no distributed tracing here, what is point of providing this plugin?', 'commenter': 'wu-sheng'}, {'comment': ""Could we discuss why there is no place to get context?\r\nCause It's always works on cross-language. like browser client use [SocketIO](https://socket.io/) send message/event to server using javascript, or server push message/event to client.\r\n\r\nWhat is point of providing this plugin?\r\nOur company using socketIO for a while, we don't know server handle client request is correct, so we want to monitor on it. It's help us positioning many issue.\r\nIf don't need this plugin, I can close it."", 'commenter': 'mrproliu'}, {'comment': 'Need or not, I am not sure. I am trying tl understand your scenarios. I have concerns of your topo, likr I said when you creating exit span.', 'commenter': 'wu-sheng'}]"
3640,apm-sniffer/apm-sdk-plugin/netty-socketio-plugin/src/main/java/org/apache/skywalking/apm/plugin/netty/socketio/NettySocketIOSendInterceptor.java,"@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.netty.socketio;
+
+import com.corundumstudio.socketio.protocol.Packet;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author MrPro
+ */
+public class NettySocketIOSendInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+        NettySocketIOClientInfo clientInfo = (NettySocketIOClientInfo) objInst.getSkyWalkingDynamicField();
+        Packet packet = (Packet) allArguments[0];
+
+        AbstractSpan span = ContextManager.createExitSpan(""SocketIO/"" + packet.getName() + ""/send"", clientInfo.getClientAddress());","[{'comment': ""My point is, if it don't propagate context, then, it is limited feature. Especially, you are creating exit span based on client IPs, then do you try what happens, id these IP are from Internet? thousands of nodes are created in the topology map. Is that what you need?"", 'commenter': 'wu-sheng'}, {'comment': ""I think what you said is right. The exit span IPs is from Internet, and It will create a lot of nodes and topology, that's not what we need. Maybe I should delete the exit span create?"", 'commenter': 'mrproliu'}, {'comment': 'Agree. at least from the span you created, nothing special.', 'commenter': 'wu-sheng'}, {'comment': 'ok, deleted.', 'commenter': 'mrproliu'}]"
3640,apm-sniffer/apm-sdk-plugin/netty-socketio-plugin/src/test/java/org/apache/skywalking/apm/plugin/netty/socketio/NettySocketIOTest.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.netty.socketio;
+
+import com.corundumstudio.socketio.SocketIOClient;
+import com.corundumstudio.socketio.handler.ClientHead;
+import com.corundumstudio.socketio.namespace.Namespace;
+import com.corundumstudio.socketio.protocol.Packet;
+import com.corundumstudio.socketio.transport.NamespaceClient;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+import org.powermock.reflect.Whitebox;
+
+import java.lang.reflect.Method;
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+/**
+ * @author MrPro
+ */
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class NettySocketIOTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    private NettySocketIOConnectionInterceptor connectionInterceptor;
+    private NettySocketIOOnEventInterceptor onEventInterceptor;
+    private NettySocketIORoomInterceptor roomInterceptor;
+    private NettySocketIOConstructorInterceptor constructorInterceptor;
+
+    @Mock
+    private SocketIOClient socketIOClient;
+    @Mock
+    private Packet sendPacket;
+    @Mock
+    private ClientHead clientHead;
+    @Mock
+    private Namespace namespace;
+
+    private Method connectOnConnectMethod;
+    private Method connectOnDisConnectMethod;
+    private Method roomLeaveMethod;
+    private Method roomJoinMethod;
+
+    private NettySocketIOClientInfo socketIOClientInfo = new NettySocketIOClientInfo(null, null, ""127.0.0.1:9092"");
+
+    private EnhancedInstance enhancedInstance = new EnhancedInstance() {
+        @Override
+        public Object getSkyWalkingDynamicField() {
+            return socketIOClientInfo;
+        }
+
+        @Override
+        public void setSkyWalkingDynamicField(Object value) {
+
+        }
+    };
+
+    @Before
+    public void setUp() {
+        InetSocketAddress addr = new InetSocketAddress(""127.0.0.1"", 9092);","[{'comment': 'Binding to a static port in the test is dangerous, right? \r\nWe should bind for `0` to represent a random port, am I right?\r\n@kezhenxu94 ', 'commenter': 'wu-sheng'}, {'comment': 'It just for declear, not bind system port actually. but I also change it to prevent confusion.', 'commenter': 'mrproliu'}]"
3640,Jenkinsfile-Agent-Test,"@@ -81,11 +81,17 @@ pipeline {
                             }
                         }
 
-                        stage('spring async 4.3.x-5.1.x (35)') {
-                            steps {","[{'comment': ""Hi, It shouldn't be changed here, right?"", 'commenter': 'arugal'}, {'comment': 'sorry? what can I do?', 'commenter': 'mrproliu'}, {'comment': 'You should keep it unchanged. Whitespace mostly', 'commenter': 'wu-sheng'}, {'comment': 'fixed.', 'commenter': 'mrproliu'}]"
3640,test/plugin/scenarios/netty-socketio-scenario/config/expectedData.yaml,"@@ -0,0 +1,97 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+registryItems:
+  applications:
+    - {netty-socketio-scenario: 2}
+  instances:
+    - {netty-socketio-scenario: 1}
+  operationNames:
+    - netty-socketio-scenario: [/netty-socketio-scenario/case/netty-socketio, /socket.io/,
+                                /netty-socketio-scenario/healthCheck, SocketIO/onConnect, SocketIO/send_data/receive]
+  heartbeat: []
+segmentItems:
+  - applicationCode: netty-socketio-scenario
+    segmentSize: ge 5","[{'comment': 'Why is ```ge 5```, but only four ```segments```,  ```/case/netty-socketio -local- >  io.socket.client.Socket -CrossProcess-> SocketIOServer ``` and ```/case/netty-socketio -local- > SocketIOClient  -CrossProcess-> io.socket.client.Socket```  whether this result is more reasonable? just for reference\r\n', 'commenter': 'arugal'}, {'comment': 'cause In this plugin, we havent provide socket.io-client intercept.', 'commenter': 'mrproliu'}]"
3640,Jenkinsfile-Agent-Test,"@@ -88,6 +88,12 @@ pipeline {
                                 sh 'bash test/plugin/run.sh --build_id=wl1_${BUILD_ID} spring-async-scenario'
                             }
                         }
+
+                        stage('netty-socketio 1.x (4)') {
+                            steps {
+                                sh 'bash test/plugin/run.sh --build_id=${BUILD_ID} netty-socketio-scenario'","[{'comment': '`--build_id=wl1_${BUILD_ID}` should replace --build_id=${BUILD_ID}', 'commenter': 'wu-sheng'}, {'comment': 'resolved', 'commenter': 'mrproliu'}]"
3640,test/plugin/scenarios/netty-socketio-scenario/config/expectedData.yaml,"@@ -0,0 +1,97 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+registryItems:
+  applications:
+    - {netty-socketio-scenario: 2}
+  instances:
+    - {netty-socketio-scenario: 1}
+  operationNames:
+    - netty-socketio-scenario: [/netty-socketio-scenario/case/netty-socketio, /socket.io/,
+                                /netty-socketio-scenario/healthCheck, SocketIO/onConnect, SocketIO/send_data/receive]
+  heartbeat: []
+segmentItems:
+  - applicationCode: netty-socketio-scenario
+    segmentSize: ge 5
+    segments:
+      - segmentId: not null
+        spans:
+          - operationName: /netty-socketio-scenario/healthCheck
+            operationId: 0
+            parentSpanId: -1","[{'comment': ""We don't need to check `health-check` usually. Because it is not a stable segment/operation. Why do we need to check it if we ensure it is alway success?"", 'commenter': 'dmsolr'}, {'comment': 'resolved. ', 'commenter': 'mrproliu'}]"
3640,apm-sniffer/apm-sdk-plugin/netty-socketio-plugin/src/main/java/org/apache/skywalking/apm/plugin/netty/socketio/NettySocketIOOnEventInterceptor.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.netty.socketio;
+
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author MrPro
+ */
+public class NettySocketIOOnEventInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        String eventName = (String) allArguments[1];
+
+        // no place to get context carrier
+        ContextCarrier contextCarrier = new ContextCarrier();
+        contextCarrier.items();
+
+        AbstractSpan span = ContextManager.createEntrySpan(""SocketIO/"" + eventName + ""/receive"", contextCarrier);
+        span.setComponent(ComponentsDefine.SOCKET_IO);
+        SpanLayer.asHttp(span);
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);
+    }","[{'comment': 'check `ContextManager.isAtivce()` before.', 'commenter': 'dmsolr'}, {'comment': 'resolved.', 'commenter': 'mrproliu'}]"
3640,apm-sniffer/apm-sdk-plugin/netty-socketio-plugin/src/main/java/org/apache/skywalking/apm/plugin/netty/socketio/NettySocketIOOnEventInterceptor.java,"@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.netty.socketio;
+
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author MrPro
+ */
+public class NettySocketIOOnEventInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        String eventName = (String) allArguments[1];
+
+        // no place to get context carrier
+        ContextCarrier contextCarrier = new ContextCarrier();
+        contextCarrier.items();","[{'comment': ""It is a minor issue, maybe remove this line will better. \r\nHow do you think? @wu-sheng if you feel it's okay, I am approved this PR. "", 'commenter': 'dmsolr'}, {'comment': 'resolved, delete `contextCarrier.items()` method invoke and blank line.', 'commenter': 'mrproliu'}]"
3644,test/plugin/scenarios/postgresql-scenario/config/expectedData.yaml,"@@ -0,0 +1,156 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+registryItems:
+    applications:
+    - {postgresql-scenario: nq 0}
+    instances:
+    - {postgresql-scenario: 1}
+    operationNames:
+    - postgresql-scenario: [/postgresql-scenario/case/healthcheck, /postgresql-scenario/case/postgres,
+                            PostgreSQL/JDBI/PreparedStatement/execute, PostgreSQL/JDBI/CallableStatement/execute,
+                            PostgreSQL/JDBI/Statement/execute, PostgreSQL/JDBI/Connection/close]
+    heartbeat: []
+segmentItems:
+- applicationCode: postgresql-scenario
+  segmentSize: ge 1
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: /postgresql-scenario/case/healthcheck
+      operationId: 0
+      parentSpanId: -1
+      spanId: 0
+      spanLayer: Http
+      startTime: gt 0
+      endTime: gt 0
+      componentId: 1
+      componentName: ''
+      isError: false
+      spanType: Entry
+      peer: ''
+      peerId: 0
+      tags:
+      - {key: url, value: 'http://localhost:8080/postgresql-scenario/case/healthcheck'}
+      - {key: http.method, value: HEAD}
+  - segmentId: not null
+    spans:
+    -
+        operationName: PostgreSQL/JDBI/PreparedStatement/execute","[{'comment': ""This structure seems not formatted well. Didn't expect a new line."", 'commenter': 'wu-sheng'}, {'comment': 'ACK', 'commenter': 'Unknown'}]"
3644,test/plugin/scenarios/postgresql-scenario/config/expectedData.yaml,"@@ -0,0 +1,156 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+registryItems:
+    applications:
+    - {postgresql-scenario: nq 0}
+    instances:
+    - {postgresql-scenario: 1}
+    operationNames:
+    - postgresql-scenario: [/postgresql-scenario/case/healthcheck, /postgresql-scenario/case/postgres,
+                            PostgreSQL/JDBI/PreparedStatement/execute, PostgreSQL/JDBI/CallableStatement/execute,
+                            PostgreSQL/JDBI/Statement/execute, PostgreSQL/JDBI/Connection/close]
+    heartbeat: []
+segmentItems:
+- applicationCode: postgresql-scenario
+  segmentSize: ge 1
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: /postgresql-scenario/case/healthcheck
+      operationId: 0
+      parentSpanId: -1
+      spanId: 0
+      spanLayer: Http
+      startTime: gt 0
+      endTime: gt 0
+      componentId: 1
+      componentName: ''
+      isError: false
+      spanType: Entry
+      peer: ''
+      peerId: 0
+      tags:
+      - {key: url, value: 'http://localhost:8080/postgresql-scenario/case/healthcheck'}
+      - {key: http.method, value: HEAD}
+  - segmentId: not null
+    spans:
+    -
+        operationName: PostgreSQL/JDBI/PreparedStatement/execute
+        operationId: eq 0
+        parentSpanId: 0
+        spanId: 1
+        tags:
+        - {key: ""db.type"", value: ""sql""}
+        - {key: ""db.instance"", value: ""postgres""}
+        - {key: ""db.statement"", value: ""CREATE TABLE test_007(\nid VARCHAR(1) PRIMARY KEY, \nvalue VARCHAR(1) NOT NULL)""}
+        startTime: nq 0
+        endTime: nq 0
+        isError: false
+        spanLayer: Database
+        spanType: Exit
+        componentName: ''
+        componentId: 37
+        peer: postgresql-server:5432
+        peerId: eq 0
+    -
+        operationName: PostgreSQL/JDBI/CallableStatement/execute
+        operationId: eq 0
+        parentSpanId: 0
+        spanId: 2
+        tags:
+        - {key: ""db.type"", value: ""sql""}
+        - {key: ""db.instance"", value: ""postgres""}
+        - {key: ""db.statement"", value: ""INSERT INTO test_007(id, value) VALUES(?,?)""}
+        startTime: nq 0
+        endTime: nq 0
+        isError: false
+        spanLayer: Database
+        spanType: Exit
+        componentName: ''
+        componentId: 37
+        peer: postgresql-server:5432
+        peerId: eq 0
+    -
+        operationName: PostgreSQL/JDBI/Statement/execute
+        operationId: eq 0
+        parentSpanId: 0
+        spanId: 3
+        tags:
+        - {key: ""db.type"", value: ""sql""}
+        - {key: ""db.instance"", value: ""postgres""}
+        - {key: ""db.statement"", value: ""DROP table test_007""}
+        startTime: nq 0
+        endTime: nq 0
+        isError: false
+        spanLayer: Database
+        spanType: Exit
+        componentName: ''
+        componentId: 37
+        peer: postgresql-server:5432
+        peerId: eq 0
+    -
+        operationName: PostgreSQL/JDBI/Connection/close
+        operationId: eq 0
+        parentSpanId: 0
+        spanId: 4
+        tags:
+        - {key: ""db.type"", value: ""sql""}
+        - {key: ""db.instance"", value: ""postgres""}
+        - {key: ""db.statement"", value: """"}
+        startTime: nq 0
+        endTime: nq 0
+        isError: false
+        spanLayer: Database
+        spanType: Exit
+        componentName: ''
+        componentId: 37
+        peer: postgresql-server:5432
+        peerId: eq 0
+    -
+        operationName: PostgreSQL/JDBI/Connection/close
+        operationId: eq 0
+        parentSpanId: 0
+        spanId: 5
+        tags:
+        - {key: ""db.type"", value: ""sql""}
+        - {key: ""db.instance"", value: ""postgres""}
+        - {key: ""db.statement"", value: """"}
+        startTime: nq 0
+        endTime: nq 0
+        isError: false
+        spanLayer: Database
+        spanType: Exit
+        componentName: ''
+        componentId: 37
+        peer: postgresql-server:5432
+        peerId: eq 0","[{'comment': 'seems `close` twice, why?', 'commenter': 'wu-sheng'}, {'comment': 'ApmTest also this，may it‘s a bug，i will find it later\r\n', 'commenter': 'Unknown'}]"
3644,test/plugin/scenarios/postgresql-scenario/support-version.list,"@@ -0,0 +1,54 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+9.2-1002-jdbc4
+9.2-1003-jdbc3
+9.2-1003-jdbc4
+9.2-1004-jdbc3
+9.2-1004-jdbc4
+9.2-1004-jdbc41
+9.3-1100-jdbc3
+9.3-1100-jdbc4
+9.3-1100-jdbc41
+9.3-1101-jdbc3
+9.3-1101-jdbc4
+9.3-1101-jdbc41
+9.3-1102-jdbc3
+9.3-1102-jdbc4
+9.3-1102-jdbc41
+9.3-1103-jdbc3
+9.3-1103-jdbc4
+9.3-1103-jdbc41
+9.3-1104-jdbc4
+9.3-1104-jdbc41
+9.4-1200-jdbc4
+9.4-1200-jdbc41
+9.4-1201-jdbc4
+9.4-1201-jdbc41
+9.4-1202-jdbc4
+9.4-1202-jdbc41
+9.4-1202-jdbc42
+9.4-1203-jdbc4
+9.4-1203-jdbc41
+9.4-1203-jdbc42
+9.4-1204-jdbc4
+9.4-1204-jdbc41
+9.4-1204-jdbc42
+9.4-1205-jdbc4
+9.4-1205-jdbc41
+9.4-1205-jdbc42
+9.4-1206-jdbc4
+9.4-1206-jdbc41
+9.4-1206-jdbc42","[{'comment': 'Also, make sure all these versions could pass, otherwise, you are facing PR CI failure, which is not satisfied with the requirements.', 'commenter': 'wu-sheng'}, {'comment': 'ok, I will check those problem', 'commenter': 'Unknown'}, {'comment': 'some jar doweload solw, any suggest?', 'commenter': 'Unknown'}, {'comment': 'Download at Jenkins should be same, the VM is hosted in US Google Cloud.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'Unknown'}, {'comment': 'this done', 'commenter': 'Unknown'}]"
3644,test/plugin/scenarios/postgresql-scenario/src/main/java/org/apache/skywalking/apm/testcase/postgresql/controller/SQLExecutor.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.testcase.postgresql.controller;
+
+import java.sql.CallableStatement;
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.Statement;
+import org.postgresql.core.BaseConnection;
+
+public class SQLExecutor {
+    private Connection connection;
+
+    public SQLExecutor(PostgresqlConfig postgresqlConfig) throws SQLException {
+        try {
+            Class.forName(""org.postgresql.Driver"");
+        } catch (ClassNotFoundException e) {
+            //
+        }
+        connection = DriverManager.getConnection(postgresqlConfig.getUrl(), postgresqlConfig.getUserName(), postgresqlConfig.getPassword());
+    }
+
+    public void createTable(String sql) throws SQLException {
+        PreparedStatement preparedStatement = connection.prepareStatement(sql);
+        preparedStatement.execute();
+    }
+
+    public void insertData(String sql, String id, String value) throws SQLException {
+        CallableStatement preparedStatement = connection.prepareCall(sql);
+        preparedStatement.setString(1, id);
+        preparedStatement.setString(2, value);
+        preparedStatement.execute();
+    }
+
+    public void dropTable(String sql) throws SQLException {
+        Statement preparedStatement = connection.createStatement();
+        preparedStatement.execute(sql);
+        closeConnection();
+    }
+
+    public void closeConnection() throws SQLException {
+        if (this.connection != null) {
+            this.connection.close();
+        }
+    }","[{'comment': ""```dropTable()``` and ```closeConnection ()```  The question is whether it's here？"", 'commenter': 'arugal'}, {'comment': 'o, it is not a bug, your question give the answer [https://github.com/apache/skywalking/pull/3644#discussion_r336150410](url) @wu-sheng \r\n> seems `close` twice, why?', 'commenter': 'Unknown'}]"
3644,test/plugin/scenarios/postgresql-scenario/src/main/java/org/apache/skywalking/apm/testcase/postgresql/controller/CaseController.java,"@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.postgresql.controller;
+
+
+import java.io.IOException;
+import java.io.PrintWriter;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RestController;
+
+@RestController
+@RequestMapping(""/postgresql-scenario/case"")
+public class CaseController {
+    private Logger logger = LogManager.getLogger(CaseController.class);
+
+    @Autowired
+    PostgresqlConfig postgresqlConfig;
+
+    @GetMapping(""/healthcheck"")","[{'comment': 'suggestion and  recommendation:\r\nWe need to connect to PostgreSQL to make sure PG is running.', 'commenter': 'dmsolr'}, {'comment': 'ACK', 'commenter': 'Unknown'}]"
3644,test/plugin/scenarios/postgresql-scenario/config/expectedData.yaml,"@@ -0,0 +1,150 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+registryItems:
+    applications:
+    - {postgresql-scenario: nq 0}
+    instances:
+    - {postgresql-scenario: 1}
+    operationNames:
+    - postgresql-scenario: [/postgresql-scenario/case/healthcheck, /postgresql-scenario/case/postgres,
+                            PostgreSQL/JDBI/PreparedStatement/execute, PostgreSQL/JDBI/CallableStatement/execute,
+                            PostgreSQL/JDBI/Statement/execute, PostgreSQL/JDBI/Connection/close]
+    heartbeat: []
+segmentItems:
+- applicationCode: postgresql-scenario
+  segmentSize: ge 1
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: /postgresql-scenario/case/healthcheck
+      operationId: 0
+      parentSpanId: -1
+      spanId: 0
+      spanLayer: Http
+      startTime: gt 0
+      endTime: gt 0
+      componentId: 1
+      componentName: ''
+      isError: false
+      spanType: Entry
+      peer: ''
+      peerId: 0
+      tags:
+      - {key: url, value: 'http://localhost:8080/postgresql-scenario/case/healthcheck'}
+      - {key: http.method, value: HEAD}","[{'comment': ""We don't need to verify the health-check segment because it would be called more than one time. "", 'commenter': 'dmsolr'}, {'comment': 'add pg check and remove health-check. Done', 'commenter': 'Unknown'}]"
3644,test/plugin/scenarios/postgresql-scenario/src/main/java/org/apache/skywalking/apm/testcase/postgresql/controller/CaseController.java,"@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.postgresql.controller;
+
+
+import java.io.IOException;
+import java.io.PrintWriter;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RestController;
+
+@RestController
+@RequestMapping(""/postgresql-scenario/case"")
+public class CaseController {
+    private Logger logger = LogManager.getLogger(CaseController.class);
+
+    @Autowired
+    PostgresqlConfig postgresqlConfig;
+
+    @GetMapping(""/healthcheck"")
+    public String healthcheck() throws Exception {
+        SQLExecutor sqlExecute = null;
+        try {
+            sqlExecute = new SQLExecutor(postgresqlConfig);
+            sqlExecute.checkPG(ConstSql.TEST_SQL);
+        } catch (SQLException e) {
+            logger.error(""Failed to execute sql."", e);
+            throw e;
+        } finally {
+            if (sqlExecute != null) {
+                try {
+                    sqlExecute.closeConnection();
+                } catch (SQLException e) {
+                    logger.error(""Failed to close connection."", e);
+                }
+            }
+        }
+        return ""Success"";
+    }
+
+    @GetMapping(""/postgres"")
+    public String postgres() throws SQLException {
+        logger.info(""Begin to start execute sql"");
+        SQLExecutor sqlExecute = null;
+        try {
+            sqlExecute = new SQLExecutor(postgresqlConfig);
+            sqlExecute.createTable(ConstSql.CREATE_TABLE_SQL);
+            sqlExecute.insertData(ConstSql.INSERT_DATA_SQL, ""1"", ""1"");
+            sqlExecute.dropTable(ConstSql.DROP_TABLE_SQL);
+        } catch (SQLException e) {
+            logger.error(""Failed to execute sql."", e);
+            throw e;
+        } finally {
+            if (sqlExecute != null) {
+                try {
+                    sqlExecute.closeConnection();","[{'comment': 'Is this why two `close` spans are generated? Could you recheck it?', 'commenter': 'dmsolr'}, {'comment': 'refer https://github.com/apache/skywalking/pull/3644#issuecomment-544152900', 'commenter': 'Unknown'}, {'comment': '@dmsolr I have debug the code, https://github.com/apache/skywalking/pull/3644#issuecomment-544152900 is right, ConnectionServiceMethodInterceptor in jdbc-commons do the Interceptor, execute twice.', 'commenter': 'Unknown'}, {'comment': 'you need to remove one, right?', 'commenter': 'dmsolr'}]"
3644,test/plugin/scenarios/postgresql-scenario/pom.xml,"@@ -36,26 +36,47 @@
 
         <spring-boot.version>2.1.4.RELEASE</spring-boot.version>
         <lombok.version>1.16.20</lombok.version>
-        <log4j.version>2.6.2</log4j.version>
+        <slf4j.version>1.7.25</slf4j.version>","[{'comment': 'Why do you need to change it without pushing `log4j.properties`?', 'commenter': 'dmsolr'}]"
3644,test/plugin/scenarios/postgresql-9.4-scenario/support-version.list,"@@ -0,0 +1,54 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+9.2-1002-jdbc4
+9.2-1003-jdbc3
+9.2-1003-jdbc4
+9.2-1004-jdbc3
+9.2-1004-jdbc4
+9.2-1004-jdbc41
+9.3-1100-jdbc3
+9.3-1100-jdbc4
+#9.3-1100-jdbc41
+9.3-1101-jdbc3
+9.3-1101-jdbc4
+9.3-1101-jdbc41
+9.3-1102-jdbc3
+9.3-1102-jdbc4
+9.3-1102-jdbc41
+9.3-1103-jdbc3
+9.3-1103-jdbc4
+9.3-1103-jdbc41
+9.3-1104-jdbc4
+9.3-1104-jdbc41
+#9.4-1200-jdbc4
+#9.4-1200-jdbc41","[{'comment': 'Remove these versions, please.', 'commenter': 'wu-sheng'}, {'comment': 'ACK', 'commenter': 'Unknown'}]"
3644,Jenkinsfile-Agent-Test-3,"@@ -77,9 +77,14 @@ pipeline {
                 }
                 stage('Group2') {
                     stages {
-                        stage('reserve stages') {
+                        stage('postgresql 9.2.x-9.4.x (36)') {
                             steps {
-                                echo ""reserve.""
+                                sh 'bash test/plugin/run.sh --build_id=${BUILD_ID} postgresql-scenario'
+                            }
+                        }
+                        stage('postgresql-9.4 (16)') {","[{'comment': 'You miss this change. The name should be `postgresql-9.4.1207+`', 'commenter': 'wu-sheng'}, {'comment': 'Your new name should be fine too.', 'commenter': 'wu-sheng'}, {'comment': 'ACK', 'commenter': 'Unknown'}]"
3654,test/plugin/scenarios/spring-3.0.x-scenario/configuration.yml,"@@ -18,4 +18,5 @@ type: tomcat
 entryService: http://localhost:8080/spring-3.0.x-scenario/case/spring3
 healthCheck: http://localhost:8080/spring-3.0.x-scenario/healthCheck
 runningMode: with_optional
+with_plugins: apm-spring-annotation-plugin-*.jar","[{'comment': ""I think it's `withPlugins`"", 'commenter': 'kezhenxu94'}, {'comment': 'Same as other places', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'arugal'}]"
3667,test/plugin/scenarios/mongodb-3.x-scenario/bin/startup.sh,"@@ -0,0 +1,21 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+#!/bin/sh
+
+home=""$(cd ""$(dirname $0)""; pwd)""
+
+java -jar ${agent_opts}  ""-Dskywalking.agent.service_name=mongodb-3.x-scenario"" ${home}/../libs/mongodb-3.x-scenario.jar &","[{'comment': ""We don't need to configure this."", 'commenter': 'dmsolr'}]"
3667,test/plugin/scenarios/mongodb-3.x-scenario/config/expectedData.yaml,"@@ -0,0 +1,171 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+registryItems:
+  applications:
+    - {mongodb-3.x-scenario: nq 0}
+  instances:
+    - {mongodb-3.x-scenario: 1}
+  operationNames:
+    - mongodb-3.x-scenario: [/case/healthCheck, /case/mongodb, MongoDB/DropDatabaseOperation, MongoDB/FindOperation,
+                             MongoDB/CreateCollectionOperation, MongoDB/MixedBulkWriteOperation]
+  heartbeat: []
+
+segmentItems:
+- applicationCode: mongodb-3.x-scenario
+  segmentSize: 2
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: /case/healthCheck
+      operationId: 0","[{'comment': 'health-check will be called more one when it misses a failure. So set `segmentSize` as `ge 2` and remove the segment of health-check.', 'commenter': 'dmsolr'}]"
3667,test/plugin/scenarios/mongodb-3.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/mongodb/controller/CaseController.java,"@@ -0,0 +1,81 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.mongodb.controller;
+
+import com.mongodb.MongoClient;
+import com.mongodb.client.FindIterable;
+import com.mongodb.client.MongoCollection;
+import com.mongodb.client.MongoDatabase;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.bson.BsonDocument;
+import org.bson.Document;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RestController;
+
+import static com.mongodb.client.model.Filters.eq;
+
+@RestController
+@RequestMapping(""/case"")
+public class CaseController {
+
+    private Logger logger = LogManager.getLogger(CaseController.class);
+
+    @Value(value = ""${mongodb.host}"")
+    private String host;
+
+    @Value(value = ""${mongodb.port:27017}"")
+    private Integer port;
+
+    @GetMapping(""/healthCheck"")
+    public String health() {
+        return ""success"";
+    }","[{'comment': 'In fact, we must ensure the MongoDB server is available. so we need to connect to MongoDB server.', 'commenter': 'dmsolr'}]"
3667,test/plugin/scenarios/mongodb-3.x-scenario/pom.xml,"@@ -0,0 +1,252 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+
+    <groupId>org.apache.skywalking</groupId>
+    <artifactId>mongodb-3.x-scenario</artifactId>
+    <version>5.0.0</version>
+
+    <name>skywalking-mongodb-3.x-scenario</name>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <compiler.version>1.8</compiler.version>
+
+        <test.framework.version>3.3.0</test.framework.version>
+        <docker.image.version>${test.framework.version}</docker.image.version>
+
+        <log4j.version>2.6.2</log4j.version>
+        <spring.version>4.3.8.RELEASE</spring.version>
+        <spring-boot-version>1.5.2.RELEASE</spring-boot-version>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.mongodb</groupId>
+            <artifactId>mongodb-driver</artifactId>
+            <version>${test.framework.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>org.springframework.boot</groupId>
+            <artifactId>spring-boot-starter</artifactId>
+            <version>${spring-boot-version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.logging.log4j</groupId>
+            <artifactId>log4j-api</artifactId>
+            <version>${log4j.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.logging.log4j</groupId>
+            <artifactId>log4j-core</artifactId>
+            <version>${log4j.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.logging.log4j</groupId>
+            <artifactId>log4j-slf4j-impl</artifactId>
+            <version>${log4j.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.logging.log4j</groupId>
+            <artifactId>log4j-jcl</artifactId>
+            <version>${log4j.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.springframework.boot</groupId>
+            <artifactId>spring-boot-starter-tomcat</artifactId>
+            <version>${spring-boot-version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.springframework.boot</groupId>
+            <artifactId>spring-boot-starter-web</artifactId>
+            <version>${spring-boot-version}</version>
+        </dependency>
+    </dependencies>
+
+    <profiles>
+        <profile>
+            <id>mongodb-3.x-scenario-3.3.0</id>
+            <properties>
+                <test.framework.version>3.3.0</test.framework.version>
+            </properties>
+        </profile>
+        <profile>
+            <id>mongodb-3.x-scenario-3.4.0</id>
+            <properties>
+                <test.framework.version>3.4.0</test.framework.version>
+            </properties>
+        </profile>","[{'comment': ""we don't need these anymore. Please refer to https://github.com/apache/skywalking/blob/master/test/plugin/scenarios/canal-scenario/pom.xml"", 'commenter': 'dmsolr'}]"
3667,test/plugin/scenarios/mongodb-3.x-scenario/src/main/resources/log4j2.xml,"@@ -0,0 +1,36 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<Configuration status=""debug"">
+    <Appenders>
+        <Console name=""Console"" target=""SYSTEM_OUT"">
+            <PatternLayout charset=""UTF-8"" pattern=""[%d{yyyy-MM-dd HH:mm:ss:SSS}] [%p] - %l - %m%n""/>
+        </Console>
+    </Appenders>
+    <Loggers>
+        <logger name=""com.a.eye.skywalking.ui"" level=""debug"" additivity=""false"">
+            <AppenderRef ref=""Console""/>
+        </logger>
+        <!--<logger name=""org.skywalking.apm.dependencies"" level=""off"">-->
+        <!--</logger>-->
+        <Root level=""debug"">
+            <AppenderRef ref=""Console""/>
+        </Root>
+    </Loggers>
+</Configuration>","[{'comment': 'Please refer to https://github.com/apache/skywalking/blob/master/test/plugin/scenarios/canal-scenario/src/main/resources/log4j2.xml', 'commenter': 'dmsolr'}]"
3667,Jenkinsfile-Agent-Test-3,"@@ -75,6 +75,11 @@ pipeline {
                                 sh 'bash test/plugin/run.sh --build_id=wl3_${BUILD_ID} canal-scenario'
                             }
                         }
+                        stage('mongodb 3.0-3.11.1 (17)') {
+                            steps {
+                                sh 'bash test/plugin/run.sh --build_id=${BUILD_ID} mongodb-3.x-scenario'","[{'comment': '`--build_id=wl3_${BUILD_ID}` should replace --build_id=${BUILD_ID}', 'commenter': 'wu-sheng'}]"
3667,test/plugin/scenarios/mongodb-3.x-scenario/support-version.list,"@@ -0,0 +1,33 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+3.4.0
+3.4.1
+3.4.2
+3.4.3
+3.5.0
+3.7.0","[{'comment': ""If the existing plugin didn't support 3.7+, then why all these versions are here?"", 'commenter': 'wu-sheng'}]"
3677,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/worker/RegisterPersistentWorker.java,"@@ -42,16 +48,21 @@
     private final IRegisterLockDAO registerLockDAO;
     private final IRegisterDAO registerDAO;
     private final DataCarrier<RegisterSource> dataCarrier;
+    private HistogramMetrics histogram;","[{'comment': '`histogram`  seems a meaningless name. Could you give a better name referring to existing codes?', 'commenter': 'wu-sheng'}]"
3677,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/worker/RegisterPersistentWorker.java,"@@ -80,39 +91,43 @@ private void onWork(RegisterSource registerSource) {
             sources.get(registerSource).combine(registerSource);
         }
 
-        if (sources.size() > 1000 || registerSource.isEndOfBatch()) {
-            sources.values().forEach(source -> {
-                try {
-                    RegisterSource dbSource = registerDAO.get(modelName, source.id());
-                    if (Objects.nonNull(dbSource)) {
-                        if (dbSource.combine(source)) {
-                            registerDAO.forceUpdate(modelName, dbSource);
-                        }
-                    } else {
-                        int sequence;
-                        if ((sequence = registerLockDAO.getId(scopeId, source)) != Const.NONE) {
-                            try {
-                                dbSource = registerDAO.get(modelName, source.id());
-                                if (Objects.nonNull(dbSource)) {
-                                    if (dbSource.combine(source)) {
-                                        registerDAO.forceUpdate(modelName, dbSource);
+        try (HistogramMetrics.Timer ignored = histogram.createTimer()) {
+            if (sources.size() > 1000 || registerSource.isEndOfBatch()) {
+                sources.values().forEach(source -> {
+                    try {
+                        RegisterSource dbSource = registerDAO.get(modelName, source.id());
+                        if (Objects.nonNull(dbSource)) {
+                            if (dbSource.combine(source)) {
+                                registerDAO.forceUpdate(modelName, dbSource);
+                            }
+                        } else {
+                            int sequence;
+                            if ((sequence = registerLockDAO.getId(scopeId, source)) != Const.NONE) {
+                                try {
+                                    dbSource = registerDAO.get(modelName, source.id());
+                                    if (Objects.nonNull(dbSource)) {
+                                        if (dbSource.combine(source)) {
+                                            registerDAO.forceUpdate(modelName, dbSource);
+                                        }
+                                    } else {
+                                        source.setSequence(sequence);
+                                        registerDAO.forceInsert(modelName, source);
                                     }
-                                } else {
-                                    source.setSequence(sequence);
-                                    registerDAO.forceInsert(modelName, source);
+                                } catch (Throwable t) {
+                                    logger.error(t.getMessage(), t);
                                 }
-                            } catch (Throwable t) {
-                                logger.error(t.getMessage(), t);
+                            } else {
+                                logger.info(""{} inventory register try lock and increment sequence failure."", DefaultScopeDefine.nameOf(scopeId));
                             }
-                        } else {
-                            logger.info(""{} inventory register try lock and increment sequence failure."", DefaultScopeDefine.nameOf(scopeId));
                         }
+                    } catch (Throwable t) {
+                        logger.error(t.getMessage(), t);
                     }
-                } catch (Throwable t) {
-                    logger.error(t.getMessage(), t);
-                }
-            });
-            sources.clear();
+                });
+                sources.clear();
+            }
+        } catch (IOException e) {
+            logger.error(""not except exception happen"", e);","[{'comment': 'Why need this log and catch? And clearly, the sentence is not right.', 'commenter': 'wu-sheng'}, {'comment': 'i want use the try-with-resource sugar . The Timer#close() throws IOException that  never throw. I will remove the IOException from the close method.', 'commenter': 'dominicqi'}]"
3677,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/register/worker/RegisterPersistentWorker.java,"@@ -80,39 +91,43 @@ private void onWork(RegisterSource registerSource) {
             sources.get(registerSource).combine(registerSource);
         }
 
-        if (sources.size() > 1000 || registerSource.isEndOfBatch()) {
-            sources.values().forEach(source -> {
-                try {
-                    RegisterSource dbSource = registerDAO.get(modelName, source.id());
-                    if (Objects.nonNull(dbSource)) {
-                        if (dbSource.combine(source)) {
-                            registerDAO.forceUpdate(modelName, dbSource);
-                        }
-                    } else {
-                        int sequence;
-                        if ((sequence = registerLockDAO.getId(scopeId, source)) != Const.NONE) {
-                            try {
-                                dbSource = registerDAO.get(modelName, source.id());
-                                if (Objects.nonNull(dbSource)) {
-                                    if (dbSource.combine(source)) {
-                                        registerDAO.forceUpdate(modelName, dbSource);
+        try (HistogramMetrics.Timer ignored = histogram.createTimer()) {","[{'comment': 'Why timer called ignored?', 'commenter': 'wu-sheng'}]"
3677,docs/en/setup/backend/telemetry/trace-mode-grafana.json,"@@ -1158,14 +1158,112 @@
         ""align"": false,
         ""alignLevel"": null
       }
+    },","[{'comment': 'You just change the trace-mode json, miss the mesh-mode one. ', 'commenter': 'wu-sheng'}]"
3695,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/define/StatementEnhanceInfos.java,"@@ -55,29 +54,14 @@ public String getStatementName() {
     }
 
     public void setParameter(int index, final Object parameter) {
-        maxIndex = maxIndex > index ? maxIndex : index;
-        index--; // start from 1
-        if (parameters == null) {
-            final int initialSize = Math.max(20, maxIndex);
-            parameters = new Object[initialSize];
-            Arrays.fill(parameters, null);
-        }
-        int length = parameters.length;
-        if (index >= length) {
-            int newSize = Math.max(index + 1, length * 2);
-            Object[] newParameters = new Object[newSize];
-            System.arraycopy(parameters, 0, newParameters, 0, length);
-            Arrays.fill(newParameters, length, newSize, null);
-            parameters = newParameters;
+        // start from 1
+        index--;
+        if (index >= 0) {
+            parameters.set(index, parameter);","[{'comment': 'Wondering whether this works or not, can you simply try the following codes?\r\n\r\n```java\r\n\r\nimport java.util.ArrayList;\r\nimport java.util.List;\r\n\r\npublic class Scratch {\r\n  public static void main(String[] args) {\r\n    List<Object> parameters = new ArrayList<Object>();\r\n    parameters.set(0, ""abc"");\r\n  }\r\n}\r\n```\r\n\r\nI remember it would throw', 'commenter': 'kezhenxu94'}, {'comment': 'and refer to https://github.com/apache/skywalking/pull/2846#discussion_r293768204 for context and reasons', 'commenter': 'kezhenxu94'}, {'comment': 'it must be add methed，local test will do tomorrow for pg etc. env at company', 'commenter': 'Unknown'}, {'comment': '@kezhenxu94 thanks for you suggest, i will keep it up', 'commenter': 'Unknown'}, {'comment': '> it must be add methed，local test will do tomorrow for pg etc. env at company\r\n\r\nI think ""add"" is still unsafe if you track back to what I mention above, users don\'t necessarily set the parameters sequentially, they may set the 4th parameter and then the 1st,  and 3rd and 2nd, I thought TreeMap is the best when I implement the MySQL version, (see my link above), so please take a look there to see why I finally give up ', 'commenter': 'kezhenxu94'}, {'comment': 'Then why tests pass? I am assuming the test is not covering accurately.', 'commenter': 'wu-sheng'}, {'comment': '> Then why tests pass? I am assuming the test is not covering accurately.\r\n\r\nBecause the config is disabled by default?', 'commenter': 'kezhenxu94'}, {'comment': 'Could be, @aderm as you are adding a new feature, please make it tested.', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng ok,  I having change the code , runing the test at the motent.', 'commenter': 'Unknown'}]"
3695,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -273,6 +273,27 @@
             public static int SQL_PARAMETERS_MAX_LENGTH = 512;
         }
 
+        public static class POSTGRESQL {
+            /**
+             * If set to true, the parameters of the sql (typically {@link java.sql.PreparedStatement}) would be
+             * collected.
+             */
+            public static boolean TRACE_SQL_PARAMETERS = true;","[{'comment': 'Default to `false`', 'commenter': 'kezhenxu94'}, {'comment': 'And use environment variable to override the config in the test', 'commenter': 'kezhenxu94'}]"
3695,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -273,6 +273,27 @@
             public static int SQL_PARAMETERS_MAX_LENGTH = 512;
         }
 
+        public static class POSTGRESQL {
+            /**
+             * If set to true, the parameters of the sql (typically {@link java.sql.PreparedStatement}) would be
+             * collected.
+             */
+            public static boolean TRACE_SQL_PARAMETERS = true;
+
+            /**
+             * For the sake of performance, limit the max number of parameter
+             */
+            public static int SQL_PARAMETERS_MAX_COUNT = 20;
+
+            /**
+             * For the sake of performance, SkyWalking won't save the entire parameters string into the tag, but only
+             * the first {@code SQL_PARAMETERS_MAX_LENGTH} characters.
+             *
+             * Set a negative number to save the complete parameter string to the tag.
+             */
+            public static int SQL_PARAMETERS_MAX_LENGTH = 512;","[{'comment': 'Add these configs to documentations, otherwise, nobody can find this feature until they read the source codes', 'commenter': 'kezhenxu94'}]"
3695,apm-sniffer/apm-sdk-plugin/postgresql-8.x-plugin/pom.xml,"@@ -48,6 +49,11 @@
             <version>${project.version}</version>
             <scope>provided</scope>
         </dependency>
+        <dependency>
+            <groupId>com.google.guava</groupId>
+            <artifactId>guava</artifactId>
+            <version>${guava.version}</version>
+        </dependency>
     </dependencies>","[{'comment': 'You **MUST NOT** use third-party dependencies in agent plugin', 'commenter': 'kezhenxu94'}, {'comment': 'Why need this lib? BTW. You are just logging parameter into the span, seems not a complex work. And clearly, the MySQL plugin has given a demo about how to do it.', 'commenter': 'wu-sheng'}]"
3695,apm-sniffer/apm-sdk-plugin/jdbc-commons/src/main/java/org/apache/skywalking/apm/plugin/jdbc/define/StatementEnhanceInfos.java,"@@ -80,4 +87,19 @@ public void setParameter(int index, final Object parameter) {
     public int getMaxIndex() {
         return maxIndex;
     }
+
+    public Map<Integer, Object> getParameterMap() {
+        return parameterMap;
+    }
+
+    public List<Object> getSortParameters() {
+        List<Object> parameters = new ArrayList<Object>();
+        if (parameterMap.size() > 0) {
+            Iterator<Entry<Integer,Object>> iterator = parameterMap.entrySet().iterator();
+            while (iterator.hasNext()) {
+                parameters.add(iterator.next().getValue());
+            }
+        }
+        return parameters;
+    }","[{'comment': 'There is still performance impact when using `TreeMap`, see [comment here](https://github.com/apache/skywalking/pull/2846#pullrequestreview-250196401), the performance is a big concern in agent side, please make a tradeoff', 'commenter': 'kezhenxu94'}]"
3695,apm-sniffer/apm-sdk-plugin/postgresql-8.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/jdbc/postgresql/util/ParameterUtil.java,"@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.jdbc.postgresql.util;
+
+import com.google.common.base.Joiner;
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * @author aderm
+ */
+public class ParameterUtil {
+
+    public static String format(Object[] params, int limitCnt, int limitLength) {
+        return format(Arrays.asList(params), limitCnt, limitLength);
+    }
+
+    public static String format(List<Object> params, int limitCnt, int limitLength) {
+        boolean overLoad = false;
+        int actualCnt = params.size();
+        if (params.size() > limitCnt) {
+            overLoad = true;
+            actualCnt = limitCnt;
+        }
+
+        String paramStr = Joiner.on("","").join(params.subList(0, actualCnt));","[{'comment': 'Introduce a third-party dependency (guava) just for one method is not worthy, and again, we **MUST NOT** use third-party dependency unless we shadow them', 'commenter': 'kezhenxu94'}, {'comment': 'ok', 'commenter': 'Unknown'}]"
3695,test/plugin/scenarios/postgresql-above9.4.1207-scenario/config/expectedData.yaml,"@@ -53,6 +53,7 @@ segmentItems:
         - {key: ""db.type"", value: ""sql""}
         - {key: ""db.instance"", value: ""postgres""}
         - {key: ""db.statement"", value: ""INSERT INTO test_007(id, value) VALUES(?,?)""}
+        - {key: ""db.bind_vars"", value: ""[1,1]""}","[{'comment': 'should be `db.sql.parameters`?', 'commenter': 'kezhenxu94'}, {'comment': 'And after setting the default value of `TRACE_SQL_PARAMETERS` to `false`, we should pass an environment variable to override it to `true`, otherwise, there is no key `db.sql.parameters`', 'commenter': 'kezhenxu94'}, {'comment': 'how to set?', 'commenter': 'Unknown'}, {'comment': 'in docker setting?', 'commenter': 'Unknown'}, {'comment': 'seems to be here\r\n\r\nhttps://github.com/apache/skywalking/blob/2e2616d0efc34c29a3d3388e100d948303ad2832/test/plugin/scenarios/postgresql-scenario/bin/startup.sh#L20\r\n\r\nyou can use something like \r\n\r\n```\r\njava -jar ${agent_opts} -Dskywalking.plugin.postgresql.trace_sql_parameters=true ${home}/../libs/posgresql.......\r\n```\r\n\r\nit should work, please try ', 'commenter': 'kezhenxu94'}, {'comment': 'ok', 'commenter': 'Unknown'}]"
3724,test/plugin/containers/jvm-container/docker/run.sh,"@@ -76,11 +76,11 @@ healthCheck http://localhost:12800/status
 healthCheck ${SCENARIO_HEALTH_CHECK_URL}
 
 echo ""To visit entry service""
-curl -s --max-time 3 ${SCENARIO_ENTRY_SERVICE}
+curl -s --max-time 60 ${SCENARIO_ENTRY_SERVICE}","[{'comment': 'If access too many, the mock collector may be OOM. ', 'commenter': 'wu-sheng'}, {'comment': 'this should be timeout, not retry count', 'commenter': 'kezhenxu94'}, {'comment': 'It is still a single thread to visit the mok-collector without retry. Increasing the timeout time why it could improve the success rate. Make tests more stable.\r\nThere is no retry but will timeout in 60s. I think this change is necessary.', 'commenter': 'dmsolr'}]"
3724,test/plugin/containers/tomcat-container/docker/run.sh,"@@ -66,11 +66,11 @@ healthCheck http://localhost:12800/status 10
 healthCheck ${SCENARIO_HEALTH_CHECK_URL}
 
 echo ""To visit entry service""
-curl -s --max-time 3 ${SCENARIO_ENTRY_SERVICE}
+curl -s --max-time 60 ${SCENARIO_ENTRY_SERVICE}
 sleep 5
 
 echo ""To receive actual data""
-curl -s --max-time 3 http://localhost:12800/receiveData > ${SCENARIO_HOME}/data/actualData.yaml
+curl -s --max-time 60 http://localhost:12800/receiveData > ${SCENARIO_HOME}/data/actualData.yaml","[{'comment': ""This is only trying to access receive data, but you don't verify. Why add this?"", 'commenter': 'wu-sheng'}]"
3774,Jenkinsfile-Agent-Test,"@@ -63,12 +64,12 @@ pipeline {
                 }
             }
             steps {
-                sh './mvnw -f test/plugin/pom.xml clean package -DskipTests -Dbuild_id=wl1_${BUILD_ID} docker:build'
+                sh './mvnw -f test/plugin/pom.xml clean package -DskipTests -Dbuild_id=${BUILD_NO} docker:build'","[{'comment': ""I don't think we need `--build_id=wl1_${BUILD_ID}` any more"", 'commenter': 'kezhenxu94'}]"
3774,test/plugin/run.sh,"@@ -20,7 +20,7 @@ home=""$(cd ""$(dirname $0)""; pwd)""
 scenario_name=""""
 parallel_run_size=1
 force_build=""off""
-build_id=""local""
+build_id=""${BUILD_NO:=local}""","[{'comment': 'Since you have use the environment variable here', 'commenter': 'kezhenxu94'}]"
3857,Jenkinsfile-Agent-Test-2,"@@ -82,6 +82,12 @@ pipeline {
             parallel {
                 stage('Group1') {
                     stages {
+                        stage('spring-tx 4.x+ (10)') {","[{'comment': 'The total case number is not updated.', 'commenter': 'wu-sheng'}, {'comment': 'I fixed, recheck please', 'commenter': 'zhaoyuguang'}]"
3857,test/plugin/scenarios/spring-tx-scenario/config/expectedData.yaml,"@@ -0,0 +1,168 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+registryItems:
+  applications:
+    - {spring-tx-scenario: 2}
+  instances:
+    - {spring-tx-scenario: 1}
+  operationNames:
+    - spring-tx-scenario: [Mysql/JDBI/Statement/execute, Mysql/JDBI/Connection/commit,
+                           Mysql/JDBI/PreparedStatement/executeUpdate, /case/spring-tx-case, /case/healthCheck,
+                           Mysql/JDBI/Connection/close, Mysql/JDBI/Statement/executeQuery]
+  heartbeat: []
+segmentItems:
+  - applicationCode: spring-tx-scenario
+    segmentSize: nq 0
+    segments:
+      - segmentId: not null
+        spans:
+          - operationName: TX/get/test.org.apache.skywalking.apm.testcase.spring.transaction.service.impl.DemoServiceImpl.doBiz","[{'comment': 'I am not familiar with this.  I think `operationName` is a little long. Maybe we can use `t.o.s.a.t.s.t.s.i.DemoServiceImpl.doBiz`.', 'commenter': 'dmsolr'}, {'comment': 'If we want to support this, please be an optional config. ', 'commenter': 'wu-sheng'}, {'comment': ""Good proposal. I'll finish it."", 'commenter': 'zhaoyuguang'}, {'comment': 'Hi, store method name in tags? FYI', 'commenter': 'arugal'}, {'comment': ""Don't save duplicated inform. Otherwise, there is no point to implement short name. Use config if you want to give user options. But, you need make sure converting to short is quick enough."", 'commenter': 'wu-sheng'}, {'comment': '```yaml\r\noperationName: TX/get\r\ntags: \r\n - {key: ""method"", value:""test.org.apache.skywalking.apm.testcase.spring.transaction.service.impl.DemoServiceImpl.doBiz""}\r\n```\r\nMy idea should be like this. Can ignore. ', 'commenter': 'arugal'}, {'comment': 'I just rechecked the specification and I am also wondering whether this operation name is **too specific**, as suggested in [the specification](https://github.com/opentracing/specification/blob/master/specification.md#start-a-new-span)', 'commenter': 'kezhenxu94'}, {'comment': ""We don't need to follow the OpenTracing, as it is not a specific at all. I would like to discuss what kind of operation name makes more sense to user when they see our trace view. Could we discuss based on this?"", 'commenter': 'wu-sheng'}]"
3857,apm-sniffer/optional-plugins/optional-spring-plugins/spring-tx-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/transaction/GetTransactionMethodInterceptor.java,"@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.plugin.spring.transaction;
+
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.spring.transaction.context.Constants;
+import org.springframework.transaction.TransactionDefinition;
+
+import java.lang.reflect.Method;
+
+/**
+ * @author zhaoyuguang
+ */
+public class GetTransactionMethodInterceptor implements InstanceMethodsAroundInterceptor {
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
+                             MethodInterceptResult result) throws Throwable {
+        TransactionDefinition definition = (TransactionDefinition) allArguments[0];","[{'comment': ""According to the [Spring source codes](https://github.com/spring-projects/spring-framework/blob/85471d05871ee8461b5f196ed26ffeb866d76cb2/spring-tx/src/main/java/org/springframework/transaction/support/AbstractPlatformTransactionManager.java#L341-L350), the `definition` is marked as `@Nullable`, and it may be null, so I'm wondering that have you covered this scenario? or should we consider this case? future users may encounter weird issues that are hard to diagnose when this happen, `NullPointerException`\r\n\r\n```java\r\n\tpublic final TransactionStatus getTransaction(@Nullable TransactionDefinition definition) throws TransactionException {\r\n\t\tObject transaction = doGetTransaction();\r\n\r\n\r\n\t\t// Cache debug flag to avoid repeated checks.\r\n\t\tboolean debugEnabled = logger.isDebugEnabled();\r\n\r\n\r\n\t\tif (definition == null) {\r\n\t\t\t// Use defaults if no transaction definition given.\r\n\t\t\tdefinition = new DefaultTransactionDefinition();\r\n\t\t}\r\n```"", 'commenter': 'kezhenxu94'}, {'comment': 'Make sense, @zhaoyuguang we should include this.', 'commenter': 'wu-sheng'}, {'comment': ""Good proposal. I'll finish it. @kezhenxu94 "", 'commenter': 'zhaoyuguang'}, {'comment': 'I  fixed  please recheck.', 'commenter': 'zhaoyuguang'}]"
3868,test/plugin/scenarios/elasticsearch-7.x-scenario/configuration.yml,"@@ -0,0 +1,35 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+type: jvm
+entryService: http://localhost:8080/elasticsearch-case/case/elasticsearch
+healthCheck: http://localhost:8080/elasticsearch-case/case/healthCheck
+startScript: ./bin/startup.sh
+framework: elasticsearch-7.x-scenario
+environment:
+- elasticsearch.server=elasticsearch-server:9200
+dependencies:
+  elasticsearch-server:
+    image: elasticsearch:7.0.0","[{'comment': '1. should be renamed.\r\n2. uses ${CASE_SERVER_IMAGE_VERSION} instead of 7.0.0, please ', 'commenter': 'dmsolr'}]"
3868,test/plugin/scenarios/elasticsearch-7.x-scenario/configuration.yml,"@@ -0,0 +1,35 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+type: jvm
+entryService: http://localhost:8080/elasticsearch-case/case/elasticsearch
+healthCheck: http://localhost:8080/elasticsearch-case/case/healthCheck
+startScript: ./bin/startup.sh
+framework: elasticsearch-7.x-scenario
+environment:
+- elasticsearch.server=elasticsearch-server:9200
+dependencies:
+  elasticsearch-server:","[{'comment': 'This server name should be different from the existing case name.', 'commenter': 'wu-sheng'}, {'comment': 'And existing es cases sharding the same name too, please make three of them different.\r\n1. https://github.com/apache/skywalking/blob/master/test/plugin/scenarios/elasticsearch-5.x-scenario/configuration.yml\r\n1. https://github.com/apache/skywalking/blob/master/test/plugin/scenarios/elasticsearch-6.x-scenario/configuration.yml\r\n', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'Unknown'}]"
3868,test/plugin/scenarios/elasticsearch-7.x-scenario/configuration.yml,"@@ -0,0 +1,35 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+type: jvm
+entryService: http://localhost:8080/elasticsearch-case/case/elasticsearch
+healthCheck: http://localhost:8080/elasticsearch-case/case/healthCheck
+startScript: ./bin/startup.sh
+framework: elasticsearch-7.x-scenario
+environment:
+- elasticsearch.server=elasticsearch-server:9200
+dependencies:
+  elasticsearch-server:
+    image: elasticsearch:7.0.0
+    hostname: elasticsearch-server","[{'comment': 'Here is the same. It will conflict with ES5/ES6.', 'commenter': 'dmsolr'}]"
4047,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/mysql/MySQLAggregationQueryDAO.java,"@@ -44,14 +49,14 @@ public MySQLAggregationQueryDAO(
         String tableName = ModelName.build(downsampling, indName);
         StringBuilder sql = new StringBuilder();
         List<Object> conditions = new ArrayList<>(10);
-        sql.append(""select * from (select avg("").append(valueCName).append("") value,"").append(Metrics.ENTITY_ID).append("" from "")
+        sql.append(""select avg("").append(valueCName).append("") value,"").append(Metrics.ENTITY_ID).append("" from "")
             .append(tableName).append("" where "");
         this.setTimeRangeCondition(sql, conditions, startTB, endTB);
         if (appender != null) {
             appender.append(sql, conditions);
         }
         sql.append("" group by "").append(Metrics.ENTITY_ID);
-        sql.append("") AS METRICS order by value "").append(order.equals(Order.ASC) ? ""asc"" : ""desc"").append("" limit "").append(topN);
+        sql.append("" order by value "").append(order.equals(Order.ASC) ? ""asc"" : ""desc"").append("" limit "").append(topN);","[{'comment': 'Have you used real data set to verify this?', 'commenter': 'wu-sheng'}, {'comment': 'Could you post the test data set and result in this PR?', 'commenter': 'wu-sheng'}, {'comment': 'Add Unit test to thi pr? Or just comment my test result?', 'commenter': 'tristaZero'}, {'comment': 'Comment should be enough.', 'commenter': 'wu-sheng'}]"
4047,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2AggregationQueryDAO.java,"@@ -83,18 +86,17 @@ public H2AggregationQueryDAO(JDBCHikariCPClient h2Client) {
 
     public List<TopNEntity> topNQuery(String indName, String valueCName, int topN, Downsampling downsampling,
                                       long startTB, long endTB, Order order, AppendCondition appender) throws IOException {
-        String tableName = ModelName.build(downsampling, indName);
+        String indexName = ModelName.build(downsampling, indName);
         StringBuilder sql = new StringBuilder();
         List<Object> conditions = new ArrayList<>(10);
-        sql.append(""select avg("").append(valueCName).append("") value,"").append(Metrics.ENTITY_ID).append("" from "")
-                .append(tableName).append("" where "");
+        sql.append(""select * from (select avg("").append(valueCName).append("") value,"").append(Metrics.ENTITY_ID).append("" from "")","[{'comment': 'This kind of query statement is required in H2?', 'commenter': 'wu-sheng'}]"
4072,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/metrics/MinLongMetrics.java,"@@ -0,0 +1,57 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis.metrics;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.analysis.metrics.annotation.Entrance;
+import org.apache.skywalking.oap.server.core.analysis.metrics.annotation.MetricsFunction;
+import org.apache.skywalking.oap.server.core.analysis.metrics.annotation.SourceFrom;
+import org.apache.skywalking.oap.server.core.storage.annotation.Column;
+
+/**
+ * @author jian.tan
+ */
+
+@MetricsFunction(functionName = ""min"")
+public abstract class MinLongMetrics extends Metrics implements LongValueHolder {
+
+    protected static final String VALUE = ""value"";
+
+    @Getter @Setter @Column(columnName = VALUE, isValue = true) private long value;
+
+    @Entrance
+    public final void combine(@SourceFrom long count) {
+        if (this.value == 0) {
+            this.value = count;
+        }","[{'comment': ""An obvious bug here, try the test codes:\r\n\r\n```java\r\n        MinLongMetricsImpl impl = new MinLongMetricsImpl();\r\n        impl.combine(10);\r\n        impl.combine(0);\r\n        impl.combine(10000);\r\n```\r\n\r\nI expect `impl.getValue()` to be `0`, but it's `10000`, please recheck @JaredTan95 "", 'commenter': 'kezhenxu94'}, {'comment': 'Making `value` default to `Long.MAX_VALUE` is my first intuition', 'commenter': 'kezhenxu94'}, {'comment': ""> An obvious bug here, try the test codes:\r\n> \r\n> ```java\r\n>         MinLongMetricsImpl impl = new MinLongMetricsImpl();\r\n>         impl.combine(10);\r\n>         impl.combine(0);\r\n>         impl.combine(10000);\r\n> ```\r\n> \r\n> I expect `impl.getValue()` to be `0`, but it's `10000`, please recheck @JaredTan95\r\n\r\nI suggest putting this into unit test as well "", 'commenter': 'kezhenxu94'}, {'comment': 'Thanks to your experienced guidance, I will update it.', 'commenter': 'JaredTan95'}]"
4145,.github/workflows/e2e.yaml,"@@ -80,6 +80,8 @@ jobs:
         run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-ttl/e2e-ttl-es
       - name: TTL ES7 Tests(JDK8)
         run: export E2E_VERSION=jdk8-1.3 DIST_PACKAGE=apache-skywalking-apm-bin-es7.tar.gz ES_VERSION=7.4.2 && bash -x test/e2e/run.sh e2e-ttl/e2e-ttl-es
+      - name: Profile Tests(JDK8)
+        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-profile/e2e-profile-test-runner","[{'comment': 'This should be top level e2e test, like `Compatibilities` test.', 'commenter': 'wu-sheng'}, {'comment': 'Ok. I will change it after the e2e task failed issue resolved.', 'commenter': 'mrproliu'}]"
4145,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/profile/IThreadMonitorTaskQueryDAO.java,"@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.oap.server.core.storage.profile;
+
+import org.apache.skywalking.oap.server.core.query.entity.ThreadMonitorTask;
+import org.apache.skywalking.oap.server.core.storage.DAO;
+
+import java.io.IOException;
+import java.util.List;
+
+/**
+ * process all thread monitor task query
+ *
+ * @author MrPro
+ */
+public interface IThreadMonitorTaskQueryDAO extends DAO {
+
+    /**
+     * get all thread monitor task start time in time range
+     * @param serviceId monitor service id
+     * @param taskStartTime task start time bigger than or equals
+     * @param taskEndTime task start time smaller than or equals
+     * @return
+     */
+    List<ThreadMonitorTask> getTaskListSearchOnStartTime(final int serviceId, final long taskStartTime, final long taskEndTime) throws IOException;
+
+    /**
+     * search task list in appoint time bucket
+     * @param serviceId monitor service id, maybe null
+     * @param endpointName endpoint name, maybe empty
+     * @param startTimeBucket time bucket bigger than or equals
+     * @param endTimeBucket time bucket small than or equals
+     * @return
+     */
+    List<ThreadMonitorTask> getTaskList(final Integer serviceId, final String endpointName, final long startTimeBucket, final long endTimeBucket) throws IOException;","[{'comment': 'Why do we need both methods? ', 'commenter': 'wu-sheng'}, {'comment': 'They have very similar parameter, but different logic? It is hard to understand.', 'commenter': 'wu-sheng'}, {'comment': ""they are using different logic.\r\n`getTaskListSearchOnStartTime`: It will use on creating a new task to check limit, Each service can monitor up to 1 endpoints during the execution of tasks. search time range on task start time.\r\n`getTaskList`: It will use on the UI level GraphQL searching. search time range on time bucket.\r\nAt present, I don't have any good way to optimize these two methods."", 'commenter': 'mrproliu'}, {'comment': 'These two names show no difference. The storage implementor must be confused.', 'commenter': 'wu-sheng'}, {'comment': 'The point is storage should consider data query only. You could query the list, then check. I still don’t see the difference. You are talking using in different places. But this is wrong as two separated methods.\r\n\r\nYou should provide a method a query existing task list based on given conditions, that is all. This method is not matching the UI query or create task. It is a storage interface.', 'commenter': 'wu-sheng'}]"
4145,apm-commons/apm-util/src/main/java/org/apache/skywalking/apm/util/StringUtil.java,"@@ -23,6 +23,10 @@ public static boolean isEmpty(String str) {
         return str == null || str.length() == 0;
     }
 
+    public static boolean isBlank(String str) {","[{'comment': 'There is already `StringUtil#isEmpty`. This is duplicated.', 'commenter': 'wu-sheng'}, {'comment': '> There is already `StringUtil#isEmpty`. This is duplicated.\r\n\r\nThey\'re different (trivial though) IMO, `StringUtil.isEmpty(""  \\t"") == false` while `StringUtil.isBlank(""  \\t"") == true`', 'commenter': 'kezhenxu94'}, {'comment': 'I highly doubt this is the purpose of creating this API..', 'commenter': 'wu-sheng'}, {'comment': 'Maybe I should do String#trim on GrapthQL resolver?', 'commenter': 'mrproliu'}, {'comment': 'Why do you need a trim? Who will send an empty string?', 'commenter': 'wu-sheng'}, {'comment': ""> Why do you need a trim? Who will send an empty string?\r\n\r\n@wu-sheng As long as the string is typed by the users, it's totally possible that it will include blank characters, or even unprintable/invisible characters, we're suffering from this because the users copy-and-pastes from else where (especially Windows users, `\\r` is painful), another solution is to trim and validate the input  in the frontend, but we may have other user interface, CLI I mean"", 'commenter': 'kezhenxu94'}, {'comment': 'If that is the concern, `trim` the data in the GraphQL service level, this kind of blank issue clearly is related to humans, not to codes. ', 'commenter': 'wu-sheng'}]"
4145,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/ProfileMutation.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.oap.query.graphql.resolver;
+
+import com.coxautodev.graphql.tools.GraphQLMutationResolver;
+import org.apache.skywalking.oap.query.graphql.type.ProfileTaskCreationRequest;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.profile.ProfileTaskMutationService;
+import org.apache.skywalking.oap.server.core.profile.entity.ProfileTaskCreationResult;
+import org.apache.skywalking.oap.server.core.query.DurationUtils;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.io.IOException;
+
+/**
+ * profile mutation GraphQL resolver
+ *
+ * @author MrPro
+ */
+public class ProfileMutation implements GraphQLMutationResolver {
+
+    private final ModuleManager moduleManager;
+    private ProfileTaskMutationService profileTaskService;
+
+    public ProfileMutation(ModuleManager moduleManager) {
+        this.moduleManager = moduleManager;
+    }
+
+    private ProfileTaskMutationService getProfileTaskService() {
+        if (profileTaskService == null) {
+            this.profileTaskService = moduleManager.find(CoreModule.NAME).provider().getService(ProfileTaskMutationService.class);
+        }
+        return profileTaskService;
+    }
+
+    public ProfileTaskCreationResult createProfileTask(ProfileTaskCreationRequest creationRequest) throws IOException {
+        return getProfileTaskService().createTask(
+                creationRequest.getServiceId(),
+                creationRequest.getEndpointName(),
+                creationRequest.getStartTime() == null ? -1 : creationRequest.getStartTime(),
+                Math.toIntExact(DurationUtils.INSTANCE.toSecond(creationRequest.getDurationUnit(), creationRequest.getDuration())),","[{'comment': 'Reading this makes me feel, we should set the duration in minute level only, and remove the step in the protocol. @kezhenxu94 @arugal  What do you think?', 'commenter': 'wu-sheng'}, {'comment': '> Reading this makes me feel, we should set the duration in minute level only, and remove the step in the protocol. @kezhenxu94 @arugal What do you think?\r\n\r\nMake sense to me, but `minute` level seems too large in time span, what about making it `second` level?', 'commenter': 'kezhenxu94'}, {'comment': 'According to https://github.com/apache/skywalking-query-protocol/blob/master/profile.graphqls#L25-L26, this duration is for the task, I think minute makes more sense.', 'commenter': 'wu-sheng'}, {'comment': 'This threshold for segment(nothing related to span) is minDurationThreshold, refer to https://github.com/apache/skywalking-query-protocol/blob/master/profile.graphqls#L30', 'commenter': 'wu-sheng'}]"
4145,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/ProfileTaskQueryEsDAO.java,"@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.elasticsearch.query;
+
+import org.apache.skywalking.apm.util.StringUtil;
+import org.apache.skywalking.oap.server.core.profile.ProfileTaskNoneStream;
+import org.apache.skywalking.oap.server.core.query.entity.ProfileTask;
+import org.apache.skywalking.oap.server.core.storage.profile.IProfileTaskQueryDAO;
+import org.apache.skywalking.oap.server.library.client.elasticsearch.ElasticSearchClient;
+import org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base.EsDAO;
+import org.elasticsearch.action.search.SearchResponse;
+import org.elasticsearch.index.query.BoolQueryBuilder;
+import org.elasticsearch.index.query.QueryBuilders;
+import org.elasticsearch.search.SearchHit;
+import org.elasticsearch.search.builder.SearchSourceBuilder;
+
+import java.io.IOException;
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author MrPro
+ */
+public class ProfileTaskQueryEsDAO extends EsDAO implements IProfileTaskQueryDAO {
+
+    public ProfileTaskQueryEsDAO(ElasticSearchClient client) {
+        super(client);
+    }
+
+    @Override
+    public List<ProfileTask> getTaskList(Integer serviceId, String endpointName, long startTimeBucket, long endTimeBucket) throws IOException {
+        SearchSourceBuilder sourceBuilder = SearchSourceBuilder.searchSource();
+
+        final BoolQueryBuilder boolQueryBuilder = QueryBuilders.boolQuery();
+        sourceBuilder.query(boolQueryBuilder);
+
+        if (serviceId != null) {
+            boolQueryBuilder.must().add(QueryBuilders.termQuery(ProfileTaskNoneStream.SERVICE_ID, serviceId));
+        }
+
+        if (!StringUtil.isBlank(endpointName)) {
+            boolQueryBuilder.must().add(QueryBuilders.termQuery(ProfileTaskNoneStream.ENDPOINT_NAME, endpointName));
+        }
+
+        boolQueryBuilder.must().add(QueryBuilders.rangeQuery(ProfileTaskNoneStream.TIME_BUCKET).gte(startTimeBucket).lte(endTimeBucket));
+
+        final SearchResponse response = getClient().search(ProfileTaskNoneStream.INDEX_NAME, sourceBuilder);","[{'comment': 'I think we need a `sourceBuilder.size(limit);` here, right? @kezhenxu94 Otherwise, ES query will only get top 10? ', 'commenter': 'wu-sheng'}, {'comment': 'Yes, we get 10 docuemnts only by default. ', 'commenter': 'dmsolr'}, {'comment': ""That's true. I think to get 10 doc it's enough. Should I add a size limit?"", 'commenter': 'mrproliu'}, {'comment': ""Why 10 is enough? I don't remember we limit the task amount."", 'commenter': 'wu-sheng'}, {'comment': 'Oh, I just think is using on the task creation limit check, forget it will use on GraphQL. Should I add a limit and from param in the GraphQL?', 'commenter': 'mrproliu'}, {'comment': 'You could have a limit in DAO interface level, but for UI, if we want to set the limit, we should set paging in the GraphQL parameter ', 'commenter': 'wu-sheng'}, {'comment': 'Because if we set a limit in UI without paging, people would not see the full list forever. I still think the full list is enough for UI as the profiling task should not a long list.', 'commenter': 'wu-sheng'}, {'comment': 'One more thing, as we have TTL for profile task, we could remove the duration here, https://github.com/apache/skywalking-query-protocol/blob/master/profile.graphqls#L68. We should always show the full list. Any suggestion? @arugal @kezhenxu94 ', 'commenter': 'wu-sheng'}, {'comment': 'Do we need to support order by `time`?', 'commenter': 'dmsolr'}, {'comment': 'Yes, should order by start time `DESC`', 'commenter': 'wu-sheng'}]"
4145,.github/workflows/e2e.yaml,"@@ -95,4 +95,20 @@ jobs:
           ./mvnw -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install
           ./mvnw -f test/e2e/pom.xml -pl e2e-base clean install
       - name: 6.x Agents & 7.x Backend
-        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-6.x-agent-7.x-oap-compatibility
\ No newline at end of file
+        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-6.x-agent-7.x-oap-compatibility
+
+  Profile:
+    runs-on: ubuntu-latest
+    steps:
+      - uses: actions/checkout@v1
+        with:
+          submodules: true
+      - name: Set environment
+        run: export MAVEN_OPTS='-Dmaven.repo.local=~/.m2/repository -XX:+TieredCompilation -XX:TieredStopAtLevel=1 -XX:+CMSClassUnloadingEnabled -XX:+UseConcMarkSweepGC -XX:-UseGCOverheadLimit -Xmx3g'
+      - name: Compile & Install Test Codes
+        run: |
+          ./mvnw checkstyle:check apache-rat:check
+          ./mvnw -Dcheckstyle.skip -Drat.skip -T2 -Dmaven.compile.fork -Dmaven.compiler.maxmem=3072 -DskipTests clean install
+          ./mvnw -f test/e2e/pom.xml -pl e2e-base clean install
+      - name: Profile Tests(JDK8)
+        run: export E2E_VERSION=jdk8-1.3 && bash -x test/e2e/run.sh e2e-profile/e2e-profile-test-runner","[{'comment': 'Profile should be tested in every storage. H2, MySQL, es6, es7.', 'commenter': 'wu-sheng'}]"
4145,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/DurationUtils.java,"@@ -187,6 +189,36 @@ public int secondsBetween(Downsampling downsampling, DateTime dateTime) {
         return durations;
     }
 
+    /**
+     * convert duration to second unit
+     * @param step
+     * @param duration
+     * @return
+     */
+    public long toSecond(Step step, long duration) {","[{'comment': 'I think this method is not necessary as the duration unit has been removed from the protocol', 'commenter': 'wu-sheng'}]"
4165,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/trace/SpanLayer.java,"@@ -26,7 +26,8 @@
     RPC_FRAMEWORK(2),
     HTTP(3),
     MQ(4),
-    CACHE(5);
+    CACHE(5),
+    COROUTINE(6);","[{'comment': 'This should not be added. `COROUTINE` is a local span. Should not be `Layer`.', 'commenter': 'wu-sheng'}, {'comment': 'Got it, I create it for other incoming coroutine plugins, like goroutine etc.', 'commenter': 'devkanro'}]"
4165,apm-sniffer/bootstrap-plugins/pom.xml,"@@ -43,6 +43,7 @@
     <modules>
         <module>jdk-http-plugin</module>
         <module>jdk-threading-plugin</module>
+        <module>kotlin-coroutine-plugin</module>","[{'comment': 'Why is kotlin coroutine plugin as bootstrap plugin? From my understanding, Kotlin still run inside JVM, and compiled as `.class` files. Bootstrap plugins should be rt.jar level injection. Does koltin plugin require this?', 'commenter': 'wu-sheng'}, {'comment': 'I have another implementation for this plugin, it based on `ThreadContextElement` which is Kotlin coroutine context for syncing thread context, it needs to create interceptor point in `newCoroutineContext`, but I got some bugs with creating the key object of `ThreadContextElement`(singleton be created twice), I change this plugin into bootstrap plugin, It works fine, I will do more test for it, and I will change it to a normal plugin after those test.', 'commenter': 'devkanro'}]"
4165,apm-sniffer/bootstrap-plugins/kotlin-coroutine-plugin/pom.xml,"@@ -0,0 +1,78 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.skywalking</groupId>
+        <artifactId>bootstrap-plugins</artifactId>
+        <version>7.0.0-SNAPSHOT</version>
+    </parent>
+
+    <artifactId>apm-kotlin-coroutine-plugin</artifactId>
+    <name>kotlin-coroutine-plugin</name>
+    <packaging>jar</packaging>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <kotlin.version>1.3.61</kotlin.version>
+        <kotlinx.coroutine.version>1.3.3</kotlinx.coroutine.version>
+        <kotlin.compiler.incremental>true</kotlin.compiler.incremental>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.jetbrains.kotlin</groupId>
+            <artifactId>kotlin-stdlib</artifactId>","[{'comment': 'I meant this, although the name is “stdlib”, but for Java it is not really standard, all the classes/functions in it will cause ClassNotFoundException when users are using vanilla Java', 'commenter': 'kezhenxu94'}, {'comment': 'Yeah, you are right, I assumed people who will use this plugin must be a Kotlin project, I will try to rewrite it in java.', 'commenter': 'devkanro'}]"
4165,apm-sniffer/bootstrap-plugins/kotlin-coroutine-plugin/pom.xml,"@@ -0,0 +1,78 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.skywalking</groupId>
+        <artifactId>bootstrap-plugins</artifactId>","[{'comment': 'Obviously it’s not bootstrap plugin', 'commenter': 'kezhenxu94'}, {'comment': '@wu-sheng has commented it too, I have reply to him, check it.\r\n\r\n>I have another implementation for this plugin, it based on `ThreadContextElement` which is Kotlin coroutine context for syncing thread context, it needs to create interceptor point in `newCoroutineContext`, but I got some bugs with creating the key object of `ThreadContextElement`(singleton be created twice), I change this plugin into bootstrap plugin, It works fine, I will do more test for it, and I will change it to a normal plugin after those test.', 'commenter': 'devkanro'}]"
4165,apm-sniffer/optional-plugins/kotlin-coroutine-plugin/src/main/java/org/apache/skywalking/apm/plugin/kotlin/coroutine/TracingRunnable.java,"@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.kotlin.coroutine;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.ContextSnapshot;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+/**
+ * {@link Runnable} wrapper with trace context snapshot, it will create span
+ * with context snapshot around {@link Runnable} runs.
+ * <p>
+ * A class implementation will be cheaper cost than lambda with captured
+ * variables implementation.
+ */
+class TracingRunnable implements Runnable {
+    private static final String COROUTINE = ""/Kotlin/Coroutine"";
+
+    private ContextSnapshot snapshot;
+    private Runnable delegate;
+    private String tracingId;
+
+    private TracingRunnable(ContextSnapshot snapshot, Runnable delegate, String tracingId) {
+        this.snapshot = snapshot;
+        this.delegate = delegate;
+        this.tracingId = tracingId;
+    }
+
+    private TracingRunnable(ContextSnapshot snapshot, Runnable delegate) {
+        this(snapshot, delegate, ContextManager.getGlobalTraceId());
+    }
+
+    /**
+     * Wrap {@link Runnable} by {@link TracingRunnable} if active trace context
+     * existed.
+     *
+     * @param delegate {@link Runnable} to wrap.
+     *
+     * @return Wrapped {@link TracingRunnable} or original {@link Runnable} if
+     * trace context not existed.
+     */
+    public static Runnable wrapOrNot(Runnable delegate) {
+        // Just wrap continuation with active trace context
+        if (ContextManager.isActive()) {
+            return new TracingRunnable(ContextManager.capture(), delegate);
+        } else {
+            return delegate;
+        }
+    }
+
+    @Override
+    public void run() {
+        if (ContextManager.getGlobalTraceId().equals(tracingId)) {
+            // Trace id same with before dispatching, skip restore snapshot.
+            delegate.run();
+            return;
+        }","[{'comment': 'Do we need it?', 'commenter': 'dmsolr'}, {'comment': 'Sometimes coroutine or suspend function will not switch the thread, we can skip creating a ""/Kotlin/Coroutine"" span for simplifying tracing.', 'commenter': 'devkanro'}, {'comment': 'Please use core API to do this check. `snapshot#isFromCurrent()`. Segment id is more accurate to do thread-switch check', 'commenter': 'wu-sheng'}, {'comment': 'Before doing this, you need to do `ContextManager#isActive`, making sure there is a context activated in the current thread.', 'commenter': 'wu-sheng'}]"
4165,test/plugin/scenarios/kotlin-coroutine-scenario/configuration.yml,"@@ -0,0 +1,22 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+type: jvm
+entryService: http://localhost:8080/kotlin-coroutine-scenario/case/h2
+healthCheck: http://localhost:8080/kotlin-coroutine-scenario/case/healthCheck
+framework: kt-coroutine
+runningMode: with_optional
+withPlugins: apm-kotlin-coroutine-plugin-*.jar","[{'comment': 'missed `startScript: ./bin/startup.sh`', 'commenter': 'kezhenxu94'}]"
4165,test/plugin/scenarios/kotlin-coroutine-scenario/pom.xml,"@@ -0,0 +1,157 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+<project xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xmlns=""http://maven.apache.org/POM/4.0.0""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+
+    <groupId>org.apache.skywalking.apm.testcase</groupId>
+    <artifactId>kotlin-coroutine-scenario</artifactId>
+    <version>1.0.0</version>
+    <packaging>jar</packaging>
+
+    <modelVersion>4.0.0</modelVersion>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <compiler.version>1.8</compiler.version>
+        <os-maven-plugin.version>1.6.2</os-maven-plugin.version>
+
+        <spring-boot-version>2.1.6.RELEASE</spring-boot-version>
+        <kotlin.version>1.3.61</kotlin.version>
+        <kotlinx.coroutine.version>1.3.3</kotlinx.coroutine.version>
+    </properties>
+
+    <name>skywalking-kotlin-coroutine-scenario</name>
+
+    <dependencyManagement>
+        <dependencies>
+            <dependency>
+                <groupId>org.springframework.boot</groupId>
+                <artifactId>spring-boot-dependencies</artifactId>
+                <version>${spring-boot-version}</version>
+                <type>pom</type>
+                <scope>import</scope>
+            </dependency>
+        </dependencies>
+    </dependencyManagement>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.springframework.boot</groupId>
+            <artifactId>spring-boot-starter-web</artifactId>
+            <exclusions>
+                <exclusion>
+                    <groupId>org.springframework.boot</groupId>
+                    <artifactId>spring-boot-starter-logging</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+        <dependency>
+            <groupId>org.springframework.boot</groupId>
+            <artifactId>spring-boot-starter-log4j2</artifactId>
+            <exclusions>
+                <exclusion>
+                    <artifactId>jul-to-slf4j</artifactId>
+                    <groupId>org.slf4j</groupId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+        <dependency>
+            <groupId>com.h2database</groupId>
+            <artifactId>h2</artifactId>
+            <version>1.4.196</version>
+        </dependency>
+        <dependency>
+            <groupId>commons-dbcp</groupId>
+            <artifactId>commons-dbcp</artifactId>
+            <version>1.4</version>
+        </dependency>
+
+        <dependency>
+            <groupId>org.jetbrains.kotlin</groupId>
+            <artifactId>kotlin-stdlib</artifactId>
+            <version>${kotlin.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.jetbrains.kotlinx</groupId>
+            <artifactId>kotlinx-coroutines-core</artifactId>
+            <version>${kotlinx.coroutine.version}</version>
+        </dependency>
+    </dependencies>
+
+    <build>
+        <finalName>kotlin-coroutine-scenario</finalName>
+        <sourceDirectory>${project.basedir}/src/main/kotlin</sourceDirectory>
+        <plugins>
+            <plugin>
+                <groupId>kr.motd.maven</groupId>
+                <artifactId>os-maven-plugin</artifactId>
+                <version>${os-maven-plugin.version}</version>
+                <executions>
+                    <execution>
+                        <phase>initialize</phase>
+                        <goals>
+                            <goal>detect</goal>
+                        </goals>
+                    </execution>
+                </executions>
+            </plugin>","[{'comment': ""You don't need this plugin, instead, you need this, otherwise the packaged jar is not executable:\r\n\r\n```xml\r\n\r\n            <plugin>\r\n                <groupId>org.springframework.boot</groupId>\r\n                <artifactId>spring-boot-maven-plugin</artifactId>\r\n                <version>${spring-boot-version}</version>\r\n                <executions>\r\n                    <execution>\r\n                        <goals>\r\n                            <goal>repackage</goal>\r\n                        </goals>\r\n                    </execution>\r\n                </executions>\r\n            </plugin>\r\n```"", 'commenter': 'kezhenxu94'}]"
4165,test/plugin/scenarios/kotlin-coroutine-scenario/config/expectedData.yaml,"@@ -0,0 +1,121 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+registryItems:
+  applications:
+    - {kotlin-coroutine: nq 0}","[{'comment': '```suggestion\r\n    - {kotlin-coroutine-scenario: nq 0}\r\n```', 'commenter': 'kezhenxu94'}]"
4165,test/plugin/scenarios/kotlin-coroutine-scenario/config/expectedData.yaml,"@@ -0,0 +1,121 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+registryItems:
+  applications:
+    - {kotlin-coroutine: nq 0}
+  instances:
+    - {kotlin-coroutine: 1}","[{'comment': '```suggestion\r\n    - {kotlin-coroutine-scenario: 1}\r\n```', 'commenter': 'kezhenxu94'}]"
4165,docs/en/setup/service-agent/java-agent/agent-optional-plugins/Kotlin-Coroutine-plugin.md,"@@ -0,0 +1,30 @@
+# Skywalking with Kotlin coroutine
+This PR provided an auto instrument support plugin for Kotlin coroutine based on context snapshot.
+
+## Description
+We have known there are some limits with skywalking and coroutine, because of the trace context based on `ThreadLocal`.
+
+But skywalking provided context snapshot for cross-thread tracing, I create this plugin for resolving context losing in Kotlin coroutine.
+
+## Implementation principle
+As we know, Kotlin coroutine switches the execution thread by `CoroutineDispatcher`.
+
+01. Create a snapshot of the current context before dispatch the continuation.
+02. Then create a coroutine span after thread switched, mark the span continued with the snapshot.
+03. Every new span which created in the new thread will be a child of this coroutine span. So we can link those span together in a tracing.
+04. After the original runnable executed, we need to stop the coroutine span for cleaning thread state.
+
+## Some screenshots
+### Run without the plugin
+We run a Kotlin coroutine based gRPC server without this coroutine plugin.  
+You can find, the one call (client -> server1 -> server2) has been split two tracing paths.
+
+01. Server1 without exit span and server2 tracing path.
+![Without kotlin plugin1](https://user-images.githubusercontent.com/9367842/71715581-dd18be80-2e4c-11ea-9316-60937ee2c03d.jpg)
+02. Server2 tracing path.
+![Without kotlin plugin2](https://user-images.githubusercontent.com/9367842/71715588-e0ac4580-2e4c-11ea-95fd-de9d276caefd.jpg)","[{'comment': 'If you want to provide screenshots, you need to host the images in Apache repo. Should create a folder named `7.0.0/kotlin/coroutine` at here https://github.com/apache/skywalking-website/tree/master/docs/.vuepress/public/screenshots\r\n', 'commenter': 'wu-sheng'}, {'comment': 'PR created [#76](https://github.com/apache/skywalking-website/pull/76).', 'commenter': 'devkanro'}]"
4165,docs/en/setup/service-agent/java-agent/agent-optional-plugins/Kotlin-Coroutine-plugin.md,"@@ -0,0 +1,30 @@
+# Skywalking with Kotlin coroutine","[{'comment': 'As an optional plugin, this doc should be linked from https://github.com/apache/skywalking/blob/master/docs/en/setup/service-agent/java-agent/README.md#optional-plugins', 'commenter': 'wu-sheng'}]"
4165,test/plugin/scenarios/kotlin-coroutine-scenario/support-version.list,"@@ -0,0 +1,16 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+1.3.0","[{'comment': 'Is only 1.3.0 supported? Or 1.3.x, or 1.0+?\r\n\r\nAccording to the central repo, there are many coroutine releases, https://mvnrepository.com/artifact/org.jetbrains.kotlinx/kotlinx-coroutines-core. We should set the boundary clear.', 'commenter': 'wu-sheng'}, {'comment': 'Maybe 1.0+, Should I list all versions in this file?\r\nLike:\r\n```\r\n1.3.3\r\n1.3.2\r\n1.3.1\r\n1.3.0\r\n# versions\r\n1.1.0\r\n1.0.1\r\n1.0.0\r\n```\r\n\r\nOr just major version\r\n```\r\n1.3.0\r\n1.2.0\r\n1.1.0\r\n1.0.0\r\n```', 'commenter': 'devkanro'}, {'comment': 'I think at least for the latest of every major release version, such as 1.3.3 for 1.3.x', 'commenter': 'wu-sheng'}, {'comment': 'I am not sure about is lastest Kotlin version compatible with every Kotlin Coroutine version.', 'commenter': 'devkanro'}, {'comment': 'Test passed, it seems to look fine', 'commenter': 'devkanro'}]"
4165,docs/en/setup/service-agent/java-agent/Supported-list.md,"@@ -86,6 +86,8 @@
   * [Spring @Async](https://github.com/spring-projects/spring-framework) 4.x and 5.x
 * Cache
   * [Ehcache](https://www.ehcache.org/) 2.x
+* Kotlin
+  * [Coroutine](https://kotlinlang.org/docs/reference/coroutines-overview.html) 1.3.x (Optional²)","[{'comment': 'You miss this update.', 'commenter': 'wu-sheng'}]"
4165,docs/en/setup/service-agent/java-agent/agent-optional-plugins/Kotlin-Coroutine-plugin.md,"@@ -0,0 +1,30 @@
+# Skywalking with Kotlin coroutine
+This PR provided an auto instrument support plugin for Kotlin coroutine based on context snapshot.","[{'comment': 'This plugin, not PR', 'commenter': 'wu-sheng'}, {'comment': 'Provided to provides', 'commenter': 'wu-sheng'}]"
4165,docs/en/setup/service-agent/java-agent/agent-optional-plugins/Kotlin-Coroutine-plugin.md,"@@ -0,0 +1,30 @@
+# Skywalking with Kotlin coroutine
+This PR provided an auto instrument support plugin for Kotlin coroutine based on context snapshot.
+
+## Description
+We have known there are some limits with skywalking and coroutine, because of the trace context based on `ThreadLocal`.
+
+But skywalking provided context snapshot for cross-thread tracing, I create this plugin for resolving context losing in Kotlin coroutine.
+
+## Implementation principle
+As we know, Kotlin coroutine switches the execution thread by `CoroutineDispatcher`.
+
+01. Create a snapshot of the current context before dispatch the continuation.
+02. Then create a coroutine span after thread switched, mark the span continued with the snapshot.
+03. Every new span which created in the new thread will be a child of this coroutine span. So we can link those span together in a tracing.
+04. After the original runnable executed, we need to stop the coroutine span for cleaning thread state.
+
+## Some screenshots
+### Run without the plugin
+We run a Kotlin coroutine based gRPC server without this coroutine plugin.  
+You can find, the one call (client -> server1 -> server2) has been split two tracing paths.
+
+01. Server1 without exit span and server2 tracing path.
+![Without kotlin plugin1](http://skywalking.apache.org/screenshots/7.0.0/kotlin/coroutine/without-coroutine-plugin-server1.jpg)
+02. Server2 tracing path.
+![Without kotlin plugin2](http://skywalking.apache.org/screenshots/7.0.0/kotlin/coroutine/without-coroutine-plugin-server2.jpg)
+
+### Run with the plugin
+With no business code changed, just install the plugin. We can find the tracing paths be connected together. We can get all info of one client call.","[{'comment': '1. With no -> Without\r\n1. Business code changed -> changing codes manually.\r\n1. Tracing path -> spans', 'commenter': 'wu-sheng'}]"
4165,docs/en/setup/service-agent/java-agent/README.md,"@@ -135,6 +135,7 @@ Now, we have the following known optional plugins.
 * [Customize enhance](Customize-enhance-trace.md) Trace methods based on description files, rather than write plugin or change source codes.
 * Plugin of Spring Cloud Gateway 2.1.x in optional plugin folder. Please only active this plugin when you install agent in Spring Gateway. spring-cloud-gateway-2.x-plugin and spring-webflux-5.x-plugin are both required.
 * Plugin of Spring Transaction in optional plugin folder. The reason of being optional plugin is, many local span are generated, which also spend more CPU, memory and network.
+* [Plugin of Kotlin coroutine](agent-optional-plugins/Kotlin-Coroutine-plugin.md)","[{'comment': 'We need to add the reason of optional plugin.\r\n\r\nPlugin of Kotlin coroutine provides the tracing across coroutines automatically. As it will add local spans to all across routines scenarios, Please assess the performance impact.', 'commenter': 'wu-sheng'}]"
4165,docs/en/setup/service-agent/java-agent/agent-optional-plugins/Kotlin-Coroutine-plugin.md,"@@ -0,0 +1,30 @@
+# Skywalking with Kotlin coroutine
+This PR provided an auto instrument support plugin for Kotlin coroutine based on context snapshot.
+
+## Description","[{'comment': 'Description official document should like\r\n\r\nSkyWalking provide tracing context propagation inside thread. In order to support Kotlin Coroutine, we provide this additional plugin.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -148,6 +148,31 @@
          * If true, skywalking agent will enable profile when user create a new profile task. Otherwise disable profile.
          */
         public static boolean ACTIVE = true;
+
+        /**
+         * Parallel monitor segment thread count
+         */
+        public static int PARALLELS_THREAD_COUNT = 5;
+
+        /**
+         * Max monitor segment time(minutes), if current segment monitor time out of limit, then stop it.
+         */
+        public static int MAX_MONITOR_TIME = 10;","[{'comment': '`MAX_MONITOR_TIME` -> `MAX_DURATION`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -148,6 +148,31 @@
          * If true, skywalking agent will enable profile when user create a new profile task. Otherwise disable profile.
          */
         public static boolean ACTIVE = true;
+
+        /**
+         * Parallel monitor segment thread count
+         */
+        public static int PARALLELS_THREAD_COUNT = 5;
+
+        /**
+         * Max monitor segment time(minutes), if current segment monitor time out of limit, then stop it.
+         */
+        public static int MAX_MONITOR_TIME = 10;
+
+        /**
+         * Max dump thread stack depth
+         */
+        public static int MAX_DUMP_STACK_DEPTH = 500;","[{'comment': '`MAX_DUMP_STACK_DEPTH` -> `DUMP_MAX_STACK_DEPTH`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -148,6 +148,31 @@
          * If true, skywalking agent will enable profile when user create a new profile task. Otherwise disable profile.
          */
         public static boolean ACTIVE = true;
+
+        /**
+         * Parallel monitor segment thread count
+         */
+        public static int PARALLELS_THREAD_COUNT = 5;
+
+        /**
+         * Max monitor segment time(minutes), if current segment monitor time out of limit, then stop it.
+         */
+        public static int MAX_MONITOR_TIME = 10;
+
+        /**
+         * Max dump thread stack depth
+         */
+        public static int MAX_DUMP_STACK_DEPTH = 500;
+
+        /**
+         * Snapshot send to backend channel size
+         */
+        public static int SNAPSHOT_SEND_CHANNEL_SIZE = 2;","[{'comment': '`SEND` -> `TRANSPORT`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -148,6 +148,31 @@
          * If true, skywalking agent will enable profile when user create a new profile task. Otherwise disable profile.
          */
         public static boolean ACTIVE = true;
+
+        /**
+         * Parallel monitor segment thread count
+         */
+        public static int PARALLELS_THREAD_COUNT = 5;
+
+        /**
+         * Max monitor segment time(minutes), if current segment monitor time out of limit, then stop it.
+         */
+        public static int MAX_MONITOR_TIME = 10;
+
+        /**
+         * Max dump thread stack depth
+         */
+        public static int MAX_DUMP_STACK_DEPTH = 500;
+
+        /**
+         * Snapshot send to backend channel size
+         */
+        public static int SNAPSHOT_SEND_CHANNEL_SIZE = 2;
+
+        /**
+         * Snapshot send to backend buffer size
+         */
+        public static int SNAPSHOT_SEND_BUFFER_SIZE = 50;","[{'comment': 'Same about the name. And is 50 enough? From my understanding, we do thread dump every 10ms, then we could have 100 in one second. I think as we could collect 5 parallel, you will highly trigger queue abandon mode easily. \r\nI suggest at least 5 * 500. @kezhenxu94 What do you think? ', 'commenter': 'wu-sheng'}, {'comment': ""Change to only one thread to process the profile task. So don't use `DataCarrier` anymore. Change to using `LinkedBlockingQueue` such as sniffer `JVMService`. using buffer size 500."", 'commenter': 'mrproliu'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/AbstractTracerContext.java,"@@ -115,4 +115,10 @@
      * @param span to be stopped.
      */
     void asyncStop(AsyncSpan span);
+
+    /**
+     * Check current creating operation can add profiling, if true, it will start profiling","[{'comment': '-> `Check whether the new segment suitable for profiling.`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/AbstractTracerContext.java,"@@ -115,4 +115,10 @@
      * @param span to be stopped.
      */
     void asyncStop(AsyncSpan span);
+
+    /**
+     * Check current creating operation can add profiling, if true, it will start profiling
+     * @param operationName
+     */
+    void checkAndAddProfiling(String operationName);","[{'comment': 'Rename to `prepareProfiling(String firstSpanOPName)`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -148,6 +148,31 @@
          * If true, skywalking agent will enable profile when user create a new profile task. Otherwise disable profile.
          */
         public static boolean ACTIVE = true;
+
+        /**
+         * Parallel monitor segment thread count
+         */
+        public static int PARALLELS_THREAD_COUNT = 5;","[{'comment': '`PARALLELS_THREAD_COUNT` -> `MAX_PARALLEL`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskExecutionService.java,"@@ -84,6 +95,33 @@ public void run() {
         }, timeToProcessMills, TimeUnit.MILLISECONDS);
     }
 
+    /**
+     * check and add {@link TraceSegment} profiling
+     * @param segment
+     * @param operationName
+     * @return has add to profiling
+     */
+    public boolean addProfiling(TraceSegment segment, String operationName) {
+        // get current monitoring task and check endpoint name, is need profiling
+        final ProfileTaskExecutionContext executionContext = taskExecutionContext.get();
+        if (executionContext == null) {
+            return false;
+        }
+        if (!Objects.equal(executionContext.getTask().getEndpointName(), operationName)) {
+            return false;
+        }
+
+        // check has slot to add
+        final ProfilingThread profilingThread = PROFILING_THREADS[PROFILING_THREAD_SELECTOR.getAndIncrement()];","[{'comment': 'Using PROFILING_THREAD_SELECTOR as index, I assume there is out of bound risk.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskExecutionService.java,"@@ -38,13 +45,17 @@
  * @author MrPro
  */
 @DefaultImplementor
-public class ProfileTaskExecutionService implements BootService {
+public class ProfileTaskExecutionService implements BootService, TracingContextListener {
 
     private static final ILog logger = LogManager.getLogger(ProfileTaskExecutionService.class);
 
     // add a schedule while waiting for the task to start or finish
     private final static ScheduledExecutorService PROFILE_TASK_SCHEDULE = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""PROFILE-TASK-SCHEDULE""));
 
+    // profiling segment thread array, Config.Profile.PARALLELS_THREAD_COUNT
+    private final static ProfilingThread[] PROFILING_THREADS = new ProfilingThread[Config.Profile.PARALLELS_THREAD_COUNT];","[{'comment': ""Are you creating so many threads for profiling tasks? I prefer to do this by using only one thread only. And don't create and dispose the thread every time. This is dangerous for JVM from my understanding. @kezhenxu94 @arugal what do you think?"", 'commenter': 'wu-sheng'}, {'comment': 'Change profile using the single one thread to process. Please check.', 'commenter': 'mrproliu'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskChannelService.java,"@@ -0,0 +1,245 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import io.grpc.Channel;
+import io.grpc.Status;
+import io.grpc.StatusRuntimeException;
+import io.grpc.stub.StreamObserver;
+import org.apache.skywalking.apm.agent.core.boot.BootService;
+import org.apache.skywalking.apm.agent.core.boot.DefaultImplementor;
+import org.apache.skywalking.apm.agent.core.boot.DefaultNamedThreadFactory;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.commands.CommandService;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.*;
+import org.apache.skywalking.apm.network.common.Commands;
+import org.apache.skywalking.apm.network.language.agent.Downstream;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskCommandQuery;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskFinishReport;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskGrpc;
+import org.apache.skywalking.apm.util.RunnableWithExceptionProtection;
+
+import java.util.LinkedList;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Collector.GRPC_UPSTREAM_TIMEOUT;
+
+/**
+ * Sniffer and backend, about the communication service of profile task protocol.
+ * 1. Sniffer will check has new profile task list every {@link Config.Collector#GET_PROFILE_TASK_INTERVAL} second.
+ * 2. When there is a new profile task snapshot, the data is transferred to the back end. use {@link LinkedBlockingQueue}
+ * 3. When profiling task finish, it will send task finish status to backend
+ *
+ * @author MrPro
+ */
+@DefaultImplementor
+public class ProfileTaskChannelService implements BootService, Runnable, GRPCChannelListener {
+    private static final ILog logger = LogManager.getLogger(ProfileTaskChannelService.class);
+
+    // channel status
+    private volatile GRPCChannelStatus status = GRPCChannelStatus.DISCONNECT;
+
+    // gRPC stub
+    private volatile ProfileTaskGrpc.ProfileTaskBlockingStub profileTaskBlockingStub;
+    private volatile ProfileTaskGrpc.ProfileTaskStub profileTaskStub;
+
+    // segment snapshot sender
+    private final LinkedBlockingQueue<ProfileTaskSegmentSnapshot> snapshotQueue = new LinkedBlockingQueue<>(Config.Profile.SNAPSHOT_TRANSPORT_BUFFER_SIZE);
+    private volatile ScheduledFuture<?> sendSnapshotFuture;
+
+    // query task list schedule
+    private volatile ScheduledFuture<?> getTaskListFuture;
+
+    @Override
+    public void run() {
+        if (RemoteDownstreamConfig.Agent.SERVICE_ID != DictionaryUtil.nullValue()
+                && RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID != DictionaryUtil.nullValue()
+        ) {
+            if (status == GRPCChannelStatus.CONNECTED) {
+                try {
+                    ProfileTaskCommandQuery.Builder builder = ProfileTaskCommandQuery.newBuilder();
+
+                    // sniffer info
+                    builder.setServiceId(RemoteDownstreamConfig.Agent.SERVICE_ID).setInstanceId(RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID);
+
+                    // last command create time
+                    builder.setLastCommandTime(ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class).getLastCommandCreateTime());
+
+                    Commands commands = profileTaskBlockingStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).getProfileTaskCommands(builder.build());
+                    ServiceManager.INSTANCE.findService(CommandService.class).receiveCommand(commands);
+                } catch (Throwable t) {
+                    if (!(t instanceof StatusRuntimeException)) {
+                        logger.error(t, ""Query profile task from backend fail."");
+                        return;
+                    }
+                    final StatusRuntimeException statusRuntimeException = (StatusRuntimeException) t;
+                    if (statusRuntimeException.getStatus().getCode() == Status.Code.UNIMPLEMENTED) {
+                        logger.warn(""Backend doesn't support profiling, profiling will be disabled"");
+                        if (getTaskListFuture != null) {
+                            getTaskListFuture.cancel(true);
+                        }
+
+                        // stop snapshot sender
+                        if (sendSnapshotFuture != null) {
+                            sendSnapshotFuture.cancel(true);
+                        }
+                    }
+                }
+            }
+        }
+
+    }
+
+    @Override
+    public void prepare() throws Throwable {
+        ServiceManager.INSTANCE.findService(GRPCChannelManager.class).addChannelListener(this);
+    }
+
+    @Override
+    public void boot() throws Throwable {
+        if (Config.Profile.ACTIVE) {
+            // query task list
+            getTaskListFuture = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""ProfileGetTaskService""))
+                    .scheduleWithFixedDelay(new RunnableWithExceptionProtection(this, new RunnableWithExceptionProtection.CallbackWhenException() {
+                        @Override
+                        public void handle(Throwable t) {
+                            logger.error(""Query profile task list failure."", t);
+                        }
+                    }), 0, Config.Collector.GET_PROFILE_TASK_INTERVAL, TimeUnit.SECONDS);
+
+            sendSnapshotFuture = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""ProfileSendSnapshotService""))
+                    .scheduleWithFixedDelay(new RunnableWithExceptionProtection(new SnapshotSender(), new RunnableWithExceptionProtection.CallbackWhenException() {
+                        @Override public void handle(Throwable t) {
+                            logger.error(""Profile segment snapshot upload failure."", t);
+                        }
+                    }), 0, 500, TimeUnit.MILLISECONDS);
+        }
+    }
+
+    @Override
+    public void onComplete() throws Throwable {
+    }
+
+    @Override
+    public void shutdown() throws Throwable {
+        if (getTaskListFuture != null) {
+            getTaskListFuture.cancel(true);
+        }
+
+        if (sendSnapshotFuture != null) {
+            sendSnapshotFuture.cancel(true);
+        }
+    }
+
+    @Override
+    public void statusChanged(GRPCChannelStatus status) {
+        if (GRPCChannelStatus.CONNECTED.equals(status)) {
+            Channel channel = ServiceManager.INSTANCE.findService(GRPCChannelManager.class).getChannel();
+            profileTaskBlockingStub = ProfileTaskGrpc.newBlockingStub(channel);
+            profileTaskStub = ProfileTaskGrpc.newStub(channel);
+        } else {
+            profileTaskBlockingStub = null;
+            profileTaskStub = null;
+        }
+        this.status = status;
+    }
+
+    /**
+     * add a new profiling snapshot, send to {@link #snapshotQueue}
+     * @param snapshot
+     */
+    public void addProfilingSnapshot(ProfileTaskSegmentSnapshot snapshot) {
+        snapshotQueue.add(snapshot);
+    }
+
+    /**
+     * notify backend profile task has finish
+     * @param task
+     */
+    public void notifyProfileTaskFinish(ProfileTask task) {
+        try {
+            final ProfileTaskFinishReport.Builder reportBuilder = ProfileTaskFinishReport.newBuilder();
+            // sniffer info
+            reportBuilder.setServiceId(RemoteDownstreamConfig.Agent.SERVICE_ID).setInstanceId(RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID);
+            // task info
+            reportBuilder.setTaskId(task.getTaskId());
+
+            // send data
+            profileTaskBlockingStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).reportTaskFinish(reportBuilder.build());
+        } catch (Throwable e) {
+            logger.error(e, ""Notify profile task finish to backend fail."");
+        }
+    }
+
+    /**
+     * send segment snapshot
+     */
+    private class SnapshotSender implements Runnable {
+
+        @Override
+        public void run() {
+            if (status == GRPCChannelStatus.CONNECTED) {
+                try {
+                    LinkedList<ProfileTaskSegmentSnapshot> buffer = new LinkedList<ProfileTaskSegmentSnapshot>();
+                    snapshotQueue.drainTo(buffer);
+                    if (buffer.size() > 0) {
+                        final GRPCStreamServiceStatus status = new GRPCStreamServiceStatus(false);
+                        StreamObserver<org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentSnapshot> snapshotStreamObserver = profileTaskStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).collectSnapshot(new StreamObserver<Downstream>() {","[{'comment': 'Why use full class name?', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskChannelService.java,"@@ -0,0 +1,245 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import io.grpc.Channel;
+import io.grpc.Status;
+import io.grpc.StatusRuntimeException;
+import io.grpc.stub.StreamObserver;
+import org.apache.skywalking.apm.agent.core.boot.BootService;
+import org.apache.skywalking.apm.agent.core.boot.DefaultImplementor;
+import org.apache.skywalking.apm.agent.core.boot.DefaultNamedThreadFactory;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.commands.CommandService;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.*;
+import org.apache.skywalking.apm.network.common.Commands;
+import org.apache.skywalking.apm.network.language.agent.Downstream;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskCommandQuery;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskFinishReport;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskGrpc;
+import org.apache.skywalking.apm.util.RunnableWithExceptionProtection;
+
+import java.util.LinkedList;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Collector.GRPC_UPSTREAM_TIMEOUT;
+
+/**
+ * Sniffer and backend, about the communication service of profile task protocol.
+ * 1. Sniffer will check has new profile task list every {@link Config.Collector#GET_PROFILE_TASK_INTERVAL} second.
+ * 2. When there is a new profile task snapshot, the data is transferred to the back end. use {@link LinkedBlockingQueue}
+ * 3. When profiling task finish, it will send task finish status to backend
+ *
+ * @author MrPro
+ */
+@DefaultImplementor
+public class ProfileTaskChannelService implements BootService, Runnable, GRPCChannelListener {
+    private static final ILog logger = LogManager.getLogger(ProfileTaskChannelService.class);
+
+    // channel status
+    private volatile GRPCChannelStatus status = GRPCChannelStatus.DISCONNECT;
+
+    // gRPC stub
+    private volatile ProfileTaskGrpc.ProfileTaskBlockingStub profileTaskBlockingStub;
+    private volatile ProfileTaskGrpc.ProfileTaskStub profileTaskStub;
+
+    // segment snapshot sender
+    private final LinkedBlockingQueue<ProfileTaskSegmentSnapshot> snapshotQueue = new LinkedBlockingQueue<>(Config.Profile.SNAPSHOT_TRANSPORT_BUFFER_SIZE);
+    private volatile ScheduledFuture<?> sendSnapshotFuture;
+
+    // query task list schedule
+    private volatile ScheduledFuture<?> getTaskListFuture;
+
+    @Override
+    public void run() {
+        if (RemoteDownstreamConfig.Agent.SERVICE_ID != DictionaryUtil.nullValue()
+                && RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID != DictionaryUtil.nullValue()
+        ) {
+            if (status == GRPCChannelStatus.CONNECTED) {
+                try {
+                    ProfileTaskCommandQuery.Builder builder = ProfileTaskCommandQuery.newBuilder();
+
+                    // sniffer info
+                    builder.setServiceId(RemoteDownstreamConfig.Agent.SERVICE_ID).setInstanceId(RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID);
+
+                    // last command create time
+                    builder.setLastCommandTime(ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class).getLastCommandCreateTime());
+
+                    Commands commands = profileTaskBlockingStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).getProfileTaskCommands(builder.build());
+                    ServiceManager.INSTANCE.findService(CommandService.class).receiveCommand(commands);
+                } catch (Throwable t) {
+                    if (!(t instanceof StatusRuntimeException)) {
+                        logger.error(t, ""Query profile task from backend fail."");
+                        return;
+                    }
+                    final StatusRuntimeException statusRuntimeException = (StatusRuntimeException) t;
+                    if (statusRuntimeException.getStatus().getCode() == Status.Code.UNIMPLEMENTED) {
+                        logger.warn(""Backend doesn't support profiling, profiling will be disabled"");
+                        if (getTaskListFuture != null) {
+                            getTaskListFuture.cancel(true);
+                        }
+
+                        // stop snapshot sender
+                        if (sendSnapshotFuture != null) {
+                            sendSnapshotFuture.cancel(true);
+                        }
+                    }
+                }
+            }
+        }
+
+    }
+
+    @Override
+    public void prepare() throws Throwable {
+        ServiceManager.INSTANCE.findService(GRPCChannelManager.class).addChannelListener(this);
+    }
+
+    @Override
+    public void boot() throws Throwable {
+        if (Config.Profile.ACTIVE) {
+            // query task list
+            getTaskListFuture = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""ProfileGetTaskService""))
+                    .scheduleWithFixedDelay(new RunnableWithExceptionProtection(this, new RunnableWithExceptionProtection.CallbackWhenException() {
+                        @Override
+                        public void handle(Throwable t) {
+                            logger.error(""Query profile task list failure."", t);
+                        }
+                    }), 0, Config.Collector.GET_PROFILE_TASK_INTERVAL, TimeUnit.SECONDS);
+
+            sendSnapshotFuture = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""ProfileSendSnapshotService""))
+                    .scheduleWithFixedDelay(new RunnableWithExceptionProtection(new SnapshotSender(), new RunnableWithExceptionProtection.CallbackWhenException() {
+                        @Override public void handle(Throwable t) {
+                            logger.error(""Profile segment snapshot upload failure."", t);
+                        }
+                    }), 0, 500, TimeUnit.MILLISECONDS);
+        }
+    }
+
+    @Override
+    public void onComplete() throws Throwable {
+    }
+
+    @Override
+    public void shutdown() throws Throwable {
+        if (getTaskListFuture != null) {
+            getTaskListFuture.cancel(true);
+        }
+
+        if (sendSnapshotFuture != null) {
+            sendSnapshotFuture.cancel(true);
+        }
+    }
+
+    @Override
+    public void statusChanged(GRPCChannelStatus status) {
+        if (GRPCChannelStatus.CONNECTED.equals(status)) {
+            Channel channel = ServiceManager.INSTANCE.findService(GRPCChannelManager.class).getChannel();
+            profileTaskBlockingStub = ProfileTaskGrpc.newBlockingStub(channel);
+            profileTaskStub = ProfileTaskGrpc.newStub(channel);
+        } else {
+            profileTaskBlockingStub = null;
+            profileTaskStub = null;
+        }
+        this.status = status;
+    }
+
+    /**
+     * add a new profiling snapshot, send to {@link #snapshotQueue}
+     * @param snapshot
+     */
+    public void addProfilingSnapshot(ProfileTaskSegmentSnapshot snapshot) {
+        snapshotQueue.add(snapshot);
+    }
+
+    /**
+     * notify backend profile task has finish
+     * @param task
+     */
+    public void notifyProfileTaskFinish(ProfileTask task) {
+        try {
+            final ProfileTaskFinishReport.Builder reportBuilder = ProfileTaskFinishReport.newBuilder();
+            // sniffer info
+            reportBuilder.setServiceId(RemoteDownstreamConfig.Agent.SERVICE_ID).setInstanceId(RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID);
+            // task info
+            reportBuilder.setTaskId(task.getTaskId());
+
+            // send data
+            profileTaskBlockingStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).reportTaskFinish(reportBuilder.build());
+        } catch (Throwable e) {
+            logger.error(e, ""Notify profile task finish to backend fail."");
+        }
+    }
+
+    /**
+     * send segment snapshot
+     */
+    private class SnapshotSender implements Runnable {
+
+        @Override
+        public void run() {
+            if (status == GRPCChannelStatus.CONNECTED) {
+                try {
+                    LinkedList<ProfileTaskSegmentSnapshot> buffer = new LinkedList<ProfileTaskSegmentSnapshot>();
+                    snapshotQueue.drainTo(buffer);
+                    if (buffer.size() > 0) {
+                        final GRPCStreamServiceStatus status = new GRPCStreamServiceStatus(false);
+                        StreamObserver<org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentSnapshot> snapshotStreamObserver = profileTaskStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).collectSnapshot(new StreamObserver<Downstream>() {
+                            @Override
+                            public void onNext(Downstream downstream) {
+                            }
+
+                            @Override
+                            public void onError(Throwable throwable) {
+                                status.finished();
+                                if (logger.isErrorEnable()) {
+                                    logger.error(throwable, ""Send profile segment snapshot to collector fail with a grpc internal exception."");
+                                }
+                                ServiceManager.INSTANCE.findService(GRPCChannelManager.class).reportError(throwable);
+                            }
+
+                            @Override
+                            public void onCompleted() {
+                                status.finished();
+                            }
+                        });
+                        for (ProfileTaskSegmentSnapshot snapshot : buffer) {
+                            final org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentSnapshot transformSnapshot = snapshot.transform();","[{'comment': 'Same here.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskChannelService.java,"@@ -0,0 +1,245 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import io.grpc.Channel;
+import io.grpc.Status;
+import io.grpc.StatusRuntimeException;
+import io.grpc.stub.StreamObserver;
+import org.apache.skywalking.apm.agent.core.boot.BootService;
+import org.apache.skywalking.apm.agent.core.boot.DefaultImplementor;
+import org.apache.skywalking.apm.agent.core.boot.DefaultNamedThreadFactory;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.commands.CommandService;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.conf.RemoteDownstreamConfig;
+import org.apache.skywalking.apm.agent.core.dictionary.DictionaryUtil;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.remote.*;
+import org.apache.skywalking.apm.network.common.Commands;
+import org.apache.skywalking.apm.network.language.agent.Downstream;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskCommandQuery;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskFinishReport;
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskGrpc;
+import org.apache.skywalking.apm.util.RunnableWithExceptionProtection;
+
+import java.util.LinkedList;
+import java.util.concurrent.Executors;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.ScheduledFuture;
+import java.util.concurrent.TimeUnit;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Collector.GRPC_UPSTREAM_TIMEOUT;
+
+/**
+ * Sniffer and backend, about the communication service of profile task protocol.
+ * 1. Sniffer will check has new profile task list every {@link Config.Collector#GET_PROFILE_TASK_INTERVAL} second.
+ * 2. When there is a new profile task snapshot, the data is transferred to the back end. use {@link LinkedBlockingQueue}
+ * 3. When profiling task finish, it will send task finish status to backend
+ *
+ * @author MrPro
+ */
+@DefaultImplementor
+public class ProfileTaskChannelService implements BootService, Runnable, GRPCChannelListener {
+    private static final ILog logger = LogManager.getLogger(ProfileTaskChannelService.class);
+
+    // channel status
+    private volatile GRPCChannelStatus status = GRPCChannelStatus.DISCONNECT;
+
+    // gRPC stub
+    private volatile ProfileTaskGrpc.ProfileTaskBlockingStub profileTaskBlockingStub;
+    private volatile ProfileTaskGrpc.ProfileTaskStub profileTaskStub;
+
+    // segment snapshot sender
+    private final LinkedBlockingQueue<ProfileTaskSegmentSnapshot> snapshotQueue = new LinkedBlockingQueue<>(Config.Profile.SNAPSHOT_TRANSPORT_BUFFER_SIZE);
+    private volatile ScheduledFuture<?> sendSnapshotFuture;
+
+    // query task list schedule
+    private volatile ScheduledFuture<?> getTaskListFuture;
+
+    @Override
+    public void run() {
+        if (RemoteDownstreamConfig.Agent.SERVICE_ID != DictionaryUtil.nullValue()
+                && RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID != DictionaryUtil.nullValue()
+        ) {
+            if (status == GRPCChannelStatus.CONNECTED) {
+                try {
+                    ProfileTaskCommandQuery.Builder builder = ProfileTaskCommandQuery.newBuilder();
+
+                    // sniffer info
+                    builder.setServiceId(RemoteDownstreamConfig.Agent.SERVICE_ID).setInstanceId(RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID);
+
+                    // last command create time
+                    builder.setLastCommandTime(ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class).getLastCommandCreateTime());
+
+                    Commands commands = profileTaskBlockingStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).getProfileTaskCommands(builder.build());
+                    ServiceManager.INSTANCE.findService(CommandService.class).receiveCommand(commands);
+                } catch (Throwable t) {
+                    if (!(t instanceof StatusRuntimeException)) {
+                        logger.error(t, ""Query profile task from backend fail."");
+                        return;
+                    }
+                    final StatusRuntimeException statusRuntimeException = (StatusRuntimeException) t;
+                    if (statusRuntimeException.getStatus().getCode() == Status.Code.UNIMPLEMENTED) {
+                        logger.warn(""Backend doesn't support profiling, profiling will be disabled"");
+                        if (getTaskListFuture != null) {
+                            getTaskListFuture.cancel(true);
+                        }
+
+                        // stop snapshot sender
+                        if (sendSnapshotFuture != null) {
+                            sendSnapshotFuture.cancel(true);
+                        }
+                    }
+                }
+            }
+        }
+
+    }
+
+    @Override
+    public void prepare() throws Throwable {
+        ServiceManager.INSTANCE.findService(GRPCChannelManager.class).addChannelListener(this);
+    }
+
+    @Override
+    public void boot() throws Throwable {
+        if (Config.Profile.ACTIVE) {
+            // query task list
+            getTaskListFuture = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""ProfileGetTaskService""))
+                    .scheduleWithFixedDelay(new RunnableWithExceptionProtection(this, new RunnableWithExceptionProtection.CallbackWhenException() {
+                        @Override
+                        public void handle(Throwable t) {
+                            logger.error(""Query profile task list failure."", t);
+                        }
+                    }), 0, Config.Collector.GET_PROFILE_TASK_INTERVAL, TimeUnit.SECONDS);
+
+            sendSnapshotFuture = Executors.newSingleThreadScheduledExecutor(new DefaultNamedThreadFactory(""ProfileSendSnapshotService""))
+                    .scheduleWithFixedDelay(new RunnableWithExceptionProtection(new SnapshotSender(), new RunnableWithExceptionProtection.CallbackWhenException() {
+                        @Override public void handle(Throwable t) {
+                            logger.error(""Profile segment snapshot upload failure."", t);
+                        }
+                    }), 0, 500, TimeUnit.MILLISECONDS);
+        }
+    }
+
+    @Override
+    public void onComplete() throws Throwable {
+    }
+
+    @Override
+    public void shutdown() throws Throwable {
+        if (getTaskListFuture != null) {
+            getTaskListFuture.cancel(true);
+        }
+
+        if (sendSnapshotFuture != null) {
+            sendSnapshotFuture.cancel(true);
+        }
+    }
+
+    @Override
+    public void statusChanged(GRPCChannelStatus status) {
+        if (GRPCChannelStatus.CONNECTED.equals(status)) {
+            Channel channel = ServiceManager.INSTANCE.findService(GRPCChannelManager.class).getChannel();
+            profileTaskBlockingStub = ProfileTaskGrpc.newBlockingStub(channel);
+            profileTaskStub = ProfileTaskGrpc.newStub(channel);
+        } else {
+            profileTaskBlockingStub = null;
+            profileTaskStub = null;
+        }
+        this.status = status;
+    }
+
+    /**
+     * add a new profiling snapshot, send to {@link #snapshotQueue}
+     * @param snapshot
+     */
+    public void addProfilingSnapshot(ProfileTaskSegmentSnapshot snapshot) {
+        snapshotQueue.add(snapshot);
+    }
+
+    /**
+     * notify backend profile task has finish
+     * @param task
+     */
+    public void notifyProfileTaskFinish(ProfileTask task) {
+        try {
+            final ProfileTaskFinishReport.Builder reportBuilder = ProfileTaskFinishReport.newBuilder();
+            // sniffer info
+            reportBuilder.setServiceId(RemoteDownstreamConfig.Agent.SERVICE_ID).setInstanceId(RemoteDownstreamConfig.Agent.SERVICE_INSTANCE_ID);
+            // task info
+            reportBuilder.setTaskId(task.getTaskId());
+
+            // send data
+            profileTaskBlockingStub.withDeadlineAfter(GRPC_UPSTREAM_TIMEOUT, TimeUnit.SECONDS).reportTaskFinish(reportBuilder.build());
+        } catch (Throwable e) {
+            logger.error(e, ""Notify profile task finish to backend fail."");
+        }
+    }
+
+    /**
+     * send segment snapshot
+     */
+    private class SnapshotSender implements Runnable {
+
+        @Override
+        public void run() {
+            if (status == GRPCChannelStatus.CONNECTED) {
+                try {
+                    LinkedList<ProfileTaskSegmentSnapshot> buffer = new LinkedList<ProfileTaskSegmentSnapshot>();","[{'comment': 'You have known the max size, using ArrayList please.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);","[{'comment': ""Don't use `Config.Profile.MAX_DURATION` in the initial codes. Move this initialization into the constructor. Because there may be a chance, someone accidentally loads this class before Config initialization."", 'commenter': 'wu-sheng'}, {'comment': ""Don't use `Config.Profile.MAX_DURATION` in the initial codes. Move this initialization into the constructor. Because there may be a chance, someone accidentally loads this class before Config initialization."", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskExecutionService.java,"@@ -108,36 +139,49 @@ public void run() {
     /**
      * stop profile task, remove context data
      */
-    private synchronized void stopCurrentProfileTask(ProfileTaskExecutionContext needToStop) {
+    synchronized void stopCurrentProfileTask(ProfileTaskExecutionContext needToStop) {
         // stop same context only
         if (needToStop == null || !taskExecutionContext.compareAndSet(needToStop, null)) {
             return;
         }
 
+        // current execution stop running
+        needToStop.setRunning(false);
+
         // remove task
         profileTaskList.remove(needToStop.getTask());
 
-        // TODO notify OAP current profile task execute finish
+        // notify profiling task has finished
+        ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class).notifyProfileTaskFinish(needToStop.getTask());
     }
 
     @Override
     public void prepare() throws Throwable {
-
     }
 
     @Override
     public void boot() throws Throwable {
-
+        // init PROFILE_THREAD and start
+        profileThread = new ProfileThread();
+        profileThread.setDaemon(true);
+        profileThread.setName(""PROFILE-MONITOR-THREAD"");","[{'comment': ""`PROFILE-MONITOR-THREAD` -> `PROFILING-THREAD` . We don't use the word `monitor`, because SkyWalking is monitoring many places :)"", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);
+                find = true;
+                break;
+            }
+        }
+
+        // decrease profile count
+        if (find) {
+            currentExecutionContext.getCurrentProfilingCount().addAndGet(-1);
+        }
+    }
+
+    /**
+     * shutdown profiling thread
+     */
+    public void shutdown() {
+        running = false;
+    }
+
+    /**
+     * start profiling
+     * @param executionContext
+     */
+    private void profiling(ProfileTaskExecutionContext executionContext) throws InterruptedException {
+
+        int maxSleepPeriod = executionContext.getTask().getThreadDumpPeriod();
+        int minDurationThreshold = executionContext.getTask().getMinDurationThreshold();
+
+        // run loop when current task still running
+        long currentLoopStartTime = -1;
+        while (checkCanKeepRunning(executionContext)) {
+            currentLoopStartTime = System.currentTimeMillis();
+
+            // each all slot
+            for (ProfilingSegmentContext slot : executionContext.getProfilingSegmentSlot()) {
+                if (slot == null) {
+                    continue;
+                }
+
+                // check is already start dump stack
+                if (slot.getStartDump()) {
+
+                    // dump stack
+                    if (!dumpSegment(slot)) {
+                        stopSegmentProfile(slot.getSegment());
+                        continue;
+                    }
+
+                } else {
+
+                    // check segment running time
+                    if (System.currentTimeMillis() - slot.getProfilingStartTime() > minDurationThreshold) {
+                        slot.setStartDump(true);
+                    }
+
+                }
+            }
+
+            // sleep to next period
+            // if out of period, sleep one period
+            long needToSleep = (currentLoopStartTime + maxSleepPeriod) - System.currentTimeMillis();
+            needToSleep = needToSleep > 0 ? needToSleep : maxSleepPeriod;
+            Thread.sleep(needToSleep);
+        }
+    }
+
+    /**
+     * dump segemnt thread stack
+     * @param segmentContext
+     * @return
+     */
+    private boolean dumpSegment(ProfilingSegmentContext segmentContext) {
+        // dump stack
+        if (!checkSegmentProfilingCanContinue(segmentContext)) {
+            return false;
+        }
+
+        return dumpThread(segmentContext);
+    }
+
+    /**
+     * dump thread stack, and push data to backend
+     * @param segmentContext
+     * @return still can dump
+     */
+    private boolean dumpThread(ProfilingSegmentContext segmentContext) {
+        long currentTime = System.currentTimeMillis();
+        // dump thread
+        final StackTraceElement[] stackTrace = segmentContext.getProfilingThread().getStackTrace();
+
+        // stack depth is zero, means thread is already run finished
+        if (stackTrace.length == 0) {
+            return false;
+        }
+
+        int dumpElementCount = Math.min(stackTrace.length, Config.Profile.DUMP_MAX_STACK_DEPTH);
+
+        // use inverted order, because thread dump is start with bottom
+        final ArrayList<String> stackList = new ArrayList<>(dumpElementCount);
+        for (int i = dumpElementCount - 1; i >= 0; i--) {
+            stackList.add(buildStackElementCodeSignature(stackTrace[i]));
+        }
+
+        // build snapshot and send
+        ProfileTaskSegmentSnapshot snapshot = new ProfileTaskSegmentSnapshot(segmentContext, segmentContext.getCurrentAndIncrementSequence(), currentTime, stackList);
+        profileTaskChannelService.addProfilingSnapshot(snapshot);
+        return true;
+    }
+
+    private String buildStackElementCodeSignature(StackTraceElement element) {
+        // className.methodName:lineNumber
+        return element.getClassName() + ""."" + element.getMethodName() + "":"" + element.getLineNumber();
+    }
+
+    /**
+     * check segment profiling is should continue
+     * @param context
+     * @return
+     */
+    private boolean checkSegmentProfilingCanContinue(ProfilingSegmentContext context) {","[{'comment': ""`checkSegmentProfilingCanContinue` -> `isSegmentProfilingContinuable`. Let's reduce the usage of `check`."", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileTaskSegmentSnapshot.java,"@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentStack;
+
+import java.util.List;
+
+/**
+ * @author MrPro
+ */
+public class ProfileTaskSegmentSnapshot {
+
+    // profiling segment context
+    private final ProfilingSegmentContext segmentContext;
+
+    // dump info
+    private final int sequence;
+    private final long time;
+    private final List<String> stackList;
+
+    public ProfileTaskSegmentSnapshot(ProfilingSegmentContext segmentContext, int sequence, long time, List<String> stackList) {
+        this.segmentContext = segmentContext;
+        this.sequence = sequence;
+        this.time = time;
+        this.stackList = stackList;
+    }
+
+    /**
+     * transform to gRPC data
+     * @return
+     */
+    public org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentSnapshot transform() {
+        final org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentSnapshot.Builder builder = org.apache.skywalking.apm.network.language.profile.ProfileTaskSegmentSnapshot.newBuilder();","[{'comment': 'Why all these are full names?', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);
+                find = true;
+                break;
+            }
+        }
+
+        // decrease profile count
+        if (find) {
+            currentExecutionContext.getCurrentProfilingCount().addAndGet(-1);
+        }
+    }
+
+    /**
+     * shutdown profiling thread
+     */
+    public void shutdown() {
+        running = false;
+    }
+
+    /**
+     * start profiling
+     * @param executionContext
+     */
+    private void profiling(ProfileTaskExecutionContext executionContext) throws InterruptedException {
+
+        int maxSleepPeriod = executionContext.getTask().getThreadDumpPeriod();
+        int minDurationThreshold = executionContext.getTask().getMinDurationThreshold();
+
+        // run loop when current task still running
+        long currentLoopStartTime = -1;
+        while (checkCanKeepRunning(executionContext)) {","[{'comment': '`#profiling` is inside `#run`, why check this again?', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);
+                find = true;
+                break;
+            }
+        }
+
+        // decrease profile count
+        if (find) {
+            currentExecutionContext.getCurrentProfilingCount().addAndGet(-1);
+        }
+    }
+
+    /**
+     * shutdown profiling thread
+     */
+    public void shutdown() {
+        running = false;
+    }
+
+    /**
+     * start profiling
+     * @param executionContext
+     */
+    private void profiling(ProfileTaskExecutionContext executionContext) throws InterruptedException {
+
+        int maxSleepPeriod = executionContext.getTask().getThreadDumpPeriod();
+        int minDurationThreshold = executionContext.getTask().getMinDurationThreshold();
+
+        // run loop when current task still running
+        long currentLoopStartTime = -1;
+        while (checkCanKeepRunning(executionContext)) {
+            currentLoopStartTime = System.currentTimeMillis();
+
+            // each all slot
+            for (ProfilingSegmentContext slot : executionContext.getProfilingSegmentSlot()) {
+                if (slot == null) {
+                    continue;
+                }
+
+                // check is already start dump stack
+                if (slot.getStartDump()) {
+
+                    // dump stack
+                    if (!dumpSegment(slot)) {
+                        stopSegmentProfile(slot.getSegment());
+                        continue;
+                    }
+
+                } else {
+
+                    // check segment running time
+                    if (System.currentTimeMillis() - slot.getProfilingStartTime() > minDurationThreshold) {
+                        slot.setStartDump(true);
+                    }
+
+                }
+            }
+
+            // sleep to next period
+            // if out of period, sleep one period
+            long needToSleep = (currentLoopStartTime + maxSleepPeriod) - System.currentTimeMillis();
+            needToSleep = needToSleep > 0 ? needToSleep : maxSleepPeriod;
+            Thread.sleep(needToSleep);
+        }
+    }
+
+    /**
+     * dump segemnt thread stack
+     * @param segmentContext
+     * @return
+     */
+    private boolean dumpSegment(ProfilingSegmentContext segmentContext) {
+        // dump stack
+        if (!checkSegmentProfilingCanContinue(segmentContext)) {
+            return false;
+        }
+
+        return dumpThread(segmentContext);
+    }
+
+    /**
+     * dump thread stack, and push data to backend
+     * @param segmentContext
+     * @return still can dump
+     */
+    private boolean dumpThread(ProfilingSegmentContext segmentContext) {
+        long currentTime = System.currentTimeMillis();
+        // dump thread
+        final StackTraceElement[] stackTrace = segmentContext.getProfilingThread().getStackTrace();
+
+        // stack depth is zero, means thread is already run finished
+        if (stackTrace.length == 0) {
+            return false;
+        }
+
+        int dumpElementCount = Math.min(stackTrace.length, Config.Profile.DUMP_MAX_STACK_DEPTH);
+
+        // use inverted order, because thread dump is start with bottom
+        final ArrayList<String> stackList = new ArrayList<>(dumpElementCount);
+        for (int i = dumpElementCount - 1; i >= 0; i--) {
+            stackList.add(buildStackElementCodeSignature(stackTrace[i]));
+        }
+
+        // build snapshot and send
+        ProfileTaskSegmentSnapshot snapshot = new ProfileTaskSegmentSnapshot(segmentContext, segmentContext.getCurrentAndIncrementSequence(), currentTime, stackList);
+        profileTaskChannelService.addProfilingSnapshot(snapshot);
+        return true;
+    }
+
+    private String buildStackElementCodeSignature(StackTraceElement element) {
+        // className.methodName:lineNumber
+        return element.getClassName() + ""."" + element.getMethodName() + "":"" + element.getLineNumber();
+    }
+
+    /**
+     * check segment profiling is should continue
+     * @param context
+     * @return
+     */
+    private boolean checkSegmentProfilingCanContinue(ProfilingSegmentContext context) {
+        // check segment still executing
+        if (!context.getSegmentIsRunning()) {","[{'comment': ""`TracingContext#finish` has a listener mechanism, you don't need to check every time, you should set up a listener, then you could remove when you get the notification.\r\n\r\nBut you should notice, there is a segment finish event right now, but tracing context has an async mode today, so you need to add a notification, named as `notifyAfterMainThreadFinish`."", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);
+                find = true;
+                break;
+            }
+        }
+
+        // decrease profile count
+        if (find) {
+            currentExecutionContext.getCurrentProfilingCount().addAndGet(-1);
+        }
+    }
+
+    /**
+     * shutdown profiling thread
+     */
+    public void shutdown() {
+        running = false;
+    }
+
+    /**
+     * start profiling
+     * @param executionContext
+     */
+    private void profiling(ProfileTaskExecutionContext executionContext) throws InterruptedException {
+
+        int maxSleepPeriod = executionContext.getTask().getThreadDumpPeriod();
+        int minDurationThreshold = executionContext.getTask().getMinDurationThreshold();
+
+        // run loop when current task still running
+        long currentLoopStartTime = -1;
+        while (checkCanKeepRunning(executionContext)) {
+            currentLoopStartTime = System.currentTimeMillis();
+
+            // each all slot
+            for (ProfilingSegmentContext slot : executionContext.getProfilingSegmentSlot()) {
+                if (slot == null) {
+                    continue;
+                }
+
+                // check is already start dump stack
+                if (slot.getStartDump()) {
+
+                    // dump stack
+                    if (!dumpSegment(slot)) {
+                        stopSegmentProfile(slot.getSegment());
+                        continue;
+                    }
+
+                } else {
+
+                    // check segment running time
+                    if (System.currentTimeMillis() - slot.getProfilingStartTime() > minDurationThreshold) {
+                        slot.setStartDump(true);
+                    }
+
+                }
+            }
+
+            // sleep to next period
+            // if out of period, sleep one period
+            long needToSleep = (currentLoopStartTime + maxSleepPeriod) - System.currentTimeMillis();
+            needToSleep = needToSleep > 0 ? needToSleep : maxSleepPeriod;
+            Thread.sleep(needToSleep);
+        }
+    }
+
+    /**
+     * dump segemnt thread stack
+     * @param segmentContext
+     * @return
+     */
+    private boolean dumpSegment(ProfilingSegmentContext segmentContext) {
+        // dump stack
+        if (!checkSegmentProfilingCanContinue(segmentContext)) {
+            return false;
+        }
+
+        return dumpThread(segmentContext);
+    }
+
+    /**
+     * dump thread stack, and push data to backend
+     * @param segmentContext
+     * @return still can dump
+     */
+    private boolean dumpThread(ProfilingSegmentContext segmentContext) {
+        long currentTime = System.currentTimeMillis();
+        // dump thread
+        final StackTraceElement[] stackTrace = segmentContext.getProfilingThread().getStackTrace();
+
+        // stack depth is zero, means thread is already run finished
+        if (stackTrace.length == 0) {
+            return false;
+        }
+
+        int dumpElementCount = Math.min(stackTrace.length, Config.Profile.DUMP_MAX_STACK_DEPTH);
+
+        // use inverted order, because thread dump is start with bottom
+        final ArrayList<String> stackList = new ArrayList<>(dumpElementCount);
+        for (int i = dumpElementCount - 1; i >= 0; i--) {
+            stackList.add(buildStackElementCodeSignature(stackTrace[i]));
+        }
+
+        // build snapshot and send
+        ProfileTaskSegmentSnapshot snapshot = new ProfileTaskSegmentSnapshot(segmentContext, segmentContext.getCurrentAndIncrementSequence(), currentTime, stackList);
+        profileTaskChannelService.addProfilingSnapshot(snapshot);
+        return true;
+    }
+
+    private String buildStackElementCodeSignature(StackTraceElement element) {
+        // className.methodName:lineNumber
+        return element.getClassName() + ""."" + element.getMethodName() + "":"" + element.getLineNumber();
+    }
+
+    /**
+     * check segment profiling is should continue
+     * @param context
+     * @return
+     */
+    private boolean checkSegmentProfilingCanContinue(ProfilingSegmentContext context) {
+        // check segment still executing
+        if (!context.getSegmentIsRunning()) {
+            return false;
+        }
+
+        // check is out of limit monitor time
+        if (System.currentTimeMillis() - context.getProfilingStartTime() > MAX_PROFILING_TIME_MILLS) {
+            return false;
+        }
+
+        // check segment executing thread is still running
+        if (!context.getProfilingThread().isAlive()) {","[{'comment': ""Don't check this every time, once you don't get the notification event(`notifyAfterMainThreadFinish`), it is safe to continue."", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfilingSegmentContext.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+
+/**
+ * @author MrPro
+ */
+public class ProfilingSegmentContext {","[{'comment': ""Renaming to `ThreadProfiler`. Don't use `context` always. You need to avoid two similar names in one place, it is very confusing when reading the codes."", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfilingSegmentContext.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+
+/**
+ * @author MrPro
+ */
+public class ProfilingSegmentContext {
+
+    // current segment id
+    private final TraceSegment segment;
+    // need to profiling thread
+    private final Thread profilingThread;
+    // profiling execution context
+    private final ProfileTaskExecutionContext executionContext;
+
+    // current segment running status, each dump will judge it. Will set false when trace notification
+    private volatile boolean segmentIsRunning = true;
+    // profiling start time
+    private long profilingStartTime;
+
+    // after min duration threshold check, it will start dump
+    private boolean startDump = false;
+    // thread dump sequence
+    private int dumpSequence = 0;
+
+    public ProfilingSegmentContext(TraceSegment segment, Thread profilingThread, ProfileTaskExecutionContext executionContext) {
+        this.segment = segment;
+        this.profilingThread = profilingThread;
+        this.executionContext = executionContext;
+        this.profilingStartTime = System.currentTimeMillis();
+    }
+
+    public TraceSegment getSegment() {
+        return segment;
+    }
+
+    public Thread getProfilingThread() {
+        return profilingThread;
+    }
+
+    public boolean getSegmentIsRunning() {
+        return segmentIsRunning;
+    }
+
+    public void setSegmentIsRunning(boolean segmentIsRunning) {
+        this.segmentIsRunning = segmentIsRunning;
+    }
+
+    public ProfileTaskExecutionContext getExecutionContext() {
+        return executionContext;
+    }
+
+    public long getProfilingStartTime() {
+        return profilingStartTime;
+    }
+
+    public boolean getStartDump() {
+        return startDump;
+    }
+
+    public void setStartDump(boolean startDump) {
+        this.startDump = startDump;
+    }
+
+    /**
+     * get current sequence then increment it
+     * @return
+     */
+    public int getCurrentAndIncrementSequence() {","[{'comment': 'Rename to `nextSeq`', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {","[{'comment': 'You should be able to use `segment#equal`, right? Also, you should begin to move the logic method into the entity. \r\nThis should be `profilingSegmentSlot[slot]`.`matchWith(segment`.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);","[{'comment': 'What is `segmentIsRunning=false`?', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);
+                find = true;
+                break;
+            }
+        }
+
+        // decrease profile count
+        if (find) {
+            currentExecutionContext.getCurrentProfilingCount().addAndGet(-1);
+        }
+    }
+
+    /**
+     * shutdown profiling thread
+     */
+    public void shutdown() {
+        running = false;
+    }
+
+    /**
+     * start profiling
+     * @param executionContext
+     */
+    private void profiling(ProfileTaskExecutionContext executionContext) throws InterruptedException {
+
+        int maxSleepPeriod = executionContext.getTask().getThreadDumpPeriod();
+        int minDurationThreshold = executionContext.getTask().getMinDurationThreshold();
+
+        // run loop when current task still running
+        long currentLoopStartTime = -1;
+        while (checkCanKeepRunning(executionContext)) {
+            currentLoopStartTime = System.currentTimeMillis();
+
+            // each all slot
+            for (ProfilingSegmentContext slot : executionContext.getProfilingSegmentSlot()) {
+                if (slot == null) {
+                    continue;
+                }
+
+                // check is already start dump stack
+                if (slot.getStartDump()) {
+
+                    // dump stack
+                    if (!dumpSegment(slot)) {
+                        stopSegmentProfile(slot.getSegment());
+                        continue;
+                    }
+
+                } else {
+
+                    // check segment running time
+                    if (System.currentTimeMillis() - slot.getProfilingStartTime() > minDurationThreshold) {
+                        slot.setStartDump(true);
+                    }
+
+                }
+            }
+
+            // sleep to next period
+            // if out of period, sleep one period
+            long needToSleep = (currentLoopStartTime + maxSleepPeriod) - System.currentTimeMillis();
+            needToSleep = needToSleep > 0 ? needToSleep : maxSleepPeriod;
+            Thread.sleep(needToSleep);
+        }
+    }
+
+    /**
+     * dump segemnt thread stack
+     * @param segmentContext
+     * @return
+     */
+    private boolean dumpSegment(ProfilingSegmentContext segmentContext) {
+        // dump stack
+        if (!checkSegmentProfilingCanContinue(segmentContext)) {
+            return false;
+        }
+
+        return dumpThread(segmentContext);
+    }
+
+    /**
+     * dump thread stack, and push data to backend
+     * @param segmentContext
+     * @return still can dump
+     */
+    private boolean dumpThread(ProfilingSegmentContext segmentContext) {
+        long currentTime = System.currentTimeMillis();
+        // dump thread
+        final StackTraceElement[] stackTrace = segmentContext.getProfilingThread().getStackTrace();","[{'comment': 'No matter how many times you check the thread#isAlive, you still could face the thread is not inactive or dead at here. Try/catch this, and remove all unnecessary check.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfilingSegmentContext.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+
+/**
+ * @author MrPro
+ */
+public class ProfilingSegmentContext {
+
+    // current segment id
+    private final TraceSegment segment;
+    // need to profiling thread
+    private final Thread profilingThread;
+    // profiling execution context
+    private final ProfileTaskExecutionContext executionContext;
+
+    // current segment running status, each dump will judge it. Will set false when trace notification
+    private volatile boolean segmentIsRunning = true;
+    // profiling start time
+    private long profilingStartTime;
+
+    // after min duration threshold check, it will start dump
+    private boolean startDump = false;
+    // thread dump sequence
+    private int dumpSequence = 0;
+
+    public ProfilingSegmentContext(TraceSegment segment, Thread profilingThread, ProfileTaskExecutionContext executionContext) {
+        this.segment = segment;
+        this.profilingThread = profilingThread;
+        this.executionContext = executionContext;
+        this.profilingStartTime = System.currentTimeMillis();
+    }
+
+    public TraceSegment getSegment() {
+        return segment;
+    }
+
+    public Thread getProfilingThread() {
+        return profilingThread;
+    }
+
+    public boolean getSegmentIsRunning() {
+        return segmentIsRunning;
+    }
+
+    public void setSegmentIsRunning(boolean segmentIsRunning) {
+        this.segmentIsRunning = segmentIsRunning;
+    }
+
+    public ProfileTaskExecutionContext getExecutionContext() {
+        return executionContext;
+    }
+
+    public long getProfilingStartTime() {
+        return profilingStartTime;
+    }
+
+    public boolean getStartDump() {
+        return startDump;
+    }
+
+    public void setStartDump(boolean startDump) {","[{'comment': ""This doesn't match the `profilingStartTime`. Is that a bug?"", 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfileThread.java,"@@ -0,0 +1,296 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import com.google.common.base.Objects;
+import org.apache.skywalking.apm.agent.core.boot.ServiceManager;
+import org.apache.skywalking.apm.agent.core.conf.Config;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+
+import java.util.ArrayList;
+import java.util.concurrent.LinkedBlockingQueue;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
+
+/**
+ * Profile task process thread, dump segment executing thread stack.
+ *
+ * @author MrPro
+ */
+public class ProfileThread extends Thread {
+
+    private static final ILog logger = LogManager.getLogger(ProfileThread.class);
+
+    // per segment max profiling time (millisecond)
+    private static final long MAX_PROFILING_TIME_MILLS = TimeUnit.MINUTES.toMillis(Config.Profile.MAX_DURATION);
+
+    // current thread running status
+    private volatile boolean running = true;
+
+    // wait and notify has new profile task
+    private final LinkedBlockingQueue<ProfileTaskExecutionContext> executionContextListener = new LinkedBlockingQueue<>();
+
+    private final ProfileTaskExecutionService profileTaskExecutionService;
+    private final ProfileTaskChannelService profileTaskChannelService;
+
+    public ProfileThread() {
+        profileTaskExecutionService = ServiceManager.INSTANCE.findService(ProfileTaskExecutionService.class);
+        profileTaskChannelService = ServiceManager.INSTANCE.findService(ProfileTaskChannelService.class);
+    }
+
+    @Override
+    public void run() {
+
+        while (running) {
+            // waiting new profile task
+            ProfileTaskExecutionContext taskExecutionContext = null;
+            try {
+                taskExecutionContext = executionContextListener.take();
+            } catch (InterruptedException e) {
+                continue;
+            }
+
+            try {
+                profiling(taskExecutionContext);
+            } catch (InterruptedException e) {
+                // ignore interrupted
+                continue;
+            } catch (Exception e) {
+                logger.error(e, ""Profiling task fail. taskId:{}"", taskExecutionContext.getTask().getTaskId());
+            } finally {
+                // finally stop current profiling task, tell execution service task has stop
+                profileTaskExecutionService.stopCurrentProfileTask(taskExecutionContext);
+            }
+        }
+    }
+
+    /**
+     * notify have new task need to process
+     */
+    void processNewProfileTask(ProfileTaskExecutionContext context) {
+        executionContextListener.add(context);
+    }
+
+    /**
+     * check have available slot to profile and add it
+     * @param segment
+     * @return
+     */
+    public ProfilingSegmentContext checkAndAddSegmentContext(TraceSegment segment, ProfileTaskExecutionContext taskExecutionContext) {
+        // check has available slot
+        AtomicInteger currentProfilingCount = taskExecutionContext.getCurrentProfilingCount();
+        final int usingSlotCount = currentProfilingCount.get();
+        if (usingSlotCount >= Config.Profile.MAX_PARALLEL) {
+            return null;
+        }
+
+        // try to occupy slot
+        if (!currentProfilingCount.compareAndSet(usingSlotCount, usingSlotCount + 1)) {
+            return null;
+        }
+
+        ProfilingSegmentContext[] profilingSegmentSlot = taskExecutionContext.getProfilingSegmentSlot();
+        final ProfilingSegmentContext segmentContext = new ProfilingSegmentContext(segment, Thread.currentThread(), taskExecutionContext);
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            if (profilingSegmentSlot[slot] == null) {
+                profilingSegmentSlot[slot] = segmentContext;
+                break;
+            }
+        }
+        return segmentContext;
+    }
+
+    /**
+     * find segment and clear on slot
+     *
+     * @param segment
+     */
+    public void stopSegmentProfile(TraceSegment segment) {
+        ProfileTaskExecutionContext currentExecutionContext = profileTaskExecutionService.getCurrentTaskExecutionContext();
+        if (currentExecutionContext == null) {
+            return;
+        }
+
+        // find current segment and clear it
+        boolean find = false;
+        ProfilingSegmentContext[] profilingSegmentSlot = currentExecutionContext.getProfilingSegmentSlot();
+        for (int slot = 0; slot < profilingSegmentSlot.length; slot++) {
+            ProfilingSegmentContext currentSlotSegment = profilingSegmentSlot[slot];
+            if (currentSlotSegment != null && Objects.equal(profilingSegmentSlot[slot].getSegment().getTraceSegmentId(), segment.getTraceSegmentId())) {
+                profilingSegmentSlot[slot] = null;
+
+                // setting stop running
+                currentSlotSegment.setSegmentIsRunning(false);
+                find = true;
+                break;
+            }
+        }
+
+        // decrease profile count
+        if (find) {
+            currentExecutionContext.getCurrentProfilingCount().addAndGet(-1);
+        }
+    }
+
+    /**
+     * shutdown profiling thread
+     */
+    public void shutdown() {
+        running = false;
+    }
+
+    /**
+     * start profiling
+     * @param executionContext
+     */
+    private void profiling(ProfileTaskExecutionContext executionContext) throws InterruptedException {
+
+        int maxSleepPeriod = executionContext.getTask().getThreadDumpPeriod();
+        int minDurationThreshold = executionContext.getTask().getMinDurationThreshold();
+
+        // run loop when current task still running
+        long currentLoopStartTime = -1;
+        while (checkCanKeepRunning(executionContext)) {
+            currentLoopStartTime = System.currentTimeMillis();
+
+            // each all slot
+            for (ProfilingSegmentContext slot : executionContext.getProfilingSegmentSlot()) {
+                if (slot == null) {
+                    continue;
+                }
+
+                // check is already start dump stack
+                if (slot.getStartDump()) {
+
+                    // dump stack
+                    if (!dumpSegment(slot)) {
+                        stopSegmentProfile(slot.getSegment());
+                        continue;
+                    }
+
+                } else {
+
+                    // check segment running time
+                    if (System.currentTimeMillis() - slot.getProfilingStartTime() > minDurationThreshold) {","[{'comment': 'This should compare to segment startTime. `slot#startTIme` is not necessary.', 'commenter': 'wu-sheng'}]"
4220,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/profile/ProfilingSegmentContext.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.profile;
+
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+
+/**
+ * @author MrPro
+ */
+public class ProfilingSegmentContext {
+
+    // current segment id
+    private final TraceSegment segment;
+    // need to profiling thread
+    private final Thread profilingThread;
+    // profiling execution context
+    private final ProfileTaskExecutionContext executionContext;
+
+    // current segment running status, each dump will judge it. Will set false when trace notification
+    private volatile boolean segmentIsRunning = true;
+    // profiling start time
+    private long profilingStartTime;
+
+    // after min duration threshold check, it will start dump
+    private boolean startDump = false;","[{'comment': '`startDump` -> `enum profilingStatus`, which has values(READY/PROFILING/STOPPED)', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-bootstrap/src/main/resources/browser_analysis.oal,"@@ -0,0 +1,87 @@
+/*
+* Licensed to the Apache Software Foundation (ASF) under one or more
+* contributor license agreements.  See the NOTICE file distributed with
+* this work for additional information regarding copyright ownership.
+* The ASF licenses this file to You under the Apache License, Version 2.0
+* (the ""License""); you may not use this file except in compliance with
+* the License.  You may obtain a copy of the License at
+*
+*     http://www.apache.org/licenses/LICENSE-2.0
+*
+* Unless required by applicable law or agreed to in writing, software
+* distributed under the License is distributed on an ""AS IS"" BASIS,
+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+* See the License for the specific language governing permissions and
+* limitations under the License.
+*
+*/
+
+// Browser service
+service_redirect_avg = from(ServicePerfDetail.redirectTime).longAvg();
+service_dns_avg = from(ServicePerfDetail.dnsTime).longAvg();
+service_req_avg = from(ServicePerfDetail.reqTime).longAvg();
+service_dom_analysis_avg = from(ServicePerfDetail.domAnalysisTime).longAvg();
+service_dom_ready_avg = from(ServicePerfDetail.domReadyTime).longAvg();
+service_blank_avg = from(ServicePerfDetail.blankTime).longAvg();
+
+// Multiple values including p50, p75, p90, p95, p99
+service_redirect_percentile = from(ServicePerfDetail.redirectTime).percentile(10);
+service_dns_percentile = from(ServicePerfDetail.dnsTime).percentile(10);
+service_req_percentile = from(ServicePerfDetail.reqTime).percentile(10);
+service_dom_analysis_percentile = from(ServicePerfDetail.domAnalysisTime).percentile(10);
+service_dom_ready_percentile = from(ServicePerfDetail.domReadyTime).percentile(10);
+service_blank_percentile = from(ServicePerfDetail.blankTime).percentile(10);
+
+// Browser service page
+service_page_pv = from(ServicePagePathPerfDetail.count).sum();
+service_page_error_rate = from(ServicePagePathPerfDetail.*).percent(status == false);
+
+service_page_redirect_avg = from(ServicePagePathPerfDetail.redirectTime).longAvg();
+service_page_dns_avg = from(ServicePagePathPerfDetail.dnsTime).longAvg();
+service_page_req_avg = from(ServicePagePathPerfDetail.reqTime).longAvg();
+service_page_dom_analysis_avg = from(ServicePagePathPerfDetail.domAnalysisTime).longAvg();
+service_page_dom_ready_avg = from(ServicePagePathPerfDetail.domReadyTime).longAvg();
+service_page_blank_avg = from(ServicePagePathPerfDetail.blankTime).longAvg();
+
+// Multiple values including p50, p75, p90, p95, p99
+service_page_redirect_percentile = from(ServicePagePathPerfDetail.redirectTime).percentile(10);
+service_page_dns_percentile = from(ServicePagePathPerfDetail.dnsTime).percentile(10);
+service_page_req_percentile = from(ServicePagePathPerfDetail.reqTime).percentile(10);
+service_page_dom_analysis_percentile = from(ServicePagePathPerfDetail.domAnalysisTime).percentile(10);
+service_page_dom_ready_percentile = from(ServicePagePathPerfDetail.domReadyTime).percentile(10);
+service_page_blank_percentile = from(ServicePagePathPerfDetail.blankTime).percentile(10);
+
+// Browser service version
+service_version_redirect_avg = from(ServiceVersionPerfDetail.redirectTime).longAvg();","[{'comment': '`service_version` -> `one_version_of_service_*`. ', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/NotifyHandler.java,"@@ -82,6 +82,12 @@ public NotifyHandler(AlarmRulesWatcher alarmRulesWatcher) {
 
             endpointMetaInAlarm.setName(textName);
             metaInAlarm = endpointMetaInAlarm;
+        } else if (DefaultScopeDefine.inServicePageCatalog(scope)) {
+            // TODO handler service page path catalog
+            return;
+        } else if (DefaultScopeDefine.inServiceVersionCatalog(scope)) {
+            // TODO handler service version page path catalog","[{'comment': 'If these are TODOs, why add this?', 'commenter': 'wu-sheng'}, {'comment': 'Done.', 'commenter': 'arugal'}]"
4228,oap-server/server-bootstrap/src/main/resources/official_analysis.oal,"@@ -102,3 +102,77 @@ envoy_parent_connections_used = from(EnvoyInstanceMetric.value).filter(metricNam
 // disable(top_n_database_statement);
 // disable(zipkin_span);
 // disable(jaeger_span);
+
+
+// Browser metrics begin","[{'comment': ""@Fine0830 Please verify, do we really need all these percentiles? I think we shouldn't. \r\n\r\n@Fine0830 After you are back from the vacation, please check which metrics we really require."", 'commenter': 'wu-sheng'}, {'comment': '@kezhenxu94 I want to discuss a thing with you. In @arugal prev PR, this part of OAL is separated in another OAL, I asked him to change like this. But in these days, I prefer his way more. If those are in another OAL file, then OAL engine could provide an API to activate some OAL files, such as from browser-receiver provider. This should make our document easier. What do you think? @arugal ', 'commenter': 'wu-sheng'}, {'comment': "">  In @arugal prev PR, this part of OAL is separated in another OAL\r\n\r\nWhich PR? I'd like to have a look;\r\n\r\nModularizing the OAL sounds good to me, maybe divide them as per entity or metrics, and make it possible for the users to put their custom metrics in a separate file"", 'commenter': 'kezhenxu94'}, {'comment': ""Actually, I don't want to separate too many files. It was this PR, there were two OAL files, one for backend service, the other for browser. They are activated by receiver. What do you think?"", 'commenter': 'wu-sheng'}, {'comment': ""> Actually, I don't want to separate too many files. It was this PR, there were two OAL files, one for backend service, the other for browser. They are activated by receiver. What do you think?\r\n\r\nAnyway, I'm with this idea, it doesn't matter for me how many OAL files are divided into, finally :)"", 'commenter': 'kezhenxu94'}, {'comment': '@arugal Sorry for requesting you to change back. Could you revert to your prev idea? And activate the OAL by the receiver? The current OAL file should be activated by the core module directly.', 'commenter': 'wu-sheng'}, {'comment': '> And activate the OAL by the receiver? \r\n\r\nAgree.\r\n\r\n### Design\r\n1.  `official_analysis.oal` and `browser_analysis.oal`\r\n1. `official_analysis.oal` activate by `mission-metric, istio-telemetry, service-mesh, receiver-trace, receiver-so11y, receiver-jvm, receiver-clr `\r\n1. `browser_analysis.oal` activate by `browser-receiver`\r\n1.  each file will only be activated once\r\n', 'commenter': 'arugal'}, {'comment': 'Good for me.', 'commenter': 'wu-sheng'}]"
4228,docs/en/setup/backend/backend-alarm.md,"@@ -85,7 +85,7 @@ Webhook requires the peer is a web container. The alarm message will send throug
 - **scopeId**, **scope**. All scopes are defined in org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.
 - **name**. Target scope entity name.
 - **id0**. The ID of scope entity, matched the name.
-- **id1**. Not used today.
+- **id1**. The ID1 of scope entity.","[{'comment': 'Do we use this today?', 'commenter': 'wu-sheng'}, {'comment': '`ID1` is designed for relationship alert. I think it is not related to this PR, right?', 'commenter': 'wu-sheng'}]"
4228,oap-server/oal-grammar/src/main/antlr4/org/apache/skywalking/oal/rt/grammar/OALLexer.g4,"@@ -44,6 +44,12 @@ SRC_SERVICE_INSTANCE_CLR_GC: 'ServiceInstanceCLRGC';
 SRC_SERVICE_INSTANCE_CLR_THREAD: 'ServiceInstanceCLRThread';
 SRC_ENVOY_INSTANCE_METRIC: 'EnvoyInstanceMetric';
 
+// Browser keywords
+SRC_BROWSER_SERVICE_PERF_DETAIL: 'ServicePerfDetail';
+SRC_BROWSER_SERVICE_PAGE_PATH_PERF_DETAIL: 'ServicePagePathPerfDetail';
+SRC_BROWSER_SERVICE_VERSION_PERF_DETAIL: 'ServiceVersionPerfDetail';
+SRC_BROWSER_SERVICE_VERSION_PAGE_PATH_PERF_DETAIL: 'ServiceVersionPagePathPerfDetail';","[{'comment': 'All these should be named `Browser*`. `ServiceVersion` should be `BrowserSingleVersion*`.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/AlarmMessageFormatter.java,"@@ -55,6 +55,9 @@ public AlarmMessageFormatter(String format) {
                         case ""id"":
                             valueFroms.add(ValueFrom.ID);
                             break;
+                        case ""id1"":
+                            valueFroms.add(ValueFrom.ID1);","[{'comment': 'Same question about `id1`', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/NotifyHandler.java,"@@ -82,6 +84,38 @@ public NotifyHandler(AlarmRulesWatcher alarmRulesWatcher) {
 
             endpointMetaInAlarm.setName(textName);
             metaInAlarm = endpointMetaInAlarm;
+        } else if (DefaultScopeDefine.inServicePageCatalog(scope)) {
+            String metricsId = meta.getId();
+            String[] ids = metricsId.split(Const.ID_SPLIT);
+            int serviceId = Integer.parseInt(ids[0]);
+            int pagePathId = Integer.parseInt(ids[1]);","[{'comment': ""ID1 should not be used in this way. If this is page related alert, then id0=pageId, which is unique, so don't worry about it."", 'commenter': 'wu-sheng'}]"
4228,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/NotifyHandler.java,"@@ -82,6 +84,38 @@ public NotifyHandler(AlarmRulesWatcher alarmRulesWatcher) {
 
             endpointMetaInAlarm.setName(textName);
             metaInAlarm = endpointMetaInAlarm;
+        } else if (DefaultScopeDefine.inServicePageCatalog(scope)) {
+            String metricsId = meta.getId();
+            String[] ids = metricsId.split(Const.ID_SPLIT);
+            int serviceId = Integer.parseInt(ids[0]);
+            int pagePathId = Integer.parseInt(ids[1]);
+            ServiceInventory serviceInventory = serviceInventoryCache.get(serviceId);
+            EndpointInventory endpointInventory = endpointInventoryCache.get(pagePathId);
+
+            ServicePageMetaInAlarm servicePageMetaInAlarm = new ServicePageMetaInAlarm();
+            servicePageMetaInAlarm.setMetricsName(meta.getMetricsName());
+            servicePageMetaInAlarm.setServiceId(serviceId);
+            servicePageMetaInAlarm.setPagePathId(pagePathId);
+
+            String textName = endpointInventory.getName() + "" in "" + serviceInventory.getName();
+            servicePageMetaInAlarm.setName(textName);
+            metaInAlarm = servicePageMetaInAlarm;
+        } else if (DefaultScopeDefine.inServiceVersionCatalog(scope)) {
+            String metricsId = meta.getId();
+            String[] ids = metricsId.split(Const.ID_SPLIT);
+            int serviceVersionId = Integer.parseInt(ids[0]);
+            int pagePathId = Integer.parseInt(ids[1]);","[{'comment': 'Same issue here about `id1`', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/DefaultScopeDefine.java,"@@ -71,16 +71,28 @@
     public static final int PROFILE_TASK_LOG = 27;
     public static final int PROFILE_TASK_SEGMENT_SNAPSHOT = 28;
 
+    // browser
+    public static final int BROWSER_PERF_DATA = 40;
+    public static final int SERVICE_PERF_DETAIL = 41;
+    public static final int SERVICE_PAGE_PATH_PERF_DETAIL = 42;
+    public static final int SERVICE_VERSION_PERF_DETAIL = 43;
+    public static final int SERVICE_VERSION_PAGE_PATH_PERF_DETAIL = 44;","[{'comment': '`SERVICE_` should be renamed to `BROWSER_`', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/DefaultScopeDefine.java,"@@ -71,16 +71,28 @@
     public static final int PROFILE_TASK_LOG = 27;
     public static final int PROFILE_TASK_SEGMENT_SNAPSHOT = 28;
 
+    // browser
+    public static final int BROWSER_PERF_DATA = 40;
+    public static final int SERVICE_PERF_DETAIL = 41;
+    public static final int SERVICE_PAGE_PATH_PERF_DETAIL = 42;
+    public static final int SERVICE_VERSION_PERF_DETAIL = 43;
+    public static final int SERVICE_VERSION_PAGE_PATH_PERF_DETAIL = 44;
+
     /**
      * Catalog of scope, the metrics processor could use this to group all generated metrics by oal rt.
      */
     public static final String SERVICE_CATALOG_NAME = ""SERVICE"";
     public static final String SERVICE_INSTANCE_CATALOG_NAME = ""SERVICE_INSTANCE"";
     public static final String ENDPOINT_CATALOG_NAME = ""ENDPOINT"";
 
+    public static final String SERVICE_PAGE_PATH_CATALOG_NAME = ""SERVICE_PAGE_PATH"";
+    public static final String SERVICE_VERSION_PAGE_PATH_CATALOG_NAME = ""SERVICE_VERSION_PAGE_PATH"";","[{'comment': 'Same rename suggestion.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/DefaultScopeDefine.java,"@@ -71,16 +71,28 @@
     public static final int PROFILE_TASK_LOG = 27;
     public static final int PROFILE_TASK_SEGMENT_SNAPSHOT = 28;
 
+    // browser
+    public static final int BROWSER_PERF_DATA = 40;
+    public static final int SERVICE_PERF_DETAIL = 41;
+    public static final int SERVICE_PAGE_PATH_PERF_DETAIL = 42;
+    public static final int SERVICE_VERSION_PERF_DETAIL = 43;
+    public static final int SERVICE_VERSION_PAGE_PATH_PERF_DETAIL = 44;
+
     /**
      * Catalog of scope, the metrics processor could use this to group all generated metrics by oal rt.
      */
     public static final String SERVICE_CATALOG_NAME = ""SERVICE"";
     public static final String SERVICE_INSTANCE_CATALOG_NAME = ""SERVICE_INSTANCE"";
     public static final String ENDPOINT_CATALOG_NAME = ""ENDPOINT"";
 
+    public static final String SERVICE_PAGE_PATH_CATALOG_NAME = ""SERVICE_PAGE_PATH"";
+    public static final String SERVICE_VERSION_PAGE_PATH_CATALOG_NAME = ""SERVICE_VERSION_PAGE_PATH"";
+
     private static final Map<Integer, Boolean> SERVICE_CATALOG = new HashMap<>();
     private static final Map<Integer, Boolean> SERVICE_INSTANCE_CATALOG = new HashMap<>();
     private static final Map<Integer, Boolean> ENDPOINT_CATALOG = new HashMap<>();
+    private static final Map<Integer, Boolean> SERVICE_PAGE_PATH_CATALOG = new HashMap<>();
+    private static final Map<Integer, Boolean> SERVICE_VERSION_PAGE_PATH_CATALOG = new HashMap<>();","[{'comment': 'Same rename suggestion.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/oal/rt/OALEngineService.java,"@@ -0,0 +1,84 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.oal.rt;
+
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.StreamAnnotationListener;
+import org.apache.skywalking.oap.server.core.source.SourceReceiver;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.module.Service;
+
+import java.lang.reflect.Constructor;
+import java.util.HashMap;
+import java.util.Map;
+
+/**
+ *
+ * @author zhangwei
+ */
+@Slf4j
+public class OALEngineService implements Service {
+
+    private final Map<OALEngine.Group, OALEngine> engineMap = new HashMap<>();
+    private final ModuleManager moduleManager;
+
+    public OALEngineService(ModuleManager moduleManager) {
+        this.moduleManager = moduleManager;
+    }
+
+    public void activate(OALEngine.Group group) throws ModuleStartException {
+        activate(group, OALEngineService.class.getClassLoader());
+    }
+
+    public void activate(OALEngine.Group group, ClassLoader classLoader) throws ModuleStartException {","[{'comment': 'Who will provide an external ClassLoader?', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/DefaultScopeDefine.java,"@@ -71,16 +71,28 @@
     public static final int PROFILE_TASK_LOG = 27;
     public static final int PROFILE_TASK_SEGMENT_SNAPSHOT = 28;
 
+    // browser
+    public static final int BROWSER_PERF_DATA = 40;
+    public static final int BROWSER_PERF_DETAIL = 41;
+    public static final int BROWSER_PAGE_PATH_PERF_DETAIL = 42;
+    public static final int BROWSER_SINGLE_VERSION_PERF_DETAIL = 43;
+    public static final int BROWSER_SINGLE_VERSION_PAGE_PATH_PERF_DETAIL = 44;
+
     /**
      * Catalog of scope, the metrics processor could use this to group all generated metrics by oal rt.
      */
     public static final String SERVICE_CATALOG_NAME = ""SERVICE"";
     public static final String SERVICE_INSTANCE_CATALOG_NAME = ""SERVICE_INSTANCE"";
     public static final String ENDPOINT_CATALOG_NAME = ""ENDPOINT"";
 
+    public static final String BROWSER_PAGE_PATH_CATALOG_NAME = ""BROWSER_PAGE_PATH"";
+    public static final String BROWSER_SINGLE_VERSION_PAGE_PATH_CATALOG_NAME = ""BROWSER_SINGLE_VERSION_PAGE_PATH"";","[{'comment': 'This should be mapping to the service instance, right? Then it should be named. `BROWSER_APP_SINGLE_VERSION_CATALOG_NAME`', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/DefaultScopeDefine.java,"@@ -71,16 +71,28 @@
     public static final int PROFILE_TASK_LOG = 27;
     public static final int PROFILE_TASK_SEGMENT_SNAPSHOT = 28;
 
+    // browser
+    public static final int BROWSER_PERF_DATA = 40;","[{'comment': '`BROWSER_` -> `BROWSER_APP_`.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-receiver-plugin/skywalking-browser-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/recevier/browser/provider/parse/BrowserPerfDataParse.java,"@@ -0,0 +1,217 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.recevier.browser.provider.parse;
+
+import lombok.Setter;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.language.agent.BrowserPerfData;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.TimeBucket;
+import org.apache.skywalking.oap.server.core.cache.ServiceInstanceInventoryCache;
+import org.apache.skywalking.oap.server.library.buffer.BufferData;
+import org.apache.skywalking.oap.server.library.buffer.DataStreamReader;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.recevier.browser.provider.BrowserServiceModuleConfig;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.decorator.BrowserErrorLogDecorator;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.decorator.BrowserPerfDataCoreInfo;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.decorator.BrowserPerfDataDecorator;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.listener.BrowserPerfDataListener;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.standardization.BrowserPerfDataStandardization;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.standardization.BrowserPerfDataStandardizationWorker;
+import org.apache.skywalking.oap.server.recevier.browser.provider.parse.standardization.PagePathIdExchanger;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.LinkedList;
+import java.util.List;
+
+/**
+ * @author zhangwei
+ */
+@Slf4j
+public class BrowserPerfDataParse {","[{'comment': '`Parse` -> `Parser`.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/browser/source/BrowserSingleVersionPagePathPerfDetail.java,"@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.browser.source;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.core.source.ScopeDeclaration;
+import org.apache.skywalking.oap.server.core.source.ScopeDefaultColumn;
+import org.apache.skywalking.oap.server.core.source.Source;
+
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_SINGLE_VERSION_PAGE_PATH_CATALOG_NAME;
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_SINGLE_VERSION_PAGE_PATH_PERF_DETAIL;
+
+/**
+ * @author zhangwei
+ */
+@ScopeDeclaration(id = BROWSER_SINGLE_VERSION_PAGE_PATH_PERF_DETAIL, name = ""BrowserSingleVersionPagePathPerfDetail"", catalog = BROWSER_SINGLE_VERSION_PAGE_PATH_CATALOG_NAME)
+@ScopeDefaultColumn.VirtualColumnDefinition(fieldName = ""entityId"", columnName = ""entity_id"", isID = true, type = String.class)
+public class BrowserSingleVersionPagePathPerfDetail extends Source {","[{'comment': 'Naming issue. This should be related to BrowserAppSignleVersion. Not to page path even you could include the path for filter and metrics funcs.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/browser/source/BrowserSingleVersionPerfDetail.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.browser.source;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.source.ScopeDeclaration;
+import org.apache.skywalking.oap.server.core.source.ScopeDefaultColumn;
+import org.apache.skywalking.oap.server.core.source.Source;
+
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_CATALOG_NAME;
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_SINGLE_VERSION_PERF_DETAIL;
+
+/**
+ * @author zhangwei
+ */
+@ScopeDeclaration(id = BROWSER_SINGLE_VERSION_PERF_DETAIL, name = ""BrowserSingleVersionPerfDetail"", catalog = SERVICE_INSTANCE_CATALOG_NAME)","[{'comment': 'Catalog is not right.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/browser/source/BrowserPagePathPerfDetail.java,"@@ -0,0 +1,60 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.browser.source;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.Const;
+import org.apache.skywalking.oap.server.core.source.ScopeDeclaration;
+import org.apache.skywalking.oap.server.core.source.ScopeDefaultColumn;
+import org.apache.skywalking.oap.server.core.source.Source;
+
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_PAGE_PATH_CATALOG_NAME;
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_PAGE_PATH_PERF_DETAIL;
+
+/**
+ * @author zhangwei
+ */
+@ScopeDeclaration(id = BROWSER_PAGE_PATH_PERF_DETAIL, name = ""BrowserPagePathPerfDetail"", catalog = BROWSER_PAGE_PATH_CATALOG_NAME)
+@ScopeDefaultColumn.VirtualColumnDefinition(fieldName = ""entityId"", columnName = ""entity_id"", isID = true, type = String.class)
+public class BrowserPagePathPerfDetail extends Source {","[{'comment': '`BrowserPagePathPerfDetail`-> `BrowserAppPagePerf`', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/browser/source/BrowserPerfData.java,"@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.browser.source;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.source.ScopeDeclaration;
+import org.apache.skywalking.oap.server.core.source.Source;
+
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_PERF_DATA;
+
+/**
+ * @author zhangwei
+ */
+@ScopeDeclaration(id = BROWSER_PERF_DATA, name = ""BrowserPerfData"")
+public class BrowserPerfData extends Source {","[{'comment': '`Browser`-> `BrowserApp`.', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-bootstrap/src/main/resources/browser_analysis.oal,"@@ -0,0 +1,87 @@
+/*
+* Licensed to the Apache Software Foundation (ASF) under one or more
+* contributor license agreements.  See the NOTICE file distributed with
+* this work for additional information regarding copyright ownership.
+* The ASF licenses this file to You under the Apache License, Version 2.0
+* (the ""License""); you may not use this file except in compliance with
+* the License.  You may obtain a copy of the License at
+*
+*     http://www.apache.org/licenses/LICENSE-2.0
+*
+* Unless required by applicable law or agreed to in writing, software
+* distributed under the License is distributed on an ""AS IS"" BASIS,
+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+* See the License for the specific language governing permissions and
+* limitations under the License.
+*
+*/
+
+// Browser service
+browser_redirect_avg = from(BrowserPerfDetail.redirectTime).longAvg();
+browser_dns_avg = from(BrowserPerfDetail.dnsTime).longAvg();
+browser_req_avg = from(BrowserPerfDetail.reqTime).longAvg();
+browser_dom_analysis_avg = from(BrowserPerfDetail.domAnalysisTime).longAvg();
+browser_dom_ready_avg = from(BrowserPerfDetail.domReadyTime).longAvg();
+browser_blank_avg = from(BrowserPerfDetail.blankTime).longAvg();
+
+// Multiple values including p50, p75, p90, p95, p99
+browser_redirect_percentile = from(BrowserPerfDetail.redirectTime).percentile(10);
+browser_dns_percentile = from(BrowserPerfDetail.dnsTime).percentile(10);
+browser_req_percentile = from(BrowserPerfDetail.reqTime).percentile(10);
+browser_dom_analysis_percentile = from(BrowserPerfDetail.domAnalysisTime).percentile(10);
+browser_dom_ready_percentile = from(BrowserPerfDetail.domReadyTime).percentile(10);
+browser_blank_percentile = from(BrowserPerfDetail.blankTime).percentile(10);
+
+// Browser service page
+browser_page_pv = from(BrowserPagePathPerfDetail.count).sum();
+browser_page_error_rate = from(BrowserPagePathPerfDetail.*).percent(status == false);
+
+browser_page_redirect_avg = from(BrowserPagePathPerfDetail.redirectTime).longAvg();
+browser_page_dns_avg = from(BrowserPagePathPerfDetail.dnsTime).longAvg();
+browser_page_req_avg = from(BrowserPagePathPerfDetail.reqTime).longAvg();
+browser_page_dom_analysis_avg = from(BrowserPagePathPerfDetail.domAnalysisTime).longAvg();
+browser_page_dom_ready_avg = from(BrowserPagePathPerfDetail.domReadyTime).longAvg();
+browser_page_blank_avg = from(BrowserPagePathPerfDetail.blankTime).longAvg();
+
+// Multiple values including p50, p75, p90, p95, p99
+browser_page_redirect_percentile = from(BrowserPagePathPerfDetail.redirectTime).percentile(10);
+browser_page_dns_percentile = from(BrowserPagePathPerfDetail.dnsTime).percentile(10);
+browser_page_req_percentile = from(BrowserPagePathPerfDetail.reqTime).percentile(10);
+browser_page_dom_analysis_percentile = from(BrowserPagePathPerfDetail.domAnalysisTime).percentile(10);
+browser_page_dom_ready_percentile = from(BrowserPagePathPerfDetail.domReadyTime).percentile(10);
+browser_page_blank_percentile = from(BrowserPagePathPerfDetail.blankTime).percentile(10);
+
+// Browser service version","[{'comment': 'This comment is not right. \r\n\r\n> Performance metrics of every single version .', 'commenter': 'wu-sheng'}]"
4228,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/browser/source/BrowserSingleVersionPerfDetail.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.browser.source;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.source.ScopeDeclaration;
+import org.apache.skywalking.oap.server.core.source.ScopeDefaultColumn;
+import org.apache.skywalking.oap.server.core.source.Source;
+
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_CATALOG_NAME;
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.BROWSER_SINGLE_VERSION_PERF_DETAIL;
+
+/**
+ * @author zhangwei
+ */
+@ScopeDeclaration(id = BROWSER_SINGLE_VERSION_PERF_DETAIL, name = ""BrowserSingleVersionPerfDetail"", catalog = SERVICE_INSTANCE_CATALOG_NAME)
+@ScopeDefaultColumn.VirtualColumnDefinition(fieldName = ""entityId"", columnName = ""entity_id"", isID = true, type = String.class)
+public class BrowserSingleVersionPerfDetail extends Source {","[{'comment': '`Browser` -> `BrowserApp`.', 'commenter': 'wu-sheng'}]"
4251,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/StandardChannelBuilder.java,"@@ -30,6 +31,10 @@
 
     @Override public ManagedChannelBuilder build(ManagedChannelBuilder managedChannelBuilder) throws Exception {
         return managedChannelBuilder.nameResolverFactory(new DnsNameResolverProvider())
+            /**
+             * It seems the code above can only work for low gRPC version.","[{'comment': 'What does this comment mean? ', 'commenter': 'wu-sheng'}, {'comment': ""We don't need to describe the history."", 'commenter': 'wu-sheng'}]"
4251,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/StandardChannelBuilder.java,"@@ -30,6 +31,10 @@
 
     @Override public ManagedChannelBuilder build(ManagedChannelBuilder managedChannelBuilder) throws Exception {
         return managedChannelBuilder.nameResolverFactory(new DnsNameResolverProvider())
+            /**
+             * It seems the code above can only work for low gRPC version.
+             */
+            .loadBalancerFactory(RoundRobinLoadBalancerFactory.getInstance())","[{'comment': 'According to the header of RoundRobinLoadBalancerFactory, this is experimental. And also, this could use more connections of OAP backend, you should create a Config, at `Config#Collector#OPEN_ROUND_ROBIN_LOAD_BALANCE` default false, to support this feature. \r\n```\r\n/**\r\n * A {@link LoadBalancer} that provides round-robin load balancing mechanism over the\r\n * addresses from the {@link NameResolver}.  The sub-lists received from the name resolver\r\n * are considered to be an {@link EquivalentAddressGroup} and each of these sub-lists is\r\n * what is then balanced across.\r\n */\r\n@ExperimentalApi(""https://github.com/grpc/grpc-java/issues/1771"")\r\npublic class RoundRobinLoadBalancerFactory extends LoadBalancer.Factory {\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'Also, this doc should be updated as new config added. https://github.com/apache/skywalking/blob/master/docs/en/setup/service-agent/java-agent/README.md#table-of-agent-configuration-properties', 'commenter': 'wu-sheng'}, {'comment': 'OK. Will add these details ASAP', 'commenter': 'solid-itec'}]"
4270,oap-server/server-receiver-plugin/skywalking-trace-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/trace/provider/parser/listener/endpoint/MultiScopesSpanListener.java,"@@ -211,6 +212,9 @@ public void parseEntry(SpanDecorator spanDecorator, SegmentCoreInfo segmentCoreI
     }
 
     private void setPublicAttrs(SourceBuilder sourceBuilder, SpanDecorator spanDecorator) {
+        if(Objects.isNull(endpointInventoryCache)){","[{'comment': 'The `endpointInventoryCache` is initialized in the constructor, why null?', 'commenter': 'wu-sheng'}]"
4278,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/match/MethodInheritsDeclaringAnnotationMatcher.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.match;
+
+import net.bytebuddy.build.HashCodeAndEqualsPlugin;
+import net.bytebuddy.description.annotation.AnnotationList;
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.description.method.MethodList;
+import net.bytebuddy.description.method.ParameterList;
+import net.bytebuddy.description.type.TypeDefinition;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.description.type.TypeList;
+import net.bytebuddy.matcher.CollectionItemMatcher;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Objects;
+
+import static net.bytebuddy.matcher.ElementMatchers.annotationType;
+
+/**
+ * @description: Matching used to match method annotations, Can match annotations on interface methods
+ * @auther: jialong  by 2020-01-23 15:41","[{'comment': 'typo `@author`, and please remove the `:`', 'commenter': 'kezhenxu94'}, {'comment': 'Thanks for your correction', 'commenter': 'jialong121'}]"
4278,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/match/MethodInheritsDeclaringAnnotationMatcher.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.match;
+
+import net.bytebuddy.build.HashCodeAndEqualsPlugin;
+import net.bytebuddy.description.annotation.AnnotationList;
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.description.method.MethodList;
+import net.bytebuddy.description.method.ParameterList;
+import net.bytebuddy.description.type.TypeDefinition;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.description.type.TypeList;
+import net.bytebuddy.matcher.CollectionItemMatcher;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Objects;
+
+import static net.bytebuddy.matcher.ElementMatchers.annotationType;
+
+/**
+ * @description: Matching used to match method annotations, Can match annotations on interface methods","[{'comment': ""remove `@description`, it's not a valid JavaDoc tag"", 'commenter': 'kezhenxu94'}]"
4278,apm-sniffer/apm-agent-core/src/test/java/org/apache/skywalking/apm/agent/core/plugin/bytebuddy/MethodInheritsDeclaringAnnotationMatcherTest.java,"@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.bytebuddy;
+
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.lang.annotation.Documented;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import java.lang.annotation.Target;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.match.MethodInheritsDeclaringAnnotationMatcher.isInheritsAnnotatedWith;
+
+/**
+ * @description:
+ * @auther: jialong  by 2020-01-23 16:09","[{'comment': 'ditto', 'commenter': 'kezhenxu94'}]"
4278,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/match/MethodInheritsDeclaringAnnotationMatcher.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.match;
+
+import net.bytebuddy.build.HashCodeAndEqualsPlugin;
+import net.bytebuddy.description.annotation.AnnotationList;
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.description.method.MethodList;
+import net.bytebuddy.description.method.ParameterList;
+import net.bytebuddy.description.type.TypeDefinition;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.description.type.TypeList;
+import net.bytebuddy.matcher.CollectionItemMatcher;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Objects;
+
+import static net.bytebuddy.matcher.ElementMatchers.annotationType;
+
+/**
+ * Matching used to match method annotations, Can match annotations on interface methods
+ * @auther jialong
+ */
+@HashCodeAndEqualsPlugin.Enhance
+public class MethodInheritsDeclaringAnnotationMatcher<T extends MethodDescription> extends ElementMatcher.Junction.AbstractBase<T> {
+    /**
+     * The matcher to be applied to the provided annotation list.
+     */
+    private final ElementMatcher<? super AnnotationList> matcher;
+
+    /**
+     * Creates a new matcher for the annotations of an annotated element.
+     *
+     * @param matcher The matcher to be applied to the provided annotation list.
+     */
+    public MethodInheritsDeclaringAnnotationMatcher(ElementMatcher<? super AnnotationList> matcher) {
+        this.matcher = matcher;
+    }
+
+    @Override
+    public boolean matches(T target) {
+        if (matcher.matches(target.getDeclaredAnnotations())) {
+            return true;
+        }
+        String name = target.getName();
+        ParameterList<?> parameters = target.getParameters();
+
+        TypeDefinition declaringType = target.getDeclaringType();
+        return recursiveMatches(declaringType, name, parameters);
+    }
+
+
+    private boolean recursiveMatches(TypeDefinition typeDefinition, String methodName, ParameterList<?> parameters) {
+        TypeList.Generic interfaces = typeDefinition.getInterfaces();
+        for (TypeDescription.Generic implInterface : interfaces) {
+            if (recursiveMatches(implInterface, methodName, parameters)) {
+                return true;
+            }
+            MethodList<MethodDescription.InGenericShape> declaredMethods = implInterface.getDeclaredMethods();
+            for (MethodDescription declaredMethod : declaredMethods) {
+                if (Objects.equals(declaredMethod.getName(), methodName) && parameterEquals(parameters, declaredMethod.getParameters())) {
+                    return matcher.matches(declaredMethod.getDeclaredAnnotations());
+                }
+            }
+        }
+        return false;
+    }
+
+
+    private boolean parameterEquals(ParameterList<?> source, ParameterList<?> impl) {
+        if (source.size() != impl.size()) {
+            return false;
+        }
+        for (int i = 0; i < source.size(); i++) {
+            if (!Objects.equals(source.get(i).getType(), impl.get(i).getType())) {
+                return false;
+            }
+        }
+        return true;
+    }
+
+    public static <T extends AnnotationSource> ElementMatcher.Junction<T> isInheritsAnnotatedWith(ElementMatcher<? super TypeDescription> matcher) {","[{'comment': 'Inherit is a verb. This method name should be `byMethodInheritanceAnnotationMatcher`', 'commenter': 'wu-sheng'}]"
4278,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/match/MethodInheritsDeclaringAnnotationMatcher.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.match;
+
+import net.bytebuddy.build.HashCodeAndEqualsPlugin;
+import net.bytebuddy.description.annotation.AnnotationList;
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.description.method.MethodList;
+import net.bytebuddy.description.method.ParameterList;
+import net.bytebuddy.description.type.TypeDefinition;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.description.type.TypeList;
+import net.bytebuddy.matcher.CollectionItemMatcher;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Objects;
+
+import static net.bytebuddy.matcher.ElementMatchers.annotationType;
+
+/**
+ * Matching used to match method annotations, Can match annotations on interface methods
+ * @auther jialong
+ */
+@HashCodeAndEqualsPlugin.Enhance
+public class MethodInheritsDeclaringAnnotationMatcher<T extends MethodDescription> extends ElementMatcher.Junction.AbstractBase<T> {","[{'comment': 'Should rename to `MethodInheritanceAnnotationMatcher`', 'commenter': 'wu-sheng'}]"
4278,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/match/MethodInheritanceAnnotationMatcher.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+package org.apache.skywalking.apm.agent.core.plugin.match;
+
+import net.bytebuddy.build.HashCodeAndEqualsPlugin;
+import net.bytebuddy.description.annotation.AnnotationList;
+import net.bytebuddy.description.annotation.AnnotationSource;
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.description.method.MethodList;
+import net.bytebuddy.description.method.ParameterList;
+import net.bytebuddy.description.type.TypeDefinition;
+import net.bytebuddy.description.type.TypeDescription;
+import net.bytebuddy.description.type.TypeList;
+import net.bytebuddy.matcher.CollectionItemMatcher;
+import net.bytebuddy.matcher.ElementMatcher;
+
+import java.util.Objects;
+
+import static net.bytebuddy.matcher.ElementMatchers.annotationType;
+
+/**
+ * Matching used to match method annotations, Can match annotations on interface methods
+ * @auther jialong","[{'comment': 'Still, `@auther` is not a valid JavaDoc\r\n\r\n```suggestion\r\n * @author jialong\r\n```', 'commenter': 'kezhenxu94'}]"
4327,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/util/TagUtil.java,"@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.context.util;
+
+import java.util.Map;
+
+import org.apache.skywalking.apm.agent.core.context.tag.StringTag;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.util.CustomizeExpression;
+
+/**
+ * @author: lxliuxuan Date: 2020/02/08","[{'comment': 'Remove author, please.', 'commenter': 'wu-sheng'}]"
4327,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/util/TagUtil.java,"@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.context.util;
+
+import java.util.Map;
+
+import org.apache.skywalking.apm.agent.core.context.tag.StringTag;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.util.CustomizeExpression;
+
+public class TagUtil {
+    public static void tagParamsSpan(final AbstractSpan span, final Map<String, Object> context,
+                                     String key, String value) {
+        new StringTag(key).set(span, CustomizeExpression.parseExpression(value, context));
+    }
+
+    public static void tagReturnSpanSpan(final AbstractSpan span, final Map<String, Object> context,
+                                         String key, String value) {
+        new StringTag(key).set(span, CustomizeExpression.parseReturnExpression(value, context));
+    }
+
+    public static Boolean isReturnTag(String expression) {
+        String[] es = expression.split(""\\."");
+        return es.length == 2 && ""returnedObj"".equals(es[0]);","[{'comment': 'Why `length==2` is required?', 'commenter': 'wu-sheng'}, {'comment': 'because expression just support string like returnedObj.xxxxx', 'commenter': 'lxliuxuankb'}]"
4327,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/util/TagUtil.java,"@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.context.util;
+
+import java.util.Map;
+
+import org.apache.skywalking.apm.agent.core.context.tag.StringTag;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.util.CustomizeExpression;
+
+public class TagUtil {","[{'comment': 'Why do we need a Util at this core level?', 'commenter': 'wu-sheng'}, {'comment': ""You are just changing a single plugin, don't change anything in the core level, unless it is really necessary. For this case, it doesn't seem so."", 'commenter': 'wu-sheng'}, {'comment': 'because TraceAnnotationMethodInterceptor  and TagAnnotationMethodInterceptor also have some same methods, so move these method into TagUtil', 'commenter': 'lxliuxuankb'}, {'comment': 'But you moved the TagUtil into the core, that is not right.', 'commenter': 'wu-sheng'}, {'comment': 'ok ,i will fix this', 'commenter': 'lxliuxuankb'}]"
4327,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-activation/src/main/java/org/apache/skywalking/apm/toolkit/activation/trace/TagAnnotationMethodInterceptor.java,"@@ -54,19 +54,18 @@ public void beforeMethod(
         final Tags tags = method.getAnnotation(Tags.class);
         if (tags != null && tags.value().length > 0) {
             for (final Tag tag : tags.value()) {
-                tagSpan(activeSpan, tag, context);
+                if (!TagUtil.isReturnTag(tag.value())) {
+                    TagUtil.tagParamsSpan(activeSpan, context, tag.key(), tag.value());
+                }
             }
         }
 
         final Tag tag = method.getAnnotation(Tag.class);
-        if (tag != null) {
-            tagSpan(activeSpan, tag, context);
+        if (tag != null && !TagUtil.isReturnTag(tag.value())) {
+            TagUtil.tagParamsSpan(activeSpan, context, tag.key(), tag.value());
         }
     }
 
-    private void tagSpan(final AbstractSpan span, final Tag tag, final Map<String, Object> context) {","[{'comment': 'Why remove this method out of here?', 'commenter': 'wu-sheng'}, {'comment': 'because TraceAnnotationMethodInterceptor  and TagAnnotationMethodInterceptor also have this method, so move this method into TagUtil', 'commenter': 'lxliuxuankb'}]"
4327,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-activation/src/main/java/org/apache/skywalking/apm/toolkit/activation/trace/TagAnnotationMethodInterceptor.java,"@@ -75,6 +74,25 @@ public Object afterMethod(
         final Object[] allArguments,
         final Class<?>[] argumentsTypes,
         final Object ret) {
+        if (ret == null || !ContextManager.isActive()) {
+            ContextManager.stopSpan();
+            return ret;","[{'comment': 'Move these two lines into the final block.', 'commenter': 'wu-sheng'}]"
4327,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-activation/src/main/java/org/apache/skywalking/apm/toolkit/activation/util/TagUtil.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.toolkit.activation.util;
+
+import java.util.Map;
+
+import org.apache.skywalking.apm.agent.core.context.tag.StringTag;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.util.CustomizeExpression;
+import org.apache.skywalking.apm.toolkit.trace.Tag;
+
+public class TagUtil {
+    public static void tagParamsSpan(final AbstractSpan span, final Map<String, Object> context,
+                                     final Tag tag) {
+        new StringTag(tag.key()).set(span, CustomizeExpression.parseExpression(tag.value(), context));
+    }
+
+    public static void tagReturnSpanSpan(final AbstractSpan span, final Map<String, Object> context,
+                                         final Tag tag) {
+        new StringTag(tag.key()).set(span, CustomizeExpression.parseReturnExpression(tag.value(), context));
+    }
+
+    public static Boolean isReturnTag(String expression) {
+        String[] es = expression.split(""\\."");
+        return es.length == 2 && ""returnedObj"".equals(es[0]);","[{'comment': '`returnedObj` has a specific meaning, should be adding into the document. https://github.com/apache/skywalking/blob/master/docs/en/setup/service-agent/java-agent/Application-toolkit-trace.md', 'commenter': 'wu-sheng'}]"
4327,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-activation/src/main/java/org/apache/skywalking/apm/toolkit/activation/trace/TagAnnotationMethodInterceptor.java,"@@ -46,23 +46,47 @@ public void beforeMethod(final EnhancedInstance objInst, final Method method, fi
         final Tags tags = method.getAnnotation(Tags.class);
         if (tags != null && tags.value().length > 0) {
             for (final Tag tag : tags.value()) {
-                tagSpan(activeSpan, tag, context);
+                if (!TagUtil.isReturnTag(tag.value())) {
+                    TagUtil.tagParamsSpan(activeSpan, context, tag);
+                }
             }
         }
 
         final Tag tag = method.getAnnotation(Tag.class);
-        if (tag != null) {
-            tagSpan(activeSpan, tag, context);
+        if (tag != null && !TagUtil.isReturnTag(tag.value())) {
+            TagUtil.tagParamsSpan(activeSpan, context, tag);
         }
     }
 
-    private void tagSpan(final AbstractSpan span, final Tag tag, final Map<String, Object> context) {
-        new StringTag(tag.key()).set(span, CustomizeExpression.parseExpression(tag.value(), context));
-    }
 
     @Override
-    public Object afterMethod(final EnhancedInstance objInst, final Method method, final Object[] allArguments,
-        final Class<?>[] argumentsTypes, final Object ret) {
+    public Object afterMethod(
+        final EnhancedInstance objInst,
+        final Method method,
+        final Object[] allArguments,
+        final Class<?>[] argumentsTypes,
+        final Object ret) {
+        try {
+            if (ret == null || !ContextManager.isActive()) {
+                return ret;
+            }
+            final AbstractSpan localSpan = ContextManager.activeSpan();
+            final Map<String, Object> context = CustomizeExpression.evaluationReturnContext(ret);
+            final Tags tags = method.getAnnotation(Tags.class);
+            if (tags != null && tags.value().length > 0) {
+                for (final Tag tag : tags.value()) {
+                    if (TagUtil.isReturnTag(tag.value())) {
+                        TagUtil.tagReturnSpanSpan(localSpan, context, tag);
+                    }
+                }
+            }
+            final Tag tag = method.getAnnotation(Tag.class);
+            if (tag != null && TagUtil.isReturnTag(tag.value())) {
+                TagUtil.tagReturnSpanSpan(localSpan, context, tag);
+            }
+        } finally {
+            ContextManager.stopSpan();","[{'comment': 'Sorry, this is not right. This could be NPE, if `ContextManager.isActive() == false`, right? In `#beforeMethod`,  there is \r\n```java\r\nif (!ContextManager.isActive()) {\r\n            return;\r\n        }\r\n```', 'commenter': 'wu-sheng'}, {'comment': ""We don't create span in the `#beforeMethod`, so please remove the `stopSpan()` here, we  cannot stop a span by mistake here"", 'commenter': 'kezhenxu94'}]"
4327,apm-sniffer/apm-toolkit-activation/apm-toolkit-trace-activation/src/main/java/org/apache/skywalking/apm/toolkit/activation/trace/TraceAnnotationMethodInterceptor.java,"@@ -56,24 +56,41 @@ public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allAr
         final Tags tags = method.getAnnotation(Tags.class);
         if (tags != null && tags.value().length > 0) {
             for (final Tag tag : tags.value()) {
-                tagSpan(localSpan, tag, context);
+                if (!TagUtil.isReturnTag(tag.value())) {
+                    TagUtil.tagParamsSpan(localSpan, context, tag);
+                }
             }
         }
-
         final Tag tag = method.getAnnotation(Tag.class);
-        if (tag != null) {
-            tagSpan(localSpan, tag, context);
+        if (tag != null && !TagUtil.isReturnTag(tag.value())) {
+            TagUtil.tagParamsSpan(localSpan, context, tag);
         }
     }
 
-    private void tagSpan(final AbstractSpan span, final Tag tag, final Map<String, Object> context) {
-        new StringTag(tag.key()).set(span, CustomizeExpression.parseExpression(tag.value(), context));
-    }
-
     @Override
     public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes,
         Object ret) throws Throwable {
-        ContextManager.stopSpan();
+        try {
+            if (ret == null) {
+                return ret;
+            }
+            final AbstractSpan localSpan = ContextManager.activeSpan();
+            final Map<String, Object> context = CustomizeExpression.evaluationReturnContext(ret);
+            final Tags tags = method.getAnnotation(Tags.class);
+            if (tags != null && tags.value().length > 0) {
+                for (final Tag tag : tags.value()) {
+                    if (TagUtil.isReturnTag(tag.value())) {
+                        TagUtil.tagReturnSpanSpan(localSpan, context, tag);
+                    }
+                }
+            }
+            final Tag tag = method.getAnnotation(Tag.class);
+            if (tag != null && TagUtil.isReturnTag(tag.value())) {
+                TagUtil.tagReturnSpanSpan(localSpan, context, tag);
+            }
+        } finally {
+            ContextManager.stopSpan();","[{'comment': 'Same here.', 'commenter': 'wu-sheng'}, {'comment': ""> Same here.\r\n\r\nThere is no conditional creation of span in the `#beforeMethod`, so it's right here"", 'commenter': 'kezhenxu94'}]"
4353,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/DurationUtils.java,"@@ -213,4 +213,36 @@ private DateTime parseToDateTime(Downsampling downsampling, long time) {
         }
         throw new UnexpectedException(""Unexpected downsampling: "" + downsampling.name());
     }
+
+    public DateTime startTimeBucket2DateTime(Downsampling downsampling, long startTB) {","[{'comment': ""First, time covert should be inside `TimeBucket`, take a look at InfluxDB, https://github.com/apache/skywalking/pull/4239/files#diff-df3b7b3f55b25fb0e29e345e7e6cc078. Maybe good for you.\r\nI think you don't need the `DateTime`? Directly convert to long as day/month makes more sense?"", 'commenter': 'wu-sheng'}, {'comment': 'Currently, you covert to DateTime, then cover to long like `202002`, but actually, you could use divide to get `202002` directly and more quickly, right?', 'commenter': 'wu-sheng'}, {'comment': 'Indeed, it maybe faster to convert to long like 202002. When the timebucket scope in loop statement add one day or month will trouble. Or maybe convert to timestamps，comparing and adding will fast，but also has to convert to Date string.', 'commenter': 'Unknown'}, {'comment': 'Why do you need to add? The current prefix should be enough. `2020021015`-`2020021315` to days is 20200210`-`20200213`\r\n\r\nDo I miss anything?', 'commenter': 'wu-sheng'}, {'comment': 'When crossing months, you need to consider the big and small months. In addition, you need to consider some leap years. like `20200227-20200305`', 'commenter': 'Unknown'}, {'comment': 'OK, got it, make sense. ', 'commenter': 'wu-sheng'}]"
4353,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/ModelName.java,"@@ -30,10 +43,73 @@ public static String build(Downsampling downsampling, String modelName) {
                 return modelName + Const.ID_SPLIT + Downsampling.Day.getName();
             case Hour:
                 return modelName + Const.ID_SPLIT + Downsampling.Hour.getName();
-            //            case Second:
-            //                return modelName + Const.ID_SPLIT + Downsampling.Second.getName();
             default:
                 return modelName;
         }
     }
+
+    public static String[] build(Downsampling downsampling, String modelName, long startTB, long endTB) {","[{'comment': 'This build method is for ES storage only, please move inside the plugin.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'Unknown'}]"
4353,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/ModelName.java,"@@ -30,10 +43,73 @@ public static String build(Downsampling downsampling, String modelName) {
                 return modelName + Const.ID_SPLIT + Downsampling.Day.getName();
             case Hour:
                 return modelName + Const.ID_SPLIT + Downsampling.Hour.getName();
-            //            case Second:
-            //                return modelName + Const.ID_SPLIT + Downsampling.Second.getName();
             default:
                 return modelName;
         }
     }
+
+    public static String[] build(Downsampling downsampling, String modelName, long startTB, long endTB) {
+        List<String> indexNameList = new ArrayList<>();
+
+        List<String> whiteIndexList = new ArrayList<String>() {","[{'comment': 'This should be a static list, rather than create everytime.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'Unknown'}]"
4353,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -291,6 +292,30 @@ public SearchResponse search(String indexName, SearchSourceBuilder searchSourceB
         return client.search(searchRequest);
     }
 
+    public SearchResponse search(String[] indexNames, SearchSourceBuilder searchSourceBuilder) throws IOException {","[{'comment': 'Add comments for these methods.', 'commenter': 'wu-sheng'}, {'comment': 'Also relate to `String[] indexNames`, should we keep all in List and covert to array at last minute?', 'commenter': 'wu-sheng'}, {'comment': 'good idea', 'commenter': 'Unknown'}]"
4353,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -291,6 +292,30 @@ public SearchResponse search(String indexName, SearchSourceBuilder searchSourceB
         return client.search(searchRequest);
     }
 
+    public SearchResponse search(String[] indexNames, SearchSourceBuilder searchSourceBuilder) throws IOException {
+        String[] fullIndexNames = formatIndexNames(indexNames);
+        SearchRequest searchRequest = new SearchRequest(fullIndexNames);
+        searchRequest.types(TYPE);
+        searchRequest.source(searchSourceBuilder);
+        return client.search(searchRequest);
+    }
+
+    public String[] filterNotExistIndex(String[] fullIndexNames, String indName) throws IOException {
+        // if no wrap, it is impossible to remove elements
+        List<String> indexNameList = new ArrayList<>(Arrays.asList(fullIndexNames));
+        if (fullIndexNames.length > 0) {
+            List<String> existIndex = retrievalIndexByAliases(indName);
+            indexNameList.removeIf(indexName -> {
+                //only filter index name with xxxx-xxxx
+                if (indexName.contains(""-"")) {","[{'comment': ""Which one doesn't contain `-`?"", 'commenter': 'wu-sheng'}, {'comment': 'for example `segment alarm_record`', 'commenter': 'Unknown'}, {'comment': 'Use `Const#LINE`', 'commenter': 'wu-sheng'}, {'comment': 'ACK', 'commenter': 'Unknown'}, {'comment': 'server-core module depends on library-client module, so `Const#LINE` in server-core can not used in library-client module.', 'commenter': 'Unknown'}, {'comment': ""Then you could provide a filter func as the parameter to do the filter works. This indicates this logic doesn't belong to this class."", 'commenter': 'wu-sheng'}]"
4353,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/ModelName.java,"@@ -30,10 +43,73 @@ public static String build(Downsampling downsampling, String modelName) {
                 return modelName + Const.ID_SPLIT + Downsampling.Day.getName();
             case Hour:
                 return modelName + Const.ID_SPLIT + Downsampling.Hour.getName();
-            //            case Second:
-            //                return modelName + Const.ID_SPLIT + Downsampling.Second.getName();
             default:
                 return modelName;
         }
     }
+
+    public static String[] build(Downsampling downsampling, String modelName, long startTB, long endTB) {
+        List<String> indexNameList = new ArrayList<>();
+
+        List<String> whiteIndexList = new ArrayList<String>() {
+            {
+                add(EndpointInventory.INDEX_NAME);
+                add(NetworkAddressInventory.INDEX_NAME);
+                add(ServiceInventory.INDEX_NAME);
+                add(ServiceInstanceInventory.INDEX_NAME);
+            }
+        };
+
+        if (whiteIndexList.contains(modelName)) {
+            return new String[] { modelName };
+        }
+
+        DateTime startDT = DurationUtils.INSTANCE.startTimeBucket2DateTime(downsampling, startTB);
+        DateTime endDT = DurationUtils.INSTANCE.endTimeBucket2DateTime(downsampling, endTB);
+        if (endDT.isAfter(startDT)) {
+            switch (downsampling) {
+                case Month:
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMM.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusMonths(1);
+                    }
+                    break;
+                case Day:
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                case Hour:
+                    //current hour index is also suffix with YYYYMMDD
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                case Minute:
+                    //current minute index is also suffix with YYYYMMDD
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                case Second:
+                    //current second index is also suffix with YYYYMMDD
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                default:
+                    indexNameList.add(modelName);
+            }
+        }
+        return indexNameList.toArray(new String[0]);","[{'comment': 'You covert to array at the first place, but then you covert to List again in `#filterNotExistIndex`. Seems unnecessary?', 'commenter': 'wu-sheng'}, {'comment': 'If select a date with a long span, which dates are not in the middle, or the system has been stopped for a few days, there may be no index data for several days. If you query date  contain those days directly, searching the index will appear `index not found exception`. so, Did a filter that the date index does not exist', 'commenter': 'Unknown'}, {'comment': 'Did you answer the question in the wrong context? I am not saying `filterNotExistIndex` is useless.\r\n\r\nBut based on the things you talked, I think you should establish a cache to `filterNotExistIndex` and cache the result for at least a day, considering the index could only be deleted day by day, right? Set up a guava cache with `#expireAfterWrite`?', 'commenter': 'wu-sheng'}, {'comment': '> Did you answer the question in the wrong context? I am not saying `filterNotExistIndex` is useless.\r\n\r\nOh, Let me perfect it. Convert at last minitue.\r\n\r\n> But based on the things you talked, I think you should establish a cache to `filterNotExistIndex` and cache the result for at least a day, considering the index could only be deleted day by day, right? Set up a guava cache with `#expireAfterWrite`?\r\n\r\nGood advice, i will try.\r\n\r\n\r\n', 'commenter': 'Unknown'}]"
4353,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/base/EsModelName.java,"@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base;
+
+import java.util.ArrayList;
+import java.util.LinkedList;
+import java.util.List;
+import org.apache.skywalking.oap.server.core.analysis.Downsampling;
+import org.apache.skywalking.oap.server.core.query.DurationUtils;
+import org.apache.skywalking.oap.server.core.register.EndpointInventory;
+import org.apache.skywalking.oap.server.core.register.NetworkAddressInventory;
+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;
+import org.apache.skywalking.oap.server.core.register.ServiceInventory;
+import org.apache.skywalking.oap.server.core.storage.model.ModelName;
+import org.joda.time.DateTime;
+import org.joda.time.format.DateTimeFormat;
+import org.joda.time.format.DateTimeFormatter;
+
+public class EsModelName extends ModelName {
+
+    private static final DateTimeFormatter YYYYMM = DateTimeFormat.forPattern(""yyyyMM"");
+    private static final DateTimeFormatter YYYYMMDD = DateTimeFormat.forPattern(""yyyyMMdd"");
+
+    public static final List<String> WHITE_INDEX_LIST = new ArrayList<String>() {
+        {
+            add(EndpointInventory.INDEX_NAME);
+            add(NetworkAddressInventory.INDEX_NAME);
+            add(ServiceInventory.INDEX_NAME);
+            add(ServiceInstanceInventory.INDEX_NAME);
+        }
+    };
+
+    public static List<String> build(Downsampling downsampling, String modelName, long startTB, long endTB) {
+        if (WHITE_INDEX_LIST.contains(modelName)) {
+            return new ArrayList<String>() {
+                {
+                    add(modelName);
+                }
+            };
+        }
+
+        List<String> indexNameList = new LinkedList<>();
+        DateTime startDT = DurationUtils.INSTANCE.startTimeBucket2DateTime(downsampling, startTB);
+        DateTime endDT = DurationUtils.INSTANCE.endTimeBucket2DateTime(downsampling, endTB);
+        if (endDT.isAfter(startDT)) {
+            switch (downsampling) {
+                case Month:
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMM.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusMonths(1);
+                    }
+                    break;
+                case Day:
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                case Hour:
+                    //current hour index is also suffix with YYYYMMDD
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                case Minute:
+                    //current minute index is also suffix with YYYYMMDD
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;
+                case Second:
+                    //current second index is also suffix with YYYYMMDD
+                    while (endDT.isAfter(startDT)) {
+                        String indexName = build(downsampling, modelName) + ""-"" + YYYYMMDD.print(startDT);
+                        indexNameList.add(indexName);
+                        startDT = startDT.plusDays(1);
+                    }
+                    break;","[{'comment': 'These can be merged into the `case Day` path, to reduce code duplicates ', 'commenter': 'kezhenxu94'}, {'comment': 'ACK', 'commenter': 'Unknown'}]"
4353,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/base/EsModelName.java,"@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base;
+
+import java.util.ArrayList;
+import java.util.LinkedList;
+import java.util.List;
+import org.apache.skywalking.oap.server.core.analysis.Downsampling;
+import org.apache.skywalking.oap.server.core.query.DurationUtils;
+import org.apache.skywalking.oap.server.core.register.EndpointInventory;
+import org.apache.skywalking.oap.server.core.register.NetworkAddressInventory;
+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;
+import org.apache.skywalking.oap.server.core.register.ServiceInventory;
+import org.apache.skywalking.oap.server.core.storage.model.ModelName;
+import org.joda.time.DateTime;
+import org.joda.time.format.DateTimeFormat;
+import org.joda.time.format.DateTimeFormatter;
+
+public class EsModelName extends ModelName {
+
+    private static final DateTimeFormatter YYYYMM = DateTimeFormat.forPattern(""yyyyMM"");
+    private static final DateTimeFormatter YYYYMMDD = DateTimeFormat.forPattern(""yyyyMMdd"");
+
+    public static final List<String> WHITE_INDEX_LIST = new ArrayList<String>() {
+        {
+            add(EndpointInventory.INDEX_NAME);
+            add(NetworkAddressInventory.INDEX_NAME);
+            add(ServiceInventory.INDEX_NAME);
+            add(ServiceInstanceInventory.INDEX_NAME);
+        }
+    };","[{'comment': ""This is not a good practice to initialize a list, it creates an unnecessary inner class. Based on your usage, please consider make it immutable by `com.google.common.collect.Sets#newHashSet(E...)`, because you're always using the `contains` method to determine the existence, `Set` should be faster IMHO"", 'commenter': 'kezhenxu94'}]"
4353,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/DurationUtils.java,"@@ -213,4 +213,36 @@ private DateTime parseToDateTime(Downsampling downsampling, long time) {
         }
         throw new UnexpectedException(""Unexpected downsampling: "" + downsampling.name());
     }
+
+    public DateTime startTimeBucket2DateTime(Downsampling downsampling, long startTB) {
+        switch (downsampling) {
+            case Month:
+                return YYYYMM.parseDateTime(String.valueOf(startTB));
+            case Day:
+                return YYYYMMDD.parseDateTime(String.valueOf(startTB));
+            case Hour:
+                return YYYYMMDDHH.parseDateTime(String.valueOf(startTB));
+            case Minute:
+                return YYYYMMDDHHMM.parseDateTime(String.valueOf(startTB));
+            case Second:
+                return YYYYMMDDHHMMSS.parseDateTime(String.valueOf(startTB));
+        }
+        throw new UnexpectedException(""Unexpected downsampling: "" + downsampling.name());
+    }
+
+    public DateTime endTimeBucket2DateTime(Downsampling downsampling, long endTB) {
+        switch (downsampling) {
+            case Month:
+                return YYYYMM.parseDateTime(String.valueOf(endTB));
+            case Day:
+                return YYYYMMDD.parseDateTime(String.valueOf(endTB));
+            case Hour:
+                return YYYYMMDDHH.parseDateTime(String.valueOf(endTB));
+            case Minute:
+                return YYYYMMDDHHMM.parseDateTime(String.valueOf(endTB));
+            case Second:
+                return YYYYMMDDHHMMSS.parseDateTime(String.valueOf(endTB));
+        }
+        throw new UnexpectedException(""Unexpected downsampling: "" + downsampling.name());","[{'comment': 'The logic seems not to be related to `startTime` or `endTime`, so I don\'t think it\'s a good method name `endTimeBucket2DateTime ` or `startTimeBucket2DateTime `, and the method body are exactly the same in `parseToDateTime`, if you meant it, simply use `parseToDateTime` is enough? Otherwise, you may forget to `.plusMonths(1)`, `plusDays(1)`, etc. like `org.apache.skywalking.oap.server.core.query.DurationUtils#endTimeToTimestamp`\r\n\r\n```java\r\n\r\n    public long endTimeToTimestamp(Step step, String dateStr) {\r\n        switch (step) {\r\n            case MONTH:\r\n                return YYYY_MM.parseDateTime(dateStr).plusMonths(1).getMillis();\r\n            case DAY:\r\n                return YYYY_MM_DD.parseDateTime(dateStr).plusDays(1).getMillis();\r\n            case HOUR:\r\n                return YYYY_MM_DD_HH.parseDateTime(dateStr).plusHours(1).getMillis();\r\n            case MINUTE:\r\n                return YYYY_MM_DD_HHMM.parseDateTime(dateStr).plusMinutes(1).getMillis();\r\n            case SECOND:\r\n                return YYYY_MM_DD_HHMMSS.parseDateTime(dateStr).plusSeconds(1).getMillis();\r\n        }\r\n        throw new UnexpectedException(""Unsupported step "" + step.name());\r\n    }\r\n```', 'commenter': 'kezhenxu94'}]"
4353,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -403,4 +421,11 @@ public String formatIndexName(String indexName) {
         }
         return indexName;
     }
+
+    public List<String> formatIndexNames(List<String> indexNameList) {
+        if (StringUtil.isNotEmpty(namespace)) {
+            indexNameList.stream().map(indexName -> namespace + ""_"" + indexName);","[{'comment': 'Bug here, you map the `indexNameList` but ignore the result, the `indexNameList` itself is unchanged', 'commenter': 'kezhenxu94'}]"
4353,oap-server/server-library/library-client/src/main/java/org/apache/skywalking/oap/server/library/client/elasticsearch/ElasticSearchClient.java,"@@ -291,6 +291,24 @@ public SearchResponse search(String indexName, SearchSourceBuilder searchSourceB
         return client.search(searchRequest);
     }
 
+    /**
+     * Search results from ES search engine according to various search conditions,
+     * Note the method is usered for the list of index names is optimized based on
+     * the scope of startTimeBucket and endTimeBucket
+     * @param indexNameList  full index names list base on timebucket scope.
+     * Except for endpoint_inventory network_address_inventory service_inventory service_instance_inventory
+     * @param searchSourceBuilder Various search query conditions
+     * @return ES search query results
+     * @throws IOException throw IOException","[{'comment': 'not a good java doc: `throw IOException`, better to describe **WHEN** the exception is thrown', 'commenter': 'kezhenxu94'}]"
4353,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/base/EsModelName.java,"@@ -0,0 +1,107 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base;
+
+import java.util.ArrayList;
+import java.util.LinkedList;
+import java.util.List;
+import org.apache.skywalking.oap.server.core.analysis.Downsampling;
+import org.apache.skywalking.oap.server.core.query.DurationUtils;
+import org.apache.skywalking.oap.server.core.register.EndpointInventory;
+import org.apache.skywalking.oap.server.core.register.NetworkAddressInventory;
+import org.apache.skywalking.oap.server.core.register.ServiceInstanceInventory;
+import org.apache.skywalking.oap.server.core.register.ServiceInventory;
+import org.apache.skywalking.oap.server.core.storage.model.ModelName;
+import org.joda.time.DateTime;
+import org.joda.time.format.DateTimeFormat;
+import org.joda.time.format.DateTimeFormatter;
+
+public class EsModelName extends ModelName {
+
+    private static final DateTimeFormatter YYYYMM = DateTimeFormat.forPattern(""yyyyMM"");
+    private static final DateTimeFormatter YYYYMMDD = DateTimeFormat.forPattern(""yyyyMMdd"");
+
+    public static final List<String> WHITE_INDEX_LIST = new ArrayList<String>() {
+        {
+            add(EndpointInventory.INDEX_NAME);
+            add(NetworkAddressInventory.INDEX_NAME);
+            add(ServiceInventory.INDEX_NAME);
+            add(ServiceInstanceInventory.INDEX_NAME);
+        }
+    };
+
+    public static List<String> build(Downsampling downsampling, String modelName, long startTB, long endTB) {
+        if (WHITE_INDEX_LIST.contains(modelName)) {
+            return new ArrayList<String>() {
+                {
+                    add(modelName);
+                }
+            };","[{'comment': 'Same here, please be careful when using this kind of initialization, it creates unnecessary inner class, if you always use this, there may be many many unnecessary inner classes, exploding the meta space of the JVM, and the problem is that we have much better method to  do this, like `Arrays.asList`, Guava list, etc.: \r\n\r\n```java\r\n              new ArrayList<String>() {\r\n                  {\r\n                      add(modelName);\r\n                  }\r\n              };\r\n```', 'commenter': 'kezhenxu94'}]"
4363,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/consumer/MultipleChannelsConsumer.java,"@@ -30,12 +31,13 @@
 public class MultipleChannelsConsumer extends Thread {
     private volatile boolean running;
     private volatile ArrayList<Group> consumeTargets;
-    private volatile long size;
+    private final AtomicLong size;","[{'comment': 'This is just for changed value accessable from other consumer thread. No requirement for AtomicLong.', 'commenter': 'wu-sheng'}]"
4363,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/GRPCChannelManager.java,"@@ -48,7 +49,7 @@
     private final List<GRPCChannelListener> listeners = Collections.synchronizedList(new LinkedList<>());
     private volatile List<String> grpcServers;
     private volatile int selectedIdx = -1;
-    private volatile int reconnectCount = 0;
+    private AtomicInteger reconnectCount = new AtomicInteger(0);","[{'comment': 'Why AtomicInteger?', 'commenter': 'wu-sheng'}]"
4363,apm-commons/apm-datacarrier/src/main/java/org/apache/skywalking/apm/commons/datacarrier/partition/SimpleRollingPartitioner.java,"@@ -18,15 +18,17 @@
 
 package org.apache.skywalking.apm.commons.datacarrier.partition;
 
+import java.util.concurrent.atomic.AtomicInteger;
+
 /**
  * use normal int to rolling.
  */
 public class SimpleRollingPartitioner<T> implements IDataPartitioner<T> {
-    private volatile int i = 0;
+    private AtomicInteger i = new AtomicInteger(0);","[{'comment': 'This will cause performance cost without much meaning. Rolling is for switching different channels, there is no need to be strict rule. ', 'commenter': 'wu-sheng'}]"
4385,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/metrics/IntKeyLongValueHashMap.java,"@@ -57,6 +58,9 @@ public String toStorageData() {
 
     @Override
     public void toObject(String data) {
+        if (Strings.isNullOrEmpty(data)) {","[{'comment': 'Personally, I want to say, this is harmful change. This `data` should not generate if there is no value of this column. `Calculate` func should make sure the `value` column is generated rather than using this `null` check. Such as `PercentileMetrics#calculate`, it guarantees the 5 values generated permanently. If there is no value, put the default value based on this metrics func, otherwise, which value should be shown up in the final query?', 'commenter': 'wu-sheng'}, {'comment': '@hanahmily Any feedback?', 'commenter': 'wu-sheng'}]"
4416,oap-server/server-tools/tool-profile-snapshot-bootstrap/src/main/java/org/apache/skywalking/oap/server/tool/profile/exporter/ExporterConfig.java,"@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.tool.profile.exporter;
+
+import lombok.Data;
+
+import java.io.File;
+
+@Data
+public class ExporterConfig {
+
+    // profile task id
+    private String taskId;
+
+    // profiled trace id
+    private String traceId;
+
+    // export to file path
+    private String analyzeResultDist;
+
+    /**
+     * parse config from command line
+     */
+    public static ExporterConfig parse(String[] args) {
+        if (args == null || args.length != 3) {
+            throw new IllegalArgumentException(""missing config, replace recheck"");","[{'comment': 'what\'s ""replace recheck""?', 'commenter': 'kezhenxu94'}, {'comment': 'I mean ""please recheck"", has fixed. ', 'commenter': 'mrproliu'}]"
4416,oap-server/server-tools/tool-profile-snapshot-bootstrap/src/main/java/org/apache/skywalking/oap/server/tool/profile/exporter/ExporterConfig.java,"@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.tool.profile.exporter;
+
+import lombok.Data;
+
+import java.io.File;
+
+@Data
+public class ExporterConfig {
+
+    // profile task id
+    private String taskId;
+
+    // profiled trace id
+    private String traceId;
+
+    // export to file path
+    private String analyzeResultDist;
+
+    /**
+     * parse config from command line
+     */
+    public static ExporterConfig parse(String[] args) {
+        if (args == null || args.length != 3) {
+            throw new IllegalArgumentException(""missing config, replace recheck"");
+        }
+
+        // build config
+        ExporterConfig config = new ExporterConfig();
+        config.setTaskId(args[0]);
+        config.setTraceId(args[1]);
+        config.setAnalyzeResultDist(args[2]);
+
+        return config;
+    }
+
+    /**
+     * initialize config, such as check dist path
+     */
+    public void init() {
+        File dist = new File(analyzeResultDist);
+        if (!dist.exists()) {
+            dist.mkdirs();
+            return;
+        }
+
+        if (dist.isFile()) {
+            throw new IllegalArgumentException(analyzeResultDist + "" must a directory"");","[{'comment': '```suggestion\r\n            throw new IllegalArgumentException(analyzeResultDist + "" must be a directory"");\r\n```', 'commenter': 'kezhenxu94'}]"
4416,apm-dist/src/main/assembly/binary.xml,"@@ -75,6 +75,12 @@
             <outputDirectory>/agent</outputDirectory>
         </fileSet>
 
+        <!-- Profile exporter tools -->
+        <fileSet>
+            <directory>${project.basedir}/../tools/profile</directory>
+            <outputDirectory>/tools/profile</outputDirectory>","[{'comment': 'better to name it ""exporter""? It\'s essentially an exporter, not a ""profile""\r\n', 'commenter': 'kezhenxu94'}, {'comment': 'Sure, should I need to add a subdirectory on the ""exporter"" named ""profile""? Because there have multiple files. ', 'commenter': 'mrproliu'}, {'comment': 'Good to me', 'commenter': 'kezhenxu94'}, {'comment': 'I think renaming makes more sense then going into a deeper path. `profile-exporter` is a tool already.', 'commenter': 'wu-sheng'}]"
4416,oap-server/server-tools/tool-profile-snapshot-bootstrap/src/test/java/org/apache/skywalking/oap/server/tool/profile/exporter/ProfileExportedAnalyze.java,"@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.tool.profile.exporter;
+
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.language.profile.ThreadSnapshot;
+import org.apache.skywalking.oap.server.core.query.entity.Span;
+
+import java.io.File;
+import java.io.IOException;
+import java.util.List;
+import java.util.Objects;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class ProfileExportedAnalyze {
+
+    public static void main(String[] args) throws IOException {","[{'comment': 'Is this a test? if not, seems not suitable to put it here', 'commenter': 'kezhenxu94'}, {'comment': 'I will be working on analyze exported data files when getting some profile future feedback. If it not necessary, I will delete this file.', 'commenter': 'mrproliu'}, {'comment': '> I will be working on analyze exported data files when getting some profile future feedback. If it not necessary, I will delete this file.\r\n\r\nWell, if this PR is still under construction, please use **Draft a Pull Request**, or add [WIP] in the title', 'commenter': 'kezhenxu94'}, {'comment': '> > I will be working on analyze exported data files when getting some profile future feedback. If it not necessary, I will delete this file.\r\n> \r\n> Well, if this PR is still under construction, please use **Draft a Pull Request**, or add [WIP] in the title\r\n\r\nSure. But this file is not in ""WIP"", maybe I need to delete it later.', 'commenter': 'mrproliu'}]"
4416,oap-server/server-tools/pom.xml,"@@ -0,0 +1,40 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>oap-server</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>7.0.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>server-tools</artifactId>
+    <packaging>pom</packaging>
+    <modules>
+        <module>tool-profile-snapshot-server-mock</module>
+        <module>tool-profile-snapshot-bootstrap</module>
+        <module>tool-profile-snapshot-exporter</module>
+        <module>tool-profile-snapshot-exporter-es7</module>","[{'comment': ""Seems the exporter doesn't depend on ES? Do you need two individual module?"", 'commenter': 'kezhenxu94'}, {'comment': 'It will use ES storage to dump trace and thread snapshots data, need to use ES7 to re-compile it. ', 'commenter': 'mrproliu'}]"
4416,tools/profile/profile_exporter.sh,"@@ -0,0 +1,107 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# This script relies on few environment variables to determine source code package
+# behavior, those variables are:
+#   RELEASE_VERSION -- The version of this source package.
+# For example: RELEASE_VERSION=5.0.0-alpha","[{'comment': 'Are these comments copied-and-pasted? Do them make sense in this file?', 'commenter': 'kezhenxu94'}, {'comment': 'Deleted. ', 'commenter': 'mrproliu'}]"
4416,tools/profile/profile_exporter.sh,"@@ -0,0 +1,107 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# This script relies on few environment variables to determine source code package
+# behavior, those variables are:
+#   RELEASE_VERSION -- The version of this source package.
+# For example: RELEASE_VERSION=5.0.0-alpha
+
+bin_path=$0
+exporter_dir=$(cd $(dirname $0); pwd)
+
+while [[ $# -gt 0 ]]; do
+  case ""$1"" in
+    --taskid=*)
+      task_id=${1#*=}
+      ;;
+    --traceid=*)
+      trace_id=${1#*=}
+      ;;
+    *)
+      dist=$1
+  esac
+  shift
+done
+
+echo ""${task_id}, ${trace_id}, ${dist}, ${workdir}, ${bin_path}""
+
+[[ ! ${task_id} || ! ${trace_id} || ! ${dist} ]] \
+  && echo 'Usage: sh tools/profile_exporter.sh [--taskid] [--traceid] export_path' \
+  && exit 1
+
+[[ ! -d ${dist} ]] \
+  && echo ""Cannot found export dist path: ${dist}"" \
+  && exit 1
+
+# prepare paths
+config_file=""${exporter_dir}/../../config/application.yml""
+oap_libs_dir=""${exporter_dir}/../../oap-libs""
+exporter_log_file=""${exporter_dir}/profile_exporter_log4j2.xml""
+awk_change_file=""${exporter_dir}/persist_core_and_storage.awk""
+[[ ! -f ${config_file} ]] \
+  && echo ""Cannot found oap application.yml"" \","[{'comment': '```suggestion\r\n  && echo ""Cannot find oap application.yml"" \\\r\n```', 'commenter': 'kezhenxu94'}]"
4416,tools/profile/profile_exporter.sh,"@@ -0,0 +1,107 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# This script relies on few environment variables to determine source code package
+# behavior, those variables are:
+#   RELEASE_VERSION -- The version of this source package.
+# For example: RELEASE_VERSION=5.0.0-alpha
+
+bin_path=$0
+exporter_dir=$(cd $(dirname $0); pwd)
+
+while [[ $# -gt 0 ]]; do
+  case ""$1"" in
+    --taskid=*)
+      task_id=${1#*=}
+      ;;
+    --traceid=*)
+      trace_id=${1#*=}
+      ;;
+    *)
+      dist=$1
+  esac
+  shift
+done
+
+echo ""${task_id}, ${trace_id}, ${dist}, ${workdir}, ${bin_path}""
+
+[[ ! ${task_id} || ! ${trace_id} || ! ${dist} ]] \
+  && echo 'Usage: sh tools/profile_exporter.sh [--taskid] [--traceid] export_path' \
+  && exit 1
+
+[[ ! -d ${dist} ]] \
+  && echo ""Cannot found export dist path: ${dist}"" \
+  && exit 1
+
+# prepare paths
+config_file=""${exporter_dir}/../../config/application.yml""
+oap_libs_dir=""${exporter_dir}/../../oap-libs""
+exporter_log_file=""${exporter_dir}/profile_exporter_log4j2.xml""
+awk_change_file=""${exporter_dir}/persist_core_and_storage.awk""
+[[ ! -f ${config_file} ]] \
+  && echo ""Cannot found oap application.yml"" \
+  && exit 1
+[[ ! -d ${oap_libs_dir} ]] \
+  && echo ""Cannot found oap libs path"" \","[{'comment': '```suggestion\r\n  && echo ""Cannot find oap libs path"" \\\r\n```', 'commenter': 'kezhenxu94'}]"
4416,tools/profile/profile_exporter.sh,"@@ -0,0 +1,107 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# This script relies on few environment variables to determine source code package
+# behavior, those variables are:
+#   RELEASE_VERSION -- The version of this source package.
+# For example: RELEASE_VERSION=5.0.0-alpha
+
+bin_path=$0
+exporter_dir=$(cd $(dirname $0); pwd)
+
+while [[ $# -gt 0 ]]; do
+  case ""$1"" in
+    --taskid=*)
+      task_id=${1#*=}
+      ;;
+    --traceid=*)
+      trace_id=${1#*=}
+      ;;
+    *)
+      dist=$1","[{'comment': '`dist` seems not to be a good name, we use `dist` in other tests to represent the distribution package', 'commenter': 'kezhenxu94'}, {'comment': '`export_path` is better.', 'commenter': 'wu-sheng'}]"
4416,tools/profile/profile_exporter.sh,"@@ -0,0 +1,107 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# This script relies on few environment variables to determine source code package
+# behavior, those variables are:
+#   RELEASE_VERSION -- The version of this source package.
+# For example: RELEASE_VERSION=5.0.0-alpha
+
+bin_path=$0
+exporter_dir=$(cd $(dirname $0); pwd)
+
+while [[ $# -gt 0 ]]; do
+  case ""$1"" in
+    --taskid=*)
+      task_id=${1#*=}
+      ;;
+    --traceid=*)
+      trace_id=${1#*=}
+      ;;
+    *)
+      dist=$1
+  esac
+  shift
+done
+
+echo ""${task_id}, ${trace_id}, ${dist}, ${workdir}, ${bin_path}""
+
+[[ ! ${task_id} || ! ${trace_id} || ! ${dist} ]] \
+  && echo 'Usage: sh tools/profile_exporter.sh [--taskid] [--traceid] export_path' \
+  && exit 1
+
+[[ ! -d ${dist} ]] \
+  && echo ""Cannot found export dist path: ${dist}"" \
+  && exit 1
+
+# prepare paths
+config_file=""${exporter_dir}/../../config/application.yml""
+oap_libs_dir=""${exporter_dir}/../../oap-libs""
+exporter_log_file=""${exporter_dir}/profile_exporter_log4j2.xml""
+awk_change_file=""${exporter_dir}/persist_core_and_storage.awk""
+[[ ! -f ${config_file} ]] \
+  && echo ""Cannot found oap application.yml"" \
+  && exit 1
+[[ ! -d ${oap_libs_dir} ]] \
+  && echo ""Cannot found oap libs path"" \
+  && exit 1
+
+# create current trace tempory path","[{'comment': '```suggestion\r\n# create current trace temporary path\r\n```', 'commenter': 'kezhenxu94'}]"
4416,docs/en/guides/backend-profile.md,"@@ -47,3 +47,6 @@ The reason for generating multiple top-level trees is that original data can be
     1. Use the same traversal node logic as in the `Combine stack trees` step. Convert to a GraphQL data structure, and put all nodes into a list for subsequent duration calculations.
     2. Calculate each node's duration in parallel. For each node, sort the sequences, if there are two continuous sequences, the duration should add the duration of these two seq's timestamp.
     3. Calculate each node execution in parallel. For each node, the duration of the current node should minus the time consumed by all children.
+
+## Profile data debug
+Please follow the [exporter tool](backend-profile-export.md#export-command-line-usage) to package profile data. Unzip the profile data and using [analyzer main function](../../../oap-server/server-tools/tool-profile-snapshot-bootstrap/src/test/java/org/apache/skywalking/oap/server/tool/profile/exporter/ProfileExportedAnalyze.java) to run it.","[{'comment': 'Is it suitable to put this kind of tool in the `test` scope?\r\n\r\n- Users have to clone the entire codebase, and set up the development environment, just to run this class?\r\n\r\n- Putting a standalone tool class in the `test` scope is just weird, IMHO, only auto-tests should locate in the `test` scope;\r\n\r\n- `ProfileExportedAnalyze` is not a ""test"" essentially\r\n\r\nWhy not make it another tool?\r\n\r\nWDYT @wu-sheng ', 'commenter': 'kezhenxu94'}, {'comment': ""Because it isn't a tool. You need the IDE to run and debug the codes. This is for developer only. The only case we use this, is user reported an unexpected analysis result, and we are trying to find out why."", 'commenter': 'wu-sheng'}, {'comment': 'well make sense then', 'commenter': 'kezhenxu94'}]"
4416,docs/en/FAQ/README.md,"@@ -21,3 +21,4 @@ These are known and common FAQs. We welcome you to contribute yours.
 * [""FORBIDDEN/12/index read-only / allow delete (api)"" appears in the log](https://discuss.elastic.co/t/forbidden-12-index-read-only-allow-delete-api/110282)
 * [No data shown and backend replies with ""Variable 'serviceId' has coerced Null value for NonNull type 'ID!'""](time-and-timezone.md)
 * [**Unexpected endpoint register** warning after 6.6.0](Unexpected-endpoint-register.md)
+* [Use the profile exporter tool if the profile analysis is not right?](../guides/backend-profile-export.md)","[{'comment': '\x08Should not have a question mark.', 'commenter': 'wu-sheng'}]"
4416,docs/en/guides/README.md,"@@ -146,6 +146,7 @@ miss any newly-added dependency:
 The performance profile is an enhancement feature in the APM system. We are using the thread dump to estimate the method execution time, rather than adding many local spans. In this way, the resource cost would be much less than using distributed tracing to locate slow method. This feature is suitable in the production environment. The following documents are important for developers to understand the key parts of this feature
 - [Profile data report procotol](https://github.com/apache/skywalking-data-collect-protocol/tree/master/profile) is provided like other trace, JVM data through gRPC.
 - [Thread dump merging mechanism](backend-profile.md) introduces the merging mechanism, which helps the end users to understand the profile report.
+- [Exporter tool of profile raw data](backend-profile-export.md) introduces when the visualization doesn't work well through the official UI, how to package the original profile data, which helps the users submit the issue to report.","[{'comment': ""```suggestion\r\n- [Exporter tool of profile raw data](backend-profile-export.md) introduces when the visualization doesn't work well through the official UI, how to package the original profile data, which helps the users report the issue.\r\n```"", 'commenter': 'wu-sheng'}]"
4416,tools/profile-exporter/profile_exporter.sh,"@@ -0,0 +1,100 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+bin_path=$0
+exporter_dir=$(cd $(dirname $0); pwd)
+
+while [[ $# -gt 0 ]]; do
+  case ""$1"" in
+    --taskid=*)
+      task_id=${1#*=}
+      ;;
+    --traceid=*)
+      trace_id=${1#*=}
+      ;;
+    *)
+      export_path=$1
+  esac
+  shift
+done
+
+[[ ! ${task_id} || ! ${trace_id} || ! ${export_path} ]] \
+  && echo 'Usage: sh tools/profile-exporter/profile_exporter.sh [--taskid] [--traceid] export_path' \
+  && exit 1
+
+[[ ! -d ${export_path} ]] \
+  && echo ""Cannot find export export_path path: ${export_path}"" \
+  && exit 1
+
+# prepare paths
+config_file=""${exporter_dir}/../../config/application.yml""
+oap_libs_dir=""${exporter_dir}/../../oap-libs""
+exporter_log_file=""${exporter_dir}/profile_exporter_log4j2.xml""
+awk_change_file=""${exporter_dir}/persist_core_and_storage.awk""","[{'comment': 'Why use `awk`? Using the user changed `application.yml` is very dangerous. We should not count on that. \r\nPlease use the separated YAML file including the minimal content, only necessary modules and providers. Then, document should be updated by following this change request.', 'commenter': 'wu-sheng'}]"
4416,docs/en/guides/backend-profile-export.md,"@@ -2,22 +2,23 @@
 When the visualization doesn't work well through the official UI, users could submit the issue to report. This tool helps the users to package the original profile data for helping the community to locate the issue in the user case. NOTICE, this report includes the class name, method name, line number, etc. Before submit this, please make sure this wouldn't become your system vulnerability.
 
 ## Export command line Usage
+1. Copy `storage` config from `config/application.yml` into `tools/profile-exporter/application.yml`, make sure they are using the same storage config.","[{'comment': '```suggestion\r\n1. Set the storage in `tools/profile-exporter/application.yml` file by following your use case.\r\n```', 'commenter': 'wu-sheng'}]"
4419,.github/workflows/ci-it.yaml,"@@ -32,9 +32,15 @@ jobs:
     strategy:
       fail-fast: true
     steps:
-      - uses: actions/checkout@v1
-        with:
-          submodules: true
+      - uses: actions/checkout@v2
+      - name: Checkout submodules
+        shell: bash
+        run: |
+          # If your submodules are configured to use SSH instead of HTTPS please uncomment the following line
+          # git config --global url.""https://github.com/"".insteadOf ""git@github.com:""","[{'comment': 'What these line for? It is confusing me, as we are using https://github.com', 'commenter': 'wu-sheng'}, {'comment': 'I think we only need `git submodule sync --recursive`', 'commenter': 'kezhenxu94'}, {'comment': '> `v2` is not compatible with `v1`, at least the parameters are not compatible, and I suggest you fix this in the pull request where you encounter the issue, which can verify the fix works\r\n\r\nSorry for not being clearly marked. It is true that the current V2 does not support the submodule function. Later, try to complete the verification in the local environment before submitting the PR.', 'commenter': 'Unknown'}, {'comment': '> What these line for? It is confusing me, as we are using https://github.com\r\n\r\nIMO, current is use https, use ssh mean agent by ssh command, such as ssh-agent.\r\nMaybe my understanding is wrong, I did n’t study this deeply.', 'commenter': 'Unknown'}, {'comment': '> I think we only need `git submodule sync --recursive`\r\n\r\n`git submodule update` updates the contents of the submodules, `git submodule sync` only update metainfo.  FYI  [https://stackoverflow.com/questions/45678862/git-submodule-update-vs-git-submodule-sync/45679230](url)', 'commenter': 'Unknown'}, {'comment': 'You misunderstand my point. These are comments, what are you trying to say? Is this IF making any sense to anyone? Why We keep this?', 'commenter': 'wu-sheng'}, {'comment': 'get it, There is indeed a problem with the comment', 'commenter': 'Unknown'}]"
4419,.github/workflows/ci-it.yaml,"@@ -32,9 +32,15 @@ jobs:
     strategy:
       fail-fast: true
     steps:
-      - uses: actions/checkout@v1
-        with:
-          submodules: true
+      - uses: actions/checkout@v2
+      - name: Checkout submodules
+        shell: bash
+        run: |
+          # If your submodules are configured to use SSH instead of HTTPS please uncomment the following line
+          # git config --global url.""https://github.com/"".insteadOf ""git@github.com:""
+          auth_header=""$(git config --local --get http.https://github.com/.extraheader)""","[{'comment': 'Why we need auth_header? As we are linking to open source only.', 'commenter': 'wu-sheng'}, {'comment': 'This is a screenshot image when the previous run failed. \r\n<img width=""1394"" alt=""WX20200227-074637@2x"" src=""https://user-images.githubusercontent.com/2892433/75398715-6b815c00-5935-11ea-9daf-58f91177367a.png"">\r\nThis should be set before. This parameter will be taken after running the command. There is no in-depth study. This is the way to refer to the official action documentation.[https://github.com/actions/checkout#Checkout-submodules](url)', 'commenter': 'Unknown'}, {'comment': ""My point is, you should be safe to run `git submodule update --init --force --recursive --depth=1` directly. I have run this command at local, we don't need that `auth_header`."", 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng  Actions execute should be a bit different from local. For this successful example , the `auth_header` parameter be set in the before checkout step `actions/checkout@v2`, So all of the following need to take this parameter.\r\n\r\n<img width=""1072"" alt=""WX20200227-115704@2x"" src=""https://user-images.githubusercontent.com/2892433/75411012-c37d8a00-5958-11ea-8193-6cb33d654b02.png"">\r\n', 'commenter': 'Unknown'}, {'comment': 'Why should be different? I am not following. We are using the same parameter to download from GitHub too.\r\n\r\nCould you explain your meaning of SHOULD?', 'commenter': 'wu-sheng'}, {'comment': ""Don't copy the thing if that is not necessary."", 'commenter': 'wu-sheng'}, {'comment': ""\r\n\r\n\r\n> Don't copy the thing if that is not necessary.\r\n\r\nget it. \r\n\r\n\r\n> Why should be different? I am not following. We are using the same parameter to download from GitHub too.\r\n> \r\n> Could you explain your meaning of SHOULD?\r\n\r\nIt is indeed that I understand it wrong, `auth_header` can be deleted for sw project, because english is not good, the description is not accurate, it is possible."", 'commenter': 'Unknown'}]"
4419,.github/workflows/ci-it.yaml,"@@ -32,9 +32,13 @@ jobs:
     strategy:
       fail-fast: true
     steps:
-      - uses: actions/checkout@v1
-        with:
-          submodules: true
+      - uses: actions/checkout@v2
+      # for checkout@v2 is not compatible with submodule","[{'comment': ""```suggestion\r\n      # In the checkout@v2, it doesn't support git submodule. Execute the commands manually.\r\n```"", 'commenter': 'wu-sheng'}, {'comment': 'Including all other comments.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'Unknown'}]"
4443,test/plugin/scenarios/resttemplate-4.x-scenario/support-version.list,"@@ -0,0 +1,16 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+1.5.9.RELEASE","[{'comment': 'Should be multiple versions, included all supported ones. How many versions are there?', 'commenter': 'wu-sheng'}]"
4443,.github/workflows/plugins-test.yaml,"@@ -300,6 +300,8 @@ jobs:
         run: ./mvnw --batch-mode -f test/plugin/pom.xml clean package -DskipTests docker:build -DBUILD_NO=local >/dev/null
       - name: Run spring 4.1.x-4.2.x (20)
         run: bash test/plugin/run.sh spring-4.1.x-scenario
+      - name: Run resttemplate 1.5.0.RELEASE-1.5.22.RELEASE (23)","[{'comment': 'Name is not right. Notice, There is another group name. You should change that too.', 'commenter': 'wu-sheng'}, {'comment': 'https://github.com/apache/skywalking/blob/47c84deea7f534f4cbb37d3b089b4b2d0ca4a4c7/.github/workflows/plugins-test.yaml#L275', 'commenter': 'wu-sheng'}]"
4443,test/plugin/scenarios/resttemplate-4.x-scenario/support-version.list,"@@ -0,0 +1,38 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+1.5.0.RELEASE","[{'comment': 'I am confused, the plugin called restteamplate 4.x, why all these versions are `1.5.x`? From test/plugin/scenarios/resttemplate-4.x-scenario/pom.xml, you are switching the spring boot version.\r\n\r\nCould you explain why?', 'commenter': 'wu-sheng'}, {'comment': 'From the plugin pom codes, clearly, it is spring version of 4.x\r\n\r\n![image](https://user-images.githubusercontent.com/5441976/76164941-e9433400-618d-11ea-8749-239dae87a195.png)\r\n', 'commenter': 'wu-sheng'}, {'comment': '`<dependency>\r\n            <groupId>org.springframework.boot</groupId>\r\n            <artifactId>spring-boot-starter-web</artifactId>\r\n            <version>${test.framework.version}</version>\r\n        </dependency>`\r\nIn resttemplate scenario, use this denpendency.', 'commenter': 'cngdkxw'}, {'comment': 'Yes, I read that, and that is my question. Why we set these versions? We are testing different rest template versions, not spring versions. We should be able to use maven to set explicit rest template versions and use the same spring version at the same time.', 'commenter': 'wu-sheng'}, {'comment': 'Please correct me if I am wrong.', 'commenter': 'wu-sheng'}]"
4443,test/plugin/scenarios/resttemplate-4.x-scenario/config/expectedData.yaml,"@@ -0,0 +1,125 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+registryItems:
+  services:
+  - {resttemplate-4.x-scenario: nq 0}
+  instances:
+  - {resttemplate-4.x-scenario: 1}
+  operationNames:
+  - resttemplate-4.x-scenario: [/resttemplate/case/resttemplate, /resttemplate/back]
+segmentItems:
+- serviceName: resttemplate-4.x-scenario
+  segmentSize: ge 3
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: /resttemplate/back
+      operationId: 0
+      parentSpanId: -1
+      spanId: 0
+      spanLayer: Http
+      startTime: nq 0
+      endTime: nq 0
+      componentId: not null
+      componentName: ''
+      isError: false
+      spanType: Entry
+      peer: ''
+      peerId: 0
+      tags:
+      - {key: url, value: 'http://127.0.0.1:8080/resttemplate/back' }
+      - {key: http.method, value: GET }
+  - segmentId: not null","[{'comment': 'You miss the reference check for these two entry spans.', 'commenter': 'wu-sheng'}]"
4443,test/plugin/scenarios/resttemplate-4.x-scenario/support-version.list,"@@ -0,0 +1,34 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+4.3.8.RELEASE","[{'comment': 'Does this plugin support 4.0, 4.1, 4.2? If so, please add some(not need to add all) to the tests.', 'commenter': 'wu-sheng'}, {'comment': 'no support', 'commenter': 'cngdkxw'}, {'comment': 'The Supported-list.md in the doc says otherwise. Is there an incompatible change? Could you explain a little about this? Is the old implementation for old versions?', 'commenter': 'wu-sheng'}, {'comment': 'Later, I will take the time to write a non-springboot project and test it', 'commenter': 'cngdkxw'}, {'comment': 'OK. Work for me.', 'commenter': 'wu-sheng'}]"
4443,test/plugin/scenarios/resttemplate-4.x-scenario/src/main/java/org/apache/skywalking/testcase/resttemplate/FrontController.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.testcase.resttemplate;
+
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.ResponseEntity;
+import org.springframework.util.concurrent.ListenableFuture;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RestController;
+import org.springframework.web.client.AsyncRestTemplate;
+import org.springframework.web.client.RestTemplate;
+
+@RestController
+@RequestMapping(""/resttemplate/case"")
+public class FrontController {
+
+    private static Logger logger = LogManager.getLogger(FrontController.class);
+
+    @Autowired
+    private AsyncRestTemplate asyncRestTemplate;
+
+    @Autowired
+    private RestTemplate restTemplate;
+
+    @GetMapping(""/healthcheck"")
+    public String healthcheck() {
+        return ""Success"";
+    }
+
+    @GetMapping(""/resttemplate"")
+    public String front() {
+        asyncRequest(""http://127.0.0.1:8080/resttemplate/back"");
+        syncRequest(""http://127.0.0.1:8080/resttemplate/back"");","[{'comment': 'As your tests called `Resttemplate`, could do add a sync request here and in the expected data file too?', 'commenter': 'wu-sheng'}, {'comment': 'One call contains both sync and async requests, the expecedData.yaml file contains also sync request result.', 'commenter': 'cngdkxw'}, {'comment': 'Yes, that is point, the sync request should be tested too, right?', 'commenter': 'wu-sheng'}]"
4443,test/plugin/scenarios/resttemplate-4.x-scenario/config/expectedData.yaml,"@@ -19,11 +19,29 @@ registryItems:
   instances:
   - {resttemplate-4.x-scenario: 1}
   operationNames:
-  - resttemplate-4.x-scenario: [/resttemplate/case/resttemplate, /resttemplate/back]
+  - resttemplate-4.x-scenario: [/resttemplate/case/healthcheck, /resttemplate/case/resttemplate, /resttemplate/back]","[{'comment': '`/resttemplate/case/healthcheck` should not be added into here.', 'commenter': 'wu-sheng'}, {'comment': 'okay', 'commenter': 'cngdkxw'}]"
4443,.github/workflows/plugins-test.yaml,"@@ -306,6 +306,8 @@ jobs:
         run: ./mvnw --batch-mode -f test/plugin/pom.xml clean package -DskipTests docker:build -DBUILD_NO=local >/dev/null
       - name: Run spring 4.1.x-4.2.x (20)
         run: bash test/plugin/run.sh spring-4.1.x-scenario
+      - name: Run resttemplate 4.0.0.RELEASE-4.3.26.RELEASE (57)
+        run: bash test/plugin/run.sh resttemplate-4.x-scenario","[{'comment': 'This line triggers all things including image build.', 'commenter': 'wu-sheng'}]"
4470,docs/en/setup/backend/grpc-ssl.md,"@@ -0,0 +1,33 @@
+#Support gRPC SSL transportation for OAP server","[{'comment': '```suggestion\r\n# Support gRPC SSL transportation for OAP server\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'without a space, the header style is not correctly rendered', 'commenter': 'kezhenxu94'}]"
4470,docs/en/setup/backend/grpc-ssl.md,"@@ -0,0 +1,33 @@
+#Support gRPC SSL transportation for OAP server
+
+For OAP communication we are currently using gRPC, a multi-platform RPC framework that uses protocol buffers for
+message serialization. The nice part about gRPC is that it promotes the use of SSL/TLS to authenticate and encrypt
+exchanges. Now OAP support to enable SSL transportation for gRPC receivers.","[{'comment': '```suggestion\r\nexchanges. Now OAP supports to enable SSL transportation for gRPC receivers.\r\n```', 'commenter': 'kezhenxu94'}]"
4470,docs/en/setup/backend/grpc-ssl.md,"@@ -0,0 +1,32 @@
+# Support gRPC SSL transportation for OAP server
+
+For OAP communication we are currently using gRPC, a multi-platform RPC framework that uses protocol buffers for
+message serialization. The nice part about gRPC is that it promotes the use of SSL/TLS to authenticate and encrypt
+exchanges. Now OAP supports to enable SSL transportation for gRPC receivers.
+
+You can follow below steps to enable this feature
+
+## Creating SSL/TLS Certificates
+
+It seems like step one is to generate certificates and key files for encrypting communication. I thought this would be
+fairly straightforward using `openssl` from the command line, However, it may be simpler to use
+[certstrap](https://github.com/square/certstrap), a simple certificate manager written in Go by the folks at Square.
+The app avoids dealing with `openssl`, but has a very simple workflow: create a certificate authority, sign certificates
+with it.
+
+After signing the certificates of OAP server, we should convert private key to a PKCS8 format before placing it into the host.
+
+```
+$ openssl pkcs8 -topk8 -inform PEM -outform PEM -nocrypt -in server.key -out server-key.pem
+```
+
+## Config OAP server 
+
+You can enable gRPC SSL by add following lines to `application.yml/core/default`.
+```json
+gRPCSslEnabled: true
+gRPCSslKeyPath: /path/to/server-key.pem
+gRPCSslCertChainPath: /path/to/server.crt
+```
+
+If you port to java agent, refer to [TLS.md](../service-agent/java-agent/TLS.md) to config java agent to enable TLS.","[{'comment': 'This linked file should be updated too, to keep consistently', 'commenter': 'wu-sheng'}]"
4470,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/RemoteClientManager.java,"@@ -55,21 +59,29 @@
     private static final Logger logger = LoggerFactory.getLogger(RemoteClientManager.class);
 
     private final ModuleDefineHolder moduleDefineHolder;
+    private final boolean grpcSslEnabled;
+    private final String grpcSslTrustCAPath;
     private ClusterNodesQuery clusterNodesQuery;
     private volatile List<RemoteClient> usingClients;
     private GaugeMetrics gauge;
     private int remoteTimeout;
 
     /**
      * Initial the manager for all remote communication clients.
-     *
-     * @param moduleDefineHolder for looking up other modules
+     *  @param moduleDefineHolder for looking up other modules
      * @param remoteTimeout      for cluster internal communication, in second unit.
+     * @param grpcSslEnabled true: enable SSL between clusters, false: plain gRPC between the cluster.
+     * @param grpcSslTrustCAPath trust certificate authorities file path.
      */
-    public RemoteClientManager(ModuleDefineHolder moduleDefineHolder, int remoteTimeout) {
+    public RemoteClientManager(ModuleDefineHolder moduleDefineHolder,","[{'comment': 'Could you make the core style consistently. `GRPCRemoteClient` client use two constructors for ssl ON/OFF, here using a boolean and empty/null string.', 'commenter': 'wu-sheng'}, {'comment': 'done. keep all parameter list the same way.', 'commenter': 'hanahmily'}]"
4470,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/remote/client/GRPCRemoteClient.java,"@@ -99,7 +110,7 @@ GRPCClient getClient() {
         if (Objects.isNull(client)) {
             synchronized (GRPCRemoteClient.class) {
                 if (Objects.isNull(client)) {
-                    this.client = new GRPCClient(address.getHost(), address.getPort());
+                    this.client = new GRPCClient(address.getHost(), address.getPort(), sslContext);","[{'comment': 'A similar code style inconsistent here, using `sslContext==null` represents no SSL.', 'commenter': 'wu-sheng'}]"
4470,oap-server/server-receiver-plugin/skywalking-sharing-server-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/sharing/server/SharingServerModuleProvider.java,"@@ -80,6 +81,15 @@ public void prepare() {
         if (config.getGRPCPort() != 0) {
             grpcServer = new GRPCServer(Strings.isBlank(config.getGRPCHost()) ? ""0.0.0.0"" : config.getGRPCHost(), config","[{'comment': 'I think you miss the deletion of this?', 'commenter': 'wu-sheng'}, {'comment': 'removed it.', 'commenter': 'hanahmily'}]"
4470,test/e2e/e2e-ssl/e2e-ssl.iml,"@@ -0,0 +1,120 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>","[{'comment': 'I think this should not be uploaded? Why git ignore is not working for this?', 'commenter': 'wu-sheng'}, {'comment': 'deleted it.', 'commenter': 'hanahmily'}]"
4470,test/e2e/e2e-ssl/src/docker/certs/server-key.pem,"@@ -0,0 +1,28 @@
+-----BEGIN PRIVATE KEY-----","[{'comment': 'Are these cert files alway valid? No expired time?', 'commenter': 'wu-sheng'}, {'comment': '2 years. Is it enough?', 'commenter': 'hanahmily'}, {'comment': ""My point is, this is for test. Could we set it forever? Or let's say 100 years?"", 'commenter': 'wu-sheng'}, {'comment': 'Now we get the  100 years/ century certificates.', 'commenter': 'hanahmily'}]"
4471,docker/oap-es7/docker-entrypoint.sh,"@@ -384,8 +384,6 @@ receiver-jvm:
   default:
 receiver-clr:
   default:
-receiver-so11y:","[{'comment': 'should move it to func `generateTelemetrySo11y `', 'commenter': 'hanahmily'}, {'comment': ""It's already there, isn't it?\r\n\r\nhttps://github.com/apache/skywalking/blob/5eba81e1409ca11204812bd456d4f4af206b76d2/docker/oap/docker-entrypoint.sh#L450-L454"", 'commenter': 'kezhenxu94'}, {'comment': ""sorry, didn't notice it"", 'commenter': 'hanahmily'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-5.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticsearch/v5/define/GenericActionInstrumentation.java,"@@ -60,4 +60,10 @@ public String getConstructorInterceptor() {
     protected ClassMatch enhanceClass() {
         return byHierarchyMatch(new String[] {""org.elasticsearch.action.GenericAction""});
     }
+
+    @Override
+    protected String[] witnessClasses() {
+        return new String[]{""org.elasticsearch.common.transport.InetSocketTransportAddress""};","[{'comment': 'recommended to put these and below const string witnesses in one place better.', 'commenter': 'Unknown'}, {'comment': 'ok', 'commenter': 'Indifer'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/TransportAddressCache.java,"@@ -0,0 +1,64 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6;
+
+import org.elasticsearch.common.transport.TransportAddress;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * date 2020.02.13 20:50","[{'comment': 'This comment be modified to describe the function of the class, same as follows.', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/TransportAddressCache.java,"@@ -0,0 +1,64 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6;
+
+import org.elasticsearch.common.transport.TransportAddress;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * date 2020.02.13 20:50
+ */
+public class TransportAddressCache {
+
+    private List<TransportAddress> transportAddresses = new ArrayList<TransportAddress>();
+    private String transportAddressesStr = """";
+
+    public synchronized void addDiscoveryNode(TransportAddress... transportAddress) {
+        transportAddresses.addAll(Arrays.asList(transportAddress));
+        transportAddressesStr = format();
+    }
+
+    public synchronized void removeDiscoveryNode(TransportAddress transportAddress) {
+        List<TransportAddress> nodesBuilder = new ArrayList<TransportAddress>();
+
+        for (TransportAddress otherNode : transportAddresses) {
+            if (!otherNode.getAddress().equals(transportAddress.getAddress())) {
+                nodesBuilder.add(otherNode);
+            }
+        }
+
+        transportAddresses = nodesBuilder;
+        transportAddressesStr = format();
+    }
+
+    private String format() {
+        StringBuilder stringBuilder = new StringBuilder();
+        for (TransportAddress node : transportAddresses) {
+            stringBuilder.append(node.getAddress()).append("":"").append(node.getPort()).append("";"");","[{'comment': 'recommended to change `;` to  `,` here, which is also consistent with the ES multi-hosts configuration method.', 'commenter': 'Unknown'}, {'comment': 'ok', 'commenter': 'Indifer'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/interceptor/TransportActionNodeProxyExecuteMethodsInterceptorTest.java,"@@ -0,0 +1,160 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.ExitSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.TransportClientEnhanceInfo;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.Elasticsearch.TRACE_DSL;
+import static org.apache.skywalking.apm.network.trace.component.ComponentsDefine.TRANSPORT_CLIENT;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+/**
+ * date 2020.03.15 21:02
+ */
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class TransportActionNodeProxyExecuteMethodsInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    @Mock
+    private DiscoveryNode discoveryNode;
+
+    @Mock
+    private GetRequest getRequest;
+
+    @Mock
+    private TransportClientEnhanceInfo enhanceInfo;
+
+    private TransportActionNodeProxyExecuteMethodsInterceptor interceptor;
+
+    @Before
+    public void setUp() {
+
+        InetSocketAddress inetSocketAddress = new InetSocketAddress(""122.122.122.122"", 9300);
+        TransportAddress transportAddress = new TransportAddress(inetSocketAddress);
+        when(discoveryNode.getAddress()).thenReturn(transportAddress);
+
+        when(enhanceInfo.transportAddresses()).thenReturn(""122.122.122.122:9300;"");
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(enhanceInfo);
+
+        interceptor = new TransportActionNodeProxyExecuteMethodsInterceptor();
+    }
+
+    @Test
+    public void testConstruct() {
+
+        final EnhancedInstance objInst1 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        final EnhancedInstance objInst2 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        objInst1.setSkyWalkingDynamicField(123);
+        Object[] allArguments = new Object[]{null, null, objInst1};
+
+        interceptor.onConstruct(objInst2, allArguments);
+        assertThat(objInst1.getSkyWalkingDynamicField(), is(objInst2.getSkyWalkingDynamicField()));
+    }
+
+    @Test
+    public void testMethodsAround() throws Throwable {
+        TRACE_DSL = true;
+        Object[] allArguments = new Object[]{discoveryNode, getRequest};
+
+        interceptor.beforeMethod(enhancedInstance, null, allArguments, null, null);
+        interceptor.afterMethod(enhancedInstance, null, allArguments, null, null);
+
+        List<TraceSegment> traceSegmentList = segmentStorage.getTraceSegments();
+        Assert.assertThat(traceSegmentList.size(), is(1));
+        TraceSegment traceSegment = traceSegmentList.get(0);
+
+        AbstractTracingSpan getSpan = SegmentHelper.getSpans(traceSegment).get(0);
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    private void assertGetSpan(AbstractTracingSpan getSpan, Object ret) {
+        assertThat(getSpan instanceof ExitSpan, is(true));
+
+        ExitSpan span = (ExitSpan) getSpan;
+        assertThat(span.getOperationName().split(""[$$]"")[0], is(""Elasticsearch/GetRequest""));
+        assertThat(SpanHelper.getComponentId(span), is(TRANSPORT_CLIENT.getId()));
+
+        List<TagValuePair> tags = SpanHelper.getTags(span);
+        Assert.assertTrue(tags.size() > 4);
+","[{'comment': 'It is recommended that the content of tags here be tested and verified.', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/define/TransportActionNodeProxyInstrumentation.java,"@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.StaticMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor.Constants;
+
+import static net.bytebuddy.matcher.ElementMatchers.any;
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * date 2020.02.13 20:32
+ */","[{'comment': 'this comment is meaningless, it is recommended to add class comment, as are other important classes.', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/define/TransportClientNodesServiceInstrumentation.java,"@@ -0,0 +1,112 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor.Constants;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.bytebuddy.ArgumentTypeNameMatch.takesArgumentWithType;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * date 2020.02.13 22:29
+ */","[{'comment': 'this is same as above.', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/define/TransportServiceInstrumentation.java,"@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.StaticMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor.Constants;
+
+import static net.bytebuddy.matcher.ElementMatchers.any;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * date 2020.02.13 20:49
+ */","[{'comment': 'same as above', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/interceptor/TransportActionNodeProxyExecuteMethodsInterceptorTest.java,"@@ -0,0 +1,241 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.ExitSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.TransportClientEnhanceInfo;
+import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
+import org.elasticsearch.action.delete.DeleteRequest;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.index.IndexRequest;
+import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.update.UpdateRequest;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.Elasticsearch.TRACE_DSL;
+import static org.apache.skywalking.apm.network.trace.component.ComponentsDefine.TRANSPORT_CLIENT;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class TransportActionNodeProxyExecuteMethodsInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    @Mock
+    private DiscoveryNode discoveryNode;
+
+//    @Mock
+//    private SearchRequest searchRequest;
+","[{'comment': 'comment should delete', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/interceptor/TransportActionNodeProxyExecuteMethodsInterceptorTest.java,"@@ -0,0 +1,241 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.ExitSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.TransportClientEnhanceInfo;
+import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
+import org.elasticsearch.action.delete.DeleteRequest;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.index.IndexRequest;
+import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.update.UpdateRequest;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.Elasticsearch.TRACE_DSL;
+import static org.apache.skywalking.apm.network.trace.component.ComponentsDefine.TRANSPORT_CLIENT;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class TransportActionNodeProxyExecuteMethodsInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    @Mock
+    private DiscoveryNode discoveryNode;
+
+//    @Mock
+//    private SearchRequest searchRequest;
+
+    @Mock
+    private GetRequest getRequest;
+
+    @Mock
+    private IndexRequest indexRequest;
+
+    @Mock
+    private UpdateRequest updateRequest;
+
+    @Mock
+    private DeleteRequest deleteRequest;
+
+    @Mock
+    private DeleteIndexRequest deleteIndexRequest;
+
+    @Mock
+    private TransportClientEnhanceInfo enhanceInfo;
+
+    private TransportActionNodeProxyExecuteMethodsInterceptor interceptor;
+
+    @Before
+    public void setUp() {
+
+        InetSocketAddress inetSocketAddress = new InetSocketAddress(""122.122.122.122"", 9300);
+        TransportAddress transportAddress = new TransportAddress(inetSocketAddress);
+        when(discoveryNode.getAddress()).thenReturn(transportAddress);
+
+        when(enhanceInfo.transportAddresses()).thenReturn(""122.122.122.122:9300"");
+        when(enhanceInfo.getClusterName()).thenReturn(""skywalking-es"");
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(enhanceInfo);
+
+//        when(searchRequest.indices()).thenReturn(new String[]{""endpoint""});
+//        when(searchRequest.types()).thenReturn(new String[]{""searchType""});","[{'comment': 'also this', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/interceptor/TransportActionNodeProxyExecuteMethodsInterceptorTest.java,"@@ -0,0 +1,241 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.ExitSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.TransportClientEnhanceInfo;
+import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
+import org.elasticsearch.action.delete.DeleteRequest;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.index.IndexRequest;
+import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.update.UpdateRequest;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.Elasticsearch.TRACE_DSL;
+import static org.apache.skywalking.apm.network.trace.component.ComponentsDefine.TRANSPORT_CLIENT;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class TransportActionNodeProxyExecuteMethodsInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    @Mock
+    private DiscoveryNode discoveryNode;
+
+//    @Mock
+//    private SearchRequest searchRequest;
+
+    @Mock
+    private GetRequest getRequest;
+
+    @Mock
+    private IndexRequest indexRequest;
+
+    @Mock
+    private UpdateRequest updateRequest;
+
+    @Mock
+    private DeleteRequest deleteRequest;
+
+    @Mock
+    private DeleteIndexRequest deleteIndexRequest;
+
+    @Mock
+    private TransportClientEnhanceInfo enhanceInfo;
+
+    private TransportActionNodeProxyExecuteMethodsInterceptor interceptor;
+
+    @Before
+    public void setUp() {
+
+        InetSocketAddress inetSocketAddress = new InetSocketAddress(""122.122.122.122"", 9300);
+        TransportAddress transportAddress = new TransportAddress(inetSocketAddress);
+        when(discoveryNode.getAddress()).thenReturn(transportAddress);
+
+        when(enhanceInfo.transportAddresses()).thenReturn(""122.122.122.122:9300"");
+        when(enhanceInfo.getClusterName()).thenReturn(""skywalking-es"");
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(enhanceInfo);
+
+//        when(searchRequest.indices()).thenReturn(new String[]{""endpoint""});
+//        when(searchRequest.types()).thenReturn(new String[]{""searchType""});
+
+        when(getRequest.index()).thenReturn(""endpoint"");
+        when(getRequest.type()).thenReturn(""getType"");
+
+        when(indexRequest.index()).thenReturn(""endpoint"");
+        when(indexRequest.type()).thenReturn(""indexType"");
+
+        when(updateRequest.index()).thenReturn(""endpoint"");
+        when(updateRequest.type()).thenReturn(""updateType"");
+
+        when(deleteRequest.index()).thenReturn(""endpoint"");
+        when(deleteRequest.type()).thenReturn(""deleteType"");
+
+        when(deleteIndexRequest.indices()).thenReturn(new String[]{""endpoint""});
+
+        interceptor = new TransportActionNodeProxyExecuteMethodsInterceptor();
+    }
+
+    @Test
+    public void testConstruct() {
+
+        final EnhancedInstance objInst1 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        final EnhancedInstance objInst2 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        objInst1.setSkyWalkingDynamicField(123);
+        Object[] allArguments = new Object[]{null, null, objInst1};
+
+        interceptor.onConstruct(objInst2, allArguments);
+        assertThat(objInst1.getSkyWalkingDynamicField(), is(objInst2.getSkyWalkingDynamicField()));
+    }
+
+    @Test
+    public void testGetRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    @Test
+    public void testIndexRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);","[{'comment': '`getRequest ` maybe `indexRequest`?', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/interceptor/TransportActionNodeProxyExecuteMethodsInterceptorTest.java,"@@ -0,0 +1,241 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.ExitSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.TransportClientEnhanceInfo;
+import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
+import org.elasticsearch.action.delete.DeleteRequest;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.index.IndexRequest;
+import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.update.UpdateRequest;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.Elasticsearch.TRACE_DSL;
+import static org.apache.skywalking.apm.network.trace.component.ComponentsDefine.TRANSPORT_CLIENT;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class TransportActionNodeProxyExecuteMethodsInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    @Mock
+    private DiscoveryNode discoveryNode;
+
+//    @Mock
+//    private SearchRequest searchRequest;
+
+    @Mock
+    private GetRequest getRequest;
+
+    @Mock
+    private IndexRequest indexRequest;
+
+    @Mock
+    private UpdateRequest updateRequest;
+
+    @Mock
+    private DeleteRequest deleteRequest;
+
+    @Mock
+    private DeleteIndexRequest deleteIndexRequest;
+
+    @Mock
+    private TransportClientEnhanceInfo enhanceInfo;
+
+    private TransportActionNodeProxyExecuteMethodsInterceptor interceptor;
+
+    @Before
+    public void setUp() {
+
+        InetSocketAddress inetSocketAddress = new InetSocketAddress(""122.122.122.122"", 9300);
+        TransportAddress transportAddress = new TransportAddress(inetSocketAddress);
+        when(discoveryNode.getAddress()).thenReturn(transportAddress);
+
+        when(enhanceInfo.transportAddresses()).thenReturn(""122.122.122.122:9300"");
+        when(enhanceInfo.getClusterName()).thenReturn(""skywalking-es"");
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(enhanceInfo);
+
+//        when(searchRequest.indices()).thenReturn(new String[]{""endpoint""});
+//        when(searchRequest.types()).thenReturn(new String[]{""searchType""});
+
+        when(getRequest.index()).thenReturn(""endpoint"");
+        when(getRequest.type()).thenReturn(""getType"");
+
+        when(indexRequest.index()).thenReturn(""endpoint"");
+        when(indexRequest.type()).thenReturn(""indexType"");
+
+        when(updateRequest.index()).thenReturn(""endpoint"");
+        when(updateRequest.type()).thenReturn(""updateType"");
+
+        when(deleteRequest.index()).thenReturn(""endpoint"");
+        when(deleteRequest.type()).thenReturn(""deleteType"");
+
+        when(deleteIndexRequest.indices()).thenReturn(new String[]{""endpoint""});
+
+        interceptor = new TransportActionNodeProxyExecuteMethodsInterceptor();
+    }
+
+    @Test
+    public void testConstruct() {
+
+        final EnhancedInstance objInst1 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        final EnhancedInstance objInst2 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        objInst1.setSkyWalkingDynamicField(123);
+        Object[] allArguments = new Object[]{null, null, objInst1};
+
+        interceptor.onConstruct(objInst2, allArguments);
+        assertThat(objInst1.getSkyWalkingDynamicField(), is(objInst2.getSkyWalkingDynamicField()));
+    }
+
+    @Test
+    public void testGetRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    @Test
+    public void testIndexRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    @Test
+    public void testUpdateRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);","[{'comment': '`getRequest ` maybe `updateRequest`?', 'commenter': 'Unknown'}]"
4517,apm-sniffer/apm-sdk-plugin/elasticsearch-6.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/elasticsearch/v6/interceptor/TransportActionNodeProxyExecuteMethodsInterceptorTest.java,"@@ -0,0 +1,241 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.elasticsearch.v6.interceptor;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.ExitSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.plugin.elasticsearch.v6.TransportClientEnhanceInfo;
+import org.elasticsearch.action.admin.indices.delete.DeleteIndexRequest;
+import org.elasticsearch.action.delete.DeleteRequest;
+import org.elasticsearch.action.get.GetRequest;
+import org.elasticsearch.action.index.IndexRequest;
+import org.elasticsearch.action.search.SearchRequest;
+import org.elasticsearch.action.update.UpdateRequest;
+import org.elasticsearch.cluster.node.DiscoveryNode;
+import org.elasticsearch.common.transport.TransportAddress;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.net.InetSocketAddress;
+import java.util.List;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.Elasticsearch.TRACE_DSL;
+import static org.apache.skywalking.apm.network.trace.component.ComponentsDefine.TRANSPORT_CLIENT;
+import static org.junit.Assert.assertThat;
+import static org.hamcrest.CoreMatchers.is;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class TransportActionNodeProxyExecuteMethodsInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    @Mock
+    private DiscoveryNode discoveryNode;
+
+//    @Mock
+//    private SearchRequest searchRequest;
+
+    @Mock
+    private GetRequest getRequest;
+
+    @Mock
+    private IndexRequest indexRequest;
+
+    @Mock
+    private UpdateRequest updateRequest;
+
+    @Mock
+    private DeleteRequest deleteRequest;
+
+    @Mock
+    private DeleteIndexRequest deleteIndexRequest;
+
+    @Mock
+    private TransportClientEnhanceInfo enhanceInfo;
+
+    private TransportActionNodeProxyExecuteMethodsInterceptor interceptor;
+
+    @Before
+    public void setUp() {
+
+        InetSocketAddress inetSocketAddress = new InetSocketAddress(""122.122.122.122"", 9300);
+        TransportAddress transportAddress = new TransportAddress(inetSocketAddress);
+        when(discoveryNode.getAddress()).thenReturn(transportAddress);
+
+        when(enhanceInfo.transportAddresses()).thenReturn(""122.122.122.122:9300"");
+        when(enhanceInfo.getClusterName()).thenReturn(""skywalking-es"");
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(enhanceInfo);
+
+//        when(searchRequest.indices()).thenReturn(new String[]{""endpoint""});
+//        when(searchRequest.types()).thenReturn(new String[]{""searchType""});
+
+        when(getRequest.index()).thenReturn(""endpoint"");
+        when(getRequest.type()).thenReturn(""getType"");
+
+        when(indexRequest.index()).thenReturn(""endpoint"");
+        when(indexRequest.type()).thenReturn(""indexType"");
+
+        when(updateRequest.index()).thenReturn(""endpoint"");
+        when(updateRequest.type()).thenReturn(""updateType"");
+
+        when(deleteRequest.index()).thenReturn(""endpoint"");
+        when(deleteRequest.type()).thenReturn(""deleteType"");
+
+        when(deleteIndexRequest.indices()).thenReturn(new String[]{""endpoint""});
+
+        interceptor = new TransportActionNodeProxyExecuteMethodsInterceptor();
+    }
+
+    @Test
+    public void testConstruct() {
+
+        final EnhancedInstance objInst1 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        final EnhancedInstance objInst2 = new EnhancedInstance() {
+            private Object object = null;
+
+            @Override
+            public Object getSkyWalkingDynamicField() {
+                return object;
+            }
+
+            @Override
+            public void setSkyWalkingDynamicField(Object value) {
+                this.object = value;
+            }
+        };
+
+        objInst1.setSkyWalkingDynamicField(123);
+        Object[] allArguments = new Object[]{null, null, objInst1};
+
+        interceptor.onConstruct(objInst2, allArguments);
+        assertThat(objInst1.getSkyWalkingDynamicField(), is(objInst2.getSkyWalkingDynamicField()));
+    }
+
+    @Test
+    public void testGetRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    @Test
+    public void testIndexRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    @Test
+    public void testUpdateRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);
+    }
+
+    @Test
+    public void testDeleteRequest() throws Throwable {
+
+        AbstractTracingSpan getSpan = getSpan();
+        assertGetSpan(getSpan, getRequest);","[{'comment': '`getRequest ` maybe `deleteRequest`?', 'commenter': 'Unknown'}]"
4529,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/AlarmQuery.java,"@@ -64,7 +64,7 @@ public Alarms getAlarm(Integer scopeId, String keyword, int limit, int from, lon
                        .and(lte(InfluxClient.TIME, InfluxClient.timeInterval(endTB)));
         }
         if (!Strings.isNullOrEmpty(keyword)) {
-            recallQuery.and(regex(AlarmRecord.ALARM_MESSAGE, keyword));
+            recallQuery.and(contains(AlarmRecord.ALARM_MESSAGE, keyword.replaceAll(""/"", ""\\/"")));","[{'comment': '```suggestion\r\n            recallQuery.and(contains(AlarmRecord.ALARM_MESSAGE, keyword.replaceAll(""/"", ""\\\\\\\\/"")));\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'Why four \\? How many do we need?\r\n\r\n@kezhenxu94 we may need an e2e query for alarm in the future.', 'commenter': 'wu-sheng'}, {'comment': '> Why four ? How many do we need?\r\n> \r\n\r\n`""\\\\""` => `\\`, `\\` in regexp pattern is for escaping, so `\\\\\\\\` in string literal => `""\\\\(escape in string literal)\\\\(escape in string literal)""` => `\\\\` (escape `\\` in regexp)', 'commenter': 'kezhenxu94'}, {'comment': '> @kezhenxu94 we may need an e2e query for alarm in the future.\r\n\r\nplease create an issue to track in case we all forget', 'commenter': 'kezhenxu94'}, {'comment': '> > Why four ? How many do we need?\r\n> \r\n> `""\\\\""` => `\\`, `\\` in regexp pattern is for escaping, so `\\\\\\\\` in string literal => `""\\\\(escape in string literal)\\\\(escape in string literal)""` => `\\\\` (escape `\\` in regexp)\r\n\r\n@wu-sheng @dmsolr if you\'re not sure, please refer to the JavaDoc of `java.util.regex.Matcher#replaceAll` or simply run the following test:\r\n\r\n```java\r\n    public static void main(String[] args) {\r\n        System.out.println(""/abc/"".replaceAll(""/"", ""\\\\/""));\r\n        // still produce /abc/ , not \\/abc\\/\r\n        System.out.println(""/abc/"".replaceAll(""/"", ""\\\\\\\\/""));\r\n        // produce \\/abc\\/ , which is what we want,\r\n    }\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'Got it', 'commenter': 'wu-sheng'}]"
4547,test/e2e/e2e-test/docker/php/docker-compose.yml,"@@ -0,0 +1,86 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    image: skywalking/oap:latest
+    expose:
+      - 11800
+      - 12800
+    networks:
+      - e2e
+    restart: on-failure
+    healthcheck:
+      test: [""CMD"", ""bash"", ""-c"", ""cat < /dev/null > /dev/tcp/127.0.0.1/11800""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  php:
+    image: skyapm/skywalking-php:latest
+    networks:
+      e2e:
+        aliases:
+          - php
+    expose:
+      - 8080
+    environment:
+      - SW_AGENT_COLLECTOR_BACKEND_SERVICES=oap:11800
+    depends_on:
+      oap:
+        condition: service_healthy
+    volumes:
+      - ../php/index.php:/opt/www/index.php
+      - ../php/php.ini:/usr/local/etc/php/conf.d/ext-skywalking.ini
+
+  php-shadow:
+    image: skyapm/skywalking-php:latest
+    networks:
+      e2e:
+        aliases:
+          - php-shadow
+    expose:
+      - 8080
+    environment:
+      - SW_AGENT_COLLECTOR_BACKEND_SERVICES=oap:11800
+    depends_on:
+      php:
+        condition: service_started
+      oap:
+        condition: service_healthy
+    volumes:
+      - ../php/index.php:/opt/www/index.php
+      - ../php/php-shadow.ini:/usr/local/etc/php/conf.d/ext-skywalking.ini","[{'comment': '```suggestion\r\n      - ./index.php:/opt/www/index.php\r\n      - ./php-shadow.ini:/usr/local/etc/php/conf.d/ext-skywalking.ini\r\n```', 'commenter': 'kezhenxu94'}]"
4547,test/e2e/e2e-test/docker/php/docker-compose.yml,"@@ -0,0 +1,86 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    image: skywalking/oap:latest
+    expose:
+      - 11800
+      - 12800
+    networks:
+      - e2e
+    restart: on-failure
+    healthcheck:
+      test: [""CMD"", ""bash"", ""-c"", ""cat < /dev/null > /dev/tcp/127.0.0.1/11800""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  php:
+    image: skyapm/skywalking-php:latest
+    networks:
+      e2e:
+        aliases:
+          - php
+    expose:
+      - 8080
+    environment:
+      - SW_AGENT_COLLECTOR_BACKEND_SERVICES=oap:11800
+    depends_on:
+      oap:
+        condition: service_healthy
+    volumes:
+      - ../php/index.php:/opt/www/index.php
+      - ../php/php.ini:/usr/local/etc/php/conf.d/ext-skywalking.ini
+
+  php-shadow:
+    image: skyapm/skywalking-php:latest
+    networks:
+      e2e:
+        aliases:
+          - php-shadow","[{'comment': ""do we need an alias? if not, let's make it minimal simple"", 'commenter': 'kezhenxu94'}]"
4547,test/e2e/e2e-test/docker/php/docker-compose.yml,"@@ -0,0 +1,86 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    image: skywalking/oap:latest
+    expose:
+      - 11800
+      - 12800
+    networks:
+      - e2e
+    restart: on-failure
+    healthcheck:
+      test: [""CMD"", ""bash"", ""-c"", ""cat < /dev/null > /dev/tcp/127.0.0.1/11800""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  php:
+    image: skyapm/skywalking-php:latest
+    networks:
+      e2e:
+        aliases:
+          - php
+    expose:
+      - 8080
+    environment:
+      - SW_AGENT_COLLECTOR_BACKEND_SERVICES=oap:11800
+    depends_on:
+      oap:
+        condition: service_healthy
+    volumes:
+      - ../php/index.php:/opt/www/index.php
+      - ../php/php.ini:/usr/local/etc/php/conf.d/ext-skywalking.ini","[{'comment': '```suggestion\r\n      - ./index.php:/opt/www/index.php\r\n      - ./php.ini:/usr/local/etc/php/conf.d/ext-skywalking.ini\r\n```', 'commenter': 'kezhenxu94'}]"
4547,test/e2e/e2e-test/docker/php/docker-compose.yml,"@@ -0,0 +1,86 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    image: skywalking/oap:latest
+    expose:
+      - 11800
+      - 12800
+    networks:
+      - e2e
+    restart: on-failure
+    healthcheck:
+      test: [""CMD"", ""bash"", ""-c"", ""cat < /dev/null > /dev/tcp/127.0.0.1/11800""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  php:
+    image: skyapm/skywalking-php:latest
+    networks:
+      e2e:
+        aliases:
+          - php","[{'comment': ""remove if we don't need it\r\n"", 'commenter': 'kezhenxu94'}]"
4547,.github/workflows/e2e.yaml,"@@ -80,6 +80,28 @@ jobs:
           name: logs
           path: logs
 
+  FeatureGroup03:","[{'comment': '@kezhenxu94 I have a doubt about the group naming principle. What are they? Why all these say `FeatureGroupxx`, and the last one shows `Gateway`?', 'commenter': 'wu-sheng'}, {'comment': ""> @kezhenxu94 I have a doubt about the group naming principle. What are they? Why all these say `FeatureGroupxx`, and the last one shows `Gateway`?\r\n\r\nThe `Gateway` should be also renamed to `FeatureGroupXX` I think, if @wu-sheng you have better suggestion, I'm good to follow :) as for the `PHP` job, as an individual language agent, I prefer to set up another workflow, named `PHP Agent` or `PHP SDK`, WDYT"", 'commenter': 'kezhenxu94'}, {'comment': ""I prefer it keeps in a separated group, to avoid unexpected CI process conflict with other tests. Also, most PMC know little about the PHP agent, if conflict occurs, it is hard to follow.\r\n\r\n@heyanlong Please create `e2e.php.yaml`.\r\n@kezhenxu94 , please rename to `FeatureGroupXX`, at least keep consistent. I don't have better idea for now."", 'commenter': 'wu-sheng'}]"
4547,test/e2e/e2e-test/docker/php/docker-compose.yml,"@@ -0,0 +1,82 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    image: skywalking/oap:latest
+    expose:
+      - 11800
+      - 12800
+    networks:
+      - e2e
+    restart: on-failure
+    healthcheck:
+      test: [""CMD"", ""bash"", ""-c"", ""cat < /dev/null > /dev/tcp/127.0.0.1/11800""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  php-shadow:
+    image: skyapm/skywalking-php:latest","[{'comment': ""I highly recommended don't use `latest`. Let's image what will happen in the next release? If something breaks in there?"", 'commenter': 'wu-sheng'}]"
4641,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/TableMetaInfo.java,"@@ -18,18 +18,80 @@
 
 package org.apache.skywalking.oap.server.storage.plugin.influxdb;
 
+import com.google.common.collect.Maps;
 import java.util.HashMap;
+import java.util.List;
 import java.util.Map;
+import lombok.AllArgsConstructor;
+import lombok.Builder;
+import lombok.Getter;
+import org.apache.skywalking.oap.server.core.analysis.manual.endpoint.EndpointTraffic;
+import org.apache.skywalking.oap.server.core.analysis.manual.instance.InstanceTraffic;
+import org.apache.skywalking.oap.server.core.analysis.manual.segment.SegmentRecord;
+import org.apache.skywalking.oap.server.core.analysis.manual.service.ServiceTraffic;
+import org.apache.skywalking.oap.server.core.analysis.metrics.Metrics;
+import org.apache.skywalking.oap.server.core.analysis.record.Record;
+import org.apache.skywalking.oap.server.core.storage.model.ColumnName;
 import org.apache.skywalking.oap.server.core.storage.model.Model;
+import org.apache.skywalking.oap.server.core.storage.model.ModelColumn;
 
+@Getter
+@Builder
+@AllArgsConstructor
 public class TableMetaInfo {
-    private static Map<String, Model> TABLES = new HashMap<>();
+    private static final Map<String, TableMetaInfo> TABLES = new HashMap<>();
+
+    private Map<String, String> storageAndColumnMap;
+    private Map<String, String> storageAndTagMap;
+    private Model model;
 
     public static void addModel(Model model) {
-        TABLES.put(model.getName(), model);
+        final List<ModelColumn> columns = model.getColumns();
+        final Map<String, String> storageAndTagMap = Maps.newHashMap();
+        final Map<String, String> storageAndColumnMap = Maps.newHashMap();
+        columns.forEach(column -> {
+            ColumnName columnName = column.getColumnName();
+            storageAndColumnMap.put(columnName.getStorageName(), columnName.getName());
+        });
+
+        if (model.getName().endsWith(""_traffic"")) {
+            // instance_traffic name, service_id
+            // endpoint_traffic name, service_id
+            storageAndTagMap.put(InstanceTraffic.NAME, InfluxConstants.TagName.NAME);
+            if (""instance_traffic"".equals(model.getName())
+                || ""endpoint_traffic"".equals(model.getName())) {","[{'comment': 'I think we need to use `InstanceTraffic#INDEX_NAME` and `EndpointTraffic#INDEX_NAME` in there. ', 'commenter': 'mrproliu'}]"
4647,test/e2e/e2e-test/docker/go/go2sky-e2e/go.sum,"@@ -0,0 +1,79 @@
+cloud.google.com/go v0.26.0/go.mod h1:aQUYkXzVsufM+DwF1aE+0xfcU+56JwCaLick0ClmMTw=","[{'comment': 'Do we really need this file? I think you have the go2sky commitid, should have these already, if we run go vendor or something in the CI process.', 'commenter': 'wu-sheng'}, {'comment': '> Do we really need this file?\r\n\r\n`go.sum` should be kept.\r\n\r\nhttps://golang.org/cmd/go/#hdr-Module_authentication_using_go_sum\r\n\r\n> I think you have the go2sky commitid, should have these already, if we run go vendor or something in the CI process.\r\n\r\nI depend on `go2sky` with the [pseudo-version](https://golang.org/cmd/go/#hdr-Pseudo_versions), which is actually the same as the `commit-id` effect.', 'commenter': 'arugal'}, {'comment': ""My point is, you have the go2sky commit I'd already, you should be able to regenerate all these. Otherwise, how users use our repo?"", 'commenter': 'wu-sheng'}, {'comment': 'I know this file is needed, but not hosted', 'commenter': 'wu-sheng'}, {'comment': 'Users can use it by adding it to [go.mod](https://github.com/arugal/skywalking/blob/5470877696289f77b40d1debb6f454417b003d27/test/e2e/e2e-test/docker/go/go2sky-e2e/go.mod#L5).', 'commenter': 'arugal'}, {'comment': ""I think you haven't followed my point. Let's talk in this way, one day, user came to the go2sky repo, he didn't need anything rather than standard Go env. Right? He could do git clone, And more commands to make things ready. Now, we have commit ID file, we should not maintain this file in main repo.\r\nIs this clear now?"", 'commenter': 'wu-sheng'}]"
4647,test/e2e/e2e-test/docker/go/Dockerfile.go,"@@ -0,0 +1,37 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+FROM golang:1.12 AS builder
+
+ARG COMMIT_HASH=fdb185d66faddad1651c18150d63bae32610f3ac","[{'comment': 'We need to update this once go2sky updated, right?', 'commenter': 'wu-sheng'}, {'comment': 'Yes', 'commenter': 'arugal'}]"
4667,apm-sniffer/apm-sdk-plugin/hystrix-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/hystrix/v1/SWExecutionHookWrapper.java,"@@ -44,10 +49,15 @@ public SWExecutionHookWrapper(HystrixCommandExecutionHook actual) {
 
         EnhancedInstance enhancedInstance = (EnhancedInstance) commandInstance;
         EnhanceRequireObjectCache enhanceRequireObjectCache = (EnhanceRequireObjectCache) enhancedInstance.getSkyWalkingDynamicField();
-        if (ContextManager.isActive()) {
-            enhanceRequireObjectCache.setContextSnapshot(ContextManager.capture());
+        try {
+            if (ContextManager.isActive()) {","[{'comment': '@BFergerson isActive should have checked the TracingContext is there,  why NPE in the `#capture`?\r\n\r\n@Indifer Your fix is not right, because this should not happen at all. We need to find out why. The reason is above.', 'commenter': 'wu-sheng'}, {'comment': 'ContextManager.isActive() is judge AbstractTracerContext is not null。\r\n![image](https://user-images.githubusercontent.com/7918822/79678912-e6c70600-8232-11ea-8b98-ea39b40018b0.png)\r\n\r\nbut ContextManager.capture() may be throw ex\r\n![image](https://user-images.githubusercontent.com/7918822/79678915-efb7d780-8232-11ea-9f87-590b6760c0c4.png)\r\n![image](https://user-images.githubusercontent.com/7918822/79678939-46251600-8233-11ea-92bf-9ed3ce08d997.png)\r\n\r\n![image](https://user-images.githubusercontent.com/7918822/79678921-fc3c3000-8232-11ea-9974-91c386006377.png)\r\n\r\n', 'commenter': 'Indifer'}, {'comment': ""With no span in the context, shouldn't have the TracingContext. That is my point."", 'commenter': 'wu-sheng'}, {'comment': ""@wu-sheng, I'm not familiar with Hystrix through I agree this change isn't the solution. My first thought is maybe the version of Hystrix @Indifer is using isn't supported yet. I think we would need a reproducible example to move forward."", 'commenter': 'BFergerson'}, {'comment': 'Agree. @Indifer I hope you could debug more about why this happens.', 'commenter': 'wu-sheng'}, {'comment': ""The version of Hystrix is 1.5.11, I'm not familiar with Hystrix too, I'll debug it sometime."", 'commenter': 'Indifer'}]"
4690,test/e2e/e2e-service-provider/src/main/java/test/apache/skywalking/e2e/User.java,"@@ -16,7 +16,7 @@
  *
  */
 
-package org.apache.skywalking.e2e;
+package test.apache.skywalking.e2e;","[{'comment': 'What does the renaming fix? If it really fixes something, please add the directory to\r\n\r\nhttps://github.com/apache/skywalking/blob/8e6a527f78108c7a466ba2dd87eaf5c47d1765cc/tools/coverage/report.sh#L32-L34\r\n\r\ni.e. `sudo rm -rf ""${JACOCO_HOME}""/classes/""${exec_data}""/test || true `', 'commenter': 'kezhenxu94'}, {'comment': 'So the package name rules need to be updated too, is the renaming a must?', 'commenter': 'kezhenxu94'}, {'comment': 'Use the `org.apache.skywalking` package prefix, then the `SpringMVC` plugin cannot be enhanced, because that package is ignored. So avoid using this package. ', 'commenter': 'mrproliu'}, {'comment': ""@kezhenxu94  I seem the e2e also has the style check, and It's must match the package name with regex, `^org\\.apache\\.skywalking(\\.[a-zA-Z][a-zA-Z0-9]*)+$`, so how can I fix that?"", 'commenter': 'mrproliu'}, {'comment': '> Use the `org.apache.skywalking` package prefix, then the `SpringMVC` plugin cannot be enhanced, because that package is ignored. So avoid using this package.\r\n\r\nThen you need to:\r\n\r\n- update the package name rules:\r\n\r\nhttps://github.com/apache/skywalking/blob/dcd66ee6e940bdc9a7ecf90415929bfd48a3a284/apm-checkstyle/checkStyle.xml#L99\r\n\r\n- add the package to exclusion list\r\n\r\nhttps://github.com/apache/skywalking/blob/8e6a527f78108c7a466ba2dd87eaf5c47d1765cc/tools/coverage/report.sh#L32-L34\r\n\r\ni.e. `sudo rm -rf ""${JACOCO_HOME}""/classes/""${exec_data}""/test || true `', 'commenter': 'kezhenxu94'}, {'comment': 'I think test.apache.skywalking package is used in the spring plugin test too.', 'commenter': 'wu-sheng'}, {'comment': '> I think test.apache.skywalking package is used in the spring plugin test too.\r\n\r\nYes.', 'commenter': 'mrproliu'}, {'comment': '> > Use the `org.apache.skywalking` package prefix, then the `SpringMVC` plugin cannot be enhanced, because that package is ignored. So avoid using this package.\r\n> \r\n> Then you need to:\r\n> \r\n> * update the package name rules:\r\n> \r\n> https://github.com/apache/skywalking/blob/dcd66ee6e940bdc9a7ecf90415929bfd48a3a284/apm-checkstyle/checkStyle.xml#L99\r\n> \r\n> * add the package to exclusion list\r\n> \r\n> https://github.com/apache/skywalking/blob/8e6a527f78108c7a466ba2dd87eaf5c47d1765cc/tools/coverage/report.sh#L32-L34\r\n> \r\n> i.e. `sudo rm -rf ""${JACOCO_HOME}""/classes/""${exec_data}""/test || true `\r\n\r\nI have changed, please take a look. ', 'commenter': 'mrproliu'}]"
4690,apm-checkstyle/checkStyle.xml,"@@ -96,7 +96,7 @@
             <property name=""format"" value=""(^[A-Z][A-Z0-9]*(_[A-Z0-9]+)*$)""/>
         </module>
         <module name=""PackageName"">
-            <property name=""format"" value=""^org\.apache\.skywalking(\.[a-zA-Z][a-zA-Z0-9]*)+$""/>
+            <property name=""format"" value=""^(org|test)\.apache\.skywalking(\.[a-zA-Z][a-zA-Z0-9]*)+$""/>","[{'comment': 'Question, in spring 4.1.x test case, we have this package name, so why we change this now? Does only e2e follow this style file, but plugin tests not?', 'commenter': 'wu-sheng'}, {'comment': '@kezhenxu94 @dmsolr ', 'commenter': 'wu-sheng'}, {'comment': '> Question, in spring 4.1.x test case, we have this package name, so why we change this now? Does only e2e follow this style file, but plugin tests not?\r\n\r\nYes obviously, there is checkstyle plugin in E2E `pom.xml`, but not in the plugin tests, ', 'commenter': 'kezhenxu94'}, {'comment': '@dmsolr Please take care of plugin test codes when you have time.', 'commenter': 'wu-sheng'}, {'comment': ""PluginTests don't enable checkstyle yet. ref #4377 "", 'commenter': 'dmsolr'}]"
4748,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/oal/rt/OALDefine.java,"@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.core.oal.rt;
+
+import lombok.Getter;
+
+import static java.util.Objects.requireNonNull;
+
+/**
+ * Define multiple OAL configuration
+ */
+@Getter
+public enum OALDefine {","[{'comment': 'Enum is now good for extension, because you have to change the source codes. Please consider this as an abstract type.', 'commenter': 'wu-sheng'}, {'comment': 'Is that right ?\r\n```java\r\n@Getter\r\npublic abstract class OALDefine {\r\n\r\n    OALDefine(final String configFile,\r\n              final String sourcePackage,\r\n              final String dynamicMetricsClassPackage,\r\n              final String dynamicMetricsBuilderClassPackage, final String dynamicDispatcherClassPackage) {\r\n        this.configFile = requireNonNull(configFile);\r\n        this.sourcePackage = requireNonNull(sourcePackage);\r\n        this.dynamicMetricsClassPackage = requireNonNull(dynamicMetricsClassPackage);\r\n        this.dynamicMetricsBuilderClassPackage = requireNonNull(dynamicMetricsBuilderClassPackage);\r\n        this.dynamicDispatcherClassPackage = requireNonNull(dynamicDispatcherClassPackage);\r\n    }\r\n\r\n    private final String configFile;\r\n    private final String sourcePackage;\r\n    private final String dynamicMetricsClassPackage;\r\n    private final String dynamicMetricsBuilderClassPackage;\r\n    private final String dynamicDispatcherClassPackage;\r\n}\r\n```\r\n```java\r\npublic class OfficialOALDefine extends OALDefine {\r\n\r\n    public static final OfficialOALDefine INSTANCE = new OfficialOALDefine();\r\n\r\n    private OfficialOALDefine() {\r\n        super(\r\n            ""official_analysis.oal"",\r\n            ""org.apache.skywalking.oap.server.core.source."",\r\n            ""org.apache.skywalking.oal.rt.official.metrics."",\r\n            ""org.apache.skywalking.oal.rt.official.metrics.builder."",\r\n            ""org.apache.skywalking.oal.rt.official.dispatcher.""\r\n        );\r\n    }\r\n}\r\n```', 'commenter': 'arugal'}, {'comment': 'Yes. Like this.', 'commenter': 'wu-sheng'}, {'comment': 'Done.', 'commenter': 'arugal'}]"
4748,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/oal/rt/OALEngineLoaderService.java,"@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.core.oal.rt;
+
+import java.lang.reflect.Constructor;
+import java.util.HashSet;
+import java.util.Set;
+import lombok.RequiredArgsConstructor;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.StreamAnnotationListener;
+import org.apache.skywalking.oap.server.core.source.SourceReceiver;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.module.ModuleProvider;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.module.Service;
+
+/**
+ * Activate {@link OALEngine} according to {@link OALDefine}
+ */
+@Slf4j
+@RequiredArgsConstructor
+public class OALEngineLoaderService implements Service {
+
+    private final Set<OALDefine> oalDefineSet = new HashSet<>();
+    private final ModuleManager moduleManager;
+
+    /**
+     * Normally it is invoked in the {@link ModuleProvider#start()} of the receiver-plugin module.
+     */
+    public void loader(OALDefine define) throws ModuleStartException {","[{'comment': '`loader` -> `load`', 'commenter': 'wu-sheng'}, {'comment': 'Should not have `ModuleStartException`, this is not a module', 'commenter': 'wu-sheng'}, {'comment': '`OALEngine` throws `ModuleStartException` and `OALCompileException`. Meanwhile `OALEngineLoaderService#load()` is called in `ModuleProvider#start()`.\r\nhttps://github.com/apache/skywalking/blob/d713076f011af2b97f61969e96fb2b56dbccbb06/oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/oal/rt/OALEngine.java#L28-L36', 'commenter': 'arugal'}, {'comment': '> `loader` -> `load`\r\n\r\nDone.', 'commenter': 'arugal'}]"
4748,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/oal/rt/OALEngineLoaderService.java,"@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.core.oal.rt;
+
+import java.lang.reflect.Constructor;
+import java.util.HashSet;
+import java.util.Set;
+import lombok.RequiredArgsConstructor;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.StreamAnnotationListener;
+import org.apache.skywalking.oap.server.core.source.SourceReceiver;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.module.ModuleProvider;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.module.Service;
+
+/**
+ * Activate {@link OALEngine} according to {@link OALDefine}
+ */
+@Slf4j
+@RequiredArgsConstructor
+public class OALEngineLoaderService implements Service {
+
+    private final Set<OALDefine> oalDefineSet = new HashSet<>();
+    private final ModuleManager moduleManager;
+
+    /**
+     * Normally it is invoked in the {@link ModuleProvider#start()} of the receiver-plugin module.
+     */
+    public void load(OALDefine define) throws ModuleStartException {
+        if (oalDefineSet.contains(define)) {","[{'comment': 'Seems you did not override the `hashCode` and `equals` methods in `OALDefine` and its subclasses', 'commenter': 'kezhenxu94'}, {'comment': 'Default, hash* uses the object ID, so, this only works for the same object, rather than the same OAL.\r\n\r\nThis should be fixed.\r\n\r\nBTW, I am considering to enhance this later, merging the content rather than the file only. But this is totally another story.', 'commenter': 'wu-sheng'}, {'comment': 'Done.', 'commenter': 'arugal'}]"
4778,docs/en/guides/Java-Plugin-Development-Guide.md,"@@ -105,7 +105,7 @@ Create ExitSpan by operation name(e.g. service name, uri) and new **ContextCarri
 
     /**
      * Only use this method in explicit instrumentation, like opentracing-skywalking-bridge.
-     * It it higher recommend don't use this for performance consideration.
+     * It is highly recommended not to use this for performance consideration.","[{'comment': 'Actually, this method has been removed in the 8.0.0. Please remove all these in the document, thanks.', 'commenter': 'wu-sheng'}, {'comment': '...Done', 'commenter': 'TerrellChen'}]"
4844,tools/dependencies/known-oap-backend-dependencies.txt,"@@ -145,22 +150,17 @@ protobuf-java-util-3.11.4.jar
 rank-eval-client-6.3.2.jar
 reactive-streams-1.0.2.jar
 reflectasm-1.11.7.jar
-resourcecify-annotations-0.9.2.jar
+resourcecify-annotations-0.21.0.jar
 retrofit-2.3.0.jar
 simpleclient-0.6.0.jar
 simpleclient_common-0.6.0.jar
 simpleclient_hotspot-0.6.0.jar
 simpleclient_httpserver-0.6.0.jar
 slf4j-api-1.7.25.jar
 snakeyaml-1.18.jar
-sundr-codegen-0.9.2.jar
-sundr-core-0.9.2.jar
-swagger-annotations-1.5.12.jar
+sundr-codegen-0.21.0.jar
+sundr-core-0.21.0.jar
+swagger-annotations-1.5.22.jar","[{'comment': 'You should update all these changes(version and new libs) into the LICENSE file. Also, if any of new lib is in Apache 2.0 license, and having NOTICE file in their original repo, you need to copy the content into our NOTICE file too(in the same folder as LICENSE file)\r\n\r\nAll these requirements are based on the license laws and ASF guidances.', 'commenter': 'wu-sheng'}]"
4844,oap-server/server-cluster-plugin/cluster-kubernetes-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/kubernetes/NamespacedPodListInformer.java,"@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.cluster.plugin.kubernetes;
+
+import io.kubernetes.client.informer.SharedIndexInformer;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.informer.cache.Lister;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1Pod;
+import io.kubernetes.client.openapi.models.V1PodList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.List;
+import java.util.Optional;
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public enum NamespacedPodListInformer {
+
+    /**
+     * contains remote collector instances
+     */
+    INFORMER;
+
+    private Lister<V1Pod> podLister;
+
+    public synchronized void init(ClusterModuleKubernetesConfig podConfig) {
+
+        try {
+            doStartPodInformer(podConfig);
+        } catch (IOException e) {
+            log.error(""cannot connect with api server in kubernetes"", e);
+        }
+    }
+
+    private void doStartPodInformer(ClusterModuleKubernetesConfig podConfig) throws IOException {
+
+        ApiClient client = Config.defaultClient();
+        CoreV1Api coreV1Api = new CoreV1Api(client);
+
+        SharedInformerFactory factory = new SharedInformerFactory();","[{'comment': ""Pls, adopt to a custom thread pool to create daemon thread instead of the default cached thread pool. That's because the cluster coordination model is lack of `stop` phase, so we don't have any opportunity to invoke `stopAllRegisteredInformers`."", 'commenter': 'hanahmily'}, {'comment': 'add a hook when service shutdown ,thx for review again', 'commenter': 'EvanLjp'}]"
4844,dist-material/release-docs/LICENSE,"@@ -216,6 +216,7 @@ The following components are provided under the Apache License. See project link
 The text of each license is also included at licenses/LICENSE-[project].txt.
 
     Apache: httpcomponents 4.x.x: http://hc.apache.org/index.html, Apache 2.0
+    Apache: fastjson 1.2.58:  https://github.com/alibaba/fastjson, Apache 2.0","[{'comment': 'Fastjson should have been removed.', 'commenter': 'wu-sheng'}]"
4844,dist-material/release-docs/LICENSE,"@@ -304,12 +306,13 @@ The text of each license is the standard Apache 2.0 license.
     HikariCP 3.1.0: https://github.com/brettwooldridge/HikariCP, Apache 2.0
     zipkin 2.9.1: https://github.com/openzipkin/zipkin, Apache 2.0
     sharding-jdbc-core 2.0.3: https://github.com/sharding-sphere/sharding-sphere, Apache 2.0
-    kubernetes-client 4.0.0: https://github.com/kubernetes-client/java, Apache 2.0
+    kubernetes-client 8.0.0: https://github.com/kubernetes-client/java, Apache 2.0
     proto files from istio/istio: https://github.com/istio/istio  Apache 2.0
     proto files from istio/api: https://github.com/istio/api      Apache 2.0
     consul-client 1.2.6: https://github.com/rickfast/consul-client, Apache 2.0
     okhttp 3.9.0: https://github.com/square/okhttp, Apache 2.0
     prometheus client_java 0.6.0: https://github.com/prometheus/client_java, Apache 2.0
+    nacos 1.2.0: https://github.com/alibaba/nacos, Apache 2.0","[{'comment': 'Nacos should be removed too.', 'commenter': 'wu-sheng'}, {'comment': 'fix it,I already know how to add a license, but how to check whether the license needs to be deleted, is there a shell script to check it?', 'commenter': 'EvanLjp'}, {'comment': 'I am afraid there is. The way is acorss-check the LICENSE file and known-oap-backend-dependencies.txt files. They should match.', 'commenter': 'wu-sheng'}, {'comment': 'which shell script? Is it in the repository? this will help us to check the dependencies before commit ', 'commenter': 'EvanLjp'}]"
4846,apm-sniffer/apm-sdk-plugin/influxdb-2.x-plugin/pom.xml,"@@ -0,0 +1,47 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+  <parent>
+    <artifactId>apm-sdk-plugin</artifactId>
+    <groupId>org.apache.skywalking</groupId>
+    <version>8.0.0-SNAPSHOT</version>
+  </parent>
+  <modelVersion>4.0.0</modelVersion>
+
+  <artifactId>apm-influxdb-2.x-plugin</artifactId>
+  <description>This plugin is for use with InfluxDB 1.x.</description>","[{'comment': ""The `artifactId` and the `description` don't match, one says it's for `2.x` while the other says it's for `1.x`"", 'commenter': 'kezhenxu94'}, {'comment': ""`apm-influxdb-2.x-plugin` means  influxdb client lib version\r\n`This plugin is for use with InfluxDB 1.x.` means influxdb version , then i'll change to client version\r\n"", 'commenter': 'dagmom'}]"
4846,apm-sniffer/apm-sdk-plugin/influxdb-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/influxdb/define/InfluxDBInstrumentation.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.influxdb.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.agent.core.plugin.match.NameMatch;
+import org.apache.skywalking.apm.plugin.influxdb.InfluxDBMethodMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.takesArgument;
+
+/**
+ * enhance InfluxDB InfluxDBFactory
+ * really impl class {@link org.influxdb.impl.InfluxDBImpl}
+ *
+ * @since  2020/05/22","[{'comment': 'Capitalize the first letter of the sentence please', 'commenter': 'kezhenxu94'}, {'comment': 'What does since date mean? Quiet unusual, from my understanding. We coulf know when be added through git log directly\r\n', 'commenter': 'wu-sheng'}, {'comment': 'What does since date mean? Quiet unusual, from my understanding. We coulf know when be added through git log directly\r\n', 'commenter': 'wu-sheng'}, {'comment': ""ok,I'll remove`since`"", 'commenter': 'dagmom'}]"
4846,apm-sniffer/apm-sdk-plugin/influxdb-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/influxdb/define/InfluxDBInstrumentation.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.influxdb.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.agent.core.plugin.match.NameMatch;
+import org.apache.skywalking.apm.plugin.influxdb.InfluxDBMethodMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.takesArgument;
+
+/**
+ * enhance InfluxDB InfluxDBFactory
+ * really impl class {@link org.influxdb.impl.InfluxDBImpl}
+ *
+ * @since  2020/05/22
+ */
+public class InfluxDBInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_CLASS = ""org.influxdb.impl.InfluxDBImpl"";
+    private static final String INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.influxdb.interceptor.InfluxDBConstructorInterceptor"";
+  private static final String INFLUXDB_METHOD_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.influxdb.interceptor.InfluxDBMethodInterceptor"";","[{'comment': '```suggestion\r\n    private static final String INFLUXDB_METHOD_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.influxdb.interceptor.InfluxDBMethodInterceptor"";\r\n```', 'commenter': 'kezhenxu94'}]"
4846,apm-sniffer/apm-sdk-plugin/influxdb-2.x-plugin/src/test/java/org/apache/skywalking/apm/plugin/influxdb/InfluxDBMethodInterceptorTest.java,"@@ -0,0 +1,147 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.influxdb;
+
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractTracingSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.LogDataEntity;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.context.trace.TraceSegment;
+import org.apache.skywalking.apm.agent.core.context.util.TagValuePair;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.test.helper.SegmentHelper;
+import org.apache.skywalking.apm.agent.test.helper.SpanHelper;
+import org.apache.skywalking.apm.agent.test.tools.AgentServiceRule;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStorage;
+import org.apache.skywalking.apm.agent.test.tools.SegmentStoragePoint;
+import org.apache.skywalking.apm.agent.test.tools.TracingSegmentRunner;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.apache.skywalking.apm.plugin.influxdb.interceptor.InfluxDBMethodInterceptor;
+import org.hamcrest.CoreMatchers;
+import org.influxdb.InfluxDBException;
+import org.influxdb.dto.Point;
+import org.influxdb.impl.InfluxDBImpl;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.powermock.modules.junit4.PowerMockRunnerDelegate;
+
+import java.lang.reflect.Method;
+import java.util.List;
+
+import static junit.framework.TestCase.assertNotNull;
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.mockito.Mockito.when;
+
+@RunWith(PowerMockRunner.class)
+@PowerMockRunnerDelegate(TracingSegmentRunner.class)
+public class InfluxDBMethodInterceptorTest {
+
+    @SegmentStoragePoint
+    private SegmentStorage segmentStorage;
+
+    @Rule
+    public AgentServiceRule serviceRule = new AgentServiceRule();
+
+    @Mock
+    private EnhancedInstance enhancedInstance;
+
+    private InfluxDBMethodInterceptor interceptor;
+
+    private Object[] allArgument;
+
+    private Class[] argumentType;
+
+    @Before
+    public void setUp() throws Exception {
+        allArgument = new Object[] {
+            Point.measurement(""cpu"")
+                .tag(""host"", ""127.0.0.1"")
+                .addField(""use_idle"", 0.8)
+                .build()
+        };
+        argumentType = new Class[] {
+            Point.class
+        };
+
+        interceptor = new InfluxDBMethodInterceptor();
+        when(enhancedInstance.getSkyWalkingDynamicField()).thenReturn(""http://127.0.0.1:8086"");
+    }
+
+    @Test
+    public void testIntercept() throws Throwable {
+        interceptor.beforeMethod(enhancedInstance, getMockWriteMethod(), allArgument, argumentType, null);
+        interceptor.afterMethod(enhancedInstance, getMockWriteMethod(), allArgument, argumentType, null);
+
+        TraceSegment traceSegment = segmentStorage.getTraceSegments().get(0);
+        List<AbstractTracingSpan> spans = SegmentHelper.getSpans(traceSegment);
+        assertThat(spans.size(), is(1));
+        assertInfluxDBSpan(spans.get(0));
+    }
+
+    @Test
+    public void testInterceptWithException() throws Throwable {
+        interceptor.beforeMethod(enhancedInstance, getMockWriteMethod(), allArgument, argumentType, null);
+        interceptor.handleMethodException(enhancedInstance, getMockWriteMethod(), allArgument, argumentType, new InfluxDBException(""test exception""));
+        interceptor.afterMethod(enhancedInstance, getMockWriteMethod(), allArgument, argumentType, null);
+
+        TraceSegment traceSegment = segmentStorage.getTraceSegments().get(0);
+        List<AbstractTracingSpan> spans = SegmentHelper.getSpans(traceSegment);
+        assertThat(spans.size(), is(1));
+        assertInfluxDBSpan(spans.get(0));
+
+        assertLogData(SpanHelper.getLogs(spans.get(0)));
+    }
+
+    private void assertLogData(List<LogDataEntity> logDataEntities) {
+        assertThat(logDataEntities.size(), is(1));
+        LogDataEntity logData = logDataEntities.get(0);
+        Assert.assertThat(logData.getLogs().size(), is(4));
+        Assert.assertThat(logData.getLogs().get(0).getValue(), CoreMatchers.<Object>is(""error""));
+        Assert.assertThat(logData.getLogs()
+                                 .get(1)
+                                 .getValue(), CoreMatchers.<Object>is(InfluxDBException.class.getName()));
+        Assert.assertEquals(""test exception"", logData.getLogs().get(2).getValue());
+        assertNotNull(logData.getLogs().get(3).getValue());
+    }
+
+    private void assertInfluxDBSpan(AbstractTracingSpan span) {
+        assertThat(span.getOperationName(), is(""InfluxDB/write""));
+        assertThat(span.isExit(), is(true));
+        assertThat(SpanHelper.getComponentId(span), is(ComponentsDefine.INFLUXDB_JAVA.getId()));
+        List<TagValuePair> tags = SpanHelper.getTags(span);
+        assertThat(tags.get(0).getValue(), is(""InfluxDB""));
+//        assertThat(tags.get(1).getValue(), is(""write "".concat(allArgument[0].toString())));","[{'comment': 'Remove if useless, or fix it if assertion is failed', 'commenter': 'kezhenxu94'}]"
4846,test/plugin/scenarios/influxdb-scenario/src/main/java/org/apache/skywalking/apm/testcase/influxdb/executor/InfluxDBExecutor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.influxdb.executor;
+
+import org.influxdb.InfluxDB;
+import org.influxdb.InfluxDBFactory;
+import org.influxdb.dto.Point;
+import org.influxdb.dto.Pong;
+import org.influxdb.dto.Query;
+import org.influxdb.dto.QueryResult;
+
+/**
+ * InfluxDBExecutor
+ *
+ * @author guhao
+ * @since 2020/6/3","[{'comment': 'Remove author tag', 'commenter': 'kezhenxu94'}]"
4846,test/plugin/scenarios/influxdb-scenario/src/test/java/org/apache/skywalking/apm/testcase/influxdb/executor/InfluxDBExecutorTest.java,"@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.influxdb.executor;
+
+/**
+ * InfluxDBExecutorTest
+ *
+ * @author guhao
+ * @since 2020/6/3
+ */
+public class InfluxDBExecutorTest {
+
+//  @Test
+//  public void testPing(){
+//    InfluxDBExecutor executor = new InfluxDBExecutor(""http://localhost:8086"");
+//    Pong pong = executor.ping();
+//    System.out.println(pong.getVersion());
+//    Assert.assertNotNull(pong.getVersion());
+//  }
+
+}","[{'comment': ""Remove this if it's useless"", 'commenter': 'kezhenxu94'}]"
4846,apm-sniffer/apm-sdk-plugin/influxdb-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/influxdb/define/InfluxDBInstrumentation.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.influxdb.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+import org.apache.skywalking.apm.agent.core.plugin.match.NameMatch;
+import org.apache.skywalking.apm.plugin.influxdb.InfluxDBMethodMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.takesArgument;
+
+/**
+ * enhance InfluxDB InfluxDBFactory
+ * really impl class {@link org.influxdb.impl.InfluxDBImpl}
+ *
+ * @since  2020/05/22
+ */
+public class InfluxDBInstrumentation extends ClassInstanceMethodsEnhancePluginDefine {
+
+    private static final String ENHANCE_CLASS = ""org.influxdb.impl.InfluxDBImpl"";
+    private static final String INTERCEPTOR_CLASS = ""org.apache.skywalking.apm.plugin.influxdb.interceptor.InfluxDBConstructorInterceptor"";
+  private static final String INFLUXDB_METHOD_INTERCEPT_CLASS = ""org.apache.skywalking.apm.plugin.influxdb.interceptor.InfluxDBMethodInterceptor"";
+
+    @Override
+    protected ClassMatch enhanceClass() {
+        return NameMatch.byName(ENHANCE_CLASS);
+    }
+
+    @Override
+    public ConstructorInterceptPoint[] getConstructorsInterceptPoints() {
+        return new ConstructorInterceptPoint[] {
+            new ConstructorInterceptPoint() {
+                @Override
+                public ElementMatcher<MethodDescription> getConstructorMatcher() {
+                    return takesArgument(0, String.class);
+                }
+
+                @Override
+                public String getConstructorInterceptor() {
+                    return INTERCEPTOR_CLASS;
+                }
+            }
+        };
+    }
+
+    @Override
+    public InstanceMethodsInterceptPoint[] getInstanceMethodsInterceptPoints() {
+      return new InstanceMethodsInterceptPoint[] {
+          new InstanceMethodsInterceptPoint() {
+            @Override
+            public ElementMatcher<MethodDescription> getMethodsMatcher() {
+              return InfluxDBMethodMatch.INSTANCE.getInfluxDBMethodMatcher();","[{'comment': ""This is good for encapsulation, but it's a pitfall that we check third-party classes in classes whose name end with `*Instrumentation`\r\n\r\nhttps://github.com/apache/skywalking/blob/f3d907bf6df924e7cc7e65efbdfd847920ce47e5/apm-checkstyle/checkStyle.xml#L122-L129\r\n\r\nto avoid issues like this https://github.com/apache/skywalking/pull/2871 , but this breaks the checks, although there is no third-party class in the `InfluxDBMethodMatch` for now, other reviewers should pay attention to this class in the future, FYI @wu-sheng "", 'commenter': 'kezhenxu94'}, {'comment': 'Question, why need this singleton. This method is not called in high frequently, and nothing cached there. ', 'commenter': 'wu-sheng'}, {'comment': 'I did it the other way', 'commenter': 'dagmom'}]"
4846,oap-server/server-bootstrap/src/main/resources/component-libraries.yml,"@@ -52,7 +52,7 @@ ORACLE:
   languages: Java
 Redis:
   id: 7
-  languages: Java,C#,Node.js,PHP
+  languages: Java,C#,Node.js","[{'comment': 'Why Deleting? Mischange?', 'commenter': 'wu-sheng'}, {'comment': 'Mischange when merge remote-tracing branch', 'commenter': 'dagmom'}]"
4846,apm-sniffer/config/agent.config,"@@ -78,3 +78,6 @@ logging.level=${SW_LOGGING_LEVEL:INFO}
 
 # mysql plugin configuration
 # plugin.mysql.trace_sql_parameters=${SW_MYSQL_TRACE_SQL_PARAMETERS:false}
+
+# influxdb plugin configuration
+# plugin.influxdb.trace_influxql=${SW_INFLUXDB_TRACE_INFLUXQL:true}","[{'comment': ""This is not a widely used config, don't need to add it into the default agent.config. Putting it in the document should be enough."", 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-configmap/pom.xml,"@@ -0,0 +1,31 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>","[{'comment': 'I think you missed this license.', 'commenter': 'wu-sheng'}, {'comment': 'sorry, i would be fix later', 'commenter': 'EvanLjp'}]"
4959,docs/en/setup/backend/dynamic-config.md,"@@ -102,3 +102,16 @@ configuration:
     appId: ${SW_CONFIG_APOLLO_APP_ID:skywalking}
     period: ${SW_CONFIG_APOLLO_PERIOD:5}
 ```
+
+## Dynamic Configuration Kuberbetes Configmap Implementation
+
+[configmap](https://kubernetes.io/docs/concepts/configuration/configmap/) is also supported as DCC(Dynamic Configuration Center), to use it, just configured as follows:
+
+```yaml
+configuration:
+  selector: ${SW_CONFIGURATION:configmap}
+  configmap:
+      period: ${SW_CONFIG_CONSUL_PERIOD:60}
+      namespace: ${SW_CLUSTER_K8S_NAMESPACE:default}
+      labelSelector: ${SW_CLUSTER_K8S_LABEL:app=collector,release=skywalking}
+```","[{'comment': 'Please add descriptions about how the `labelSelector` works.', 'commenter': 'wu-sheng'}, {'comment': 'And please link the `skywalking-dynamic-configmap.example.yaml` as an example here.', 'commenter': 'wu-sheng'}, {'comment': 'no problem', 'commenter': 'EvanLjp'}, {'comment': 'typo: confiigmap -> configmap', 'commenter': 'innerpeacez'}]"
4959,oap-server/server-configuration/configuration-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigurationConfigmapInformer.java,"@@ -0,0 +1,99 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import io.kubernetes.client.informer.SharedIndexInformer;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.informer.cache.Lister;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1ConfigMap;
+import io.kubernetes.client.openapi.models.V1ConfigMapList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public enum ConfigurationConfigmapInformer {","[{'comment': ""Why enum? Typically, we recommend don't' do this, unless you have to."", 'commenter': 'wu-sheng'}, {'comment': 'It is supposed to be singleton and initialized once, but there are some problems, I will fix it.', 'commenter': 'EvanLjp'}, {'comment': 'I hope it should a logic singleton, rather than an enum. Because you have the provider initialization process to make sure there is only one instance. ', 'commenter': 'wu-sheng'}, {'comment': 'yes, i agree with u ,thx for review again', 'commenter': 'EvanLjp'}]"
4959,oap-server/server-configuration/configuration-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigurationConfigmapInformer.java,"@@ -0,0 +1,108 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import io.kubernetes.client.informer.SharedIndexInformer;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.informer.cache.Lister;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1ConfigMap;
+import io.kubernetes.client.openapi.models.V1ConfigMapList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class ConfigurationConfigmapInformer {
+
+    private static ConfigurationConfigmapInformer informer;
+
+    private Lister<V1ConfigMap> configMapLister;
+
+    private SharedInformerFactory factory;
+
+    private final ExecutorService executorService = Executors.newSingleThreadExecutor(r -> {
+        Thread thread = new Thread(r, ""SKYWALKING_KUBERNETES_CONFIGURATION_INFORMER"");
+        thread.setDaemon(true);
+        return thread;
+    });
+
+    public static ConfigurationConfigmapInformer getInstance(ConfigmapConfigurationSettings settings) {
+        if (informer == null) {
+            synchronized (ConfigurationConfigmapInformer.class) {
+                if (informer == null) {
+                    informer = new ConfigurationConfigmapInformer(settings);
+                }
+            }
+        }
+        return informer;
+    }
+
+    private ConfigurationConfigmapInformer(ConfigmapConfigurationSettings settings) {
+
+        try {
+            doStartConfigMapInformer(settings);
+            doAddShowdownHook();
+        } catch (IOException e) {
+            log.error(""cannot connect with api server in kubernetes"", e);
+        }
+
+    }
+
+    private void doAddShowdownHook() {","[{'comment': 'Typo `doAddShowdownHook` -> `doAddShutdownHook`', 'commenter': 'kezhenxu94'}, {'comment': 'fixed', 'commenter': 'EvanLjp'}]"
4959,oap-server/server-bootstrap/src/main/resources/application.yml,"@@ -264,6 +264,10 @@ configuration:
     period: ${SW_CONFIG_CONSUL_PERIOD:1}
     # Consul aclToken
     aclToken: ${SW_CONFIG_CONSUL_ACL_TOKEN:""""}
+  configmap:
+    period: ${SW_CONFIG_CONSUL_PERIOD:60}","[{'comment': 'typo: SW_CONFIG_CONSUL_PERIOD -> SW_CONFIG_CONFIGMAP_PERIOD', 'commenter': 'innerpeacez'}, {'comment': 'ok', 'commenter': 'EvanLjp'}]"
4959,docs/en/setup/backend/dynamic-config.md,"@@ -103,3 +103,20 @@ configuration:
     appId: ${SW_CONFIG_APOLLO_APP_ID:skywalking}
     period: ${SW_CONFIG_APOLLO_PERIOD:5}
 ```
+
+## Dynamic Configuration Kuberbetes Configmap Implementation
+
+[configmap](https://kubernetes.io/docs/concepts/configuration/configmap/) is also supported as DCC(Dynamic Configuration Center), to use it, just configured as follows:
+
+```yaml
+configuration:
+  selector: ${SW_CONFIGURATION:configmap}
+  # [example] (../../../../oap-server/server-configuration/configuration-configmap/src/test/resources/skywalking-dynamic-configmap.example.yaml)
+  configmap:
+      # Sync period in seconds. Defaults to 60 seconds.
+      period: ${SW_CONFIG_CONSUL_PERIOD:60}","[{'comment': 'typo: SW_CONFIG_CONSUL_PERIOD -> SW_CONFIG_CONFIGMAP_PERIOD', 'commenter': 'innerpeacez'}]"
4959,oap-server/server-configuration/configuration-configmap/pom.xml,"@@ -0,0 +1,54 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-configuration</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>8.1.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>configuration-configmap</artifactId>","[{'comment': '```suggestion\r\n    <artifactId>configuration-k8s-configmap</artifactId>\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'Have you finished all these changes?', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigmapConfigurationProvider.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import com.google.common.base.Strings;
+import org.apache.skywalking.oap.server.configuration.api.AbstractConfigurationProvider;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+
+public class ConfigmapConfigurationProvider extends AbstractConfigurationProvider {
+
+    private final ConfigmapConfigurationSettings settings;
+
+    public ConfigmapConfigurationProvider() {
+        this.settings = new ConfigmapConfigurationSettings();
+    }
+
+    @Override
+    public String name() {
+        return ""configmap"";","[{'comment': '```suggestion\r\n        return ""k8s_configmap"";\r\n```\r\n\r\nAnd please change other docs related to this.', 'commenter': 'wu-sheng'}, {'comment': '```suggestion\r\n        return ""k8s_configmap"";\r\n```', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigmapConfigurationWatcherRegister.java,"@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import io.kubernetes.client.openapi.models.V1ConfigMap;
+import java.util.Optional;
+import java.util.Set;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+
+@Slf4j
+public class ConfigmapConfigurationWatcherRegister extends ConfigWatcherRegister {
+
+    private final ConfigurationConfigmapInformer informer;
+
+    public ConfigmapConfigurationWatcherRegister(ConfigmapConfigurationSettings settings,
+                                                 ConfigurationConfigmapInformer informer) {
+        super(settings.getPeriod());
+        this.informer = informer;
+    }
+
+    @Override
+    public Optional<ConfigTable> readConfig(Set<String> keys) {
+        final ConfigTable configTable = new ConfigTable();
+
+        Optional<V1ConfigMap> v1ConfigMap = informer.configMap();
+
+        for (final String name : keys) {
+
+            final String value = v1ConfigMap.map(configMap -> configMap.getData().get(name)).orElse(null);","[{'comment': ""If you can't read the key from configmap, please don't include value in the ConfigTable. I received a report today, someone accidentally reset the default value, even they didn't config the new value in the dynamic configuration center."", 'commenter': 'wu-sheng'}, {'comment': 'ok,thanks for your notice', 'commenter': 'EvanLjp'}]"
4959,all-dependencies-es7.txt,"@@ -0,0 +1,211 @@
+HdrHistogram-2.1.9.jar","[{'comment': 'I think this should not be committed? And the next file?', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-k8s_configmap/pom.xml,"@@ -0,0 +1,54 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>server-configuration</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>8.1.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>configuration-k8s_configmap</artifactId>","[{'comment': '`oap-server/server-configuration/configuration-k8s_configmap` should be `oap-server/server-configuration/configuration-k8s-configmap`', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-bootstrap/src/main/resources/application.yml,"@@ -264,6 +264,10 @@ configuration:
     period: ${SW_CONFIG_CONSUL_PERIOD:1}
     # Consul aclToken
     aclToken: ${SW_CONFIG_CONSUL_ACL_TOKEN:""""}
+  k8s_configmap:","[{'comment': '```suggestion\r\n  k8s-configmap:\r\n```\r\n\r\nSame here, by following other module and provider style.', 'commenter': 'wu-sheng'}, {'comment': 'Sorry for I commented wrong before.', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-k8s_configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigurationConfigmapInformer.java,"@@ -0,0 +1,95 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import io.kubernetes.client.informer.SharedIndexInformer;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.informer.cache.Lister;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1ConfigMap;
+import io.kubernetes.client.openapi.models.V1ConfigMapList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class ConfigurationConfigmapInformer {
+
+    private Lister<V1ConfigMap> configMapLister;
+
+    private SharedInformerFactory factory;
+
+    private final ExecutorService executorService = Executors.newSingleThreadExecutor(r -> {
+        Thread thread = new Thread(r, ""SKYWALKING_KUBERNETES_CONFIGURATION_INFORMER"");
+        thread.setDaemon(true);
+        return thread;
+    });
+
+    public ConfigurationConfigmapInformer(ConfigmapConfigurationSettings settings) {
+
+        try {
+            doStartConfigMapInformer(settings);
+            doAddShutdownHook();
+        } catch (IOException e) {
+            log.error(""cannot connect with api server in kubernetes"", e);
+        }
+
+    }
+
+    private void doAddShutdownHook() {
+        Runtime.getRuntime().addShutdownHook(new Thread(() -> {
+            if (Objects.nonNull(factory)) {
+                factory.stopAllRegisteredInformers();
+            }
+        }));
+    }
+
+    private void doStartConfigMapInformer(final ConfigmapConfigurationSettings settings) throws IOException {
+        ApiClient apiClient = Config.defaultClient();
+        apiClient.setHttpClient(apiClient.getHttpClient().newBuilder().readTimeout(0, TimeUnit.SECONDS).build());
+        CoreV1Api coreV1Api = new CoreV1Api(apiClient);
+
+        factory = new SharedInformerFactory(executorService);
+
+        SharedIndexInformer<V1ConfigMap> configMapSharedIndexInformer = factory.sharedIndexInformerFor(
+            params -> coreV1Api.listNamespacedConfigMapCall(
+                settings.getNamespace(), null, null, null, null, settings.getLabelSelector()
+                , 1, params.resourceVersion, params.timeoutSeconds, params.watch, null
+            ),
+            V1ConfigMap.class, V1ConfigMapList.class
+        );
+
+        factory.startAllRegisteredInformers();
+        configMapLister = new Lister<>(configMapSharedIndexInformer.getIndexer());
+
+    }
+
+    public Optional<V1ConfigMap> configMap() {
+
+        return Optional.ofNullable(configMapLister.list().size() == 1 ? configMapLister.list().get(0) : null);
+","[{'comment': 'Many emtpy lines, please polish the code format.', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-k8s-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigurationConfigmapInformer.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import io.kubernetes.client.informer.SharedIndexInformer;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.informer.cache.Lister;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1ConfigMap;
+import io.kubernetes.client.openapi.models.V1ConfigMapList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class ConfigurationConfigmapInformer {
+
+    private Lister<V1ConfigMap> configMapLister;
+
+    private SharedInformerFactory factory;
+
+    private final ExecutorService executorService = Executors.newSingleThreadExecutor(r -> {
+        Thread thread = new Thread(r, ""SKYWALKING_KUBERNETES_CONFIGURATION_INFORMER"");
+        thread.setDaemon(true);
+        return thread;
+    });
+
+    public ConfigurationConfigmapInformer(ConfigmapConfigurationSettings settings) {
+","[{'comment': 'An unnecessary empty line.', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-k8s-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigmapConfigurationWatcherRegister.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import io.kubernetes.client.openapi.models.V1ConfigMap;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.Set;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+
+@Slf4j
+public class ConfigmapConfigurationWatcherRegister extends ConfigWatcherRegister {
+
+    private final ConfigurationConfigmapInformer informer;
+
+    public ConfigmapConfigurationWatcherRegister(ConfigmapConfigurationSettings settings,
+                                                 ConfigurationConfigmapInformer informer) {
+        super(settings.getPeriod());
+        this.informer = informer;
+    }
+
+    @Override
+    public Optional<ConfigTable> readConfig(Set<String> keys) {
+        final ConfigTable configTable = new ConfigTable();
+
+        Optional<V1ConfigMap> v1ConfigMap = informer.configMap();
+
+        for (final String name : keys) {
+
+            final String value = v1ConfigMap.map(configMap -> configMap.getData().get(name)).orElse(null);
+
+            if (log.isDebugEnabled()) {
+                log.debug(""read config: name:{} ,value:{}"", name, value);
+            }
+            if (Objects.nonNull(value)) {
+                configTable.add(new ConfigTable.ConfigItem(name, value));
+            }
+        }
+","[{'comment': 'Many unnecessary empty lines.', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-k8s-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigmapConfigurationSettings.java,"@@ -0,0 +1,32 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+
+@Setter
+@Getter
+public class ConfigmapConfigurationSettings extends ModuleConfig {
+","[{'comment': 'An unnecessary empty line.', 'commenter': 'wu-sheng'}]"
4959,oap-server/server-configuration/configuration-k8s-configmap/src/main/java/org/apache/skywalking/oap/server/configuration/configmap/ConfigmapConfigurationSettings.java,"@@ -0,0 +1,32 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.configuration.configmap;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+
+@Setter
+@Getter
+public class ConfigmapConfigurationSettings extends ModuleConfig {
+
+    private String namespace;
+    private String labelSelector;
+    private Integer period;","[{'comment': 'Comments are required in here too.', 'commenter': 'wu-sheng'}]"
5085,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/interceptor/RestMappingMethodInterceptor.java,"@@ -80,6 +80,20 @@ public String getRequestURL(Method method) {
 
     @Override
     public String getAcceptedMethodTypes(Method method) {
-        return """";
+        return ParsePathUtil.recursiveParseMethodAnnotation(method, m -> {
+            if (AnnotationUtils.getAnnotation(m, GetMapping.class) != null) {
+                return ""{GET}"";
+            } else if (AnnotationUtils.getAnnotation(m, PostMapping.class) != null) {
+                return ""{POST}"";
+            } else if (AnnotationUtils.getAnnotation(m, PutMapping.class) != null) {
+                return ""{PUT}"";
+            } else if (AnnotationUtils.getAnnotation(m, DeleteMapping.class) != null) {
+                return ""{DELETE}"";
+            } else if (AnnotationUtils.getAnnotation(m, PatchMapping.class) != null) {
+                return ""{PATCH}"";
+            } else {
+                return """";","[{'comment': 'this return will cause the recursive parse to be ended， should be “return null”', 'commenter': 'whfjam'}, {'comment': '```suggestion\r\n                return null;\r\n```', 'commenter': 'BFergerson'}]"
5085,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/interceptor/RestMappingMethodInterceptor.java,"@@ -80,6 +80,20 @@ public String getRequestURL(Method method) {
 
     @Override
     public String getAcceptedMethodTypes(Method method) {
-        return """";
+        return ParsePathUtil.recursiveParseMethodAnnotation(method, m -> {
+            if (AnnotationUtils.getAnnotation(m, GetMapping.class) != null) {
+                return ""{GET}"";","[{'comment': 'consider about return RequestMethod.GET.toString(); and so on', 'commenter': 'whfjam'}]"
5085,apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/interceptor/RestMappingMethodInterceptor.java,"@@ -80,6 +80,20 @@ public String getRequestURL(Method method) {
 
     @Override
     public String getAcceptedMethodTypes(Method method) {
-        return """";
+        return ParsePathUtil.recursiveParseMethodAnnotation(method, m -> {
+            if (AnnotationUtils.getAnnotation(m, GetMapping.class) != null) {
+                return ""{GET}"";
+            } else if (AnnotationUtils.getAnnotation(m, PostMapping.class) != null) {
+                return ""{POST}"";
+            } else if (AnnotationUtils.getAnnotation(m, PutMapping.class) != null) {
+                return ""{PUT}"";
+            } else if (AnnotationUtils.getAnnotation(m, DeleteMapping.class) != null) {
+                return ""{DELETE}"";
+            } else if (AnnotationUtils.getAnnotation(m, PatchMapping.class) != null) {
+                return ""{PATCH}"";
+            } else {
+                return null;","[{'comment': 'I think for safe, this should return """", right?', 'commenter': 'wu-sheng'}, {'comment': 'I\'m sure it\'ll always end up being `""""` but returning `null` allows https://github.com/apache/skywalking/blob/b173cde5dbeeb1a15aa25954fe960dd480267f20/apm-sniffer/apm-sdk-plugin/spring-plugins/mvc-annotation-commons/src/main/java/org/apache/skywalking/apm/plugin/spring/mvc/commons/ParsePathUtil.java#L34 to execute.', 'commenter': 'BFergerson'}]"
5129,oap-server/server-bootstrap/src/main/resources/oal/java-agent.oal,"@@ -25,4 +25,7 @@ instance_jvm_memory_noheap_max = from(ServiceInstanceJVMMemory.max).filter(heapS
 instance_jvm_young_gc_time = from(ServiceInstanceJVMGC.time).filter(phrase == GCPhrase.NEW).sum();
 instance_jvm_old_gc_time = from(ServiceInstanceJVMGC.time).filter(phrase == GCPhrase.OLD).sum();
 instance_jvm_young_gc_count = from(ServiceInstanceJVMGC.count).filter(phrase == GCPhrase.NEW).sum();
-instance_jvm_old_gc_count = from(ServiceInstanceJVMGC.count).filter(phrase == GCPhrase.OLD).sum();
\ No newline at end of file
+instance_jvm_old_gc_count = from(ServiceInstanceJVMGC.count).filter(phrase == GCPhrase.OLD).sum();
+instance_jvm_thread_live_count = from(ServiceInstanceThreadGC.liveCount).sum();
+instance_jvm_thread_daemon_count = from(ServiceInstanceThreadGC.daemonCount).sum();
+instance_jvm_thread_peak_count = from(ServiceInstanceThreadGC.peakCount).sum();","[{'comment': 'Why do you `sum` the count? This value could be collected multiple times, then the thread number(sum value) would be very large.', 'commenter': 'wu-sheng'}, {'comment': 'Sorry, I was wrong here', 'commenter': 'stalary'}]"
5129,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/jvm/thread/ThreadProvider.java,"@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.jvm.thread;
+
+import java.lang.management.ManagementFactory;
+import java.lang.management.ThreadMXBean;
+import org.apache.skywalking.apm.network.language.agent.v3.Thread;
+
+public enum ThreadProvider {
+    INSTANCE;
+    private final ThreadMXBean threadMXBean;
+
+    ThreadProvider() {
+        this.threadMXBean = ManagementFactory.getThreadMXBean();
+    }
+
+    public Thread getThreadMetric() {","[{'comment': '`getThreadMetric` -> `getThreadMetrics`.', 'commenter': 'wu-sheng'}]"
5129,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/ServiceInstanceJVMThread.java,"@@ -0,0 +1,64 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.source;
+
+import lombok.Getter;
+import lombok.Setter;
+
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_CATALOG_NAME;
+import static org.apache.skywalking.oap.server.core.source.DefaultScopeDefine.SERVICE_INSTANCE_JVM_THREAD;
+
+@ScopeDeclaration(id = SERVICE_INSTANCE_JVM_THREAD, name = ""ServiceInstanceJVMThread"", catalog = SERVICE_INSTANCE_CATALOG_NAME)
+@ScopeDefaultColumn.VirtualColumnDefinition(fieldName = ""entityId"", columnName = ""entity_id"", isID = true, type = String.class)
+public class ServiceInstanceJVMThread extends Source {","[{'comment': 'As you added a new source, `scope-definitions.md` doc should be added.', 'commenter': 'wu-sheng'}]"
5129,oap-server/server-bootstrap/src/main/resources/oal/java-agent.oal,"@@ -26,6 +26,6 @@ instance_jvm_young_gc_time = from(ServiceInstanceJVMGC.time).filter(phrase == GC
 instance_jvm_old_gc_time = from(ServiceInstanceJVMGC.time).filter(phrase == GCPhrase.OLD).sum();
 instance_jvm_young_gc_count = from(ServiceInstanceJVMGC.count).filter(phrase == GCPhrase.NEW).sum();
 instance_jvm_old_gc_count = from(ServiceInstanceJVMGC.count).filter(phrase == GCPhrase.OLD).sum();
-instance_jvm_thread_live_count = from(ServiceInstanceThreadGC.liveCount).sum();
-instance_jvm_thread_daemon_count = from(ServiceInstanceThreadGC.daemonCount).sum();
-instance_jvm_thread_peak_count = from(ServiceInstanceThreadGC.peakCount).sum();
\ No newline at end of file
+instance_jvm_thread_live_count = from(ServiceInstanceThreadGC.liveCount);
+instance_jvm_thread_daemon_count = from(ServiceInstanceThreadGC.daemonCount);
+instance_jvm_thread_peak_count = from(ServiceInstanceThreadGC.peakCount);","[{'comment': 'No function? It is strange.', 'commenter': 'wu-sheng'}, {'comment': 'longAvg() looks suitable', 'commenter': 'stalary'}]"
5129,oap-server/server-bootstrap/src/main/resources/ui-initialized-templates.yml,"@@ -359,6 +359,17 @@ templates:
                   ""chartType"": ""ChartBar"",
                   ""metricName"": ""instance_jvm_young_gc_count, instance_jvm_old_gc_count""
                 },
+                {
+                  ""width"": 3,
+                  ""title"": ""JVM Thread Count (Java Service)"",
+                  ""height"": ""250"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartBar"",","[{'comment': '```suggestion\r\n                  ""chartType"": ""ChartLine"",\r\n```', 'commenter': 'arugal'}, {'comment': '### screenshots\r\n![image](https://user-images.githubusercontent.com/26432832/88074656-47efd400-cbaa-11ea-8a13-a08e01f33fce.png)\r\n', 'commenter': 'arugal'}]"
5139,docker/docker-compose.yml,"@@ -42,6 +42,14 @@ services:
     environment:
       SW_STORAGE: elasticsearch
       SW_STORAGE_ES_CLUSTER_NODES: elasticsearch:9200
+      SW_HEALTH_CHECKER: default
+      SW_TELEMETRY: prometheus
+    healthcheck:
+      test: [""CMD"", ""./bin/swctl"", ""ch""]","[{'comment': ""I didn't found this command doc on the CLI repo. Seems we missed it. Please update the doc. @hanahmily "", 'commenter': 'wu-sheng'}]"
5160,oap-server/server-core/src/test/resources/component-libraries.yml,"@@ -173,8 +176,26 @@ Elasticsearch:
 transport-client:
   id: 48
   languages: Java
-Undertow:
+http:
   id: 49
+  languages: Java,C#,Node.js","[{'comment': 'Why change this file?', 'commenter': 'wu-sheng'}, {'comment': 'This file is sync from oap-server/server-bootstrap/src/main/resources/component-libraries.yml. Maybe this pr should not make too many changes to the file?', 'commenter': 'LiWenGu'}, {'comment': '> Why change this file?\r\n\r\nDo I need to reset this file(just change what I need to change)?', 'commenter': 'LiWenGu'}, {'comment': 'This is just a UT related file. You just need to change the one in the src/main/resources folder.', 'commenter': 'wu-sheng'}]"
5293,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/PluginSelector.java,"@@ -0,0 +1,38 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.plugin;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.EXCLUDE_PLUGINS;
+
+public class PluginSelector {
+
+    public List<PluginDefine> select(List<PluginDefine> pluginDefines) {
+        if (!EXCLUDE_PLUGINS.isEmpty()) {
+            List<String> includes = Arrays.asList(EXCLUDE_PLUGINS.toLowerCase().split("",""));","[{'comment': 'You forgot to update the name `includes`, should be `excludes`', 'commenter': 'kezhenxu94'}, {'comment': 'fix', 'commenter': 'EvanLjp'}]"
5293,apm-sniffer/config/agent.config,"@@ -90,3 +90,6 @@ logging.level=${SW_LOGGING_LEVEL:INFO}
 
 # Kafka producer configuration
 plugin.kafka.bootstrap_servers=${SW_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
+
+# elclude some plugins which define in plugins dir,
+plugin.exclude_plugins=${SW_EXCLUDE_PLUGINS:""""}","[{'comment': 'This config item should go to [the doc](https://github.com/apache/skywalking/tree/master/docs/en/setup/service-agent/java-agent#table-of-agent-configuration-properties) as well', 'commenter': 'kezhenxu94'}, {'comment': 'add doc', 'commenter': 'EvanLjp'}]"
5293,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -266,6 +266,11 @@
          * Control the length of the peer field.
          */
         public static int PEER_MAX_LENGTH = 200;
+
+        /**
+         * Excludes some plugins which define in plugins dir","[{'comment': '```suggestion\r\n         * Exclude activated plugins\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'fix', 'commenter': 'EvanLjp'}]"
5293,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/PluginSelector.java,"@@ -0,0 +1,38 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.plugin;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import static org.apache.skywalking.apm.agent.core.conf.Config.Plugin.EXCLUDE_PLUGINS;
+
+public class PluginSelector {","[{'comment': 'Comments required.', 'commenter': 'wu-sheng'}, {'comment': 'fix', 'commenter': 'EvanLjp'}]"
5293,apm-sniffer/config/agent.config,"@@ -90,3 +90,6 @@ logging.level=${SW_LOGGING_LEVEL:INFO}
 
 # Kafka producer configuration
 plugin.kafka.bootstrap_servers=${SW_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
+
+# exclude some plugins define in plugins dir
+plugin.exclude_plugins=${SW_EXCLUDE_PLUGINS:""""}","[{'comment': ""Don't open this in default."", 'commenter': 'wu-sheng'}, {'comment': 'fix', 'commenter': 'EvanLjp'}]"
5293,docs/en/setup/service-agent/java-agent/Plugin-list.md,"@@ -0,0 +1,101 @@
+- Skywalking Agent List
+    - activemq-5.x
+    - armeria-063-084
+    - armeria-085
+    - armeria-086
+    - armeria-098
+    - avro-1.x
+    - brpc-java
+    - canal-1.x
+    - cassandra-java-driver-3.x
+    - dubbo
+    - ehcache-2.x
+    - elastic-job-2.x
+    - elastic-job-3.x
+    - elasticsearch-5.x
+    - elasticsearch-6.x
+    - feign-default-http-9.x
+    - feign-pathvar-9.x
+    - finagle
+    - graphql
+    - grpc-1.x
+    - gson-2.8.x
+    - h2-1.x
+    - hbase-1.x
+    - httpasyncclient-4.x
+    - httpclient-3.x
+    - httpclient-4.x
+    - hystrix-1.x
+    - influxdb-2.x
+    - jdk-http-plugin
+    - jdk-threading-plugin
+    - jedis-2.x
+    - jetty-client-9.0
+    - jetty-client-9.x
+    - jetty-server-9.x
+    - kafka-0.11.x/1.x/2.x
+    - kotlin-coroutine
+    - lettuce-5.x
+    - light4j
+    - mariadb-2.x
+    - memcache-2.x
+    - mongodb-2.x
+    - mongodb-3.x
+    - motan-0.x
+    - mysql-5.x
+    - mysql-6.x
+    - mysql-8.x
+    - netty-socketio
+    - nutz-http-1.x
+    - nutz-mvc-annotation-1.x
+    - okhttp-3.x
+    - play-2.x
+    - postgresql-8.x
+    - pulsar
+    - quasar
+    - rabbitmq-5.x
+    - redisson-3.x
+    - resteasy-server-3.x
+    - rocketMQ-3.x
+    - rocketMQ-4.x
+    - servicecomb-0.x
+    - servicecomb-1.x
+    - sharding-jdbc-1.5.x
+    - sharding-sphere-3.x
+    - sharding-sphere-4.0.0
+    - sharding-sphere-4.1.0
+    - sharding-sphere-4.x
+    - sharding-sphere-4.x-rc3
+    - sofarpc
+    - solrj-7.x
+    - spring-annotation
+    - spring-async-annotation-5.x
+    - spring-cloud-feign-1.x
+    - spring-cloud-feign-2.x
+    - spring-cloud-gateway-2.0.x
+    - spring-cloud-gateway-2.1.x
+    - spring-concurrent-util-4.x
+    - spring-core-patch
+    - spring-kafka-2.x
+    - spring-mvc-annotation
+    - spring-mvc-annotation-3.x
+    - spring-mvc-annotation-4.x
+    - spring-mvc-annotation-5.x
+    - spring-resttemplate-4.x
+    - spring-tx
+    - spring-webflux-5.x
+    - spymemcached-2.x
+    - struts2-2.x
+    - tomcat-7.x/8.x
+    - toolkit-counter
+    - toolkit-gauge
+    - toolkit-histogram
+    - toolkit-log4j
+    - toolkit-log4j2
+    - toolkit-logback
+    - toolkit-opentracing
+    - toolkit-tag
+    - toolkit-trace
+    - undertow-2.x-plugin
+    - vertx-core-3.x
+    - zookeeper-3.4.x   ","[{'comment': '@kezhenxu94 Do you have any change to use some mechanisms to check this? Such as building a mock agent core main?', 'commenter': 'wu-sheng'}, {'comment': 'possible', 'commenter': 'kezhenxu94'}, {'comment': 'the list is got from my shell tools, already push', 'commenter': 'EvanLjp'}]"
5293,apm-sniffer/config/agent.config,"@@ -90,3 +90,6 @@ logging.level=${SW_LOGGING_LEVEL:INFO}
 
 # Kafka producer configuration
 plugin.kafka.bootstrap_servers=${SW_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
+
+# exclude some plugins define in plugins dir","[{'comment': '```suggestion\r\n# Exclude activated plugins\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'fix', 'commenter': 'EvanLjp'}]"
5293,tools/plugin/scan-agent-plugins.sh,"@@ -0,0 +1,39 @@
+#!/usr/bin/env bash","[{'comment': '@kezhenxu94 Please review this script.\r\n\r\n@EvanLjp Tool script should be used in the CI process. Like the license check script. Check the result with the markdown document, make sure the new contributors have updated the doc.', 'commenter': 'wu-sheng'}, {'comment': 'LGTM except for the code style', 'commenter': 'dmsolr'}, {'comment': ""> @kezhenxu94 Please review this script.\r\n> \r\n> \r\n> \r\n> @EvanLjp Tool script should be used in the CI process. Like the license check script. Check the result with the markdown document, make sure the new contributors have updated the doc.\r\n\r\nRefer to the [check-LICENSE.sh](https://github.com/apache/skywalking/blob/master/tools/dependencies/check-LICENSE.sh) script, your scrip is expected to be rewrote to check actual plugin list and the md doc, instead of simply generating a list, of course you can print the diff so that one knows what's wrong when running your script, another tip is to put this check at the very beginning of the CI stages, because it's more lightweight and doesn't depends on the final tar (while check-LICENSE.sh does)"", 'commenter': 'kezhenxu94'}, {'comment': 'push again, the script looks like check-LICENSE.sh', 'commenter': 'EvanLjp'}]"
5293,apm-sniffer/config/agent.config,"@@ -90,3 +90,5 @@ logging.level=${SW_LOGGING_LEVEL:INFO}
 
 # Kafka producer configuration
 # plugin.kafka.bootstrap_servers=${SW_KAFKA_BOOTSTRAP_SERVERS:localhost:9092}
+#  Exclude activated plugins
+#plugin.exclude_plugins=${SW_EXCLUDE_PLUGINS:""""}","[{'comment': 'Need to pay attention on the details.\r\n```suggestion\r\n# Exclude activated plugins\r\n# plugin.exclude_plugins=${SW_EXCLUDE_PLUGINS:""""}\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'thx', 'commenter': 'EvanLjp'}]"
5293,tools/plugin/check-javaagent-plugin-list.sh,"@@ -0,0 +1,51 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+SRC_DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" && pwd)""
+WORK_DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" &&cd ../.. && pwd)""
+GENERNATE_PLUGINS_LIST=${SRC_DIR}/genernate-javaagent-plugin-list.txt
+MD_PLUGINS_LIST=${SRC_DIR}/md-javaagent-plugin-list.txt
+
+function genernateJavaagentPluginList() {
+    position_file=""javaagent-position.txt""
+    find ${WORK_DIR}/apm-sniffer -name ""skywalking-plugin.def""|grep ""src/main/resources"" > ${position_file}
+    cat ${position_file} | while read line
+    do
+        cat ${line}|grep -v ""#""|grep -v ""^$""|awk -F ""="" '{print $1}' >> temp.txt
+    done
+    cat temp.txt|sort|uniq|awk NF  > ${GENERNATE_PLUGINS_LIST}
+    rm -rf temp.txt
+}
+
+function getMdJavaagentPluginList() {
+    md_javaagent_plugins_file=${WORK_DIR}/docs/en/setup/service-agent/java-agent/Plugin-list.md
+    cat  ${md_javaagent_plugins_file}|grep -v ""#"" |awk -F "" "" '{ print $2}'|sort >${MD_PLUGINS_LIST}
+}
+
+function checkDiff() {
+    diff -w -bB -U0 ${MD_PLUGINS_LIST} ${GENERNATE_PLUGINS_LIST}","[{'comment': 'should pass this exit code to the end of the script, the CI status depends on the final exit code, `0 == success, otherwise == failure`', 'commenter': 'kezhenxu94'}, {'comment': 'yes,already fix,try again', 'commenter': 'EvanLjp'}]"
5293,.github/workflows/ci-it.yaml,"@@ -45,6 +45,8 @@ jobs:
           bash <(curl -s https://codecov.io/bash)
       - name: 'Check Dependencies Licenses'
         run: tools/dependencies/check-LICENSE.sh
+      - name: 'Check Javaagent Plugin List'
+        run: tools/plugin/check-javaagent-plugin-list.sh","[{'comment': 'I suggest to move this to the beginning of the the steps (line 42) because this script is more lightweight that can fail quickly, and thus prevents unnecessary `Install & Test`, `Install & Test` is much more expensive', 'commenter': 'kezhenxu94'}, {'comment': 'Make sense, it could fail fast.', 'commenter': 'wu-sheng'}]"
5293,tools/plugin/check-javaagent-plugin-list.sh,"@@ -41,10 +41,5 @@ function getMdJavaagentPluginList() {
 genernateJavaagentPluginList
 getMdJavaagentPluginList
 diff -w -bB -U0 ${MD_PLUGINS_LIST} ${GENERNATE_PLUGINS_LIST}
-status=$?
-echo ${status}
-rm -rf  ${MD_PLUGINS_LIST}
-rm -rf ${GENERNATE_PLUGINS_LIST}
-[[ ${status} -ne 0 ]] && exit ${status}","[{'comment': 'What are you testing? I think we need the `exit code` to fail the CI process.', 'commenter': 'wu-sheng'}]"
5293,tools/plugin/check-javaagent-plugin-list.sh,"@@ -0,0 +1,45 @@
+#!/usr/bin/env bash
+
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#    http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+SRC_DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" && pwd)""
+WORK_DIR=""$(cd ""$(dirname ""${BASH_SOURCE[0]}"")"" &&cd ../.. && pwd)""
+GENERNATE_PLUGINS_LIST=${SRC_DIR}/genernate-javaagent-plugin-list.txt
+MD_PLUGINS_LIST=${SRC_DIR}/md-javaagent-plugin-list.txt
+
+function genernateJavaagentPluginList() {
+    position_file=""javaagent-position.txt""
+    find ${WORK_DIR}/apm-sniffer -name ""skywalking-plugin.def""|grep ""src/main/resources"" > ${position_file}
+    cat ${position_file} | while read line
+    do
+        cat ${line}|grep -v ""#""|awk -F ""="" '{print $1}' >> temp.txt
+    done
+    cat temp.txt|sort|uniq|awk NF|grep -E '^[a-z].*'  > ${GENERNATE_PLUGINS_LIST}
+    rm -rf temp.txt
+}
+
+function getMdJavaagentPluginList() {
+    md_javaagent_plugins_file=${WORK_DIR}/docs/en/setup/service-agent/java-agent/Plugin-list.md
+    cat  ${md_javaagent_plugins_file}|grep -v ""#"" |awk -F "" "" '{ print $2}'|grep -E '^[a-z].*'|sort|uniq|awk NF >${MD_PLUGINS_LIST}
+}
+
+genernateJavaagentPluginList
+getMdJavaagentPluginList
+diff -w -bB -U0 ${MD_PLUGINS_LIST} ${GENERNATE_PLUGINS_LIST}","[{'comment': 'We need the thing you deleted.', 'commenter': 'wu-sheng'}, {'comment': ""The exit code of the last line of script will serve as the final exit code of the entire script, it's ok here"", 'commenter': 'kezhenxu94'}]"
5339,.github/workflows/plugins-test.3.yaml,"@@ -55,6 +55,7 @@ jobs:
           - { name: 'hbase-scenario', title: 'hbase-scenario (5)' }
           - { name: 'spring-kafka-2.2.x-scenario', title: 'Spring-Kafka 2.2.x (7)' }
           - { name: 'spring-kafka-2.3.x-scenario', title: 'Spring-Kafka 2.3.x (7)' }
+          - { name: 'spring-scheduled-scenario', title: 'Spring Scheduled 3.1.x-5.2.x (119)' }","[{'comment': ""Don't use all 119 versions, it costs too many CI resources and time. Just choose the typical ones, such as choose the latest version in 5.0.x to represent all versions."", 'commenter': 'wu-sheng'}]"
5339,test/plugin/scenarios/spring-scheduled-scenario/config/expectedData.yaml,"@@ -0,0 +1,48 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+segmentItems:
+  - serviceName: spring-scheduled-scenario
+    segmentSize: ge 2
+    segments:","[{'comment': 'From my reading of your test case codes, there should be a segment starting with `SchedulingJob#work`, where it is? Or do I miss anything?', 'commenter': 'wu-sheng'}, {'comment': ""Yes, it's on [line 37](https://github.com/apache/skywalking/pull/5339/files/7f6bba6a27a0ba0ccb41c639f0002e5276b7de3a#diff-f1c217f8303ef2da8c91cd14aaa67300R37)."", 'commenter': 'hailin0'}, {'comment': 'You missed the segment from the peer. There should be entry span representing the server side of this exit span.\r\n\r\nI know it is not the thing you added, but it should work, and the segment is expected.', 'commenter': 'wu-sheng'}]"
5339,apm-sniffer/apm-sdk-plugin/spring-plugins/scheduled-annotation-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/scheduled/ScheduledMethodInterceptor.java,"@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.spring.scheduled;
+
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class ScheduledMethodInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+
+    private static final String DEFAULT_OPERATION_NAME = ""SpringScheduled"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        String targetMethodName = (String) objInst.getSkyWalkingDynamicField();
+        String operationName = targetMethodName != null ? targetMethodName : DEFAULT_OPERATION_NAME;
+
+        AbstractSpan span = ContextManager.createEntrySpan(operationName, new ContextCarrier());","[{'comment': 'This is just a local scheduler task, not an entry. Please read the plugin dev document. This should be a local span. Could you share why you put this as Entry Span?', 'commenter': 'wu-sheng'}, {'comment': 'Thank you, I will read the plugin dev document.\r\nI referenced [elasticjob plugin](https://github.com/apache/skywalking/blob/master/apm-sniffer/apm-sdk-plugin/elastic-job-3.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/elasticjob/ElasticJobExecutorInterceptor.java#L39)\r\n', 'commenter': 'hailin0'}, {'comment': 'If it is an entry, then it is a bug. Could you confirm? If yes. please send a pull request to fix.\r\n\r\nAnd if you want to analysis the performance of the job, consider to use logic endpoint tag, which is also included in the dev doc, too.', 'commenter': 'wu-sheng'}, {'comment': '@zhaoyuguang Please recheck the ElasticJob plugin too.', 'commenter': 'wu-sheng'}, {'comment': ""> @zhaoyuguang Please recheck the ElasticJob plugin too.\r\n\r\nWell, I'm using it the wrong way"", 'commenter': 'zhaoyuguang'}]"
5339,apm-sniffer/apm-sdk-plugin/spring-plugins/scheduled-annotation-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/scheduled/ScheduledMethodInterceptor.java,"@@ -0,0 +1,81 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.spring.scheduled;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class ScheduledMethodInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+
+    private static final String DEFAULT_OPERATION_NAME = ""SpringScheduled"";
+    private static final String DEFAULT_LOGIC_ENDPOINT_CONTENT = ""{\""logic-span\"":true}"";","[{'comment': 'Could you move this into `Tags` as more plugins are going to use this? And name this as `VAL_LOCAL_SPAN_AS_LOGIC_ENDPOINT`·', 'commenter': 'wu-sheng'}, {'comment': 'Add logic endpoint into others plugin？I could try', 'commenter': 'hailin0'}, {'comment': 'Move this value constant into the Tags(core class), and do a little refactor to GraphQL plugin, by sharing this new constant', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'hailin0'}, {'comment': 'This has been done in #5347', 'commenter': 'wu-sheng'}, {'comment': 'I will merge that soon, please update the codes after that.', 'commenter': 'wu-sheng'}]"
5339,apm-sniffer/apm-sdk-plugin/spring-plugins/scheduled-annotation-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/scheduled/ScheduledMethodInterceptor.java,"@@ -0,0 +1,81 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.spring.scheduled;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceConstructorInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class ScheduledMethodInterceptor implements InstanceMethodsAroundInterceptor, InstanceConstructorInterceptor {
+
+    private static final String DEFAULT_OPERATION_NAME = ""SpringScheduled"";
+    private static final String DEFAULT_LOGIC_ENDPOINT_CONTENT = ""{\""logic-span\"":true}"";
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        String targetMethodName = (String) objInst.getSkyWalkingDynamicField();
+        String operationName = targetMethodName != null ? targetMethodName : DEFAULT_OPERATION_NAME;
+
+        AbstractSpan span = ContextManager.createLocalSpan(operationName);
+        Tags.LOGIC_ENDPOINT.set(span, DEFAULT_LOGIC_ENDPOINT_CONTENT);
+        span.setComponent(ComponentsDefine.SPRING_SCHEDULED);
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);
+    }
+
+    @Override
+    public void onConstruct(EnhancedInstance objInst, Object[] allArguments) throws Throwable {
+        Object targetMethod = allArguments[1];
+        String targetMethodName = getTargetMethodName(targetMethod);
+
+        objInst.setSkyWalkingDynamicField(targetMethodName);
+    }
+
+    private String getTargetMethodName(Object targetMethod) {
+        if (targetMethod instanceof String) {","[{'comment': '`Instanceof` is not recommended in the interceptor. Usually, we set up two instrumentation for constructures with different parameters(if necessary)', 'commenter': 'wu-sheng'}]"
5339,test/plugin/scenarios/spring-scheduled-scenario/src/main/java/org/apache/skywalking/apm/testcase/spring/scheduled/job/SchedulingJob.java,"@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.spring.scheduled.job;
+
+import okhttp3.OkHttpClient;
+import okhttp3.Request;
+import okhttp3.Response;
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.springframework.scheduling.annotation.EnableScheduling;
+import org.springframework.scheduling.annotation.Scheduled;
+import org.springframework.stereotype.Component;
+
+import java.io.IOException;
+
+@Component
+@EnableScheduling
+public class SchedulingJob {
+
+    private static final Logger logger = LogManager.getLogger(SchedulingJob.class);
+    
+    private static final OkHttpClient client = new OkHttpClient.Builder().build();
+
+    @Scheduled(fixedDelay = 5000)","[{'comment': ""@hailin0, I think I got @zhaoyuguang 's point as he DM me.\r\n\r\nThis bean has `@Component` already, so, why this method wouldn't work? I think Spring annotation plugin tracing all methods of the bean. Unless you only want to activate this, rather than other beans?"", 'commenter': 'wu-sheng'}, {'comment': 'I found some bugs...  @wu-sheng \r\n\r\nExpected to be normal when I use @Configuration\r\n-------------------\r\n\r\n![9CFE35D62F59B825122F05C9D3555F27](https://user-images.githubusercontent.com/14371345/90636027-9a311d00-e25c-11ea-9e4f-1261fe2d2240.png)\r\n![A37D3CE0897B9D84C08F71E841E6AF46](https://user-images.githubusercontent.com/14371345/90636076-aa48fc80-e25c-11ea-8f26-4a16c7a121d7.png)\r\n\r\n\r\nDuplicate tracing occurs when I use @Component\r\n-------------------\r\n![0C5D9D790774A98490A8E3513A7EFCE8](https://user-images.githubusercontent.com/14371345/90636208-dc5a5e80-e25c-11ea-8b73-95368df28454.png)\r\n![1A2F323E9BFF2FC94BD11ACCD690C27B](https://user-images.githubusercontent.com/14371345/90636226-e2e8d600-e25c-11ea-8772-0eb0c05399f8.png)\r\n\r\n', 'commenter': 'hailin0'}, {'comment': 'Maybe the @Scheduled method should be filtered out in spring-annotation-plugi.\r\n\r\n1. @Scheduled is not an optional plugin\r\n2. spring-scheduler can be started through [xml configuration files](https://github.com/spring-projects/spring-framework/blob/master/spring-context/src/main/java/org/springframework/scheduling/config/ScheduledTasksBeanDefinitionParser.java#L103) instead of just annotations\r\n\r\n```xml\r\n<bean id=""myJob"" class=""org.example.Job"" />\r\n\r\n<task:scheduled-tasks scheduler=""myScheduler"">  \r\n    <task:scheduled ref=""myJob"" method=""work1"" cron=""0 0/10 * * * ?""/>  \r\n</task:scheduled-tasks>  \r\n<task:scheduler id=""myScheduler"" pool-size=""1""/>\r\n```\r\n\r\nHow do you think about it ?\r\n', 'commenter': 'hailin0'}, {'comment': ""The first one is easy to explain, we don't watch the configuration. The second one is not clear, why `Duplicate tracing occurs when I use @component`? Who will trace twice?"", 'commenter': 'wu-sheng'}, {'comment': 'Does this duplicated tracing cause by this new plugin with `@component`?', 'commenter': 'wu-sheng'}, {'comment': 'Note, I know this plugin should be useful at some points, but I need to make it clear.', 'commenter': 'wu-sheng'}, {'comment': ""> The first one is easy to explain, we don't watch the configuration. The second one is not clear, why `Duplicate tracing occurs when I use @component`? Who will trace twice?\r\n\r\nspring-scheduled-annotation-plugin trace once\r\nthen spring-annotation-plugin(optional-plugin) trace it again"", 'commenter': 'hailin0'}, {'comment': ""OK, seems byte-buddy added some features. FYI @apache/skywalking-committers. It used to can't instrument a class twice, but this test proved it is not the case today."", 'commenter': 'wu-sheng'}, {'comment': 'According to the official doc, https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/Configuration.html\r\n\r\n`@Configuration` should only be used for `@Bean`. Is there abuse? I am not working on Spring for a long time, could you explain more about the use case.', 'commenter': 'wu-sheng'}, {'comment': '> According to the official doc, https://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/context/annotation/Configuration.html\r\n> \r\n> `@Configuration` should only be used for `@Bean`. Is there abuse? I am not working on Spring for a long time, could you explain more about the use case.\r\n\r\nThe document describes ` @Configuration` and `@Scheduled` can be used together\r\n\r\nhttps://docs.spring.io/spring-framework/docs/current/javadoc-api/org/springframework/scheduling/annotation/EnableScheduling.html', 'commenter': 'hailin0'}, {'comment': '>  @configuration and @scheduled can be used together\r\n\r\nYes, but with `component` is the right usage?', 'commenter': 'wu-sheng'}, {'comment': '> > @configuration and @scheduled can be used together\r\n> \r\n> Yes, but with `component` is the right usage?\r\n\r\nThe document indicates that `@Component` and `@Scheduled` can also be used together', 'commenter': 'hailin0'}, {'comment': '> > > @configuration and @scheduled can be used together\r\n> > \r\n> > \r\n> > Yes, but with `component` is the right usage?\r\n> \r\n> The document indicates that `@Component` and `@Scheduled` can also be used together\r\n\r\nDuplicate tracing occurs when `@Component` and `@Scheduled` are used together', 'commenter': 'hailin0'}, {'comment': 'This is a tricky point, I think maybe you should consider put this plugin as optional too. And add a FAQ doc to describe these cases, and provide recommended solutions.', 'commenter': 'wu-sheng'}]"
5376,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/grpc/ssl/DynamicSslContext.java,"@@ -0,0 +1,134 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.library.server.grpc.ssl;
+
+import io.grpc.netty.GrpcSslContexts;
+import io.netty.buffer.ByteBufAllocator;
+import io.netty.handler.ssl.ApplicationProtocolNegotiator;
+import io.netty.handler.ssl.SslContext;
+import io.netty.handler.ssl.SslContextBuilder;
+import io.netty.handler.ssl.SslProvider;
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.nio.file.Paths;
+import java.security.GeneralSecurityException;
+import java.util.List;
+import javax.net.ssl.SSLEngine;
+import javax.net.ssl.SSLException;
+import javax.net.ssl.SSLSessionContext;
+import org.apache.skywalking.oap.server.library.util.MultipleFilesChangeMonitor;
+
+/**
+ * Load SslContext dynamically.
+ */
+public class DynamicSslContext extends SslContext {
+    private final MultipleFilesChangeMonitor monitor;
+    private volatile SslContext ctx;
+
+    public static DynamicSslContext forServer(final String privateKeyFile, final String certChainFile) {
+        return new DynamicSslContext(privateKeyFile, certChainFile);
+    }
+
+    public static DynamicSslContext forClient(final String caFile) {
+        return new DynamicSslContext(caFile);
+    }
+
+    private DynamicSslContext(final String privateKeyFile, final String certChainFile) {
+        updateContext(privateKeyFile, certChainFile);
+        monitor = new MultipleFilesChangeMonitor(
+            10,
+            readableContents -> updateContext(privateKeyFile, certChainFile),
+            certChainFile,
+            privateKeyFile);
+    }
+
+    private DynamicSslContext(final String caFile) {
+        updateContext(caFile);
+        monitor = new MultipleFilesChangeMonitor(
+            10,
+            readableContents -> updateContext(caFile),
+            caFile);
+    }
+
+    private void updateContext(String caFile) {
+        try {
+            GrpcSslContexts.forClient().trustManager(Paths.get(caFile).toFile()).build();","[{'comment': ""The returned value is just ignored? If that's intentionally, do we need a null check in the following uses of `ctx`?"", 'commenter': 'kezhenxu94'}, {'comment': 'I think this is a lambda based on `MultipleFilesChangeMonitor#FilesChangedNotifier#filesChanged`. It is triggered by the file change monitor, I think there is nothing you could do.', 'commenter': 'wu-sheng'}, {'comment': ""> I think this is a lambda based on `MultipleFilesChangeMonitor#FilesChangedNotifier#filesChanged`. It is triggered by the file change monitor, I think there is nothing you could do.\n\nThat's not what I meant, compare it with the other overloaded method `updateContext`"", 'commenter': 'kezhenxu94'}, {'comment': 'Got it, you mean this\r\n\r\n```suggestion\r\n            ctx = GrpcSslContexts.forClient().trustManager(Paths.get(caFile).toFile()).build();\r\n```\r\n\r\n@hanahmily Please take a look.', 'commenter': 'wu-sheng'}]"
5425,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/function/AvgHistogramFunction.java,"@@ -83,33 +84,39 @@ public void accept(final MeterEntity entity, final BucketedValues value) {
 
         this.entityId = entity.id();
 
+        String template = ""%s"";
+        if (!Strings.isNullOrEmpty(value.getGroup())) {
+            template   = value.getGroup() + "":%s"";
+        }
         final long[] values = value.getValues();
         for (int i = 0; i < values.length; i++) {
-            String bucketName = String.valueOf(value.getBuckets()[i]);
-            summation.valueAccumulation(bucketName, values[i]);
-            count.valueAccumulation(bucketName, 1L);
+            long bucket = value.getBuckets()[i];
+            String bucketName = bucket == Long.MIN_VALUE ? Bucket.INFINITE_NEGATIVE : String.valueOf(bucket);
+            String key = String.format(template, bucketName);
+            summation.valueAccumulation(key, values[i]);
+            count.valueAccumulation(key, 1L);
         }
     }
 
     @Override
     public void combine(final Metrics metrics) {
         AvgHistogramFunction histogram = (AvgHistogramFunction) metrics;
-
-        if (!summation.keysEqual(histogram.getSummation())) {","[{'comment': 'Do you remove this for accepting different labels in 2 instances?', 'commenter': 'wu-sheng'}, {'comment': 'exactly. ', 'commenter': 'hanahmily'}]"
5425,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/function/AvgHistogramFunction.java,"@@ -83,33 +84,39 @@ public void accept(final MeterEntity entity, final BucketedValues value) {
 
         this.entityId = entity.id();
 
+        String template = ""%s"";
+        if (!Strings.isNullOrEmpty(value.getGroup())) {
+            template   = value.getGroup() + "":%s"";
+        }
         final long[] values = value.getValues();
         for (int i = 0; i < values.length; i++) {
-            String bucketName = String.valueOf(value.getBuckets()[i]);
-            summation.valueAccumulation(bucketName, values[i]);
-            count.valueAccumulation(bucketName, 1L);
+            long bucket = value.getBuckets()[i];
+            String bucketName = bucket == Long.MIN_VALUE ? Bucket.INFINITE_NEGATIVE : String.valueOf(bucket);
+            String key = String.format(template, bucketName);
+            summation.valueAccumulation(key, values[i]);
+            count.valueAccumulation(key, 1L);
         }
     }
 
     @Override
     public void combine(final Metrics metrics) {
         AvgHistogramFunction histogram = (AvgHistogramFunction) metrics;
-
-        if (!summation.keysEqual(histogram.getSummation())) {
-            log.warn(""Incompatible input [{}}] for current HistogramFunction[{}], entity {}"",
-                     histogram, this, entityId
-            );
-            return;
-        }
         this.summation.append(histogram.summation);
         this.count.append(histogram.count);
     }
 
     @Override
     public void calculate() {
-        final List<String> sortedKeys = summation.sortedKeys(Comparator.comparingInt(Integer::parseInt));
-        for (String key : sortedKeys) {
-            dataset.put(key, summation.get(key) / count.get(key));
+        final Set<String> keys = summation.keys();
+        for (String key : keys) {","[{'comment': '```suggestion\r\n        for (String key : summation.keys()) {\r\n```', 'commenter': 'wu-sheng'}]"
5425,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/function/AvgHistogramFunction.java,"@@ -157,6 +165,7 @@ public void deserialize(final RemoteData remoteData) {
 
         remoteBuilder.addDataObjectStrings(count.toStorageData());
         remoteBuilder.addDataObjectStrings(summation.toStorageData());
+        remoteBuilder.addDataObjectStrings(dataset.toStorageData());","[{'comment': 'Did you forget to serialize this field?', 'commenter': 'wu-sheng'}, {'comment': ""yep. With the unit test's help, I found this issue."", 'commenter': 'hanahmily'}]"
5425,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/function/AvgHistogramPercentileFunction.java,"@@ -125,11 +135,17 @@ public void accept(final MeterEntity entity, final AvgPercentileArgument value)
 
         this.entityId = entity.id();
 
+        String template = ""%s"";
+        if (!Strings.isNullOrEmpty(value.getBucketedValues().getGroup())) {
+            template   = value.getBucketedValues().getGroup() + "":%s"";","[{'comment': '```suggestion\r\n            template  = value.getBucketedValues().getGroup() + "":%s"";\r\n```', 'commenter': 'wu-sheng'}]"
5425,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/function/AvgHistogramPercentileFunction.java,"@@ -125,11 +135,17 @@ public void accept(final MeterEntity entity, final AvgPercentileArgument value)
 
         this.entityId = entity.id();
 
+        String template = ""%s"";
+        if (!Strings.isNullOrEmpty(value.getBucketedValues().getGroup())) {
+            template   = value.getBucketedValues().getGroup() + "":%s"";
+        }
         final long[] values = value.getBucketedValues().getValues();
         for (int i = 0; i < values.length; i++) {
-            String bucketName = String.valueOf(value.getBucketedValues().getBuckets()[i]);
-            summation.valueAccumulation(bucketName, values[i]);
-            count.valueAccumulation(bucketName, 1L);
+            long bucket = value.getBucketedValues().getBuckets()[i];
+            String bucketName = bucket == Long.MIN_VALUE ? Bucket.INFINITE_NEGATIVE : String.valueOf(bucket);
+            String key = String.format(template, bucketName);
+            summation.valueAccumulation(key, values[i]);","[{'comment': 'Could you add comments about how you format this key?', 'commenter': 'wu-sheng'}, {'comment': ""It's `<group>:<percentile>` which is composed of some lines above."", 'commenter': 'hanahmily'}]"
5425,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/function/AvgHistogramPercentileFunction.java,"@@ -168,38 +178,64 @@ public void combine(final Metrics metrics) {
     @Override
     public void calculate() {
         if (!isCalculated) {
-            final List<String> sortedKeys = summation.sortedKeys(Comparator.comparingInt(Integer::parseInt));
-            for (String key : sortedKeys) {
-                dataset.put(key, summation.get(key) / count.get(key));
-            }
-
-            long total = dataset.sumOfValues();
-
-            int[] roofs = new int[ranks.size()];
-            for (int i = 0; i < ranks.size(); i++) {
-                roofs[i] = Math.round(total * ranks.get(i) * 1.0f / 100);
-            }
-
-            int count = 0;
-            int loopIndex = 0;
-
-            for (int i = 0; i < sortedKeys.size(); i++) {
-                String key = sortedKeys.get(i);
-                final Long value = dataset.get(key);
-
-                count += value;
-                for (int rankIdx = loopIndex; rankIdx < roofs.length; rankIdx++) {
-                    int roof = roofs[rankIdx];
-
-                    if (count >= roof) {
-                        long latency = (i + 1 == sortedKeys.size()) ? Long.MAX_VALUE : Long.parseLong(sortedKeys.get(i + 1));
-                        percentileValues.put(String.valueOf(ranks.get(rankIdx)), latency);
-                        loopIndex++;
-                    } else {
-                        break;
+            final Set<String> keys = summation.keys();
+            for (String key : keys) {
+                long value = 0;
+                if (count.get(key) != 0) {
+                    value = summation.get(key) / count.get(key);
+                    if (value == 0L && summation.get(key) > 0L) {
+                        value = 1;
                     }
                 }
+                dataset.put(key, value);
             }
+            dataset.keys().stream()
+                .map(key -> {
+                    if (key.contains("":"")) {
+                        String[] kk = key.split("":"");
+                        return Tuple.of(kk[0], key);
+                    } else {
+                        return Tuple.of(DEFAULT_GROUP, key);
+                    }
+                })
+                .collect(groupingBy(Tuple2::_1, mapping(Tuple2::_2, Collector.of(
+                    DataTable::new,
+                    (dt, key) -> dt.put(key.contains("":"") ? key.split("":"")[1] : key, dataset.get(key)),
+                    DataTable::append))))
+                .forEach((group, subDataset) -> {
+                    long total;
+                    total = subDataset.sumOfValues();
+
+                    int[] roofs = new int[ranks.size()];
+                    for (int i = 0; i < ranks.size(); i++) {
+                        roofs[i] = Math.round(total * ranks.get(i) * 1.0f / 100);
+                    }
+
+                    int count = 0;
+                    final List<String> sortedKeys = subDataset.sortedKeys(Comparator.comparingLong(Long::parseLong));
+
+                    int loopIndex = 0;
+
+                    for (String key : sortedKeys) {
+                        final Long value = subDataset.get(key);
+
+                        count += value;
+                        for (int rankIdx = loopIndex; rankIdx < roofs.length; rankIdx++) {
+                            int roof = roofs[rankIdx];
+
+                            if (count >= roof) {
+                                if (group.equals(DEFAULT_GROUP)) {
+                                    percentileValues.put(String.valueOf(ranks.get(rankIdx)), Long.parseLong(key));
+                                } else {
+                                    percentileValues.put(String.format(""%s:%s"", group, ranks.get(rankIdx)), Long.parseLong(key));","[{'comment': 'So, according to this, the `name:99` is formated from here, right?', 'commenter': 'wu-sheng'}, {'comment': 'Exactly. `:` is the splitter.', 'commenter': 'hanahmily'}]"
5509,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/slack/SlackhookCallback.java,"@@ -77,31 +77,26 @@ public void doAlarm(List<AlarmMessage> alarmMessages) {
 
                 StringEntity entity;
                 try {
-
                     JsonObject jsonObject = new JsonObject();
                     JsonArray jsonElements = new JsonArray();
-
                     alarmMessages.forEach(item -> {
                         jsonElements.add(GSON.fromJson(
                             String.format(
                                 this.alarmRulesWatcher.getSlackSettings().getTextTemplate(), item.getAlarmMessage()
                             ), JsonObject.class));
                     });
-
                     jsonObject.add(""blocks"", jsonElements);
-
                     entity = new StringEntity(GSON.toJson(jsonObject), ContentType.APPLICATION_JSON);
-
                     post.setEntity(entity);
                     CloseableHttpResponse httpResponse = httpClient.execute(post);
                     StatusLine statusLine = httpResponse.getStatusLine();
                     if (statusLine != null && statusLine.getStatusCode() != HttpStatus.SC_OK) {
-                        log.error(""send alarm to "" + url + "" failure. Response code: "" + statusLine.getStatusCode());
+                        log.error(""Send slack alarm to {} failure. Response code: {}"", url , statusLine.getStatusCode());
                     }
                 } catch (UnsupportedEncodingException e) {
-                    log.error(""Alarm to JSON error, "" + e.getMessage(), e);
+                    log.error(""Alarm to JSON error, {} "", e.getMessage(), e);
                 } catch (IOException e) {
-                    log.error(""send alarm to "" + url + "" failure."", e);
+                    log.error(""Send slack alarm to {} failure."", url , e);","[{'comment': ""Actually, I think this should not change, but wechat callback should be changed.\r\n\r\nTake a look on the source codes\r\n```\r\npublic void error(Marker marker, String format, Object arg);\r\n\r\npublic void error(String msg, Throwable t);\r\n```\r\n\r\nIf you want to print exception stack, then can't use the arguments for log text."", 'commenter': 'wu-sheng'}, {'comment': 'I don\'t think so , actually It will match   this method   public void error(String format, Object arg1, Object arg2), \r\nplease check below simple test \r\n```\r\n  @Test\r\n    public void testLog() {\r\n        try {\r\n            int a = 1 / 0;\r\n        } catch (Throwable e) {\r\n            log.error(""aha err {}"", ""formated error"", e);\r\n        }\r\n    }\r\n\r\nlogs as belows ........\r\n\r\n\r\n      2020-09-17 16:45:52.749  LogTest.java:22\r\n      - aha err formated error\r\n\r\njava.lang.ArithmeticException: / by zero\r\n\tat com.credigo.czs.service.LogTest.testLog(LogTest.java:20) ~[test-classes/:?]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) ~[?:1.8.0_231]\r\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) ~[?:1.8.0_231]\r\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) ~[?:1.8.0_231]\r\n\tat java.lang.reflect.Method.invoke(Method.java:498) ~[?:1.8.0_231]\r\n\tat org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50) ~[junit-4.12.jar:4.12]\r\n\tat org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12) ~[junit-4.12.jar:4.12]\r\n\tat org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47) ~[junit-4.12.jar:4.12]\r\n```', 'commenter': 'xbkaishui'}, {'comment': 'Thanks for the demo codes. Interesting, the comments of methods are not consistent.', 'commenter': 'wu-sheng'}, {'comment': 'please check [this](https://gist.github.com/xbkaishui/5afaee39e862ef38c2daaae954140340) ', 'commenter': 'xbkaishui'}]"
5523,docs/en/guides/Java-Plugin-Development-Guide.md,"@@ -443,3 +443,44 @@ Please follow there steps:
 1. Send the pull request and ask for review. 
 1. The plugin committers approve your plugins, plugin CI-with-IT, e2e and plugin tests passed.
 1. The plugin accepted by SkyWalking. 
+
+### Plugin Meter reporter
+Java agent also supports customize meter report to backend. We provide Java Agent Core level API such as [Application Toolkit meter](../setup/service-agent/java-agent/Application-toolkit-meter.md).
+
+* `Counter` API represents a single monotonically increasing counter, automatic collect data and report to backend.
+```java
+import org.apache.skywalking.apm.agent.core.meter.MeterFactory;
+
+Counter counter = MeterFactory.counter(meterName).tag(""tagKey"", ""tagValue"").mode(Counter.Mode.INCREMENT).build();
+counter.increment(1d);
+```
+1. `MeterFactory.counter` Create a new counter builder with the meter name.
+1. `Counter.Builder.tag(String key, String value)` Mark a tag key/value pair.
+1. `Counter.Builder.mode(Counter.Mode mode)` Change the counter mode, `RATE` mode means reporting rate to the backend.
+1. `Counter.Builder.build()` Build a new `Counter` which is collected and reported to the backend.
+1. `Counter.increment(double count)` Increment count to the `Counter`, It could be a positive/negative value.","[{'comment': 'I feel accepting the `negative` value is conflicting with the definition of the counter. `a single monotonically increasing counter`. \r\n\r\nPlease recheck.', 'commenter': 'wu-sheng'}]"
5523,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/meter/builder/Histogram.java,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.meter.builder;
+
+import java.util.List;
+
+/**
+ * Similar to a histogram, a summary sample observations (usual things like request durations and response sizes).","[{'comment': ""What does this `similar to a histogram` mean? Isn't this a histogram already?"", 'commenter': 'wu-sheng'}]"
5523,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/meter/builder/Histogram.java,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.meter.builder;
+
+import java.util.List;
+
+/**
+ * Similar to a histogram, a summary sample observations (usual things like request durations and response sizes).
+ * While it also provides a total count of observations and a sum of all observed values, it calculates configurable quartiles over a sliding time window.","[{'comment': ""Are you copying this from Prometheus or somewhere? Also, at the same time, `HistogramImpl`'s comments don't make sense."", 'commenter': 'wu-sheng'}]"
5523,apm-application-toolkit/apm-toolkit-meter/src/main/java/org/apache/skywalking/apm/toolkit/meter/impl/CounterImpl.java,"@@ -51,30 +48,13 @@ public void increment(double count) {
     /**
      * Get count value
      */
-    public double get() {
+    public double getCount() {","[{'comment': 'Why change this name? But such as in `GuageImpl`, still, use `get`? Seems inconsistent to me.\r\n', 'commenter': 'wu-sheng'}, {'comment': 'Change them to the same function name, using `getCount` to get meter value. I forget to change the `Gauge`, has resolved.', 'commenter': 'mrproliu'}]"
5523,docs/en/guides/Java-Plugin-Development-Guide.md,"@@ -443,3 +443,44 @@ Please follow there steps:
 1. Send the pull request and ask for review. 
 1. The plugin committers approve your plugins, plugin CI-with-IT, e2e and plugin tests passed.
 1. The plugin accepted by SkyWalking. 
+
+### Plugin Meter reporter","[{'comment': '```suggestion\r\n### Plugin Meter Plugin\r\n```', 'commenter': 'wu-sheng'}]"
5523,docs/en/guides/Java-Plugin-Development-Guide.md,"@@ -443,3 +443,44 @@ Please follow there steps:
 1. Send the pull request and ask for review. 
 1. The plugin committers approve your plugins, plugin CI-with-IT, e2e and plugin tests passed.
 1. The plugin accepted by SkyWalking. 
+
+### Plugin Meter reporter
+Java agent also supports customize meter report to backend. We provide Java Agent Core level API such as [Application Toolkit meter](../setup/service-agent/java-agent/Application-toolkit-meter.md).","[{'comment': '```suggestion\r\nJava agent plugin could use meter APIs to collect the metrics for backend analysis.\r\n```', 'commenter': 'wu-sheng'}]"
5523,apm-sniffer/optional-reporter-plugins/kafka-reporter-plugin/src/main/java/org/apache/skywalking/apm/agent/core/kafka/KafkaMeterSender.java,"@@ -53,7 +53,7 @@ public void boot() {
         producer = ServiceManager.INSTANCE.findService(KafkaProducerManager.class).getProducer();
     }
 
-    public void send(Map<MeterId, MeterTransformer> meterMap, MeterService meterService) {
+    public void send(Map<MeterId, BaseMeter> meterMap, MeterService meterService) {","[{'comment': '*MissingOverride:*  send overrides method in MeterSender; expected @Override', 'commenter': 'sonatype-lift[bot]'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/dbcp/SQLExecutor.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.dbcp;
+
+import org.apache.commons.dbcp2.BasicDataSource;
+import org.apache.commons.dbcp2.BasicDataSourceFactory;
+
+import java.io.InputStream;
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.util.Properties;
+
+public class SQLExecutor implements AutoCloseable {
+    public static BasicDataSource ds;
+    private static Connection connection;
+
+    public SQLExecutor() throws SQLException {
+        try {
+            Properties properties = new Properties();
+            properties.setProperty(""driverClassName"", ""com.mysql.jdbc.Driver"");
+            properties.setProperty(""url"", MysqlConfig.getUrl());
+            properties.setProperty(""username"", MysqlConfig.getUserName());
+            properties.setProperty(""password"", MysqlConfig.getPassword());
+            ds = BasicDataSourceFactory.createDataSource(properties);
+        } catch (Exception e) {
+            //
+        }
+        connection = ds.getConnection();
+    }
+
+    public void createTable(String sql) throws SQLException {
+        Statement statement = connection.createStatement();
+        statement.execute(sql);
+        statement.close();","[{'comment': 'This is not the right way to close `Statement`. ', 'commenter': 'wu-sheng'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/dbcp/SQLExecutor.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.dbcp;
+
+import org.apache.commons.dbcp2.BasicDataSource;
+import org.apache.commons.dbcp2.BasicDataSourceFactory;
+
+import java.io.InputStream;
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.util.Properties;
+
+public class SQLExecutor implements AutoCloseable {
+    public static BasicDataSource ds;
+    private static Connection connection;
+
+    public SQLExecutor() throws SQLException {
+        try {
+            Properties properties = new Properties();
+            properties.setProperty(""driverClassName"", ""com.mysql.jdbc.Driver"");
+            properties.setProperty(""url"", MysqlConfig.getUrl());
+            properties.setProperty(""username"", MysqlConfig.getUserName());
+            properties.setProperty(""password"", MysqlConfig.getPassword());
+            ds = BasicDataSourceFactory.createDataSource(properties);","[{'comment': 'Why init the static field in the constructor?', 'commenter': 'wu-sheng'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/dbcp/SQLExecutor.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.dbcp;
+
+import org.apache.commons.dbcp2.BasicDataSource;
+import org.apache.commons.dbcp2.BasicDataSourceFactory;
+
+import java.io.InputStream;
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.util.Properties;
+
+public class SQLExecutor implements AutoCloseable {
+    public static BasicDataSource ds;
+    private static Connection connection;
+
+    public SQLExecutor() throws SQLException {
+        try {
+            Properties properties = new Properties();
+            properties.setProperty(""driverClassName"", ""com.mysql.jdbc.Driver"");
+            properties.setProperty(""url"", MysqlConfig.getUrl());
+            properties.setProperty(""username"", MysqlConfig.getUserName());
+            properties.setProperty(""password"", MysqlConfig.getPassword());
+            ds = BasicDataSourceFactory.createDataSource(properties);
+        } catch (Exception e) {
+            //
+        }
+        connection = ds.getConnection();
+    }
+
+    public void createTable(String sql) throws SQLException {
+        Statement statement = connection.createStatement();
+        statement.execute(sql);
+        statement.close();
+        connection.close();
+        connection = null;
+    }
+
+    public void dropTable(String sql) throws SQLException {
+        connection = ds.getConnection();
+        executeStatement(sql);
+    }
+
+    public void executeStatement(String sql) throws SQLException {
+        Statement statement = connection.createStatement();
+        statement.execute(sql);
+        statement.close();
+    }
+    
+    public void closeConnection() throws SQLException {
+        if (connection != null) {
+            connection.close();
+        }
+    }
+
+    public void closePool() throws SQLException {
+        if (ds != null) {
+            ds.close();
+        }
+    }
+
+    @Override
+    public void close() throws Exception {
+        closeConnection();
+        closePool();","[{'comment': ""Don't use the closing pool. The pool should have the same life cycle as the application."", 'commenter': 'wu-sheng'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/PoolingCloseConnectInterceptor.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PoolingCloseConnectInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        AbstractSpan span = ContextManager.createLocalSpan(""DBCP/Connection/"" + method.getName());
+        span.setComponent(ComponentsDefine.DBCP);
+        SpanLayer.asDB(span);","[{'comment': 'Connection pool is not a DB layer.', 'commenter': 'wu-sheng'}, {'comment': ""Dear Mr Wu @wu-sheng, Is connection pool a cache layer? I didn't find any other suitable layer to describe it. "", 'commenter': 'Jargon9'}, {'comment': 'Dear Mr Wu @wu-sheng  ,sorry to bother you, but could you give me some help?', 'commenter': 'Jargon9'}, {'comment': ""> Dear Mr Wu @wu-sheng ,sorry to bother you, but could you give me some help?\r\n\r\nHe is on vocation recently.\r\n\r\nFrom the functionality of connection pool, I think it's ok to consider it as cache layer."", 'commenter': 'kezhenxu94'}, {'comment': ""> > Dear Mr Wu @wu-sheng ,sorry to bother you, but could you give me some help?\r\n> \r\n> He is on vocation recently.\r\n> \r\n> From the functionality of connection pool, I think it's ok to consider it as cache layer.\r\n\r\nI got it！thanks for your reply！\r\n"", 'commenter': 'Jargon9'}, {'comment': ""We don't.require layer for all plugins. For the connection pool, layer is not required."", 'commenter': 'wu-sheng'}, {'comment': ""> We don't.require layer for all plugins. For the connection pool, layer is not required.\r\n\r\nThank you sir, and wish you a happy vacation!"", 'commenter': 'Jargon9'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/PoolingCloseConnectInterceptor.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PoolingCloseConnectInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        AbstractSpan span = ContextManager.createLocalSpan(""DBCP/Connection/"" + method.getName());
+        span.setComponent(ComponentsDefine.DBCP);
+        SpanLayer.asDB(span);
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        if (ContextManager.isActive()) {","[{'comment': 'Why need this?', 'commenter': 'wu-sheng'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/PoolingCloseConnectInterceptor.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PoolingCloseConnectInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+        AbstractSpan span = ContextManager.createLocalSpan(""DBCP/Connection/"" + method.getName());
+        span.setComponent(ComponentsDefine.DBCP);
+        SpanLayer.asDB(span);
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        if (ContextManager.isActive()) {
+            ContextManager.stopSpan();
+        }
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments, Class<?>[] argumentsTypes, Throwable t) {
+        if (ContextManager.isActive()) {","[{'comment': 'Why need this?', 'commenter': 'wu-sheng'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/PoolingGetConnectInterceptor.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PoolingGetConnectInterceptor implements InstanceMethodsAroundInterceptor {","[{'comment': 'Take the reference from the review on `PoolingCloseConnectInterceptor`.', 'commenter': 'wu-sheng'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/PoolingCloseConnectInterceptor.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2;
+
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+public class PoolingCloseConnectInterceptor implements InstanceMethodsAroundInterceptor {","[{'comment': 'Comments are required.', 'commenter': 'wu-sheng'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/define/BasicDataSourceInstrumentation.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.StaticMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+public class BasicDataSourceInstrumentation extends ClassEnhancePluginDefine {","[{'comment': 'Please extends `ClassInstanceMethodsEnhancePluginDefine`.', 'commenter': 'wu-sheng'}, {'comment': 'Comments required.', 'commenter': 'wu-sheng'}]"
5550,apm-sniffer/apm-sdk-plugin/dbcp-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/dbcp/v2/define/DelegatingConnectionInstrumentation.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.dbcp.v2.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.StaticMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassEnhancePluginDefine;
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+public class DelegatingConnectionInstrumentation extends ClassEnhancePluginDefine {","[{'comment': 'Please extends `ClassInstanceMethodsEnhancePluginDefine`.', 'commenter': 'wu-sheng'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/dbcp/controller/CaseController.java,"@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.dbcp.controller;
+
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.apache.skywalking.apm.testcase.dbcp.SQLExecutor;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseBody;
+import org.springframework.web.bind.annotation.RestController;
+
+@RestController
+@RequestMapping(""/case"")
+public class CaseController {
+
+    private static final Logger logger = LogManager.getLogger(CaseController.class);
+
+    private static final String SUCCESS = ""Success"";
+
+    private static final String CREATE_TABLE_SQL = ""CREATE TABLE test_DBCP(\n"" + ""id VARCHAR(1) PRIMARY KEY, \n"" + ""value VARCHAR(1) NOT NULL)"";
+    private static final String DROP_TABLE_SQL = ""DROP table test_DBCP"";
+    
+    @RequestMapping(""/dbcp-2.x-scenario"")
+    @ResponseBody
+    public String testcase() throws Exception {
+        try (SQLExecutor sqlExecute = new SQLExecutor()) {
+            sqlExecute.createTable(CREATE_TABLE_SQL);
+            sqlExecute.dropTable(DROP_TABLE_SQL);","[{'comment': 'Create and drop are not typical SQLs in the execution stage, insert/update/delete are.', 'commenter': 'wu-sheng'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/dbcp/controller/CaseController.java,"@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.dbcp.controller;
+
+import org.apache.logging.log4j.LogManager;
+import org.apache.logging.log4j.Logger;
+import org.apache.skywalking.apm.testcase.dbcp.SQLExecutor;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseBody;
+import org.springframework.web.bind.annotation.RestController;
+
+@RestController
+@RequestMapping(""/case"")
+public class CaseController {
+
+    private static final Logger logger = LogManager.getLogger(CaseController.class);
+
+    private static final String SUCCESS = ""Success"";
+
+    private static final String CREATE_TABLE_SQL = ""CREATE TABLE test_DBCP(\n"" + ""id VARCHAR(1) PRIMARY KEY, \n"" + ""value VARCHAR(1) NOT NULL)"";
+    private static final String DROP_TABLE_SQL = ""DROP table test_DBCP"";
+    
+    @RequestMapping(""/dbcp-2.x-scenario"")
+    @ResponseBody
+    public String testcase() throws Exception {
+        try (SQLExecutor sqlExecute = new SQLExecutor()) {","[{'comment': ""You are using `SQLExecutor` like a connection, but in the codes, it actually is controlling the whole datasource. This is not right. The real services don't use it in this way."", 'commenter': 'wu-sheng'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/config/expectedData.yaml,"@@ -0,0 +1,255 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+segmentItems:
+- serviceName: dbcp-2.x-scenario
+  segmentSize: nq 0
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: /dbcp-2.x-scenario/case/healthCheck
+      operationId: eq 0
+      parentSpanId: -1
+      spanId: 0
+      spanLayer: Http
+      componentId: 1
+      isError: false
+      spanType: Entry
+      peer: ''
+      skipAnalysis: false
+      tags:
+        - {key: url, value: 'http://localhost:8080/dbcp-2.x-scenario/case/healthCheck'}
+        - {key: http.method, value: HEAD}","[{'comment': ""we don't need to validate this segment."", 'commenter': 'dmsolr'}, {'comment': ""> we don't need to validate this segment.\r\n\r\n@dmsolr Thank you sir, I have deleted this segment."", 'commenter': 'Jargon9'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/support-version.list,"@@ -0,0 +1,20 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+2.7.0
+2.6.0
+2.5.0
+2.4.0","[{'comment': 'Do DBCP have 2.0-2.4?', 'commenter': 'wu-sheng'}, {'comment': ""> Do DBCP have 2.0-2.4?\r\n\r\n@wu-sheng Thanks for your review~ Yes, sir.  It also has these versions\r\n2.0 - 2.4: 2.3.0/2.2.0/2.1.1/2.1/2.0.1/2.0 \r\nI've tested these versions locally. Do I need to add it to the list？"", 'commenter': 'Jargon9'}, {'comment': 'We should add the latest of each version, 2.3.0, 2.2.0, 2.1.1, 2.0.1', 'commenter': 'wu-sheng'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/config/expectedData.yaml,"@@ -0,0 +1,240 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+segmentItems:
+- serviceName: dbcp-2.x-scenario
+  segmentSize: nq 0
+  segments:
+  - segmentId: not null
+    spans:
+    - operationName: Mysql/JDBI/Connection/close
+      operationId: eq 0
+      parentSpanId: 1
+      spanId: 2
+      componentId: 33
+      isError: false
+      spanType: Exit
+      peer: mysql-server:3306
+      skipAnalysis: false
+      tags:
+        - {key: db.type, value: sql}
+        - {key: db.instance, value: test}
+        - {key: db.statement, value: ''}
+    - operationName: DBCP/Connection/getConnection
+      operationId: 0
+      parentSpanId: 0
+      spanId: 1
+      startTime: gt 0
+      endTime: gt 0
+      componentId: 102
+      isError: false
+      spanType: Local
+      peer: ''
+      skipAnalysis: false
+    - operationName: Mysql/JDBI/Statement/execute
+      operationId: 0
+      parentSpanId: 0
+      spanId: 3
+      startTime: gt 0
+      endTime: gt 0
+      componentId: 33
+      isError: false
+      spanType: Exit
+      peer: mysql-server:3306
+      skipAnalysis: false
+      tags:
+        - {key: db.type, value: sql}
+        - {key: db.instance, value: test}
+        - key: db.statement
+          value: ""CREATE TABLE test_DBCP(\nid VARCHAR(1) PRIMARY KEY, \nvalue VARCHAR(1)\
+          \ NOT NULL)""
+    - operationName: DBCP/Connection/close","[{'comment': '@Jargon96 @dmsolr @ascrutae Does DBCP pool have a name? I hope this could be `DBCP/{pool-name}/...`. Then some of the operations like `get` and `close` should be the logic span later to show the connection pool performance.', 'commenter': 'wu-sheng'}, {'comment': '> @Jargon96 @dmsolr @ascrutae Does DBCP pool have a name? I hope this could be `DBCP/{pool-name}/...`. Then some of the operations like `get` and `close` should be the logic span later to show the connection pool performance.\r\n\r\n@wu-sheng Could I use this ?  `DBCP/Apache-Commons-DBCP/...`', 'commenter': 'Jargon9'}, {'comment': 'See my comment below.', 'commenter': 'wu-sheng'}, {'comment': '@wu-sheng  said whether the pool has something like a name or others to identify it.\r\nAs far as I see, it does not have.', 'commenter': 'dmsolr'}]"
5550,test/plugin/scenarios/dbcp-2.x-scenario/src/main/java/org/apache/skywalking/apm/testcase/dbcp/service/CaseService.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.testcase.dbcp.service;
+
+import org.apache.commons.dbcp2.BasicDataSourceFactory;
+import org.apache.skywalking.apm.testcase.dbcp.MysqlConfig;
+import org.springframework.stereotype.Service;
+
+import javax.sql.DataSource;
+import java.sql.Connection;
+import java.sql.SQLException;
+import java.sql.Statement;
+import java.util.Properties;
+
+@Service
+public class CaseService {
+
+    public static DataSource ds;
+    private static final String CREATE_TABLE_SQL = ""CREATE TABLE test_DBCP(\n"" + ""id VARCHAR(1) PRIMARY KEY, \n"" + ""value VARCHAR(1) NOT NULL)"";
+    private static final String INSERT_DATA_SQL = ""INSERT INTO test_DBCP(id, value) VALUES(1,1)"";
+    private static final String QUERY_DATA_SQL = ""SELECT id, value FROM test_DBCP WHERE id=1"";
+    private static final String DELETE_DATA_SQL = ""DELETE FROM test_DBCP WHERE id=1"";
+    private static final String DROP_TABLE_SQL = ""DROP table test_DBCP"";
+
+    static {
+        Properties properties = new Properties();
+        properties.setProperty(""driverClassName"", ""com.mysql.jdbc.Driver"");
+        properties.setProperty(""url"", MysqlConfig.getUrl());
+        properties.setProperty(""username"", MysqlConfig.getUserName());
+        properties.setProperty(""password"", MysqlConfig.getPassword());
+        try {
+            ds = BasicDataSourceFactory.createDataSource(properties);
+        } catch (Exception e) {
+            e.printStackTrace();
+        }","[{'comment': 'I mean, does the connection pool has an attribute called `name` or something?', 'commenter': 'wu-sheng'}, {'comment': 'If not, then there is nothing to be changed.', 'commenter': 'wu-sheng'}]"
5554,apm-sniffer/optional-reporter-plugins/kafka-reporter-plugin/src/main/java/org/apache/skywalking/apm/agent/core/kafka/KafkaProducerManager.java,"@@ -42,6 +46,8 @@
 
     private KafkaProducer<String, Bytes> producer;
 
+    private static final ILog LOGGER = LogManager.getLogger(KafkaProducerManager.class);","[{'comment': 'The static field should be on the top.', 'commenter': 'wu-sheng'}]"
5571,apm-commons/apm-util/src/main/java/org/apache/skywalking/apm/util/MD5Util.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.util;
+
+import java.security.MessageDigest;
+import java.security.NoSuchAlgorithmException;
+
+public class MD5Util {
+    /**
+     * 16 Bit MD5 RSA
+     */
+    public static String md516BitUpper(String string) {
+        return md5(string).substring(8, 24).toUpperCase();
+    }
+
+    /**
+     * 32 Bit MD5 RSA
+     */
+    public static String md532BitUpper(String string) {
+        return md5(string).toUpperCase();
+    }
+
+    private static String md5(final String string) {
+        try {
+            MessageDigest md = MessageDigest.getInstance(""MD5"");","[{'comment': '*BAD_HEXA_CONVERSION:*  Leading zeros are omitted in the concatenation increasing collision potential [(details)](https://find-sec-bugs.github.io/bugs.htm#BAD_HEXA_CONVERSION)', 'commenter': 'sonatype-lift[bot]'}, {'comment': '*WEAK_MESSAGE_DIGEST_MD5:*  This API MD5 (MDX) is not a recommended cryptographic hash function [(details)](https://find-sec-bugs.github.io/bugs.htm#WEAK_MESSAGE_DIGEST_MD5)', 'commenter': 'sonatype-lift[bot]'}]"
5571,apm-commons/apm-util/src/main/java/org/apache/skywalking/apm/util/MD5Util.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.util;
+
+import java.security.MessageDigest;
+import java.security.NoSuchAlgorithmException;
+
+public class MD5Util {
+    /**
+     * 16 Bit MD5
+     */
+    public static String md516BitUpper(String string) {
+        return md5(string).substring(8, 24).toUpperCase();
+    }
+
+    /**
+     * 32 Bit MD5
+     */
+    public static String md532BitUpper(String string) {
+        return md5(string).toUpperCase();
+    }
+
+    private static String md5(final String string) {
+        try {
+            MessageDigest md = MessageDigest.getInstance(""MD5"");","[{'comment': '*opt.semgrep.java.lang.security.audit.crypto.weak-hash.use-of-md5:*  Detected MD5 hash algorithm which is considered insecure. MD5 is not \ncollision resistant and is therefore not suitable as a cryptographic\nsignature. Use SHA256 or SHA3 instead.\n', 'commenter': 'sonatype-lift[bot]'}]"
5605,apm-application-toolkit/apm-toolkit-meter/src/main/java/org/apache/skywalking/apm/toolkit/meter/MeterId.java,"@@ -64,7 +64,7 @@ public MeterId copyTo(String name, MeterType type) {
     @Override
     public boolean equals(Object o) {
         if (this == o) return true;
-        if (o == null || getClass() != o.getClass()) return false;
+        if (o == null || !(o instanceof MeterId)) return false;","[{'comment': ""This is how IDE(IntelliJ) generated. I don't think this is an issue."", 'commenter': 'wu-sheng'}]"
5612,apm-sniffer/optional-plugins/customize-enhance-plugin/src/main/java/org/apache/skywalking/apm/plugin/customize/interceptor/BaseInterceptorMethods.java,"@@ -56,15 +56,14 @@ void beforeMethod(Method method, Object[] allArguments) {
                     }
                 }
                 if (tags != null && !tags.isEmpty()) {
-                    for (String key : tags.keySet()) {
-                        String expression = tags.get(key);
-                        spanTags.put(key, CustomizeExpression.parseExpression(expression, context));
+                    for (Map.Entry<String, String> expression: tags.entrySet()) {
+                        spanTags.put(expression.getKey(), CustomizeExpression.parseExpression(expression.getValue(), context));
                     }
                 }
                 if (logs != null && !logs.isEmpty()) {
-                    for (String key : logs.keySet()) {
-                        String expression = logs.get(key);
-                        spanLogs.put(key, CustomizeExpression.parseExpression(expression, context));
+                    for (Map.Entry<String, String> entries : logs.entrySet()) {
+                        String expression = logs.get(entries.getKey());","[{'comment': 'Well, I\'m late for just a second 🤣 but this doesn\'t fix what you said in the comment \r\n\r\n> Accessing a value using a key that was retrieved from a keySet iterator. It is more efficient to use an iterator on the entrySet of the map, avoiding the extra HashMap.get(key) lookup.\r\n\r\n""avoiding the extra HashMap.get(key) lookup."", you are still looking up with the key, should replace `logs.get(entries.getKey())` `entries.getValue()`', 'commenter': 'kezhenxu94'}, {'comment': 'Seems so, just clicked the merge. Anyway, no real harm, if you want, submit a pull request to fix again.', 'commenter': 'wu-sheng'}]"
5616,apm-sniffer/optional-plugins/trace-ignore-plugin/src/main/java/org/apache/skywalking/apm/plugin/trace/ignore/conf/IgnoreConfigInitializer.java,"@@ -89,10 +88,12 @@ private static void overrideConfigBySystemProp() throws IllegalAccessException {
     private static InputStream loadConfigFromAgentFolder() throws AgentPackageNotFoundException, ConfigNotFoundException {
         File configFile = new File(AgentPackagePath.getPath(), CONFIG_FILE_NAME);
         if (configFile.exists() && configFile.isFile()) {
-            try {
+            try(var configFileStream = new FileInputStream(configFile)) {","[{'comment': 'It is closed in L50.', 'commenter': 'dmsolr'}, {'comment': 'ok, is false positive.', 'commenter': 'x22x22'}]"
5616,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/plugin/loader/AgentClassLoader.java,"@@ -192,9 +193,11 @@ public URL nextElement() {
                 for (String fileName : jarFileNames) {
                     try {
                         File file = new File(path, fileName);
-                        Jar jar = new Jar(new JarFile(file), file);
-                        jars.add(jar);
-                        LOGGER.info(""{} loaded."", file.toString());
+                        try(var jarFile = new JarFile(file)){","[{'comment': 'JarFile need to be resident in memory. @wu-sheng @acurtain ', 'commenter': 'dmsolr'}, {'comment': '`var` is not acceptable in the JDK8 compiler. Why use this?', 'commenter': 'wu-sheng'}, {'comment': ""We don't recommend abusing `lombok`. Its annotation-based usages are enough. Don't put `var` in the codes."", 'commenter': 'wu-sheng'}, {'comment': ""We are using Java, rather than Scala or Kotlin today, we don't want to make codes simpler, but want to make the codes easier to read for everyone. At here, you are just trying to fix the muse recommendation, so, please don't bring any related thing in."", 'commenter': 'wu-sheng'}, {'comment': 'is false positive, I have restored the original code', 'commenter': 'x22x22'}]"
5616,oap-server/server-receiver-plugin/zipkin-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/zipkin/handler/SpanProcessor.java,"@@ -39,37 +39,36 @@ public SpanProcessor(SourceReceiver receiver) {
     }
 
     void convert(ZipkinReceiverConfig config, SpanBytesDecoder decoder, HttpServletRequest request) throws IOException {
-        InputStream inputStream = getInputStream(request);
-        ByteArrayOutputStream out = new ByteArrayOutputStream();
-        byte[] buffer = new byte[2048];
-        int readCntOnce;
+        try(InputStream inputStream = getInputStream(request)) {
+            ByteArrayOutputStream out = new ByteArrayOutputStream();
+            byte[] buffer = new byte[2048];
+            int readCntOnce;
 
-        while ((readCntOnce = inputStream.read(buffer)) >= 0) {
-            out.write(buffer, 0, readCntOnce);
-        }
+            while ((readCntOnce = inputStream.read(buffer)) >= 0) {
+                out.write(buffer, 0, readCntOnce);
+            }
 
-        List<Span> spanList = decoder.decodeList(out.toByteArray());
+            List<Span> spanList = decoder.decodeList(out.toByteArray());
 
-        if (config.isNeedAnalysis()) {
-            ZipkinSkyWalkingTransfer transfer = new ZipkinSkyWalkingTransfer();
-            transfer.doTransfer(config, spanList);
-        } else {
-            SpanForward forward = new SpanForward(config, receiver);
-            forward.send(spanList);
+            if (config.isNeedAnalysis()) {
+                ZipkinSkyWalkingTransfer transfer = new ZipkinSkyWalkingTransfer();
+                transfer.doTransfer(config, spanList);
+            } else {
+                SpanForward forward = new SpanForward(config, receiver);
+                forward.send(spanList);
+            }
         }
     }
 
     private InputStream getInputStream(HttpServletRequest request) throws IOException {
-        InputStream requestInStream;
-
         String headEncoding = request.getHeader(""accept-encoding"");
         if (headEncoding != null && (headEncoding.indexOf(""gzip"") != -1)) {
-            requestInStream = new GZIPInputStream(request.getInputStream());
+            try(InputStream requestInStream = new GZIPInputStream(request.getInputStream());){
+                return requestInStream;","[{'comment': 'Closing this?', 'commenter': 'wu-sheng'}, {'comment': 'Restored code.', 'commenter': 'x22x22'}]"
5637,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java,"@@ -205,4 +230,20 @@ public static TimeInterval timeIntervalTS(long timestamp) {
     public static TimeInterval timeIntervalTB(long timeBucket) {
         return ti(TimeBucket.getTimestamp(timeBucket), ""ms"");
     }
+
+    @Override
+    public void registerChecker(HealthChecker healthChecker) {
+        this.healthChecker.register(healthChecker);
+    }
+
+    /**
+     * Check influx health, Ignore grammar related exception
+     */
+    private void checkHealth(Throwable e) {
+        if (e instanceof InfluxDBIOException) {
+            healthChecker.unHealth(e);
+        } else if (!(e instanceof InfluxDBException)) {
+            healthChecker.unHealth(e);
+        }","[{'comment': 'Grammar related exceptions seem `unhealth` to me. @hanahmily What do you think?', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5637,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java,"@@ -101,11 +113,10 @@ private InfluxDB getInflux() {
 
         try {
             QueryResult result = getInflux().query(new Query(query.getCommand()));
-            if (result.hasError()) {
-                throw new IOException(result.getError());
-            }
+            healthChecker.health();","[{'comment': 'The test of result.hasError is dropped. Maybe some errors are ignored. Pls double check whether it leaves out them.', 'commenter': 'hanahmily'}, {'comment': 'I have checked the source code of [influx client](https://github.com/influxdata/influxdb-java/blob/bfbbcd0f4ec8bb1a6362e7a36b62d81e13693393/src/main/java/org/influxdb/impl/InfluxDBImpl.java#L804), \r\nwhen some errors happens it will throw an exception, no need to check the hasError method\r\n', 'commenter': 'xbkaishui'}, {'comment': '@dmsolr Could you confirm the status? Is there some case there could be some errors w/o exception?', 'commenter': 'wu-sheng'}, {'comment': 'hi @xbkaishui \r\nI had test some cases. The result show following\r\n1. syntax error/parse error, connection, etc will throw an exception.\r\n2. aggregate function error maybe doesn\'t throw.\r\n\r\nFor example:\r\n1. case 1\r\n ```\r\nQuery: SELECT mean(""square""),""round"" FROM ""peg""\r\nResponse: QueryResult [results=[Result [series=null, error=mixing aggregate and non-aggregate queries is not supported]], error=null]\r\n```\r\n\r\n2. case 2 \r\n```\r\nQuery: SELECT sum(""square"", 2),""round"" FROM ""peg""\r\n\r\nResponse: [results=[Result [series=null, error=invalid number of arguments for mean, expected 1, got 2]], error=null]\r\n```\r\n\r\nThese two examples put error messages in clauses only. :( ', 'commenter': 'dmsolr'}, {'comment': 'I am not sure that is wrong what I did before. But we need to consider this scenario, right?', 'commenter': 'dmsolr'}, {'comment': 'Nop, for below sql , in the java client it will throws an exception.  did you use the java client to test ? ', 'commenter': 'xbkaishui'}, {'comment': 'please check me test code [gist](https://gist.github.com/xbkaishui/493009dcb56dd9cda8b8ddd82f53f34f)', 'commenter': 'xbkaishui'}, {'comment': '@xbkaishui I am curious if all things go through exception, why InfluxDB Java client designs that API? In case the exception has been caught?', 'commenter': 'wu-sheng'}, {'comment': 'from what I test, the error msg is wrapper as an exception in java client', 'commenter': 'xbkaishui'}, {'comment': 'Maybe other client has different implement. ', 'commenter': 'xbkaishui'}, {'comment': '> from what I test, the error msg is wrapper as an exception in java client\r\n\r\nOK, if so, that we may be able to remove the codes. But in another hand, to do the check seems harmless :)', 'commenter': 'wu-sheng'}, {'comment': 'I\'ve read your code. I think have some issue.\r\n\r\n```java\r\npublic static void main(String[] args) {\r\n    final InfluxDB influxDB = InfluxDBFactory.connect(""http://127.0.0.1:8086"");\r\n    String databaseName = ""NOAA_water_database"";\r\n    try {\r\n        QueryResult result = influxDB.query(new Query(""SELECT sum(\\""square\\"", 2),\\""round\\"" FROM \\""peg\\""\\n"" +\r\n                                                          "";"" + databaseName)); // There is syntax issue, so InfluxDB Client throws an exception. You don\'t need to append `+ "";"" + databaseName`.\r\n        String error = result.getError();\r\n        System.out.println(error);\r\n        influxDB.setDatabase(databaseName);\r\n    } catch (Throwable e) {\r\n        e.printStackTrace();\r\n    }\r\n}\r\n```\r\n\r\nYou could try the following code.\r\n\r\n```java\r\ntry {\r\n    influxDB.setDatabase(databaseName);\r\n    QueryResult result = influxDB.query(new Query(""SELECT sum(\\""square\\"", 2),\\""round\\"" FROM \\""peg\\""\\n""));\r\n    result.hasError(); // it is false.\r\n    result.getError(); // null\r\n\r\n    result.getResults().forEach(series -> {\r\n        series.hasError(); // it is true\r\n        series.getError(); // error message\r\n    });\r\n} catch (Throwable e) {\r\n    e.printStackTrace();\r\n}\r\n```', 'commenter': 'dmsolr'}, {'comment': 'Syntax errors can be detected by the client, so the exception is thrown directly.\r\nSome errors, like aggregate function wrong, do not throw the exception.', 'commenter': 'dmsolr'}, {'comment': '> Syntax errors can be detected by the client, so the exception is thrown directly.\r\n> Some errors, like aggregate function wrong, do not throw the exception.\r\n\r\nbut for the aggregate function, the hasError return false, it will not throws an exception using the orginal code, so the check error logic is take no effect  right ? ', 'commenter': 'xbkaishui'}, {'comment': 'I will revert my changes. thanks', 'commenter': 'xbkaishui'}, {'comment': 'done', 'commenter': 'xbkaishui'}, {'comment': '> but for the aggregate function, the hasError return false, it will not throws an exception using the orginal code, so the check error logic is take no effect right ?\r\n\r\nIt is basically right. Would you like to fix it in this PR?', 'commenter': 'dmsolr'}, {'comment': 'Do you mean also check the child resuts error ? ', 'commenter': 'xbkaishui'}]"
5637,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java,"@@ -161,11 +172,7 @@ public int getCounter(Query query) throws IOException {
      */
     public void dropSeries(String measurement, long timeBucket) throws IOException {
         Query query = new Query(""DROP SERIES FROM "" + measurement + "" WHERE time_bucket='"" + timeBucket + ""'"");
-        QueryResult result = getInflux().query(query);
-
-        if (result.hasError()) {
-            throw new IOException(""Statement: "" + query.getCommand() + "", ErrorMsg: "" + result.getError());
-        }
+        this.query(query);","[{'comment': 'Ditto ', 'commenter': 'hanahmily'}, {'comment': 'Same comment as above', 'commenter': 'xbkaishui'}, {'comment': 'Done, this.query already checked the hasError logic, no need to check again', 'commenter': 'xbkaishui'}]"
5637,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/InfluxClient.java,"@@ -205,4 +230,20 @@ public static TimeInterval timeIntervalTS(long timestamp) {
     public static TimeInterval timeIntervalTB(long timeBucket) {
         return ti(TimeBucket.getTimestamp(timeBucket), ""ms"");
     }
+
+    @Override
+    public void registerChecker(HealthChecker healthChecker) {
+        this.healthChecker.register(healthChecker);
+    }
+
+    /**
+     * Check influx health, Ignore grammar related exception","[{'comment': 'Why do you ignore grammar relevant errors? They would indicate the version mismatches between OAP and influxdb server.', 'commenter': 'hanahmily'}, {'comment': 'ok will change', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-cluster-plugin/pom.xml,"@@ -47,5 +47,10 @@
             <artifactId>library-util</artifactId>
             <version>${project.version}</version>
         </dependency>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>library-client</artifactId>
+            <version>${project.version}</version>
+        </dependency>","[{'comment': 'You should remove this dependency totally.', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-cluster-plugin/cluster-consul-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/consul/ConsulCoordinator.java,"@@ -27,19 +27,25 @@
 import com.orbitz.consul.model.health.ServiceHealth;
 import java.util.ArrayList;
 import java.util.List;
+import java.util.stream.Collectors;
+
 import org.apache.skywalking.oap.server.core.cluster.ClusterNodesQuery;
 import org.apache.skywalking.oap.server.core.cluster.ClusterRegister;
 import org.apache.skywalking.oap.server.core.cluster.RemoteInstance;
+import org.apache.skywalking.oap.server.core.cluster.ServiceQueryException;
 import org.apache.skywalking.oap.server.core.cluster.ServiceRegisterException;
 import org.apache.skywalking.oap.server.core.remote.client.Address;
+import org.apache.skywalking.oap.server.library.client.healthcheck.HealthCheckable;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.library.util.HealthChecker;
 
-public class ConsulCoordinator implements ClusterRegister, ClusterNodesQuery {
+public class ConsulCoordinator implements ClusterRegister, ClusterNodesQuery, HealthCheckable {","[{'comment': 'You are still using the ` org.apache.skywalking.oap.server.library.util.HealthChecker` and `org.apache.skywalking.oap.server.library.client.healthcheck.HealthCheckable`.', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-cluster-plugin/cluster-consul-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/consul/ConsulCoordinator.java,"@@ -49,22 +56,32 @@ public ConsulCoordinator(ClusterModuleConsulConfig config, Consul client) {
 
     @Override
     public List<RemoteInstance> queryRemoteNodes() {
-        HealthClient healthClient = client.healthClient();
-
-        // Discover only ""passing"" nodes
-        List<ServiceHealth> nodes = healthClient.getHealthyServiceInstances(serviceName).getResponse();
-
         List<RemoteInstance> remoteInstances = new ArrayList<>();
-        if (CollectionUtils.isNotEmpty(nodes)) {
-            nodes.forEach(node -> {
-                if (!Strings.isNullOrEmpty(node.getService().getAddress())) {
-                    Address address = new Address(node.getService().getAddress(), node.getService().getPort(), false);
-                    if (address.equals(selfAddress)) {
-                        address.setSelf(true);
+        try {
+            HealthClient healthClient = client.healthClient();
+            // Discover only ""passing"" nodes
+            List<ServiceHealth> nodes = healthClient.getHealthyServiceInstances(serviceName).getResponse();
+            if (CollectionUtils.isNotEmpty(nodes)) {
+                nodes.forEach(node -> {
+                    if (!Strings.isNullOrEmpty(node.getService().getAddress())) {
+                        Address address = new Address(node.getService().getAddress(), node.getService().getPort(), false);
+                        if (address.equals(selfAddress)) {
+                            address.setSelf(true);
+                        }
+                        remoteInstances.add(new RemoteInstance(address));","[{'comment': 'If you found `127.0.0.1` or `localhost` exists in the node list(list#size > 1), then the node should be labeled as unhealthy.\r\nFYI @hanahmily @kezhenxu94 Make sense?', 'commenter': 'wu-sheng'}, {'comment': 'Same thing should be checked in every coordinator implementation. I noted that the users usually set up the cluster mode incorrectly, then, blame SkyWalking insert duplicated data or statistic not accurate.', 'commenter': 'wu-sheng'}, {'comment': 'got it ', 'commenter': 'xbkaishui'}, {'comment': 'Done, current implementation will ignore coordinator  standalone mode ', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-library/library-util/src/main/java/org/apache/skywalking/oap/server/library/util/HealthCheckUtil.java,"@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.library.util;
+
+import com.google.common.collect.Sets;
+
+import java.util.Set;
+
+public class HealthCheckUtil {","[{'comment': 'Please move this class to the same folder of `ClusterModule`, as where it belongs. Then rename it to `OAPNodeChecker`.', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-library/library-util/src/main/java/org/apache/skywalking/oap/server/library/util/HealthCheckUtil.java,"@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.library.util;
+
+import com.google.common.collect.Sets;
+
+import java.util.Set;
+
+public class HealthCheckUtil {
+    private static final Set<String> UN_HEALTH_ADDRESS = Sets.newHashSet(""127.0.0.1"", ""localhost"");","[{'comment': '```suggestion\r\n    private static final Set<String> ILLEGAL_NODE_ADDRESS_IN_CLUSTER_MODE = Sets.newHashSet(""127.0.0.1"", ""localhost"");\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-cluster-plugin/cluster-etcd-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/etcd/EtcdCoordinator.java,"@@ -51,6 +59,9 @@
 
     private static final Integer KEY_TTL = 45;
 
+    @Setter
+    private HealthCheckMetrics healthChecker;","[{'comment': ""As this is required in the process, please don't use the `setter`. Initial this in the constructor."", 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-core/src/test/java/org/apache/skywalking/oap/server/core/cluster/OAPNodeCheckerTest.java,"@@ -0,0 +1,58 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.cluster;
+
+import com.google.common.collect.Sets;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.util.Set;
+
+import static org.hamcrest.CoreMatchers.is;
+
+public class OAPNodeCheckerTest {
+
+    @Test
+    public void hasUnHealthAddressFalse() {
+        Set<String> address = Sets.newHashSet(""123.23.4.2"");
+        boolean flag = OAPNodeChecker.hasUnHealthAddress(address);
+        Assert.assertThat(flag, is(false));","[{'comment': 'There is `Assert.assertFalse()`', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-cluster-plugin/cluster-etcd-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/etcd/EtcdCoordinator.java,"@@ -73,15 +83,30 @@ public EtcdCoordinator(ClusterModuleEtcdConfig config, EtcdClient client) {
                     if (!address.equals(selfAddress)) {
                         address.setSelf(false);
                     }
-                    res.add(new RemoteInstance(address));
+                    remoteInstances.add(new RemoteInstance(address));
                 });
             }
-
-        } catch (Exception e) {
+            if (remoteInstances.size() > 1) {
+                Set<String> remoteAddressSet = remoteInstances.stream().map(remoteInstance ->
+                        remoteInstance.getAddress().getHost()).collect(Collectors.toSet());
+                boolean hasUnHealthAddress = OAPNodeChecker.hasUnHealthAddress(remoteAddressSet);
+                if (hasUnHealthAddress) {
+                    this.healthChecker.unHealth(new ServiceQueryException(""found 127.0.0.1 or localhost in cluster mode""));
+                } else {
+                    List<RemoteInstance> selfInstances = remoteInstances.stream().
+                            filter(remoteInstance -> remoteInstance.getAddress().isSelf()).collect(Collectors.toList());
+                    if (CollectionUtils.isNotEmpty(selfInstances) && selfInstances.size() == 1) {","[{'comment': 'Why `&& selfInstances.size() == 1`? Are you planning to check duplicate addresses? If so, please move this login into `OAPNodeChecker`, all coordinator implementations should check this too, right?', 'commenter': 'wu-sheng'}, {'comment': 'Yes, changed ', 'commenter': 'xbkaishui'}]"
5661,oap-server/server-cluster-plugin/cluster-zookeeper-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/zookeeper/ZookeeperCoordinator.java,"@@ -73,28 +84,49 @@ public synchronized void registerRemote(RemoteInstance remoteInstance) throws Se
             serviceDiscovery.registerService(thisInstance);
 
             this.selfAddress = remoteInstance.getAddress();
-        } catch (Exception e) {
+            this.healthChecker.health();
+        } catch (Throwable e) {
+            this.healthChecker.unHealth(e);
             throw new ServiceRegisterException(e.getMessage());
         }
     }
 
     @Override
     public List<RemoteInstance> queryRemoteNodes() {
-        List<RemoteInstance> remoteInstanceDetails = new ArrayList<>(20);
-        List<ServiceInstance<RemoteInstance>> serviceInstances = serviceCache.getInstances();
-        serviceInstances.forEach(serviceInstance -> {
-            RemoteInstance instance = serviceInstance.getPayload();
-            if (instance.getAddress().equals(selfAddress)) {
-                instance.getAddress().setSelf(true);
+        List<RemoteInstance> remoteInstances = new ArrayList<>(20);
+        try {
+            initHealthChecker();","[{'comment': '*THREAD_SAFETY_VIOLATION:*  Unprotected write. Non-private method `ZookeeperCoordinator.queryRemoteNodes()` indirectly writes to field `this.healthChecker` outside of synchronization.\n Reporting because another access to the same memory occurs on a background thread, although this access may not.', 'commenter': 'sonatype-lift[bot]'}]"
5661,oap-server/server-cluster-plugin/cluster-zookeeper-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/zookeeper/ZookeeperCoordinator.java,"@@ -22,29 +22,39 @@
 import java.util.ArrayList;
 import java.util.List;
 import java.util.UUID;
+
+import lombok.Setter;
 import org.apache.curator.x.discovery.ServiceCache;
 import org.apache.curator.x.discovery.ServiceDiscovery;
 import org.apache.curator.x.discovery.ServiceInstance;
 import org.apache.skywalking.oap.server.core.cluster.ClusterNodesQuery;
 import org.apache.skywalking.oap.server.core.cluster.ClusterRegister;
+import org.apache.skywalking.oap.server.core.cluster.OAPNodeChecker;
 import org.apache.skywalking.oap.server.core.cluster.RemoteInstance;
+import org.apache.skywalking.oap.server.core.cluster.ServiceQueryException;
 import org.apache.skywalking.oap.server.core.cluster.ServiceRegisterException;
 import org.apache.skywalking.oap.server.core.remote.client.Address;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+import org.apache.skywalking.oap.server.library.module.ModuleDefineHolder;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.HealthCheckMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
 
 public class ZookeeperCoordinator implements ClusterRegister, ClusterNodesQuery {
-    private static final Logger LOGGER = LoggerFactory.getLogger(ZookeeperCoordinator.class);
 
     private static final String REMOTE_NAME_PATH = ""remote"";
 
     private final ClusterModuleZookeeperConfig config;
     private final ServiceDiscovery<RemoteInstance> serviceDiscovery;
     private final ServiceCache<RemoteInstance> serviceCache;
     private volatile Address selfAddress;
+    @Setter","[{'comment': '*THREAD_SAFETY_VIOLATION:*  Unprotected write. Non-private method `ZookeeperCoordinator.setHealthChecker(...)` writes to field `this.healthChecker` outside of synchronization.\n Reporting because another access to the same memory occurs on a background thread, although this access may not.', 'commenter': 'sonatype-lift[bot]'}]"
5661,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/cluster/OAPNodeChecker.java,"@@ -0,0 +1,63 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.cluster;
+
+import com.google.common.collect.Sets;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+
+import java.util.List;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+public class OAPNodeChecker {
+    private static final Set<String> ILLEGAL_NODE_ADDRESS_IN_CLUSTER_MODE = Sets.newHashSet(""127.0.0.1"", ""localhost"");
+
+    public static boolean hasIllegalNodeAddress(List<RemoteInstance> remoteInstances) {
+        if (CollectionUtils.isEmpty(remoteInstances)) {
+            return false;
+        }
+        Set<String> remoteAddressSet = remoteInstances.stream().map(remoteInstance ->
+                remoteInstance.getAddress().getHost()).collect(Collectors.toSet());
+        return !Sets.intersection(ILLEGAL_NODE_ADDRESS_IN_CLUSTER_MODE, remoteAddressSet).isEmpty();
+    }
+
+    /**
+     * Check the remote instance healthiness, set health to false for bellow conditions:
+     * 1.can't get the instance list
+     * 2.can't get itself
+     * 3.check for illegal node in cluster mode such as 127.0.0.1, localhost
+     *
+     * @param remoteInstances all the remote instances from cluster
+     * @return true health false unHealth
+     */
+    public static boolean isHealth(List<RemoteInstance> remoteInstances) {","[{'comment': 'Make the return value as an object. then you could get a boolean with the reason.\r\nThe reason could include which illegal address is found.', 'commenter': 'wu-sheng'}, {'comment': ""Then add a new method in `HealthCheckMetrics`, `unHealth(String message)`(note, the message is just for log like exception). Creating exception cause unnecessary resource, and the `HealthQueryService` and `HealthCheckerProvider#notifyAfterCompleted` don't care the exception at all."", 'commenter': 'wu-sheng'}, {'comment': 'Ok, sounds better to me', 'commenter': 'xbkaishui'}, {'comment': 'done, please help to check ', 'commenter': 'xbkaishui'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -33,13 +36,20 @@
      */
     private boolean skipAnalysis;
 
+    /**
+     * The sending timestamp of the exit span.
+     */
+    @Getter
+    @Setter
+    private long sendingTimestamp = 0;
+
     /**
      * Serialize this {@link ExtensionContext} to a {@link String}
      *
      * @return the serialization string.
      */
     String serialize() {
-        return skipAnalysis ? ""1"" : ""0"";
+        return skipAnalysis ? ""1"" : ""0"" + ""-"" + sendingTimestamp;","[{'comment': 'You should not transport the timestamp if it is a `0`, otherwise, `0` would provide a super huge false latency for this RPC.', 'commenter': 'wu-sheng'}, {'comment': '```suggestion\r\n        return (skipAnalysis ? ""1"" : ""0"") + ""-"" + sendingTimestamp;\r\n```', 'commenter': 'mrproliu'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -54,6 +64,7 @@ void deserialize(String value) {
         // only try to read it when it exist.
         if (extensionParts.length > 0) {
             this.skipAnalysis = Objects.equals(extensionParts[0], ""1"");
+            this.sendingTimestamp = Long.parseLong(extensionParts[1]);","[{'comment': 'This is optional, you should add `if (extensionParts.length > 1) {`, then get (1) and parsing. Also, you need `if not empty` and `try/catch` to avoid the empty string as it is optional, and illegal character.', 'commenter': 'wu-sheng'}]"
5666,test/plugin/scenarios/kafka-scenario/config/expectedData.yaml,"@@ -156,6 +157,7 @@ segmentItems:
         tags:
           - {key: mq.broker, value: 'kafka-server:9092'}
           - {key: mq.topic, value: test.}
+          - {key: transmission.latency, value: not null}","[{'comment': 'Why only Kafka test case updated? I am assuming this should relate to all MQ plugins.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'EvanLjp'}]"
5666,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/MultiScopesAnalysisListener.java,"@@ -234,6 +234,12 @@ public void parseExit(SpanObject span, SegmentObject segmentObject) {
 
     private void setPublicAttrs(SourceBuilder sourceBuilder, SpanObject span) {","[{'comment': 'Rename this to `parseRPC`, as it does more than it used to be.', 'commenter': 'wu-sheng'}]"
5666,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/MultiScopesAnalysisListener.java,"@@ -234,6 +234,12 @@ public void parseExit(SpanObject span, SegmentObject segmentObject) {
 
     private void setPublicAttrs(SourceBuilder sourceBuilder, SpanObject span) {
         long latency = span.getEndTime() - span.getStartTime();
+        for (final KeyStringValuePair keyStringValuePair : span.getTagsList()) {
+            if (keyStringValuePair.getKey().equals(SpanTags.TRANSMISSION_LATENCY)) {
+                latency += Integer.parseInt(keyStringValuePair.getValue());
+                break;
+            }
+        }","[{'comment': ""We have a `for span` in the L240-L248 already, please don't do duplicated iteration."", 'commenter': 'wu-sheng'}, {'comment': 'Why rewrite the latency of this? We never said the latency of span/segment/service including the network when we talked about the server-side latency.', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -78,19 +89,25 @@ void handle(AbstractSpan span) {
         if (this.skipAnalysis) {
             span.skipAnalysis();
         }
+        if (this.sendingTimestamp != 0) {
+            Tags.TRANSMISSION_LATENCY.set(span, String.valueOf(span.getStartTime() - sendingTimestamp));
+        }","[{'comment': 'Should not be`span.getStartTime() - sendingTimestamp`. At here, for you, the latency is `current time - sending timestamp`', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/trace/AbstractSpan.java,"@@ -124,4 +124,10 @@
      * Should skip analysis in the backend.
      */
     void skipAnalysis();
+
+    /**
+     * Get the start time stamp of this span.
+     */
+    long getStartTime();","[{'comment': 'This should be removed.', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionInjector.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.context;
+
+/**
+ * Inject or read the extension protocol fields,such as {@link ExtensionContext#sendingTimestamp}.
+ */
+public class ExtensionInjector {
+
+    private final ExtensionContext extensionContext;
+
+    ExtensionInjector(final ExtensionContext extensionContext) {
+        this.extensionContext = extensionContext;
+    }
+
+    public void injectSendingTimestamp() {
+        extensionContext.setSendingTimestamp(System.currentTimeMillis());
+    }
+
+    public long readSendingTimestamp() {","[{'comment': ""`long` -> `Long`, as it could be NULL if don't exist in the in-wire context."", 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/tag/Tags.java,"@@ -77,7 +77,11 @@ private Tags() {
      */
     public static final StringTag MQ_TOPIC = new StringTag(9, ""mq.topic"");
 
-    public static final StringTag TRANSMISSION_LATENCY = new StringTag(15, ""transmission.latency"");
+    /**
+     * The latency of transmission. If there were more than one downstream endpoints, multiple tags will be recorded,","[{'comment': '```suggestion\r\n     * The latency of transmission. When there are more than one downstream parent/segment-ref(s), multiple tags will be recorded,\r\n```', 'commenter': 'wu-sheng'}]"
5666,test/plugin/scenarios/pulsar-scenario/config/expectedData.yaml,"@@ -83,9 +83,9 @@ segmentItems:
       spanType: Entry
       peer: ''
       tags:
-      - {key: mq.broker, value: not null}
+        - {key: transmission.latency, value: not null}
+        - {key: mq.broker, value: not null}","[{'comment': 'Is this format correct?', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -28,18 +33,30 @@
  */
 public class ExtensionContext {
 
+    private static final ILog LOGGER = LogManager.getLogger(ExtensionContext.class);
     /**
      * Tracing Mode. If true means represents all spans generated in this context should skip analysis.
      */
     private boolean skipAnalysis;
 
+    /**
+     * The sending timestamp of the exit span.
+     */
+    @Getter
+    @Setter
+    private long sendingTimestamp = 0;
+
     /**
      * Serialize this {@link ExtensionContext} to a {@link String}
      *
      * @return the serialization string.
      */
     String serialize() {
-        return skipAnalysis ? ""1"" : ""0"";
+        String res = skipAnalysis ? ""1"" : ""0"";
+        if (sendingTimestamp != 0) {
+            res += ""-"" + sendingTimestamp;","[{'comment': ""Maybe we should always serialize this part even `if sendingTimestamp != 0`? The extension fields are order-sensitive, we always need a real value or placeholder, otherwise, if the downstream agent plugin don't have this field but have their own extended fields(now for now, though), it will be trouble, WDYT? @wu-sheng "", 'commenter': 'kezhenxu94'}, {'comment': ""Yes, my previous comment is about don't serialize the 0, but - should be included. \r\nIt seems to be misunderstood."", 'commenter': 'wu-sheng'}, {'comment': 'I have similar concerns about this, so the zero is a placeholder before. WDYT? @wu-sheng ', 'commenter': 'EvanLjp'}, {'comment': ""I don't like `0`, as `0` is a real value, you are going to represent no value. So you could use `0-` as timestamp doesn't exist."", 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -69,14 +65,12 @@ void deserialize(String value) {
         final String[] extensionParts = value.split(""-"");
         // All parts of the extension header are optional.
         // only try to read it when it exist.
-        if (extensionParts.length > 0) {
+        if (extensionParts.length == 2) {","[{'comment': ""Again, don't use `2`."", 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'EvanLjp'}, {'comment': 'Because all parameters are passing rather than optional fields, the length of extensionParts is fixed.\r\n\r\nnow, the passing data maybe ""0-"" or ""0-1602743904804"", length of extensionParts must be 2.\r\nin the feature, if add another field, the propagate data may be ""0--"" or ""0-xxx-xxx"". And the length of extensionParts must be 3.\r\n\r\nI think logic greater than 0 is redundant\r\n\r\n\r\n\r\n\r\n\r\n\r\n', 'commenter': 'EvanLjp'}, {'comment': ""Don't require `must`, that is the key. If the new agent propagates `0-xxx-xxx`, I hope the older agent still works, that is why I wrote this part as `>0`, and ask you to do `>1`."", 'commenter': 'wu-sheng'}, {'comment': 'I finally understand the key: the compatibility.', 'commenter': 'EvanLjp'}, {'comment': 'Yes, this kind of PR shows me the case is, the extension header may be used more in the future.', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -49,11 +64,23 @@ void deserialize(String value) {
         if (StringUtil.isEmpty(value)) {
             return;
         }
-        final String[] extensionParts = value.split(""-"");
+        String[] extensionParts = value.replaceAll(""-"", ""- "").split(""-"");","[{'comment': 'Please inject ` `(whitespace), rather than this strange `replaceAll`.', 'commenter': 'wu-sheng'}, {'comment': 'I may have misunderstood what you meant, thinking you meant to pass as few characters as possible. fix it later.', 'commenter': 'EvanLjp'}, {'comment': 'The size is not a concern, as we have injected a much bigger `sw8` header. ', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -28,18 +33,28 @@
  */
 public class ExtensionContext {
 
+    private static final ILog LOGGER = LogManager.getLogger(ExtensionContext.class);
     /**
      * Tracing Mode. If true means represents all spans generated in this context should skip analysis.
      */
     private boolean skipAnalysis;
 
+    /**
+     * The sending timestamp of the exit span.
+     */
+    @Getter
+    @Setter
+    private long sendingTimestamp;","[{'comment': 'Please use `Long` to separate real 0 and NULL.', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -49,11 +73,23 @@ void deserialize(String value) {
         if (StringUtil.isEmpty(value)) {
             return;
         }
-        final String[] extensionParts = value.split(""-"");
+        String[] extensionParts = value.split(SEPARATOR);","[{'comment': 'I think you misunderstand me, I mean no value should be represented by ` `, the separator should always be `-`.', 'commenter': 'wu-sheng'}]"
5666,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ExtensionContext.java,"@@ -100,11 +142,11 @@ public boolean equals(Object o) {
         if (o == null || getClass() != o.getClass())
             return false;
         ExtensionContext that = (ExtensionContext) o;
-        return skipAnalysis == that.skipAnalysis;
+        return skipAnalysis == that.skipAnalysis && sendingTimestamp == that.sendingTimestamp;","[{'comment': 'I think this equal is incorrect, as it is an object for now.', 'commenter': 'wu-sheng'}]"
5666,docs/en/protocols/Skywalking-Cross-Process-Propagation-Headers-Protocol-v3.md,"@@ -43,5 +43,7 @@ The current value includes fields.
 1. Tracing Mode. empty, 0 or 1. empty or 0 is default. 1 represents all spans generated in this context should skip analysis,
 `spanObject#skipAnalysis=true`. This context should be propagated to upstream in the default, unless it is changed in the 
 tracing process.
+2. The Exit span sending timestamp.  Space is the default. If the downstream timestamp was not space, the latency cost between downstream and upstream services
+   should be tagged in the entry spans of the upstream services.","[{'comment': '\r\n2. The timestamp of sending at the client side. This is used in async RPC such as MQ. Once it is set, the consumer side would calculate the latency between sending and receiving, and tag it in the span by using key `transmission.latency ` automatically.\r\n', 'commenter': 'wu-sheng'}]"
5690,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -185,4 +185,7 @@
 
     public static final OfficialComponent THRIFT_CLIENT = new OfficialComponent(101, ""thrift-client"");
 
+    public static final OfficialComponent ASYNC_HTTP_CLIENT = new OfficialComponent(102, ""AsyncHttpClient"");","[{'comment': 'This one should be added to the `skywalking/oap-server/server-bootstrap/src/main/resources/component-libraries.yml`', 'commenter': 'kezhenxu94'}, {'comment': 'OK,thanks.', 'commenter': 'zhentaoJin'}]"
5690,test/plugin/scenarios/asynchttpclient-scenario/support-version.list,"@@ -0,0 +1,17 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+2.10.0","[{'comment': 'Is this the only supported version?', 'commenter': 'wu-sheng'}, {'comment': 'As you documented, you support 2.x, then should be `2.0`, `2.1`... `2.10`.', 'commenter': 'wu-sheng'}, {'comment': 'Not only support this version, I will update the list of supported versions', 'commenter': 'zhentaoJin'}]"
5690,apm-sniffer/apm-sdk-plugin/asynchttpclient-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/asynchttpclient/v1/ExecuteInterceptor.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.asynchttpclient.v1;
+
+import io.netty.handler.codec.http.HttpHeaders;
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.asynchttpclient.Request;
+import org.asynchttpclient.uri.Uri;
+
+public class ExecuteInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                             Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+        final Request httpRequest = (Request) allArguments[0];
+        final Uri requestUri = httpRequest.getUri();
+
+        AbstractSpan span = ContextManager.createExitSpan(
+            ""AsyncHttpClient"" + requestUri.getPath(), requestUri.getHost() + "":"" + requestUri.getPort());
+
+        ContextCarrier contextCarrier = new ContextCarrier();
+        ContextManager.inject(contextCarrier);
+        span.setComponent(ComponentsDefine.ASYNC_HTTP_CLIENT);
+        Tags.HTTP.METHOD.set(span, httpRequest.getMethod());
+        Tags.URL.set(span, httpRequest.getUrl());
+        SpanLayer.asHttp(span);
+
+        final HttpHeaders headers = httpRequest.getHeaders();
+        CarrierItem next = contextCarrier.items();
+        while (next.hasNext()) {
+            next = next.next();
+            headers.add(next.getHeadKey(), next.getHeadValue());
+        }
+    }
+
+    @Override
+    public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                              Class<?>[] argumentsTypes, Object ret) throws Throwable {
+        ContextManager.stopSpan();
+        return ret;
+    }
+
+    @Override
+    public void handleMethodException(EnhancedInstance objInst, Method method, Object[] allArguments,
+                                      Class<?>[] argumentsTypes, Throwable t) {
+        ContextManager.activeSpan().errorOccurred().log(t);","[{'comment': '```suggestion\r\n        ContextManager.activeSpan()..log(t);\r\n```\r\n\r\nI think I have reminded this? `log` includes the `error` default today.', 'commenter': 'wu-sheng'}, {'comment': 'this is my fault. i will fix it.', 'commenter': 'zifeihan'}]"
5690,CHANGES.md,"@@ -14,6 +14,7 @@ Release Notes.
 * Make the Feign plugin to support Java 14
 * Make the okhttp3 plugin to support Java 14
 * Polish tracing context related codes.
+* Make the asynchttpclient 2.x plugin to support collecting HTTP parameters.","[{'comment': '```suggestion\r\n* Add the plugin for async-http-client 2.x\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'done', 'commenter': 'zhentaoJin'}]"
5690,apm-sniffer/apm-sdk-plugin/asynchttpclient-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/asynchttpclient/v1/AsyncHandlerWrapper.java,"@@ -0,0 +1,148 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.asynchttpclient.v1;
+
+import io.netty.channel.Channel;
+import io.netty.handler.codec.http.HttpHeaders;
+import java.net.InetSocketAddress;
+import java.util.List;
+import javax.net.ssl.SSLSession;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.asynchttpclient.AsyncCompletionHandlerBase;
+import org.asynchttpclient.AsyncHandler;
+import org.asynchttpclient.HttpResponseBodyPart;
+import org.asynchttpclient.HttpResponseStatus;
+import org.asynchttpclient.netty.request.NettyRequest;
+
+/**
+ * {@link AsyncHandlerWrapper} wrapper the {@link AsyncHandler} object for tracing.
+ * if userAsyncHandler is null, we will set {@link AsyncCompletionHandlerBase} to avoid NPE.
+ */
+public class AsyncHandlerWrapper implements AsyncHandler {
+
+    private final AsyncHandler userAsyncHandler;
+    private final AbstractSpan asyncSpan;
+
+    public AsyncHandlerWrapper(AsyncHandler asyncHandler, AbstractSpan span) {
+        this.userAsyncHandler = asyncHandler == null ? new AsyncCompletionHandlerBase() : asyncHandler;
+        this.asyncSpan = span;
+    }
+
+    @Override
+    public State onStatusReceived(final HttpResponseStatus httpResponseStatus) throws Exception {
+        return userAsyncHandler.onStatusReceived(httpResponseStatus);
+    }
+
+    @Override
+    public State onHeadersReceived(final HttpHeaders httpHeaders) throws Exception {
+        return userAsyncHandler.onHeadersReceived(httpHeaders);
+    }
+
+    @Override
+    public State onBodyPartReceived(final HttpResponseBodyPart httpResponseBodyPart) throws Exception {
+        return userAsyncHandler.onBodyPartReceived(httpResponseBodyPart);
+    }
+
+    @Override
+    public State onTrailingHeadersReceived(final HttpHeaders headers) throws Exception {
+        return userAsyncHandler.onTrailingHeadersReceived(headers);
+    }
+
+    @Override
+    public void onThrowable(final Throwable throwable) {
+        asyncSpan.log(throwable);
+        asyncSpan.asyncFinish();
+        userAsyncHandler.onThrowable(throwable);
+    }
+
+    @Override
+    public Object onCompleted() throws Exception {
+        asyncSpan.asyncFinish();
+        return userAsyncHandler.onCompleted();
+    }","[{'comment': 'Note that, must be avoided to interrupt the process of the application in the wrapper class.', 'commenter': 'dmsolr'}, {'comment': 'Thanks for reminding, it is really polished here', 'commenter': 'zhentaoJin'}, {'comment': 'done.', 'commenter': 'zifeihan'}]"
5690,apm-sniffer/apm-sdk-plugin/asynchttpclient-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/asynchttpclient/v1/ExecuteInterceptor.java,"@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.asynchttpclient.v1;
+
+import io.netty.handler.codec.http.HttpHeaders;
+import java.lang.reflect.Method;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+import org.asynchttpclient.AsyncHandler;
+import org.asynchttpclient.Request;
+import org.asynchttpclient.uri.Uri;
+
+/**
+ * interceptor for {@link org.asynchttpclient.DefaultAsyncHttpClient}
+ */
+public class ExecuteInterceptor implements InstanceMethodsAroundInterceptor {
+
+    @Override
+    public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allArguments,
+                             Class<?>[] argumentsTypes, MethodInterceptResult result) throws Throwable {
+
+        final Request httpRequest = (Request) allArguments[0];
+        final Uri requestUri = httpRequest.getUri();
+
+        AbstractSpan span = ContextManager.createExitSpan(
+            ""AsyncHttpClient"" + requestUri.getPath(), requestUri.getHost() + "":"" + requestUri.getPort());
+
+        /**
+         * We wrapper the allArguments[1] for get the real time duration, and stop the span.
+         */","[{'comment': 'Change to single-line comment', 'commenter': 'dmsolr'}, {'comment': 'done', 'commenter': 'zhentaoJin'}]"
5690,apm-sniffer/apm-sdk-plugin/asynchttpclient-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/asynchttpclient/v1/AsyncHandlerWrapper.java,"@@ -0,0 +1,148 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.asynchttpclient.v1;","[{'comment': 'what does the `v1` mean?', 'commenter': 'dmsolr'}, {'comment': 'The naming is really not very good, it has been modified', 'commenter': 'zhentaoJin'}]"
5690,apm-sniffer/apm-sdk-plugin/asynchttpclient-2.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/asynchttpclient/v1/AsyncHandlerWrapper.java,"@@ -0,0 +1,148 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.plugin.asynchttpclient.v1;
+
+import io.netty.channel.Channel;
+import io.netty.handler.codec.http.HttpHeaders;
+import java.net.InetSocketAddress;
+import java.util.List;
+import javax.net.ssl.SSLSession;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.asynchttpclient.AsyncCompletionHandlerBase;
+import org.asynchttpclient.AsyncHandler;
+import org.asynchttpclient.HttpResponseBodyPart;
+import org.asynchttpclient.HttpResponseStatus;
+import org.asynchttpclient.netty.request.NettyRequest;
+
+/**
+ * {@link AsyncHandlerWrapper} wrapper the {@link AsyncHandler} object for tracing.
+ * if userAsyncHandler is null, we will set {@link AsyncCompletionHandlerBase} to avoid NPE.
+ */
+public class AsyncHandlerWrapper implements AsyncHandler {
+
+    private final AsyncHandler userAsyncHandler;
+    private final AbstractSpan asyncSpan;
+
+    public AsyncHandlerWrapper(AsyncHandler asyncHandler, AbstractSpan span) {
+        this.userAsyncHandler = asyncHandler == null ? new AsyncCompletionHandlerBase() : asyncHandler;
+        this.asyncSpan = span;
+    }
+
+    @Override
+    public State onStatusReceived(final HttpResponseStatus httpResponseStatus) throws Exception {
+        return userAsyncHandler.onStatusReceived(httpResponseStatus);
+    }
+
+    @Override
+    public State onHeadersReceived(final HttpHeaders httpHeaders) throws Exception {
+        return userAsyncHandler.onHeadersReceived(httpHeaders);
+    }
+
+    @Override
+    public State onBodyPartReceived(final HttpResponseBodyPart httpResponseBodyPart) throws Exception {
+        return userAsyncHandler.onBodyPartReceived(httpResponseBodyPart);
+    }
+
+    @Override
+    public State onTrailingHeadersReceived(final HttpHeaders headers) throws Exception {
+        return userAsyncHandler.onTrailingHeadersReceived(headers);
+    }
+
+    @Override
+    public void onThrowable(final Throwable throwable) {
+        asyncSpan.log(throwable);
+        asyncSpan.asyncFinish();
+        userAsyncHandler.onThrowable(throwable);
+    }
+
+    @Override
+    public Object onCompleted() throws Exception {
+        asyncSpan.asyncFinish();","[{'comment': 'This method should be `try-catch`. This could trigger the exception if the plugin has bug, or the target lib has bug.', 'commenter': 'wu-sheng'}, {'comment': 'done. ', 'commenter': 'zifeihan'}]"
5707,oap-server/analyzer/agent-analyzer/src/test/java/org/apache/skywalking/oap/server/analyzer/provider/trace/TraceLatencyThresholdsAndWatcherTest.java,"@@ -0,0 +1,113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.analyzer.provider.trace;
+
+import java.util.Optional;
+import java.util.Set;
+import org.apache.skywalking.oap.server.analyzer.provider.AnalyzerModuleProvider;
+import org.apache.skywalking.oap.server.configuration.api.ConfigChangeWatcher;
+import org.apache.skywalking.oap.server.configuration.api.ConfigTable;
+import org.apache.skywalking.oap.server.configuration.api.ConfigWatcherRegister;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.runners.MockitoJUnitRunner;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.MatcherAssert.assertThat;
+
+@RunWith(MockitoJUnitRunner.class)
+public class TraceLatencyThresholdsAndWatcherTest {
+    private AnalyzerModuleProvider provider;
+
+    @Before
+    public void init() {
+        provider = new AnalyzerModuleProvider();
+    }
+
+    @Test
+    public void testInit() {
+        TraceLatencyThresholdsAndWatcher traceLatencyThresholdsAndWatcher = new TraceLatencyThresholdsAndWatcher(provider);
+        Assert.assertEquals(traceLatencyThresholdsAndWatcher.getSlowTraceSegmentThreshold(), 500);
+        Assert.assertEquals(traceLatencyThresholdsAndWatcher.value(), ""500"");
+    }
+
+    @Test(timeout = 20000)
+    public void testDynamicUpdate() throws InterruptedException {
+        ConfigWatcherRegister register = new MockConfigWatcherRegister(3);
+
+        TraceLatencyThresholdsAndWatcher watcher = new TraceLatencyThresholdsAndWatcher(provider);
+        register.registerConfigChangeWatcher(watcher);
+        register.start();
+
+        while (watcher.getSlowTraceSegmentThreshold() == 10000) {
+            Thread.sleep(2000);
+        }
+        assertThat(watcher.getSlowTraceSegmentThreshold(), is(1000));
+        assertThat(provider.getModuleConfig().getSlowTraceSegmentThreshold(), is(500));","[{'comment': ""why `is(500)`? Shouldn't it be `1000`?"", 'commenter': 'kezhenxu94'}, {'comment': ""hello, `provider.getModuleConfig().getSlowTraceSegmentThreshold()` is module config value, watcher can't change it. watcher has it own value."", 'commenter': 'zifeihan'}]"
5707,docs/en/setup/backend/configuration-vocabulary.md,"@@ -145,6 +145,7 @@ core|default|role|Option values, `Mixed/Receiver/Aggregator`. **Receiver** mode
 | - | - |forceSampleErrorSegment|When sampling mechanism activated, this config would make the error status segment sampled, ignoring the sampling rate.|SW_FORCE_SAMPLE_ERROR_SEGMENT|true|
 | - | - |segmentStatusAnalysisStrategy|Determine the final segment status from the status of spans. Available values are `FROM_SPAN_STATUS` , `FROM_ENTRY_SPAN` and `FROM_FIRST_SPAN`. `FROM_SPAN_STATUS` represents the segment status would be error if any span is in error status. `FROM_ENTRY_SPAN` means the segment status would be determined by the status of entry spans only. `FROM_FIRST_SPAN` means the segment status would be determined by the status of the first span only.|SW_SEGMENT_STATUS_ANALYSIS_STRATEGY|FROM_SPAN_STATUS|
 | - | - |noUpstreamRealAddressAgents|Exit spans with the component in the list would not generate the client-side instance relation metrics. As some tracing plugins can't collect the real peer ip address, such as Nginx-LUA and Envoy. |SW_NO_UPSTREAM_REAL_ADDRESS|6000,9000|
+| - | - |slowTraceSegmentThreshold|The threshold used to check the slow trace segment. Unit, millisecond.|SW_SLOW_TRACE_SEGMENT_THRESHOLD|2000|","[{'comment': '```suggestion\r\n| - | - |slowTraceSegmentThreshold|The threshold is used to check the slow trace segment. Unit, millisecond.|SW_SLOW_TRACE_SEGMENT_THRESHOLD|2000|\r\n```', 'commenter': 'kezhenxu94'}]"
5707,docs/en/setup/backend/dynamic-config.md,"@@ -12,6 +12,7 @@ Right now, SkyWalking supports following dynamic configurations.
 |core.default.apdexThreshold| The apdex threshold settings, will override `service-apdex-threshold.yml`. | same as [`service-apdex-threshold.yml`](apdex-threshold.md) |
 |core.default.endpoint-name-grouping| The endpoint name grouping setting, will override `endpoint-name-grouping.yml`. | same as [`endpoint-name-grouping.yml`](endpoint-grouping-rules.md) |
 |agent-analyzer.default.sampleRate| Trace sampling , override `receiver-trace/default/sampleRate` of `applciation.yml`. | 10000 |
+|agent-analyzer.default.slowTraceSegmentThreshold| The threshold used to check the slow trace segment, override `receiver-trace/default/slowTraceSegmentThreshold` of `applciation.yml`. | 2000 |","[{'comment': '```suggestion\r\n|agent-analyzer.default.slowTraceSegmentThreshold| The threshold is used to check the slow trace segment, override `receiver-trace/default/slowTraceSegmentThreshold` of `application.yml`. | 2000 |\r\n```\r\n\r\nplease also fix the typo at line 14 👆', 'commenter': 'kezhenxu94'}]"
5707,oap-server/server-bootstrap/src/main/resources/application.yml,"@@ -191,6 +191,7 @@ agent-analyzer:
     # Nginx and Envoy agents can't get the real remote address.
     # Exit spans with the component in the list would not generate the client-side instance relation metrics.
     noUpstreamRealAddressAgents: ${SW_NO_UPSTREAM_REAL_ADDRESS:6000,9000}
+    slowTraceSegmentThreshold: ${SW_SLOW_TRACE_SEGMENT_THRESHOLD:2000} # The threshold used to check the slow trace segment. Unit, millisecond.","[{'comment': '```suggestion\r\n    slowTraceSegmentThreshold: ${SW_SLOW_TRACE_SEGMENT_THRESHOLD:2000} # The threshold is used to check the slow trace segment. Unit, millisecond.\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'thanks for your review, done.', 'commenter': 'zifeihan'}]"
5707,docs/en/setup/backend/configuration-vocabulary.md,"@@ -145,6 +145,7 @@ core|default|role|Option values, `Mixed/Receiver/Aggregator`. **Receiver** mode
 | - | - |forceSampleErrorSegment|When sampling mechanism activated, this config would make the error status segment sampled, ignoring the sampling rate.|SW_FORCE_SAMPLE_ERROR_SEGMENT|true|
 | - | - |segmentStatusAnalysisStrategy|Determine the final segment status from the status of spans. Available values are `FROM_SPAN_STATUS` , `FROM_ENTRY_SPAN` and `FROM_FIRST_SPAN`. `FROM_SPAN_STATUS` represents the segment status would be error if any span is in error status. `FROM_ENTRY_SPAN` means the segment status would be determined by the status of entry spans only. `FROM_FIRST_SPAN` means the segment status would be determined by the status of the first span only.|SW_SEGMENT_STATUS_ANALYSIS_STRATEGY|FROM_SPAN_STATUS|
 | - | - |noUpstreamRealAddressAgents|Exit spans with the component in the list would not generate the client-side instance relation metrics. As some tracing plugins can't collect the real peer ip address, such as Nginx-LUA and Envoy. |SW_NO_UPSTREAM_REAL_ADDRESS|6000,9000|
+| - | - |slowTraceSegmentThreshold|The threshold is used to check the slow trace segment. Unit, millisecond.|SW_SLOW_TRACE_SEGMENT_THRESHOLD|2000|","[{'comment': 'The description is incorrect. What do you mean check slow trace?', 'commenter': 'wu-sheng'}, {'comment': 'This kind of description exists in many places.', 'commenter': 'wu-sheng'}]"
5707,CHANGES.md,"@@ -12,6 +12,7 @@ Release Notes.
 
 #### OAP-Backend
 * Add the `@SuperDataset` annotation for BrowserErrorLog.
+* Support the slowly segment in the sampling mechanism.","[{'comment': '```suggestion\r\n* Support keeping collecting the slowly segments in the sampling mechanism.\r\n```', 'commenter': 'wu-sheng'}]"
5722,CHANGES.md,"@@ -9,6 +9,7 @@ Release Notes.
 #### Java Agent
 
 #### OAP-Backend
+* Improve Kubernetes service registry fo ALS analysis.","[{'comment': 'fo? Typo?', 'commenter': 'wu-sheng'}, {'comment': '> fo? Typo?\r\n\r\n🤣 definitely, fixed', 'commenter': 'kezhenxu94'}]"
5722,oap-server/server-receiver-plugin/envoy-metrics-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/envoy/als/K8SServiceRegistry.java,"@@ -0,0 +1,217 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.envoy.als;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+import io.kubernetes.client.informer.ResourceEventHandler;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1Endpoints;
+import io.kubernetes.client.openapi.models.V1EndpointsList;
+import io.kubernetes.client.openapi.models.V1ObjectMeta;
+import io.kubernetes.client.openapi.models.V1Pod;
+import io.kubernetes.client.openapi.models.V1PodList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import lombok.extern.slf4j.Slf4j;
+
+import static java.util.Objects.isNull;
+import static java.util.Objects.requireNonNull;
+
+@Slf4j
+class K8SServiceRegistry {
+    final Map<String, ServiceMetaInfo> ipServiceMap;
+
+    final ExecutorService executor;
+
+    K8SServiceRegistry() {
+        ipServiceMap = new ConcurrentHashMap<>();
+        executor = Executors.newCachedThreadPool(
+            new ThreadFactoryBuilder()
+                .setNameFormat(""K8SServiceRegistry-%d"")
+                .setDaemon(true)
+                .build()
+        );
+    }
+
+    void start() throws IOException {
+        final ApiClient apiClient = Config.defaultClient();
+        apiClient.setHttpClient(apiClient.getHttpClient()
+                                         .newBuilder()
+                                         .readTimeout(0, TimeUnit.SECONDS)
+                                         .build());
+
+        final CoreV1Api coreV1Api = new CoreV1Api(apiClient);
+        final SharedInformerFactory factory = new SharedInformerFactory(executor);
+
+        listenEndpointsEvents(coreV1Api, factory);
+        listenPodEvents(coreV1Api, factory);
+
+        factory.startAllRegisteredInformers();
+    }
+
+    private void listenEndpointsEvents(final CoreV1Api coreV1Api, final SharedInformerFactory factory) {
+        factory.sharedIndexInformerFor(
+            params -> coreV1Api.listEndpointsForAllNamespacesCall(
+                null,
+                null,
+                null,
+                null,
+                null,
+                null,
+                params.resourceVersion,
+                params.timeoutSeconds,
+                params.watch,
+                null
+            ),
+            V1Endpoints.class,
+            V1EndpointsList.class
+        ).addEventHandler(new ResourceEventHandler<V1Endpoints>() {
+            @Override
+            public void onAdd(final V1Endpoints endpoints) {
+                addEndpoints(endpoints);
+            }
+
+            @Override
+            public void onUpdate(final V1Endpoints oldEndpoints, final V1Endpoints newEndpoints) {
+                addEndpoints(newEndpoints);
+            }
+
+            @Override
+            public void onDelete(final V1Endpoints endpoints, final boolean deletedFinalStateUnknown) {
+                removeEndpoints(endpoints);
+            }
+        });
+    }
+
+    private void listenPodEvents(final CoreV1Api coreV1Api, final SharedInformerFactory factory) {
+        factory.sharedIndexInformerFor(
+            params -> coreV1Api.listPodForAllNamespacesCall(
+                null,
+                null,
+                null,
+                null,
+                null,
+                null,
+                params.resourceVersion,
+                params.timeoutSeconds,
+                params.watch,
+                null
+            ),
+            V1Pod.class,
+            V1PodList.class
+        ).addEventHandler(new ResourceEventHandler<V1Pod>() {
+            @Override
+            public void onAdd(final V1Pod pod) {
+                addPod(pod);
+            }
+
+            @Override
+            public void onUpdate(final V1Pod oldPod, final V1Pod newPod) {
+                addPod(newPod);
+            }
+
+            @Override
+            public void onDelete(final V1Pod pod, final boolean deletedFinalStateUnknown) {
+                removePod(pod);
+            }
+        });
+    }
+
+    private void removePod(final V1Pod pod) {
+        log.debug(""Removing pod {}"", pod);
+
+        Optional.ofNullable(pod.getStatus()).ifPresent(
+            status -> ipServiceMap.remove(status.getPodIP())
+        );
+    }
+
+    private void addPod(final V1Pod pod) {
+        log.debug(""Adding pod {}"", pod);
+
+        Optional.ofNullable(pod.getStatus()).ifPresent(
+            status -> {
+                final String ip = status.getPodIP();
+                final ServiceMetaInfo service = ipServiceMap.computeIfAbsent(ip, unused -> new ServiceMetaInfo());
+
+                final V1ObjectMeta podMeta = requireNonNull(pod.getMetadata());
+                service.setServiceInstanceName(String.format(""%s.%s"", podMeta.getName(), podMeta.getNamespace()));
+                service.setTags(transformLabelsToTags(podMeta.getLabels()));
+            }
+        );
+    }
+
+    private void addEndpoints(final V1Endpoints endpoints) {
+        log.debug(""Adding endpoints {}"", endpoints);
+
+        final String serviceName = requireNonNull(endpoints.getMetadata()).getName();","[{'comment': 'We had better introduce a service name rule to format it. For instance, if some users want to append a version to the service name, they have to issue an expression, like `${service.name}-${pod.labels.version}`\r\n\r\nIf they deploy `bookinfo`, the service name of the service productpage might be `productpage-v1`, `producatpage-v2` and etc.', 'commenter': 'hanahmily'}, {'comment': 'I think the key is providing the format expression. Defaut should be only service name with version, correct?', 'commenter': 'wu-sheng'}, {'comment': 'Done', 'commenter': 'kezhenxu94'}]"
5722,oap-server/server-receiver-plugin/envoy-metrics-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/envoy/als/K8SServiceRegistry.java,"@@ -0,0 +1,217 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.envoy.als;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+import io.kubernetes.client.informer.ResourceEventHandler;
+import io.kubernetes.client.informer.SharedInformerFactory;
+import io.kubernetes.client.openapi.ApiClient;
+import io.kubernetes.client.openapi.apis.CoreV1Api;
+import io.kubernetes.client.openapi.models.V1Endpoints;
+import io.kubernetes.client.openapi.models.V1EndpointsList;
+import io.kubernetes.client.openapi.models.V1ObjectMeta;
+import io.kubernetes.client.openapi.models.V1Pod;
+import io.kubernetes.client.openapi.models.V1PodList;
+import io.kubernetes.client.util.Config;
+import java.io.IOException;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutorService;
+import java.util.concurrent.Executors;
+import java.util.concurrent.TimeUnit;
+import java.util.stream.Collectors;
+import lombok.extern.slf4j.Slf4j;
+
+import static java.util.Objects.isNull;
+import static java.util.Objects.requireNonNull;
+
+@Slf4j
+class K8SServiceRegistry {
+    final Map<String, ServiceMetaInfo> ipServiceMap;
+
+    final ExecutorService executor;
+
+    K8SServiceRegistry() {
+        ipServiceMap = new ConcurrentHashMap<>();
+        executor = Executors.newCachedThreadPool(
+            new ThreadFactoryBuilder()
+                .setNameFormat(""K8SServiceRegistry-%d"")
+                .setDaemon(true)
+                .build()
+        );
+    }
+
+    void start() throws IOException {
+        final ApiClient apiClient = Config.defaultClient();
+        apiClient.setHttpClient(apiClient.getHttpClient()
+                                         .newBuilder()
+                                         .readTimeout(0, TimeUnit.SECONDS)
+                                         .build());
+
+        final CoreV1Api coreV1Api = new CoreV1Api(apiClient);
+        final SharedInformerFactory factory = new SharedInformerFactory(executor);
+
+        listenEndpointsEvents(coreV1Api, factory);","[{'comment': '[Endpoint slice](https://kubernetes.io/docs/concepts/services-networking/endpoint-slices/) resources should be listened to either.', 'commenter': 'hanahmily'}, {'comment': ""@hanahmily even the [latest kubernetes-client](https://mvnrepository.com/artifact/io.kubernetes/client-java/10.0.0)(10.0.0, 27th, Oct, 2020) doesn't support to listen to the EndpointSlice events. There is no such API to do this 😢 Let's postponed this resource until the newer version can do this."", 'commenter': 'kezhenxu94'}, {'comment': 'If no listener, are you reading the data periodically like the old way?', 'commenter': 'wu-sheng'}, {'comment': ""> If no listener, are you reading the data periodically like the old way?\r\n\r\nNot now, as the doc says, EndpointSlice is to improve the performance of Endpoints, so I think it's OK to just ignore this kind of event for now, (p.s. EndpointSlice is still in beta now), is it OK @hanahmily ?"", 'commenter': 'kezhenxu94'}, {'comment': ""If java client doesn't support it right now, feel free to leave it alone. But we should mention it in our document and leave `todo` market in codes."", 'commenter': 'hanahmily'}, {'comment': 'How about submitting a request to k8s java client repo about listen to the EndpointSlice ?', 'commenter': 'wu-sheng'}, {'comment': 'They may need a scenario about which java codes need this.', 'commenter': 'wu-sheng'}, {'comment': ""> How about submitting a request to k8s java client repo about listen to the EndpointSlice ?\r\n\r\nI'm thinking that they don't support it only because EndpointSlice is still in beta(after stabilization, they will), and the methods to list/watch that resources are unstable now, (e.g. need the `apiGroup`, `version`, which are changing for an alpha/beta feature).\r\n\r\nIMO, ignoring EndpointSlice for now is safe because the docs says\r\n\r\n> Although the EndpointSlice API is providing a newer and more scalable alternative to the Endpoints API, the Endpoints API will continue to be considered generally available and stable."", 'commenter': 'kezhenxu94'}, {'comment': 'We can revamp this after the EndpointSlice API is stabilised', 'commenter': 'kezhenxu94'}, {'comment': 'My point is only creating an issue to track this todo as backlog.', 'commenter': 'wu-sheng'}]"
5775,tools/dependencies/known-oap-backend-dependencies-es7.txt,"@@ -29,14 +29,18 @@ curator-client-4.0.1.jar
 curator-framework-4.0.1.jar
 curator-recipes-4.0.1.jar
 curator-x-discovery-4.0.1.jar
-elasticsearch-7.0.0.jar
-elasticsearch-cli-7.0.0.jar
-elasticsearch-core-7.0.0.jar
-elasticsearch-geo-7.0.0.jar
-elasticsearch-rest-client-7.0.0.jar
-elasticsearch-rest-high-level-client-7.0.0.jar
-elasticsearch-secure-sm-7.0.0.jar
-elasticsearch-x-content-7.0.0.jar
+elasticsearch-7.5.0.jar
+elasticsearch-cli-7.5.0.jar
+elasticsearch-core-7.5.0.jar
+elasticsearch-geo-7.5.0.jar
+elasticsearch-rest-client-7.5.0.jar
+elasticsearch-rest-high-level-client-7.5.0.jar
+elasticsearch-secure-sm-7.5.0.jar
+elasticsearch-x-content-7.5.0.jar
+lang-mustache-client-7.5.0.jar
+mapper-extras-client-7.5.0.jar
+parent-join-client-7.5.0.jar
+rank-eval-client-7.5.0.jar","[{'comment': 'You need to update LICENSE including\r\n1. Versions of `lang-mustache-client` and `parent-join-client` \r\n1. Add `mapper-extras-client` with license as we missed before\r\n1. Add `rank-eval-client` with license as we missed before, both 6.3.2(es6 package) and 7.5.0(you updated)', 'commenter': 'wu-sheng'}]"
5775,dist-material/release-docs/LICENSE,"@@ -233,9 +233,13 @@ The text of each license is the standard Apache 2.0 license.
     Google: proto-google-common-protos 1.17.0: https://github.com/googleapis/googleapis , Apache 2.0
     Google: jsr305 3.0.2: http://central.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.0/jsr305-3.0.0.pom , Apache 2.0
     Elasticsearch BV (Elasticsearch) 6.3.2: https://www.elastic.co/products/elasticsearch , Apache 2.0
-    Elasticsearch BV (Elasticsearch) 7.0.0: https://www.elastic.co/products/elasticsearch , Apache 2.0
-    lang-mustache-client 5.5.0: https://github.com/elastic/elasticsearch/tree/master/modules/lang-mustache , Apache 2.0
-    parent-join-client 5.5.0: https://github.com/elastic/elasticsearch/tree/master/modules/parent-join , Apache 2.0
+    Elasticsearch BV (Elasticsearch) 7.5.0: https://www.elastic.co/products/elasticsearch , Apache 2.0","[{'comment': '```\r\nElasticsearch BV (Elasticsearch) 6.3.2, 7.5.0: https://www.elastic.co/products/elasticsearch , Apache 2.0\r\n```\r\nFor multiple versions, should be like this.', 'commenter': 'wu-sheng'}, {'comment': 'done.', 'commenter': 'zifeihan'}]"
5842,apm-sniffer/apm-sdk-plugin/mssql-jtds-1.x-plugin/pom.xml,"@@ -0,0 +1,51 @@
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>apm-sdk-plugin</artifactId>
+        <groupId>org.apache.skywalking</groupId>
+        <version>8.3.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>apm-mssql-jtds-1.x-plugin</artifactId>
+    <packaging>jar</packaging>
+
+    <name>mssql-jtds-1.x-plugin</name>
+    <url>http://maven.apache.org</url>
+
+    <properties>
+        <mssql-jtds.version>1.2.6</mssql-jtds.version>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>apm-jdbc-commons</artifactId>
+            <version>${project.version}</version>
+            <scope>provided</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>net.sourceforge.jtds</groupId>
+            <artifactId>jtds</artifactId>
+            <version>${mssql-jtds.version}</version>
+        </dependency>","[{'comment': 'Should be `provided` scope', 'commenter': 'kezhenxu94'}, {'comment': 'fixed.', 'commenter': 'zifeihan'}]"
5842,docs/en/setup/service-agent/java-agent/Plugin-list.md,"@@ -109,3 +109,5 @@
 - vertx-core-3.x
 - xxl-job-2.x
 - zookeeper-3.4.x
+- zookeeper-3.4.x","[{'comment': 'Duplicated?', 'commenter': 'wu-sheng'}, {'comment': 'fixed.', 'commenter': 'zifeihan'}]"
5842,oap-server/server-bootstrap/src/main/resources/component-libraries.yml,"@@ -537,4 +540,5 @@ Component-Server-Mappings:
   influxdb-java: InfluxDB
   Predis: Redis
   PyMysql: Mysql
-  spring-kafka-consumer: kafka-consumer
\ No newline at end of file
+  spring-kafka-consumer: kafka-consumer
+  mssql-jdbc-driver: SqlServer","[{'comment': '```\r\nSqlServer:\r\n  id: 3006\r\n  languages: C#\r\n```\r\nSqlServer language should be updated.', 'commenter': 'wu-sheng'}, {'comment': 'fixed.', 'commenter': 'zifeihan'}]"
5842,.github/workflows/plugins-test.0.yaml,"@@ -70,6 +70,7 @@ jobs:
           - gson-scenario
           - elasticjob-3.x-scenario
           - springmvc-reactive-scenario
+          - mssql-jtds-scenario","[{'comment': 'Put this in file `plugins-test.1.yaml`', 'commenter': 'kezhenxu94'}, {'comment': 'fixed.', 'commenter': 'zifeihan'}]"
5842,apm-sniffer/apm-sdk-plugin/mssql-jtds-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/mssql/jtds/v1/define/ConnectionJDBC2Instrumentation.java,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.mssql.jtds.v1.define;
+
+import org.apache.skywalking.apm.agent.core.plugin.match.ClassMatch;
+
+import static org.apache.skywalking.apm.agent.core.plugin.match.NameMatch.byName;
+
+/**
+ * {@link ConnectionJDBC2Instrumentation} presents that skywalking intercepts {@link net.sourceforge.jtds.jdbc.ConnectionJDBC2}.
+ */
+public class ConnectionJDBC2Instrumentation extends AbstractConnectionInstrumentation {
+    public static final String ENHANCE_CLASS = ""net.sourceforge.jtds.jdbc.ConnectionJDBC2"";
+
+    @Override
+    protected ClassMatch enhanceClass() {
+        return byName(ENHANCE_CLASS);","[{'comment': ""Why not use `org.apache.skywalking.apm.agent.core.plugin.match.MultiClassNameMatch` so that you don't need several subclasses?"", 'commenter': 'kezhenxu94'}, {'comment': 'fixed.', 'commenter': 'zifeihan'}]"
5842,apm-sniffer/apm-sdk-plugin/mssql-jtds-1.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/mssql/jtds/v1/define/AbstractConnectionInstrumentation.java,"@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.mssql.jtds.v1.define;
+
+import net.bytebuddy.description.method.MethodDescription;
+import net.bytebuddy.matcher.ElementMatcher;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.ConstructorInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.InstanceMethodsInterceptPoint;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.ClassInstanceMethodsEnhancePluginDefine;
+import org.apache.skywalking.apm.plugin.jdbc.define.Constants;
+
+import static net.bytebuddy.matcher.ElementMatchers.named;
+import static net.bytebuddy.matcher.ElementMatchers.takesArguments;
+
+/**
+ * {@link AbstractConnectionInstrumentation} define how to enhance the following methods that the class which extend
+ * {@link java.sql.Connection}.
+ * <p>
+ * 1. Enhance <code>prepareStatement</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.JDBCPrepareStatementInterceptor</code>
+ * 3. Enhance <code>prepareCall</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.JDBCPrepareCallInterceptor</code>
+ * 4. Enhance <code>createStatement</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.JDBCStatementInterceptor</code>
+ * 5. Enhance <code>commit, rollback, close, releaseSavepoint</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.ConnectionServiceMethodInterceptor</code>","[{'comment': '```suggestion\r\n * 1. Enhance <code>prepareStatement</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.JDBCPrepareStatementInterceptor</code>\r\n * 2. Enhance <code>prepareCall</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.JDBCPrepareCallInterceptor</code>\r\n * 3. Enhance <code>createStatement</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.JDBCStatementInterceptor</code>\r\n * 4. Enhance <code>commit, rollback, close, releaseSavepoint</code> by <code>org.apache.skywalking.apm.plugin.jdbc.define.ConnectionServiceMethodInterceptor</code>\r\n```', 'commenter': 'kezhenxu94'}]"
5879,test/plugin/scenarios/spring-kafka-1.3.x-scenario/support-version.list,"@@ -0,0 +1,17 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+1.3.11.RELEASE","[{'comment': 'please add some little other version to prove support `1.3.x` ', 'commenter': 'zhaoyuguang'}, {'comment': 'Now three latest versions of 1.3.x are used to better prove the idea.', 'commenter': 'lujiajing1126'}]"
5879,CHANGES.md,"@@ -21,6 +21,7 @@ Release Notes.
 * Add the plugin for mssql-jtds 1.x.
 * Add the plugin for mssql-jdbc 6.x -> 9.x.
 * Fix the default ignore mechanism isn't accurate enough bug.
+* Add the plugin for spring-kafka 1.x.","[{'comment': 'I think you indicate 1.3.x only? At least tested? Do I miss anything?', 'commenter': 'wu-sheng'}, {'comment': '> I think you indicate 1.3.x only? At least tested? Do I miss anything?\r\n\r\nYes. You are right, we have only tested 1.3.x. Changed.', 'commenter': 'lujiajing1126'}]"
5886,apm-sniffer/optional-plugins/optional-spring-plugins/spring-webflux-5.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/webflux/v5/DispatcherHandlerHandleMethodInterceptor.java,"@@ -77,13 +77,14 @@ public void beforeMethod(EnhancedInstance objInst, Method method, Object[] allAr
         exchange.getAttributes().put(""SKYWALING_SPAN"", span);
     }
     
-    private void setPattern(AbstractSpan span, ServerWebExchange exchange) {
+    private void maybeSetPattern(AbstractSpan span, ServerWebExchange exchange) {
         if (span != null) {
-            Object pathPattern = exchange.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE);
-            if (pathPattern != null) {
-                span.setOperationName(((PathPattern) pathPattern).getPatternString());
+            PathPattern pathPattern = exchange.getAttribute(HandlerMapping.BEST_MATCHING_PATTERN_ATTRIBUTE);
+            if (pathPattern != null && pathPattern.matches(exchange.getRequest().getPath().pathWithinApplication())) {","[{'comment': 'What does `pathPattern.matches(exchange.getRequest().getPath().pathWithinApplication())` mean? Could you add comments about this?', 'commenter': 'wu-sheng'}]"
5886,apm-sniffer/optional-plugins/optional-spring-plugins/spring-webflux-5.x-plugin/src/main/java/org/apache/skywalking/apm/plugin/spring/webflux/v5/DispatcherHandlerHandleMethodInterceptor.java,"@@ -93,14 +94,11 @@ public Object afterMethod(EnhancedInstance objInst, Method method, Object[] allA
 
         AbstractSpan span = (AbstractSpan) exchange.getAttributes().get(""SKYWALING_SPAN"");
         
-        return ((Mono) ret).flatMap(s -> {
-                    setPattern(span, exchange);
-                    return s;
-                 })
-                .doOnError(s -> setPattern(span, exchange))
+                return ((Mono) ret)","[{'comment': 'Is this the right format? I am feeling not. Could you confirm? Rather than waste CI resources.', 'commenter': 'wu-sheng'}, {'comment': ""slightly changed code style so to doesn't looks weird now。"", 'commenter': 'yujiaxinlong'}]"
5989,apm-sniffer/apm-sdk-plugin/thrift-plugin/src/main/java/org/apache/skywalking/apm/plugin/thrift/wrapper/ServerInProtocolWrapper.java,"@@ -57,10 +64,11 @@ public void initial(AbstractContext context) {
     @Override
     public TField readFieldBegin() throws TException {
         final TField field = super.readFieldBegin();
+        Map<String, String> header = new HashMap<>(1);","[{'comment': ""The variable is visible in the if statement block. So we don't need to move it out of the if statement block.\r\n"", 'commenter': 'dmsolr'}, {'comment': 'done', 'commenter': 'ZS-Oliver'}]"
5989,apm-sniffer/apm-sdk-plugin/thrift-plugin/src/main/java/org/apache/skywalking/apm/plugin/thrift/wrapper/ServerInProtocolWrapper.java,"@@ -81,6 +90,20 @@ public TField readFieldBegin() throws TException {
             }
             return readFieldBegin();
         }
+        if (field.type == TType.STOP && !HAVE_CREATED.get()) {","[{'comment': 'Would you try to do it without `ThreadLocal`?', 'commenter': 'dmsolr'}, {'comment': ""I don't recommend to use `ThreadLocal` here."", 'commenter': 'dmsolr'}, {'comment': '@ZS-Oliver Could you explain why do you need this? Are there many wrapper instances or something?', 'commenter': 'wu-sheng'}, {'comment': ""sorry，I took leave on Friday and didn't go to work，I will update on Monday.  happy weekend !"", 'commenter': 'ZS-Oliver'}, {'comment': 'I saw ServerInProtocolWrapper was initialized in TServerInterceptor.onConstruct.\r\nThe method onConstruct was called when an intercept construction method is called.\r\nI use ThreadLocal to do the isolation, because I think this behavior will only be invoked once during the enhancement.\r\nAre there any better way to implement this ?', 'commenter': 'ZS-Oliver'}, {'comment': 'LGTM, Thanks @ZS-Oliver ', 'commenter': 'dmsolr'}]"
5989,apm-sniffer/apm-sdk-plugin/thrift-plugin/src/main/java/org/apache/skywalking/apm/plugin/thrift/wrapper/ServerInProtocolWrapper.java,"@@ -45,6 +45,7 @@
     private static final ILog LOGGER = LogManager.getLogger(ServerInProtocolWrapper.class);
     private static final StringTag TAG_ARGS = new StringTag(""args"");
     private AbstractContext context;
+    private static ThreadLocal<Boolean> HAVE_CREATED = ThreadLocal.withInitial(() -> Boolean.FALSE);","[{'comment': 'TracingContext has native running context for this case, could you consider to use that? It could be auto cleared when the tracing context finished.', 'commenter': 'wu-sheng'}, {'comment': 'It seems like the life cycle of a TraceContext is exactly one trace. Thinking of such a circumstance that we have A, B, C three services and they are inter-communicated through RPC like A->B->C, with both A and C mounted the Agent while B not. Then, in the above situation, C will start a new trace since the trace from A is stopped at B. Hence, C could not obsever A with the use of TraceContext.', 'commenter': 'ZS-Oliver'}, {'comment': ""How is your description relating to what I asked? I am talking about don't your own threadlocal, use the one core provided. Do you misunderstand somehow?"", 'commenter': 'wu-sheng'}, {'comment': 'SkyWalking provides a safe `RuntimeContext` which is alive during a tracing. So we prefer to use this rather than directly ThreadLocal. \r\nMore details see `ContextManager#getRuntimeContext()`, please.', 'commenter': 'dmsolr'}, {'comment': 'Sorry,  I misunderstand in some aspect.\r\nThanks for your advice.', 'commenter': 'ZS-Oliver'}]"
5989,CHANGES.md,"@@ -12,6 +12,7 @@ Release Notes.
 * The operation name of quartz-scheduler plugin, has been changed as the `quartz-scheduler/${className}` format.
 * Fix jdk-http and okhttp-3.x plugin did not overwrite the old trace header.
 * Support collecting logs of log4j, log4j2, and logback in the tracing context with a new `logger-plugin`.
+* Fix thrift plugin trace link broken when intermediate service does not mount agent, and collect wrong args when method without parameters.","[{'comment': '```suggestion\r\n* Fix thrift plugin trace link broken when intermediate service does not mount agent\r\n* Fix thrift plugin collects wrong args when the method without parameter.\r\n```', 'commenter': 'wu-sheng'}, {'comment': '2lines of changelog seem more clear. Agree?', 'commenter': 'wu-sheng'}, {'comment': '👍 ', 'commenter': 'ZS-Oliver'}]"
5989,apm-sniffer/apm-sdk-plugin/thrift-plugin/src/main/java/org/apache/skywalking/apm/plugin/thrift/wrapper/ServerInProtocolWrapper.java,"@@ -81,6 +84,24 @@ public TField readFieldBegin() throws TException {
             }
             return readFieldBegin();
         }
+        if (field.type == TType.STOP) {
+            boolean haveCreatedSpan =
+                    (boolean) ContextManager.getRuntimeContext().get(HAVE_CREATED_SPAN);","[{'comment': 'I think there is an NPE risk.\r\n```suggestion\r\n            Boolean haveCreatedSpan =\r\n                    ContextManager.getRuntimeContext().get(HAVE_CREATED_SPAN);\r\n```\r\nAnd you should check `haveCreatedSpan != null && !haveCreatedSpan`, agree? ', 'commenter': 'wu-sheng'}, {'comment': ""If this context doesn't exist, then it could not change to `boolean`."", 'commenter': 'wu-sheng'}, {'comment': 'I think I forgot to initialize, Otherwise haveCreatedSpan cannot be false.\r\nI think Object cannot auto cast to Boolean.', 'commenter': 'ZS-Oliver'}, {'comment': ""I don't say any object. I was saying null casting to Boolean rather than boolean. "", 'commenter': 'wu-sheng'}, {'comment': '👍 , done', 'commenter': 'ZS-Oliver'}]"
5989,apm-sniffer/apm-sdk-plugin/thrift-plugin/src/main/java/org/apache/skywalking/apm/plugin/thrift/wrapper/ServerInProtocolWrapper.java,"@@ -81,6 +85,24 @@ public TField readFieldBegin() throws TException {
             }
             return readFieldBegin();
         }
+        if (field.type == TType.STOP) {
+            Boolean haveCreatedSpan =
+                    (Boolean) ContextManager.getRuntimeContext().get(HAVE_CREATED_SPAN);
+            if (!haveCreatedSpan) {","[{'comment': 'This is still an NPE risk. Take a look at my previous comment. If you are using `Boolean`, you need to `haveCreatedSpan != null &&` first.\r\n\r\nIf you are not familiar with auto-unboxing in Java, take a look at this, https://stackoverflow.com/questions/55100449/unexpected-nullpointerexception-while-autoboxing-unboxing-java-long-type-as-re\r\n', 'commenter': 'wu-sheng'}, {'comment': 'I think I\'ve initialize ""haveCreatedSpan"" in initial(), so it would\'t be NPE.\r\nBut It is necessary to add a precaution. Good advice. ', 'commenter': 'ZS-Oliver'}, {'comment': 'Yes, just be preciseness. :)', 'commenter': 'wu-sheng'}]"
6091,docs/en/setup/envoy/examples/metrics/docker-compose.yaml,"@@ -17,7 +17,7 @@
 version: ""3""
 services:
   envoy:
-    image: envoyproxy/envoy-alpine:latest
+    image: envoyproxy/envoy-alpine:v1.16.2","[{'comment': ""Envoy now doesn't have a latest tag, and pinning the image version is a good practice IMO."", 'commenter': 'kezhenxu94'}]"
6091,oap-server/analyzer/meter-analyzer/src/main/java/org/apache/skywalking/oap/meter/analyzer/prometheus/PrometheusMetricConverter.java,"@@ -141,6 +141,11 @@ public void toMeter(Stream<Metric> metricStream) {
         if (ss.length < 1) {
             return Optional.empty();
         }
-        return Optional.of(Tuple.of(metric.getName(), SampleFamilyBuilder.newBuilder(ss).build()));
+        return Optional.of(Tuple.of(escapedName(metric.getName()), SampleFamilyBuilder.newBuilder(ss).build()));
+    }
+
+    // Returns the escaped name of the given one, with ""."" replaced by ""_""
+    protected String escapedName(final String name) {
+        return name.replaceAll(""\\."", ""_"");
     }","[{'comment': 'Metrics names in Envoy contain `.`, hence this is necessary', 'commenter': 'kezhenxu94'}]"
6091,oap-server/server-bootstrap/src/main/resources/otel-oc-rules/istio-controlplane.yaml,"@@ -28,7 +28,7 @@
 #    ""-P6H3M""    -- parses as ""-6 hours and -3 minutes""
 #    ""-P-6H+3M""  -- parses as ""+6 hours and -3 minutes""
 # </pre>
-expSuffix: tag({tags -> tags.cluster = 'istio-ctrl::' + tags.cluster}).service(['cluster', 'app'])","[{'comment': 'Does this make sense @hanahmily ? Seems both control plane and data plane all share the same ""serviceGroup"" in ""oap-server/server-bootstrap/src/main/resources/ui-initialized-templates/istio.yml""', 'commenter': 'kezhenxu94'}, {'comment': 'This rule file intends to ingest metrics from different Kubernetes clusters, not identify control plane and data plane. There might be more than one cluster when two different OT collectors transfer metrics to the OAP cluster. ', 'commenter': 'hanahmily'}]"
6091,oap-server/server-bootstrap/src/main/resources/application.yml,"@@ -266,6 +266,7 @@ envoy-metric:
     # to append the version number to the service name.
     # Be careful, when using environment variables to pass this configuration, use single quotes(`''`) to avoid it being evaluated by the shell.
     k8sServiceNameRule: ${K8S_SERVICE_NAME_RULE:""${service.metadata.name}""}
+    enabledMALRules: ${SW_ENVOY_METRIC_MAL_RULES:""envoy""}","[{'comment': 'Why need this? Could we disable through `SW_ENVOY_METRIC=-`?', 'commenter': 'wu-sheng'}, {'comment': '> Why need this? Could we disable through `SW_ENVOY_METRIC=-`?\r\n\r\nWe could disable through `SW_ENVOY_METRIC=-` but I thought this was not for disabling, it shares the same idea as https://github.com/apache/skywalking/issues/5853 , we may need this for the same reason as #5853 , do we?', 'commenter': 'kezhenxu94'}, {'comment': ""What is this related to the #5853 ? Could you be more clear? That issue is asking for adding group for all services involved in the specific dashboard.\r\nSuch as envoy service should include a `group` name in name definition, then they wouldn't show up in other dashboard's service list."", 'commenter': 'wu-sheng'}, {'comment': ':( I pasted the wrong issue number, should be https://github.com/apache/skywalking/issues/5035 and https://github.com/apache/skywalking/issues/5530', 'commenter': 'kezhenxu94'}, {'comment': ""I think this would be a little different actually. I can't see the chance of multiple rule config files in `metric-receiver`. All those two are only general receiver, you could have data from different sources."", 'commenter': 'wu-sheng'}, {'comment': 'OK, removed', 'commenter': 'kezhenxu94'}]"
6091,oap-server/server-receiver-plugin/envoy-metrics-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/envoy/metrics/adapters/ProtoMetricFamily2MetricsAdapter.java,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.envoy.metrics.adapters;
+
+import io.prometheus.client.Metrics;
+import java.util.Map;
+import java.util.stream.Stream;
+import lombok.RequiredArgsConstructor;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Gauge;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Metric;
+
+import static java.util.stream.Collectors.toMap;
+
+@RequiredArgsConstructor
+public class ProtoMetricFamily2MetricsAdapter {
+    protected final Metrics.MetricFamily metricFamily;
+
+    public Stream<Metric> adapt() {
+        // TODO: should adapt more types
+        switch (metricFamily.getType()) {","[{'comment': '*NULL_DEREFERENCE:*  object returned by `ProtoMetricFamily2MetricsAdapter.metricFamily.getType()` could be null and is dereferenced at line 36.', 'commenter': 'sonatype-lift[bot]'}, {'comment': ""Can't be null actually"", 'commenter': 'kezhenxu94'}]"
6091,oap-server/server-bootstrap/src/main/resources/ui-initialized-templates/istio-dp.yml,"@@ -0,0 +1,82 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+templates:
+  - name: ""Istio Data Plane""","[{'comment': 'I am good with this name. @hanahmily Please review from tech perspective, especially MAL integration.', 'commenter': 'wu-sheng'}]"
6091,test/e2e/e2e-test/src/test/resources/expected/metricsservice/services.yml,"@@ -0,0 +1,28 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+services:
+  - key: not null
+    label: istio-dp::ratings.default
+  - key: not null
+    label: istio-dp::reviews.default
+  - key: not null
+    label: istio-dp::productpage.default
+  - key: not null
+    label: istio-dp::details.default
+  - key: not null
+    label: istio-dp::istio-ingressgateway","[{'comment': ""Such as this one should be same as ALS did. https://github.com/apache/skywalking/blob/1b1f08511ccb8542d96f29dcaee72c73492b74f9/test/e2e/e2e-test/src/test/resources/expected/als/services.yml#L16-L26\r\n\r\nMore importantly, the instance name should be pod's name."", 'commenter': 'wu-sheng'}, {'comment': 'This is `services.yaml`, not instances', 'commenter': 'kezhenxu94'}, {'comment': ""I know. I just take an example, because we don't verify the instance name in the test. The point is, we need ALS and MetricsService analysis results share the same naming rule."", 'commenter': 'wu-sheng'}]"
6091,oap-server/server-receiver-plugin/envoy-metrics-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/envoy/MetricServiceGRPCHandler.java,"@@ -79,17 +93,15 @@ public void onNext(StreamMetricsMessage message) {
                     isFirst = false;
                     StreamMetricsMessage.Identifier identifier = message.getIdentifier();
                     Node node = identifier.getNode();
-                    if (node != null) {
-                        String nodeId = node.getId();
-                        if (!StringUtil.isEmpty(nodeId)) {
-                            serviceInstanceName = nodeId;
-                        }
-                        String cluster = node.getCluster();
-                        if (!StringUtil.isEmpty(cluster)) {
-                            serviceName = cluster;
-                            if (serviceInstanceName == null) {
-                                serviceInstanceName = serviceName;
-                            }
+                    String nodeId = node.getId();
+                    if (!StringUtil.isEmpty(nodeId)) {
+                        serviceInstanceName = nodeId;
+                    }
+                    String cluster = node.getCluster();
+                    if (!StringUtil.isEmpty(cluster)) {
+                        serviceName = cluster;
+                        if (serviceInstanceName == null) {
+                            serviceInstanceName = serviceName;","[{'comment': 'This is the logic we used to do, but I think we should share the ALS logic. Then in future integration, the entity names of sidecar metrics will be as same as the traffic related metrics.', 'commenter': 'wu-sheng'}, {'comment': ""The service names in metrics service have a service group prefix (`istio-dp::`) while those in ALS don't have, do we want to add service group in ALS as well?"", 'commenter': 'kezhenxu94'}]"
6091,oap-server/server-receiver-plugin/envoy-metrics-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/envoy/MetricServiceGRPCHandler.java,"@@ -60,111 +69,65 @@ public MetricServiceGRPCHandler(ModuleManager moduleManager) {
             ""envoy_metric_in_latency"", ""The process latency of service metrics receiver"", MetricsTag.EMPTY_KEY,
             MetricsTag.EMPTY_VALUE
         );
+
+        final MeterSystem meterSystem = moduleManager.find(CoreModule.NAME).provider().getService(MeterSystem.class);
+
+        converters = config.rules()
+                           .stream()
+                           .map(rule -> new PrometheusMetricConverter(rule, meterSystem))
+                           .collect(Collectors.toList());
     }
 
     @Override
     public StreamObserver<StreamMetricsMessage> streamMetrics(StreamObserver<StreamMetricsResponse> responseObserver) {
         return new StreamObserver<StreamMetricsMessage>() {
             private volatile boolean isFirst = true;
-            private String serviceName = null;
-            private String serviceInstanceName = null;
+            private ServiceMetaInfo service;
 
             @Override
+            @SneakyThrows
             public void onNext(StreamMetricsMessage message) {
                 if (log.isDebugEnabled()) {
                     log.debug(""Received msg {}"", message);
                 }
 
                 if (isFirst) {
                     isFirst = false;
-                    StreamMetricsMessage.Identifier identifier = message.getIdentifier();
-                    Node node = identifier.getNode();
-                    if (node != null) {
-                        String nodeId = node.getId();
-                        if (!StringUtil.isEmpty(nodeId)) {
-                            serviceInstanceName = nodeId;
-                        }
-                        String cluster = node.getCluster();
-                        if (!StringUtil.isEmpty(cluster)) {
-                            serviceName = cluster;
-                            if (serviceInstanceName == null) {
-                                serviceInstanceName = serviceName;
-                            }
-                        }
-                    }
-
-                    if (serviceName == null) {
-                        serviceName = serviceInstanceName;
-                    }
+                    service = new ServiceMetaInfoAdapter(message.getIdentifier().getNode().getMetadata());","[{'comment': '`ServiceMetaInfoAdapter` is for meta exchange only, right? Where is the ip-mapping mechanism?', 'commenter': 'wu-sheng'}]"
6091,.github/workflows/e2e.istio.yaml,"@@ -129,3 +129,93 @@ jobs:
       - name: Clean up
         if: ${{ always() }}
         run: minikube delete
+
+  metrics-service:
+    runs-on: ubuntu-16.04
+    timeout-minutes: 60
+    name: MetricsService
+    steps:
+      - uses: actions/checkout@v2
+        with:
+          submodules: true
+
+      - uses: actions/cache@v2
+        with:
+          path: ~/.m2/repository
+          key: ${{ runner.os }}-maven-${{ hashFiles('**/pom.xml') }}
+          restore-keys: ${{ runner.os }}-maven-
+
+      - name: Build Docker Image
+        run: make docker
+
+      - name: Prepare envrionment
+        run: bash ${SCRIPTS_DIR}/pre.sh
+
+      - name: Install Minikube
+        run: bash ${SCRIPTS_DIR}/minikube.sh start
+
+      - name: Install Istio
+        run: bash ${SCRIPTS_DIR}/istio.sh --set profile=demo --set meshConfig.defaultConfig.envoyMetricsService.address=skywalking-oap.istio-system:11800","[{'comment': ""I assume meta-exchange is default ON by today's Istio, right? I think we need to disable it manually?"", 'commenter': 'wu-sheng'}, {'comment': 'And e2e fails, please recheck.', 'commenter': 'wu-sheng'}]"
6091,oap-server/analyzer/meter-analyzer/src/main/java/org/apache/skywalking/oap/meter/analyzer/dsl/SampleFamily.java,"@@ -161,12 +162,32 @@ public SampleFamily div(SampleFamily another) {
 
     /* Aggregation operators */
     public SampleFamily sum(List<String> by) {
+        return aggregate(by, Double::sum);
+    }
+
+    public SampleFamily max(List<String> by) {
+        return aggregate(by, Double::max);
+    }
+
+    public SampleFamily min(List<String> by) {
+        return aggregate(by, Double::min);","[{'comment': 'Pls add more unit tests to cover these functions\r\n', 'commenter': 'hanahmily'}]"
6091,docs/en/setup/envoy/metrics_service_setting.md,"@@ -39,6 +39,17 @@ A more complete static configuration, can be observed [here](config.yaml).
 
 Note that Envoy can also be configured dynamically through [xDS Protocol](https://github.com/envoyproxy/data-plane-api/blob/master/XDS_PROTOCOL.md).
 
+**Attention**: Only use this when Envoy is under Istio's control, because SkyWalking needs to parse the service name and service instance name from the metadata that is injected by Istio. However, if you want to use this without Istio, you need to inject the metadata yourself like this:","[{'comment': ""cc @hanahmily Due to share the same node id mechanism, even we don't require header exchange in the metrics service analysis. We will still depend on Istio control. We fetch the name based on that."", 'commenter': 'wu-sheng'}]"
6139,oap-server/server-storage-plugin/storage-influxdb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/influxdb/query/LogQuery.java,"@@ -98,9 +98,10 @@ public Logs queryLogs(String metricName, int serviceId, int serviceInstanceId, S
         if (!Strings.isNullOrEmpty(stateCode)) {
             recallQuery.and(eq(STATUS_CODE, stateCode));
         }
-        recallQuery.and(gte(AbstractLogRecord.TIME_BUCKET, startTB))
-                   .and(lte(AbstractLogRecord.TIME_BUCKET, endTB));
-
+        if (startTB != 0 && endTB != 0) {
+            recallQuery.and(gte(AbstractLogRecord.TIME_BUCKET, startTB))
+                       .and(lte(AbstractLogRecord.TIME_BUCKET, endTB));
+        }","[{'comment': ""Please revert this. I can't see the point of change this. Log feature is provided #6120"", 'commenter': 'wu-sheng'}, {'comment': 'In log.graphqls，LogQueryCondition.queryDuration is an optional field with annotation ""The time range of log happened"". If I understand correctly, when this field is empty it will query for all the logs. But the original code didn\'t do that, it can\'t find any log.', 'commenter': 'cuiweiwei'}, {'comment': 'I think the comment is very clear, https://github.com/apache/skywalking-query-protocol/blob/0eb55a7de358d35a3f8982bdd39ba7d21dde4f9c/log.graphqls#L53-L54', 'commenter': 'wu-sheng'}, {'comment': ""The key is, your PR doesn't relate to this implementation. This query has been used in any place, before the PR I pointed to you."", 'commenter': 'wu-sheng'}, {'comment': 'My local code is behind https://github.com/apache/skywalking-query-protocol/blob/0eb55a7de358d35a3f8982bdd39ba7d21dde4f9c/log.graphqls#L53-L54，I only got the L52. So above changes are unnecessary? But i find that other storage plugin have the same zero value judgment, such as H2LogQueryDAO.java', 'commenter': 'cuiweiwei'}, {'comment': ""All log query(s) are not used, take a look  #6120. It is being introduced recently(haven't merged). The codes you are seeing are not working in any case.\r\nPlease revert change and avoid unnecessary conflict. "", 'commenter': 'wu-sheng'}]"
6193,docs/en/setup/backend/backend-alarm.md,"@@ -237,11 +237,31 @@ dingtalkHooks:
       secret: dummysecret
 ```
 
-
 ## Update the settings dynamically
 Since 6.5.0, the alarm settings can be updated dynamically at runtime by [Dynamic Configuration](dynamic-config.md),
 which will override the settings in `alarm-settings.yml`.
 
 In order to determine that whether an alarm rule is triggered or not, SkyWalking needs to cache the metrics of a time window for
 each alarm rule, if any attribute (`metrics-name`, `op`, `threshold`, `period`, `count`, etc.) of a rule is changed,
 the sliding window will be destroyed and re-created, causing the alarm of this specific rule to restart again.
+
+
+## Feishu Hook","[{'comment': 'Move this before `Update the settings dynamically` part.', 'commenter': 'wu-sheng'}]"
6193,oap-server/server-bootstrap/src/main/resources/alarm-settings.yml,"@@ -81,3 +81,16 @@ dingtalkHooks:
   webhooks:
 #    - url: https://oapi.dingtalk.com/robot/send?access_token=dummy_token
 #      secret: dummysecret
+
+feishuHooks:
+  textTemplate: |-
+    {
+      ""msg_type"": ""text"",
+      ""content"": {
+        ""text"": ""Apache SkyWalking Alarm: \n %s.""
+      },","[{'comment': 'This may cause the OAP startup to fail due to a YAML parse failure. You need to remove this if it is unnecessary params, as follows:\r\n```yaml\r\nfeishuHooks:\r\n  textTemplate: |-\r\n    {\r\n      ""msg_type"": ""text"",\r\n      ""content"": {\r\n        ""text"": ""Apache SkyWalking Alarm: \\n %s.""\r\n      }\r\n    }\r\n```\r\n', 'commenter': 'JaredTan95'}, {'comment': 'and others work well.\r\n\r\n![image](https://user-images.githubusercontent.com/12468337/104831221-d0cd9b00-58c1-11eb-8341-6ed7dde5cd84.png)\r\n', 'commenter': 'JaredTan95'}, {'comment': '```suggestion\r\n      }\r\n```', 'commenter': 'wu-sheng'}]"
6193,oap-server/server-bootstrap/src/main/resources/alarm-settings.yml,"@@ -88,9 +88,10 @@ feishuHooks:
       ""msg_type"": ""text"",
       ""content"": {
         ""text"": ""Apache SkyWalking Alarm: \n %s.""
-      },
+      }
+#      ,
 #      ""ats"":""feishu_user_id_1,feishu_user_id_2""","[{'comment': 'Seems you should move `ats` above the `content`?', 'commenter': 'wu-sheng'}, {'comment': 'good idea', 'commenter': 'kim-up'}, {'comment': 'After you update this, I think this should be ready to merge.', 'commenter': 'wu-sheng'}]"
6193,oap-server/server-bootstrap/src/main/resources/alarm-settings.yml,"@@ -81,3 +81,29 @@ dingtalkHooks:
   webhooks:
 #    - url: https://oapi.dingtalk.com/robot/send?access_token=dummy_token
 #      secret: dummysecret
+
+#feishuHooks:
+#  textTemplate: |-
+#    {
+#    ""msg_type"": ""text"",
+#    # at someone with feishu_user_ids
+#    ""ats"": ""feishu_user_id_1,feishu_user_id_2"",
+#    ""content"": {
+#      ""text"": ""Apache SkyWalking Alarm: \n %s.""
+#    }
+#  }
+#  webhooks:
+#    - url: https://open.feishu.cn/open-apis/bot/v2/hook/dummy_token
+#      secret: dummysecret
+
+feishuHooks:
+  textTemplate: |-
+    {
+      ""msg_type"": ""text"",
+      ""content"": {
+        ""text"": ""Apache SkyWalking Alarm: \n %s.""
+      }
+    }
+  webhooks:
+#    - url: https://open.feishu.cn/open-apis/bot/v2/hook/dummy_token
+#      secret: dummysecret","[{'comment': 'I think you submit some duplicated things?', 'commenter': 'wu-sheng'}]"
6213,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/ContextManager.java,"@@ -72,11 +74,23 @@ private static AbstractTracerContext get() {
      */
     public static String getGlobalTraceId() {
         AbstractTracerContext segment = CONTEXT.get();
-        if (segment == null) {
-            return ""N/A"";
-        } else {
-            return segment.getReadablePrimaryTraceId();
-        }
+        return Objects.nonNull(segment) ? segment.getReadablePrimaryTraceId() : EMPTY_TRACE_CONTEXT_ID;
+    }
+
+    /**
+     * @return the current segment id if needEnhance. Otherwise, ""N/A"".
+     */
+    public static String getSegmentId() {
+        AbstractTracerContext segment = CONTEXT.get();","[{'comment': 'Please rename variable to `context`, seems the previous version is wrong.', 'commenter': 'wu-sheng'}]"
6240,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -163,11 +163,14 @@
          * Get profile task list interval
          */
         public static int GET_PROFILE_TASK_INTERVAL = 20;
-
         /**
          * Get agent dynamic config interval
          */
         public static int GET_AGENT_DYNAMIC_CONFIG_INTERVAL = 20;
+        /**
+         * If true, skywalking agent will enable periodically resolving DNS to update receiver service addresses. Otherwise disable
+         */
+        public static boolean DNS_PERIOD_RESOLVE_ACTIVE = false;","[{'comment': '```suggestion\r\n        public static boolean IS_RESOLVE_DNS_PERIODICALLY = false;\r\n```\r\nI think the current naming style is like this.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'xuanyu66'}]"
6240,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/conf/Config.java,"@@ -163,11 +163,14 @@
          * Get profile task list interval
          */
         public static int GET_PROFILE_TASK_INTERVAL = 20;
-
         /**
          * Get agent dynamic config interval
          */
         public static int GET_AGENT_DYNAMIC_CONFIG_INTERVAL = 20;
+        /**
+         * If true, skywalking agent will enable periodically resolving DNS to update receiver service addresses. Otherwise disable","[{'comment': '```suggestion\r\n         * If true, skywalking agent will enable periodically resolving DNS to update receiver service addresses. \r\n```', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'xuanyu66'}]"
6240,CHANGES.md,"@@ -37,6 +37,7 @@ Release Notes.
 * Fix RestTemplate plugin recording url tag with wrong port
 * Support collecting logs and forwarding through gRPC.
 * Support config `agent.sample_n_per_3_secs` can be changed in the runtime.
+* Support DNS period resolving mechanism to update backend service.","[{'comment': '```suggestion\r\n* Support DNS periodic resolving mechanism to update backend service addresses.\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'xuanyu66'}]"
6240,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/GRPCChannelManager.java,"@@ -91,6 +97,23 @@ public void shutdown() {
 
     @Override
     public void run() {
+        if (DNS_PERIOD_RESOLVE_ACTIVE) {
+            String backendService = Config.Collector.BACKEND_SERVICE.split("","")[0];
+            try {
+                String[] domainAndPort = backendService.split("":"");
+
+                List<String> newGrpcServers = Arrays
+                        .stream(InetAddress.getAllByName(domainAndPort[0]))
+                        .map(InetAddress::getHostAddress)
+                        .map(ip -> String.format(""%s:%s"", ip, domainAndPort[1]))
+                        .collect(Collectors.toList());
+
+                grpcServers = newGrpcServers;
+            } catch (Throwable t) {
+                LOGGER.error(t, ""Failed to resolve {} of backend service."", backendService);
+            }
+        }
+","[{'comment': 'I think this should be called only when gRPC connection available. `reconnect==true`', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'xuanyu66'}]"
6240,docs/en/setup/service-agent/java-agent/README.md,"@@ -95,6 +95,7 @@ property key | Description | Default |
 `collector.grpc_upstream_timeout`|How long grpc client will timeout in sending data to upstream. Unit is second.|`30` seconds|
 `collector.get_profile_task_interval`|Sniffer get profile task list interval.|`20`|
 `collector.get_agent_dynamic_config_interval`|Sniffer get agent dynamic config interval|`20`|
+`collector.dns_period_resolve_active`|If true, skywalking agent will enable periodically resolving DNS to update receiver service addresses. Otherwise disable|`false`|","[{'comment': '```suggestion\r\n`collector.dns_period_resolve_active`|If true, skywalking agent will enable periodically resolving DNS to update receiver service addresses. |`false`|\r\n```\r\n\r\nAlso should follow latest naming suggestion.', 'commenter': 'wu-sheng'}, {'comment': 'fixed', 'commenter': 'xuanyu66'}]"
6240,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/GRPCChannelManager.java,"@@ -92,6 +98,23 @@ public void shutdown() {
     @Override
     public void run() {
         LOGGER.debug(""Selected collector grpc service running, reconnect:{}."", reconnect);
+        if (IS_RESOLVE_DNS_PERIODICALLY || reconnect) {
+            String backendService = Config.Collector.BACKEND_SERVICE.split("","")[0];
+            try {
+                String[] domainAndPort = backendService.split("":"");
+
+                List<String> newGrpcServers = Arrays
+                        .stream(InetAddress.getAllByName(domainAndPort[0]))
+                        .map(InetAddress::getHostAddress)
+                        .map(ip -> String.format(""%s:%s"", ip, domainAndPort[1]))
+                        .collect(Collectors.toList());
+
+                grpcServers = newGrpcServers;","[{'comment': ""You are overriding the `grpcServers`, you wouldn't have the chance to resolve DNS again."", 'commenter': 'wu-sheng'}, {'comment': ""I don't get it"", 'commenter': 'xuanyu66'}, {'comment': 'Oh, sorry, my mistake. You split the config string every time. ', 'commenter': 'wu-sheng'}]"
6240,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/GRPCChannelManager.java,"@@ -92,6 +98,23 @@ public void shutdown() {
     @Override
     public void run() {
         LOGGER.debug(""Selected collector grpc service running, reconnect:{}."", reconnect);
+        if (IS_RESOLVE_DNS_PERIODICALLY || reconnect) {","[{'comment': '```suggestion\n        if (IS_RESOLVE_DNS_PERIODICALLY && reconnect) {\n```\n', 'commenter': 'kezhenxu94'}]"
6266,CHANGES.md,"@@ -37,7 +37,7 @@ Release Notes.
 * Support collecting logs and forwarding through gRPC.
 * Support config `agent.sample_n_per_3_secs` can be changed in the runtime.
 * Support DNS periodic resolving mechanism to update backend service.
-
+* Support config `agent.trace.ignore_path` can be changed in the runtime.","[{'comment': '```suggestion\r\n* Support config `agent.trace.ignore_path` can be changed in the runtime.\r\n\r\n```', 'commenter': 'wu-sheng'}]"
6266,apm-sniffer/optional-plugins/trace-ignore-plugin/src/main/java/org/apache/skywalking/apm/plugin/trace/ignore/TraceIgnorePatternWatcher.java,"@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.trace.ignore;
+
+import java.util.concurrent.atomic.AtomicReference;
+import org.apache.skywalking.apm.agent.core.conf.dynamic.AgentConfigChangeWatcher;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.plugin.trace.ignore.conf.IgnoreConfig;
+
+public class TraceIgnorePatternWatcher extends AgentConfigChangeWatcher {
+    private static final ILog LOGGER = LogManager.getLogger(TraceIgnorePatternWatcher.class);
+
+    private final AtomicReference<String> traceIgnorePathPatterns;
+    private final TraceIgnoreExtendService traceIgnoreExtendService;
+
+    public TraceIgnorePatternWatcher(final String propertyKey, TraceIgnoreExtendService traceIgnoreExtendService) {
+        super(propertyKey);
+        this.traceIgnorePathPatterns = new AtomicReference(getDefaultValue());
+        this.traceIgnoreExtendService = traceIgnoreExtendService;
+    }
+
+    private void activeSetting(String config) {
+        if (LOGGER.isDebugEnable()) {
+            LOGGER.debug(""Updating using new static config: {}"", config);
+        }
+        try {
+            this.traceIgnorePathPatterns.set(config);
+            traceIgnoreExtendService.handleTraceIgnorePatternsChanged();
+        } catch (NumberFormatException ex) {","[{'comment': 'no `NumberFormatException` will be thrown in this case ', 'commenter': 'kezhenxu94'}, {'comment': 'yes, copied from SampleRateWatcher,I will delete id.', 'commenter': 'JaredTan95'}]"
6266,apm-sniffer/optional-plugins/trace-ignore-plugin/src/main/java/org/apache/skywalking/apm/plugin/trace/ignore/TraceIgnoreExtendService.java,"@@ -76,4 +85,10 @@ public boolean trySampling(final String operationName) {
     public void forceSampled() {
         super.forceSampled();
     }
+
+    void handleTraceIgnorePatternsChanged() {
+        if (StringUtil.isNotBlank(traceIgnorePatternWatcher.getTraceIgnorePathPatterns())) {","[{'comment': 'What happens if I set the value as blank? I think the PR misses some logic here.', 'commenter': 'wu-sheng'}, {'comment': 'Blank string is considered as `DELETE` event, and it will use the default value (`TraceIgnorePatternWatcher#51`) of `IgnoreConfig.Trace.IGNORE_PATH`, so `traceIgnorePatternWatcher.getTraceIgnorePathPatterns()` may be effectively not blank unless `IgnoreConfig.Trace.IGNORE_PATH` is set to empty', 'commenter': 'kezhenxu94'}]"
6329,apm-protocol/apm-network/src/main/java/org/apache/skywalking/apm/network/trace/component/ComponentsDefine.java,"@@ -194,4 +194,6 @@
     public static final OfficialComponent APACHE_CXF = new OfficialComponent(105, ""Apache-CXF"");
 
     public static final OfficialComponent DOLPHIN_SCHEDULER = new OfficialComponent(106, ""dolphinscheduler"");
+
+    public static final OfficialComponent CUSTOM_ENHANCE = new OfficialComponent(999, ""custom-enhance"");","[{'comment': ""We don't need component id for local span."", 'commenter': 'wu-sheng'}]"
6329,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/trace/SpanLayer.java,"@@ -19,7 +19,7 @@
 package org.apache.skywalking.apm.agent.core.context.trace;
 
 public enum SpanLayer {
-    DB(1), RPC_FRAMEWORK(2), HTTP(3), MQ(4), CACHE(5);
+    DB(1), RPC_FRAMEWORK(2), HTTP(3), MQ(4), CACHE(5), CUSTOM_ENHANCE(9);","[{'comment': 'This is illegal.', 'commenter': 'wu-sheng'}]"
6329,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/trace/SpanLayer.java,"@@ -50,4 +50,8 @@ public static void asHttp(AbstractSpan span) {
     public static void asMQ(AbstractSpan span) {
         span.setLayer(SpanLayer.MQ);
     }
+
+    public static void asCustomEnhance(AbstractSpan span) {","[{'comment': 'Illegal.', 'commenter': 'wu-sheng'}]"
6329,apm-sniffer/optional-plugins/customize-enhance-plugin/src/main/java/org/apache/skywalking/apm/plugin/customize/interceptor/BaseInterceptorMethods.java,"@@ -35,54 +38,63 @@
 
     void beforeMethod(Method method, Object[] allArguments) {
         Map<String, Object> configuration = CustomizeConfiguration.INSTANCE.getConfiguration(method);
-        if (!MethodConfiguration.isCloseBeforeMethod(configuration)) {
-            String operationName = MethodConfiguration.getOperationName(configuration);
-            Map<String, Object> context = CustomizeExpression.evaluationContext(allArguments);
-            if (context == null || context.isEmpty()) {
-                ContextManager.createLocalSpan(operationName);
-            } else {
+        String operationName = MethodConfiguration.getOperationName(configuration);
+        String requestInfo = (allArguments == null || allArguments.length == 0) ? """" : new Gson().toJson(allArguments);
+        Map<String, Object> context = CustomizeExpression.evaluationContext(allArguments);
+        AbstractSpan span;
+        if (context == null || context.isEmpty()) {
+            span = ContextManager.createLocalSpan(operationName);
+        } else {
 
-                Map<String, String> tags = MethodConfiguration.getTags(configuration);
-                Map<String, String> spanTags = new HashMap<String, String>();
-                Map<String, String> logs = MethodConfiguration.getLogs(configuration);
-                Map<String, String> spanLogs = new HashMap<String, String>();
+            Map<String, String> tags = MethodConfiguration.getTags(configuration);
+            Map<String, String> spanTags = new HashMap<String, String>();
+            Map<String, String> logs = MethodConfiguration.getLogs(configuration);
+            Map<String, String> spanLogs = new HashMap<String, String>();
 
-                List<String> operationNameSuffixes = MethodConfiguration.getOperationNameSuffixes(configuration);
-                StringBuilder operationNameSuffix = new StringBuilder();
-                if (operationNameSuffixes != null && !operationNameSuffixes.isEmpty()) {
-                    for (String expression : operationNameSuffixes) {
-                        operationNameSuffix.append(Constants.OPERATION_NAME_SEPARATOR);
-                        operationNameSuffix.append(CustomizeExpression.parseExpression(expression, context));
-                    }
+            List<String> operationNameSuffixes = MethodConfiguration.getOperationNameSuffixes(configuration);
+            StringBuilder operationNameSuffix = new StringBuilder();
+            if (operationNameSuffixes != null && !operationNameSuffixes.isEmpty()) {
+                for (String expression : operationNameSuffixes) {
+                    operationNameSuffix.append(Constants.OPERATION_NAME_SEPARATOR);
+                    operationNameSuffix.append(CustomizeExpression.parseExpression(expression, context));
                 }
-                if (tags != null && !tags.isEmpty()) {
-                    for (Map.Entry<String, String> expression: tags.entrySet()) {
-                        spanTags.put(expression.getKey(), CustomizeExpression.parseExpression(expression.getValue(), context));
-                    }
+            }
+            if (tags != null && !tags.isEmpty()) {
+                for (Map.Entry<String, String> expression : tags.entrySet()) {
+                    spanTags.put(expression.getKey(), CustomizeExpression.parseExpression(expression.getValue(), context));
                 }
-                if (logs != null && !logs.isEmpty()) {
-                    for (Map.Entry<String, String> entries : logs.entrySet()) {
-                        String expression = logs.get(entries.getKey());
-                        spanLogs.put(entries.getKey(), CustomizeExpression.parseExpression(expression, context));
-                    }
+            }
+            if (logs != null && !logs.isEmpty()) {
+                for (Map.Entry<String, String> entries : logs.entrySet()) {
+                    String expression = logs.get(entries.getKey());
+                    spanLogs.put(entries.getKey(), CustomizeExpression.parseExpression(expression, context));
                 }
-                operationName = operationNameSuffix.insert(0, operationName).toString();
+            }
+            operationName = operationNameSuffix.insert(0, operationName).toString();
 
-                AbstractSpan span = ContextManager.createLocalSpan(operationName);
-                if (!spanTags.isEmpty()) {
-                    for (Map.Entry<String, String> tag : spanTags.entrySet()) {
-                        span.tag(Tags.ofKey(tag.getKey()), tag.getValue());
-                    }
-                }
-                if (!spanLogs.isEmpty()) {
-                    span.log(System.currentTimeMillis(), spanLogs);
+            span = ContextManager.createLocalSpan(operationName);
+            if (!spanTags.isEmpty()) {
+                for (Map.Entry<String, String> tag : spanTags.entrySet()) {
+                    span.tag(Tags.ofKey(tag.getKey()), tag.getValue());
                 }
             }
+            if (!spanLogs.isEmpty()) {
+                span.log(System.currentTimeMillis(), spanLogs);
+            }
         }
+        span.setComponent(ComponentsDefine.CUSTOM_ENHANCE);
+        SpanLayer.asCustomEnhance(span);
+
+        // collect request info.
+        Tags.CUSTOM.PARAMS.set(span, requestInfo);
+        // collect method info.
+        Tags.CUSTOM.METHOD.set(span, MethodConfiguration.getMethodName(configuration));
     }
 
     void afterMethod(Method method) {
-        if (!MethodConfiguration.isCloseAfterMethod(CustomizeConfiguration.INSTANCE.getConfiguration(method))) {
+        // fix ThreadLocal memory leak bug.
+        // Resolves #6301 https://github.com/apache/skywalking/issues/6301","[{'comment': ""Don't put this issue link in the codes"", 'commenter': 'wu-sheng'}]"
6329,oap-server/server-bootstrap/src/main/resources/component-libraries.yml,"@@ -350,6 +350,10 @@ Apache-CXF:
 dolphinscheduler:
   id: 106
   languages: Java
+# The id of supported Java component library can be increased in order (usually less than 999) and written here.","[{'comment': 'Illegal.', 'commenter': 'wu-sheng'}]"
6329,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/context/tag/Tags.java,"@@ -98,6 +98,12 @@ private Tags() {
         public static final StringTag HEADERS = new StringTag(14, ""http.headers"");
     }
 
+    public static final class CUSTOM {","[{'comment': 'If you want to add new feature, you need a new PR and issue.', 'commenter': 'wu-sheng'}]"
6478,CHANGES.md,"@@ -48,7 +48,7 @@ Release Notes.
 * Fix trace id by clear search conditions.
 * Search endpoints with keywords.
 * Fix pageSize on logs page.
-
+* Update echarts version to 5.0.2.","[{'comment': '```suggestion\r\n* Update echarts version to 5.0.2.\r\n\r\n```', 'commenter': 'wu-sheng'}]"
6478,dist-material/release-docs/LICENSE,"@@ -498,8 +499,8 @@ d3-tip          0.9.1:  https://github.com/Caged/d3-tip BSD-3-Clause
 d3-transition   1.1.3:  https://github.com/d3/d3-transition     BSD-3-Clause
 d3-voronoi      1.1.4:  https://github.com/d3/d3-voronoi        BSD-3-Clause
 d3-zoom 1.7.3:  https://github.com/d3/d3-zoom   BSD-3-Clause
-zrender 4.0.4:  https://github.com/ecomfe/zrender   BSD-3-Clause
-vue-i18n 8.10.0:  https://github.com/kazupon/vue-i18n   MIT
+zrender 5.0.4:  https://github.com/ecomfe/zrender   BSD-3-Clause
+tslib 2.0.3 https://github.com/libts/tslib LGPL-2.1","[{'comment': 'IMO the real ""tslib"" should be https://github.com/Microsoft/tslib instead of https://github.com/libts/tslib, also, LGPL-2.1 is category X in Apache projects, please confirm', 'commenter': 'kezhenxu94'}, {'comment': 'The latest version of https://github.com/libts/tslib is 1.22, far away from 2.0.3', 'commenter': 'kezhenxu94'}, {'comment': 'Yes, I checked, repo actually is https://www.npmjs.com/package/tslib.', 'commenter': 'wu-sheng'}, {'comment': 'According to this, it is BSD Zero(https://github.com/microsoft/tslib/blob/master/LICENSE.txt), which belongs to Catalog A. We are good to go. Just need to update the license file. Thanks for catching this, otherwise it will be super confused we included LGPL-2 ', 'commenter': 'wu-sheng'}, {'comment': '@Fine0830 Please be advised, GPL, LGPL are not allowed to be used in the ASF. Please be careful when you add new dependency and edit LICENSE file.', 'commenter': 'wu-sheng'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            analyzerService.analyze(constructCurrentEvent(a));
+        });
+    }
+
+    private Event constructCurrentEvent(AlarmMessage msg) {
+        long millis = System.currentTimeMillis();
+        Event event =  Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis)
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis)
+                .build();","[{'comment': ""Don't `.build()` too early, so that we don't need to convert it back to a builder again (line 72, line 80, line 88, etc.)"", 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            analyzerService.analyze(constructCurrentEvent(a));
+        });
+    }
+
+    private Event constructCurrentEvent(AlarmMessage msg) {
+        long millis = System.currentTimeMillis();
+        Event event =  Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis)
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis)
+                .build();
+
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition serviceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                    Source.newBuilder()
+                            .setService(serviceIdDef.getName())
+                            .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.SERVICE_INSTANCE :
+                IDManager.ServiceInstanceID.InstanceIDDefinition instanceIdDef = IDManager.ServiceInstanceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setServiceInstance(instanceIdDef.getName())
+                                .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.ENDPOINT :
+                IDManager.EndpointID.EndpointIDDefinition endpointIDDef = IDManager.EndpointID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setEndpoint(endpointIDDef.getEndpointName())
+                                .build()
+                ).build();
+                break;
+            default:
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setService(msg.getName())
+                                .build()
+                ).build();
+                break;
+        }
+        return event;","[{'comment': ""Let's invoke builder `.build()` here"", 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/AlarmModuleProvider.java,"@@ -91,4 +92,8 @@ public void notifyAfterCompleted() throws ServiceNotProvidedException, ModuleSta
             ConfigurationModule.NAME
         };
     }
+
+    ModuleManager getModuleManager() {
+        return getManager();
+    }
 }","[{'comment': 'This method is only for testing purpose, we don\'t add methods just for testing, please use `Whitebox.getInternalState(moduleProvider, ""manager"");` to get the `manager` field in the unit test', 'commenter': 'kezhenxu94'}, {'comment': '> This method is only for testing purpose, we don\'t add methods just for testing, please use `Whitebox.getInternalState(moduleProvider, ""manager"");` to get the `manager` field in the unit test\r\n\r\ncopy that. \r\n\r\n> Also update the `CHANGES.log` to include this feature\r\n\r\ncopy that .', 'commenter': 'chenmudu'}]"
6702,oap-server/server-alarm-plugin/src/test/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallbackTest.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleProvider;
+import org.junit.Before;
+import org.junit.Test;
+
+import java.util.ArrayList;
+import java.util.Iterator;
+import java.util.List;
+import java.util.ServiceLoader;
+
+import static org.junit.Assert.assertTrue;
+
+/**
+ * EventHookCallbackTest.
+ *
+ */
+public class EventHookCallbackTest {
+
+    private AlarmModuleProvider moduleProvider;
+
+    @Before
+    public void setUp() throws Exception {
+        ServiceLoader<ModuleProvider> serviceLoader = ServiceLoader.load(ModuleProvider.class);
+        Iterator<ModuleProvider> providerIterator = serviceLoader.iterator();
+
+        assertTrue(providerIterator.hasNext());
+
+        moduleProvider = (AlarmModuleProvider) providerIterator.next();
+
+        moduleProvider.createConfigBeanIfAbsent();
+
+        moduleProvider.prepare();
+    }
+
+    @Test
+    public void testEventCallback() {
+        List<AlarmMessage> msgs = new ArrayList<>();
+        AlarmMessage msg = constructAlarmMessage();
+        msgs.add(msg);
+        new EventHookCallback(moduleProvider.getModuleManager()).doAlarm(msgs);
+    }","[{'comment': ""This test case doesn't make too much sense as there is no assertion in it"", 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            analyzerService.analyze(constructCurrentEvent(a));
+        });
+    }
+
+    private Event constructCurrentEvent(AlarmMessage msg) {
+        long millis = System.currentTimeMillis();
+        Event event =  Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis)
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis)
+                .build();
+
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition serviceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                    Source.newBuilder()
+                            .setService(serviceIdDef.getName())
+                            .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.SERVICE_INSTANCE :
+                IDManager.ServiceInstanceID.InstanceIDDefinition instanceIdDef = IDManager.ServiceInstanceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setServiceInstance(instanceIdDef.getName())
+                                .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.ENDPOINT :
+                IDManager.EndpointID.EndpointIDDefinition endpointIDDef = IDManager.EndpointID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setEndpoint(endpointIDDef.getEndpointName())","[{'comment': 'For endpoint, you need to set the service name as well', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            analyzerService.analyze(constructCurrentEvent(a));
+        });
+    }
+
+    private Event constructCurrentEvent(AlarmMessage msg) {
+        long millis = System.currentTimeMillis();
+        Event event =  Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis)
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis)
+                .build();
+
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition serviceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                    Source.newBuilder()
+                            .setService(serviceIdDef.getName())
+                            .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.SERVICE_INSTANCE :
+                IDManager.ServiceInstanceID.InstanceIDDefinition instanceIdDef = IDManager.ServiceInstanceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setServiceInstance(instanceIdDef.getName())","[{'comment': 'For service instance scope, you need to set the service name as well\r\n', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            analyzerService.analyze(constructCurrentEvent(a));
+        });
+    }
+
+    private Event constructCurrentEvent(AlarmMessage msg) {
+        long millis = System.currentTimeMillis();
+        Event event =  Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis)
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis)
+                .build();
+
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition serviceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                    Source.newBuilder()
+                            .setService(serviceIdDef.getName())
+                            .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.SERVICE_INSTANCE :
+                IDManager.ServiceInstanceID.InstanceIDDefinition instanceIdDef = IDManager.ServiceInstanceID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setServiceInstance(instanceIdDef.getName())
+                                .build()
+                ).build();
+                break;
+            case DefaultScopeDefine.ENDPOINT :
+                IDManager.EndpointID.EndpointIDDefinition endpointIDDef = IDManager.EndpointID.analysisId(msg.getId0());
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setEndpoint(endpointIDDef.getEndpointName())
+                                .build()
+                ).build();
+                break;
+            default:
+                event = event.toBuilder().setSource(
+                        Source.newBuilder()
+                                .setService(msg.getName())
+                                .build()
+                ).build();","[{'comment': 'Why default should be a service level event?', 'commenter': 'wu-sheng'}, {'comment': '> Why default should be a service level event?\r\n\r\nMaybe I should make sure that the scopeId list and the scope info should be set under the corresponding scopeId, which may differ from the three points((Service, Instance, and Endpoint).) on the [UI](https://github.com/apache/skywalking-rocketbot-ui/pull/452#issuecomment-804719314) ， and the default level of event may not be the service . ', 'commenter': 'chenmudu'}, {'comment': 'NotifyHandler has covered important logic. UI includes dashboard and topology.', 'commenter': 'wu-sheng'}, {'comment': ""Okay,thanks, I'll see what's going on."", 'commenter': 'chenmudu'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);","[{'comment': ""Let's get this in the constructor, and no `if (null == manager)` is needed"", 'commenter': 'kezhenxu94'}, {'comment': 'Move this into the constructor. ', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,104 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (null == manager) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            analyzerService.analyze(constructCurrentEvent(a));
+        });
+    }
+
+    private Event constructCurrentEvent(AlarmMessage msg) {
+        long millis = System.currentTimeMillis();
+        Event event =  Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis)
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis)","[{'comment': ""Let's add the AlarmRule's `period` into `AlarmMessage` (make it not serializable). I'd like to compute the `startTime` and `endTime` as `startTime = now() - period` and `endTime = now()`, @wu-sheng thoughts?"", 'commenter': 'kezhenxu94'}, {'comment': '@kezhenxu94 What do you want to calculate? Could you be more specific?', 'commenter': 'wu-sheng'}, {'comment': '> @kezhenxu94 What do you want to calculate? Could you be more specific?\r\n\r\nFor now, the `startTime` and `endTime` are both set to the time when the alarm occurs (`now()`), what I want to do is to loop the period of the alarm rule in, and set the `startTime = now() - period` ', 'commenter': 'kezhenxu94'}, {'comment': 'Make sense.\r\nAnother thing missing here is for relationship alarm, we need to add event for entity related to upstream and downstream.', 'commenter': 'wu-sheng'}, {'comment': '> Make sense.\r\n\r\n@chenmudu please do this. \r\n\r\n> Another thing missing here is for relationship alarm, we need to add event for entity related to upstream and downstream.\r\n\r\nSo for one relationship alarm, we would generate 2 events, for upstream and downstream respectively, right?\r\n', 'commenter': 'kezhenxu94'}, {'comment': '> So for one relationship alarm, we would generate 2 events, for upstream and downstream respectively, right?\r\n\r\nYes.', 'commenter': 'wu-sheng'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {","[{'comment': 'One of the events may be null', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,153 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                analyzerService.analyze(event);
+            }
+        });
+    }
+
+    private Event[] constructCurrentEvent(AlarmMessage msg) {
+        Event[] events = new Event[2];
+        long millis = System.currentTimeMillis();
+        Event.Builder builder = Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis - msg.getPeriod())
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis);
+
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition singleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                builder.setSource(
+                    Source.newBuilder()
+                            .setService(singleServiceIdDef.getName())
+                            .build()
+                );
+                events[0] = builder.build();
+                break;
+            case DefaultScopeDefine.SERVICE_RELATION :
+                IDManager.ServiceID.ServiceIDDefinition doubleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                builder.setSource(
+                        Source.newBuilder()
+                            .setService(doubleServiceIdDef.getName())
+                            .build()
+                );
+                events[0] = builder.build();
+                doubleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId1());
+                builder.setSource(","[{'comment': 'When building the second event, you need to reset the uuid', 'commenter': 'kezhenxu94'}, {'comment': 'Ok.', 'commenter': 'chenmudu'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final EventAnalyzerService analyzerService;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                if (Objects.nonNull(event)) {
+                    this.analyzerService.analyze(event);
+                }
+            }
+        });
+    }
+
+    private Event[] constructCurrentEvent(AlarmMessage msg) {
+        Event[] events = new Event[2];
+        long millis = System.currentTimeMillis();","[{'comment': 'Rename `millis` to `now` or `endTime`', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final EventAnalyzerService analyzerService;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                if (Objects.nonNull(event)) {
+                    this.analyzerService.analyze(event);
+                }
+            }
+        });
+    }
+
+    private Event[] constructCurrentEvent(AlarmMessage msg) {
+        Event[] events = new Event[2];
+        long millis = System.currentTimeMillis();
+        Event.Builder builder = Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis - msg.getPeriod())
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(millis);
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition singleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                builder.setSource(
+                    Source.newBuilder()
+                            .setService(singleServiceIdDef.getName())
+                            .build()
+                );
+                events[0] = builder.build();
+                break;
+            case DefaultScopeDefine.SERVICE_RELATION :
+                IDManager.ServiceID.ServiceIDDefinition doubleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                builder.setSource(
+                        Source.newBuilder()
+                            .setService(doubleServiceIdDef.getName())
+                            .build()
+                );
+                events[0] = builder.build();
+                doubleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId1());
+                builder.setSource(
+                        Source.newBuilder()
+                                .setService(doubleServiceIdDef.getName())
+                                .build()
+                ).setUuid(UUID.randomUUID().toString());
+                events[1] = builder.build();
+                break;
+            case DefaultScopeDefine.SERVICE_INSTANCE :
+                IDManager.ServiceInstanceID.InstanceIDDefinition singleInstanceIdDef = IDManager.ServiceInstanceID.analysisId(msg.getId0());
+                builder.setSource(
+                        Source.newBuilder()
+                                .setServiceInstance(singleInstanceIdDef.getName())
+                                .setService(singleInstanceIdDef.getServiceId())","[{'comment': 'You need to parse the service name from the ID instead of setting the ID directly ', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final EventAnalyzerService analyzerService;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                if (Objects.nonNull(event)) {
+                    this.analyzerService.analyze(event);
+                }
+            }
+        });
+    }
+
+    private Event[] constructCurrentEvent(AlarmMessage msg) {
+        Event[] events = new Event[2];
+        long millis = System.currentTimeMillis();
+        Event.Builder builder = Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(millis - msg.getPeriod())","[{'comment': 'Please take care of the time units, `millis` is in millisecond but `period` is in minutes. ', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (Objects.isNull(this.manager)) {","[{'comment': ""`#manager` is initialized through the constructor, I think we don't need NOT-NULL check."", 'commenter': 'wu-sheng'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (Objects.isNull(this.manager)) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                if (Objects.nonNull(event)) {
+                    analyzerService.analyze(event);
+                }
+            }
+        });
+    }
+
+    private Event[] constructCurrentEvent(AlarmMessage msg) {
+        Event[] events = new Event[2];
+        long now = System.currentTimeMillis();
+        Event.Builder builder = Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")","[{'comment': '@kezhenxu94 Do we suppose to have a document to maintain the knowing event name? As this seems going to keep adding.', 'commenter': 'wu-sheng'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (Objects.isNull(this.manager)) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                if (Objects.nonNull(event)) {
+                    analyzerService.analyze(event);
+                }
+            }
+        });
+    }
+
+    private Event[] constructCurrentEvent(AlarmMessage msg) {
+        Event[] events = new Event[2];
+        long now = System.currentTimeMillis();
+        Event.Builder builder = Event.newBuilder()
+                .setUuid(UUID.randomUUID().toString())
+                .setName(""Alarm"")
+                .setStartTime(now - (msg.getPeriod() * 60 * 1000))
+                .setMessage(msg.getAlarmMessage())
+                .setType(Type.Error)
+                .setEndTime(now);
+        switch (msg.getScopeId()) {
+            case DefaultScopeDefine.SERVICE :
+                IDManager.ServiceID.ServiceIDDefinition singleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                builder.setSource(
+                    Source.newBuilder()
+                            .setService(singleServiceIdDef.getName())
+                            .build()
+                );
+                events[0] = builder.build();
+                break;
+            case DefaultScopeDefine.SERVICE_RELATION :
+                IDManager.ServiceID.ServiceIDDefinition doubleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId0());
+                builder.setSource(
+                        Source.newBuilder()
+                            .setService(doubleServiceIdDef.getName())
+                            .build()
+                );
+                events[0] = builder.build();
+                doubleServiceIdDef = IDManager.ServiceID.analysisId(msg.getId1());
+                builder.setSource(
+                        Source.newBuilder()
+                                .setService(doubleServiceIdDef.getName())
+                                .build()
+                ).setUuid(UUID.randomUUID().toString());","[{'comment': 'Why set UUID again?', 'commenter': 'wu-sheng'}, {'comment': '> Why set UUID again?\r\n\r\nhttps://github.com/apache/skywalking/pull/6702#discussion_r611450353 when building the second event, the UUID need to be regenerated otherwise it would override the first event (or is dropped)', 'commenter': 'kezhenxu94'}]"
6702,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/EventHookCallback.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import org.apache.skywalking.apm.network.event.v3.Event;
+import org.apache.skywalking.apm.network.event.v3.Source;
+import org.apache.skywalking.apm.network.event.v3.Type;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerModule;
+import org.apache.skywalking.oap.server.analyzer.event.EventAnalyzerService;
+import org.apache.skywalking.oap.server.core.alarm.AlarmCallback;
+import org.apache.skywalking.oap.server.core.alarm.AlarmMessage;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.source.DefaultScopeDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+import java.util.List;
+import java.util.Objects;
+import java.util.UUID;
+
+/**
+ * EventCallBack: When an alert is present, an event is generated for each alert message. These events are then sent to the internal event analyzer.
+ *
+ */
+public class EventHookCallback implements AlarmCallback {
+
+    private final ModuleManager manager;
+
+    public EventHookCallback(ModuleManager manager) {
+        this.manager = manager;
+    }
+
+    @Override
+    public void doAlarm(List<AlarmMessage> alarmMessage) {
+        if (Objects.isNull(this.manager)) {
+            return ;
+        }
+        EventAnalyzerService analyzerService = manager.find(EventAnalyzerModule.NAME).provider().getService(EventAnalyzerService.class);
+        alarmMessage.forEach(a -> {
+            for (Event event : constructCurrentEvent(a)) {
+                if (Objects.nonNull(event)) {","[{'comment': 'Why use `Event[]` rather than `ArrayList(2)? Which should be able to avoid `nonNull` check.', 'commenter': 'wu-sheng'}]"
6774,apm-sniffer/apm-sdk-plugin/pulsar-plugin/src/main/java/org/apache/skywalking/apm/plugin/pulsar/PulsarConsumerListenerInterceptor.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.plugin.pulsar;
+
+import org.apache.pulsar.client.api.Message;
+import org.apache.skywalking.apm.agent.core.context.CarrierItem;
+import org.apache.skywalking.apm.agent.core.context.ContextCarrier;
+import org.apache.skywalking.apm.agent.core.context.ContextManager;
+import org.apache.skywalking.apm.agent.core.context.tag.Tags;
+import org.apache.skywalking.apm.agent.core.context.trace.AbstractSpan;
+import org.apache.skywalking.apm.agent.core.context.trace.SpanLayer;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.EnhancedInstance;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.InstanceMethodsAroundInterceptor;
+import org.apache.skywalking.apm.agent.core.plugin.interceptor.enhance.MethodInterceptResult;
+import org.apache.skywalking.apm.network.trace.component.ComponentsDefine;
+
+import java.lang.reflect.Method;
+
+/**
+ * Interceptor for pulsar consumer message listener enhanced instance
+ * <p>
+ * Here is the intercept process steps:
+ *
+ * <pre>
+ *  1. Get @{@link ContextCarrier} from message
+ *  2. Create a local span when call <code>received</code> method
+ *  3. Extract trace information from context carrier
+ *  4. Stop the local span when <code>received</code> method finished.
+ * </pre>
+ */
+public class PulsarConsumerListenerInterceptor implements InstanceMethodsAroundInterceptor {
+
+    public static final String CONSUMER_OPERATE_NAME = ""Pulsar/Consumer/MessageListener"";","[{'comment': ""Shall we need to introduce a new operation name? The message listener just a way to consume messages, for the tracing context, we just need to know the consumer got the message.\r\n\r\nAnd, the message listener can't work together with the receive() method, so I think we can use the existing operation name."", 'commenter': 'codelipenghui'}, {'comment': 'Before entering the `MessageListener` callback method, the `receive()` method will be called to receive the message first, so I think introduce a new operation name can distinguish these two spans. Just like `Pulsar/Producer` and `Pulsar/Producer/Callback`', 'commenter': 'wallezhang'}, {'comment': ""It's not the same concepts here I think, the `Pulsar/Producer` means the client sends out the message, the `Pulsar/Producer/Callback` means the broker sends out the publish receipt to the client, if not callback from the broker, this means the message does not written succeed. \r\n\r\nBut for the message listener, it's a way at the client side to get messages, both `Pulsar/Consumer/MessageListener` and `Pulsar/Consumer` are indicate the messages are arrivals the consumer, and we are not support the `Pulsar/Consumer/Acknowledge` for now to indicate the consumer processed the message and acked it.\r\n\r\nThe reason that I think we don't need a new operation here is we might have different get message methods in the client side such as batchReceive etc., I think the trace is telling users that the message arrives the consumer is enough here, If we want to add more details about how the users get the messages, I think we can add some labels in the trace context, but not a new operation name.\r\n\r\nBTW, do we need to add a new span for handling this case? Looks like\r\n\r\n```\r\n--- Pulsar/Consumer\r\n      --- Pulsar/Consumer/MessageListener\r\n```\r\nIf there is a way to set the existing span to the message listener thread, seems more reasonable here."", 'commenter': 'codelipenghui'}, {'comment': 'I know what you mean, but in most cases, we will write the business code directly in the `MessageListener`, therefore it is not a span of message reception, but more like a process of message handling, such as\r\n```\r\n// span Pulsar/Consumer start\r\nMessage message = consumer.receive();\r\n// List<Message> messages = consumer.batchReceive();\r\n// span Pulsar/Consumer end\r\n\r\n// business code, maybe start a new span named HandleMessage\r\n// do some business  logic with message...\r\nconsumer.acknowledge(message);\r\n// business code end, and the HandleMessage span is end\r\n```\r\n\r\nAnd with `MessageListener`, we will do the business logic like this\r\n```\r\npulsarClient.newConsumer().topic(""test"").subscriptionName(""test"").messageListener((consumer,message) -> {\r\n    // span Pulsar/Consumer/MessageListener start\r\n    // do some business logic with message...\r\n    consumer.acknowledge(message);\r\n    // span Pulsar/Consumer/MessageListener end\r\n})\r\n```\r\nSpan `Pulsar/Consumer` is finished in client internal, and the `Pulsar/Consumer/MessageListener` is a `Local` span that represent the business logic processing. So I agree with adding a new span with `Pulsar/Consumer` span as parent.', 'commenter': 'wallezhang'}]"
6774,test/plugin/scenarios/pulsar-scenario/src/main/java/test/apache/skywalking/apm/testcase/pulsar/controller/CaseController.java,"@@ -51,38 +51,37 @@ public String pulsarCase() throws PulsarClientException, InterruptedException {
 
         String topic = ""test"";
 
+        CountDownLatch latch = new CountDownLatch(1);
+
         PulsarClient pulsarClient = PulsarClient.builder().serviceUrl(PULSAR_DOMAIN + serviceUrl).build();
 
         Producer<byte[]> producer = pulsarClient.newProducer().topic(topic).create();
 
-        Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topic).subscriptionName(""test"").subscribe();
+        Consumer<byte[]> consumer = pulsarClient.newConsumer().topic(topic)","[{'comment': 'I noticed you are replacing the old one(based on the receive method) with the message listener one. We should cover all of these two cases in the test. Could you please add a new consumer or add a new test for this case. I think you can add a new consumer with a different subscription name which will get the same messages from the topic.', 'commenter': 'codelipenghui'}, {'comment': 'Yes, because the `receive()` method will be called first before entering the `MessageListener` callback, so I directly replace the old one, and I think this can cover all cases in the test. I just add new expect data in `expectedData.yml` and reserve the `receive()` method segment. So based on this consideration, do I still need to create a new consumer to cover the new case?', 'commenter': 'wallezhang'}, {'comment': 'The consumer might disabled the message listener, it not a required feature for users to consume messages.', 'commenter': 'codelipenghui'}, {'comment': 'OK, I will add a new consumer with message listener to test new case', 'commenter': 'wallezhang'}]"
6781,apm-sniffer/optional-reporter-plugins/kafka-reporter-plugin/src/main/java/org/apache/skywalking/apm/agent/core/kafka/KafkaConnectionStatus.java,"@@ -0,0 +1,23 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.apm.agent.core.kafka;
+
+enum KafkaConnectionStatus {
+    CONNECTED, UNCONNECTED
+}","[{'comment': ""@darcydai\r\nHi, I don't found the retrying machine. I mean when is the status set to UNCONNECTED?"", 'commenter': 'dmsolr'}, {'comment': 'yes. firstly,  UNCONNECTED should named DISCONNECTED, it is a bad spell,  I already update it in the last commit.\r\nactually, DISCONNECTED is never used, because KafkaProducer has no way to measure the Kafka producer status in its API, maybe it will have the way in later.  Reconnection mechanism has implemented by KafkaProdcer if KafkaProdcer has been created, those works blew want to resolve KafkaProdcer create failed when the agent bootstrap\r\n', 'commenter': 'darcydai'}, {'comment': ""I got it. That is why we didn't have this feature yet."", 'commenter': 'dmsolr'}]"
6781,apm-sniffer/optional-reporter-plugins/kafka-reporter-plugin/src/main/java/org/apache/skywalking/apm/agent/core/kafka/KafkaJVMMetricsSender.java,"@@ -38,55 +39,52 @@
  * A report to send JVM Metrics data to Kafka Broker.
  */
 @OverrideImplementor(JVMMetricsSender.class)
-public class KafkaJVMMetricsSender extends JVMMetricsSender {
+public class KafkaJVMMetricsSender extends JVMMetricsSender implements KafkaConnectionStatusListener {
     private static final ILog LOGGER = LogManager.getLogger(KafkaJVMMetricsSender.class);
     private KafkaProducer<String, Bytes> producer;
     private String topic;
-
     private BlockingQueue<JVMMetric> queue;
-    private volatile boolean running = false;
 
     @Override
     public void run() {
         if (!queue.isEmpty()) {
             List<JVMMetric> buffer = new ArrayList<>();
             queue.drainTo(buffer);
 
-            if (running) {
+            if (producer != null) {
                 JVMMetricCollection metrics = JVMMetricCollection.newBuilder()
                                                                  .addAllMetrics(buffer)
                                                                  .setService(Config.Agent.SERVICE_NAME)
                                                                  .setServiceInstance(Config.Agent.INSTANCE_NAME)
                                                                  .build();
 
-                if (LOGGER.isDebugEnable()) {
-                    LOGGER.debug(
+            if (LOGGER.isDebugEnable()) {
+                LOGGER.debug(
                         ""JVM metrics reporting, topic: {}, key: {}, length: {}"", topic, metrics.getServiceInstance(),
                         buffer.size()
-                    );
-                }
+                );
+            }
 
-                producer.send(new ProducerRecord<>(
+            producer.send(new ProducerRecord<>(
                     topic,
                     metrics.getServiceInstance(),
                     Bytes.wrap(metrics.toByteArray())
-                ));
-                producer.flush();
+            ));
+            producer.flush();
             }","[{'comment': 'There seems to be a code style issue.', 'commenter': 'dmsolr'}, {'comment': 'I think it is not resolved yet. Code indentation is incorrect. Please recheck.', 'commenter': 'dmsolr'}, {'comment': 'I will recheck later', 'commenter': 'darcydai'}]"
6781,apm-sniffer/optional-reporter-plugins/kafka-reporter-plugin/src/main/java/org/apache/skywalking/apm/agent/core/kafka/KafkaJVMMetricsSender.java,"@@ -96,4 +94,11 @@ public void offer(final JVMMetric metric) {
             queue.offer(metric);
         }
     }
+
+    @Override
+    public void onStatusChanged(KafkaConnectionStatus status) {
+        if (status == KafkaConnectionStatus.CONNECTED) {
+            producer = ServiceManager.INSTANCE.findService(KafkaProducerManager.class).getProducer();
+        }
+    }","[{'comment': 'Seem like to do not have retry logical? ', 'commenter': 'dmsolr'}, {'comment': 'retry logical means that it will retry in bootstrap if KafkaProducer creates failure.  see this class named KafkaProducerManager, it has a schedule thread pool to retry until KafkaProducer created ', 'commenter': 'darcydai'}]"
6781,docs/en/setup/backend/backend-fetcher.md,"@@ -84,11 +84,15 @@ Kafka Fetcher pulls messages from Kafka Broker(s) what is the Agent delivered. C
 
 Kafka Fetcher is disabled in default, and we configure as following to enable.
 
+namespace aims to isolate multi OAP cluster when using the same Kafka cluster.
+if you set a namespace for Kafka fetcher, OAP will add a prefix to topic name. you should also set namespace in `agent.config`, the property named `plugin.kafka.namespace`.
+
 ```yaml
 kafka-fetcher:
   selector: ${SW_KAFKA_FETCHER:default}
   default:
     bootstrapServers: ${SW_KAFKA_FETCHER_SERVERS:localhost:9092}
+    namespace: ${SW_NAMESPACE:""""}","[{'comment': '1. `configuration-vocabulary.md` is not updated.', 'commenter': 'wu-sheng'}]"
6795,apm-sniffer/apm-toolkit-activation/apm-toolkit-logback-1.x-activation/src/main/resources/skywalking-plugin.def,"@@ -15,9 +15,11 @@
 # limitations under the License.
 
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.LogbackPatternConverterActivation
+toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.LogbackSkywalkingContextPatternConverterActivation
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.mdc.MDCConverterActivation
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.async.AsyncAppenderBaseInstrumentation
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.async.LoggingEventInstrumentation
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.logstash.TcpSocketAppenderActivation
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.logstash.TraceIdJsonProviderActivation
+toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.logstash.SkywalkingContextJsonProviderActivation
 toolkit-logback=org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.log.GRPCLogAppenderActivation","[{'comment': 'Losing `org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.mdc.PrintMDCSkywalkingContextInterceptor` ?', 'commenter': 'dmsolr'}, {'comment': '> Losing `org.apache.skywalking.apm.toolkit.activation.log.logback.v1.x.mdc.PrintMDCSkywalkingContextInterceptor` ?\r\n\r\nI think only `*Instrumentation` and `*Activation` classes are needed in `*.def` file', 'commenter': 'kezhenxu94'}, {'comment': 'emmm..', 'commenter': 'dmsolr'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -62,11 +85,166 @@ public Alarms getAlarm(final Duration duration, final Scope scope, final String
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        condition.setType(EventType.Error);
+        condition.setName(""Alarm"");","[{'comment': ""These conditions are specific to alarm events, which is not what we want.\r\n\r\nLet's take an example, if there is an alarm saying that `cpm(serviceA_Instance1) == 0`, we should include all events of `serviceA_Instance1` during that period, they may be `Shutdown` event, `Crash` event, etc. so that users can make sense of the alarm from the events quickly"", 'commenter': 'kezhenxu94'}, {'comment': 'Yeah, which means that there are fewer filters to query Events, which means that when an alert occurs, the number of Events associated is no longer the corresponding event, but all related Events.\r\n\r\nWhat I wanted to establish was whether Alarms and Event(s) had a unique connection, rather than all of the events associated with the application in a given time period.\r\n\r\nBecause this association method may not be accurate and accurate enough in special scenarios, it may produce incorrect association relationship.What do you think? @kezhenxu94  @wu-sheng .\r\n\r\nLooking forward to your reply. Thanks a lot.\r\n', 'commenter': 'chenmudu'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -62,11 +85,166 @@ public Alarms getAlarm(final Duration duration, final Scope scope, final String
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        condition.setType(EventType.Error);
+        condition.setName(""Alarm"");
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        Events events = null;
+        try {
+            events = getEventQueryService().queryEvents(condition);
+        } catch (Throwable e) {
+            LOGGER.error(e.getMessage(), e);
+            return alarms;
         }
-        return getQueryService().getAlarm(
-            scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        return includeEvents2Alarms(alarms, events);
+    }
+
+    private Alarms includeEvents2Alarms(Alarms alarms, Events events) {
+        if (alarms.getTotal() < 1 || CollectionUtils.isEmpty(alarms.getMsgs()) || events.getTotal() < 1 || CollectionUtils.isEmpty(events.getEvents())) {
+            return alarms;
+        }
+        Map<String, List<Event>> mappingMap = events.getEvents().stream().collect(Collectors.groupingBy(Event::getServiceInSource));
+        alarms.getMsgs().forEach(a -> {
+            switch (a.getScopeId()) {
+                case DefaultScopeDefine.SERVICE :
+                    List<Event> serviceEvent = mappingMap.get(IDManager.ServiceID.analysisId(a.getId()).getName());
+                    if (CollectionUtils.isNotEmpty(serviceEvent)) {
+                        if (serviceEvent.size() == 1) {
+                            a.setEvents(serviceEvent);
+                        } else {
+                            Event event = serviceEvent.stream().filter(e -> StringUtils.equals(a.getMessage(), e.getMessage())).findFirst().orElse(null);","[{'comment': 'Ditto, filtering according to the message makes no sense as per our goal', 'commenter': 'kezhenxu94'}, {'comment': '> Ditto, filtering according to the message makes no sense as per our goal\r\n\r\nCopy that.', 'commenter': 'chenmudu'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -62,11 +83,111 @@ public Alarms getAlarm(final Duration duration, final Scope scope, final String
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        Events events = null;
+        try {
+            events = getEventQueryService().queryEvents(condition);","[{'comment': ""So, you only get to query a maximum of 100 events. SkyWalking could easily face 300+ services, 10k+instances, and countless endpoints (even we don't recommend alarm on the endpoint). This seems not the right call."", 'commenter': 'wu-sheng'}, {'comment': 'I think we should the alarm list first, and query the event accordingly, @kezhenxu94 What do you think?\r\nIf you have concerns about performance, try concurrently query.', 'commenter': 'wu-sheng'}, {'comment': '> I think we should the alarm list first, and query the event accordingly, @kezhenxu94 What do you think?\r\n> If you have concerns about performance, try concurrently query.\r\n\r\n+1, please narrow the `condition` as much as possible, querying events by time range may cause critical performance problem', 'commenter': 'kezhenxu94'}, {'comment': ""Also, I don't think we want to include the `Alarm` events in the alarm messages, it seems to be pointless to me."", 'commenter': 'kezhenxu94'}, {'comment': 'Ok. Thanks.', 'commenter': 'chenmudu'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -62,11 +83,111 @@ public Alarms getAlarm(final Duration duration, final Scope scope, final String
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        Events events = null;
+        try {
+            events = getEventQueryService().queryEvents(condition);
+        } catch (Throwable e) {
+            LOGGER.error(e.getMessage(), e);
+            return alarms;","[{'comment': 'Why catch exceptions here? ', 'commenter': 'wu-sheng'}, {'comment': ""So I'm going to thrwos it up to `GraphQLQueryHandler#execute`, and let it deal with it in the outermost layer."", 'commenter': 'chenmudu'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -62,11 +83,111 @@ public Alarms getAlarm(final Duration duration, final Scope scope, final String
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        Events events = null;
+        try {
+            events = getEventQueryService().queryEvents(condition);
+        } catch (Throwable e) {
+            LOGGER.error(e.getMessage(), e);
+            return alarms;
+        }
+        return includeEvents2Alarms(alarms, events);
+    }
+
+    private Alarms includeEvents2Alarms(Alarms alarms, Events events) {
+        if (alarms.getTotal() < 1 || events.getTotal() < 1) {
+            return alarms;
         }
-        return getQueryService().getAlarm(
-            scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        Map<String, List<Event>> mappingMap = events.getEvents().stream().collect(Collectors.groupingBy(Event::getServiceInSource));
+        alarms.getMsgs().forEach(a -> {
+            switch (a.getScopeId()) {
+                case DefaultScopeDefine.SERVICE :
+                    List<Event> serviceEvent = mappingMap.get(IDManager.ServiceID.analysisId(a.getId()).getName());
+                    if (CollectionUtils.isNotEmpty(serviceEvent)) {
+                        a.setEvents(serviceEvent);
+                    }
+                    break;
+                case DefaultScopeDefine.SERVICE_RELATION :
+                    List<Event> sourceServiceEvent = mappingMap.get(IDManager.ServiceID.analysisId(a.getId()));
+                    List<Event> destServiceEvent = mappingMap.get(IDManager.ServiceID.analysisId(a.getId1()));
+                    if (CollectionUtils.isNotEmpty(sourceServiceEvent)) {
+                        a.setEvents(sourceServiceEvent);
+                    }
+                    if (CollectionUtils.isNotEmpty(destServiceEvent)) {
+                        a.getEvents().addAll(destServiceEvent);
+                    }
+                    break;
+                case DefaultScopeDefine.SERVICE_INSTANCE :
+                    IDManager.ServiceInstanceID.InstanceIDDefinition instanceIDDefinition = IDManager.ServiceInstanceID.analysisId(a.getId());
+                    String serviceInstanceName = instanceIDDefinition.getName();
+                    String serviceName = IDManager.ServiceID.analysisId(instanceIDDefinition.getServiceId()).getName();
+                    List<Event> serviceInstanceEvent = mappingMap.get(serviceName);
+                    if (CollectionUtils.isNotEmpty(serviceInstanceEvent)) {
+                        List<Event> filterEvents = serviceInstanceEvent.stream().filter(e -> StringUtils.equals(e.getSource().getServiceInstance(), serviceInstanceName)).collect(Collectors.toList());
+                        a.setEvents(filterEvents);
+                    }
+                    break;
+                case DefaultScopeDefine.SERVICE_INSTANCE_RELATION :
+                    IDManager.ServiceInstanceID.InstanceIDDefinition sourceInstanceIDDefinition = IDManager.ServiceInstanceID.analysisId(a.getId());
+                    String sourceServiceInstanceName = sourceInstanceIDDefinition.getName();
+                    String sourceServiceName = IDManager.ServiceID.analysisId(sourceInstanceIDDefinition.getServiceId()).getName();
+
+                    IDManager.ServiceInstanceID.InstanceIDDefinition destInstanceIDDefinition = IDManager.ServiceInstanceID.analysisId(a.getId1());
+                    String destServiceInstanceName = destInstanceIDDefinition.getName();
+                    String destServiceName = IDManager.ServiceID.analysisId(destInstanceIDDefinition.getServiceId()).getName();
+
+                    List<Event> sourceInstanceEvent = mappingMap.get(sourceServiceName);
+                    List<Event> destInstanceEvent = mappingMap.get(destServiceName);
+
+                    if (CollectionUtils.isNotEmpty(sourceInstanceEvent)) {
+                        List<Event> filterEvents = sourceInstanceEvent.stream().filter(e -> StringUtils.equals(e.getSource().getServiceInstance(), sourceServiceInstanceName)).collect(Collectors.toList());
+                        a.setEvents(filterEvents);
+                    }
+                    if (CollectionUtils.isNotEmpty(destInstanceEvent)) {
+                        List<Event> filterEvents = destInstanceEvent.stream().filter(e -> StringUtils.equals(e.getSource().getServiceInstance(), destServiceInstanceName)).collect(Collectors.toList());
+                        a.getEvents().addAll(filterEvents);
+                    }
+                    break;
+                case DefaultScopeDefine.ENDPOINT :","[{'comment': ""As for the `endpoint` scope, I'm wondering what do you think about the idea that we simply fallback to the service instance level events, because there are rarely endpoint events in my opinion, but endpoint alarms are highly possible triggered by instance events. Associating endpoint alarm with endpoint events ONLY may be correct, but it's highly possible to miss the relationship between them once there missed the endpoint events."", 'commenter': 'kezhenxu94'}, {'comment': 'Copy,  Thanks for your answer.', 'commenter': 'chenmudu'}, {'comment': ""@kezhenxu94 I think currently, I can't see a chance to see endpoint-level event, unless we have IDE or some code analysis tech to report there is logic changed in an endpoint scope.\r\n\r\n> but endpoint alarms are highly possible triggered by instance events\r\n\r\nI think you can't have endpoint-instance mapping, only could have service and service's all instances events, are you asking to get all of them?"", 'commenter': 'wu-sheng'}, {'comment': 'I need to determine the number and types of **case branches** again here. I am not sure if I understand it correctly, it seems that the `case` judgment of `ENDPOINT_RELATION` needs to be **removed** here.', 'commenter': 'chenmudu'}, {'comment': ""> I think you can't have endpoint-instance mapping, only could have service and service's all instances events.\r\n\r\nOK I missed that.\r\n\r\n> are you asking to get all of them?\r\n\r\nIf we can't get instance-endpoint mapping, listing all of the instances' events is one way, WDYT? @wu-sheng "", 'commenter': 'kezhenxu94'}, {'comment': ""> we can't get instance-endpoint mapping\r\n\r\nNo, we can't. I prefer a service level event should be enough for the endpoint, after all, the endpoint belongs to a service. The unstable of a single instance can't impact the performance of an endpoint in most cases unless there is a load balance issue."", 'commenter': 'wu-sheng'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -50,23 +65,199 @@ private AlarmQueryService getQueryService() {
         return queryService;
     }
 
+    private EventQueryService getEventQueryService() {
+        if (eventQueryService == null) {
+            this.eventQueryService = moduleManager.find(CoreModule.NAME).provider().getService(EventQueryService.class);
+        }
+        return eventQueryService;
+    }
+
+    private ForkJoinPool getForkJoinPool() {
+        if (forkJoinPool == null) {
+            this.forkJoinPool = new ForkJoinPool(Runtime.getRuntime().availableProcessors());
+        }
+        return forkJoinPool;
+    }
+
     public AlarmTrend getAlarmTrend(final Duration duration) {
         return new AlarmTrend();
     }
 
     public Alarms getAlarm(final Duration duration, final Scope scope, final String keyword,
-                           final Pagination paging, final List<Tag> tags) throws IOException {
+                           final Pagination paging, final List<Tag> tags) throws Throwable {
         Integer scopeId = null;
         if (scope != null) {
             scopeId = scope.getScopeId();
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        return includeEvents2AlarmsByCondition(alarms, condition);
+    }
+
+    private Alarms includeEvents2AlarmsByCondition(Alarms alarms, EventQueryCondition condition) throws Throwable {
+        if (alarms.getTotal() < 1) {
+            return alarms;
+        }
+        SearchEventTask searchEventTask = new SearchEventTask(alarms.getMsgs(), condition);
+        ForkJoinTask<List<AlarmMessage>> queryEventTask = getForkJoinPool().submit(searchEventTask);","[{'comment': ""A question, do we really need this? At least, do we really need this at OAP service level?\r\nMultiple conditions match(like a `OR` in SQL) could be handled by ES `should` or `SQL's OR statement`or `SQL's Union statement`. I think most database has good optimization to do this kind of query in the DB engine."", 'commenter': 'wu-sheng'}, {'comment': ""Even some storage can't, I don't know whether InfluxDB can, its DAO implementation could have the thread pool feature, provided by a util class. "", 'commenter': 'wu-sheng'}, {'comment': '`org.influxdb.querybuilder.WhereQueryImpl#orNested` and `org.influxdb.querybuilder.WhereNested#close` cooperate to use can be achieved like **OR** in SQL and ES the same effect as **should**. More info is [available here](https://github.com/influxdata/influxdb-java/blob/828298022b1a53c45ce84ccb2e03cb983469c38b/src/test/java/org/influxdb/querybuilder/api/BuiltQueryTest.java#L461).', 'commenter': 'chenmudu'}, {'comment': 'OK, it seems all storage could work in this case.', 'commenter': 'wu-sheng'}]"
6888,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/EventQueryService.java,"@@ -53,6 +56,14 @@ public Events queryEvents(final EventQueryCondition condition) throws Exception
         return getDao().queryEvents(condition);
     }
 
+    public Events queryEvents(final List<EventQueryCondition> conditions) throws Exception {","[{'comment': 'Please be explicit about the condition. In the `List<EventQueryCondition>` case, should not have UUID. You should refactor to codes to make 2 `queryEvents` more clear.', 'commenter': 'wu-sheng'}, {'comment': 'Copy.', 'commenter': 'chenmudu'}, {'comment': ""I can't see any change about this. Could you explain more?"", 'commenter': 'wu-sheng'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -50,23 +64,167 @@ private AlarmQueryService getQueryService() {
         return queryService;
     }
 
+    private EventQueryService getEventQueryService() {
+        if (eventQueryService == null) {
+            this.eventQueryService = moduleManager.find(CoreModule.NAME).provider().getService(EventQueryService.class);
+        }
+        return eventQueryService;
+    }
+
+    private ForkJoinPool getForkJoinPool() {","[{'comment': 'Legal codes, please clean your PR.', 'commenter': 'wu-sheng'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -50,23 +64,167 @@ private AlarmQueryService getQueryService() {
         return queryService;
     }
 
+    private EventQueryService getEventQueryService() {
+        if (eventQueryService == null) {
+            this.eventQueryService = moduleManager.find(CoreModule.NAME).provider().getService(EventQueryService.class);
+        }
+        return eventQueryService;
+    }
+
+    private ForkJoinPool getForkJoinPool() {
+        if (forkJoinPool == null) {
+            this.forkJoinPool = new ForkJoinPool(Runtime.getRuntime().availableProcessors());
+        }
+        return forkJoinPool;
+    }
+
     public AlarmTrend getAlarmTrend(final Duration duration) {
         return new AlarmTrend();
     }
 
     public Alarms getAlarm(final Duration duration, final Scope scope, final String keyword,
-                           final Pagination paging, final List<Tag> tags) throws IOException {
+                           final Pagination paging, final List<Tag> tags) throws Throwable {
         Integer scopeId = null;
         if (scope != null) {
             scopeId = scope.getScopeId();
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        return includeEvents2AlarmsByCondition(alarms, condition);
+    }
+
+    private Alarms includeEvents2AlarmsByCondition(Alarms alarms, EventQueryCondition condition) throws Exception {","[{'comment': '```suggestion\r\n    private Alarms findReleventEvents(Alarms alarms, EventQueryCondition condition) throws Exception {\r\n```', 'commenter': 'wu-sheng'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -50,23 +64,167 @@ private AlarmQueryService getQueryService() {
         return queryService;
     }
 
+    private EventQueryService getEventQueryService() {
+        if (eventQueryService == null) {
+            this.eventQueryService = moduleManager.find(CoreModule.NAME).provider().getService(EventQueryService.class);
+        }
+        return eventQueryService;
+    }
+
+    private ForkJoinPool getForkJoinPool() {
+        if (forkJoinPool == null) {
+            this.forkJoinPool = new ForkJoinPool(Runtime.getRuntime().availableProcessors());
+        }
+        return forkJoinPool;
+    }
+
     public AlarmTrend getAlarmTrend(final Duration duration) {
         return new AlarmTrend();
     }
 
     public Alarms getAlarm(final Duration duration, final Scope scope, final String keyword,
-                           final Pagination paging, final List<Tag> tags) throws IOException {
+                           final Pagination paging, final List<Tag> tags) throws Throwable {
         Integer scopeId = null;
         if (scope != null) {
             scopeId = scope.getScopeId();
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
+        EventQueryCondition condition = new EventQueryCondition();
         if (nonNull(duration)) {
             startSecondTB = duration.getStartTimeBucketInSec();
             endSecondTB = duration.getEndTimeBucketInSec();
+            condition.setTime(duration);
+        }
+        Alarms alarms = getQueryService().getAlarm(
+                scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+        return includeEvents2AlarmsByCondition(alarms, condition);
+    }
+
+    private Alarms includeEvents2AlarmsByCondition(Alarms alarms, EventQueryCondition condition) throws Exception {
+        if (alarms.getTotal() < 1) {
+            return alarms;
         }
-        return getQueryService().getAlarm(
-            scopeId, keyword, paging, startSecondTB, endSecondTB, tags);
+
+        final List<EventQueryCondition> allConditions = new ArrayList<>(alarms.getTotal());
+        alarms.getMsgs().stream().forEach(m -> {
+            constructCurrentSource(m).stream().forEach(c -> {
+                final EventQueryCondition currentCondition = constructNewEventQueryCondition(condition);
+                currentCondition.setSource(c);
+                allConditions.add(currentCondition);
+            });
+        });
+
+        List<Event> events = getEventQueryService().queryEvents(allConditions).getEvents();
+        Map<String, List<Event>> mappingEvents = events.stream().collect(Collectors.toMap(Event::getSourcesString, e -> {
+            final List<Event> allEvents = new ArrayList<>();
+            allEvents.add(e);
+            return allEvents;
+        }, (List<Event> firstEvents, List<Event> secondEvents) -> {
+                if (CollectionUtils.isNotEmpty(firstEvents)) {
+                    firstEvents.addAll(secondEvents);
+                }
+                return firstEvents;
+        }));
+        alarms.getMsgs().stream().forEach(a -> {
+            if (CollectionUtils.isNotEmpty(mappingEvents.get(a.getId0SourcesStr()))) {
+                a.getEvents().addAll(mappingEvents.get(a.getId0SourcesStr()));
+            }
+            if (Boolean.TRUE.equals(a.getId0LinkId1Flag()) && CollectionUtils.isNotEmpty(mappingEvents.get(a.getId1SourcesStr()))) {
+                a.getEvents().addAll(mappingEvents.get(a.getId0SourcesStr()));
+            }
+        });
+        return alarms;
+    }
+
+    private List<Source> constructCurrentSource(AlarmMessage msg) {","[{'comment': '```suggestion\r\n    private List<Source> buildEventSources(AlarmMessage msg) {\r\n```', 'commenter': 'wu-sheng'}]"
6888,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -50,23 +62,160 @@ private AlarmQueryService getQueryService() {
         return queryService;
     }
 
+    private EventQueryService getEventQueryService() {
+        if (eventQueryService == null) {
+            this.eventQueryService = moduleManager.find(CoreModule.NAME).provider().getService(EventQueryService.class);
+        }
+        return eventQueryService;
+    }
+
     public AlarmTrend getAlarmTrend(final Duration duration) {
         return new AlarmTrend();
     }
 
     public Alarms getAlarm(final Duration duration, final Scope scope, final String keyword,
-                           final Pagination paging, final List<Tag> tags) throws IOException {
+                           final Pagination paging, final List<Tag> tags) throws Throwable {","[{'comment': 'Why `Throwable`? This is rarely to see in the codes.', 'commenter': 'wu-sheng'}]"
6888,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/type/event/Source.java,"@@ -29,4 +30,18 @@
     private String service;
     private String serviceInstance;
     private String endpoint;
+
+    public String getSourcesStr() {","[{'comment': 'I am super confused about this logic, every entity has a very clear ID rule, managed by `IDManager` in SkyWalking. Why do you create so many of this kind of method in here and `AlarmMessage`?\r\nThe codes seem to be changed randomly.', 'commenter': 'wu-sheng'}]"
6952,docs/en/setup/backend/log-analyzer.md,"@@ -11,8 +11,29 @@ Java agent provides toolkit for
 to report logs through gRPC with automatic injected trace context.
 
 [SkyWalking Satellite sidecar](https://github.com/apache/skywalking-satellite) is a recommended proxy/side to
-forward logs including to use Kafka MQ to transport logs. When use this, need to open [kafka-fetcher](backend-fetcher.md#kafka-fetcher).
+forward logs including to use Kafka MQ to transport logs. When use this, need to open [kafka-fetcher](backend-fetcher.md#kafka-fetcher)
+and enable configs `enableNativeProtoLog`.
 
+### Log files collector
+
+Java agent provides toolkit for
+[log4j](../service-agent/java-agent/Application-toolkit-log4j-1.x.md#print-skywalking-context-in-your-logs),
+[log4j2](../service-agent/java-agent/Application-toolkit-log4j-2.x.md#print-skywalking-context-in-your-logs),
+[logback](../service-agent/java-agent/Application-toolkit-logback-1.x.md#print-skywalking-context-in-your-logs)
+to report logs through files with automatic injected trace context.
+
+Log framework config examples:
+- [log4j1.x fileAppender](../../../../test/e2e/e2e-service-provider/src/main/resources/log4j.properties)
+- [log4j2.x fileAppender](../../../../test/e2e/e2e-service-provider/src/main/resources/log4j2.xml)
+- [logback fileAppender](../../../../test/e2e/e2e-service-provider/src/main/resources/logback.xml)
+
+You can use [Filebeat](https://www.elastic.co/cn/beats/filebeat) 、[Fluentd](https://fluentd.org) to
+collect file logs including to use Kafka MQ to transport logs. When use this, need to open [kafka-fetcher](backend-fetcher.md#kafka-fetcher)
+and enable configs `enableNativeJsonLog`.
+
+Collector config examples:
+- [filebeat.yml](../../../../test/e2e/e2e-test/docker/kafka/filebeat.yml)
+- [fluentd.conf](../../../../test/e2e/e2e-test/docker/kafka/fluentd.conf)","[{'comment': ""We need an update here, https://github.com/apache/skywalking/blob/master/docs/en/protocols/Log-Data-Protocol.md, to update log's JSON format. We don't implement HTTP JSON format receiver yet, right?"", 'commenter': 'wu-sheng'}, {'comment': ""`We don't implement HTTP JSON format receiver yet, right?`\r\n\r\nYes, need to add and merge into this branch?"", 'commenter': 'hailin0'}, {'comment': ""We don't need to. I mean we should update the doc."", 'commenter': 'wu-sheng'}]"
6952,oap-server/server-fetcher-plugin/kafka-fetcher-plugin/src/main/java/org/apache/skywalking/oap/server/analyzer/agent/kafka/provider/KafkaFetcherProvider.java,"@@ -77,9 +78,13 @@ public void start() throws ServiceNotProvidedException {
         if (config.isEnableMeterSystem()) {
             handlerRegister.register(new MeterServiceHandler(getManager(), config));
         }
-        if (config.isEnableLog()) {
+        if (config.isEnableNativeProtoLog()) {
             handlerRegister.register(new LogHandler(getManager(), config));
         }
+        if (config.isEnableNativeJsonLog()) {
+            handlerRegister.register(new JonLogHandler(getManager(), config));","[{'comment': '```suggestion\r\n            handlerRegister.register(new JsonLogHandler(getManager(), config));\r\n```', 'commenter': 'kezhenxu94'}]"
6952,oap-server/server-fetcher-plugin/kafka-fetcher-plugin/src/main/java/org/apache/skywalking/oap/server/analyzer/agent/kafka/provider/handler/JonLogHandler.java,"@@ -0,0 +1,52 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.analyzer.agent.kafka.provider.handler;
+
+import com.google.protobuf.InvalidProtocolBufferException;
+import com.google.protobuf.util.JsonFormat;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.kafka.clients.consumer.ConsumerRecord;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.skywalking.apm.network.logging.v3.LogData;
+import org.apache.skywalking.oap.server.analyzer.agent.kafka.module.KafkaFetcherConfig;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+@Slf4j
+public class JonLogHandler extends LogHandler {
+
+    private static final JsonFormat.Parser JSON_PARSER = JsonFormat.parser().ignoringUnknownFields();","[{'comment': 'Can you reuse https://github.com/apache/skywalking/blob/d56b0b0d41eefe4b81c02aa8f4c4b9c75721acf4/oap-server/server-library/library-util/src/main/java/org/apache/skywalking/oap/server/library/util/ProtoBufJsonUtils.java#L47', 'commenter': 'kezhenxu94'}]"
6952,oap-server/server-fetcher-plugin/kafka-fetcher-plugin/src/main/java/org/apache/skywalking/oap/server/analyzer/agent/kafka/provider/handler/JsonLogHandler.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.analyzer.agent.kafka.provider.handler;
+
+import com.google.protobuf.util.JsonFormat;
+import java.io.IOException;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.kafka.clients.consumer.ConsumerRecord;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.skywalking.apm.network.logging.v3.LogData;
+import org.apache.skywalking.oap.server.analyzer.agent.kafka.module.KafkaFetcherConfig;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.ProtoBufJsonUtils;
+
+@Slf4j
+public class JsonLogHandler extends LogHandler {
+
+    private static final JsonFormat.Parser JSON_PARSER = JsonFormat.parser().ignoringUnknownFields();","[{'comment': 'Unused', 'commenter': 'kezhenxu94'}]"
6952,oap-server/server-fetcher-plugin/kafka-fetcher-plugin/src/main/java/org/apache/skywalking/oap/server/analyzer/agent/kafka/provider/handler/JsonLogHandler.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.analyzer.agent.kafka.provider.handler;
+
+import com.google.protobuf.util.JsonFormat;
+import java.io.IOException;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.kafka.clients.consumer.ConsumerRecord;
+import org.apache.kafka.common.utils.Bytes;
+import org.apache.skywalking.apm.network.logging.v3.LogData;
+import org.apache.skywalking.oap.server.analyzer.agent.kafka.module.KafkaFetcherConfig;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.ProtoBufJsonUtils;
+
+@Slf4j
+public class JsonLogHandler extends LogHandler {
+
+    private static final JsonFormat.Parser JSON_PARSER = JsonFormat.parser().ignoringUnknownFields();
+
+    private final KafkaFetcherConfig config;
+
+    public JsonLogHandler(ModuleManager moduleManager, KafkaFetcherConfig config) {
+        super(moduleManager, config);
+        this.config = config;","[{'comment': 'You may also want to override the fields `histogram` and `errorCounter` to distinguish metrics for `native-proto` and `native-json`?', 'commenter': 'kezhenxu94'}]"
7020,dist-material/bin/oapServiceShutdown.sh,"@@ -0,0 +1,30 @@
+#!/usr/bin/env sh
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+PRG=""$0""
+PRGDIR=$(dirname ""$PRG"")
+[ -z ""$SW_HOME"" ] && SW_HOME=$(cd ""$PRGDIR/.."" > /dev/null || exit 1; pwd)
+
+OAP_PID_FILE=""${SW_HOME}/bin/oap.pid""
+
+if [ -f $OAP_PID_FILE ]; then
+  kill -9 $(cat ""$OAP_PID_FILE"")
+  rm $OAP_PID_FILE
+  echo 'SkyWalking OAP stopped successfully!'","[{'comment': '```suggestion\r\nif [ -f ""$OAP_PID_FILE"" ]; then\r\n  kill -9 $(cat ""$OAP_PID_FILE"")\r\n  rm ""$OAP_PID_FILE""\r\n  echo \'SkyWalking OAP stopped successfully!\'\r\n```', 'commenter': 'kezhenxu94'}]"
7020,dist-material/bin/webappService.sh,"@@ -37,8 +37,11 @@ eval exec ""\""$_RUNJAVA\"" ${JAVA_OPTS} -jar ${JAR_PATH}/skywalking-webapp.jar \
          --logging.file=${LOG_FILE_LOCATION} \
         2>${WEBAPP_LOG_DIR}/webapp-console.log 1> /dev/null &""
 
+UI_PID_FILE=""${WEBAPP_HOME}/bin/ui.pid""
+
 if [ $? -eq 0 ]; then
-    sleep 1
+  sleep 1
+  /bin/echo -n $! > ""$UI_PID_FILE""","[{'comment': 'I suggest moving `$!` to line 39 and give it a variable, in case we add background commands between line 38 and this line, the pid will be wrong', 'commenter': 'kezhenxu94'}, {'comment': ""I don't know how to give it a variable ,because _$! is the PID of the last program your shell ran in the background_"", 'commenter': 'jgzl'}, {'comment': ""> I don't know how to give it a variable ,because _$! is the PID of the last program your shell ran in the background_\r\n\r\nI know. I mean `pid=$!`"", 'commenter': 'kezhenxu94'}]"
7020,dist-material/bin/webappServiceShutdown.sh,"@@ -0,0 +1,30 @@
+#!/usr/bin/env sh
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+PRG=""$0""
+PRGDIR=$(dirname ""$PRG"")
+[ -z ""$SW_HOME"" ] && SW_HOME=$(cd ""$PRGDIR/.."" > /dev/null || exit 1; pwd)
+
+UI_PID_FILE=""${SW_HOME}/bin/ui.pid""
+
+if [ -f $UI_PID_FILE ]; then
+  kill -9 $(cat ""$UI_PID_FILE"")","[{'comment': 'Do we really need `-9`? ', 'commenter': 'kezhenxu94'}, {'comment': 'After careful consideration, the current scenario does not need kill - 9, and using the kill command can meet the needs of graceful downtime', 'commenter': 'jgzl'}, {'comment': ""@kezhenxu94 I think with using `graceful shutting down`, we need a simple e2e to verify whether OAP and UI could be shut down successfully. Because, once we have one unexpected thread, the shutdown wouldn't work."", 'commenter': 'wu-sheng'}, {'comment': 'The simplest version is to update `JDK-version` CI process to add `shutdown` and `check` at the end of processes. @kezhenxu94 Make sense?', 'commenter': 'wu-sheng'}, {'comment': '> The simplest version is to update `JDK-version` CI process to add `shutdown` and `check` at the end of processes. @kezhenxu94 Make sense?\r\n\r\nTrack here https://github.com/apache/skywalking/issues/7022', 'commenter': 'kezhenxu94'}]"
7020,dist-material/bin/oapService.sh,"@@ -40,8 +40,11 @@ OAP_OPTIONS="" -Doap.logDir=${OAP_LOG_DIR}""
 eval exec ""\""$_RUNJAVA\"" ${JAVA_OPTS} ${OAP_OPTIONS} -classpath $CLASSPATH org.apache.skywalking.oap.server.starter.OAPServerStartUp \
         2>${OAP_LOG_DIR}/oap.log 1> /dev/null &""
 
+OAP_PID_FILE=""${OAP_HOME}/bin/oap.pid""
+
 if [ $? -eq 0 ]; then
-    sleep 1
+  sleep 1
+  /bin/echo -n $! > ""$OAP_PID_FILE""
 	echo ""SkyWalking OAP started successfully!""
 else
 	echo ""SkyWalking OAP started failure!""","[{'comment': 'Please keep 2 spaces as indentation.', 'commenter': 'dmsolr'}, {'comment': '> Please keep 2 spaces as indentation.\r\n\r\nI\'ve completed \r\n```shell\r\n  echo ""SkyWalking OAP started successfully!""\r\nelse\r\n  echo ""SkyWalking OAP started failure!""\r\n```\r\n\r\n```shell\r\n  echo ""SkyWalking Web Application started successfully!""\r\nelse\r\n  echo ""SkyWalking Web Application started failure!""\r\n```', 'commenter': 'jgzl'}]"
7020,dist-material/bin/oapServiceShutdown.sh,"@@ -0,0 +1,30 @@
+#!/usr/bin/env sh
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+PRG=""$0""
+PRGDIR=$(dirname ""$PRG"")
+[ -z ""$SW_HOME"" ] && SW_HOME=$(cd ""$PRGDIR/.."" > /dev/null || exit 1; pwd)
+
+OAP_PID_FILE=""${SW_HOME}/bin/oap.pid""
+
+if [ -f $OAP_PID_FILE ]; then
+  kill -9 $(cat ""$OAP_PID_FILE"")","[{'comment': 'SIGNAL=${SIGNAL:-TERM}\r\nPID=$(cat ""$OAP_PID_FILE"")\r\nkill -s $SIGNAL $PID', 'commenter': 'innerpeacez'}, {'comment': ' I think this is a good suggestion ', 'commenter': 'jgzl'}, {'comment': 'I\'ve complete\r\n\r\n> SIGNAL=${SIGNAL:-TERM}\r\n> PID=$(cat ""$OAP_PID_FILE"")\r\n> kill -s $SIGNAL $PID\r\n\r\nI\'ve complete\r\n\r\n```shell\r\nOAP_PID_FILE=""${SW_HOME}/bin/oap.pid""\r\n\r\nif [ -f ""$OAP_PID_FILE"" ]; then\r\n  SIGNAL=${SIGNAL:-TERM}\r\n  PID=$(cat ""$OAP_PID_FILE"")\r\n  kill -s ""$SIGNAL"" ""$PID""\r\n  rm ""$OAP_PID_FILE""\r\n  echo \'SkyWalking OAP stopped successfully!\'\r\nelse\r\n  echo \'SkyWalking OAP not exist(could not find file $OAP_PID_FILE)!\'\r\nfi\r\n```', 'commenter': 'jgzl'}, {'comment': 'What I mean is: Let the user control the SIGNAL used by himself in a variable way, we only provide a default SIGNAL.', 'commenter': 'innerpeacez'}]"
7020,dist-material/bin/oapService.sh,"@@ -40,10 +40,14 @@ OAP_OPTIONS="" -Doap.logDir=${OAP_LOG_DIR}""
 eval exec ""\""$_RUNJAVA\"" ${JAVA_OPTS} ${OAP_OPTIONS} -classpath $CLASSPATH org.apache.skywalking.oap.server.starter.OAPServerStartUp \
         2>${OAP_LOG_DIR}/oap.log 1> /dev/null &""
 
+PID=""$!""
+OAP_PID_FILE=""${OAP_HOME}/bin/oap.pid""
+
 if [ $? -eq 0 ]; then","[{'comment': '`$?` should be also extracted into variable, now, and should be right after `eval exec ...`', 'commenter': 'kezhenxu94'}, {'comment': 'like this\r\n```shell\r\nOAP_PID_FILE=""${OAP_HOME}/bin/oap.pid""\r\neval exec ""\\""$_RUNJAVA\\"" ${JAVA_OPTS} ${OAP_OPTIONS} -classpath $CLASSPATH org.apache.skywalking.oap.server.starter.OAPServerStartUp \\\r\n        2>${OAP_LOG_DIR}/oap.log 1> /dev/null & /bin/echo -n ""$$"" > ""$OAP_PID_FILE""""\r\n```', 'commenter': 'jgzl'}, {'comment': '> like this\r\n> \r\n> ```shell\r\n> OAP_PID_FILE=""${OAP_HOME}/bin/oap.pid""\r\n> eval exec ""\\""$_RUNJAVA\\"" ${JAVA_OPTS} ${OAP_OPTIONS} -classpath $CLASSPATH org.apache.skywalking.oap.server.starter.OAPServerStartUp \\\r\n>         2>${OAP_LOG_DIR}/oap.log 1> /dev/null & /bin/echo -n ""$$"" > ""$OAP_PID_FILE""""\r\n> ```\r\n\r\nIt\'s ok, but you have to remove the PID file if `$? != 0`, right?', 'commenter': 'kezhenxu94'}, {'comment': '> > like this\r\n> > ```shell\r\n> > OAP_PID_FILE=""${OAP_HOME}/bin/oap.pid""\r\n> > eval exec ""\\""$_RUNJAVA\\"" ${JAVA_OPTS} ${OAP_OPTIONS} -classpath $CLASSPATH org.apache.skywalking.oap.server.starter.OAPServerStartUp \\\r\n> >         2>${OAP_LOG_DIR}/oap.log 1> /dev/null & /bin/echo -n ""$$"" > ""$OAP_PID_FILE""""\r\n> > ```\r\n> \r\n> It\'s ok, but you have to remove the PID file if `$? != 0`, right?\r\n\r\nI\'m sorry , i didn\'t test before, this script can\'t get correct PID. tomcat shell script \r\n```shell\r\n  else\r\n    eval $_NOHUP ""\\""$_RUNJAVA\\"""" ""\\""$LOGGING_CONFIG\\"""" $LOGGING_MANAGER ""$JAVA_OPTS"" ""$CATALINA_OPTS"" \\\r\n      -D$ENDORSED_PROP=""\\""$JAVA_ENDORSED_DIRS\\"""" \\\r\n      -classpath ""\\""$CLASSPATH\\"""" \\\r\n      -Dcatalina.base=""\\""$CATALINA_BASE\\"""" \\\r\n      -Dcatalina.home=""\\""$CATALINA_HOME\\"""" \\\r\n      -Djava.io.tmpdir=""\\""$CATALINA_TMPDIR\\"""" \\\r\n      org.apache.catalina.startup.Bootstrap ""$@"" start \\\r\n      >> ""$CATALINA_OUT"" 2>&1 ""&""\r\n\r\n  fi\r\n\r\n  if [ ! -z ""$CATALINA_PID"" ]; then\r\n    echo $! > ""$CATALINA_PID""\r\n  fi\r\n```', 'commenter': 'jgzl'}, {'comment': '@kezhenxu94 Because $! or $$ is used after exec, the PID obtained is the PID of the shell of the child process executed by exec, so the definition of $! can only be defined after the execution of exec. The reference tomcat\'s startup.sh is also written like this .\r\n\r\n```shell\r\n  if [ ! -z ""$CATALINA_PID"" ]; then\r\n    echo $! > ""$CATALINA_PID""\r\n  fi\r\n```', 'commenter': 'jgzl'}, {'comment': '@kezhenxu94 Because $! or $$ is used after exec, the PID obtained is the PID of the shell of the child process executed by exec, so the definition of $! can only be defined after the execution of exec. The reference tomcat\'s startup.sh is also written like this .\r\n\r\n```shell\r\n  if [ ! -z ""$CATALINA_PID"" ]; then\r\n    echo $! > ""$CATALINA_PID""\r\n  fi\r\n```', 'commenter': 'jgzl'}]"
7027,CHANGES.md,"@@ -8,6 +8,7 @@ Release Notes.
 * Add OpenSearch as storage option.
 * Upgrade Kubernetes Java client dependency to 11.0.
 * Fix plugin test script error in macOS.
+* Make the number of core worker in meter converter thread pool configurable.","[{'comment': 'This should be a backend changelog.', 'commenter': 'wu-sheng'}]"
7027,oap-server/server-fetcher-plugin/prometheus-fetcher-plugin/src/main/java/org/apache/skywalking/oap/server/fetcher/prometheus/provider/PrometheusFetcherConfig.java,"@@ -28,13 +28,15 @@
 
 @Getter
 public class PrometheusFetcherConfig extends ModuleConfig {
+
+    private int meterConvertWorker = Runtime.getRuntime().availableProcessors() / 2;","[{'comment': 'You will face a bug when `Runtime.getRuntime().availableProcessors()`=1, I think. \r\nAnd take a look at `BulkConsumePool`, this usually accepts a System ENV override.', 'commenter': 'wu-sheng'}, {'comment': 'the field name is different with the one in config file\r\n\r\n\r\n```diff\r\n- meterConvertWorker\r\n+ maxConvertWorker\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'I would like to default the worker number to `Runtime.getRuntime().availableProcessors()`(the min value should be 1). An env could override it. ', 'commenter': 'hanahmily'}, {'comment': '> I would like to default the worker number to `Runtime.getRuntime().availableProcessors()`(the min value should be 1). An env could override it.\r\n\r\nReally need so many threads? This should not cost too many resources, as prom data structure is not complex and data set is not very big.', 'commenter': 'wu-sheng'}, {'comment': ""I will avoid this case, core == 1. But I don't think we need EnvUtil to do it, because we have provided a configuration option that can override the value."", 'commenter': 'dmsolr'}, {'comment': 'Using module config to override works for me.', 'commenter': 'wu-sheng'}]"
7027,oap-server/server-bootstrap/src/main/resources/application.yml,"@@ -337,7 +337,9 @@ envoy-metric:
 prometheus-fetcher:
   selector: ${SW_PROMETHEUS_FETCHER:-}
   default:
+    active: ${SW_PROMETHEUS_FETCHER_ACTIVE:false}
     enabledRules: ${SW_PROMETHEUS_FETCHER_ENABLED_RULES:""self""}
+    maxConvertWorker: ${SW_PROMETHEUS_FETCHER_NUM_CONVERT_WORKER:-}","[{'comment': ""I don't think we support `-` in these config items (only `selector` supports `-` I think)"", 'commenter': 'kezhenxu94'}]"
7027,docs/en/setup/backend/configuration-vocabulary.md,"@@ -210,6 +210,8 @@ core|default|role|Option values, `Mixed/Receiver/Aggregator`. **Receiver** mode
 | - | - | maxMessageSize | Sets the maximum message size allowed to be received on the server. Empty means 4 MiB | - | 4M(based on Netty) |
 | prometheus-fetcher | default | Read [fetcher doc](backend-fetcher.md) for more details | - | - |
 | - | - | active | Activate the Prometheus fetcher. | SW_PROMETHEUS_FETCHER_ACTIVE | false |
+| - | - | enabledRules | Enable rules. | SW_PROMETHEUS_FETCHER_ENABLED_RULES | self |
+| - | - | numConvertWorker | The maximize meter convert worker. | SW_PROMETHEUS_FETCHER_NUM_CONVERT_WORKER | half the number of CPU core(s) |   ","[{'comment': 'Wrong name here too…', 'commenter': 'kezhenxu94'}]"
7027,oap-server/server-bootstrap/src/main/resources/application.yml,"@@ -337,7 +337,9 @@ envoy-metric:
 prometheus-fetcher:
   selector: ${SW_PROMETHEUS_FETCHER:-}
   default:
+    active: ${SW_PROMETHEUS_FETCHER_ACTIVE:false}
     enabledRules: ${SW_PROMETHEUS_FETCHER_ENABLED_RULES:""self""}
+    # maxConvertWorker: ${SW_PROMETHEUS_FETCHER_NUM_CONVERT_WORKER:8}","[{'comment': 'Commenting out this line is not a good idea, it makes the env var not work and the user have to edit this file. Please default this value to 0 and set it to cpuCore / 2 if it’s 0. ', 'commenter': 'kezhenxu94'}, {'comment': '0 or negative, should make the codes falling back to core / 2.', 'commenter': 'wu-sheng'}, {'comment': 'Got it', 'commenter': 'dmsolr'}]"
7145,oap-server/analyzer/meter-analyzer/src/main/java/org/apache/skywalking/oap/meter/analyzer/dsl/counter/CounterWindow.java,"@@ -47,15 +47,20 @@
     public Tuple2<Long, Double> increase(String name, ImmutableMap<String, String> labels, Double value, long windowSize, long now) {
         ID id = new ID(name, labels);
         if (!windows.containsKey(id)) {
-            windows.put(id, new LinkedList<>());
+            windows.put(id, new PriorityQueue<>());
         }
+
         Queue<Tuple2<Long, Double>> window = windows.get(id);
         window.offer(Tuple.of(now, value));
-        Tuple2<Long, Double> ps = window.element();
-        if ((now - ps._1) >= windowSize) {
-            window.remove();
+
+        long waterLevel = now - windowSize + 60;","[{'comment': 'What does `60` mean?', 'commenter': 'wu-sheng'}]"
7145,oap-server/analyzer/meter-analyzer/src/main/java/org/apache/skywalking/oap/meter/analyzer/dsl/counter/CounterWindow.java,"@@ -47,15 +47,27 @@
     public Tuple2<Long, Double> increase(String name, ImmutableMap<String, String> labels, Double value, long windowSize, long now) {
         ID id = new ID(name, labels);
         if (!windows.containsKey(id)) {
-            windows.put(id, new LinkedList<>());
+            windows.put(id, new PriorityQueue<>());
         }
+
         Queue<Tuple2<Long, Double>> window = windows.get(id);
         window.offer(Tuple.of(now, value));
-        Tuple2<Long, Double> ps = window.element();
-        if ((now - ps._1) >= windowSize) {
-            window.remove();
+
+        long waterLevel = now - windowSize;
+        Tuple2<Long, Double> peek = window.peek();
+        if (peek._1 > waterLevel) {
+            return peek;
+        }
+        Tuple2<Long, Double> result = peek;
+        while (peek._1 <= waterLevel) {
+            result = window.poll();
+            peek = window.element();
         }","[{'comment': 'This logic seems correct, have you tried `Collections.binarySearch()`? `window` is an ordered list, right? If so, a binary search would be much faster than a sequential search。', 'commenter': 'wu-sheng'}]"
7145,oap-server/analyzer/meter-analyzer/src/main/java/org/apache/skywalking/oap/meter/analyzer/dsl/counter/CounterWindow.java,"@@ -42,20 +42,46 @@
 
     public static final CounterWindow INSTANCE = new CounterWindow();
 
+    private final Map<ID, Tuple2<Long, Double>> lastElementMap = Maps.newHashMap();
     private final Map<ID, Queue<Tuple2<Long, Double>>> windows = Maps.newHashMap();
 
     public Tuple2<Long, Double> increase(String name, ImmutableMap<String, String> labels, Double value, long windowSize, long now) {
         ID id = new ID(name, labels);
         if (!windows.containsKey(id)) {
-            windows.put(id, new LinkedList<>());
+            windows.put(id, new PriorityQueue<>());
         }
+
         Queue<Tuple2<Long, Double>> window = windows.get(id);
         window.offer(Tuple.of(now, value));
-        Tuple2<Long, Double> ps = window.element();
-        if ((now - ps._1) >= windowSize) {
-            window.remove();
+        long waterLevel = now - windowSize;
+        Tuple2<Long, Double> peek = window.peek();
+        if (peek._1 > waterLevel) {
+            return peek;
+        }
+
+        Tuple2<Long, Double> result = peek;
+        while (peek._1 < waterLevel) {
+            result = window.poll();
+            peek = window.element();
+        }
+
+        if (waterLevel - result._1 <= peek._1 - waterLevel) {","[{'comment': '```suggestion\r\n        // Choose the closed slot to the expected timestamp\r\n        if (waterLevel - result._1 <= peek._1 - waterLevel) {\r\n```', 'commenter': 'wu-sheng'}]"
7215,CHANGES.md,"@@ -60,9 +60,10 @@ Release Notes.
 * Performance: cache regex pattern and result, optimize string concatenation in Envy ALS analyzer.
 * Performance: cache metrics id and entity id in `Metrics` and `ISource`.
 * Performance: enhance persistent session mechanism, about differentiating cache timeout for different dimensionality
-  metrics. The timeout of the cache for minute and hour level metrics has been prolonged to ~5 min.
+  metrics. The timeout of the cache for minute and hour level metrics has been prolonged to ~5 min. ","[{'comment': ""Why this line keeps changing in PRs? I think trimming tailing spaces is correct but you're adding a space here"", 'commenter': 'kezhenxu94'}]"
7215,CHANGES.md,"@@ -60,9 +60,10 @@ Release Notes.
 * Performance: cache regex pattern and result, optimize string concatenation in Envy ALS analyzer.
 * Performance: cache metrics id and entity id in `Metrics` and `ISource`.
 * Performance: enhance persistent session mechanism, about differentiating cache timeout for different dimensionality
-  metrics. The timeout of the cache for minute and hour level metrics has been prolonged to ~5 min.
+  metrics. The timeout of the cache for minute and hour level metrics has been prolonged to ~5 min. 
 * Performance: Add L1 aggregation flush period, which reduce the CPU load and help young GC.
 * Support connectTimeout and socketTimeout settings for ElasticSearch6 and ElasticSearch7 storages.
+* Upgrade etcd to v3.x.","[{'comment': '```suggestion\r\n* Upgrade etcd cluster coordinator and dynamic configuration to v3.x.\r\n```', 'commenter': 'kezhenxu94'}]"
7215,oap-server/server-configuration/configuration-etcd/src/test/java/org/apache/skywalking/oap/server/configuration/etcd/ITEtcdConfigurationTest.java,"@@ -18,99 +18,111 @@
 
 package org.apache.skywalking.oap.server.configuration.etcd;
 
+import com.google.common.collect.Lists;
+import io.etcd.jetcd.ByteSequence;
+import io.etcd.jetcd.Client;
+import io.etcd.jetcd.KV;
 import java.io.FileNotFoundException;
 import java.io.Reader;
-import java.net.URI;
-import java.util.List;
+import java.nio.charset.Charset;
 import java.util.Map;
 import java.util.Properties;
-import mousio.etcd4j.EtcdClient;
-import mousio.etcd4j.promises.EtcdResponsePromise;
-import mousio.etcd4j.responses.EtcdKeysResponse;
+import java.util.concurrent.TimeUnit;
+import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.util.PropertyPlaceholderHelper;
 import org.apache.skywalking.oap.server.library.module.ApplicationConfiguration;
+import org.apache.skywalking.oap.server.library.module.ModuleConfigException;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.module.ModuleNotFoundException;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
 import org.apache.skywalking.oap.server.library.util.ResourceUtils;
-import org.junit.Before;
+import org.junit.AfterClass;
+import org.junit.BeforeClass;
 import org.junit.Test;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
+import org.testcontainers.containers.GenericContainer;
+import org.testcontainers.utility.DockerImageName;
 import org.yaml.snakeyaml.Yaml;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.junit.Assert.assertNull;
-import static org.junit.Assert.assertTrue;
 
+@Slf4j
 public class ITEtcdConfigurationTest {
+    private static final GenericContainer CONTAINER = new GenericContainer(DockerImageName.parse(""bitnami/etcd:3.5.0""));
+    private static EtcdConfigurationTestProvider PROVIDER;
 
-    private static final Logger LOGGER = LoggerFactory.getLogger(ITEtcdConfigurationTest.class);
+    private static final String TEST_VALUE = ""value"";
 
-    private final Yaml yaml = new Yaml();
+    @BeforeClass
+    public static void beforeClass() throws FileNotFoundException, ModuleConfigException, ModuleNotFoundException, ModuleStartException {
+        CONTAINER.setEnv(Lists.newArrayList(
+            ""ALLOW_NONE_AUTHENTICATION=yes""
+        ));
+        CONTAINER.start();","[{'comment': ""Need some `waitStrategy` to wait for the container's healthiness."", 'commenter': 'kezhenxu94'}]"
7215,apm-sniffer/apm-sdk-plugin/pom.xml,"@@ -28,92 +28,8 @@
 
     <artifactId>apm-sdk-plugin</artifactId>
     <modules>
-        <module>dubbo-plugin</module>","[{'comment': 'What are you doing?', 'commenter': 'wu-sheng'}]"
7215,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -37,106 +37,54 @@
         </dependency>
 
         <dependency>
-            <groupId>io.netty</groupId>
-            <artifactId>netty-codec-dns</artifactId>
+            <groupId>io.etcd</groupId>
+            <artifactId>jetcd-core</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>io.netty</groupId>
-            <artifactId>netty-codec-http</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-core</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>io.netty</groupId>
-            <artifactId>netty-handler</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-netty</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>io.netty</groupId>
-            <artifactId>netty-resolver-dns</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-protobuf</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>org.mousio</groupId>
-            <artifactId>etcd4j</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-stub</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>com.fasterxml.jackson.module</groupId>
-            <artifactId>jackson-module-afterburner</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-grpclb</artifactId>
         </dependency>
 
+        <dependency>","[{'comment': '*Critical OSS Vulnerability:*  &nbsp;\n### pkg:maven/org.yaml/snakeyaml\n1 Critical, 0 Severe, 0 Moderate and 0 Unknown vulnerabilities have been found in a direct dependency \n\n\n\n<!-- Lift_Details -->\n<details>\n<summary><b>CRITICAL Vulnerabilities (1)</b></summary>\n\n<ul>\n\n  ***\n  > #### [CVE-2017-18640] The Alias feature in SnakeYAML 1.18 allows entity expansion during a load operat...\n  > The Alias feature in SnakeYAML 1.18 allows entity expansion during a load operation, a related issue to CVE-2003-1564.\n  >\n  > **CVSS Score:** 7.5\n  >\n  > **CVSS Vector:** CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n\n  ***\n</ul>\n\n</details>\n\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}, {'comment': 'ignore', 'commenter': 'dmsolr'}, {'comment': ""I've recorded this as ignored for this pull request. If you change your mind, just comment `@sonatype-lift unignore`."", 'commenter': 'sonatype-lift[bot]'}]"
7215,tools/dependencies/known-oap-backend-dependencies.txt,"@@ -117,26 +120,23 @@ lucene-spatial-extras-7.3.1.jar
 lucene-spatial3d-7.3.1.jar
 lucene-suggest-7.3.1.jar
 lz4-java-1.6.0.jar
-minimal-json-0.9.5.jar
 moshi-1.5.0.jar
 msgpack-core-0.8.16.jar
 mvel2-2.4.8.Final.jar
 nacos-api-1.4.2.jar
 nacos-client-1.4.2.jar
 nacos-common-1.4.2.jar
-netty-buffer-4.1.65.Final.jar
-netty-codec-4.1.65.Final.jar
-netty-codec-dns-4.1.65.Final.jar
+netty-buffer-4.1.51.Final.jar
+netty-codec-4.1.51.Final.jar
 netty-codec-http-4.1.65.Final.jar
 netty-codec-http2-4.1.51.Final.jar
 netty-codec-socks-4.1.51.Final.jar
-netty-common-4.1.65.Final.jar
+netty-common-4.1.51.Final.jar
 netty-handler-4.1.65.Final.jar
 netty-handler-proxy-4.1.51.Final.jar
-netty-resolver-4.1.65.Final.jar
-netty-resolver-dns-4.1.65.Final.jar
+netty-resolver-4.1.51.Final.jar
 netty-tcnative-boringssl-static-2.0.39.Final.jar
-netty-transport-4.1.65.Final.jar
+netty-transport-4.1.51.Final.jar","[{'comment': ""I don't think you should change these versions, they are upgraded before due to CVEs"", 'commenter': 'kezhenxu94'}]"
7215,tools/dependencies/known-oap-backend-dependencies.txt,"@@ -90,7 +94,6 @@ jna-4.5.1.jar
 joda-time-2.10.5.jar
 jopt-simple-4.6.jar
 jose4j-0.7.6.jar
-json-flattener-0.6.0.jar","[{'comment': 'Remove corresponding item in `dist/LICENSE` file', 'commenter': 'kezhenxu94'}]"
7215,oap-server/server-library/library-client/pom.xml,"@@ -47,6 +47,18 @@
             <groupId>io.grpc</groupId>
             <artifactId>grpc-netty</artifactId>
         </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-http2</artifactId>
+        </dependency>
+        <dependency>","[{'comment': '*Critical OSS Vulnerability:*  &nbsp;\n### pkg:maven/io.netty/netty-handler\n1 Critical, 0 Severe, 0 Moderate and 0 Unknown vulnerabilities have been found in a direct dependency \n\n\n\n<!-- Lift_Details -->\n<details>\n<summary><b>CRITICAL Vulnerabilities (1)</b></summary>\n\n<ul>\n\n  ***\n  > #### [CVE-2016-4970] handler/ssl/OpenSslEngine.java in Netty 4.0.x before 4.0.37.Final and 4.1.x befo...\n  > handler/ssl/OpenSslEngine.java in Netty 4.0.x before 4.0.37.Final and 4.1.x before 4.1.1.Final allows remote attackers to cause a denial of service (infinite loop).\n  >\n  > **CVSS Score:** 7.5\n  >\n  > **CVSS Vector:** CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n\n  ***\n</ul>\n\n</details>\n\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}, {'comment': 'ignore', 'commenter': 'dmsolr'}, {'comment': ""I've recorded this as ignored for this pull request. If you change your mind, just comment `@sonatype-lift unignore`."", 'commenter': 'sonatype-lift[bot]'}]"
7215,oap-server/server-library/library-server/pom.xml,"@@ -59,5 +59,21 @@
             <groupId>org.eclipse.jetty</groupId>
             <artifactId>jetty-servlet</artifactId>
         </dependency>
+        <dependency>","[{'comment': '*Critical OSS Vulnerability:*  &nbsp;\n### pkg:maven/io.netty/netty-handler\n1 Critical, 0 Severe, 0 Moderate and 0 Unknown vulnerabilities have been found in a direct dependency \n\n\n\n<!-- Lift_Details -->\n<details>\n<summary><b>CRITICAL Vulnerabilities (1)</b></summary>\n\n<ul>\n\n  ***\n  > #### [CVE-2016-4970] handler/ssl/OpenSslEngine.java in Netty 4.0.x before 4.0.37.Final and 4.1.x befo...\n  > handler/ssl/OpenSslEngine.java in Netty 4.0.x before 4.0.37.Final and 4.1.x before 4.1.1.Final allows remote attackers to cause a denial of service (infinite loop).\n  >\n  > **CVSS Score:** 7.5\n  >\n  > **CVSS Vector:** CVSS:3.0/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:N/A:H\n\n  ***\n</ul>\n\n</details>\n\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}, {'comment': 'ignore', 'commenter': 'dmsolr'}, {'comment': ""I've recorded this as ignored for this pull request. If you change your mind, just comment `@sonatype-lift unignore`."", 'commenter': 'sonatype-lift[bot]'}]"
7215,oap-server-bom/pom.xml,"@@ -73,10 +73,66 @@
         <commons-beanutils.version>1.9.4</commons-beanutils.version>
         <flatbuffers-java.version>1.12.0</flatbuffers-java.version>
         <postgresql.version>42.2.18</postgresql.version>
+        <jetcd.version>0.5.3</jetcd.version>
+        <testcontainers.version>1.15.3</testcontainers.version>
     </properties>
 
     <dependencyManagement>
         <dependencies>
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-handler</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-resolver-dns</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-codec</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-codec-dns</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-codec-http</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-codec-http2</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-handler-proxy</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-transport-native-unix-common</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+
+            <dependency>
+                <groupId>io.netty</groupId>
+                <artifactId>netty-transport-native-epoll</artifactId>
+                <version>${netty.version}</version>
+            </dependency>
+","[{'comment': ""Let's replace this with another bom\r\n```suggestion\r\n            <dependency>\r\n                <groupId>io.netty</groupId>\r\n                <artifactId>netty-bom</artifactId>\r\n                <version>${netty.version}</version>\r\n                <scope>import</scope>\r\n                <type>pom</type>\r\n            </dependency>\r\n```"", 'commenter': 'kezhenxu94'}]"
7215,oap-server/server-cluster-plugin/cluster-etcd-plugin/src/test/java/org/apache/skywalking/oap/server/cluster/plugin/etcd/AbstractEtcdContainerBaseTest.java,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.cluster.plugin.etcd;
+
+import com.google.common.collect.Lists;
+import org.testcontainers.containers.GenericContainer;
+import org.testcontainers.containers.wait.strategy.LogMessageWaitStrategy;
+import org.testcontainers.utility.DockerImageName;
+
+abstract class AbstractEtcdContainerBaseTest {
+    static final GenericContainer CONTAINER = new GenericContainer(DockerImageName.parse(""bitnami/etcd:3.5.0""));
+
+
+    static {
+        CONTAINER.setWaitStrategy(new LogMessageWaitStrategy().withRegEx("".*etcd setup finished!.*""));
+        CONTAINER.withReuse(false);
+        CONTAINER.setEnv(Lists.newArrayList(""ALLOW_NONE_AUTHENTICATION=yes""));
+        CONTAINER.start();
+    }
+}","[{'comment': ""Sharing a container between tests is not a good practice in my opinion, making this container static is also not a good choice as it will be started even I don't want to run the test.\r\n\r\nPlease use this https://github.com/apache/skywalking/pull/7215#discussion_r663316495\r\n"", 'commenter': 'kezhenxu94'}]"
7215,oap-server/server-cluster-plugin/cluster-etcd-plugin/src/test/java/org/apache/skywalking/oap/server/cluster/plugin/etcd/ITClusterEtcdPluginTest.java,"@@ -18,63 +18,57 @@
 
 package org.apache.skywalking.oap.server.cluster.plugin.etcd;
 
-import java.net.URI;
+import io.etcd.jetcd.ByteSequence;
+import io.etcd.jetcd.Client;
+import io.etcd.jetcd.kv.GetResponse;
+import io.etcd.jetcd.options.GetOption;
+import java.nio.charset.Charset;
 import java.util.List;
-import mousio.etcd4j.EtcdClient;
-import mousio.etcd4j.responses.EtcdKeysResponse;
+import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.oap.server.core.cluster.RemoteInstance;
 import org.apache.skywalking.oap.server.core.remote.client.Address;
 import org.apache.skywalking.oap.server.library.module.ModuleDefineHolder;
 import org.apache.skywalking.oap.server.telemetry.api.HealthCheckMetrics;
-import org.junit.After;
 import org.junit.Before;
 import org.junit.Test;
 import org.powermock.reflect.Whitebox;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
 import static org.mockito.Mockito.doNothing;
 import static org.mockito.Mockito.mock;
 
-public class ITClusterEtcdPluginTest {
-
-    private static final Logger LOGGER = LoggerFactory.getLogger(ITClusterEtcdPluginTest.class);
-
+@Slf4j
+public class ITClusterEtcdPluginTest extends AbstractEtcdContainerBaseTest {","[{'comment': 'Do not use inheritance as I said https://github.com/apache/skywalking/pull/7215#discussion_r663316390\r\n\r\nplease use 👇 in each test class\r\n\r\n\r\n```java\r\n\r\n    @ClassRule\r\n    private static final GenericContainer container =\r\n        new GenericContainer(DockerImageName.parse(""bitnami/etcd:3.5.0""))\r\n            .waitingFor(Wait.forLogMessage("".*etcd setup finished!.*"", 1))\r\n            .withEnv(Collections.singletonMap(""ALLOW_NONE_AUTHENTICATION"", ""yes""));\r\n```', 'commenter': 'kezhenxu94'}]"
7215,oap-server/server-cluster-plugin/cluster-etcd-plugin/src/main/java/org/apache/skywalking/oap/server/cluster/plugin/etcd/EtcdCoordinator.java,"@@ -97,54 +126,62 @@ public EtcdCoordinator(final ModuleDefineHolder manager, final ClusterModuleEtcd
 
     @Override
     public void registerRemote(RemoteInstance remoteInstance) throws ServiceRegisterException {
-
         if (needUsingInternalAddr()) {
-            remoteInstance = new RemoteInstance(new Address(config.getInternalComHost(), config.getInternalComPort(), true));
+            remoteInstance = new RemoteInstance(
+                new Address(config.getInternalComHost(), config.getInternalComPort(), true));
         }
 
         this.selfAddress = remoteInstance.getAddress();
-
-        EtcdEndpoint endpoint = new EtcdEndpoint.Builder().serviceName(serviceName)
-                                                          .host(selfAddress.getHost())
-                                                          .port(selfAddress.getPort())
-                                                          .build();
+        final EtcdEndpoint endpoint = new EtcdEndpoint.Builder().serviceName(serviceName)
+                                                                .host(selfAddress.getHost())
+                                                                .port(selfAddress.getPort())
+                                                                .build();
         try {
             initHealthChecker();
-            client.putDir(serviceName).send();
-            String key = buildKey(serviceName, selfAddress, remoteInstance);
-            String json = new Gson().toJson(endpoint);
-            EtcdResponsePromise<EtcdKeysResponse> promise = client.put(key, json).ttl(KEY_TTL).send();
-            //check register.
-            promise.get();
-            renew(client, key, json);
+
+            final Lease leaseClient = client.getLeaseClient();
+            final long leaseID = leaseClient.grant(30L).get().getID();
+
+            ByteSequence instance = ByteSequence.from(GSON.toJson(endpoint), Charset.defaultCharset());
+            client.getKVClient()
+                  .put(
+                      buildKey(serviceName, selfAddress, remoteInstance),
+                      instance,
+                      PutOption.newBuilder().withLeaseId(leaseID).build()
+                  )
+                  .get();
             healthChecker.health();
+
+            client.getLeaseClient().keepAlive(leaseID, new StreamObserver<LeaseKeepAliveResponse>() {
+                @Override
+                public void onNext(final LeaseKeepAliveResponse response) {
+                    if (log.isDebugEnabled()) {
+                        log.debug(""Refresh lease id = {}, ttl = {}"", response.getID(), response.getTTL());
+                    }
+                }
+
+                @Override
+                public void onError(final Throwable throwable) {
+                    log.error("""", throwable);","[{'comment': 'Add some informative message so we can distinguish this in massive logs, also, do we need to mark it as unhealthy here?\r\n\r\n```suggestion\r\n                    log.error(""Failed to keep alive in Etcd coordinator"", throwable);\r\n                    healthChecker.unHealth(throwable);\r\n```', 'commenter': 'kezhenxu94'}]"
7215,tools/dependencies/known-oap-backend-dependencies-es7.txt,"@@ -129,19 +131,17 @@ nacos-client-1.4.2.jar
 nacos-common-1.4.2.jar
 netty-buffer-4.1.65.Final.jar
 netty-codec-4.1.65.Final.jar
-netty-codec-dns-4.1.65.Final.jar","[{'comment': 'Why codec-dns missing?', 'commenter': 'wu-sheng'}, {'comment': ""we don't depend on it."", 'commenter': 'dmsolr'}]"
7215,dist-material/release-docs/NOTICE,"@@ -896,3 +896,17 @@ This distribution has a binary dependency on jersey, which is available under th
 License. The source code of jersey can be found at https://github.com/jersey/jersey/.
 
 ========================================================================
+
+------","[{'comment': 'What is this?', 'commenter': 'wu-sheng'}]"
7215,oap-server/server-cluster-plugin/cluster-etcd-plugin/pom.xml,"@@ -37,106 +37,64 @@
         </dependency>
 
         <dependency>
-            <groupId>io.netty</groupId>
-            <artifactId>netty-codec-dns</artifactId>
+            <groupId>io.etcd</groupId>
+            <artifactId>jetcd-core</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>io.netty</groupId>
-            <artifactId>netty-codec-http</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-core</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-netty</artifactId>
         </dependency>
 
         <dependency>
             <groupId>io.netty</groupId>
-            <artifactId>netty-handler</artifactId>
+            <artifactId>netty-codec-http2</artifactId>
         </dependency>
 
         <dependency>
             <groupId>io.netty</groupId>
-            <artifactId>netty-resolver-dns</artifactId>
+            <artifactId>netty-handler-proxy</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>org.mousio</groupId>
-            <artifactId>etcd4j</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-protobuf</artifactId>
         </dependency>
 
         <dependency>
-            <groupId>com.fasterxml.jackson.module</groupId>
-            <artifactId>jackson-module-afterburner</artifactId>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-stub</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>io.grpc</groupId>
+            <artifactId>grpc-grpclb</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.yaml</groupId>
+            <artifactId>snakeyaml</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.testcontainers</groupId>
+            <artifactId>testcontainers</artifactId>
+        </dependency>
     </dependencies>
 
     <profiles>
         <profile>
             <id>CI-with-IT</id>
             <build>
                 <plugins>
-                    <plugin>
-                        <groupId>io.fabric8</groupId>
-                        <artifactId>docker-maven-plugin</artifactId>","[{'comment': 'Why this gets removed?', 'commenter': 'wu-sheng'}, {'comment': 'Because use testcontainer instead?', 'commenter': 'wu-sheng'}, {'comment': 'Yes, `testcontainers` is more friendly.', 'commenter': 'dmsolr'}]"
7215,oap-server/server-library/library-client/pom.xml,"@@ -47,6 +47,18 @@
             <groupId>io.grpc</groupId>
             <artifactId>grpc-netty</artifactId>
         </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-http2</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-handler</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-handler-proxy</artifactId>
+        </dependency>","[{'comment': 'No code change in this maven module, why change library?', 'commenter': 'wu-sheng'}]"
7215,oap-server/server-library/library-server/pom.xml,"@@ -59,5 +59,21 @@
             <groupId>org.eclipse.jetty</groupId>
             <artifactId>jetty-servlet</artifactId>
         </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-handler</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-http</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>io.netty</groupId>
+            <artifactId>netty-codec-http2</artifactId>
+        </dependency>","[{'comment': 'No code change in this maven module, why change library?', 'commenter': 'wu-sheng'}, {'comment': ""@kezhenxu94 reminded me what there is a CVE issue in netty 4.1.45. Therefore we upgraded the netty's bom to 4.1.65 and remove this version.\r\nI excluded netty from grpc-netty, because grpc-netty included netty 4.1.45. So that we have to explicitly add those dependencies. (the same as above)"", 'commenter': 'dmsolr'}]"
7220,apm-webapp/src/main/resources/application.yml,"@@ -17,28 +17,28 @@
 server:
   port: 8080
 
-zuul:
-  ignoredServices: '*'
-  routes:
-    api:
-      path: /graphql
-      serviceId: collector
-    login:
-      path: /login/account
-      serviceId: collector
-
-collector:
-  path: /graphql
-  ribbon:
-    # Point to all backend's restHost:restPort, split by ,
-    listOfServers: 127.0.0.1:12800
-
 spring:
-  resources:
-    add-mappings: false
+  cloud:
+    gateway:
+      routes:
+        - id: oap-route
+          uri: lb://oap-service","[{'comment': 'Where does this mean?', 'commenter': 'wu-sheng'}, {'comment': '`lb:` represents client-side  `load balance`', 'commenter': 'JaredTan95'}]"
7220,apm-webapp/pom.xml,"@@ -29,18 +30,18 @@
     <packaging>jar</packaging>
 
     <properties>
+        <java.version>1.8</java.version>
         <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
-        <spring.boot.version>1.5.22.RELEASE</spring.boot.version>
+        <spring.boot.version>2.4.8</spring.boot.version>
         <log4j.version>2.6.2</log4j.version>
         <gson.version>2.8.2</gson.version>
         <apache-httpclient.version>4.5.3</apache-httpclient.version>
-        <spring-cloud-dependencies.version>Edgware.SR1</spring-cloud-dependencies.version>
+        <spring-cloud-dependencies.version>2020.0.3</spring-cloud-dependencies.version>
         <frontend-maven-plugin.version>1.11.0</frontend-maven-plugin.version>
         <logback-classic.version>1.2.3</logback-classic.version>
         <jackson-version>2.12.2</jackson-version>
         <yaml.version>1.28</yaml.version>
-        <netty.version>4.1.65.Final</netty.version>
-        <tomcat.version>8.5.66</tomcat.version>
+        <tomcat.version>9.0.48</tomcat.version>","[{'comment': 'dist/LICENSE should be updated accordingly.', 'commenter': 'wu-sheng'}, {'comment': ""I did not found `springboot/cloud` license under `dist/LICENSE`, I'm not sure if I need to add it"", 'commenter': 'JaredTan95'}, {'comment': 'https://github.com/apache/skywalking/blob/669fe1593c8cd3591652c13d1088c72d2c45ab89/dist-material/release-docs/LICENSE#L254', 'commenter': 'kezhenxu94'}]"
7220,CHANGES.md,"@@ -63,6 +63,7 @@ Release Notes.
   metrics. The timeout of the cache for minute and hour level metrics has been prolonged to ~5 min.
 * Performance: Add L1 aggregation flush period, which reduce the CPU load and help young GC.
 * Support connectTimeout and socketTimeout settings for ElasticSearch6 and ElasticSearch7 storages.
+* replace zuul proxy with spring cloud gateway 2.x. in webapp module","[{'comment': '```suggestion\r\n* Replace zuul proxy with spring cloud gateway 2.x. in webapp module.\r\n```', 'commenter': 'kezhenxu94'}]"
7220,apm-webapp/src/main/resources/application.yml,"@@ -17,28 +17,28 @@
 server:
   port: 8080
 
-zuul:
-  ignoredServices: '*'
-  routes:
-    api:
-      path: /graphql
-      serviceId: collector
-    login:
-      path: /login/account
-      serviceId: collector
-
-collector:
-  path: /graphql
-  ribbon:
-    # Point to all backend's restHost:restPort, split by ,
-    listOfServers: 127.0.0.1:12800
-
 spring:
-  resources:
-    add-mappings: false
+  cloud:
+    gateway:
+      routes:
+        - id: oap-route
+          uri: lb://oap-service
+          predicates:
+            - Path=/graphql/**
+    discovery:
+      client:
+        simple:
+          instances:
+            oap-service:
+              - uri: http://127.0.0.1:12800","[{'comment': ""Need some comments here, for example\r\n\r\n```\r\n# Array of all backend's restHost:restPort\r\noap-service:\r\n  - uri: http://127.0.0.1:12800\r\n  # - uri: http://<oap-host-1>:<oap-port1>\r\n  # - uri: http://<oap-host-2>:<oap-port2>\r\n```"", 'commenter': 'kezhenxu94'}]"
7220,dist-material/release-docs/LICENSE,"@@ -270,9 +272,7 @@ The text of each license is the standard Apache 2.0 license.
     Apache: commons-io 2.4: https://github.com/apache/commons-io, Apache 2.0
     Apache: commons-compress 1.20: https://github.com/apache/commons-compress, Apache 2.0
     Apache: commons-collections4 4.4: https://mvnrepository.com/artifact/org.apache.commons/commons-collections4, Apache 2.0
-    Apache: tomcat 8.5.66: https://github.com/apache/tomcat/tree/trunk, Apache 2.0
     Apache: freemarker 2.3.28: https://github.com/apache/freemarker, Apache 2.0
-    netty 4.1.65: https://github.com/netty/netty/blob/4.1/LICENSE.txt, Apache 2.0","[{'comment': 'This is still used in oap-server', 'commenter': 'kezhenxu94'}]"
7220,.github/workflows/e2e.istio.yaml,"@@ -95,7 +95,7 @@ jobs:
         run: |
           git clone https://github.com/apache/skywalking-kubernetes.git
           cd skywalking-kubernetes
-          git reset --hard 2fdcdc3bb39496bf49626755e8f60c998be5f587
+          git reset --hard 6d5897616ce30ebb1706c0cf566ac36f733d93e0","[{'comment': 'Line 240 should be updated too', 'commenter': 'kezhenxu94'}]"
7271,test/plugin/scenarios/gateway-2.0.x-scenario/config/expectedData.yaml,"@@ -57,7 +57,7 @@ segmentItems:
       tags:
       - {key: url, value: 'http://localhost:8080/provider/b/testcase'}
       - {key: http.method, value: GET}
-      - {key: status_code, value: '200'}
+      - {key: http.status_code, value: '200'}","[{'comment': 'FYI @JaredTan95 After this change, Resin plugins in https://github.com/SkyAPM/java-plugin-extensions should break. We need a fix after 8.8.0 release, and release 3.0.0. Could you create an issue there to track this?', 'commenter': 'wu-sheng'}]"
7271,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/MultiScopesAnalysisListener.java,"@@ -240,12 +240,15 @@ private void setPublicAttrs(SourceBuilder sourceBuilder, SpanObject span) {
         sourceBuilder.setLatency((int) latency);
         sourceBuilder.setResponseCode(Const.NONE);
         span.getTagsList().forEach(tag -> {
-            if (SpanTags.STATUS_CODE.equals(tag.getKey())) {
+            if (SpanTags.HTTP_RESPONSE_STATUS_CODE.equals(tag.getKey())) {","[{'comment': 'I think we should check the old tag too? Unless, OAL engine is not compatible with old agent, right? But we should indicate it is `Deprecated` through comment and make the logic clear through comments.', 'commenter': 'wu-sheng'}, {'comment': ""Yes, it's reasonable. So I should keep the old tag `SpanTags.STATUS_CODE` and explain in comment that it has been deprecated."", 'commenter': 'wallezhang'}, {'comment': 'I have another question, if application use the new agent, and the tag will be `http.status_code` or `rpc.status_code`, while the old OAL server unrecognized the new tag, so the `responseCode` field will always be 0. Therefore, does agent also need to consider compatible issues?', 'commenter': 'wallezhang'}, {'comment': 'The agent changes should be applied. And OAP would work with both(deprecated and new)', 'commenter': 'wu-sheng'}, {'comment': ""We don't need `new agent`->`old OAP` works. We never recommended that."", 'commenter': 'wu-sheng'}, {'comment': 'OK, got it', 'commenter': 'wallezhang'}, {'comment': ""You could add a change log at the project section to highlight this change, and the new agent plugins' response code would not be compatible with old OAP versions."", 'commenter': 'wu-sheng'}]"
7274,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/type/Pagination.java,"@@ -18,11 +18,15 @@
 
 package org.apache.skywalking.oap.server.core.query.type;
 
+import lombok.AllArgsConstructor;
 import lombok.Getter;
+import lombok.NoArgsConstructor;
 import lombok.Setter;
 
 @Getter
 @Setter
+@NoArgsConstructor
+@AllArgsConstructor","[{'comment': 'Who is using `AllArgsConstructor`?', 'commenter': 'wu-sheng'}]"
7274,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/AlarmQuery.java,"@@ -88,7 +88,9 @@ public Alarms getAlarm(final Duration duration, final Scope scope, final String
         }
         long startSecondTB = 0;
         long endSecondTB = 0;
-        final EventQueryCondition.EventQueryConditionBuilder conditionPrototype = EventQueryCondition.builder().size(IEventQueryDAO.MAX_SIZE);
+        final EventQueryCondition.EventQueryConditionBuilder conditionPrototype =
+            EventQueryCondition.builder()
+                               .paging(new Pagination(1, IEventQueryDAO.MAX_SIZE, false));","[{'comment': '> Who is using AllArgsConstructor?\r\n\r\nHere', 'commenter': 'kezhenxu94'}]"
7367,oap-server/server-bootstrap/src/main/resources/ui-initialized-templates/self-observability.yml,"@@ -184,6 +184,42 @@ templates:
                   ""metricLabels"": ""50,70,90,99"",
                   ""labelsIndex"": ""50,70,90,99"",
                   ""unit"": ""Millisecond""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_live_count,meter_oap_instance_jvm_thread_daemon_count,meter_oap_instance_jvm_thread_peak_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartLine"",
+                  ""unit"": ""Per Minute""","[{'comment': ""what does the unit `Per Minute`  mean?  If you want to get the time duration metric you should use like `rate('PT1M')`  or `increase('PT1M')` in the expressions."", 'commenter': 'wankai123'}, {'comment': 'done', 'commenter': 'Switch-vov'}]"
7367,oap-server/server-bootstrap/src/main/resources/ui-initialized-templates/self-observability.yml,"@@ -184,6 +184,42 @@ templates:
                   ""metricLabels"": ""50,70,90,99"",
                   ""labelsIndex"": ""50,70,90,99"",
                   ""unit"": ""Millisecond""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_live_count,meter_oap_instance_jvm_thread_daemon_count,meter_oap_instance_jvm_thread_peak_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartLine"",
+                  ""unit"": ""Per Minute""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread State Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_runnable_state_thread_count,meter_oap_instance_jvm_thread_blocked_state_thread_count,meter_oap_instance_jvm_thread_waiting_state_thread_count,meter_oap_instance_jvm_thread_timed_waiting_state_thread_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartBar"",
+                  ""unit"": ""Per Minute""","[{'comment': 'also here.', 'commenter': 'wankai123'}, {'comment': 'done', 'commenter': 'Switch-vov'}]"
7367,oap-server/server-bootstrap/src/main/resources/ui-initialized-templates/self-observability.yml,"@@ -184,6 +184,42 @@ templates:
                   ""metricLabels"": ""50,70,90,99"",
                   ""labelsIndex"": ""50,70,90,99"",
                   ""unit"": ""Millisecond""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_live_count,meter_oap_instance_jvm_thread_daemon_count,meter_oap_instance_jvm_thread_peak_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartLine"",
+                  ""unit"": ""Per Minute""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread State Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_runnable_state_thread_count,meter_oap_instance_jvm_thread_blocked_state_thread_count,meter_oap_instance_jvm_thread_waiting_state_thread_count,meter_oap_instance_jvm_thread_timed_waiting_state_thread_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartBar"",
+                  ""unit"": ""Per Minute""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Class Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_class_loaded_class_count,meter_oap_instance_jvm_class_total_unloaded_class_count,meter_oap_instance_jvm_class_total_loaded_class_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartArea"",
+                  ""unit"": ""Per Minute""","[{'comment': 'and here ', 'commenter': 'wankai123'}, {'comment': 'done', 'commenter': 'Switch-vov'}]"
7367,test/e2e/e2e-data/src/main/java/org/apache/skywalking/e2e/metrics/MetricsQuery.java,"@@ -137,13 +137,21 @@
     public static String METER_INSTANCE_METRICS_FIRST_AGGREGATION = ""meter_oap_instance_metrics_first_aggregation"";
     public static String METER_INSTANCE_PERSISTENCE_PREPARE_COUNT = ""meter_oap_instance_persistence_prepare_count"";
     public static String METER_INSTANCE_PERSISTENCE_EXECUTE_COUNT = ""meter_oap_instance_persistence_execute_count"";
+    public static String METER_INSTANCE_JVM_THREAD_LIVE_COUNT = ""meter_oap_instance_jvm_thread_live_count"";
+    public static String METER_INSTANCE_JVM_THREAD_RUNNABLE_STATE_THREAD_COUNT = ""meter_oap_instance_jvm_thread_runnable_state_thread_count"";
+    public static String METER_INSTANCE_JVM_CLASS_LOADED_CLASS_COUNT = ""meter_oap_instance_jvm_class_loaded_class_count"";
+    public static String METER_INSTANCE_JVM_CLASS_TOTAL_LOADED_CLASS_COUNT = ""meter_oap_instance_jvm_class_total_loaded_class_count"";
 
     public static String[] ALL_SO11Y_LINER_METRICS = {
         METER_INSTANCE_CPU_PERCENTAGE,
         METER_INSTANCE_JVM_MEMORY_BYTES_USED,
         METER_INSTANCE_METRICS_FIRST_AGGREGATION,
         METER_INSTANCE_PERSISTENCE_PREPARE_COUNT,
-        METER_INSTANCE_PERSISTENCE_EXECUTE_COUNT 
+        METER_INSTANCE_PERSISTENCE_EXECUTE_COUNT,
+        METER_INSTANCE_JVM_THREAD_LIVE_COUNT,","[{'comment': ""Does the live thread metric really have values? I can't see that from your screenshots."", 'commenter': 'wu-sheng'}, {'comment': 'Or other metrics are always having no-zero values? E2e is checking the values of metrics.', 'commenter': 'wu-sheng'}, {'comment': 'https://github.com/apache/skywalking/pull/7367#issuecomment-885995038\r\n\r\n![img](https://user-images.githubusercontent.com/11993575/126856553-3bfabb14-be6f-479f-a214-2b7829061da6.png)\r\n\r\n``` yaml\r\n  - name: instance_jvm_thread_live_count\r\n    exp: jvm_threads_current.sum([\'service\', \'instance\'])\r\n```\r\n\r\n```\r\n""metricName"": ""meter_oap_instance_jvm_thread_live_count,meter_oap_instance_jvm_thread_daemon_count,meter_oap_instance_jvm_thread_peak_count""\r\n```', 'commenter': 'Switch-vov'}]"
7367,oap-server/server-bootstrap/src/main/resources/ui-initialized-templates/self-observability.yml,"@@ -184,6 +184,39 @@ templates:
                   ""metricLabels"": ""50,70,90,99"",
                   ""labelsIndex"": ""50,70,90,99"",
                   ""unit"": ""Millisecond""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_live_count,meter_oap_instance_jvm_thread_daemon_count,meter_oap_instance_jvm_thread_peak_count"",
+                  ""queryMetricType"": ""readMetricsValues"",
+                  ""chartType"": ""ChartLine""
+                },
+                {
+                  ""width"": 3,
+                  ""title"": ""Thread State Count"",
+                  ""height"": ""200"",
+                  ""entityType"": ""ServiceInstance"",
+                  ""independentSelector"": false,
+                  ""metricType"": ""REGULAR_VALUE"",
+                  ""metricName"": ""meter_oap_instance_jvm_thread_runnable_state_thread_count,meter_oap_instance_jvm_thread_blocked_state_thread_count,meter_oap_instance_jvm_thread_waiting_state_thread_count,meter_oap_instance_jvm_thread_timed_waiting_state_thread_count"",","[{'comment': 'Could you run test on real PostgreSQL? I am feeling whether this name, `meter_oap_instance_jvm_thread_runnable_state_thread_count`, is too long for PostgreSQL.', 'commenter': 'wu-sheng'}]"
7367,oap-server/server-bootstrap/src/main/resources/fetcher-prom-rules/self.yaml,"@@ -79,3 +79,23 @@ metricsRules:
     exp: persistence_timer_bulk_execute_latency_count.sum(['service', 'instance']).increase('PT5M')
   - name: instance_persistence_prepare_count
     exp: persistence_timer_bulk_prepare_latency_count.sum(['service', 'instance']).increase('PT5M')
+  - name: instance_jvm_thread_live_count
+    exp: jvm_threads_current.sum(['service', 'instance'])
+  - name: instance_jvm_thread_daemon_count
+    exp: jvm_threads_daemon.sum(['service', 'instance'])
+  - name: instance_jvm_thread_peak_count
+    exp: jvm_threads_peak.sum(['service', 'instance'])
+  - name: instance_jvm_thread_runnable_state_thread_count
+    exp: jvm_threads_state.tagMatch('state', 'RUNNABLE').sum(['service', 'instance'])
+  - name: instance_jvm_thread_blocked_state_thread_count
+    exp: jvm_threads_state.tagMatch('state', 'BLOCKED').sum(['service', 'instance'])
+  - name: instance_jvm_thread_waiting_state_thread_count
+    exp: jvm_threads_state.tagMatch('state', 'WAITING').sum(['service', 'instance'])
+  - name: instance_jvm_thread_timed_waiting_state_thread_count
+    exp: jvm_threads_state.tagMatch('state', 'TIMED_WAITING').sum(['service', 'instance'])
+  - name: instance_jvm_class_loaded_class_count
+    exp: jvm_classes_loaded.sum(['service', 'instance'])
+  - name: instance_jvm_class_total_unloaded_class_count
+    exp: jvm_classes_unloaded_total.sum(['service', 'instance'])
+  - name: instance_jvm_class_total_loaded_class_count
+    exp: jvm_classes_loaded_total.sum(['service', 'instance'])","[{'comment': 'Consider removing `instance_` as a prefix, as JVM has indicated it is instance level.\r\nFor example, change `instance_jvm_thread_waiting_state_thread_count` to `jvm_thread_waiting_count`. Remove unnecessary words. The different storages have different rules.', 'commenter': 'wu-sheng'}]"
7498,.mvn/wrapper/MavenWrapperDownloader.java,"@@ -1,18 +1,21 @@
 /*
- * Copyright 2007-present the original author or authors.
+ * Licensed to the Apache Software Foundation (ASF) under one or more","[{'comment': 'Why change back to ASF?', 'commenter': 'wu-sheng'}, {'comment': 'https://github.com/apache/shardingsphere/blob/c2df0553596ccd24646fafe1ab11b63baa81c8d3/.mvn/wrapper/MavenWrapperDownloader.java#L2-L14\r\n\r\nShardingSphere is using this too.', 'commenter': 'wu-sheng'}, {'comment': 'At https://github.com/apache/shardingsphere/pull/11883#discussion_r691303345, you said, the `Licensed to the Apache Software Foundation (ASF) under one or more` comes from SkyWalking, but from this change log, SkyWalking has the correct and original header.\r\n\r\nCould you share what is missing here?', 'commenter': 'wu-sheng'}, {'comment': 'Sorry, I think I might understand it wrong.', 'commenter': 'totalo'}, {'comment': 'OK, get it.', 'commenter': 'wu-sheng'}]"
7565,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/TLSChannelBuilder.java,"@@ -23,26 +23,55 @@
 import io.grpc.netty.NettyChannelBuilder;
 import io.netty.handler.ssl.SslContextBuilder;
 import java.io.File;
-import javax.net.ssl.SSLException;
+import java.io.FileInputStream;
+import java.io.IOException;
 import org.apache.skywalking.apm.agent.core.boot.AgentPackageNotFoundException;
 import org.apache.skywalking.apm.agent.core.boot.AgentPackagePath;
 import org.apache.skywalking.apm.agent.core.conf.Config;
-import org.apache.skywalking.apm.agent.core.conf.Constants;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.util.PrivateKeyUtil;
+import org.apache.skywalking.apm.util.StringUtil;
 
 /**
- * Detect the `/ca` folder in agent package, if `ca.crt` exists, start TLS (no mutual auth).
+ * If only ca.crt exists, start TLS. If cert, key and ca files exist, enable mTLS.
  */
 public class TLSChannelBuilder implements ChannelBuilder<NettyChannelBuilder> {
-    private static String CA_FILE_NAME = ""ca"" + Constants.PATH_SEPARATOR + ""ca.crt"";
+    private static final ILog LOGGER = LogManager.getLogger(TLSChannelBuilder.class);
 
     @Override
     public NettyChannelBuilder build(
-        NettyChannelBuilder managedChannelBuilder) throws AgentPackageNotFoundException, SSLException {
-        File caFile = new File(AgentPackagePath.getPath(), CA_FILE_NAME);
-        boolean isCAFileExist = caFile.exists() && caFile.isFile();
-        if (Config.Agent.FORCE_TLS || isCAFileExist) {
+        NettyChannelBuilder managedChannelBuilder) throws AgentPackageNotFoundException, IOException {
+
+        String caPath = Config.Agent.SSL_TRUSTED_CA_PATH;
+        if (caPath.startsWith(""./"")) {
+            caPath = AgentPackagePath.getPath() + caPath.substring(2);
+        }
+        File caFile = new File(caPath);","[{'comment': '*PATH_TRAVERSAL_IN:*  This API (java/io/File.<init>(Ljava/lang/String;)V) reads a file whose location might be specified by user input [(details)](https://find-sec-bugs.github.io/bugs.htm#PATH_TRAVERSAL_IN)\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
7565,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/util/PrivateKeyUtil.java,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.agent.core.util;
+
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.util.Base64;
+
+/**
+ * Util intends to parse PKCS#1 and PKCS#8 at same time.
+ */
+public class PrivateKeyUtil {
+    private static final String PKCS_1_PEM_HEADER = ""-----BEGIN RSA PRIVATE KEY-----"";
+    private static final String PKCS_1_PEM_FOOTER = ""-----END RSA PRIVATE KEY-----"";
+    private static final String PKCS_8_PEM_HEADER = ""-----BEGIN PRIVATE KEY-----"";
+    private static final String PKCS_8_PEM_FOOTER = ""-----END PRIVATE KEY-----"";
+
+    /**
+     * Load a RSA decryption key from a file (PEM or DER).
+     */
+    public static InputStream loadDecryptionKey(String keyFilePath) throws IOException {
+        byte[] keyDataBytes = Files.readAllBytes(Paths.get(keyFilePath));","[{'comment': '*PATH_TRAVERSAL_IN:*  This API (java/nio/file/Paths.get(Ljava/lang/String;[Ljava/lang/String;)Ljava/nio/file/Path;) reads a file whose location might be specified by user input [(details)](https://find-sec-bugs.github.io/bugs.htm#PATH_TRAVERSAL_IN)\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
7565,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/util/PrivateKeyUtil.java,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.apm.agent.core.util;
+
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.util.Base64;
+
+/**
+ * Util intends to parse PKCS#1 and PKCS#8 at same time.","[{'comment': 'We should support PKCS#12 which is a more useful private key format than PKCS#8. We should document which key and cert formats are supported by oap and agent', 'commenter': 'hanahmily'}, {'comment': 'I am not familiar with this.  May I improve it in new PR.', 'commenter': 'dmsolr'}, {'comment': 'yes, but we should document private key supports PKCS#8 and PKCS#1 for now ', 'commenter': 'hanahmily'}]"
7565,CHANGES.md,"@@ -18,6 +18,7 @@ Release Notes.
 * Fix kafka-reporter-plugin shade package conflict
 * Add all config items to `agent.conf` file for convenient containerization use cases.
 * Advanced Kafka Producer configuration enhancement.
+* Enable mTLS for gRPC channel.","[{'comment': ""Maybe change `Enable` to `Support`? Because we don't enable it by default"", 'commenter': 'kezhenxu94'}]"
7565,apm-sniffer/apm-agent-core/src/main/java/org/apache/skywalking/apm/agent/core/remote/TLSChannelBuilder.java,"@@ -23,31 +23,59 @@
 import io.grpc.netty.NettyChannelBuilder;
 import io.netty.handler.ssl.SslContextBuilder;
 import java.io.File;
-import javax.net.ssl.SSLException;
+import java.io.FileInputStream;
+import java.io.IOException;
 import org.apache.skywalking.apm.agent.core.boot.AgentPackageNotFoundException;
 import org.apache.skywalking.apm.agent.core.boot.AgentPackagePath;
 import org.apache.skywalking.apm.agent.core.conf.Config;
-import org.apache.skywalking.apm.agent.core.conf.Constants;
+import org.apache.skywalking.apm.agent.core.logging.api.ILog;
+import org.apache.skywalking.apm.agent.core.logging.api.LogManager;
+import org.apache.skywalking.apm.agent.core.util.PrivateKeyUtil;
+import org.apache.skywalking.apm.util.StringUtil;
 
 /**
- * Detect the `/ca` folder in agent package, if `ca.crt` exists, start TLS (no mutual auth).
+ * If only ca.crt exists, start TLS. If cert, key and ca files exist, enable mTLS.
  */
 public class TLSChannelBuilder implements ChannelBuilder<NettyChannelBuilder> {
-    private static String CA_FILE_NAME = ""ca"" + Constants.PATH_SEPARATOR + ""ca.crt"";
+    private static final ILog LOGGER = LogManager.getLogger(TLSChannelBuilder.class);
 
     @Override
     public NettyChannelBuilder build(
-        NettyChannelBuilder managedChannelBuilder) throws AgentPackageNotFoundException, SSLException {
-        File caFile = new File(AgentPackagePath.getPath(), CA_FILE_NAME);
-        boolean isCAFileExist = caFile.exists() && caFile.isFile();
-        if (Config.Agent.FORCE_TLS || isCAFileExist) {
+        NettyChannelBuilder managedChannelBuilder) throws AgentPackageNotFoundException, IOException {
+
+        File caFile = new File(toAbsolutePath(Config.Agent.SSL_TRUSTED_CA_PATH));
+        if (Config.Agent.FORCE_TLS || caFile.isFile()) {
             SslContextBuilder builder = GrpcSslContexts.forClient();
-            if (isCAFileExist) {
+
+            if (caFile.isFile()) {
+                String certPath = Config.Agent.SSL_CERT_CHAIN_PATH;
+                String keyPath = Config.Agent.SSL_KEY_PATH;
+                if (StringUtil.isNotBlank(certPath) && StringUtil.isNotBlank(keyPath)) {
+                    File keyFile = new File(toAbsolutePath(keyPath));
+                    File certFile = new File(toAbsolutePath(certPath));
+                    if (certFile.isFile() && keyFile.isFile()) {
+                        builder.keyManager(new FileInputStream(certFile), PrivateKeyUtil.loadDecryptionKey(keyPath));","[{'comment': ""Seems `builder.keyManager` doesn't close the passed-in `InputStream`? If so, should close it"", 'commenter': 'kezhenxu94'}]"
7565,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/grpc/ssl/DynamicSslContext.java,"@@ -59,18 +63,25 @@ protected void updateContext(String caFile) {
         }
     }
 
-    @Override
-    protected void updateContext(final String privateKeyFile, final String certChainFile) {
+    protected void updateContext(final String privateKeyFile, final String certChainFile, final String trustedCAsFile) {
         try {
-            setCtx(GrpcSslContexts
-                .configure(SslContextBuilder
-                    .forServer(
-                        new FileInputStream(Paths.get(certChainFile).toFile()),
-                        PrivateKeyUtil.loadDecryptionKey(privateKeyFile)),
-                    SslProvider.OPENSSL)
-                .build());
+            SslContextBuilder builder = GrpcSslContexts.configure(
+                SslContextBuilder.forServer(
+                    new FileInputStream(Paths.get(certChainFile).toFile()),
+                    PrivateKeyUtil.loadDecryptionKey(privateKeyFile)
+                ),
+                SslProvider.OPENSSL
+            );
+
+            if (StringUtil.isNotEmpty(trustedCAsFile)) {
+                builder.trustManager(new FileInputStream(Paths.get(trustedCAsFile).toFile()))","[{'comment': 'Same here', 'commenter': 'kezhenxu94'}]"
7565,docs/en/setup/service-agent/java-agent/TLS.md,"@@ -17,10 +16,24 @@ Only support **no mutual auth**.
 ## Open and config TLS
 
 ### Agent config
-- Place `ca.crt` into `/ca` folder in agent package. Notice, `/ca` is not created in distribution, please create it by yourself.
-
-- Agent open TLS automatically after the `/ca/ca.crt` file detected.
+- Agent open TLS automatically after the `ca.crt`(by default `/ca` folder in agent package) file detected.
 - TLS with no CA mode could be activated by this setting.
 ```
-agent.force_tls=${SW_AGENT_FORCE_TLS:false}
+agent.force_tls=${SW_AGENT_FORCE_TLS:true}
+```
+
+## Enable mutual TLS
+
+- Sharing gRPC server must be started with enabled mTLS. More details see `receiver-sharing-server` section in `application.yaml`. Please refer to [gRPC SSL](../../backend/grpc-ssl.md)  
+- Configure Client-side SSL/TLS in `agent.conf`.
+- Change `SW_AGENT_COLLECTOR_BACKEND_SERVICES` to host and port of `receiver-sharing-server`.
+
+For example:
+```
+agent.force_tls=${SW_AGENT_FORCE_TLS:true}
+agent.ssl_trusted_ca_path=${SW_AGENT_SSL_TRUSTED_CA_PATH:/path/to/ca.crt}
+agent.ssl_key_path=${SW_AGENT_SSL_KEY_PATH:/path/to/client.pem}","[{'comment': 'Could you mention that this key is generated from a CA which should be loaded by OAP?', 'commenter': 'hanahmily'}]"
7565,docs/en/setup/backend/grpc-ssl.md,"@@ -44,3 +44,25 @@ gRPCSslCertChainPath: /path/to/server.crt
 Since `sharding-server` only receives data from an external source, it doesn't need a CA at all.
 
 If you port to Java agent, refer to [the Java agent repo](http://github.com/apache/skywalking-java) to config java agent and enable TLS.
+
+## mutual TLS mode","[{'comment': 'I noticed this `grpc-ssl.md ` has not been referenced in any place of the repo.\r\n\r\nPlease add a menu here, \r\n![image](https://user-images.githubusercontent.com/5441976/131243238-7c2e4183-3c26-4c52-8159-fd5a8a735126.png)\r\n', 'commenter': 'wu-sheng'}]"
7565,docs/menu.yml,"@@ -91,6 +91,8 @@ catalog:
               path: ""/en/setup/backend/ttl""
             - name: ""Dynamical Logging""
               path: ""/en/setup/backend/dynamical-logging""
+            - name: ""gRPC SSL transportation support for OAP serve""
+              path: ""/en/setup/backend/grpc-ssl""","[{'comment': '```suggestion\r\n            - name: ""Security(SSL/TLS/mTLS)""\r\n              path: ""/en/setup/backend/grpc-security""\r\n```\r\n\r\nPlease rename `grpc-ssl.md` to `grpc-security.md`.', 'commenter': 'wu-sheng'}, {'comment': '> Please rename grpc-ssl.md to grpc-security.md.\r\n\r\n@dmsolr I think you miss this.', 'commenter': 'wu-sheng'}]"
7565,docs/en/setup/backend/grpc-security.md,"@@ -44,3 +44,28 @@ gRPCSslCertChainPath: /path/to/server.crt
 Since `sharding-server` only receives data from an external source, it doesn't need a CA at all.
 
 If you port to Java agent, refer to [the Java agent repo](http://github.com/apache/skywalking-java) to config java agent and enable TLS.
+
+## mutual TLS mode
+
+To enable `mTLS` mode for gRPC channel requires [Sharing gRPC Server](./backend-receivers.md/#grpchttp-server-for-receiver) enabled, as following configuration. 
+
+```properties
+receiver-sharing-server:
+  selector: ${SW_RECEIVER_SHARING_SERVER:default}
+  default:
+    # For gRPC server
+    gRPCHost: ${SW_RECEIVER_GRPC_HOST:0.0.0.0}
+    gRPCPort: ${SW_RECEIVER_GRPC_PORT:11801}
+    maxConcurrentCallsPerConnection: ${SW_RECEIVER_GRPC_MAX_CONCURRENT_CALL:0}
+    maxMessageSize: ${SW_RECEIVER_GRPC_MAX_MESSAGE_SIZE:0}
+    gRPCThreadPoolQueueSize: ${SW_RECEIVER_GRPC_POOL_QUEUE_SIZE:0}
+    gRPCThreadPoolSize: ${SW_RECEIVER_GRPC_THREAD_POOL_SIZE:0}
+    gRPCSslEnabled: ${SW_RECEIVER_GRPC_SSL_ENABLED:true}
+    gRPCSslKeyPath: ${SW_RECEIVER_GRPC_SSL_KEY_PATH:""/path/to/server.pem""}
+    gRPCSslCertChainPath: ${SW_RECEIVER_GRPC_SSL_CERT_CHAIN_PATH:""/path/to/server.crt""}
+    gRPCSslTrustedCAsPath: ${SW_RECEIVER_GRPC_SSL_TRUSTED_CAS_PATH:""/path/to/ca.crt""}
+    authentication: ${SW_AUTHENTICATION:""""}
+```","[{'comment': 'A question, could you share what are the major differences of settings between mTLS and `Config OAP server` part?', 'commenter': 'wu-sheng'}, {'comment': 'And this is not documented yet, https://github.com/apache/skywalking/pull/7565#discussion_r698094625.\r\n\r\nCould you polish the whole document, and make the whole doc more clear.', 'commenter': 'wu-sheng'}, {'comment': 'Sure. ', 'commenter': 'dmsolr'}]"
7565,oap-server/server-bootstrap/src/main/java/org/apache/skywalking/oap/server/starter/OAPServerBootstrap.java,"@@ -58,4 +58,8 @@ public static void start() {
             System.exit(1);
         }
     }
+
+    public static void main(String[] args) {
+        OAPServerBootstrap.start();
+    }","[{'comment': 'Why add this?\r\n\r\n```suggestion\r\n```', 'commenter': 'kezhenxu94'}]"
7580,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BrowserLogQueryDAO.java,"@@ -31,6 +31,7 @@
 import org.apache.skywalking.oap.server.core.query.type.BrowserErrorLogs;
 import org.apache.skywalking.oap.server.core.storage.query.IBrowserLogQueryDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
+import org.elasticsearch.search.sort.SortOrder;","[{'comment': 'This is a wrong import', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'LIU-WEI-git'}]"
7580,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BrowserLogQueryDAO.java,"@@ -78,6 +79,8 @@ public BrowserErrorLogs queryBrowserErrorLogs(String serviceId,
             parameters.add(category.getValue());
         }
 
+        sql.append("" order by "").append(BrowserErrorLogRecord.TIMESTAMP).append("" "").append(SortOrder.DESC);","[{'comment': '```suggestion\r\n        sql.append("" order by "").append(BrowserErrorLogRecord.TIMESTAMP).append("" DESC "");\r\n```', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -81,6 +92,36 @@ public void flush(List<PrepareRequest> prepareRequests) {
         }
     }
 
+    private void executeSql(List<PrepareRequest> prepareRequests, int maxBatchSqlSize) {
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql batch. data size:{}"", prepareRequests.size());
+        }
+        Map<String, List<PrepareRequest>> batchRequestMap = new HashMap<>();
+        for (PrepareRequest prepareRequest : prepareRequests) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
+            if (batchRequestMap.get(sqlExecutor.getSql()) == null) {
+                List<PrepareRequest> prepareRequestList = new ArrayList<>();
+                batchRequestMap.put(sqlExecutor.getSql(), prepareRequestList);
+            }
+            batchRequestMap.get(sqlExecutor.getSql()).add(prepareRequest);
+        }
+        try (Connection connection = h2Client.getConnection()) {
+            try {
+                for (String key : batchRequestMap.keySet()) {
+                    BatchSQLExecutor batchSQLExecutor = new BatchSQLExecutor(key, batchRequestMap.get(key));","[{'comment': '*INEFFICIENT_KEYSET_ITERATOR:*  Accessing a value using a key that was retrieved from a `keySet` iterator. It is more efficient to use an iterator on the `entrySet` of the map, avoiding the extra `HashMap.get(key)` lookup.\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}, {'comment': 'ok.', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -81,6 +92,36 @@ public void flush(List<PrepareRequest> prepareRequests) {
         }
     }
 
+    private void executeSql(List<PrepareRequest> prepareRequests, int maxBatchSqlSize) {
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql batch. data size:{}"", prepareRequests.size());
+        }
+        Map<String, List<PrepareRequest>> batchRequestMap = new HashMap<>();
+        for (PrepareRequest prepareRequest : prepareRequests) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
+            if (batchRequestMap.get(sqlExecutor.getSql()) == null) {
+                List<PrepareRequest> prepareRequestList = new ArrayList<>();
+                batchRequestMap.put(sqlExecutor.getSql(), prepareRequestList);
+            }
+            batchRequestMap.get(sqlExecutor.getSql()).add(prepareRequest);","[{'comment': '*NULL_DEREFERENCE:*  object returned by `batchRequestMap.get(sqlExecutor.getSql())` could be null and is dereferenced at line 106.\n(at-me [in a reply](https://help.sonatype.com/lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}, {'comment': 'i will modify like this .\r\n\r\nif (batchRequestMap.containsKey(sqlExecutor.getSql())) {\r\n                batchRequestMap.get(sqlExecutor.getSql()).add(prepareRequest);\r\n            } else {\r\n                List<PrepareRequest> prepareRequestList = new ArrayList<>();\r\n                batchRequestMap.put(sqlExecutor.getSql(), prepareRequestList);\r\n            }', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/H2StorageConfig.java,"@@ -59,4 +59,16 @@
      * @since 8.2.0
      */
     private int numOfSearchableValuesPerTag = 2;
+    /**
+     * max size per batch execute sql
+     */
+    private int maxSizeOfBatchSql = 2000;
+    /**
+     * async batch execute pool size
+     */
+    private int h2AsyncBatchPersistentPoolSize = 4;
+    /**
+     * async batch execute channel size
+     */
+    private int h2AsyncBatchPersistentChannelSize = 4;","[{'comment': '```suggestion\r\n    /**\r\n     * max size per batch execute sql\r\n     */\r\n    private int maxSizeOfBatchSql = 100;\r\n    /**\r\n     * async batch execute pool size\r\n     */\r\n    private int h2AsyncBatchPersistentPoolSize = 1;\r\n    /**\r\n     * async batch execute channel size\r\n     */\r\n    private int h2AsyncBatchPersistentChannelSize = 1;\r\n```\r\n\r\nH2 is not that powerful, I recommend to use less number of threads and size in default.\r\n___\r\nAlso, according to DataCarrier implementation, it is better to merge `h2AsyncBatchPersistentPoolSize` and `h2AsyncBatchPersistentChannelSize` as `asyncBatchPersistentPoolSize` only. There is no point to create more threads than the number of channels.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/BatchSQLExecutor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.jdbc;
+
+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.List;
+
+/**
+ * A Batch SQL executor.
+ */
+public class BatchSQLExecutor implements InsertRequest, UpdateRequest {
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(BatchSQLExecutor.class);","[{'comment': 'Recommend to use `@Slf4j`', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/BatchSQLExecutor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.jdbc;
+
+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.List;
+
+/**
+ * A Batch SQL executor.
+ */
+public class BatchSQLExecutor implements InsertRequest, UpdateRequest {
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(BatchSQLExecutor.class);
+
+    private String sql;
+    private List<PrepareRequest> prepareRequests;
+
+    public BatchSQLExecutor(String sql, List<PrepareRequest> prepareRequests) {
+        this.sql = sql;
+        this.prepareRequests = prepareRequests;
+    }
+
+    public void invoke(Connection connection, int maxBatchSqlSize) throws SQLException {
+        if (LOGGER.isDebugEnabled()) {
+            LOGGER.debug(""execute sql batch.sql by key size: {},sql:{}"", prepareRequests.size(), sql);
+        }
+        PreparedStatement preparedStatement = connection.prepareStatement(sql);
+        int index = 0;
+        for (int k = 0; k < prepareRequests.size(); k++) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequests.get(k);
+            for (int i = 0; i < sqlExecutor.getParam().size(); i++) {
+                preparedStatement.setObject(i + 1, sqlExecutor.getParam().get(i));
+            }
+            preparedStatement.addBatch();
+            if (k > 0 && k % maxBatchSqlSize == 0) {
+                long start = System.currentTimeMillis();
+                preparedStatement.executeBatch();
+                long end = System.currentTimeMillis();
+                long cost = end - start;
+                if (LOGGER.isDebugEnabled()) {
+                    LOGGER.debug(""execute batch sql,batch size: {}, cost:{},sql: {}"", maxBatchSqlSize, cost, sql);
+                }
+                index = 0;
+            } else {
+                index = index + 1;","[{'comment': '```suggestion\r\n                index++;\r\n```', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/BatchSQLExecutor.java,"@@ -0,0 +1,82 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.jdbc;
+
+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.List;
+
+/**
+ * A Batch SQL executor.
+ */
+public class BatchSQLExecutor implements InsertRequest, UpdateRequest {
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(BatchSQLExecutor.class);
+
+    private String sql;
+    private List<PrepareRequest> prepareRequests;
+
+    public BatchSQLExecutor(String sql, List<PrepareRequest> prepareRequests) {
+        this.sql = sql;
+        this.prepareRequests = prepareRequests;
+    }
+
+    public void invoke(Connection connection, int maxBatchSqlSize) throws SQLException {
+        if (LOGGER.isDebugEnabled()) {
+            LOGGER.debug(""execute sql batch.sql by key size: {},sql:{}"", prepareRequests.size(), sql);
+        }
+        PreparedStatement preparedStatement = connection.prepareStatement(sql);
+        int index = 0;","[{'comment': 'Why name this `index`? It should be `pendingCount` or similar.', 'commenter': 'wu-sheng'}, {'comment': 'ok', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -81,6 +92,36 @@ public void flush(List<PrepareRequest> prepareRequests) {
         }
     }
 
+    private void executeSql(List<PrepareRequest> prepareRequests, int maxBatchSqlSize) {
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql batch. data size:{}"", prepareRequests.size());
+        }
+        Map<String, List<PrepareRequest>> batchRequestMap = new HashMap<>();
+        for (PrepareRequest prepareRequest : prepareRequests) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
+            if (batchRequestMap.get(sqlExecutor.getSql()) == null) {","[{'comment': 'When this could be null?', 'commenter': 'wu-sheng'}, {'comment': 'in this batch prepareRequests when first same name sql to insert batchRequestMap. this get will be null.\r\ni modify this by  sonatype-lift review advise. modify after:\r\n            if (batchRequestMap.containsKey(sqlExecutor.getSql())) {\r\n                batchRequestMap.get(sqlExecutor.getSql()).add(prepareRequest);\r\n            } else {\r\n                List<PrepareRequest> prepareRequestList = new ArrayList<>();\r\n                batchRequestMap.put(sqlExecutor.getSql(), prepareRequestList);\r\n            }', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -22,50 +22,61 @@
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Properties;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;
 import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;
-import org.apache.skywalking.oap.server.core.UnexpectedException;
 import org.apache.skywalking.oap.server.core.storage.IBatchDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.JDBCClientException;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
 import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
 import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.storage.plugin.jdbc.BatchSQLExecutor;
 import org.apache.skywalking.oap.server.storage.plugin.jdbc.SQLExecutor;
 
 @Slf4j
 public class H2BatchDAO implements IBatchDAO {
     private JDBCHikariCPClient h2Client;
     private final DataCarrier<PrepareRequest> dataCarrier;
+    private int maxBatchSqlSize = 2000;
+    private int h2AsyncBatchPersistentPoolSize = 4;
+    private int h2AsyncBatchPersistentChannelSize = 4;
 
-    public H2BatchDAO(JDBCHikariCPClient h2Client) {
+    public H2BatchDAO(JDBCHikariCPClient h2Client, int batchSqlSize, int h2AsyncBatchPersistentPoolSize, int h2AsyncBatchPersistentChannelSize) {
         this.h2Client = h2Client;
-
         String name = ""H2_ASYNCHRONOUS_BATCH_PERSISTENT"";
-        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20);
-        try {
-            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);
-        } catch (Exception e) {
-            throw new UnexpectedException(e.getMessage(), e);
+        if (log.isDebugEnabled()) {
+            log.debug(""H2_ASYNCHRONOUS_BATCH_PERSISTENT poolSize: {},channelSize: {},maxBatchSqlSize:{}"", h2AsyncBatchPersistentPoolSize, h2AsyncBatchPersistentChannelSize, batchSqlSize);
         }
-
-        this.dataCarrier = new DataCarrier<>(1, 10000);
-        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new H2BatchDAO.H2BatchConsumer(this));
+        this.dataCarrier = new DataCarrier<>(name, h2AsyncBatchPersistentChannelSize, 10000);
+        this.dataCarrier.consume(new H2BatchDAO.H2BatchConsumer(this), h2AsyncBatchPersistentPoolSize, 20);
     }
 
     @Override
     public void flush(List<PrepareRequest> prepareRequests) {
         if (CollectionUtils.isEmpty(prepareRequests)) {
             return;
         }
-
         if (log.isDebugEnabled()) {
-            log.debug(""batch sql statements execute, data size: {}"", prepareRequests.size());
+            log.debug(""to execute sql statements execute, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
+        }
+        if (maxBatchSqlSize <= 1) {
+            executeSql(prepareRequests);
+        } else {
+            executeSql(prepareRequests, maxBatchSqlSize);
+        }","[{'comment': ""I think making `size == 1` as a special case doesn't make sense. "", 'commenter': 'wu-sheng'}, {'comment': ""ok .i remove this  'if'"", 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/mysql/MySQLStorageConfig.java,"@@ -39,5 +39,18 @@
      * @since 8.2.0
      */
     private int numOfSearchableValuesPerTag = 2;
+    /**
+     * max size per batch execute sql
+     */
+    private int maxSizeOfBatchSql = 2000;
+    /**
+     * async batch execute pool size
+     */
+    private int h2AsyncBatchPersistentPoolSize = 4;
+    /**
+     * async batch execute channel size
+     */
+    private int h2AsyncBatchPersistentChannelSize = 4;
+","[{'comment': 'Same as above, you should consider merging. And `h2` prefix is incorrect.', 'commenter': 'wu-sheng'}, {'comment': 'ok. i use asyncBatchPersistentPoolSize  and remove h2AsyncBatchPersistentChannelSize', 'commenter': 'chenyi19851209'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/H2StorageConfig.java,"@@ -59,4 +59,16 @@
      * @since 8.2.0
      */
     private int numOfSearchableValuesPerTag = 2;
+    /**
+     * max size per batch execute sql
+     */
+    private int maxSizeOfBatchSql = 2000;","[{'comment': 'No configuration requires `@since 8.8.0`\r\n\r\nThe storage doc and configuration-vocabulary.md should be updated accordingly.', 'commenter': 'wu-sheng'}, {'comment': 'ok . i update backend-storage.md and configuration-vocabulary.md', 'commenter': 'chenyi19851209'}]"
7691,docs/en/setup/backend/configuration-vocabulary.md,"@@ -114,16 +114,22 @@ core|default|role|Option values: `Mixed/Receiver/Aggregator`. **Receiver** mode
 | - | - | metadataQueryMaxSize | The maximum size of metadata per query. | SW_STORAGE_H2_QUERY_MAX_SIZE | 5000 |
 | - | - | maxSizeOfArrayColumn | Some entities (e.g. trace segments) include the logic column with multiple values. In H2, we use multiple physical columns to host the values: e.g. change column_a with values [1,2,3,4,5] to `column_a_0 = 1, column_a_1 = 2, column_a_2 = 3 , column_a_3 = 4, column_a_4 = 5`. | SW_STORAGE_MAX_SIZE_OF_ARRAY_COLUMN | 20 |
 | - | - | numOfSearchableValuesPerTag | In a trace segment, this includes multiple spans with multiple tags. Different spans may have the same tag key, e.g. multiple HTTP exit spans all have their own `http.method` tags. This configuration sets the limit on the maximum number of values for the same tag key. | SW_STORAGE_NUM_OF_SEARCHABLE_VALUES_PER_TAG | 2 |
+| - | - | maxSizeOfBatchSql | The maximum size of execute batch sql per execute sql | SW_STORAGE_MAX_SIZE_OF_BATCH_SQL | 100 |","[{'comment': '```suggestion\r\n| - | - | maxSizeOfBatchSql | The maximum size of batch size of SQL execution | SW_STORAGE_MAX_SIZE_OF_BATCH_SQL | 100 |\r\n```\r\n\r\nPlease apply this to other comments and documents too.', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-starter/src/main/resources/application.yml,"@@ -170,9 +172,11 @@ storage:
     metadataQueryMaxSize: ${SW_STORAGE_MYSQL_QUERY_MAX_SIZE:5000}
     maxSizeOfArrayColumn: ${SW_STORAGE_MAX_SIZE_OF_ARRAY_COLUMN:20}
     numOfSearchableValuesPerTag: ${SW_STORAGE_NUM_OF_SEARCHABLE_VALUES_PER_TAG:2}
+    maxSizeOfBatchSql: ${SW_STORAGE_MAX_SIZE_OF_BATCH_SQL:2000}
+    asyncBatchPersistentPoolSize: ${SW_STORAGE_ASYNC_BATCH_PERSISTENT_POOL_SIZE:4}
   tidb:
     properties:
-      jdbcUrl: ${SW_JDBC_URL:""jdbc:mysql://localhost:4000/tidbswtest""}
+      jdbcUrl: ${SW_JDBC_URL:""jdbc:mysql://localhost:4000/tidbswtest?rewriteBatchedStatements=true""}","[{'comment': ""`rewriteBatchedStatements=true` What does this mean? And this doesn't exist in your doc change. Please make sure they are consistent."", 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/H2StorageConfig.java,"@@ -59,4 +59,12 @@
      * @since 8.2.0
      */
     private int numOfSearchableValuesPerTag = 2;
+    /**
+     * max size per batch execute sql
+     */","[{'comment': 'Still miss `@Since`.', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -22,61 +22,85 @@
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Properties;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.Iterator;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;
 import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;
-import org.apache.skywalking.oap.server.core.UnexpectedException;
 import org.apache.skywalking.oap.server.core.storage.IBatchDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.JDBCClientException;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
 import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
 import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.storage.plugin.jdbc.BatchSQLExecutor;
 import org.apache.skywalking.oap.server.storage.plugin.jdbc.SQLExecutor;
 
 @Slf4j
 public class H2BatchDAO implements IBatchDAO {
     private JDBCHikariCPClient h2Client;
     private final DataCarrier<PrepareRequest> dataCarrier;
+    private int maxBatchSqlSize = 2000;
+    private int asyncBatchPersistentPoolSize = 4;
 
-    public H2BatchDAO(JDBCHikariCPClient h2Client) {
+    public H2BatchDAO(JDBCHikariCPClient h2Client, int batchSqlSize, int asyncBatchPersistentPoolSize) {
         this.h2Client = h2Client;
-
         String name = ""H2_ASYNCHRONOUS_BATCH_PERSISTENT"";
-        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20);
-        try {
-            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);
-        } catch (Exception e) {
-            throw new UnexpectedException(e.getMessage(), e);
+        if (log.isDebugEnabled()) {
+            log.debug(""H2_ASYNCHRONOUS_BATCH_PERSISTENT poolSize: {},maxBatchSqlSize:{}"", asyncBatchPersistentPoolSize, batchSqlSize);
         }
-
-        this.dataCarrier = new DataCarrier<>(1, 10000);
-        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new H2BatchDAO.H2BatchConsumer(this));
+        this.dataCarrier = new DataCarrier<>(name, asyncBatchPersistentPoolSize, 10000);
+        this.dataCarrier.consume(new H2BatchDAO.H2BatchConsumer(this), asyncBatchPersistentPoolSize, 20);
     }
 
     @Override
     public void flush(List<PrepareRequest> prepareRequests) {
         if (CollectionUtils.isEmpty(prepareRequests)) {
             return;
         }
-
         if (log.isDebugEnabled()) {
-            log.debug(""batch sql statements execute, data size: {}"", prepareRequests.size());
+            log.debug(""to execute sql statements execute, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
+        }
+        executeSql(prepareRequests, maxBatchSqlSize);
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql statements done, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
         }
+    }
 
+    private void executeSql(List<PrepareRequest> prepareRequests, int maxBatchSqlSize) {","[{'comment': 'Why do we need a new method out of `flush`, but only called by it without any extra logic? Please merge them.', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/BatchSQLExecutor.java,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.jdbc;
+
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
+import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
+import org.apache.skywalking.oap.server.library.client.request.UpdateRequest;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.SQLException;
+import java.util.List;
+
+/**
+ * A Batch SQL executor.
+ */
+@Slf4j
+public class BatchSQLExecutor implements InsertRequest, UpdateRequest {
+
+    private String sql;
+    private List<PrepareRequest> prepareRequests;
+
+    public BatchSQLExecutor(String sql, List<PrepareRequest> prepareRequests) {
+        this.sql = sql;
+        this.prepareRequests = prepareRequests;
+    }
+
+    public void invoke(Connection connection, int maxBatchSqlSize) throws SQLException {
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql batch.sql by key size: {},sql:{}"", prepareRequests.size(), sql);
+        }
+        PreparedStatement preparedStatement = connection.prepareStatement(sql);
+        int pendingCount = 0;
+        for (int k = 0; k < prepareRequests.size(); k++) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequests.get(k);
+            for (int i = 0; i < sqlExecutor.getParam().size(); i++) {
+                preparedStatement.setObject(i + 1, sqlExecutor.getParam().get(i));
+            }","[{'comment': 'This code block should be merged into `sqlExecutor#setParameters`, rather than using `getParam` to expose the logic. Notice, SQLExecutor is the owner of the logic.', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/SQLExecutor.java,"@@ -54,4 +54,12 @@ public void invoke(Connection connection) throws SQLException {
         }
         preparedStatement.execute();
     }
+
+    public String getSql() {
+        return sql;
+    }","[{'comment': ""You could override `hashcode` and `equals` methods using SQL as the only condition. Then, this object could be taken as `key` of HashMap. We don't need another `getSql` method actually, from my understanding."", 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/SQLExecutor.java,"@@ -54,4 +54,12 @@ public void invoke(Connection connection) throws SQLException {
         }
         preparedStatement.execute();
     }
+
+    public String getSql() {
+        return sql;
+    }
+
+    public List<Object> getParam() {
+        return param;
+    }","[{'comment': 'This should be replaced by https://github.com/apache/skywalking/pull/7691/files#r706947361', 'commenter': 'wu-sheng'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -22,61 +22,85 @@
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Properties;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.Iterator;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;
 import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;
-import org.apache.skywalking.oap.server.core.UnexpectedException;
 import org.apache.skywalking.oap.server.core.storage.IBatchDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.JDBCClientException;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
 import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
 import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.storage.plugin.jdbc.BatchSQLExecutor;
 import org.apache.skywalking.oap.server.storage.plugin.jdbc.SQLExecutor;
 
 @Slf4j
 public class H2BatchDAO implements IBatchDAO {
     private JDBCHikariCPClient h2Client;
     private final DataCarrier<PrepareRequest> dataCarrier;
+    private int maxBatchSqlSize = 2000;
+    private int asyncBatchPersistentPoolSize = 4;","[{'comment': 'Unused\r\n\r\n```suggestion\r\n```', 'commenter': 'kezhenxu94'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -22,61 +22,85 @@
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Properties;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.Iterator;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;
 import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;
-import org.apache.skywalking.oap.server.core.UnexpectedException;
 import org.apache.skywalking.oap.server.core.storage.IBatchDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.JDBCClientException;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
 import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
 import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.storage.plugin.jdbc.BatchSQLExecutor;
 import org.apache.skywalking.oap.server.storage.plugin.jdbc.SQLExecutor;
 
 @Slf4j
 public class H2BatchDAO implements IBatchDAO {
     private JDBCHikariCPClient h2Client;
     private final DataCarrier<PrepareRequest> dataCarrier;
+    private int maxBatchSqlSize = 2000;
+    private int asyncBatchPersistentPoolSize = 4;
 
-    public H2BatchDAO(JDBCHikariCPClient h2Client) {
+    public H2BatchDAO(JDBCHikariCPClient h2Client, int batchSqlSize, int asyncBatchPersistentPoolSize) {","[{'comment': ""You need to assign `batchSqlSize` to field `maxBatchSqlSize`, it's unused now"", 'commenter': 'kezhenxu94'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -22,61 +22,85 @@
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Properties;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.Iterator;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;
 import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;
-import org.apache.skywalking.oap.server.core.UnexpectedException;
 import org.apache.skywalking.oap.server.core.storage.IBatchDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.JDBCClientException;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
 import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
 import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.storage.plugin.jdbc.BatchSQLExecutor;
 import org.apache.skywalking.oap.server.storage.plugin.jdbc.SQLExecutor;
 
 @Slf4j
 public class H2BatchDAO implements IBatchDAO {
     private JDBCHikariCPClient h2Client;
     private final DataCarrier<PrepareRequest> dataCarrier;
+    private int maxBatchSqlSize = 2000;
+    private int asyncBatchPersistentPoolSize = 4;
 
-    public H2BatchDAO(JDBCHikariCPClient h2Client) {
+    public H2BatchDAO(JDBCHikariCPClient h2Client, int batchSqlSize, int asyncBatchPersistentPoolSize) {
         this.h2Client = h2Client;
-
         String name = ""H2_ASYNCHRONOUS_BATCH_PERSISTENT"";
-        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20);
-        try {
-            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);
-        } catch (Exception e) {
-            throw new UnexpectedException(e.getMessage(), e);
+        if (log.isDebugEnabled()) {
+            log.debug(""H2_ASYNCHRONOUS_BATCH_PERSISTENT poolSize: {},maxBatchSqlSize:{}"", asyncBatchPersistentPoolSize, batchSqlSize);
         }
-
-        this.dataCarrier = new DataCarrier<>(1, 10000);
-        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new H2BatchDAO.H2BatchConsumer(this));
+        this.dataCarrier = new DataCarrier<>(name, asyncBatchPersistentPoolSize, 10000);
+        this.dataCarrier.consume(new H2BatchDAO.H2BatchConsumer(this), asyncBatchPersistentPoolSize, 20);
     }
 
     @Override
     public void flush(List<PrepareRequest> prepareRequests) {
         if (CollectionUtils.isEmpty(prepareRequests)) {
             return;
         }
-
         if (log.isDebugEnabled()) {
-            log.debug(""batch sql statements execute, data size: {}"", prepareRequests.size());
+            log.debug(""to execute sql statements execute, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
+        }
+        executeSql(prepareRequests, maxBatchSqlSize);
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql statements done, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
         }
+    }
 
+    private void executeSql(List<PrepareRequest> prepareRequests, int maxBatchSqlSize) {
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql batch. data size:{}"", prepareRequests.size());
+        }
+        Map<String, List<PrepareRequest>> batchRequestMap = new HashMap<>();
+        for (PrepareRequest prepareRequest : prepareRequests) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
+            if (batchRequestMap.containsKey(sqlExecutor.getSql())) {
+                batchRequestMap.get(sqlExecutor.getSql()).add(prepareRequest);
+            } else {
+                List<PrepareRequest> prepareRequestList = new ArrayList<>();
+                prepareRequestList.add(sqlExecutor);
+                batchRequestMap.put(sqlExecutor.getSql(), prepareRequestList);
+            }
+        }
         try (Connection connection = h2Client.getConnection()) {
-            for (PrepareRequest prepareRequest : prepareRequests) {
-                try {
-                    SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
-                    sqlExecutor.invoke(connection);
-                } catch (SQLException e) {
-                    // Just avoid one execution failure makes the rest of batch failure.
-                    log.error(e.getMessage(), e);
+            try {
+                Set<Map.Entry<String, List<PrepareRequest>>> entrySet = batchRequestMap.entrySet();
+                Iterator<Map.Entry<String, List<PrepareRequest>>> iterator = entrySet.iterator();
+                while (iterator.hasNext()) {
+                    Map.Entry<String, List<PrepareRequest>> next = iterator.next();
+                    BatchSQLExecutor batchSQLExecutor = new BatchSQLExecutor(next.getKey(), next.getValue());
+                    batchSQLExecutor.invoke(connection, maxBatchSqlSize);
                 }
+            } catch (SQLException e) {
+                // Just avoid one execution failure makes the rest of batch failure.
+                log.error(e.getMessage(), e);
             }
+
         } catch (SQLException | JDBCClientException e) {
+            log.warn(""execute sql failed, discard data size: {}"", prepareRequests.size());","[{'comment': '```suggestion\r\n            log.warn(""execute sql failed, discard data size: {}"", prepareRequests.size(), e);\r\n```\r\n\r\nAnd remove the next line `log.error(e.getMessage(), e);`', 'commenter': 'kezhenxu94'}]"
7691,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2BatchDAO.java,"@@ -22,61 +22,85 @@
 import java.sql.SQLException;
 import java.util.List;
 import java.util.Properties;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.Set;
+import java.util.Iterator;
 import lombok.extern.slf4j.Slf4j;
 import org.apache.skywalking.apm.commons.datacarrier.DataCarrier;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.BulkConsumePool;
-import org.apache.skywalking.apm.commons.datacarrier.consumer.ConsumerPoolFactory;
 import org.apache.skywalking.apm.commons.datacarrier.consumer.IConsumer;
-import org.apache.skywalking.oap.server.core.UnexpectedException;
 import org.apache.skywalking.oap.server.core.storage.IBatchDAO;
 import org.apache.skywalking.oap.server.library.client.jdbc.JDBCClientException;
 import org.apache.skywalking.oap.server.library.client.jdbc.hikaricp.JDBCHikariCPClient;
 import org.apache.skywalking.oap.server.library.client.request.InsertRequest;
 import org.apache.skywalking.oap.server.library.client.request.PrepareRequest;
 import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.storage.plugin.jdbc.BatchSQLExecutor;
 import org.apache.skywalking.oap.server.storage.plugin.jdbc.SQLExecutor;
 
 @Slf4j
 public class H2BatchDAO implements IBatchDAO {
     private JDBCHikariCPClient h2Client;
     private final DataCarrier<PrepareRequest> dataCarrier;
+    private int maxBatchSqlSize = 2000;
+    private int asyncBatchPersistentPoolSize = 4;
 
-    public H2BatchDAO(JDBCHikariCPClient h2Client) {
+    public H2BatchDAO(JDBCHikariCPClient h2Client, int batchSqlSize, int asyncBatchPersistentPoolSize) {
         this.h2Client = h2Client;
-
         String name = ""H2_ASYNCHRONOUS_BATCH_PERSISTENT"";
-        BulkConsumePool.Creator creator = new BulkConsumePool.Creator(name, 1, 20);
-        try {
-            ConsumerPoolFactory.INSTANCE.createIfAbsent(name, creator);
-        } catch (Exception e) {
-            throw new UnexpectedException(e.getMessage(), e);
+        if (log.isDebugEnabled()) {
+            log.debug(""H2_ASYNCHRONOUS_BATCH_PERSISTENT poolSize: {},maxBatchSqlSize:{}"", asyncBatchPersistentPoolSize, batchSqlSize);
         }
-
-        this.dataCarrier = new DataCarrier<>(1, 10000);
-        this.dataCarrier.consume(ConsumerPoolFactory.INSTANCE.get(name), new H2BatchDAO.H2BatchConsumer(this));
+        this.dataCarrier = new DataCarrier<>(name, asyncBatchPersistentPoolSize, 10000);
+        this.dataCarrier.consume(new H2BatchDAO.H2BatchConsumer(this), asyncBatchPersistentPoolSize, 20);
     }
 
     @Override
     public void flush(List<PrepareRequest> prepareRequests) {
         if (CollectionUtils.isEmpty(prepareRequests)) {
             return;
         }
-
         if (log.isDebugEnabled()) {
-            log.debug(""batch sql statements execute, data size: {}"", prepareRequests.size());
+            log.debug(""to execute sql statements execute, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
+        }
+        executeSql(prepareRequests, maxBatchSqlSize);
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql statements done, data size: {}, maxBatchSqlSize: {}"", prepareRequests.size(), maxBatchSqlSize);
         }
+    }
 
+    private void executeSql(List<PrepareRequest> prepareRequests, int maxBatchSqlSize) {
+        if (log.isDebugEnabled()) {
+            log.debug(""execute sql batch. data size:{}"", prepareRequests.size());
+        }
+        Map<String, List<PrepareRequest>> batchRequestMap = new HashMap<>();
+        for (PrepareRequest prepareRequest : prepareRequests) {
+            SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
+            if (batchRequestMap.containsKey(sqlExecutor.getSql())) {
+                batchRequestMap.get(sqlExecutor.getSql()).add(prepareRequest);
+            } else {
+                List<PrepareRequest> prepareRequestList = new ArrayList<>();
+                prepareRequestList.add(sqlExecutor);
+                batchRequestMap.put(sqlExecutor.getSql(), prepareRequestList);
+            }
+        }
         try (Connection connection = h2Client.getConnection()) {
-            for (PrepareRequest prepareRequest : prepareRequests) {
-                try {
-                    SQLExecutor sqlExecutor = (SQLExecutor) prepareRequest;
-                    sqlExecutor.invoke(connection);
-                } catch (SQLException e) {
-                    // Just avoid one execution failure makes the rest of batch failure.
-                    log.error(e.getMessage(), e);
+            try {
+                Set<Map.Entry<String, List<PrepareRequest>>> entrySet = batchRequestMap.entrySet();
+                Iterator<Map.Entry<String, List<PrepareRequest>>> iterator = entrySet.iterator();
+                while (iterator.hasNext()) {
+                    Map.Entry<String, List<PrepareRequest>> next = iterator.next();
+                    BatchSQLExecutor batchSQLExecutor = new BatchSQLExecutor(next.getKey(), next.getValue());
+                    batchSQLExecutor.invoke(connection, maxBatchSqlSize);
                 }
+            } catch (SQLException e) {
+                // Just avoid one execution failure makes the rest of batch failure.","[{'comment': ""The commend `// Just avoid one execution failure makes the rest of batch failure.` doesn't make sense, if you want to do that, please `try-catch` inside the while loop.\r\n\r\n\r\n```java\r\n            while (iterator.hasNext()) {\r\n                try {\r\n                    Map.Entry<String, List<PrepareRequest>> next = iterator.next();\r\n                    BatchSQLExecutor batchSQLExecutor =\r\n                        new BatchSQLExecutor(next.getKey(), next.getValue());\r\n                    batchSQLExecutor.invoke(connection, maxBatchSqlSize);\r\n                } catch (SQLException e) {\r\n                    // Just avoid one execution failure makes the rest of batch failure.\r\n                    log.error(e.getMessage(), e);\r\n                }\r\n            }\r\n```"", 'commenter': 'kezhenxu94'}]"
7790,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/meter/MeterEntity.java,"@@ -35,6 +36,8 @@
 @Getter
 @Builder(toBuilder = true)
 public class MeterEntity {
+    private static NamingControl NAMING_CONTROL;","[{'comment': 'Where is it used?', 'commenter': 'kezhenxu94'}, {'comment': 'I forgot to submit the second change. Just did.', 'commenter': 'wu-sheng'}]"
7795,docker/README.md,"@@ -55,6 +55,6 @@ From the output, we can find out the building tool adopts the files stored in `o
 We can start up backend cluster by docker-compose
 ```
 cd docker
-docker compose up
+docker-compose up -d","[{'comment': ""This doesn't need to change, I think."", 'commenter': 'wu-sheng'}, {'comment': '`docker compose` is already a command.', 'commenter': 'wu-sheng'}]"
7856,test/e2e-v2/cases/log/expected/service-endpoint.yml,"@@ -0,0 +1,21 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+{{- range .}}
+{{- if eq .name ""POST:/info"" }}","[{'comment': 'take a reference at #7849, we misuse some rules before.', 'commenter': 'wankai123'}, {'comment': 'okay,', 'commenter': 'JaredTan95'}]"
7856,.github/workflows/e2e.log.yaml,"@@ -39,9 +39,23 @@ jobs:
     timeout-minutes: 90
     strategy:
       matrix:
-        storage: ['h2', 'mysql', 'es6', 'es7', 'es7.14', 'influxdb']
-    env:
-      SW_STORAGE: ${{ matrix.storage }}
+        case:
+          - name: h2
+            config-file: log/h2/e2e.yaml
+          - name: mysql
+            config-file: log/mysql/e2e.yaml
+          - name: es6
+            config-file: log/es6/e2e.yaml
+          - name: es7
+            config-file: log/es7/e2e.yaml
+          - name: es7.14
+            config-file: log/es7.14/e2e.yaml","[{'comment': 'Can you take a look at `e2e.storages.yaml` and use the same style to set up ElasticSearch related cases? We need to test as many versions as possible with ease now that we are using our own ES client', 'commenter': 'kezhenxu94'}]"
7856,test/e2e-v2/cases/log/es6/e2e.yaml,"@@ -0,0 +1,70 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# This file is used to show how to write configuration files and can be used to test.
+
+setup:
+  env: compose
+  file: docker-compose.yml
+  timeout: 1200
+  init-system-environment: ../../../script/env
+  steps:
+    - name: install yq
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh yq
+    - name: install swctl
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh swctl
+    - name: install etcdctl
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh etcdctl
+
+cleanup:
+  on: success","[{'comment': ""Let's remove this as we have this https://github.com/apache/skywalking-infra-e2e/blob/main/docs/en/setup/Configuration-File.md#cleanup\r\n\r\n> If the on option under cleanup is not set, it will be automatically set to always if there is environment variable CI=true, which is present on many popular CI services, such as GitHub Actions, CircleCI, etc., otherwise it will be set to success, so the testing environment can be preserved when tests failed in your local machine."", 'commenter': 'kezhenxu94'}]"
7856,test/e2e-v2/cases/log/es6/e2e.yaml,"@@ -0,0 +1,70 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# This file is used to show how to write configuration files and can be used to test.
+
+setup:
+  env: compose
+  file: docker-compose.yml
+  timeout: 1200
+  init-system-environment: ../../../script/env
+  steps:
+    - name: install yq
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh yq
+    - name: install swctl
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh swctl
+    - name: install etcdctl
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh etcdctl
+
+cleanup:
+  on: success
+
+trigger:
+  action: http
+  interval: 10s
+  times: 10
+  url: http://${consumer_host}:${consumer_9092}/info
+  method: POST
+
+verify:
+  # verify with retry strategy
+  retry:
+    # max retry count
+    count: 20
+    # the interval between two retries, in millisecond.
+    interval: 10s
+  cases:
+    # service list
+    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql service ls
+      expected: ../expected/service.yml
+    # service endpoint
+    - query: |
+        swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql endpoint list --keyword=info --service-id=$( \
+          swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql service ls | yq e '.[]|select(.name==""e2e-service-provider"").id' - \
+        )","[{'comment': 'We can now use `--service-name` directly, no need `$( \\\r\n           swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql service ls | yq e \'.[]|select(.name==""e2e-service-provider"").id\' - \\\r\n         )`', 'commenter': 'kezhenxu94'}]"
7856,test/e2e-v2/cases/log/es6/e2e.yaml,"@@ -0,0 +1,70 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# This file is used to show how to write configuration files and can be used to test.
+
+setup:
+  env: compose
+  file: docker-compose.yml
+  timeout: 1200
+  init-system-environment: ../../../script/env
+  steps:
+    - name: install yq
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh yq
+    - name: install swctl
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh swctl
+    - name: install etcdctl
+      command: bash test/e2e-v2/script/prepare/setup-e2e-shell/install.sh etcdctl
+
+cleanup:
+  on: success
+
+trigger:
+  action: http
+  interval: 10s
+  times: 10
+  url: http://${consumer_host}:${consumer_9092}/info
+  method: POST
+
+verify:
+  # verify with retry strategy
+  retry:
+    # max retry count
+    count: 20
+    # the interval between two retries, in millisecond.
+    interval: 10s
+  cases:
+    # service list
+    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql service ls
+      expected: ../expected/service.yml
+    # service endpoint
+    - query: |
+        swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql endpoint list --keyword=info --service-id=$( \
+          swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql service ls | yq e '.[]|select(.name==""e2e-service-provider"").id' - \
+        )
+      expected: ../expected/service-endpoint.yml
+    # service instance list
+    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql instance list --service-name=e2e-service-provider
+      expected: ../expected/service-instance.yml
+    # logs
+    - query: |
+        swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql logs list --service-id=$( \","[{'comment': 'Same here', 'commenter': 'kezhenxu94'}]"
7856,test/e2e/e2e-test/src/test/java/org/apache/skywalking/e2e/log/FluentBitE2E.java,"@@ -31,7 +31,7 @@
 public class FluentBitE2E extends LogE2E {
     @SuppressWarnings(""unused"")
     @DockerCompose({
-        ""docker/log/docker-compose.fluentbit.yml""
+        ""docker/log/docker-compose.yml""","[{'comment': 'Do not change this for now', 'commenter': 'kezhenxu94'}]"
7856,.github/workflows/e2e.log.yaml,"@@ -39,9 +39,31 @@ jobs:
     timeout-minutes: 90
     strategy:
       matrix:
-        storage: ['h2', 'mysql', 'es6', 'es7', 'es7.14', 'influxdb']
+        case:
+          - name: h2
+            config-file: log/h2/e2e.yaml
+          - name: mysql
+            config-file: log/mysql/e2e.yaml
+        include:
+          - { case: elasticsearch, es-version: 6.3.2, config-file: log/es6/e2e.yaml }
+          - { case: elasticsearch, es-version: 7.0.0, config-file: log/es7/e2e.yaml }
+          - { case: elasticsearch, es-version: 7.8.0, config-file: log/es7/e2e.yaml }
+          - { case: elasticsearch, es-version: 7.10.1, config-file: log/es7/e2e.yaml }
+          - { case: elasticsearch, es-version: 7.14.0, config-file: log/es7/e2e.yaml }
+          - { case: elasticsearch, es-version: 7.15.0, config-file: log/es7/e2e.yaml }
+          - name: influxdb
+            config-file: log/influxdb/e2e.yaml
+          - name: postgres
+            config-file: log/postgres/e2e.yaml","[{'comment': ""Let's move this up to line 42, it's wrong in syntax here (no `case` section)"", 'commenter': 'kezhenxu94'}]"
7856,.github/workflows/e2e.log.yaml,"@@ -39,9 +39,52 @@ jobs:
     timeout-minutes: 90
     strategy:
       matrix:
-        storage: ['h2', 'mysql', 'es6', 'es7', 'es7.14', 'influxdb']
-    env:
-      SW_STORAGE: ${{ matrix.storage }}
+        case:
+          - name: h2
+            config-file: log/h2/e2e.yaml
+          - name: mysql
+            config-file: log/mysql/e2e.yaml
+          - name: influxdb
+            config-file: log/influxdb/e2e.yaml
+          - name: postgres
+            config-file: log/postgres/e2e.yaml
+        include:
+          - name: elasticsearch
+            es-version: 6.3.2
+            config-file: log/es6/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.0.0
+            config-file: log/es7/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.8.0
+            config-file: log/es7/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.10.1
+            config-file: log/es7/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.14.0
+            config-file: log/es7/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.15.0
+            config-file: log/es7/e2e.yaml
+          - name: elasticsearch
+            es-version: 6.3.2
+            config-file: log/fluent-bit/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.0.0
+            config-file: log/fluent-bit/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.8.0
+            config-file: log/fluent-bit/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.10.1
+            config-file: log/fluent-bit/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.14.0
+            config-file: log/fluent-bit/e2e.yaml
+          - name: elasticsearch
+            es-version: 7.15.0
+            config-file: log/fluent-bit/e2e.yaml","[{'comment': 'This is still not right, you missed the `case` section', 'commenter': 'kezhenxu94'}]"
8003,changes/changes-8.4.0.md,"@@ -22,7 +22,7 @@ Release Notes.
 * Update `byte-buddy` to 1.10.19.
 * Fix thrift plugin trace link broken when intermediate service does not mount agent
 * Fix thrift plugin collects wrong args when the method without parameter.
-* Fix DataCarrier's `org.apache.skywalking.apm.commons.datacarrier.buffer.Buffer` implementation isn't activated in `IF_POSSIBLE` mode.
+* Fix DataCarrier's `Buffer` implementation isn't activated in `IF_POSSIBLE` mode.","[{'comment': 'I think this is history, nothing should be changed.', 'commenter': 'wu-sheng'}, {'comment': 'Thanks, I have restored it.', 'commenter': 'CalvinKirs'}]"
8003,oap-server/server-receiver-plugin/skywalking-sharing-server-plugin/pom.xml,"@@ -1,30 +0,0 @@
-<?xml version=""1.0"" encoding=""UTF-8""?>","[{'comment': 'Why this file gets removed?', 'commenter': 'wu-sheng'}, {'comment': 'sorry, I see it wrong, sorry', 'commenter': 'CalvinKirs'}]"
8193,oap-server/server-receiver-plugin/envoy-metrics-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/envoy/AccessLogServiceGRPCHandler.java,"@@ -105,7 +110,7 @@ public AccessLogServiceGRPCHandler(ModuleManager manager,
             public void onNext(StreamAccessLogsMessage message) {
                 HistogramMetrics.Timer timer = histogram.createTimer();
                 try {
-                    if (isFirst) {
+                    if (isFirst || (alwaysAnalyzeIdentity && message.getIdentifier() != null)) {","[{'comment': ""Reply to https://github.com/apache/skywalking/pull/8193#issuecomment-980809798\r\n\r\n@kezhenxu94 I don't think this will affect the parsing here. The parsing is already done, this if protobuf, not flatbuffer.\r\nSo, the only one more cost is reading `message.getIdentifier()`, which is a Java bean getting only."", 'commenter': 'wu-sheng'}, {'comment': 'You overlooked these:\r\n\r\n```java\r\n            for (ALSHTTPAnalysis analysis : envoyHTTPAnalysisList) {\r\n                 role = analysis.identify(identifier, role);\r\n            }\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'How about this? Logic inside has nothing relating to this added flag. I am not following your question.\r\nNo matter in which case, this `identifier ` is required. The difference is from `StreamObserver#cache` or next element.', 'commenter': 'wu-sheng'}, {'comment': 'The difference to me is \r\n\r\n# old\r\n\r\n```java\r\nif (isFirst) { // only true for the first element per stream\r\n            for (ALSHTTPAnalysis analysis : envoyHTTPAnalysisList) {\r\n                 role = analysis.identify(identifier, role);\r\n            }\r\n}\r\n```\r\n\r\n# new\r\n\r\n```java\r\nif (true) { // it is no 100% always true but is extremely high possibility true from my understanding\r\n            for (ALSHTTPAnalysis analysis : envoyHTTPAnalysisList) {\r\n                 role = analysis.identify(identifier, role);\r\n            }\r\n}\r\n```\r\n\r\ndoes this illustrate my concern? @wu-sheng \r\n\r\nIf @mrproliu you had experimented this, can you just post the so11y metrics (especially CPU) of OAP before and after the new protocol?', 'commenter': 'kezhenxu94'}, {'comment': 'If you mean flatbuffer parsing, then this is really having no different than before.\nI think your gap is that, you are not considering we merged the stream, currently, one stream is representing the previous multiple streaming, then logically, all those identifiers are pasred too, just through different streamings.', 'commenter': 'wu-sheng'}, {'comment': '> If @mrproliu you had experimented this, can you just post the so11y metrics (especially CPU) of OAP before and after the new protocol?\r\n\r\nIt could not happen on this, because it decides by the satellite message package mechanism. Only the first message in the batch could have the identity.', 'commenter': 'mrproliu'}, {'comment': 'I am not sure why this possiblily could be high. You are comparing this logic between one stream and 2k+ streaming. Then you have a conclusion, this one streaming has higher possible to parse identify.\nMore parsing per stream, yes, but no different when condidering this whole 2k streamings(2k envoy instances)', 'commenter': 'wu-sheng'}, {'comment': 'If you want I could do the experiment, we also using the new protocol and the `OAP` side is using current and this one. Then I post the so11y metrics.\r\n```java\r\nif (isFirst || (alwaysAnalyzeIdentity && message.getIdentifier() != null)) {\r\n    identifier = message.getIdentifier();\r\n    isFirst = false;\r\n    role = Role.NONE;\r\n}\r\n\r\nfor (ALSHTTPAnalysis analysis : envoyHTTPAnalysisList) {\r\n    role = analysis.identify(identifier, role);\r\n}\r\n```\r\nI think only this one could find the identity analysis whether there is a performance problem.', 'commenter': 'mrproliu'}, {'comment': '> If you mean flatbuffer parsing, then this is really having no different than before.\r\n\r\nI never mean flatbuffer parsing. I meant this part \r\n\r\n```java\r\nfor (ALSHTTPAnalysis analysis : envoyHTTPAnalysisList) {\r\n                 role = analysis.identify(identifier, role);\r\n}\r\n```\r\n\r\n> I think your gap is that, you are not considering we merged the stream, currently, one stream is representing the previous multiple streaming, then logically, all those identifiers are pasred too, just through different streamings.\r\n\r\nI’m rather aware of that you merged the streams, and because you merge the streams from different Envoy nodes the OAP needs to identify the node in every message\r\n', 'commenter': 'kezhenxu94'}, {'comment': '@wu-sheng forget the word “parse”, I don’t mean parsing flatbuffer, I mean identifying the role of the node \r\n\r\n```java\r\nfor (ALSHTTPAnalysis analysis : envoyHTTPAnalysisList) {\r\n                 role = analysis.identify(identifier, role);\r\n            }\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'Let’s have a DM discuss if you still don’t get my point', 'commenter': 'kezhenxu94'}, {'comment': ""I think I know what is the gap here. Let me put in this way\r\n\r\n1. `Envoy -> OAP` direct linking\r\n\r\nAll envoy open unclosed streaming because the connection is always open, then the identifier only gets parsed once. This costs minimal in identifier parsing, but we have been facing load not balanced. Then we were introducing Satellite.\r\n\r\n2. `Envoy->Satellite->OAP`, current satellite implementation.\r\n\r\nIt maintains the context for a bulk of ALS message(such as 100 per bulk), then it created stream every time. With this solution, the load is balanced like you have seen in previous Satellite PR. \r\nThis change doesn't require any OAP side change, but actually, it already introduce the extra identifier parsing logic, you raised here(which is why I can't understand for a while, this is never introduced by this change).\r\nOne side, maintaining unclosed streaming in Satellite is impossible(costing more CPUs), also, keeping open/close streaming(current status) is also not good.\r\n\r\nThen, we get the idea of this new protocol and new PR.\r\n\r\nWe are merging these streamings as one new streaming(unclosed this time) but carrying different identifiers."", 'commenter': 'wu-sheng'}, {'comment': 'What you are concerned and asked about actually is already there after local balancer added. So, generally, you need a tradeoff, because trying to balance 2k+ envoy instances, the streaming must be merged one way or another.\r\n\r\nBut what is cost could be controlled by what is the size of Satellite side bulk setting. Higher is set, less CPU(parsing identifier) used, but more memory is used at Satellite.', 'commenter': 'wu-sheng'}, {'comment': 'So, generally, your asking about more resource cost at OAP side is true, but not because of this flag, but load balancing mechanism.', 'commenter': 'wu-sheng'}, {'comment': ""> What you are concerned and asked about actually is already there after local balancer added. So, generally, you need a tradeoff, because trying to balance 2k+ envoy instances, the streaming must be merged one way or another.\r\n\r\nI agree we need tradeoff and I've also given another merging strategy for discussion, which I think might be better https://github.com/apache/skywalking/pull/8193#issuecomment-980766033\r\n\r\n> So, generally, your asking about more resource cost at OAP side is true, but not because of this flag, but load balancing mechanism.\r\n\r\nI doubt this and need to confirm with @mrproliu .\r\n\r\nDespite of all above, `if (isFirst || (alwaysAnalyzeIdentity && message.getIdentifier() != null))` is buggy because `message.getIdentifier()` is never null, it returns a default instance if `identifier == null` so you might always get `role == NONE`"", 'commenter': 'kezhenxu94'}, {'comment': '>   // Identifier data that will only be sent in the first message on the stream. This is effectively\r\n  // structured metadata and is a performance optimization.\r\n  Identifier identifier = 1;\r\n\r\nThis is from ALS definition. What do you mean `never null`?', 'commenter': 'wu-sheng'}, {'comment': 'I said this from code level. `message.getIdentifier()` never returns null, protocol buffer compiler generates codes like `return identifier == null ? defaultInstance : identifier`, please use `message.hasIdentifier()`', 'commenter': 'kezhenxu94'}, {'comment': 'OK, make sense. ', 'commenter': 'wu-sheng'}, {'comment': 'Fixed. thanks.\r\n', 'commenter': 'mrproliu'}, {'comment': ""I can't see the commit."", 'commenter': 'wu-sheng'}]"
8193,oap-server/server-receiver-plugin/receiver-proto/src/main/proto/satellite/envoy/accesslog/v3/als.proto,"@@ -0,0 +1,24 @@
+syntax = ""proto3"";
+
+package satellite.envoy.accesslog.v3;
+
+import ""envoy/service/accesslog/v3/als.proto"";
+
+option java_package = ""org.apache.skywalking.satellite.envoy.accesslog.v3"";
+option java_outer_classname = ""SatelliteAlsProto"";
+option java_multiple_files = true;
+option java_generic_services = true;
+
+// [#protodoc-title: Satellite gRPC Access Log Service (ALS)]
+
+// Duplicate the Envoy ALS protocol, work for satellite transmit the ALS message to oap.","[{'comment': 'This is NOT duplicate, this is a new protocol(new service name changed)', 'commenter': 'wu-sheng'}]"
8193,.licenserc.yaml,"@@ -57,6 +57,7 @@ header:
     - '**/src/main/proto/jaeger/**'
     - '**/src/main/proto/mixer/**'
     - '**/src/main/proto/policy/**'
+    - '**/src/main/proto/satellite/**'","[{'comment': ""I'd say these files are our own work, not third parties', so please add license headers to them instead of excluding them"", 'commenter': 'kezhenxu94'}, {'comment': ""I was struggling about this, right now, I think yes, this is written and provided by us, let's add license for it."", 'commenter': 'wu-sheng'}]"
8193,oap-server/server-receiver-plugin/receiver-proto/src/main/proto/satellite/envoy/accesslog/v2/als.proto,"@@ -0,0 +1,43 @@
+//
+// Licensed to the Apache Software Foundation (ASF) under one
+// or more contributor license agreements.  See the NOTICE file
+// distributed with this work for additional information
+// regarding copyright ownership.  The ASF licenses this file
+// to you under the Apache License, Version 2.0 (the
+// ""License""); you may not use this file except in compliance
+// with the License.  You may obtain a copy of the License at
+//
+//   http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing,
+// software distributed under the License is distributed on an
+// ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+// KIND, either express or implied.  See the License for the
+// specific language governing permissions and limitations
+// under the License.
+//
+
+syntax = ""proto3"";
+
+package satellite.envoy.accesslog.v2;
+
+import ""envoy/service/accesslog/v3/als.proto"";
+
+option java_package = ""org.apache.skywalking.satellite.envoy.accesslog.v2"";
+option java_outer_classname = ""SatelliteAlsProto"";
+option java_multiple_files = true;
+option java_generic_services = true;
+
+// [#protodoc-title: Satellite gRPC Access Log Service (ALS)]
+
+// The new Envoy ALS protocol, work for satellite transmit the ALS message to oap.
+service SatelliteAccessLogService {
+  // Use the same parameters to transmit access log messages.
+  // The only difference is that the identity information (StreamAccessLogsMessage#identity) may occur on each message.
+  // Rely on the streaming messages are orderly, so there will be no problems with message processing.
+  // Therefore, when the satellite transmits the ALS message, it does not need to open, send and close the stream for each different identity (envoy).
+  // As a result, unnecessary streaming operation requests could be reduced, and the satellite becomes more stable when the satellite sends requests to the upstream.
+  // Especially when the number of envoys increases, the optimization becomes more obvious.
+  rpc StreamAccessLogs(stream .envoy.service.accesslog.v3.StreamAccessLogsMessage) returns (.envoy.service.accesslog.v3.StreamAccessLogsResponse) {","[{'comment': 'This should be `v2`?', 'commenter': 'kezhenxu94'}, {'comment': 'Currently, the OAP ALS handler has combined the `v2` and `v3` version message and response, and they do not contain conflict. So I think we could just keep it, all they use the `v3` version.', 'commenter': 'mrproliu'}, {'comment': ""For messages they are all v3, but for gRPC service they are different versions\r\n\r\n```diff\r\n- io.envoyproxy.envoy.service.accesslog.v2.AccessLogServiceGrpc\r\n+ io.envoyproxy.envoy.service.accesslog.v3.AccessLogServiceGrpc\r\n```\r\n\r\nif you want to keep in v3 service between Satellite and OAP, then I don't think you need to copy `v3/als.proto` to `v2/als.proto`, they are exactly the same."", 'commenter': 'kezhenxu94'}, {'comment': 'v3 should be correct. But this reminds me, do we really need v2? Satellite should be 100% good to forward v2 ALS to the v3 endpoint of OAP, right? We could add less codes in OAP for now. v3 is the only main stream.', 'commenter': 'wu-sheng'}, {'comment': '@kezhenxu94 That is what you did :) Maybe you forget it. v2 gRPC service with v3 parameter and return values.\r\n\r\nhttps://github.com/apache/skywalking/blob/842b5d927e9c196e14a4dc3f73812d2c4adfebf4/oap-server/server-receiver-plugin/receiver-proto/src/main/proto/envoy/service/accesslog/v2/als.proto\r\n\r\n', 'commenter': 'wu-sheng'}, {'comment': 'Anyway, I still prefer to using v3 only.', 'commenter': 'wu-sheng'}, {'comment': ""I know it, I remember it...\r\n\r\nBut what @mrproliu did is provide 2 exactly the same service version and same message version, what I did is 2 different service with same protocol buffer message, different Envoy version send via different service version.\r\n\r\n**HIGHLIGHT**:\r\n\r\n- mine: different service version and same message version\r\n- @mrproliu: same service version and same message version, what's the point?"", 'commenter': 'kezhenxu94'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/Layer.java,"@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis;
+
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+
+public enum Layer {
+
+    undefined(0),","[{'comment': 'I think enum values are usually all capitalized or CamelCase. ', 'commenter': 'kezhenxu94'}, {'comment': 'This reminds me,  I think should be upper case according to Oracle doc, https://docs.oracle.com/javase/tutorial/java/javaOO/enum.html', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/Layer.java,"@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis;
+
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+
+public enum Layer {
+
+    undefined(0),
+
+    mesh(1),
+
+    general(2),
+
+    os_linux(3),
+
+    k8s(4),
+
+    faas(5),
+
+    mesh_cp(6),
+
+    mesh_dp(7),
+
+    database(8),
+
+    cache(9),
+
+    browser(10),
+
+    so11y_oap(11),
+
+    so11y_satellite(12),
+
+    mq(13),
+
+    virtual_database(14),
+
+    virtual_mq(15);
+
+    private final int value;
+
+    Layer(int value) {
+        this.value = value;
+    }
+
+    public int value() {
+        return value;
+    }
+
+    public static Layer valueOf(int value) {
+        switch (value) {","[{'comment': ""Consider using a map or even an array to index the values, so that you don't need a long switch statement. "", 'commenter': 'kezhenxu94'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/IDManager.java,"@@ -35,19 +35,19 @@
      * Service ID related functions.
      */
     public static class ServiceID {
-        /**
-         * @return encoded service id
-         */
-        public static String buildId(String name, NodeType type) {
-            return buildId(name, type.equals(NodeType.Normal) || type.equals(NodeType.Browser));
-        }
+//        /**
+//         * @return encoded service id
+//         */
+//        public static String buildId(String name, NodeType type) {
+//            return buildId(name, type.equals(NodeType.Normal) || type.equals(NodeType.Browser));
+//        }","[{'comment': 'Tip, remove legacy codes.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/Layer.java,"@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis;
+
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+
+public enum Layer {","[{'comment': 'We need comments on Layer. Such as copy from https://github.com/apache/skywalking-query-protocol/blob/d9039e01767bc79e845bb32dbbeb6cdf74403af5/metadata-v2.graphqls#L40-L54', 'commenter': 'wu-sheng'}, {'comment': 'Added', 'commenter': 'wankai123'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/manual/service/ServiceTraffic.java,"@@ -35,40 +35,63 @@
 import org.apache.skywalking.oap.server.core.storage.StorageHashMapBuilder;
 import org.apache.skywalking.oap.server.core.storage.annotation.Column;
 
+import static org.apache.logging.log4j.util.Base64Util.encode;
 import static org.apache.skywalking.oap.server.core.Const.DOUBLE_COLONS_SPLIT;
 
 @Stream(name = ServiceTraffic.INDEX_NAME, scopeId = DefaultScopeDefine.SERVICE,
     builder = ServiceTraffic.Builder.class, processor = MetricsStreamProcessor.class)
 @MetricsExtension(supportDownSampling = false, supportUpdate = false)
 @EqualsAndHashCode(of = {
     ""name"",
-    ""nodeType""
+    ""layer""
 })
 public class ServiceTraffic extends Metrics {
     public static final String INDEX_NAME = ""service_traffic"";
 
     public static final String NAME = ""name"";
-    public static final String NODE_TYPE = ""node_type"";
+
+    public static final String SHORT_NAME = ""short_name"";
+
+    public static final String SERVICE_ID = ""service_id"";
+
     public static final String GROUP = ""service_group"";
 
+    public static final String LAYER = ""layer"";
+
     @Setter
     @Getter
     @Column(columnName = NAME, matchQuery = true)
     private String name = Const.EMPTY_STRING;
 
     @Setter
     @Getter
-    @Column(columnName = NODE_TYPE)
-    private NodeType nodeType;
+    @Column(columnName = SHORT_NAME)
+    private String shortName = Const.EMPTY_STRING;
+
+    @Setter
+    @Column(columnName = SERVICE_ID)
+    private String serviceId;
 
     @Setter
     @Getter
     @Column(columnName = GROUP)
     private String group;
 
+    @Setter
+    @Getter
+    @Column(columnName = LAYER)
+    private Layer layer = Layer.undefined;
+
+    @Setter
+    private boolean isNormal = true;
+
     @Override
     protected String id0() {","[{'comment': 'We need comments to explain what `id0` is about, and what is the `#serviceId` rule.', 'commenter': 'wu-sheng'}, {'comment': 'Added', 'commenter': 'wankai123'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/manual/service/ServiceTraffic.java,"@@ -35,40 +35,63 @@
 import org.apache.skywalking.oap.server.core.storage.StorageHashMapBuilder;
 import org.apache.skywalking.oap.server.core.storage.annotation.Column;
 
+import static org.apache.logging.log4j.util.Base64Util.encode;
 import static org.apache.skywalking.oap.server.core.Const.DOUBLE_COLONS_SPLIT;
 
 @Stream(name = ServiceTraffic.INDEX_NAME, scopeId = DefaultScopeDefine.SERVICE,
     builder = ServiceTraffic.Builder.class, processor = MetricsStreamProcessor.class)
 @MetricsExtension(supportDownSampling = false, supportUpdate = false)
 @EqualsAndHashCode(of = {
     ""name"",
-    ""nodeType""
+    ""layer""
 })
 public class ServiceTraffic extends Metrics {
     public static final String INDEX_NAME = ""service_traffic"";
 
     public static final String NAME = ""name"";
-    public static final String NODE_TYPE = ""node_type"";
+
+    public static final String SHORT_NAME = ""short_name"";
+
+    public static final String SERVICE_ID = ""service_id"";
+
     public static final String GROUP = ""service_group"";
 
+    public static final String LAYER = ""layer"";
+
     @Setter
     @Getter
     @Column(columnName = NAME, matchQuery = true)
     private String name = Const.EMPTY_STRING;
 
     @Setter
     @Getter
-    @Column(columnName = NODE_TYPE)
-    private NodeType nodeType;
+    @Column(columnName = SHORT_NAME)
+    private String shortName = Const.EMPTY_STRING;
+
+    @Setter
+    @Column(columnName = SERVICE_ID)
+    private String serviceId;
 
     @Setter
     @Getter
     @Column(columnName = GROUP)
     private String group;
 
+    @Setter
+    @Getter
+    @Column(columnName = LAYER)
+    private Layer layer = Layer.undefined;
+
+    @Setter
+    private boolean isNormal = true;","[{'comment': '```suggestion\r\n    /**\r\n     * The `normal` status represents this service is detected by an agent.\r\n     *\r\n     * The un-normal service is conjectured by telemetry data collected from agents on/in the `normal` service.\r\n     */\r\n    @Setter\r\n    private boolean isNormal = true;\r\n```', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/manual/service/ServiceTraffic.java,"@@ -110,16 +136,20 @@ public ServiceTraffic storage2Entity(final Map<String, Object> dbMap) {
         @Override
         public Map<String, Object> entity2Storage(final ServiceTraffic storageData) {
             final String serviceName = storageData.getName();
-            if (NodeType.Normal.equals(storageData.getNodeType())) {","[{'comment': 'The normal service condition should be kept. Because no matter what service name of a conjectured service is, it is conjectured by the collected telemetry data. `Group name` should be set by users only.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/manual/service/ServiceTraffic.java,"@@ -98,8 +121,11 @@ public void deserialize(final RemoteData remoteData) {
         public ServiceTraffic storage2Entity(final Map<String, Object> dbMap) {
             ServiceTraffic serviceTraffic = new ServiceTraffic();
             serviceTraffic.setName((String) dbMap.get(NAME));
-            serviceTraffic.setNodeType(NodeType.valueOf(((Number) dbMap.get(NODE_TYPE)).intValue()));
+            serviceTraffic.setShortName((String) dbMap.get(SHORT_NAME));
             serviceTraffic.setGroup((String) dbMap.get(GROUP));
+            if (dbMap.get(LAYER) != null) {
+                serviceTraffic.setLayer(Layer.valueOf(((Number) dbMap.get(LAYER)).intValue()));
+            }","[{'comment': 'You should add a `else` here to set Layer as default(`undefined`) for the legacy data.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/MetadataQueryService.java,"@@ -60,49 +58,61 @@ private IMetadataQueryDAO getMetadataQueryDAO() {
                                     .collect(Collectors.toList());
     }
 
-    public List<Service> getAllBrowserServices() throws IOException {
-        return getMetadataQueryDAO().getAllBrowserServices().stream().distinct().collect(Collectors.toList());
-    }
-
-    public List<Database> getAllDatabases() throws IOException {
-        return getMetadataQueryDAO().getAllDatabases().stream().distinct().collect(Collectors.toList());
-    }
-
-    public List<Service> searchServices(final long startTimestamp, final long endTimestamp,
-                                        final String keyword) throws IOException {
-        return getMetadataQueryDAO().searchServices(NodeType.Normal, keyword)
-                                    .stream()
-                                    .distinct()
-                                    .collect(Collectors.toList());
+    public Service getService(final String serviceId) throws IOException {
+        Service service = getMetadataQueryDAO().findService(serviceId);
+        if (service.getGroup() == null) {
+            service.setGroup(Const.EMPTY_STRING);
+        }
+        return service;
     }
 
-    public List<Service> searchBrowserServices(final long startTimestamp, final long endTimestamp,
-                                               final String keyword) throws IOException {
-        return getMetadataQueryDAO().searchServices(NodeType.Browser, keyword)
-                                    .stream()
-                                    .distinct()
-                                    .collect(Collectors.toList());
+    public ServiceInstance getInstance(final String instanceId) throws IOException {
+        return getMetadataQueryDAO().getInstance(instanceId);
     }
 
-    public List<ServiceInstance> getServiceInstances(final long startTimestamp, final long endTimestamp,
+//    public List<Service> getAllBrowserServices() throws IOException {
+//        return getMetadataQueryDAO().getAllBrowserServices().stream().distinct().collect(Collectors.toList());
+//    }
+//
+//    public List<Database> getAllDatabases() throws IOException {
+//        return getMetadataQueryDAO().getAllDatabases().stream().distinct().collect(Collectors.toList());
+//    }
+//
+//    public List<Service> searchServices(final long startTimestamp, final long endTimestamp,
+//                                        final String keyword) throws IOException {
+//        return getMetadataQueryDAO().searchServices(NodeType.Normal, keyword)
+//                                    .stream()
+//                                    .distinct()
+//                                    .collect(Collectors.toList());
+//    }
+//
+//    public List<Service> searchBrowserServices(final long startTimestamp, final long endTimestamp,
+//                                               final String keyword) throws IOException {
+//        return getMetadataQueryDAO().searchServices(NodeType.Browser, keyword)
+//                                    .stream()
+//                                    .distinct()
+//                                    .collect(Collectors.toList());
+//    }","[{'comment': 'Remove commented codes please.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetadataQuery.java,"@@ -54,68 +51,53 @@ private MetadataQueryService getMetadataQueryService() {
         return metadataQueryService;
     }
 
-    /**","[{'comment': '`@Deprecated` is required on methods and class level.', 'commenter': 'wu-sheng'}, {'comment': 'Comments are required, ref to `MetricQuery`.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetadataQueryV2.java,"@@ -0,0 +1,98 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.query.graphql.resolver;
+
+import com.coxautodev.graphql.tools.GraphQLQueryResolver;
+import java.io.IOException;
+import java.text.SimpleDateFormat;
+import java.util.Date;
+import java.util.List;
+import org.apache.skywalking.oap.query.graphql.type.TimeInfo;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.query.MetadataQueryService;
+import org.apache.skywalking.oap.server.core.query.input.Duration;
+import org.apache.skywalking.oap.server.core.query.type.Endpoint;
+import org.apache.skywalking.oap.server.core.query.type.EndpointInfo;
+import org.apache.skywalking.oap.server.core.query.type.Service;
+import org.apache.skywalking.oap.server.core.query.type.ServiceInstance;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+
+public class MetadataQueryV2 implements GraphQLQueryResolver {","[{'comment': 'Comments are required.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/MetadataQueryService.java,"@@ -60,49 +58,61 @@ private IMetadataQueryDAO getMetadataQueryDAO() {
                                     .collect(Collectors.toList());
     }
 
-    public List<Service> getAllBrowserServices() throws IOException {
-        return getMetadataQueryDAO().getAllBrowserServices().stream().distinct().collect(Collectors.toList());
-    }
-
-    public List<Database> getAllDatabases() throws IOException {
-        return getMetadataQueryDAO().getAllDatabases().stream().distinct().collect(Collectors.toList());
-    }
-
-    public List<Service> searchServices(final long startTimestamp, final long endTimestamp,
-                                        final String keyword) throws IOException {
-        return getMetadataQueryDAO().searchServices(NodeType.Normal, keyword)
-                                    .stream()
-                                    .distinct()
-                                    .collect(Collectors.toList());
+    public Service getService(final String serviceId) throws IOException {
+        Service service = getMetadataQueryDAO().findService(serviceId);
+        if (service.getGroup() == null) {
+            service.setGroup(Const.EMPTY_STRING);
+        }
+        return service;
     }
 
-    public List<Service> searchBrowserServices(final long startTimestamp, final long endTimestamp,
-                                               final String keyword) throws IOException {
-        return getMetadataQueryDAO().searchServices(NodeType.Browser, keyword)
-                                    .stream()
-                                    .distinct()
-                                    .collect(Collectors.toList());
+    public ServiceInstance getInstance(final String instanceId) throws IOException {
+        return getMetadataQueryDAO().getInstance(instanceId);
     }
 
-    public List<ServiceInstance> getServiceInstances(final long startTimestamp, final long endTimestamp,
+//    public List<Service> getAllBrowserServices() throws IOException {
+//        return getMetadataQueryDAO().getAllBrowserServices().stream().distinct().collect(Collectors.toList());
+//    }
+//
+//    public List<Database> getAllDatabases() throws IOException {
+//        return getMetadataQueryDAO().getAllDatabases().stream().distinct().collect(Collectors.toList());
+//    }
+//
+//    public List<Service> searchServices(final long startTimestamp, final long endTimestamp,
+//                                        final String keyword) throws IOException {
+//        return getMetadataQueryDAO().searchServices(NodeType.Normal, keyword)
+//                                    .stream()
+//                                    .distinct()
+//                                    .collect(Collectors.toList());
+//    }
+//
+//    public List<Service> searchBrowserServices(final long startTimestamp, final long endTimestamp,
+//                                               final String keyword) throws IOException {
+//        return getMetadataQueryDAO().searchServices(NodeType.Browser, keyword)
+//                                    .stream()
+//                                    .distinct()
+//                                    .collect(Collectors.toList());
+//    }
+
+    public List<ServiceInstance> listInstances(final long startTimestamp, final long endTimestamp,
                                                      final String serviceId) throws IOException {
-        return getMetadataQueryDAO().getServiceInstances(startTimestamp, endTimestamp, serviceId)
+        return getMetadataQueryDAO().listInstances(startTimestamp, endTimestamp, serviceId)
                                     .stream().distinct().collect(Collectors.toList());
     }
 
-    public List<Endpoint> searchEndpoint(final String keyword, final String serviceId,
-                                         final int limit) throws IOException {
-        return getMetadataQueryDAO().searchEndpoint(keyword, serviceId, limit)
+    public List<Endpoint> findEndpoint(final String keyword, final String serviceId,
+                                       final int limit) throws IOException {
+        return getMetadataQueryDAO().findEndpoint(keyword, serviceId, limit)
                                     .stream().distinct().collect(Collectors.toList());
     }
 
-    public Service searchService(final String serviceCode) throws IOException {
-        return getMetadataQueryDAO().searchService(NodeType.Normal, serviceCode);
-    }
-
-    public Service searchBrowserService(final String serviceCode) throws IOException {
-        return getMetadataQueryDAO().searchService(NodeType.Browser, serviceCode);
-    }
+//    public Service searchService(final String serviceCode) throws IOException {
+//        return getMetadataQueryDAO().searchService(NodeType.Normal, serviceCode);
+//    }
+//
+//    public Service searchBrowserService(final String serviceCode) throws IOException {
+//        return getMetadataQueryDAO().searchService(NodeType.Browser, serviceCode);
+//    }","[{'comment': 'Remove these', 'commenter': 'kezhenxu94'}]"
8367,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/MetadataQueryEsDAO.java,"@@ -143,55 +128,55 @@ public Service searchService(final NodeType nodeType, final String serviceCode)
     }
 
     @Override
-    public List<Endpoint> searchEndpoint(String keyword, String serviceId, int limit)
-        throws IOException {
-        final String index = IndexController.LogicIndicesRegister.getPhysicalTableName(
-            EndpointTraffic.INDEX_NAME);
+    public List<ServiceInstance> listInstances(long startTimestamp, long endTimestamp,
+                                               String serviceId) throws IOException {
+        final String index =
+            IndexController.LogicIndicesRegister.getPhysicalTableName(InstanceTraffic.INDEX_NAME);
 
+        final long minuteTimeBucket = TimeBucket.getMinuteTimeBucket(startTimestamp);
         final BoolQueryBuilder query =
             Query.bool()
-                 .must(Query.term(EndpointTraffic.SERVICE_ID, serviceId));
-
-        if (!Strings.isNullOrEmpty(keyword)) {
-            String matchCName = MatchCNameBuilder.INSTANCE.build(EndpointTraffic.NAME);
-            query.must(Query.match(matchCName, keyword));
-        }
-
-        final SearchBuilder search = Search.builder().query(query).size(limit);
+                 .must(Query.range(InstanceTraffic.LAST_PING_TIME_BUCKET).gte(minuteTimeBucket))
+                 .must(Query.term(InstanceTraffic.SERVICE_ID, serviceId));
+        final SearchBuilder search = Search.builder().query(query).size(queryMaxSize);
 
         final SearchResponse response = getClient().search(index, search.build());
-
-        List<Endpoint> endpoints = new ArrayList<>();
-        for (SearchHit searchHit : response.getHits()) {
-            Map<String, Object> sourceAsMap = searchHit.getSource();
-
-            final EndpointTraffic endpointTraffic =
-                new EndpointTraffic.Builder().storage2Entity(sourceAsMap);
-
-            Endpoint endpoint = new Endpoint();
-            endpoint.setId(endpointTraffic.id());
-            endpoint.setName((String) sourceAsMap.get(EndpointTraffic.NAME));
-            endpoints.add(endpoint);
-        }
-
-        return endpoints;
+        return buildInstances(response);
     }
 
     @Override
-    public List<ServiceInstance> getServiceInstances(long startTimestamp, long endTimestamp,
-                                                     String serviceId) throws IOException {
+    public ServiceInstance getInstance(final String instanceId) throws IOException {
         final String index =
             IndexController.LogicIndicesRegister.getPhysicalTableName(InstanceTraffic.INDEX_NAME);
-
-        final long minuteTimeBucket = TimeBucket.getMinuteTimeBucket(startTimestamp);
         final BoolQueryBuilder query =
             Query.bool()
-                 .must(Query.range(InstanceTraffic.LAST_PING_TIME_BUCKET).gte(minuteTimeBucket))
-                 .must(Query.term(InstanceTraffic.SERVICE_ID, serviceId));
-        final SearchBuilder search = Search.builder().query(query).size(queryMaxSize);
+                 .must(Query.term(""_id"", instanceId));","[{'comment': ""How can you find the instance by `_id`? I don't think we ever use `_id` (which is generated by ES) in our logic"", 'commenter': 'kezhenxu94'}, {'comment': ""I think we don't use `ES` generated ID. I haven't verified this method, but AFAIK, `_id` of index is really generally by traffic and metric entities, they have `id()` method for this. Such as\r\n\r\n```java\r\n    @Override\r\n    public InsertRequest prepareBatchInsert(Model model, Metrics metrics) {\r\n        Map<String, Object> builder =\r\n            IndexController.INSTANCE.appendMetricTableColumn(model, storageBuilder.entity2Storage(metrics));\r\n        String modelName = TimeSeriesUtils.writeIndexName(model, metrics.getTimeBucket());\r\n        // Notice this metrics.id(). In instance_traffic case, this is IDManager.ServiceInstanceID.buildId(serviceId, name);\r\n        String id = IndexController.INSTANCE.generateDocId(model, metrics.id());\r\n        return getClient().prepareInsert(modelName, id, builder);\r\n    }\r\n```"", 'commenter': 'wu-sheng'}, {'comment': ""OK make sense to me, we don't use ID generated by ES, we specify them when inserting documents."", 'commenter': 'kezhenxu94'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/type/Service.java,"@@ -28,5 +30,7 @@
 public class Service {
     private String id;
     private String name;
+    private String shortName;
     private String group;
+    private List<String> layers = new ArrayList<>();","[{'comment': 'What about using `Set<String>`?', 'commenter': 'kezhenxu94'}]"
8367,oap-server/server-storage-plugin/storage-jdbc-hikaricp-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/jdbc/h2/dao/H2MetadataQueryDAO.java,"@@ -146,125 +143,84 @@ public H2MetadataQueryDAO(JDBCHikariCPClient h2Client, int metadataQueryMaxSize)
     }
 
     @Override
-    public Service searchService(NodeType nodeType, String serviceCode) throws IOException {
+    public Service findService(final String serviceId) throws IOException {
         StringBuilder sql = new StringBuilder();
         List<Object> condition = new ArrayList<>(5);
         sql.append(""select * from "").append(ServiceTraffic.INDEX_NAME).append("" where "");
-        sql.append(ServiceTraffic.NODE_TYPE).append(""=?"");
-        condition.add(nodeType.value());
-        sql.append("" and "").append(ServiceTraffic.NAME).append("" = ?"");
-        condition.add(serviceCode);
+        sql.append(ServiceTraffic.SERVICE_ID).append("" = ?"");
+        condition.add(serviceId);
 
         try (Connection connection = h2Client.getConnection()) {
-            try (ResultSet resultSet = h2Client.executeQuery(
-                connection, sql.toString(), condition.toArray(new Object[0]))) {
-
-                while (resultSet.next()) {
-                    Service service = new Service();
-                    service.setId(resultSet.getString(H2TableInstaller.ID_COLUMN));
-                    service.setName(resultSet.getString(ServiceTraffic.NAME));
-                    service.setGroup(resultSet.getString(ServiceTraffic.GROUP));
-                    return service;
-                }
-            }
+            ResultSet resultSet = h2Client.executeQuery(
+                connection, sql.toString(), condition.toArray(new Object[0]));
+            final List<Service> services = buildServices(resultSet);
+            return services.size() > 0 ? services.get(0) : null;
         } catch (SQLException e) {
             throw new IOException(e);
         }
-
-        return null;
     }
 
     @Override
-    public List<Endpoint> searchEndpoint(String keyword, String serviceId, int limit) throws IOException {
+    public ServiceInstance getInstance(final String instanceId) throws IOException {
         StringBuilder sql = new StringBuilder();
         List<Object> condition = new ArrayList<>(5);
-        sql.append(""select * from "").append(EndpointTraffic.INDEX_NAME).append("" where "");
-        sql.append(EndpointTraffic.SERVICE_ID).append(""=?"");
-        condition.add(serviceId);
-        if (!Strings.isNullOrEmpty(keyword)) {
-            sql.append("" and "").append(EndpointTraffic.NAME).append("" like concat('%',?,'%') "");
-            condition.add(keyword);
-        }
-        sql.append("" limit "").append(limit);
+        sql.append(""select * from "").append(InstanceTraffic.INDEX_NAME).append("" where "");
+        sql.append(H2TableInstaller.ID_COLUMN).append("" = ?"");","[{'comment': ""I don't think we have stored the instance id as column `H2TableInstaller.ID_COLUMN`"", 'commenter': 'kezhenxu94'}, {'comment': 'I guess similar to https://github.com/apache/skywalking/pull/8367#discussion_r776910074.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/query/IMetadataQueryDAO.java,"@@ -20,58 +20,37 @@
 
 import java.io.IOException;
 import java.util.List;
-import org.apache.skywalking.oap.server.core.analysis.NodeType;
-import org.apache.skywalking.oap.server.core.query.type.Database;
 import org.apache.skywalking.oap.server.core.query.type.Endpoint;
 import org.apache.skywalking.oap.server.core.query.type.Service;
 import org.apache.skywalking.oap.server.core.query.type.ServiceInstance;
 import org.apache.skywalking.oap.server.core.storage.DAO;
 
 public interface IMetadataQueryDAO extends DAO {
     /**
-     * @param group group name for filtering.
-     * @return list of the all available normal services
+     * @param layer layer name for filtering
+     * @param group group name for filtering
+     * @return list of the all available services
      */
-    List<Service> getAllServices(final String group) throws IOException;
+    List<Service> listServices(final String layer, final String group) throws IOException;
 
-    /**
-     * @return list of the all available browser services
-     */
-    List<Service> getAllBrowserServices() throws IOException;
-
-    /**
-     * @return list of all conjecture database services.
-     */
-    List<Database> getAllDatabases() throws IOException;
+    Service findService(final String serviceId) throws IOException;
 
     /**
-     * @param nodeType describe which kind of node of Service
-     * @param keyword  to filter the normal service
-     * @return the list of normal services matching the given keyword
+     * @param startTimestamp The instance is required to be live after this timestamp
+     * @param endTimestamp   The instance is required to be live before this timestamp.
+     * @param serviceId      the owner of the instances.
+     * @return list of instances matching the given conditions.
      */
-    List<Service> searchServices(final NodeType nodeType, final String keyword) throws IOException;
+    List<ServiceInstance> listInstances(final long startTimestamp, final long endTimestamp,
+                                        final String serviceId) throws IOException;
 
-    /**
-     * @param nodeType    describe which kind of node of Service
-     * @param serviceCode to literal match
-     * @return the service matching the given full name.
-     */
-    Service searchService(final NodeType nodeType, final String serviceCode) throws IOException;
+    ServiceInstance getInstance(final String instanceId) throws IOException;","[{'comment': 'Please add an E2E to verify this new API, from the implementation it seems this is not working', 'commenter': 'kezhenxu94'}, {'comment': '@wankai123 Please recheck and do manual GraphQL testing. \r\n\r\n@kezhenxu94 e2e is not working at this stage I am afraid. CLI is lack of env to verify its feature. We have to use manual tests for some parts.', 'commenter': 'wu-sheng'}, {'comment': ""Manual tested, it works fine. Once CLI supported the new query, I'll add the new verify."", 'commenter': 'wankai123'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/MetadataQueryService.java,"@@ -49,8 +47,8 @@ private IMetadataQueryDAO getMetadataQueryDAO() {
         return metadataQueryDAO;
     }
 
-    public List<Service> getAllServices(final String group) throws IOException {
-        return getMetadataQueryDAO().getAllServices(group).stream()
+    public List<Service> listServices(final String layer, final String group) throws IOException {
+        return getMetadataQueryDAO().listServices(layer, group).stream()","[{'comment': 'I know you built a `map`-based distinct/merge on DAO level, which should be moved here. And `distinct` is not working anymore as `layer` list added. You should do `reduce` here to merging according to service name.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/MetadataQueryEsDAO.java,"@@ -61,80 +60,66 @@ public MetadataQueryEsDAO(ElasticSearchClient client, int queryMaxSize) {
     }
 
     @Override
-    public List<Service> getAllServices(final String group) throws IOException {
-        final String index =
-            IndexController.LogicIndicesRegister.getPhysicalTableName(ServiceTraffic.INDEX_NAME);
+    public List<Endpoint> findEndpoint(String keyword, String serviceId, int limit)","[{'comment': ""Please re-order the methods in all `IMetadataQueryDAO`'s implementations. `#findEndpoint` should not be the first method here."", 'commenter': 'wu-sheng'}]"
8367,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/MetadataQueryEsDAO.java,"@@ -61,80 +60,66 @@ public MetadataQueryEsDAO(ElasticSearchClient client, int queryMaxSize) {
     }
 
     @Override
-    public List<Service> getAllServices(final String group) throws IOException {
-        final String index =
-            IndexController.LogicIndicesRegister.getPhysicalTableName(ServiceTraffic.INDEX_NAME);
+    public List<Endpoint> findEndpoint(String keyword, String serviceId, int limit)
+        throws IOException {
+        final String index = IndexController.LogicIndicesRegister.getPhysicalTableName(
+            EndpointTraffic.INDEX_NAME);
 
         final BoolQueryBuilder query =
             Query.bool()
-                 .must(Query.term(ServiceTraffic.NODE_TYPE, NodeType.Normal.value()));
-        final SearchBuilder search = Search.builder().query(query).size(queryMaxSize);
-        if (StringUtil.isNotEmpty(group)) {
-            query.must(Query.term(ServiceTraffic.GROUP, group));
+                 .must(Query.term(EndpointTraffic.SERVICE_ID, serviceId));
+
+        if (!Strings.isNullOrEmpty(keyword)) {
+            String matchCName = MatchCNameBuilder.INSTANCE.build(EndpointTraffic.NAME);
+            query.must(Query.match(matchCName, keyword));
         }
-        final SearchResponse results = getClient().search(index, search.build());
 
-        return buildServices(results);
-    }
+        final SearchBuilder search = Search.builder().query(query).size(limit);
 
-    @Override
-    public List<Service> getAllBrowserServices() throws IOException {
-        final String index =
-            IndexController.LogicIndicesRegister.getPhysicalTableName(ServiceTraffic.INDEX_NAME);
-        final BoolQueryBuilder query = Query.bool().must(
-            Query.term(ServiceTraffic.NODE_TYPE, NodeType.Browser.value()));
-        final SearchBuilder search = Search.builder().query(query).size(queryMaxSize);
-        final SearchResponse result = getClient().search(index, search.build());
+        final SearchResponse response = getClient().search(index, search.build());
 
-        return buildServices(result);
-    }
+        List<Endpoint> endpoints = new ArrayList<>();
+        for (SearchHit searchHit : response.getHits()) {
+            Map<String, Object> sourceAsMap = searchHit.getSource();
 
-    @Override
-    public List<Database> getAllDatabases() throws IOException {
-        final String index =
-            IndexController.LogicIndicesRegister.getPhysicalTableName(ServiceTraffic.INDEX_NAME);
+            final EndpointTraffic endpointTraffic =
+                new EndpointTraffic.Builder().storage2Entity(sourceAsMap);
 
-        final BoolQueryBuilder query = Query.bool().must(
-            Query.term(ServiceTraffic.NODE_TYPE, NodeType.Database.value()));
-        final SearchBuilder search = Search.builder().query(query).size(queryMaxSize);
-        final SearchResponse results = getClient().search(index, search.build());
+            Endpoint endpoint = new Endpoint();
+            endpoint.setId(endpointTraffic.id());
+            endpoint.setName((String) sourceAsMap.get(EndpointTraffic.NAME));
+            endpoints.add(endpoint);
+        }
 
-        final List<Service> serviceList = buildServices(results);
-        return serviceList.stream().map(service -> {
-            Database database = new Database();
-            database.setId(service.getId());
-            database.setName(service.getName());
-            return database;
-        }).collect(Collectors.toList());
+        return endpoints;
     }
 
     @Override
-    public List<Service> searchServices(final NodeType nodeType, final String keyword) throws IOException {
+    public List<Service> listServices(final String layer, final String group) throws IOException {
         final String index =
             IndexController.LogicIndicesRegister.getPhysicalTableName(ServiceTraffic.INDEX_NAME);
 
         final BoolQueryBuilder query =
-            Query.bool()
-                 .must(Query.term(ServiceTraffic.NODE_TYPE, nodeType.value()));
+            Query.bool();
         final SearchBuilder search = Search.builder().query(query).size(queryMaxSize);
-
-        if (!Strings.isNullOrEmpty(keyword)) {
-            String matchCName = MatchCNameBuilder.INSTANCE.build(ServiceTraffic.NAME);
-            query.must(Query.match(matchCName, keyword));
+        if (StringUtil.isNotEmpty(layer)) {
+            query.must(Query.term(ServiceTraffic.LAYER, Layer.valueOf(layer).value()));
         }
+        if (StringUtil.isNotEmpty(group)) {
+            query.must(Query.term(ServiceTraffic.GROUP, group));
+        }
+        final SearchResponse results = getClient().search(index, search.build());
 
-        SearchResponse response = getClient().search(index, search.build());
-        return buildServices(response);
+        return buildServices(results);
     }
 
     @Override
-    public Service searchService(final NodeType nodeType, final String serviceCode) throws IOException {
+    public Service findService(final String serviceId) throws IOException {
         final String index =
             IndexController.LogicIndicesRegister.getPhysicalTableName(ServiceTraffic.INDEX_NAME);
         final BoolQueryBuilder query =
             Query.bool()
-                 .must(Query.term(ServiceTraffic.NODE_TYPE, nodeType.value()))
-                 .must(Query.term(ServiceTraffic.NAME, serviceCode));
+                 .must(Query.term(ServiceTraffic.SERVICE_ID, serviceId));
         final SearchBuilder search = Search.builder().query(query).size(1);","[{'comment': 'I am feeling `size(1)` is not correct here anymore. We could have multiple layers(meaning multiple records per service) now.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/query/MetadataQueryService.java,"@@ -117,4 +97,19 @@ public EndpointInfo getEndpointInfo(final String endpointId) throws IOException
         endpointInfo.setServiceName(serviceIDDefinition.getName());
         return endpointInfo;
     }
+
+    private List<Service> combineServices(List<Service> services) {
+        return new ArrayList<>(services.stream()
+                                                    .peek(service -> {
+                                                        if (service.getGroup() == null) {
+                                                            service.setGroup(Const.EMPTY_STRING);
+                                                        }
+                                                    })
+                                                    .collect(Collectors.toMap(Service::getName, service -> service,
+                                                                              (s1, s2) -> {
+                                                                                  s1.getLayers().addAll(s2.getLayers());
+                                                                                  return s1;
+                                                                              }
+                                                    )).values());","[{'comment': '```suggestion\r\n        return new ArrayList<>(\r\n            services.stream()\r\n                    .peek(service -> {\r\n                        if (service.getGroup() == null) {\r\n                            service.setGroup(Const.EMPTY_STRING);\r\n                        }\r\n                    })\r\n                    .collect(\r\n                        Collectors.toMap(Service::getName, service -> service,\r\n                                         (s1, s2) -> {\r\n                                             s1.getLayers().addAll(s2.getLayers());\r\n                                             return s1;\r\n                                         }\r\n                        )).values());\r\n    };\r\n```\r\n\r\nThis format seems more readable, although the current one could pass the style check.', 'commenter': 'wu-sheng'}]"
8367,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/Layer.java,"@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis;
+
+import java.util.Arrays;
+import java.util.Map;
+import java.util.stream.Collectors;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+
+/**
+ * Layer represents an abstract framework in the computer science, such as operation system(OS_LINUX layer), Kubernetes(k8s layer)
+ */
+public enum Layer {
+
+    UNDEFINED(0),","[{'comment': 'Some values of this enum have comments, others are not.\r\nPlease add comments to all of them.', 'commenter': 'wu-sheng'}]"
8705,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/Column.java,"@@ -102,6 +101,28 @@
      */
     AnalyzerType analyzer() default AnalyzerType.OAP_ANALYZER;
 
+    /**
+     * Sharding key is used to group time series data per metric of one entity.
+     * For example,
+     * ServiceA's traffic gauge, service call per minute, includes following timestamp values, then it should be shard
+     * by service ID
+     * [ServiceA(encoded ID): 01-28 18:30 values-1, 01-28 18:31 values-2, 01-28 18:32 values-3, 01-28 18:32 values-4]
+     *
+     * BanyanDB is the 1st storage implementation supporting this. It would make continuous time series metrics stored
+     * closely and compressed better.
+     *
+     * 1. One entity at most has one sharding key
+     * 2. If no column is appointed for this, {@link org.apache.skywalking.oap.server.core.storage.StorageData#id}
+     * would
+     * be used by the storage implementation accordingly.
+     *
+     * NOTICE, this sharding concept is NOT for splitting data into different database instances or physical files.
+     *
+     * @return TRUE if this column could(not must) be used for sharding.
+     * @since 9.0.0
+     */
+    boolean shardingKey() default false;","[{'comment': '@hanahmily @lujiajing1126 Please check this comment carefully. I want to be sure I understand this concept correctly.', 'commenter': 'wu-sheng'}]"
8705,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/Column.java,"@@ -102,6 +101,28 @@
      */
     AnalyzerType analyzer() default AnalyzerType.OAP_ANALYZER;
 
+    /**
+     * Sharding key is used to group time series data per metric of one entity.
+     * For example,
+     * ServiceA's traffic gauge, service call per minute, includes following timestamp values, then it should be shard
+     * by service ID
+     * [ServiceA(encoded ID): 01-28 18:30 values-1, 01-28 18:31 values-2, 01-28 18:32 values-3, 01-28 18:32 values-4]
+     *
+     * BanyanDB is the 1st storage implementation supporting this. It would make continuous time series metrics stored
+     * closely and compressed better.
+     *
+     * 1. One entity at most has one sharding key","[{'comment': 'No. We support sharding with multiple keys now.', 'commenter': 'lujiajing1126'}, {'comment': '@hanahmily What do you prefer? I think you mentioned not to use multiple keys.', 'commenter': 'wu-sheng'}]"
8705,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/Column.java,"@@ -102,6 +101,28 @@
      */
     AnalyzerType analyzer() default AnalyzerType.OAP_ANALYZER;
 
+    /**
+     * Sharding key is used to group time series data per metric of one entity.
+     * For example,
+     * ServiceA's traffic gauge, service call per minute, includes following timestamp values, then it should be shard
+     * by service ID
+     * [ServiceA(encoded ID): 01-28 18:30 values-1, 01-28 18:31 values-2, 01-28 18:32 values-3, 01-28 18:32 values-4]
+     *
+     * BanyanDB is the 1st storage implementation supporting this. It would make continuous time series metrics stored
+     * closely and compressed better.","[{'comment': '```suggestion\r\n     * closely and compressed better. Besides, it can significantly alleviate high-cardinality issue for some indexed tags.\r\n```', 'commenter': 'lujiajing1126'}, {'comment': 'I think what you add is from database implementation, not has to be. Right?', 'commenter': 'wu-sheng'}]"
8705,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/Column.java,"@@ -102,6 +101,28 @@
      */
     AnalyzerType analyzer() default AnalyzerType.OAP_ANALYZER;
 
+    /**
+     * Sharding key is used to group time series data per metric of one entity.
+     * For example,
+     * ServiceA's traffic gauge, service call per minute, includes following timestamp values, then it should be shard
+     * by service ID
+     * [ServiceA(encoded ID): 01-28 18:30 values-1, 01-28 18:31 values-2, 01-28 18:32 values-3, 01-28 18:32 values-4]","[{'comment': '```suggestion\r\n     * [ServiceA(encoded via hash function): 01-28 18:30 values-1, 01-28 18:31 values-2, 01-28 18:32 values-3, 01-28 18:32 values-4]\r\n```', 'commenter': 'lujiajing1126'}, {'comment': 'encoded means from OAP perspective. Via hash function is another thing from server side implementation. We should not document here.', 'commenter': 'wu-sheng'}, {'comment': 'Make sense', 'commenter': 'lujiajing1126'}]"
8705,CHANGES.md,"@@ -112,14 +113,28 @@ Release Notes.
   , `SW_CORE_REST_JETTY_DELTA`).
 * [Breaking Change] Remove configuration `graphql/path` (env var: `SW_QUERY_GRAPHQL_PATH`).
 * Add storage column attribute `indexOnly`, support ElasticSearch only index and not store some fields.
-* Add `indexOnly=true` to `SegmentRecord.tags`, `AlarmRecord.tags`, `AbstractLogRecord.tags`, to reduce unnecessary storage.
+* Add `indexOnly=true` to `SegmentRecord.tags`, `AlarmRecord.tags`, `AbstractLogRecord.tags`, to reduce unnecessary
+  storage.
 * [Breaking Change] Remove configuration `restMinThreads` (env var: `SW_CORE_REST_JETTY_MIN_THREADS`
   , `SW_RECEIVER_SHARING_JETTY_MIN_THREADS`).
 * Refactor the core Builder mechanism, new storage plugin could implement their own converter and get rid of hard
   requirement of using HashMap to communicate between data object and database native structure.
 * [Breaking Change] Break all existing 3rd-party storage extensions.
 * Remove hard requirement of BASE64 encoding for binary field.
 * Add complexity limitation for GraphQL query to avoid malicious query.
+* Add `Column.shardingKeyIdx` for column definition for BanyanDB.
+
+```
+Sharding key is used to group time series data per metric of one entity in one place (same sharding or same 
+column for column-oriented database).
+For example,
+ServiceA's traffic gauge, service call per minute, includes following timestamp values, then it should be sharded by service ID
+[ServiceA(encoded ID): 01-28 18:30 values-1, 01-28 18:31 values-2, 01-28 18:32 values-3, 01-28 18:32 values-4]
+
+BanyanDB is the 1st storage implementation supporting this. It would make continuous time series metrics stored closely and compressed better.
+
+NOTICE, this sharding concept is NOT just for splitting data into different database instances or physical files.","[{'comment': ""You keep using the term `shard` but explaining it's actually for grouping, what's the reason not to just use name like `Column.groupKeyIdx`? This is really confusing"", 'commenter': 'kezhenxu94'}, {'comment': 'From the prospetive of the acutual implementation, the value generated from the ordered combination of all sharkdingKeys here is used for sharding.', 'commenter': 'lujiajing1126'}, {'comment': '> Sharding key is used to group time-series data per metric of one entity in one place\r\n\r\n> this sharding concept is NOT just for splitting data into different database instances or physical files\r\n\r\nThese 2 sentences are not conflicting. Group the key-equal data, and split the whole data set. If you feel confused, what do you prefer?', 'commenter': 'wu-sheng'}]"
8719,test/e2e-v2/cases/so11y/so11y-cases.yaml,"@@ -30,7 +30,7 @@
       expected: expected/metrics-has-value.yml
     - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_trace_count --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -
       expected: expected/metrics-has-value.yml
-    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_metrics_first_aggregation --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -
+    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_metrics_aggregation --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -","[{'comment': 'You are changing `single value` -> `labeled value`, I assume the expected file should be updated too.', 'commenter': 'wu-sheng'}, {'comment': '> You are changing `single value` -> `labeled value`, I assume the expected file should be updated too.\r\n\r\nI am not familiar  with `e2e-solly`. Take a moment, I will look at it. Thanks for your reminder and patience.', 'commenter': 'Cool-Coding'}, {'comment': 'You could copy this expected file into the so11y folder, https://github.com/apache/skywalking/blob/master/test/e2e-v2/cases/vm/expected/metrics-has-value-label.yml', 'commenter': 'wu-sheng'}, {'comment': '> You could copy this expected file into the so11y folder, https://github.com/apache/skywalking/blob/master/test/e2e-v2/cases/vm/expected/metrics-has-value-label.yml\r\n\r\nok', 'commenter': 'Cool-Coding'}, {'comment': '@wu-sheng I have run the ""swctl"" command in my own computer. please help me review again. Thanks!', 'commenter': 'Cool-Coding'}]"
8719,test/e2e-v2/cases/so11y/so11y-cases.yaml,"@@ -30,8 +30,8 @@
       expected: expected/metrics-has-value.yml
     - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_trace_count --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -
       expected: expected/metrics-has-value.yml
-    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_metrics_first_aggregation --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -
-      expected: expected/metrics-has-value.yml
+    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics multiple-linear --name=meter_oap_instance_metrics_aggregation --labels=level --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries | with(.[] ; .value=(.value | to_entries))' -
+      expected: expected/metrics-has-value-label.yml","[{'comment': '@wankai123 Could you check this? It seems tests are still failure.', 'commenter': 'wu-sheng'}]"
8719,test/e2e-v2/cases/so11y/so11y-cases.yaml,"@@ -30,8 +30,8 @@
       expected: expected/metrics-has-value.yml
     - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_trace_count --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -
       expected: expected/metrics-has-value.yml
-    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics linear --name=meter_oap_instance_metrics_first_aggregation --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries' -
-      expected: expected/metrics-has-value.yml
+    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics multiple-linear --name=meter_oap_instance_metrics_aggregation --labels=level --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e 'to_entries | with(.[] ; .value=(.value | to_entries))' -","[{'comment': '```suggestion\r\n    - query: swctl --display yaml --base-url=http://${oap_host}:${oap_12800}/graphql metrics multiple-linear --name=meter_oap_instance_metrics_aggregation --labels=""L1 aggregation"" --instance-name=http://localhost:1234 --service-name=oap::oap-server |yq e \'to_entries | with(.[] ; .value=(.value | to_entries))\' -\r\n```', 'commenter': 'wankai123'}, {'comment': 'The `--labels=` needs to provide the label-value .', 'commenter': 'wankai123'}, {'comment': '> The `--labels=` needs to provide the label-value .\r\n\r\n@wankai123 Thank you very much!', 'commenter': 'Cool-Coding'}]"
8724,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/Layer.java,"@@ -131,4 +131,23 @@ public static Layer valueOf(int value) {
         }
         return layer;
     }
+
+    /**
+     * The `normal` status represents this service is detected by an agent. The `un-normal` service is conjectured by
+     * telemetry data collected from agents on/in the `normal` service.
+     */
+    public static boolean isNormal(Layer layer) {","[{'comment': 'Adding `Layer#isNormal` may be easier, but anyway, not requried.', 'commenter': 'wu-sheng'}]"
8724,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/EndpointRelation.java,"@@ -96,11 +93,17 @@ public String getEntityId() {
     @Getter","[{'comment': '*SameNameButDifferent:*  The name `@Getter` refers to [java.lang.SuppressWarnings, lombok.Generated, java.lang.String, java.lang.Deprecated, org.apache.skywalking.oap.server.core.source.RequestType, org.apache.skywalking.oap.server.core.source.DetectPoint, org.apache.skywalking.oap.server.core.analysis.Layer] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8724,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/source/ServiceMeta.java,"@@ -37,10 +37,10 @@ public int scope() {
 
     @Override
     public String getEntityId() {
-        return IDManager.ServiceID.buildId(name, isNormal);
+        return IDManager.ServiceID.buildId(name, layer.isNormal());
     }
 
     private String name;","[{'comment': '*SameNameButDifferent:*  The name `name;` refers to [java.lang.SuppressWarnings, lombok.Generated, java.lang.String] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}, {'comment': '@sonatype-lift ignore', 'commenter': 'wu-sheng'}, {'comment': ""I've recorded this as ignored for this pull request. If you change your mind, just comment `@sonatype-lift unignore`."", 'commenter': 'sonatype-lift[bot]'}]"
8739,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/LogQuery.java,"@@ -61,7 +61,10 @@ public Logs queryLogs(LogQueryCondition condition) throws IOException {
             endSecondTB = condition.getQueryDuration().getEndTimeBucketInSec();
         }
         Order queryOrder = isNull(condition.getQueryOrder()) ? Order.DES : condition.getQueryOrder();
-
+        condition.getTags().forEach(tag -> {","[{'comment': 'I think tags could be NULL? All log relative e2e tests are failing.', 'commenter': 'wu-sheng'}, {'comment': 'I will modify', 'commenter': 'absorprofess'}]"
8739,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/LogQuery.java,"@@ -62,20 +65,26 @@ public Logs queryLogs(LogQueryCondition condition) throws IOException {
         }
         Order queryOrder = isNull(condition.getQueryOrder()) ? Order.DES : condition.getQueryOrder();
         condition.getTags().forEach(tag -> {
-            tag.setKey(tag.getKey().trim());
-            tag.setValue(tag.getValue().trim());
+            if (tag != null) {","[{'comment': 'You should check the error logs, I am not sure it is tags or tag is null. But I prefer tags.', 'commenter': 'wu-sheng'}]"
8739,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/LogQuery.java,"@@ -62,20 +65,26 @@ public Logs queryLogs(LogQueryCondition condition) throws IOException {
         }
         Order queryOrder = isNull(condition.getQueryOrder()) ? Order.DES : condition.getQueryOrder();
         condition.getTags().forEach(tag -> {
-            tag.setKey(tag.getKey().trim());
-            tag.setValue(tag.getValue().trim());
+            if (tag != null) {
+                if (StringUtil.isNotEmpty(tag.getKey())) {
+                    tag.setKey(tag.getKey().trim());
+                }
+                if (StringUtil.isNotEmpty(tag.getValue())) {
+                    tag.setValue(tag.getValue().trim());
+                }
+            }
         });
         return getQueryService().queryLogs(
-            condition.getServiceId(),
-            condition.getServiceInstanceId(),
-            condition.getEndpointId(),
-            condition.getRelatedTrace(),
-            condition.getPaging(),
-            queryOrder,
-            startSecondTB, endSecondTB,
-            condition.getTags(),
-            condition.getKeywordsOfContent(),
-            condition.getExcludingKeywordsOfContent()
+                condition.getServiceId(),
+                condition.getServiceInstanceId(),
+                condition.getEndpointId(),
+                condition.getRelatedTrace(),
+                condition.getPaging(),
+                queryOrder,
+                startSecondTB, endSecondTB,
+                condition.getTags(),
+                condition.getKeywordsOfContent(),
+                condition.getExcludingKeywordsOfContent()","[{'comment': 'These should not be changed.', 'commenter': 'wu-sheng'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/EndpointSourceBuilder.java,"@@ -0,0 +1,113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.analyzer.provider.trace.parser.listener;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import lombok.Getter;
+import lombok.RequiredArgsConstructor;
+import lombok.Setter;
+import org.apache.skywalking.apm.network.common.v3.KeyStringValuePair;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
+import org.apache.skywalking.oap.server.core.config.NamingControl;
+import org.apache.skywalking.oap.server.core.source.DetectPoint;
+import org.apache.skywalking.oap.server.core.source.Endpoint;
+import org.apache.skywalking.oap.server.core.source.RequestType;
+
+/**
+ * Endpoint traffic source builder. Endpoint represents an entrance to expose logic.
+ * Typically, it could be HTTP URI, gRPC service name, etc. for RPC, or a local method is required to be analyzed.
+ *
+ * @since 9.0.0
+ */
+@RequiredArgsConstructor
+class EndpointSourceBuilder {
+    protected final NamingControl namingControl;
+
+    @Getter
+    @Setter
+    protected long timeBucket;
+    @Getter
+    @Setter
+    protected String destServiceName;
+    @Getter
+    @Setter
+    protected Layer destLayer;
+    @Getter
+    @Setter
+    protected String destServiceInstanceName;
+    @Getter
+    @Setter
+    protected String destEndpointName;
+    @Getter
+    @Setter
+    protected int latency;
+    @Getter","[{'comment': '*SameNameButDifferent:*  The name `@Getter` refers to [java.lang.SuppressWarnings, lombok.Generated, java.lang.String, org.apache.skywalking.oap.server.core.analysis.Layer, org.apache.skywalking.oap.server.core.source.RequestType, org.apache.skywalking.oap.server.core.source.DetectPoint, java.util.List, java.util.Map] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/EndpointSourceBuilder.java,"@@ -0,0 +1,113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.analyzer.provider.trace.parser.listener;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import lombok.Getter;
+import lombok.RequiredArgsConstructor;
+import lombok.Setter;
+import org.apache.skywalking.apm.network.common.v3.KeyStringValuePair;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
+import org.apache.skywalking.oap.server.core.config.NamingControl;
+import org.apache.skywalking.oap.server.core.source.DetectPoint;
+import org.apache.skywalking.oap.server.core.source.Endpoint;
+import org.apache.skywalking.oap.server.core.source.RequestType;
+
+/**
+ * Endpoint traffic source builder. Endpoint represents an entrance to expose logic.
+ * Typically, it could be HTTP URI, gRPC service name, etc. for RPC, or a local method is required to be analyzed.
+ *
+ * @since 9.0.0
+ */
+@RequiredArgsConstructor","[{'comment': '*SameNameButDifferent:*  The name `@RequiredArgsConstructor` refers to [java.lang.SuppressWarnings, lombok.Generated, org.apache.skywalking.oap.server.core.config.NamingControl] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/RPCTrafficSourceBuilder.java,"@@ -54,68 +48,39 @@
     @Setter
     private String sourceServiceInstanceName;
     /**
+     * Same as {@link #sourceEndpointOwnerServiceName}
      * Source endpoint could be not owned by {@link #sourceServiceName}, such as in the MQ or un-instrumented proxy
-     * cases. This service always comes from the span.ref, so it is always a normal service.
+     * cases. This service always comes from the span.ref, so it is always a general service.
+     *
+     * @since 9.0.0
      */
     @Getter
     @Setter
-    private String sourceEndpointOwnerServiceName;
-    @Getter
-    @Setter
-    private String sourceEndpointName;
-    @Getter
-    @Setter
-    private String destServiceName;
-    @Getter
-    @Setter
-    private Layer destLayer;
+    private Layer sourceEndpointOwnerServiceLayer;
+    /**
+     * Source endpoint could be not owned by {@link #sourceServiceName}, such as in the MQ or un-instrumented proxy
+     * cases. This service always comes from the span.ref, so it is always a general service.
+     */
     @Getter
     @Setter
-    private String destServiceInstanceName;
+    private String sourceEndpointOwnerServiceName;
     @Getter
     @Setter
-    private String destEndpointName;
+    private String sourceEndpointName;
     @Getter
     @Setter","[{'comment': '*SameNameButDifferent:*  The name `@Setter` refers to [java.lang.SuppressWarnings, lombok.Generated, java.lang.String, org.apache.skywalking.oap.server.core.analysis.Layer] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/RPCAnalysisListener.java,"@@ -368,7 +365,6 @@ private void parseLogicEndpoints(final SpanObject span, final SegmentObject segm
                     sourceBuilder.setLatency(latency);
                     sourceBuilder.setStatus(status);
                     sourceBuilder.setType(RequestType.LOGIC);
-                    sourceBuilder.setResponseCode(Const.NONE);
                     logicEndpointBuilders.add(sourceBuilder);
                 default:","[{'comment': '*FallThrough:*  Execution may fall through from the previous case; add a `// fall through` comment before this line if it was deliberate [(details)](https://errorprone.info/bugpattern/FallThrough)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/EndpointSourceBuilder.java,"@@ -0,0 +1,113 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.analyzer.provider.trace.parser.listener;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import lombok.Getter;
+import lombok.RequiredArgsConstructor;
+import lombok.Setter;
+import org.apache.skywalking.apm.network.common.v3.KeyStringValuePair;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
+import org.apache.skywalking.oap.server.core.config.NamingControl;
+import org.apache.skywalking.oap.server.core.source.DetectPoint;
+import org.apache.skywalking.oap.server.core.source.Endpoint;
+import org.apache.skywalking.oap.server.core.source.RequestType;
+
+/**
+ * Endpoint traffic source builder. Endpoint represents an entrance to expose logic.
+ * Typically, it could be HTTP URI, gRPC service name, etc. for RPC, or a local method is required to be analyzed.
+ *
+ * @since 9.0.0
+ */
+@RequiredArgsConstructor
+class EndpointSourceBuilder {
+    protected final NamingControl namingControl;
+
+    @Getter
+    @Setter
+    protected long timeBucket;
+    @Getter
+    @Setter
+    protected String destServiceName;
+    @Getter
+    @Setter
+    protected Layer destLayer;
+    @Getter
+    @Setter","[{'comment': '*SameNameButDifferent:*  The name `@Setter` refers to [java.lang.SuppressWarnings, lombok.Generated, java.lang.String, org.apache.skywalking.oap.server.core.analysis.Layer, org.apache.skywalking.oap.server.core.source.RequestType, org.apache.skywalking.oap.server.core.source.DetectPoint] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/RPCAnalysisListener.java,"@@ -51,19 +48,20 @@
 import org.apache.skywalking.oap.server.core.source.ServiceInstanceRelation;
 import org.apache.skywalking.oap.server.core.source.SourceReceiver;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.StringUtil;
+
+import static org.apache.skywalking.oap.server.analyzer.provider.trace.parser.SpanTags.LOGIC_ENDPOINT;
 
 /**
- * MultiScopesSpanListener includes the most segment to source(s) logic.
- *
- * This listener traverses the whole segment.
+ * RPCAnalysisListener detects all RPC relative statistics.
  */
 @Slf4j
 @RequiredArgsConstructor","[{'comment': '*SameNameButDifferent:*  The name `@RequiredArgsConstructor` refers to [java.lang.SuppressWarnings, lombok.Generated, org.apache.skywalking.oap.server.core.source.SourceReceiver, org.apache.skywalking.oap.server.analyzer.provider.AnalyzerModuleConfig, org.apache.skywalking.oap.server.core.cache.NetworkAddressAliasCache, org.apache.skywalking.oap.server.core.config.NamingControl] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8747,oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/parser/listener/RPCAnalysisListener.java,"@@ -51,19 +48,20 @@
 import org.apache.skywalking.oap.server.core.source.ServiceInstanceRelation;
 import org.apache.skywalking.oap.server.core.source.SourceReceiver;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.StringUtil;
+
+import static org.apache.skywalking.oap.server.analyzer.provider.trace.parser.SpanTags.LOGIC_ENDPOINT;
 
 /**
- * MultiScopesSpanListener includes the most segment to source(s) logic.
- *
- * This listener traverses the whole segment.
+ * RPCAnalysisListener detects all RPC relative statistics.
  */
 @Slf4j","[{'comment': '*SameNameButDifferent:*  The name `@Slf4j` refers to [java.lang.SuppressWarnings, lombok.Generated, org.slf4j.Logger, org.slf4j.LoggerFactory] within this file. It may be confusing to have the same name refer to multiple types. Consider qualifying them for clarity. [(details)](https://errorprone.info/bugpattern/SameNameButDifferent)\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)', 'commenter': 'sonatype-lift[bot]'}]"
8986,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/profiling/trace/ProfileThreadSnapshotRecord.java,"@@ -81,11 +80,7 @@ public ProfileThreadSnapshotRecord storage2Entity(final Convert2Entity converter
             snapshot.setDumpTime(((Number) converter.get(DUMP_TIME)).longValue());
             snapshot.setSequence(((Number) converter.get(SEQUENCE)).intValue());
             snapshot.setTimeBucket(((Number) converter.get(TIME_BUCKET)).intValue());
-            if (StringUtil.isEmpty((String) converter.get(STACK_BINARY))) {
-                snapshot.setStackBinary(new byte[] {});
-            } else {
-                snapshot.setStackBinary(Base64.getDecoder().decode((String) converter.get(STACK_BINARY)));
-            }
+            snapshot.setStackBinary(converter.getBytes(STACK_BINARY));","[{'comment': 'For `ProfileThreadSnapshotRecord`,  I suppose the `entity2Storage` also needs some patch,\r\n\r\n```diff\r\n-converter.accept(STACK_BINARY, new String(Base64.getEncoder().encode(storageData.getStackBinary())));\r\n+converter.accept(STACK_BINARY, storageData.getStackBinary());\r\n```', 'commenter': 'lujiajing1126'}, {'comment': 'Fixed.', 'commenter': 'wu-sheng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -40,6 +44,7 @@
  * @since 8.0.0 This query is replaced by {@link MetricsQuery}
  */
 @Deprecated
+@Slf4j
 public class MetricQuery implements GraphQLQueryResolver {","[{'comment': 'Please notice, this class has been `Deprecated`, which means it is a shell only. The real codes are in `org.apache.skywalking.oap.query.graphql.resolver.MetricsQuery`', 'commenter': 'wu-sheng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +64,28 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture> futureList = new LinkedList<>();
+            metrics.getIds().stream().forEach(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
-                values.addKVInt(kv);
-            }
+                CompletableFuture future = CompletableFuture.supplyAsync(() -> {","[{'comment': 'The question is, what exactly the case you are facing to make you feel you need query to be async? One way or another, UI has to wait for a database response.', 'commenter': 'wu-sheng'}, {'comment': ""This means that the id is queried concurrently, and you don't have to wait for each result before proceeding the next time."", 'commenter': 'chenhaipeng'}, {'comment': 'I think the best way is to modify MetricsQueryEsDAO to support batch query of ids', 'commenter': 'chenhaipeng'}, {'comment': 'Yes, but v1 metric APIs have been `Deprecated`, we recommend using v2, and making this kind of bulk questions as different GraphQL level queries.', 'commenter': 'wu-sheng'}, {'comment': 'When there are many applications, the topology map display is too slow. The reason is that in the previous position, each id triggers a query, and the next query needs to wait for the query result of the previous id.', 'commenter': 'chenhaipeng'}, {'comment': ""Which version's UI are you talking about?"", 'commenter': 'wu-sheng'}, {'comment': 'v8.9.1', 'commenter': 'chenhaipeng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +64,28 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture> futureList = new LinkedList<>();","[{'comment': ""*[JdkObsolete](https://errorprone.info/bugpattern/JdkObsolete):*  It is very rare for LinkedList to out-perform ArrayList or ArrayDeque. Avoid it unless you're willing to invest a lot of time into benchmarking. Caveat: LinkedList supports null elements, but ArrayDeque does not.\n\n\n```suggestion\n            List<CompletableFuture> futureList = new ArrayList<>();\n```\n\n\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=205559277&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=205559277&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=205559277&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=205559277&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=205559277&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +64,28 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture> futureList = new LinkedList<>();
+            metrics.getIds().stream().forEach(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
-                values.addKVInt(kv);
-            }
+                CompletableFuture future = CompletableFuture.supplyAsync(() -> {
+                    try {
+                        return query.readMetricsValue(condition, duration);
+                    } catch (IOException e) {
+                        log.error(""query.readMetricsValue error"", e);
+                    }
+                    return 0L;
+                }).thenAccept(value -> {
+                    KVInt kv = new KVInt();
+                    kv.setId(id);
+                    kv.setValue(value);
+                    values.addKVInt(kv);
+                });
+                futureList.add(future);
+            });
+            futureList.stream().map(CompletableFuture::join).collect(Collectors.toList());","[{'comment': ""*[ReturnValueIgnored](https://errorprone.info/bugpattern/ReturnValueIgnored):*  Return value of 'collect' must be used\n\n(at-me [in a reply](https://help.sonatype.com/lift/talking-to-lift) with `help` or `ignore`)\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=205559301&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=205559301&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=205559301&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=205559301&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=205559301&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9003,docs/en/changes/changes.md,"@@ -43,6 +43,7 @@
 * Add ""execution_hint"": ""map"", ""collect_mode"": ""breadth_first"" for aggregation and topology query to improve 5-10x performance.
 * Clean up scroll contexts after used.
 * Support autocomplete tags in logs query.
+* Enhance MetricQuery querying getValues to asynchronous concurrency query","[{'comment': '```suggestion\r\n* Enhance Deprecated MetricQuery(v1) getValues querying to asynchronous concurrency query\r\n```', 'commenter': 'wu-sheng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +64,28 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture> futureList = new ArrayList<>();
+            metrics.getIds().stream().forEach(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
-                values.addKVInt(kv);
-            }
+                CompletableFuture future = CompletableFuture.supplyAsync(() -> {
+                    try {
+                        return query.readMetricsValue(condition, duration);
+                    } catch (IOException e) {
+                        log.error(""query.readMetricsValue error"", e);
+                    }
+                    return 0L;
+                }).thenAccept(value -> {
+                    KVInt kv = new KVInt();
+                    kv.setId(id);
+                    kv.setValue(value);
+                    values.addKVInt(kv);","[{'comment': ""It's `ArrayList.add` behind `values.addKVInt(kv);` and `ArrayList` is not thread-safe, you need synchronization here."", 'commenter': 'kezhenxu94'}, {'comment': 'I think adding `Collections.synchronizedList` wrapper should be enough.', 'commenter': 'wu-sheng'}, {'comment': 'I change another way to implement it, avoid use  lock', 'commenter': 'chenhaipeng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +64,28 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture> futureList = new ArrayList<>();","[{'comment': ""You don't need this variable `futureList`, just use `metrics.getIds().stream().map(...).forEach(...)`"", 'commenter': 'kezhenxu94'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +64,28 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture> futureList = new ArrayList<>();
+            metrics.getIds().stream().forEach(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
-                values.addKVInt(kv);
-            }
+                CompletableFuture future = CompletableFuture.supplyAsync(() -> {
+                    try {
+                        return query.readMetricsValue(condition, duration);
+                    } catch (IOException e) {
+                        log.error(""query.readMetricsValue error"", e);","[{'comment': 'This somewhat changes the logic, previously it throws and the UI will display the error message, while now you just return all `0` to frontend and there is no clue why all `0`s unless users check OAP logs.', 'commenter': 'kezhenxu94'}, {'comment': '> \r\n\r\nI change another way to implement it', 'commenter': 'chenhaipeng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +65,26 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture<Pair<String, Long>>> futureList = metrics.getIds().stream().map(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
+                CompletableFuture<Pair<String, Long>> future = CompletableFuture.supplyAsync(() -> {","[{'comment': 'KVInt is the pair, I think?', 'commenter': 'wu-sheng'}, {'comment': 'ok, I remove pair\r\n', 'commenter': 'chenhaipeng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +63,24 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture<KVInt>> futureList = metrics.getIds().stream().map(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
-                values.addKVInt(kv);
-            }
+                CompletableFuture<KVInt> future = CompletableFuture.supplyAsync(() -> {
+                    try {
+                        KVInt kv = new KVInt();
+                        kv.setId(id);
+                        kv.setValue(query.readMetricsValue(condition, duration));
+                        return kv;
+                    } catch (IOException e) {
+                        throw new RuntimeException(e);","[{'comment': 'Once you do this, I think you need to check `CompletableFuture#isCompletedExceptionally` and process in this case?', 'commenter': 'wu-sheng'}, {'comment': '> Once you do this, I think you need to check `CompletableFuture#isCompletedExceptionally` and process in this case?\r\n\r\n\r\nThe exception will propagate to caller in `.join`', 'commenter': 'kezhenxu94'}, {'comment': 'OK, then.', 'commenter': 'wu-sheng'}]"
9003,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetricQuery.java,"@@ -59,17 +63,24 @@ public IntValues getValues(final BatchMetricConditions metrics, final Duration d
             kv.setValue(query.readMetricsValue(condition, duration));
             values.addKVInt(kv);
         } else {
-            for (final String id : metrics.getIds()) {
-                KVInt kv = new KVInt();
-                kv.setId(id);
+            List<CompletableFuture<KVInt>> futureList = metrics.getIds().stream().map(id -> {
 
                 MetricsCondition condition = new MetricsCondition();
                 condition.setName(metrics.getName());
                 condition.setEntity(new MockEntity(id));
-
-                kv.setValue(query.readMetricsValue(condition, duration));
-                values.addKVInt(kv);
-            }
+                CompletableFuture<KVInt> future = CompletableFuture.supplyAsync(() -> {
+                    try {
+                        KVInt kv = new KVInt();
+                        kv.setId(id);
+                        kv.setValue(query.readMetricsValue(condition, duration));
+                        return kv;
+                    } catch (IOException e) {
+                        throw new RuntimeException(e);
+                    }
+                });
+                return future;
+            }).collect(Collectors.toList());
+            futureList.stream().map(CompletableFuture::join).forEach(v -> values.addKVInt(v));","[{'comment': ""Actually `CompletableFuture.supplyAsync` can be replaced with `parallelStream` with just a very trivial difference that it doesn't matter in the case here, but is simpler, what do you think?\r\n\r\n```java\r\n            List<KVInt> ints = metrics.getIds()\r\n                   .parallelStream()\r\n                   .map(id -> {\r\n                        MetricsCondition condition = new MetricsCondition();\r\n                        condition.setName(metrics.getName());\r\n                        condition.setEntity(new MockEntity(id));\r\n                        try {\r\n                            KVInt kv = new KVInt();\r\n                            kv.setId(id);\r\n                            kv.setValue(query.readMetricsValue(condition, duration));\r\n                            return kv;\r\n                        } catch (IOException e) {\r\n                            throw new RuntimeException(e);\r\n                        }\r\n                   })\r\n                   .collect(toList());\r\n           ints.forEach(v -> values.addKVInt(v));\r\n\r\n```\r\n\r\n"", 'commenter': 'kezhenxu94'}, {'comment': '@chenhaipeng What do you think about this?', 'commenter': 'wu-sheng'}, {'comment': 'yes! I think so too', 'commenter': 'chenhaipeng'}, {'comment': ""OK, I would wait for your update.\r\n\r\nThanks for bringing this to the community's attention. We missed this when building `v1->v2` bridge."", 'commenter': 'wu-sheng'}]"
9033,docs/en/setup/backend/dynamic-config.md,"@@ -32,7 +32,7 @@ Supported configurations are as follows:
 | Config Key | Value Description | Value Format Example |
 |:----:|:----:|:----:|
 |agent-analyzer.default.slowDBAccessThreshold| Thresholds of slow Database statement. Overrides `receiver-trace/default/slowDBAccessThreshold` of `application.yml`. | default:200,mongodb:50|
-|agent-analyzer.default.uninstrumentedGateways| The uninstrumented gateways. Overrides `gateways.yml`. | Same as [`gateways.yml`](uninstrumented-gateways.md#configuration-format). |
+|receiver-trace.default.uninstrumentedGateways| The uninstrumented gateways. Overrides `gateways.yml`. | Same as [`gateways.yml`](uninstrumented-gateways.md#configuration-format). |","[{'comment': 'I checked the latest codebase, it seems the configuration is correct.\r\n\r\nhttps://github.com/apache/skywalking/blob/62a67bacb612a19f78b8101de7017a7675673c72/oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/provider/trace/UninstrumentedGatewaysConfig.java#L53\r\n\r\nhttps://github.com/apache/skywalking/blob/62a67bacb612a19f78b8101de7017a7675673c72/oap-server/analyzer/agent-analyzer/src/main/java/org/apache/skywalking/oap/server/analyzer/module/AnalyzerModule.java#L26\r\n\r\nAnything I missed here?', 'commenter': 'wu-sheng'}, {'comment': '`skywalking-dynamic-configmap.example.yaml` file includes the incorrect example. You should fix it there, but it is commented, I am not sure whether it has the real meaning.', 'commenter': 'wu-sheng'}, {'comment': ""What I find is the config key is `receiver-trace.default.uninstrumentedGateways`  in https://github.com/apache/skywalking/blob/62a67bacb612a19f78b8101de7017a7675673c72/oap-server/server-configuration/configuration-k8s-configmap/src/test/resources/skywalking-dynamic-configmap.example.yaml#L104-L109\r\n\r\nAnd there are no `uninstrumentedGateways` filed in `application.yml`\r\nhttps://github.com/apache/skywalking/blob/62a67bacb612a19f78b8101de7017a7675673c72/oap-server/server-starter/src/main/resources/application.yml#L264-L275\r\n\r\nBut the config key is `agent-analyzer.default.uninstrumentedGateways` in the doc, so I don't know which key should be correct. "", 'commenter': 'dashanji'}, {'comment': 'Check the links I posted, that is how the codes control this config. Nothing relates to the application.yml, which is booting intializtion only.', 'commenter': 'wu-sheng'}, {'comment': 'Make sense to me, thanks. BTW, should we change the configmap in there and other repo like `skywalking-kubenertes` to keep doc and code consistent? ', 'commenter': 'dashanji'}, {'comment': ""If this key exists in other official helm or operator, it should be kept consistent with the codes.\r\n\r\nThe UT of configmap config center should be changed to avoid other's confusion as you did."", 'commenter': 'wu-sheng'}, {'comment': 'Okay, I will change it next.', 'commenter': 'dashanji'}]"
9128,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/cache/NetworkAddressAliasEsDAO.java,"@@ -62,9 +62,9 @@ public List<NetworkAddressAlias> loadLastUpdate(long timeBucketInMinute) {
 
             SearchResponse results =
                 getClient().search(NetworkAddressAlias.INDEX_NAME, search, params);
-            while (true) {
-                final String scrollId = results.getScrollId();
-                try {
+            final String scrollId = results.getScrollId();
+            try {
+                while (true) {","[{'comment': ""This is wrong, `scrollId` is never updated and you'll be always scrolling to the same context (at line 82)"", 'commenter': 'kezhenxu94'}, {'comment': ""They both throw exceptions.\r\n\r\n`getClient().scroll(SCROLL_CONTEXT_RETENTION, scrollId)` throws scroll not found. \r\n![image](https://user-images.githubusercontent.com/3417650/170228950-ec842e00-f99c-480e-92e9-f3f96fd70608.png)\r\n\r\n`getClient().deleteScrollContextQuietly(scrollId);` throws `RuntimeException` because It delete twice and ElasticSearch response status code is not `OK`.\r\n![image](https://user-images.githubusercontent.com/3417650/170232313-016abcb6-8e7a-445c-bf67-0e06f7d0b905.png)\r\n\r\n> This is wrong, `scrollId` is never updated.\r\n\r\nYes, the `scrollId` is never updated. So we can't delete the `scrollId` after executing the scroll once, it cannot scroll it again based on the same `scrollId` for the second time. Because we delete the `scrollId` early.\r\n\r\nBTW: I have added some logs in the `NetworkAddressAliasEsDAO.java`, so the code line in the screenshot is not the same as the `master` branch code. "", 'commenter': 'mrproliu'}]"
9128,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/StorageModuleElasticsearchConfig.java,"@@ -117,6 +117,12 @@ public class StorageModuleElasticsearchConfig extends ModuleConfig {
     private int scrollingBatchSize = 5000;
     private int segmentQueryMaxSize = 200;
     private int profileTaskQueryMaxSize = 200;
+    /**
+     * The batch size that used to scroll on the large eBPF profiling data result.
+     * The profiling data contains full symbol data, that could make ElasticSearch response large content,
+     * so could not same with {@link #scrollingBatchSize}.
+     */","[{'comment': '```suggestion\r\n    /**\r\n     * The batch size that is used to scroll on the large eBPF profiling data result.\r\n     * The profiling data contains full-stack symbol data, which could make ElasticSearch response large content.\r\n     *  {@link #scrollingBatchSize} would not be used in profiling data query.\r\n     */\r\n```', 'commenter': 'wu-sheng'}]"
9261,dist-material/release-docs/licenses/ui-licenses/LICENSE-vis-timeline,"@@ -0,0 +1,177 @@
+ Apache License","[{'comment': ""We don't need a copy of Apache 2.0 license."", 'commenter': 'wu-sheng'}]"
9533,docs/en/changes/changes.md,"@@ -102,7 +102,7 @@
 * Fix picking calendar with a wrong time range and setting a unique value for dashboard grid key.
 * Add PostgreSQL to Database sub-menu.
 * Implement the network profiling widget.
-* Add Nats icon for Java plugin.","[{'comment': 'This should be kept, as UI is released in main repo.', 'commenter': 'wu-sheng'}]"
9533,docs/en/changes/changes.md,"@@ -102,7 +102,7 @@
 * Fix picking calendar with a wrong time range and setting a unique value for dashboard grid key.
 * Add PostgreSQL to Database sub-menu.
 * Implement the network profiling widget.
-* Add Nats icon for Java plugin.
+* Add component ID(132) for NAST java client plugin","[{'comment': 'Move to backend part of changelog.', 'commenter': 'wu-sheng'}, {'comment': '`Add component ID(131) for Java Micronaut plugin` is also in UI part . \r\nThe previous format of  micronaut plugin was also wrong , I will fix it  together  .\r\nFinally , add mictonaut、nats icon should be in UI part , add component id for micronaut、nats in backend part\r\n', 'commenter': 'pg-yang'}, {'comment': 'Yes, icon is UI part. ID is backend part.', 'commenter': 'wu-sheng'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/LogAnalyzerModuleConfig.java,"@@ -51,7 +51,7 @@ public class LogAnalyzerModuleConfig extends ModuleConfig {
     private List<Rule> meterConfigs;
 
     public List<String> lalFiles() {
-        return Splitter.on("","").omitEmptyStrings().splitToList(Strings.nullToEmpty(getLalFiles()));
+        return Splitter.on("","").omitEmptyStrings().trimResults().splitToList(Strings.nullToEmpty(getLalFiles()));","[{'comment': 'I change this method because I found that it can not split strings such as ""a, b"" before. It will split as ""a"" and ""<space>b"".', 'commenter': 'yswdqz'}, {'comment': 'Pleasw verify whether layer is legal and not empty.', 'commenter': 'wu-sheng'}]"
9593,oap-server/server-starter/src/main/resources/lal/default.yaml,"@@ -16,6 +16,7 @@
 # The default LAL script to save all logs, behaving like the versions before 8.5.0.
 rules:
   - name: default
+    layer: UNDEFINED","[{'comment': 'This should be general service layer', 'commenter': 'wu-sheng'}, {'comment': 'I feel we may not need a default LAL file. You could change this LAL for general service only.', 'commenter': 'wu-sheng'}]"
9593,docs/en/concepts-and-designs/lal.md,"@@ -7,6 +7,9 @@ segment ID and span ID) and metrics (by generating metrics from the logs and sen
 The LAL config files are in YAML format, and are located under directory `lal`. You can
 set `log-analyzer/default/lalFiles` in the `application.yml` file or set environment variable `SW_LOG_LAL_FILES` to
 activate specific LAL config files.
+## Layer
+Every LAL file is a list of LAL rule, and every LAL rule has a layer property.If a log sent to OAP has the same layer value, this rule will be enable.
+NOTICE: Every layer should only has one rule.","[{'comment': '```suggestion\n\n## Layer\nLayer should be declared in the LAL script to represent the analysis scope of the logs.\n```\n', 'commenter': 'wu-sheng'}, {'comment': 'Notice the way of describing things in docs. It is not about the code logic, instead it should decribe how end users would use it.', 'commenter': 'wu-sheng'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,55 +19,65 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.StringUtil;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final Map<String, DSL> dsls;
+    private LogData.Builder logData;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        DSL dsl = dsls.get(logData.getLayer());
+        try {
+            if (dsl == null) {
+                if (StringUtil.isEmpty(logData.getLayer())) {
+                    log.debug(""The layer is empty, will use default rules"");
+                }
+                dsl = dsls.get(Layer.UNDEFINED.name());","[{'comment': ""I think if we can't find suitable layer, we could simply skip the log process."", 'commenter': 'wu-sheng'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,55 +19,65 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.StringUtil;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final Map<String, DSL> dsls;
+    private LogData.Builder logData;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        DSL dsl = dsls.get(logData.getLayer());
+        try {
+            if (dsl == null) {
+                if (StringUtil.isEmpty(logData.getLayer())) {
+                    log.debug(""The layer is empty, will use default rules"");
+                }
+                dsl = dsls.get(Layer.UNDEFINED.name());
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
+        dsls.forEach((layer, dsl) -> dsl.bind(new Binding().log(logData.build())
                                                   .extraLog(extraLog)));
+        this.logData = logData;
         return this;
     }
 
     public static class Factory implements LogAnalysisListenerFactory {
-        private final List<DSL> dsls;
+        private final Map<String, DSL> dsls;","[{'comment': ""I checked how this Factory is used, I feel you don't need this Map in the LogFilterListener. You could use `layer` as a parameter in `#create` method to build the suitable listener directly."", 'commenter': 'wu-sheng'}, {'comment': ""I have thought about it. But I think if I add a param to Factory#create method will affect other two listeners(RecordAnalysisListener and TrafficAnalysisListener).\r\nIs that OK? They seems don't need layer param."", 'commenter': 'yswdqz'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,76 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final DSL dsl;","[{'comment': '`dsl` should be non null, otherwise you should not create this listener.\r\n\r\n```suggestion\r\n    @lombok.NonNull\r\n    private final DSL dsl;\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,76 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;","[{'comment': 'Prefer `java.util.HashMap`', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,76 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
-                                                  .extraLog(extraLog)));
+        if (dsl == null) {
+            return null;
+        }
+        dsl.bind(new Binding().log(logData.build()).extraLog(extraLog));
         return this;
     }
 
     public static class Factory implements LogAnalysisListenerFactory {
-        private final List<DSL> dsls;
+        private final Map<Layer, DSL> dsls;
 
         public Factory(final ModuleManager moduleManager, final LogAnalyzerModuleConfig config) throws Exception {
-            dsls = new ArrayList<>();
+            dsls = new HashedMap<>();
 
             final List<LALConfig> configList = LALConfigs.load(config.getLalPath(), config.lalFiles())
                                                          .stream()
                                                          .flatMap(it -> it.getRules().stream())
                                                          .collect(Collectors.toList());
             for (final LALConfig c : configList) {
-                dsls.add(DSL.of(moduleManager, config, c.getDsl()));
+                try {
+                    Layer layer = Layer.nameOf(c.getLayer());
+                    dsls.put(layer, DSL.of(moduleManager, config, c.getDsl()));
+                } catch (UnexpectedException e) {
+                    log.warn(""layer not found, will ignore this rule:"" + c.getName());","[{'comment': '```suggestion\r\n                    log.warn(""layer {} not found, will ignore this rule."", c.getName());\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,76 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
-                                                  .extraLog(extraLog)));
+        if (dsl == null) {
+            return null;
+        }
+        dsl.bind(new Binding().log(logData.build()).extraLog(extraLog));
         return this;
     }
 
     public static class Factory implements LogAnalysisListenerFactory {
-        private final List<DSL> dsls;
+        private final Map<Layer, DSL> dsls;
 
         public Factory(final ModuleManager moduleManager, final LogAnalyzerModuleConfig config) throws Exception {
-            dsls = new ArrayList<>();
+            dsls = new HashedMap<>();
 
             final List<LALConfig> configList = LALConfigs.load(config.getLalPath(), config.lalFiles())
                                                          .stream()
                                                          .flatMap(it -> it.getRules().stream())
                                                          .collect(Collectors.toList());
             for (final LALConfig c : configList) {
-                dsls.add(DSL.of(moduleManager, config, c.getDsl()));
+                try {
+                    Layer layer = Layer.nameOf(c.getLayer());
+                    dsls.put(layer, DSL.of(moduleManager, config, c.getDsl()));
+                } catch (UnexpectedException e) {
+                    log.warn(""layer not found, will ignore this rule:"" + c.getName());
+                }
             }
         }
 
         @Override
-        public LogAnalysisListener create() {
-            return new LogFilterListener(dsls);
+        public LogAnalysisListener create(Layer layer) {
+            if (layer == null) {
+                return null;
+            }
+            return new LogFilterListener(dsls.get(layer));","[{'comment': '```suggestion\r\n            final DSL dsl = dsls.get(layer);\r\n            if (dsl == null) {\r\n                return null;\r\n            }\r\n            return new LogFilterListener(dsl);\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,76 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
-                                                  .extraLog(extraLog)));
+        if (dsl == null) {
+            return null;
+        }
+        dsl.bind(new Binding().log(logData.build()).extraLog(extraLog));
         return this;
     }
 
     public static class Factory implements LogAnalysisListenerFactory {
-        private final List<DSL> dsls;
+        private final Map<Layer, DSL> dsls;
 
         public Factory(final ModuleManager moduleManager, final LogAnalyzerModuleConfig config) throws Exception {
-            dsls = new ArrayList<>();
+            dsls = new HashedMap<>();
 
             final List<LALConfig> configList = LALConfigs.load(config.getLalPath(), config.lalFiles())
                                                          .stream()
                                                          .flatMap(it -> it.getRules().stream())
                                                          .collect(Collectors.toList());
             for (final LALConfig c : configList) {
-                dsls.add(DSL.of(moduleManager, config, c.getDsl()));
+                try {
+                    Layer layer = Layer.nameOf(c.getLayer());
+                    dsls.put(layer, DSL.of(moduleManager, config, c.getDsl()));
+                } catch (UnexpectedException e) {
+                    log.warn(""layer not found, will ignore this rule:"" + c.getName());
+                }
             }
         }
 
         @Override
-        public LogAnalysisListener create() {
-            return new LogFilterListener(dsls);
+        public LogAnalysisListener create(Layer layer) {
+            if (layer == null) {
+                return null;","[{'comment': 'Check the places where this method `create` is invoked, if you return null here, `NullPointerException` might be thrown, you have to check the nullability in the callers.', 'commenter': 'kezhenxu94'}, {'comment': 'I have checked it. No other invoker use the return value.', 'commenter': 'yswdqz'}, {'comment': ""> I have checked it. No other invoker use the return value.\r\n\r\nHi, `listeners` is an `ArrayList`, it doesn't allow null, so if `create` returns `null`, `NullPointerException` will be thrown in the following line\r\n\r\nhttps://github.com/apache/skywalking/blob/81878331e59c435e011eb8c73fe5617201708968/oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/LogAnalyzer.java#L79-L80"", 'commenter': 'kezhenxu94'}, {'comment': '@kezhenxu94 I have tested a null value situation. It will not throw a Exception.\r\nAn ArrayList can store more than one null.\r\n', 'commenter': 'yswdqz'}, {'comment': ""> @kezhenxu94 I have tested a null value situation. It will not throw a Exception.\r\n> An ArrayList can store more than one null.\r\n\r\nHey, hosting a `null` value in the list is not a good idea. What's more, did you test the case where the logs will be persisted? The following lines when iterating the array list will throw exception. `listeners.forEach(LogAnalysisListener::build);` Element in `listeners` might be null and calling `null.build()` should throw.\r\n\r\nhttps://github.com/apache/skywalking/blob/166a62612d20e403241aec24b95ceef1c64d898e/oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/LogAnalyzer.java#L73-L81"", 'commenter': 'kezhenxu94'}, {'comment': ""I understand , it's my fault. I will change it soon."", 'commenter': 'yswdqz'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,76 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.collections4.map.HashedMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
-                                                  .extraLog(extraLog)));
+        if (dsl == null) {
+            return null;
+        }
+        dsl.bind(new Binding().log(logData.build()).extraLog(extraLog));
         return this;
     }
 
     public static class Factory implements LogAnalysisListenerFactory {
-        private final List<DSL> dsls;
+        private final Map<Layer, DSL> dsls;
 
         public Factory(final ModuleManager moduleManager, final LogAnalyzerModuleConfig config) throws Exception {
-            dsls = new ArrayList<>();
+            dsls = new HashedMap<>();
 
             final List<LALConfig> configList = LALConfigs.load(config.getLalPath(), config.lalFiles())
                                                          .stream()
                                                          .flatMap(it -> it.getRules().stream())
                                                          .collect(Collectors.toList());
             for (final LALConfig c : configList) {
-                dsls.add(DSL.of(moduleManager, config, c.getDsl()));
+                try {
+                    Layer layer = Layer.nameOf(c.getLayer());
+                    dsls.put(layer, DSL.of(moduleManager, config, c.getDsl()));","[{'comment': 'Now there is a limitation that only one LAL script can be configured for a layer, you might need to check here and throw exception if multiple DSLs are configured for a same layer', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,86 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+
+import java.util.HashMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    @lombok.NonNull
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
-                                                  .extraLog(extraLog)));
+        if (dsl == null) {
+            return null;
+        }
+        dsl.bind(new Binding().log(logData.build()).extraLog(extraLog));
         return this;
     }
 
     public static class Factory implements LogAnalysisListenerFactory {
-        private final List<DSL> dsls;
+        private final Map<Layer, DSL> dsls;
 
         public Factory(final ModuleManager moduleManager, final LogAnalyzerModuleConfig config) throws Exception {
-            dsls = new ArrayList<>();
+            dsls = new HashMap<>();
 
             final List<LALConfig> configList = LALConfigs.load(config.getLalPath(), config.lalFiles())
                                                          .stream()
                                                          .flatMap(it -> it.getRules().stream())
                                                          .collect(Collectors.toList());
             for (final LALConfig c : configList) {
-                dsls.add(DSL.of(moduleManager, config, c.getDsl()));
+                Layer layer = null;
+                try {
+                    layer = Layer.nameOf(c.getLayer());
+                    if (dsls.containsKey(layer)) {
+                        log.warn(""layer {} has set a rule, old one will be ignore."", c.getName());
+                    }
+                    dsls.put(layer, DSL.of(moduleManager, config, c.getDsl()));
+                } catch (UnexpectedException e) {
+                    log.warn(""layer {} not found, will ignore this rule."", c.getName());
+                }","[{'comment': '```suggestion\r\n                try {\r\n                    Layer layer = Layer.nameOf(c.getLayer());\r\n                    if (dsls.put(layer, DSL.of(moduleManager, config, c.getDsl())) != null) {\r\n                        log.warn(""layer {} has already set a rule {}, the old one will be ignored."", layer, c.getName());\r\n                    }\r\n                } catch (UnexpectedException e) {\r\n                    log.warn(""layer {} not found, will ignore this rule."", c.getName(), e);\r\n                }\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,86 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+
+import java.util.HashMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    @lombok.NonNull
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }","[{'comment': '`dsl` is already non null.\r\n\r\n```suggestion\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/listener/LogFilterListener.java,"@@ -19,61 +19,86 @@
 package org.apache.skywalking.oap.log.analyzer.provider.log.listener;
 
 import com.google.protobuf.Message;
-import java.util.ArrayList;
 import java.util.List;
+import java.util.Map;
 import java.util.stream.Collectors;
 import lombok.RequiredArgsConstructor;
 import lombok.extern.slf4j.Slf4j;
+
+import java.util.HashMap;
 import org.apache.skywalking.apm.network.logging.v3.LogData;
 import org.apache.skywalking.oap.log.analyzer.dsl.Binding;
 import org.apache.skywalking.oap.log.analyzer.dsl.DSL;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfig;
 import org.apache.skywalking.oap.log.analyzer.provider.LALConfigs;
 import org.apache.skywalking.oap.log.analyzer.provider.LogAnalyzerModuleConfig;
+import org.apache.skywalking.oap.server.core.UnexpectedException;
+import org.apache.skywalking.oap.server.core.analysis.Layer;
 import org.apache.skywalking.oap.server.library.module.ModuleManager;
 
 @Slf4j
 @RequiredArgsConstructor
 public class LogFilterListener implements LogAnalysisListener {
-    private final List<DSL> dsls;
+    @lombok.NonNull
+    private final DSL dsl;
 
     @Override
     public void build() {
-        dsls.forEach(dsl -> {
-            try {
-                dsl.evaluate();
-            } catch (final Exception e) {
-                log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        try {
+            if (dsl == null) {
+                log.warn(""No rules match, the process will skip."");
+                return;
             }
-        });
+            dsl.evaluate();
+        } catch (final Exception e) {
+            log.warn(""Failed to evaluate dsl: {}"", dsl, e);
+        }
     }
 
     @Override
     public LogAnalysisListener parse(final LogData.Builder logData,
                                      final Message extraLog) {
-        dsls.forEach(dsl -> dsl.bind(new Binding().log(logData.build())
-                                                  .extraLog(extraLog)));
+        if (dsl == null) {
+            return null;
+        }","[{'comment': '`dsl` is non null.\r\n```suggestion\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/dsl/spec/filter/FilterSpec.java,"@@ -169,7 +169,7 @@ public void sink(@DelegatesTo(SinkSpec.class) final Closure<?> cl) {
         final Optional<AtomicReference<Log>> container = BINDING.get().logContainer();
         if (container.isPresent()) {
             factories.stream()
-                     .map(LogAnalysisListenerFactory::create)
+                     .map(it -> it.create(null))","[{'comment': 'I am wondering, why we use `null` here? ', 'commenter': 'wu-sheng'}, {'comment': ""This listener needn't layer param."", 'commenter': 'yswdqz'}, {'comment': '@kezhenxu94 Should we separate `LogFilterListener.Factory` and `TrafficAnalysisListener.Factory`/`RecordAnalysisListener.Factory`?\r\n\r\n`TrafficAnalysisListener.Factory`/`RecordAnalysisListener.Factory` are more likely `LogSinkListener`.', 'commenter': 'wu-sheng'}, {'comment': ""> @kezhenxu94 Should we separate `LogFilterListener.Factory` and `TrafficAnalysisListener.Factory`/`RecordAnalysisListener.Factory`?\r\n> \r\n> `TrafficAnalysisListener.Factory`/`RecordAnalysisListener.Factory` are more likely `LogSinkListener`.\r\n\r\nHi, I'm not sure, these factories share the same interface and they are used basically in the core log analyzer, so splitting these might bring huge changes."", 'commenter': 'kezhenxu94'}, {'comment': 'The issue is what I proposed. The create  method is adding layer, but those two for sink are not relative. \n\n@yswdqz put a null layer for create method. I feel we should change it.', 'commenter': 'wu-sheng'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/LogAnalyzer.java,"@@ -64,8 +79,8 @@ private void notifyListenerToBuild() {
         listeners.forEach(LogAnalysisListener::build);
     }
 
-    private void createListeners() {
+    private void createListeners(Layer layer) {
         factoryManager.getLogAnalysisListenerFactories()
-                      .forEach(factory -> listeners.add(factory.create()));
+                      .forEach(factory -> listeners.add(factory.create(layer)));","[{'comment': 'Maybe change to \r\n\r\n```java\r\n        factoryManager.getLogAnalysisListenerFactories()\r\n                      .stream()\r\n                      .map(factory -> factory.create(layer))\r\n                      .filter(Objects::nonNull)\r\n                      .forEach(listeners::add);\r\n```', 'commenter': 'kezhenxu94'}]"
9593,oap-server/analyzer/log-analyzer/src/main/java/org/apache/skywalking/oap/log/analyzer/provider/log/LogAnalyzer.java,"@@ -46,7 +50,20 @@ public void doAnalysis(LogData.Builder builder, Message extraLog) {
             log.debug(""The log is ignored because the Service name is empty"");
             return;
         }
-        createListeners();
+        Layer layer;
+        if ("""".equals(builder.getLayer())) {
+            layer = Layer.GENERAL;
+        }
+        else {
+            try {
+                layer = Layer.nameOf(builder.getLayer());
+            } catch (UnexpectedException e) {
+                log.warn(""layer not found, will skip this process."");","[{'comment': '```suggestion\r\n                log.warn(The Layer {} is not found, abandon the log."", builder.getLayer());\r\n```', 'commenter': 'wu-sheng'}]"
9614,oap-server/server-starter/src/main/resources/ui-initialized-templates/mysql/mysql-service.json,"@@ -17,317 +17,345 @@
 
 [
    {
-      ""id"":""2981ef0e-1552-4cf0-a68c-da023b4a0fd8"",
+      ""id"":""2ca19857-dcdb-491a-9739-d7ab79beb60b"",
       ""configuration"":{
          ""children"":[
             {
                ""x"":0,
                ""y"":0,
-               ""w"":6,
-               ""h"":11,
+               ""w"":24,
+               ""h"":33,
                ""i"":""0"",
-               ""type"":""Widget"",
-               ""metricTypes"":[
-                  ""readMetricsValue""
-               ],
-               ""metrics"":[
-                  ""meter_mysql_uptime""
-               ],
-               ""graph"":{
-                  ""type"":""Card"",
-                  ""fontSize"":40,
-                  ""textAlign"":""center"",
-                  ""showUnit"":true
-               },
-               ""metricConfig"":[
+               ""type"":""Tab"",
+               ""children"":[
                   {
-                     ""calculation"":""secondToDay""
-                  }
-               ],
-               ""widget"":{
-                  ""title"":""MySQL Uptime (day)""
-               }
-            },
-            {
-               ""x"":0,
-               ""y"":11,
-               ""w"":6,
-               ""h"":14,
-               ""i"":""1"",
-               ""type"":""Widget"",
-               ""metricTypes"":[
-                  ""readMetricsValues""
-               ],
-               ""metrics"":[
-                  ""meter_mysql_qps""
-               ],
-               ""graph"":{
-                  ""type"":""Line"",
-                  ""step"":false,
-                  ""smooth"":false,
-                  ""showSymbol"":false,
-                  ""showXAxis"":true,
-                  ""showYAxis"":true
-               },
-               ""widget"":{
-                  ""title"":""Current QPS""
-               },
-               ""value"":""1"",
-               ""label"":""1""
-            },
-            {
-               ""x"":12,
-               ""y"":0,
-               ""w"":6,
-               ""h"":11,
-               ""i"":""2"",
-               ""type"":""Widget"",
-               ""metricTypes"":[
-                  ""readMetricsValue""
-               ],
-               ""metrics"":[
-                  ""meter_mysql_innodb_buffer_pool_size""
-               ],
-               ""graph"":{
-                  ""type"":""Card"",
-                  ""fontSize"":40,
-                  ""textAlign"":""center"",
-                  ""showUnit"":true
-               },
-               ""metricConfig"":[
+                     ""name"":""Inspections"",
+                     ""children"":[
+                        {
+                           ""x"":0,
+                           ""y"":0,
+                           ""w"":6,
+                           ""h"":9,
+                           ""i"":""0"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValue""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_uptime""
+                           ],
+                           ""graph"":{
+                              ""type"":""Card"",
+                              ""fontSize"":40,
+                              ""textAlign"":""center"",
+                              ""showUnit"":true
+                           },
+                           ""metricConfig"":[
+                              {
+                                 ""calculation"":""secondToDay""
+                              }
+                           ],
+                           ""widget"":{
+                              ""title"":""MySQL Uptime (day)""
+                           }
+                        },
+                        {
+                           ""x"":0,
+                           ""y"":9,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""1"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_qps""
+                           ],
+                           ""graph"":{
+                              ""type"":""Line"",
+                              ""step"":false,
+                              ""smooth"":false,
+                              ""showSymbol"":false,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Current QPS""
+                           }
+                        },
+                        {
+                           ""x"":12,
+                           ""y"":0,
+                           ""w"":6,
+                           ""h"":9,
+                           ""i"":""2"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValue""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_innodb_buffer_pool_size""
+                           ],
+                           ""graph"":{
+                              ""type"":""Card"",
+                              ""fontSize"":40,
+                              ""textAlign"":""center"",
+                              ""showUnit"":true
+                           },
+                           ""metricConfig"":[
+                              {
+                                 ""calculation"":""byteToMB""
+                              }
+                           ],
+                           ""widget"":{
+                              ""title"":""Innodb Buffer Pool Size (MB)""
+                           }
+                        },
+                        {
+                           ""x"":6,
+                           ""y"":0,
+                           ""w"":6,
+                           ""h"":9,
+                           ""i"":""3"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValue""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_max_connections""
+                           ],
+                           ""graph"":{
+                              ""type"":""Card"",
+                              ""fontSize"":40,
+                              ""textAlign"":""center"",
+                              ""showUnit"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Max Connections""
+                           }
+                        },
+                        {
+                           ""x"":18,
+                           ""y"":0,
+                           ""w"":6,
+                           ""h"":9,
+                           ""i"":""4"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValue""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_thread_cache_size""
+                           ],
+                           ""graph"":{
+                              ""type"":""Card"",
+                              ""fontSize"":40,
+                              ""textAlign"":""center"",
+                              ""showUnit"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Thread Cache Size""
+                           }
+                        },
+                        {
+                           ""x"":6,
+                           ""y"":9,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""5"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_tps""
+                           ],
+                           ""graph"":{
+                              ""type"":""Line"",
+                              ""step"":false,
+                              ""smooth"":false,
+                              ""showSymbol"":false,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Current TPS""
+                           }
+                        },
+                        {
+                           ""x"":12,
+                           ""y"":9,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""6"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues"",
+                              ""readMetricsValues"",
+                              ""readMetricsValues"",
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_commands_insert_rate"",
+                              ""meter_mysql_commands_select_rate"",
+                              ""meter_mysql_commands_delete_rate"",
+                              ""meter_mysql_commands_update_rate""
+                           ],
+                           ""graph"":{
+                              ""type"":""Area"",
+                              ""opacity"":0.4,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Commands Trend (rows per second)""
+                           }
+                        },
+                        {
+                           ""x"":6,
+                           ""y"":19,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""7"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues"",
+                              ""readMetricsValues"",
+                              ""readMetricsValues"",
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_threads_cached"",
+                              ""meter_mysql_threads_running"",
+                              ""meter_mysql_threads_created"",
+                              ""meter_mysql_threads_connected""
+                           ],
+                           ""graph"":{
+                              ""type"":""Area"",
+                              ""opacity"":0.4,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Threads""
+                           }
+                        },
+                        {
+                           ""x"":0,
+                           ""y"":19,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""8"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues"",
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_connects_available"",
+                              ""meter_mysql_connects_aborted""
+                           ],
+                           ""graph"":{
+                              ""type"":""Line"",
+                              ""step"":false,
+                              ""smooth"":false,
+                              ""showSymbol"":false,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Connects""
+                           }
+                        },
+                        {
+                           ""x"":18,
+                           ""y"":9,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""10"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_slow_queries_rate""
+                           ],
+                           ""graph"":{
+                              ""type"":""Line"",
+                              ""step"":false,
+                              ""smooth"":false,
+                              ""showSymbol"":false,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Slow Queries Trend (queries per second)""
+                           }
+                        },
+                        {
+                           ""x"":12,
+                           ""y"":19,
+                           ""w"":6,
+                           ""h"":10,
+                           ""i"":""11"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readMetricsValues"",
+                              ""readMetricsValues""
+                           ],
+                           ""metrics"":[
+                              ""meter_mysql_connection_errors_internal"",
+                              ""meter_mysql_connection_errors_max_connections""
+                           ],
+                           ""graph"":{
+                              ""type"":""Line"",
+                              ""step"":false,
+                              ""smooth"":false,
+                              ""showSymbol"":false,
+                              ""showXAxis"":true,
+                              ""showYAxis"":true
+                           },
+                           ""widget"":{
+                              ""title"":""Connection Errors""
+                           }
+                        }
+                     ]
+                  },
                   {
-                     ""calculation"":""byteToMB""
+                     ""name"":""Slow Statements"",
+                     ""children"":[
+                        {
+                           ""x"":0,
+                           ""y"":0,
+                           ""w"":24,
+                           ""h"":29,
+                           ""i"":""0"",
+                           ""type"":""Widget"",
+                           ""metricTypes"":[
+                              ""readSampledRecords""
+                           ],
+                           ""metrics"":[
+                              ""top_n_database_statement""","[{'comment': 'Do we support to set N for sampled record on UI?\nAs you use a whole page to show. Top 50 seems better.', 'commenter': 'wu-sheng'}, {'comment': '> Do we support to set N for sampled record on UI? As you use a whole page to show. Top 50 seems better.\r\n\r\nWe support that, and default is 10.\r\n> As you use a whole page to show. Top 50 seems better.\r\n\r\nI get it.', 'commenter': 'yswdqz'}]"
9614,docs/en/setup/backend/backend-mysql-monitoring.md,"@@ -1,21 +1,34 @@
 # MySQL monitoring
-SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data from MySQL. It leverages OpenTelemetry Collector to transfer the metrics to
+SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data. It leverages OpenTelemetry Collector to transfer the metrics to
 [OpenTelemetry receiver](opentelemetry-receiver.md) and into the [Meter System](./../../concepts-and-designs/meter.md).
+SkyWalking also leverages fluentbit(or other log collector) for collecting slow sql statement from MySQL.","[{'comment': '```suggestion\nSkyWalking also leverages fluentbit(or other log collector) for collecting slow sql statements from MySQL.\n```\n', 'commenter': 'wu-sheng'}]"
9614,docs/en/setup/backend/backend-mysql-monitoring.md,"@@ -1,21 +1,34 @@
 # MySQL monitoring
-SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data from MySQL. It leverages OpenTelemetry Collector to transfer the metrics to
+SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data. It leverages OpenTelemetry Collector to transfer the metrics to
 [OpenTelemetry receiver](opentelemetry-receiver.md) and into the [Meter System](./../../concepts-and-designs/meter.md).
+SkyWalking also leverages fluentbit(or other log collector) for collecting slow sql statement from MySQL.
 
 ## Data flow
+- `prometheus/mysqld_exporter`","[{'comment': '```suggestion\n- MySQL server performance from `prometheus/mysqld_exporter`\n```\n', 'commenter': 'wu-sheng'}]"
9614,docs/en/setup/backend/backend-mysql-monitoring.md,"@@ -1,21 +1,34 @@
 # MySQL monitoring
-SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data from MySQL. It leverages OpenTelemetry Collector to transfer the metrics to
+SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data. It leverages OpenTelemetry Collector to transfer the metrics to
 [OpenTelemetry receiver](opentelemetry-receiver.md) and into the [Meter System](./../../concepts-and-designs/meter.md).
+SkyWalking also leverages fluentbit(or other log collector) for collecting slow sql statement from MySQL.
 
 ## Data flow
+- `prometheus/mysqld_exporter`
 1. mysqld_exporter collect metrics data from MySQL.
 2. OpenTelemetry Collector fetches metrics from mysqld_exporter via Prometheus Receiver and pushes metrics to SkyWalking OAP Server via the OpenCensus gRPC Exporter or OpenTelemetry gRPC exporter.
 3. The SkyWalking OAP Server parses the expression with [MAL](../../concepts-and-designs/mal.md) to filter/calculate/aggregate and store the results.
 
+- `slowsql`","[{'comment': '```suggestion\n- Collect sampled slow SQLs\n```\n', 'commenter': 'wu-sheng'}]"
9614,docs/en/setup/backend/backend-mysql-monitoring.md,"@@ -1,5 +1,5 @@
-# MySQL monitoring
-SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data from MySQL. It leverages OpenTelemetry Collector to transfer the metrics to
+# MySQL server performance from `prometheus/mysqld_exporter`","[{'comment': ""Don't change level one in the docs \n\n"", 'commenter': 'wu-sheng'}, {'comment': 'Add a level two menu for this please ', 'commenter': 'wu-sheng'}]"
9620,oap-server/server-starter/src/main/resources/telegraf-rules/default.yaml,"@@ -0,0 +1,50 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+expSuffix: service(['host'], Layer.OS_LINUX)","[{'comment': 'Is this file working well as same as OTEL Linux monitoring? Could we activate them at the same time?', 'commenter': 'wu-sheng'}, {'comment': '> Is this file working well as same as OTEL Linux monitoring? Could we activate them at the same time?\r\n\r\nI am not sure whether they can activate at the same time, I will test it.', 'commenter': 'soander'}, {'comment': ""If it can't for now, please let me know. Unless there are differences at aggregation function level, or downsampling. We should be able to.\n\nOtherwise, this configurations(rules) should be in default release. Because there is no dashboard for it."", 'commenter': 'wu-sheng'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfigs.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.library.util.ResourceUtils;
+import org.yaml.snakeyaml.Yaml;
+
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafConfigs {
+    public static List<TelegrafConfig> loadConfigs(String path, List<String> fileNames) throws ModuleStartException {
+        if (CollectionUtils.isEmpty(fileNames)) {
+            return Collections.emptyList();
+        }
+
+        File[] configs;
+        try {
+            configs = ResourceUtils.getPathFiles(path);
+        } catch (FileNotFoundException e) {
+            throw new ModuleStartException(""Load telegraf configs failed"", e);
+        }
+
+        return Arrays.stream(configs)
+                .filter(File::isFile)
+                .map(f -> {
+                    String fileName = f.getName();
+                    int dotIndex = fileName.lastIndexOf('.');
+                    fileName = (dotIndex == -1) ? fileName : fileName.substring(0, dotIndex);
+                    if (!fileNames.contains(fileName)) {
+                        return null;
+                    }
+                    try (Reader r = new FileReader(f)) {","[{'comment': ""*[DefaultCharset](https://errorprone.info/bugpattern/DefaultCharset):*  Implicit use of the platform default charset, which can result in differing behaviour between JVM executions or incorrect behavior if the encoding of the data source doesn't match expectations.\n\n---\n\n\n```suggestion\n                    try (Reader r = Files.newBufferedReader(f.toPath(), Charset.defaultCharset())) {\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280424&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280424&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280424&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280424&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280424&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;
+    private String expPrefix;
+    private String filter;
+    private String initExp;
+    private List<Rule> metricsRules;
+
+    @Data
+    @NoArgsConstructor
+    public static class Rule implements RuleConfig {
+        private String name;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getName implements method in RuleConfig; expected @Override\n\n---\n\n\n```suggestion\n        private String @Override name;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280309&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280309&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280309&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280309&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280309&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;
+    private String expPrefix;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getExpPrefix implements method in MetricRuleConfig; expected @Override\n\n---\n\n\n```suggestion\n    private String @Override expPrefix;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280322&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280322&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280322&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280322&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280322&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;
+    private String expPrefix;
+    private String filter;
+    private String initExp;
+    private List<Rule> metricsRules;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getMetricsRules implements method in MetricRuleConfig; expected @Override\n\n---\n\n\n```suggestion\n    private List<Rule> @Override metricsRules;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280334&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280334&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280334&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280334&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280334&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getExpSuffix implements method in MetricRuleConfig; expected @Override\n\n---\n\n\n```suggestion\n    private String @Override expSuffix;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280349&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280349&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280349&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280349&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280349&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;
+    private String expPrefix;
+    private String filter;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getFilter implements method in MetricRuleConfig; expected @Override\n\n---\n\n\n```suggestion\n    private String @Override filter;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280433&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280433&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280433&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280433&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280433&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;
+    private String expPrefix;
+    private String filter;
+    private String initExp;
+    private List<Rule> metricsRules;
+
+    @Data
+    @NoArgsConstructor
+    public static class Rule implements RuleConfig {
+        private String name;
+        private String exp;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getExp implements method in RuleConfig; expected @Override\n\n---\n\n\n```suggestion\n        private String @Override exp;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280522&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280522&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280522&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280522&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280522&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getMetricPrefix implements method in MetricRuleConfig; expected @Override\n\n---\n\n\n```suggestion\n    private String @Override metricPrefix;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280509&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280509&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280509&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280509&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280509&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfig.java,"@@ -0,0 +1,43 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+import org.apache.skywalking.oap.meter.analyzer.MetricRuleConfig;
+
+import java.util.List;
+
+@Data
+public class TelegrafConfig implements MetricRuleConfig {
+
+    private String metricPrefix;
+    private String expSuffix;
+    private String expPrefix;
+    private String filter;
+    private String initExp;","[{'comment': ""*[MissingOverride](https://errorprone.info/bugpattern/MissingOverride):*  getInitExp implements method in MetricRuleConfig; expected @Override\n\n---\n\n\n```suggestion\n    private String @Override initExp;\n```\n\n\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=333280641&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=333280641&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280641&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=333280641&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=333280641&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());
+
+        Map<String, Object> fields = telegrafData.getFields();
+        String name = telegrafData.getName();
+        Map<String, String> tags = telegrafData.getTags();
+        ImmutableMap<String, String> immutableTags = ImmutableMap.copyOf(tags);
+        long timestamp = telegrafData.getTimestamp();
+
+        fields.forEach((key, value) -> {
+            Sample.SampleBuilder builder = Sample.builder();
+            if (value instanceof String) return;","[{'comment': 'Hi, could you provide some JSON data samples? I want to know more details about the convert logic. Such as why the value might be String.', 'commenter': 'wankai123'}, {'comment': '> Hi, could you provide some JSON data samples? I want to know more details about the convert logic. Such as why the value might be String.\r\n\r\nThe following data is JSON data samples:\r\n`{""metrics"":[{""fields"":{""available"":6047739904,""available_percent"":35.41215070500567,""total"":17078149120,""used"":11030409216,""used_percent"":64.58784929499433},""name"":""mem"",""tags"":{""host"":""DESKTOP-S9HLAV6""},""timestamp"":1663391390},{""fields"":{""usage_guest"":0,""usage_guest_nice"":0,""usage_idle"":95.32710280373831,""usage_iowait"":0,""usage_irq"":0.3115264797507788,""usage_nice"":0,""usage_softirq"":0,""usage_steal"":0,""usage_system"":1.7133956386292835,""usage_user"":2.64797507788162},""name"":""cpu"",""tags"":{""cpu"":""cpu0"",""host"":""DESKTOP-S9HLAV6""},""timestamp"":1663391390}]}`\r\n\r\nThe convert logic is build a sample by iterating every pair of key and value. Then adding the single simple to the sample list. Maybe the value will never be String, so the line of code is probably useless.', 'commenter': 'soander'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());
+
+        Map<String, Object> fields = telegrafData.getFields();
+        String name = telegrafData.getName();
+        Map<String, String> tags = telegrafData.getTags();
+        ImmutableMap<String, String> immutableTags = ImmutableMap.copyOf(tags);
+        long timestamp = telegrafData.getTimestamp();
+
+        fields.forEach((key, value) -> {
+            Sample.SampleBuilder builder = Sample.builder();
+            if (value instanceof String) return;
+            Sample sample = builder.name(name + ""_"" + key)
+                    .timestamp(timestamp * 1000L)","[{'comment': 'can you confirm the timestamp unit is `second` by default?\r\nI found a doc: https://docs.influxdata.com/telegraf/v1.23/data_formats/output/json/\r\nmaybe the timestamp unit is configurable.', 'commenter': 'wankai123'}, {'comment': '> can you confirm the timestamp unit is `second` by default? I found a doc: https://docs.influxdata.com/telegraf/v1.23/data_formats/output/json/ maybe the timestamp unit is configurable.\r\n\r\nYeah, I can confirm that the default timestamp unit is `second`. Because I just set the `data_format = ""json""`, and didn\'t configure the `json_timestamp_units`. According to output timestamp result, the default timestamp is `second`.\r\nThe following screenshot is my configuration.\r\n<img width=""538"" alt=""image"" src=""https://user-images.githubusercontent.com/79000735/190842615-9c08fc66-70be-405f-892c-8958de710c2b.png"">\r\n\r\nSo what should I do to handle different timestamp unit, such as `""1ns"", ""1us"", ""1ms"", ""10ms""`? I will appreciate your guidance!', 'commenter': 'soander'}, {'comment': 'We should have a configuration to match telegraf configuration about time precision.\n\nIn the MAL, the timestamp(from Java spec) is ms, please refer to the Java spec', 'commenter': 'wu-sheng'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/TelegrafReceiverProvider.java,"@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider;
+
+import com.google.common.base.Splitter;
+import com.linecorp.armeria.common.HttpMethod;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.core.server.HTTPHandlerRegister;
+import org.apache.skywalking.oap.server.library.module.ModuleConfig;
+import org.apache.skywalking.oap.server.library.module.ModuleDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleProvider;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.module.ServiceNotProvidedException;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.library.util.StringUtil;
+import org.apache.skywalking.oap.server.receiver.sharing.server.SharingServerModule;
+import org.apache.skywalking.oap.server.receiver.telegraf.module.TelegrafReceiverModule;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfigs;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.TelegrafServiceHandler;
+
+import java.util.Collections;
+import java.util.List;
+
+public class TelegrafReceiverProvider extends ModuleProvider {
+    private List<TelegrafConfig> configs;
+    private TelegrafModuleConfig moduleConfig;
+
+    @Override
+    public String name() {
+        return ""default"";
+    }
+
+    @Override
+    public Class<? extends ModuleDefine> module() {
+        return TelegrafReceiverModule.class;
+    }
+
+    @Override
+    public ModuleConfig createConfigBeanIfAbsent() {
+        moduleConfig = new TelegrafModuleConfig();
+        return moduleConfig;","[{'comment': 'This is not `create if absent` (`createConfigBeanIfAbsent`)', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/config/TelegrafConfigs.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.config;
+
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+import org.apache.skywalking.oap.server.library.util.ResourceUtils;
+import org.yaml.snakeyaml.Yaml;
+
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileReader;
+import java.io.IOException;
+import java.io.Reader;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafConfigs {
+    public static List<TelegrafConfig> loadConfigs(String path, List<String> fileNames) throws ModuleStartException {
+        if (CollectionUtils.isEmpty(fileNames)) {
+            return Collections.emptyList();
+        }
+
+        File[] configs;
+        try {
+            configs = ResourceUtils.getPathFiles(path);
+        } catch (FileNotFoundException e) {
+            throw new ModuleStartException(""Load telegraf configs failed"", e);
+        }
+
+        return Arrays.stream(configs)
+                .filter(File::isFile)
+                .map(f -> {
+                    String fileName = f.getName();
+                    int dotIndex = fileName.lastIndexOf('.');
+                    fileName = (dotIndex == -1) ? fileName : fileName.substring(0, dotIndex);
+                    if (!fileNames.contains(fileName)) {
+                        return null;
+                    }
+                    try (Reader r = new FileReader(f)) {
+                        return new Yaml().loadAs(r, TelegrafConfig.class);
+                    } catch (IOException e) {
+                        log.warn(""Reading file {} failed"", f, e);","[{'comment': 'Please throw module start exception, this is a fatal error', 'commenter': 'kezhenxu94'}, {'comment': '> Please throw module start exception, this is a fatal error\r\n\r\nI set the `loadConfigs` method throws the `ModuleStartException` , should I change it?\r\n![image](https://user-images.githubusercontent.com/79000735/190843723-2cbbfe34-9552-424c-a370-28d31f35f2c4.png)\r\n', 'commenter': 'soander'}, {'comment': '> > Please throw module start exception, this is a fatal error\r\n> \r\n> I set the `loadConfigs` method throws the `ModuleStartException` , should I change it? ![image](https://user-images.githubusercontent.com/79000735/190843723-2cbbfe34-9552-424c-a370-28d31f35f2c4.png)\r\n\r\nI mean you should throw a `ModuleStartException` here, logging it is not enough.\r\n\r\n```suggestion\r\n                        throw new ModuleStartException(e);\r\n```', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());
+
+        Map<String, Object> fields = telegrafData.getFields();
+        String name = telegrafData.getName();
+        Map<String, String> tags = telegrafData.getTags();
+        ImmutableMap<String, String> immutableTags = ImmutableMap.copyOf(tags);
+        long timestamp = telegrafData.getTimestamp();
+
+        fields.forEach((key, value) -> {
+            Sample.SampleBuilder builder = Sample.builder();
+            if (value instanceof String) return;
+            Sample sample = builder.name(name + ""_"" + key)
+                    .timestamp(timestamp * 1000L)
+                    .value(((Number) value).doubleValue())
+                    .labels(immutableTags).build();
+
+            sampleList.add(sample);
+        });
+        return sampleList;
+
+    }
+
+    @Post(""/telegraf"")
+    public Commands collectData(String jsonInfo) {
+        TelegrafData telegrafData;","[{'comment': '```suggestion\r\n```', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());
+
+        Map<String, Object> fields = telegrafData.getFields();
+        String name = telegrafData.getName();
+        Map<String, String> tags = telegrafData.getTags();
+        ImmutableMap<String, String> immutableTags = ImmutableMap.copyOf(tags);
+        long timestamp = telegrafData.getTimestamp();
+
+        fields.forEach((key, value) -> {
+            Sample.SampleBuilder builder = Sample.builder();
+            if (value instanceof String) return;
+            Sample sample = builder.name(name + ""_"" + key)
+                    .timestamp(timestamp * 1000L)
+                    .value(((Number) value).doubleValue())
+                    .labels(immutableTags).build();
+
+            sampleList.add(sample);
+        });
+        return sampleList;
+
+    }
+
+    @Post(""/telegraf"")
+    public Commands collectData(String jsonInfo) {
+        TelegrafData telegrafData;
+        try (HistogramMetrics.Timer ignored = histogram.createTimer()) {
+            List<Sample> allSamples = new ArrayList<>();
+            ObjectMapper mapper = new ObjectMapper();
+            JsonNode node = mapper.readTree(jsonInfo);
+
+            // Read each metrics json and convert it to Sample
+            JsonNode metrics = node.get(""metrics"");
+            for (JsonNode m : metrics) {
+                telegrafData = mapper.convertValue(m, TelegrafData.class);","[{'comment': '```suggestion\r\n                TelegrafData telegrafData = mapper.convertValue(m, TelegrafData.class);\r\n```', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());
+
+        Map<String, Object> fields = telegrafData.getFields();
+        String name = telegrafData.getName();
+        Map<String, String> tags = telegrafData.getTags();
+        ImmutableMap<String, String> immutableTags = ImmutableMap.copyOf(tags);
+        long timestamp = telegrafData.getTimestamp();
+
+        fields.forEach((key, value) -> {
+            Sample.SampleBuilder builder = Sample.builder();
+            if (value instanceof String) return;
+            Sample sample = builder.name(name + ""_"" + key)
+                    .timestamp(timestamp * 1000L)
+                    .value(((Number) value).doubleValue())
+                    .labels(immutableTags).build();
+
+            sampleList.add(sample);
+        });
+        return sampleList;
+
+    }
+
+    @Post(""/telegraf"")
+    public Commands collectData(String jsonInfo) {
+        TelegrafData telegrafData;
+        try (HistogramMetrics.Timer ignored = histogram.createTimer()) {
+            List<Sample> allSamples = new ArrayList<>();
+            ObjectMapper mapper = new ObjectMapper();","[{'comment': 'Extract this to a field, the mapper should not be instantiated every time.', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/pojo/TelegrafData.java,"@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonProperty;
+import lombok.AllArgsConstructor;
+import lombok.Data;
+import lombok.NoArgsConstructor;
+
+import java.util.Map;
+
+@Data
+@NoArgsConstructor
+@AllArgsConstructor
+@JsonIgnoreProperties(ignoreUnknown = true)
+public class TelegrafData {
+    @JsonProperty(""fields"")
+    private Map<String, Object> fields;
+    @JsonProperty(""name"")
+    private String name;
+    @JsonProperty(""tags"")
+    private Map<String, String> tags;
+    @JsonProperty(""timestamp"")
+    private long timestamp;","[{'comment': 'If the json field names are the same as the Java field names, `@JsonProperty` is redundant', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());","[{'comment': '```suggestion\r\n        List<Sample> sampleList = new ArrayList<>();\r\n```', 'commenter': 'kezhenxu94'}]"
9620,oap-server/server-receiver-plugin/skywalking-telegraf-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/telegraf/provider/handler/TelegrafServiceHandler.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.telegraf.provider.handler;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.collect.ImmutableMap;
+import com.linecorp.armeria.server.annotation.Post;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.apm.network.common.v3.Commands;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.dsl.Sample;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamily;
+import org.apache.skywalking.oap.meter.analyzer.dsl.SampleFamilyBuilder;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.config.TelegrafConfig;
+import org.apache.skywalking.oap.server.receiver.telegraf.provider.handler.pojo.TelegrafData;
+import org.apache.skywalking.oap.server.telemetry.TelemetryModule;
+import org.apache.skywalking.oap.server.telemetry.api.CounterMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.HistogramMetrics;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsCreator;
+import org.apache.skywalking.oap.server.telemetry.api.MetricsTag;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+
+@Slf4j
+public class TelegrafServiceHandler {
+
+    private final HistogramMetrics histogram;
+    private final CounterMetrics errorCounter;
+    private List<MetricConvert> metricConvert;
+
+    public TelegrafServiceHandler(ModuleManager moduleManager, MeterSystem meterSystem, List<TelegrafConfig> rules) {
+
+        this.metricConvert = rules.stream().map(r -> new MetricConvert(r, meterSystem)).collect(Collectors.toList());
+
+        final MetricsCreator metricsCreator = moduleManager.find(TelemetryModule.NAME)
+                                                           .provider()
+                                                           .getService(MetricsCreator.class);
+
+        histogram = metricsCreator.createHistogramMetric(
+                ""telegraf_in_latency"", ""The process latency of telegraf data"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+
+        errorCounter = metricsCreator.createCounter(
+                ""telegraf_error_count"", ""The error number of telegraf analysis"",
+                new MetricsTag.Keys(""protocol""), new MetricsTag.Values(""http"")
+        );
+    }
+
+    /**
+    * Convert the TelegrafData object to meter {@link Sample}
+    **/
+    public List<Sample> convertTelegraf(TelegrafData telegrafData) {
+
+        List<Sample> sampleList = new ArrayList<>(Collections.emptyList());
+
+        Map<String, Object> fields = telegrafData.getFields();
+        String name = telegrafData.getName();
+        Map<String, String> tags = telegrafData.getTags();
+        ImmutableMap<String, String> immutableTags = ImmutableMap.copyOf(tags);
+        long timestamp = telegrafData.getTimestamp();
+
+        fields.forEach((key, value) -> {
+            Sample.SampleBuilder builder = Sample.builder();
+            if (value instanceof String) return;
+            Sample sample = builder.name(name + ""_"" + key)
+                    .timestamp(timestamp * 1000L)
+                    .value(((Number) value).doubleValue())
+                    .labels(immutableTags).build();
+
+            sampleList.add(sample);
+        });
+        return sampleList;
+
+    }
+
+    @Post(""/telegraf"")
+    public Commands collectData(String jsonInfo) {
+        TelegrafData telegrafData;
+        try (HistogramMetrics.Timer ignored = histogram.createTimer()) {
+            List<Sample> allSamples = new ArrayList<>();
+            ObjectMapper mapper = new ObjectMapper();
+            JsonNode node = mapper.readTree(jsonInfo);","[{'comment': ""Can you rename the original `TelegrafData` class to `TelegrafDatum`, and define a class `TelegrafData` to contain a field `List<TelegrafDatum> metrics`, so you don't need to `readTree` here, and just declare the method `public Commands collectData(TelegrafData telegrafData) {`"", 'commenter': 'kezhenxu94'}, {'comment': ""> Can you rename the original `TelegrafData` class to `TelegrafDatum`, and define a class `TelegrafData` to contain a field `List<TelegrafDatum> metrics`, so you don't need to `readTree` here, and just declare the method `public Commands collectData(TelegrafData telegrafData) {`\r\n\r\nI change code according to your suggestion. Everything works fine.\r\n\r\nThis is `TelegrafData` class.\r\n![image](https://user-images.githubusercontent.com/79000735/191666192-76d80f30-eed9-4569-ae26-3619578f0b98.png)\r\n\r\nThis is `public Commands collectData(TelegrafData telegrafData)` method.\r\n![image](https://user-images.githubusercontent.com/79000735/191666960-bf395584-b0db-494f-b02e-3ed922c7863c.png)\r\n\r\nIs this modification good? If there are still problems, what else do I need to fix? Thank you for your guidance!\r\n"", 'commenter': 'soander'}, {'comment': ""Not sure whether it's necessary that class `TelegrafData` should implement `RequestConverterFunction`, this is a standard POJO and the Armeria should be able to deserialize it correctly"", 'commenter': 'kezhenxu94'}, {'comment': ""> Not sure whether it's necessary that class `TelegrafData` should implement `RequestConverterFunction`, this is a standard POJO and the Armeria should be able to deserialize it correctly\r\n\r\nI set the class `TelegrafData` like this:\r\n![image](https://user-images.githubusercontent.com/79000735/192081885-8811cae0-2432-4184-b197-c074d451c68f.png)\r\n\r\nThe method shows this **error**.\r\n![image](https://user-images.githubusercontent.com/79000735/192082071-73e300a9-b1b5-4090-a395-a69ee0f17b47.png)\r\n\r\nAfter I removed the code `@RequestConverter(TelegrafData.class)`, the oap-server can be run, but the class `TelegrafServiceHandler` can't work, and pops up **error** info:\r\n![image](https://user-images.githubusercontent.com/79000735/192081965-2df5f991-e30c-4202-a709-c21b17785985.png)\r\n\r\nAccording to the Armeria document, the POJO class should implement `RequestConverterFunction` that can be used in the `@RequestConverter` and `@RequestObject` annotations. You can check the section **Conversion between an HTTP message and a Java object** in this document [https://armeria.dev/docs/server-annotated-service/](url) or the part **Write a request converter** in this tutorials [https://armeria.dev/tutorials/rest/blog/implement-create/](url).\r\n\r\nMaybe the class `TelegrafData` can be optimized, but I think class `TelegrafData `must implement `RequestConverterFunction` for converting JSON object to JAVA object. "", 'commenter': 'soander'}]"
9839,oap-server-bom/pom.xml,"@@ -73,7 +73,7 @@
         <awaitility.version>3.0.0</awaitility.version>
         <httpcore.version>4.4.13</httpcore.version>
         <commons-compress.version>1.21</commons-compress.version>
-        <banyandb-java-client.version>0.1.0</banyandb-java-client.version>
+        <banyandb-java-client.version>0.2.0-SNAPSHOT</banyandb-java-client.version>","[{'comment': 'You need a repository to get this version, I think?', 'commenter': 'wu-sheng'}, {'comment': 'Yes. Pending util we publish java client `0.2.0`.', 'commenter': 'lujiajing1126'}, {'comment': 'TODO: Once PR is approved, we would wait for the BanyanDB client 0.2.0 released. ', 'commenter': 'wu-sheng'}]"
9839,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/MetadataRegistry.java,"@@ -322,9 +323,9 @@ public Group getOrCreateGroup(BanyanDBClient client) throws BanyanDBException {
             }
             switch (kind) {
                 case STREAM:
-                    return client.define(Group.create(this.group, Catalog.STREAM, this.shard, 0, Duration.ofDays(7)));
+                    return client.define(Group.create(this.group, Catalog.STREAM, this.shard, IntervalRule.create(IntervalRule.Unit.HOUR, 4), IntervalRule.create(IntervalRule.Unit.DAY, 1), IntervalRule.create(IntervalRule.Unit.DAY, 7)));
                 case MEASURE:
-                    return client.define(Group.create(this.group, Catalog.MEASURE, this.shard, 12, Duration.ofDays(7)));
+                    return client.define(Group.create(this.group, Catalog.MEASURE, this.shard, IntervalRule.create(IntervalRule.Unit.HOUR, 4), IntervalRule.create(IntervalRule.Unit.HOUR, 24), IntervalRule.create(IntervalRule.Unit.DAY, 7)));","[{'comment': 'I think we should provide these as storage settings. These are polices controlling segment and blocks creating, right? ', 'commenter': 'wu-sheng'}, {'comment': 'Added', 'commenter': 'lujiajing1126'}]"
9839,.licenserc.yaml,"@@ -119,3 +119,9 @@ dependency:
     - name: com.google.flatbuffers:flatbuffers-java
       version: 1.12.0
       license: Apache-2.0
+    - name: build.buf.protoc-gen-validate:pgv-java-stub
+      version: 0.6.13
+      license: Apache-2.0
+    - name: build.buf.protoc-gen-validate:protoc-gen-validate
+      version: 0.6.13
+      license: Apache-2.0","[{'comment': 'As these are added, you should update license files accordingly.', 'commenter': 'wu-sheng'}, {'comment': 'LICENSE regenerated', 'commenter': 'lujiajing1126'}]"
9839,docs/en/changes/changes.md,"@@ -3,6 +3,7 @@
 #### Project
 
 * Bump up the embedded `swctl` version in OAP Docker image.
+* Migrate to BanyanDB v0.2.0.","[{'comment': 'I think this should be in `backend` only?', 'commenter': 'wu-sheng'}, {'comment': 'Also, please make this a breaking change. BanyanDB server breaks the protocol, and we change the ways to store data.', 'commenter': 'wu-sheng'}, {'comment': 'Let\'s add these key changes into changelog as well\r\n<img width=""527"" alt=""image"" src=""https://user-images.githubusercontent.com/5441976/198961517-93b521be-c53e-4cd0-9198-d299350551ba.png"">\r\n', 'commenter': 'wu-sheng'}, {'comment': 'Added', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/BanyanDB.java,"@@ -91,4 +91,19 @@
     @interface NoIndexing {
 
     }
+
+    /**
+     * Additional information for constructing Index in BanyanDB.
+     *
+     * @since 9.3.0
+     */
+    @Target({ElementType.FIELD})
+    @Retention(RetentionPolicy.RUNTIME)
+    @interface IndexRule {
+        IndexType indexType() default IndexType.INVERTED;
+
+        enum IndexType {
+            INVERTED, TREE;","[{'comment': 'Please provide a simple explanation for those two index types.', 'commenter': 'wu-sheng'}, {'comment': 'Added', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/MetadataRegistry.java,"@@ -293,21 +335,41 @@ public SchemaMetadata parseMetadata(Model model, BanyanDBStorageConfig config) {
     @Data
     public static class SchemaMetadata {
         private final String group;
-        private final String name;
+        /**
+         * name of the {@link Model}
+         */
+        private final String modelName;
         private final Kind kind;
-
+        /**
+         * down-sampling of the {@link Model}
+         */
+        private final DownSampling downSampling;
         private final int shard;
         private final int blockIntervalHrs;
         private final int segmentIntervalHrs;
         private final int ttlDays;
 
+        /**
+         * Format the entity name for BanyanDB
+         *
+         * @param modelName    name of the model
+         * @param downSampling not used if it is {@link DownSampling#None}
+         * @return entity (e.g. measure, stream) name
+         */
+        static String formatName(String modelName, DownSampling downSampling) {
+            if (downSampling == null || downSampling == DownSampling.None) {
+                return modelName;
+            }
+            return modelName + "":"" + downSampling.getName();","[{'comment': 'Underscore ""_""  is better and compatible with the metric name\'s convention.', 'commenter': 'hanahmily'}, {'comment': 'Fixed', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/measure/BanyanDBMetricsQueryDAO.java,"@@ -205,19 +199,38 @@ public HeatMap readHeatMap(MetricsCondition condition, String valueColumnName, D
         return heatMap;
     }
 
-    private Map<String, DataPoint> queryIDs(String modelName, String valueColumnName, List<String> measureIDs) throws IOException {
-        Map<String, DataPoint> map = new HashMap<>(measureIDs.size());
-        for (final String id : measureIDs) {
-            MeasureQueryResponse resp = query(modelName, Collections.emptySet(), ImmutableSet.of(valueColumnName), new QueryBuilder<MeasureQuery>() {
-                @Override
-                protected void apply(MeasureQuery query) {
-                    query.andWithID(id);
-                }
-            });
-            if (resp.size() > 0) {
-                map.putIfAbsent(resp.getDataPoints().get(0).getId(), resp.getDataPoints().get(0));
+    private List<String> extractMeasureIDs(Duration duration, String entityID) {
+        final List<PointOfTime> pointOfTimes = duration.assembleDurationPoints();
+        List<String> ids = new ArrayList<>(pointOfTimes.size());
+        pointOfTimes.forEach(pointOfTime -> {
+            String id = pointOfTime.id(entityID);
+            ids.add(id);
+        });
+        return ids;
+    }
+
+    private Map<String, DataPoint> queryByEntityID(final MetricsCondition condition, String valueColumnName, Duration duration) throws IOException {
+        final MetadataRegistry.Schema schema = MetadataRegistry.INSTANCE.findMetadata(condition.getName(), duration.getStep());
+        if (schema == null) {
+            throw new IOException(""schema is not registered"");
+        }
+        return queryByEntityID(schema, valueColumnName, duration, condition.getEntity().buildId());
+    }
+
+    private Map<String, DataPoint> queryByEntityID(MetadataRegistry.Schema schema, String valueColumnName, Duration duration, String entityID) throws IOException {
+        TimestampRange timestampRange = new TimestampRange(duration.getStartTimestamp(), duration.getEndTimestamp());
+
+        Map<String, DataPoint> map = new HashMap<>();
+        MeasureQueryResponse resp = query(schema, Collections.emptySet(), ImmutableSet.of(valueColumnName), timestampRange, new QueryBuilder<MeasureQuery>() {
+            @Override
+            protected void apply(MeasureQuery query) {
+                query.and(eq(Metrics.ENTITY_ID, entityID));
             }
+        });
+        for (final DataPoint dp : resp.getDataPoints()) {
+            map.putIfAbsent(dp.getId(), dp);","[{'comment': 'If a duplicated data point is here, please raise warnings to make some noise.', 'commenter': 'hanahmily'}]"
9839,docs/en/changes/changes.md,"@@ -93,7 +105,7 @@
   to change the OAP backend service addresses, like `SW_OAP_ADDRESS=localhost:12800,localhost:12801`, and use
   environment
   variable `SW_SERVER_PORT` to change the port. Other Spring-related configurations don't take effect anymore.
-* Polish the endpoint list graph.
+* Polish the endpoint list graph.g","[{'comment': 'Typo?', 'commenter': 'hanahmily'}, {'comment': 'Oh, deleted', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-starter/src/main/resources/application.yml,"@@ -236,6 +236,12 @@ storage:
     superDatasetShardsFactor: ${SW_STORAGE_BANYANDB_SUPERDATASET_SHARDS_FACTOR:2}
     concurrentWriteThreads: ${SW_STORAGE_BANYANDB_CONCURRENT_WRITE_THREADS:15}
     profileTaskQueryMaxSize: ${SW_STORAGE_BANYANDB_PROFILE_TASK_QUERY_MAX_SIZE:200} # the max number of fetch task in a request
+    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:4} # Unit is Hours
+    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:24} # Unit is Hours
+    streamTTL: ${SW_STORAGE_BANYANDB_STREAM_TTL:24} # Unit is Days","[{'comment': ""Could we read TTLs from the core's `recordTTL` and `metricTTL`? `segmentInterval` should not be greater than them."", 'commenter': 'hanahmily'}, {'comment': 'Yes, `ConfigService` is exposed from the Core module.', 'commenter': 'wu-sheng'}, {'comment': 'Fixed', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/measure/BanyanDBMetadataQueryDAO.java,"@@ -230,18 +230,18 @@ public List<Process> listProcesses(String serviceInstanceId, Duration duration,
         long lastPingStartTimeBucket = duration.getStartTimeBucket();
         long lastPingEndTimeBucket = duration.getEndTimeBucket();","[{'comment': 'redandunt variable.', 'commenter': 'hanahmily'}, {'comment': 'Removed', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/stream/BanyanDBProfileThreadSnapshotQueryDAO.java,"@@ -105,43 +103,40 @@ public void apply(StreamQuery query) {
             segmentIds.add(rowEntity.getTagValue(ProfileThreadSnapshotRecord.SEGMENT_ID));
         }
 
-        // TODO: support `IN` or `OR` logic operation in BanyanDB
-        List<BasicTrace> basicTraces = new ArrayList<>();
-        for (String segmentID : segmentIds) {
-            final StreamQueryResponse segmentRecordResp = query(SegmentRecord.INDEX_NAME,
-                    TAGS_TRACE,
-                    new QueryBuilder<StreamQuery>() {
-                        @Override
-                        public void apply(StreamQuery traceQuery) {
-                            traceQuery.and(eq(SegmentRecord.SEGMENT_ID, segmentID));
-                        }
-                    });
-
-            for (final RowEntity row : segmentRecordResp.getElements()) {
-                BasicTrace basicTrace = new BasicTrace();
-
-                basicTrace.setSegmentId(row.getId());
-                basicTrace.setStart(String.valueOf((Number) row.getTagValue(SegmentRecord.START_TIME)));
-                basicTrace.getEndpointNames().add(IDManager.EndpointID.analysisId(
-                        row.getTagValue(SegmentRecord.ENDPOINT_ID)
-                ).getEndpointName());
-                basicTrace.setDuration(((Number) row.getTagValue(SegmentRecord.LATENCY)).intValue());
-                basicTrace.setError(BooleanUtils.valueToBoolean(
-                        ((Number) row.getTagValue(SegmentRecord.IS_ERROR)).intValue()
-                ));
-                basicTrace.getTraceIds().add(row.getTagValue(SegmentRecord.TRACE_ID));
-
-                basicTraces.add(basicTrace);
-            }
+        if (segmentIds.isEmpty()) {
+            return Collections.emptyList();
         }
 
-        // TODO: Sort in DB with DESC
-        basicTraces = basicTraces.stream()
-                // comparing start_time
-                .sorted(Comparator.comparing((Function<BasicTrace, Long>) basicTrace -> Long.parseLong(basicTrace.getStart()))
-                        // and sort in reverse order
-                        .reversed())
-                .collect(Collectors.toList());
+        final StreamQueryResponse segmentRecordResp = query(SegmentRecord.INDEX_NAME,
+                TAGS_TRACE,
+                new QueryBuilder<StreamQuery>() {
+                    @Override
+                    public void apply(StreamQuery traceQuery) {
+                        for (final String segmentID : segmentIds) {
+                            traceQuery.or(eq(SegmentRecord.SEGMENT_ID, segmentID));
+                            traceQuery.setLimit(segmentIds.size());
+                            traceQuery.setOrderBy(desc(SegmentRecord.START_TIME));","[{'comment': 'They should be out of the loop. \n\nAnd add a ""todo"" to use ""in"" in place of ""or"" later.', 'commenter': 'hanahmily'}, {'comment': 'Fixed', 'commenter': 'lujiajing1126'}]"
9839,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/BanyanDBConverter.java,"@@ -215,11 +218,19 @@ public static class StorageToMeasure implements Convert2Entity {
         private final MetadataRegistry.Schema schema;
         private final DataPoint dataPoint;
 
-        public StorageToMeasure(String modelName, DataPoint dataPoint) {
-            this.schema = MetadataRegistry.INSTANCE.findMetadata(modelName);
+        public StorageToMeasure(MetadataRegistry.Schema schema, DataPoint dataPoint) {
+            this.schema = schema;
             this.dataPoint = dataPoint;
         }
 
+        /**
+         * Currently, only used by {@link org.apache.skywalking.oap.server.storage.plugin.banyandb.measure.BanyanDBNetworkAddressAliasDAO}.
+         * The default DownSampling strategy, i.e. {@link DownSampling#Minute} is assumed in this case.
+         */
+        public StorageToMeasure(String measureModelName, DataPoint dataPoint) {
+            this(checkNotNull(MetadataRegistry.INSTANCE.findMetadata(measureModelName, DownSampling.Minute), ""measure schema""), dataPoint);","[{'comment': '@wu-sheng Could we make such assumption?', 'commenter': 'hanahmily'}, {'comment': 'What assumption? Could you be more specific?', 'commenter': 'wu-sheng'}, {'comment': ""I read the comments, why don't we move this special case into the BanyanDBNetworkAddressAliasDAO? This seems a thing not belonging to the converter."", 'commenter': 'wu-sheng'}, {'comment': '> What assumption? Could you be more specific?\r\n\r\nDoes this mean `DownSampling == Minute`? If so, for this specific case, yes, it is correct. `NetworkAddressAlias` has this annotation `@MetricsExtension(supportDownSampling = false, supportUpdate = true)`.\r\n\r\n`*Traffic` has the same annotation for no downsampling too. This is a very special annotation, for now, it is used for models having their own DAOs. ', 'commenter': 'wu-sheng'}, {'comment': 'Moved to `BanyanDBNetworkAddressAliasDAO`', 'commenter': 'lujiajing1126'}]"
9955,oap-server/server-starter/src/main/resources/component-libraries.yml,"@@ -425,6 +425,15 @@ tls:
 Micronaut:
   id: 131
   languages: Java
+AWSDynamoDB:
+  id: 132
+  languages: Java,C#,Node.js,Python
+AWSSNS:
+  id: 133
+  languages: Java,C#,Node.js,Python
+AWSSQS:
+  id: 134
+  languages: Java,C#,Node.js,Python","[{'comment': '132-134 have been registered. Please register to new IDs.', 'commenter': 'wu-sheng'}, {'comment': 'Fixed.', 'commenter': 'tom-pytel'}]"
10115,.gitignore,"@@ -22,3 +22,4 @@ oap-server/oal-grammar/**/gen/
 # This serves as a template but will ONLY be updated when building a source release tar,
 # so we don't track future updates of this file.
 oap-server/server-starter/src/main/resources/version.properties
+test/e2e-v2/cases/mariadb/mariadb-slowsql/log/","[{'comment': 'This is an unexpected change.\r\n\r\n```suggestion\r\n```\r\n\r\nI think the logs should not be generated in local disk.', 'commenter': 'wu-sheng'}]"
10115,test/e2e-v2/cases/mariadb/mariadb-slowsql/docker-compose.yaml,"@@ -0,0 +1,140 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  ui:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: ui
+    image: apache/skywalking-ui:9.2.0
+    networks:
+      - e2e
+    ports:
+      - ""80:8080""
+  oap:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: oap
+    image: ghcr.io/apache/skywalking/oap:bcd9f7a56b99ca612711ed3a540bdae5f46e9171
+    ports:
+      - 12800
+    entrypoint: ['sh', '-c', '/download-mysql.sh /skywalking/oap-libs && chmod 777 /skywalking/docker-entrypoint.sh && /skywalking/docker-entrypoint.sh']
+    networks:
+      - e2e
+    environment:
+      - TZ=Asia/Shanghai
+      - SW_STORAGE=mysql","[{'comment': ""I think for e2e, H2 is good enough, we don't need mysql as storage."", 'commenter': 'wu-sheng'}]"
10115,docs/en/setup/backend/backend-mysql-monitoring.md,"@@ -13,9 +13,9 @@ SkyWalking leverages prometheus/mysqld_exporter for collecting metrics data. It
 2. Set up [OpenTelemetry Collector ](https://opentelemetry.io/docs/collector/getting-started/#docker). For details on Prometheus Receiver in OpenTelemetry Collector, refer to [here](../../../../test/e2e-v2/cases/mysql/prometheus-mysql-exporter/otel-collector-config.yaml).
 3. Config SkyWalking [OpenTelemetry receiver](opentelemetry-receiver.md).
 
-### MySQL Monitoring
-MySQL monitoring provides monitoring of the status and resources of the MySQL server. MySQL cluster is cataloged as a `Layer: MYSQL` `Service` in OAP.
-Each MySQL server is cataloged as an `Instance` in OAP.
+### MySQL/MariaDB Monitoring
+MySQL/MariaDB monitoring provides monitoring of the status and resources of the MySQL/MariaDB server. MySQL/MariaDB cluster is cataloged as a `Layer: MYSQL` `Service` in OAP.
+Each MySQL/MariaDB server is cataloged as an `Instance` in OAP.","[{'comment': 'In the slow SQL part,\n>Config MySQL to enable slow log.example.\n\nYou should update MariaDB part, and link to your e2e example.', 'commenter': 'wu-sheng'}]"
10115,test/e2e-v2/cases/mariadb/mariadb-slowsql/docker-compose.yaml,"@@ -0,0 +1,124 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: oap
+    image: ghcr.io/apache/skywalking/oap:bcd9f7a56b99ca612711ed3a540bdae5f46e9171
+    ports:
+      - 12800
+    entrypoint: ['sh', '-c', '/download-mysql.sh /skywalking/oap-libs && chmod 777 /skywalking/docker-entrypoint.sh && /skywalking/docker-entrypoint.sh']
+    networks:
+      - e2e
+    environment:
+      - TZ=Asia/Shanghai
+      - SW_CORE_TOPN_REPORT_PERIOD=1
+      - SW_OTEL_RECEIVER=default
+      
+  mariadb:
+    image: mariadb:10.7.3
+    networks:
+      - e2e
+    volumes:
+      - ../mariadb-slowsql/log:/var/lib/mysql
+      - ../mariadb-slowsql/my.cnf:/etc/mysql/my.cnf
+    environment:
+      - ""MYSQL_ROOT_PASSWORD=password""
+    healthcheck:
+      test: ""/usr/bin/mysql --user=root --password=password --execute \""SHOW DATABASES;\""""
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  mysql-load:","[{'comment': 'There are several mysql as prefix of the service names in docker compose, consider renaming them to MariaDB?', 'commenter': 'wu-sheng'}]"
10115,docs/en/changes/changes.md,"@@ -31,11 +31,16 @@
 * Rename MAL rule `spring-sleuth.yaml` to `spring-micrometer.yaml`.
 * Fix memory leak in Zipkin API.
 
+#### OAP-Backend
+
+* Support monitoring MariaDB.
+
 #### UI
 
 #### Documentation
 
 * Remove Spring Sleuth docs, and add `Spring MicroMeter Observations Analysis` with the latest Java agent side
   enhancement.
+* Update [monitoring MySQL document](docs/en/setup/backend/backend-mysql-monitoring.md).","[{'comment': 'This is a dead link. Use the relative path from this file. Or remove the link.', 'commenter': 'wu-sheng'}, {'comment': '```suggestion\r\n* Update `monitoring MySQL document` to add the `MariaDB` part.\r\n```', 'commenter': 'wu-sheng'}]"
10115,test/e2e-v2/cases/mariadb/mariadb-slowsql/docker-compose.yaml,"@@ -0,0 +1,124 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: oap
+    image: ghcr.io/apache/skywalking/oap:bcd9f7a56b99ca612711ed3a540bdae5f46e9171","[{'comment': '```suggestion\r\n```\r\nThe oap image version should be controled in `base-compose`', 'commenter': 'wankai123'}, {'comment': 'OAP should be latest build, rather than an old commit ID.\n@yswdqz Does your test have similar case?', 'commenter': 'wu-sheng'}, {'comment': '> OAP should be latest build, rather than an old commit ID.\r\n> @yswdqz Does your test have similar case?\r\n\r\nYes, I think it should be latest build. `Image` should be removed.', 'commenter': 'yswdqz'}, {'comment': ""TTL cases have all down. @yswdqz I don't know why. Could you recheck on the master branch as well?"", 'commenter': 'wu-sheng'}, {'comment': 'I get it.', 'commenter': 'yswdqz'}, {'comment': ""I think I have stabled the TTL tests. They don't block this PR for now."", 'commenter': 'wu-sheng'}]"
10115,test/e2e-v2/cases/mariadb/mariadb-slowsql/docker-compose.yaml,"@@ -0,0 +1,124 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '2.1'
+
+services:
+  oap:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: oap
+    image: ghcr.io/apache/skywalking/oap:bcd9f7a56b99ca612711ed3a540bdae5f46e9171
+    ports:
+      - 12800
+    entrypoint: ['sh', '-c', '/download-mysql.sh /skywalking/oap-libs && chmod 777 /skywalking/docker-entrypoint.sh && /skywalking/docker-entrypoint.sh']
+    networks:
+      - e2e
+    environment:
+      - TZ=Asia/Shanghai","[{'comment': ""```suggestion\r\n```\r\nI think it's not belong to OAP"", 'commenter': 'wankai123'}]"
10115,.gitignore,"@@ -21,4 +21,4 @@ oap-server/oal-grammar/**/gen/
 
 # This serves as a template but will ONLY be updated when building a source release tar,
 # so we don't track future updates of this file.
-oap-server/server-starter/src/main/resources/version.properties
+oap-server/server-starter/src/main/resources/version.properties","[{'comment': 'Please rollback this file. No need change\r\n', 'commenter': 'wankai123'}, {'comment': 'Is this changed due to a different OS?', 'commenter': 'wu-sheng'}, {'comment': 'Maybe it was a mistake. @wankai123 asked to rollback it.', 'commenter': 'mahmoud-anwer'}, {'comment': 'I saw that, but this is still shown as changed in the GitHub changes page.', 'commenter': 'wu-sheng'}, {'comment': 'I think it\'s caused by IDE‘s setting:\r\n<img width=""812"" alt=""image"" src=""https://user-images.githubusercontent.com/16773043/206896708-ef6dae2e-35a9-42bf-9f01-61045628e268.png"">\r\n', 'commenter': 'wankai123'}]"
10128,oap-server/server-starter/src/main/resources/application.yml,"@@ -236,10 +236,8 @@ storage:
     superDatasetShardsFactor: ${SW_STORAGE_BANYANDB_SUPERDATASET_SHARDS_FACTOR:2}
     concurrentWriteThreads: ${SW_STORAGE_BANYANDB_CONCURRENT_WRITE_THREADS:15}
     profileTaskQueryMaxSize: ${SW_STORAGE_BANYANDB_PROFILE_TASK_QUERY_MAX_SIZE:200} # the max number of fetch task in a request
-    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:4} # Unit is hour
-    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:24} # Unit is hour
-    measureBlockInterval: ${SW_STORAGE_BANYANDB_MEASURE_BLOCK_INTERVAL:4} # Unit is hour
-    measureSegmentInterval: ${SW_STORAGE_BANYANDB_MEASURE_SEGMENT_INTERVAL:24} # Unit is hour
+    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:24} # Unit is hour","[{'comment': 'The key should be `blockIntervalHours`, which defaults to `4` hours as before.', 'commenter': 'hanahmily'}, {'comment': 'Done', 'commenter': 'lujiajing1126'}]"
10128,oap-server/server-starter/src/main/resources/application.yml,"@@ -236,10 +236,8 @@ storage:
     superDatasetShardsFactor: ${SW_STORAGE_BANYANDB_SUPERDATASET_SHARDS_FACTOR:2}
     concurrentWriteThreads: ${SW_STORAGE_BANYANDB_CONCURRENT_WRITE_THREADS:15}
     profileTaskQueryMaxSize: ${SW_STORAGE_BANYANDB_PROFILE_TASK_QUERY_MAX_SIZE:200} # the max number of fetch task in a request
-    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:4} # Unit is hour
-    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:24} # Unit is hour
-    measureBlockInterval: ${SW_STORAGE_BANYANDB_MEASURE_BLOCK_INTERVAL:4} # Unit is hour
-    measureSegmentInterval: ${SW_STORAGE_BANYANDB_MEASURE_SEGMENT_INTERVAL:24} # Unit is hour
+    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:24} # Unit is hour
+    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:1} # Unit is day","[{'comment': '`segmentIntervalDays` is the key.', 'commenter': 'hanahmily'}, {'comment': 'Done', 'commenter': 'lujiajing1126'}]"
10128,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/MetadataRegistry.java,"@@ -68,6 +72,8 @@ public enum MetadataRegistry {
 
     private final Map<String, Schema> registry = new HashMap<>();
 
+    private final Map<String, Tuple2<Integer, Integer>> intervalConfig = new HashMap<>();","[{'comment': ""![47% of developers fix this issue](https://lift.sonatype.com/api/commentimage/fixrate/47/display.svg)\n\n*[ImmutableEnumChecker](https://errorprone.info/bugpattern/ImmutableEnumChecker):*  enums should be immutable: 'MetadataRegistry' has field 'intervalConfig' of type 'java.util.Map<java.lang.String,io.vavr.Tuple2<java.lang.Integer,java.lang.Integer>>', 'Map' is mutable\n\n---\n\n<details><summary><b>ℹ️ Learn about @sonatype-lift commands</b></summary>\n\nYou can reply with the following commands. For example, reply with ***@sonatype-lift ignoreall*** to leave out all findings.\n| **Command** | **Usage** |\n| ------------- | ------------- |\n| `@sonatype-lift ignore` | Leave out the above finding from this PR |\n| `@sonatype-lift ignoreall` | Leave out all the existing findings from this PR |\n| `@sonatype-lift exclude <file\\|issue\\|path\\|tool>` | Exclude specified `file\\|issue\\|path\\|tool` from Lift findings by updating your config.toml file |\n\n**Note:** When talking to LiftBot, you need to **refresh** the page to see its response.\n<sub>[Click here](https://github.com/apps/sonatype-lift/installations/new) to add LiftBot to another repo.</sub></details>\n\n\n\n---\n\nWas this a good recommendation?\n[ [🙁 Not relevant](https://www.sonatype.com/lift-comment-rating?comment=359346804&lift_comment_rating=1) ] - [ [😕 Won't fix](https://www.sonatype.com/lift-comment-rating?comment=359346804&lift_comment_rating=2) ] - [ [😑 Not critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=359346804&lift_comment_rating=3) ] - [ [🙂 Critical, will fix](https://www.sonatype.com/lift-comment-rating?comment=359346804&lift_comment_rating=4) ] - [ [😊 Critical, fixing now](https://www.sonatype.com/lift-comment-rating?comment=359346804&lift_comment_rating=5) ]"", 'commenter': 'sonatype-lift[bot]'}]"
10128,oap-server/server-starter/src/main/resources/application.yml,"@@ -235,10 +235,9 @@ storage:
     superDatasetShardsFactor: ${SW_STORAGE_BANYANDB_SUPERDATASET_SHARDS_FACTOR:2}
     concurrentWriteThreads: ${SW_STORAGE_BANYANDB_CONCURRENT_WRITE_THREADS:15}
     profileTaskQueryMaxSize: ${SW_STORAGE_BANYANDB_PROFILE_TASK_QUERY_MAX_SIZE:200} # the max number of fetch task in a request
-    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:4} # Unit is hour
-    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:24} # Unit is hour
-    measureBlockInterval: ${SW_STORAGE_BANYANDB_MEASURE_BLOCK_INTERVAL:4} # Unit is hour
-    measureSegmentInterval: ${SW_STORAGE_BANYANDB_MEASURE_SEGMENT_INTERVAL:24} # Unit is hour
+    blockIntervalHours: ${SW_STORAGE_BANYANDB_BLOCK_INTERVAL_HOURS:24} # Unit is hour
+    segmentIntervalDays: ${SW_STORAGE_BANYANDB_SEGMENT_INTERVAL_DAYS:1} # Unit is day
+    overrideGroupIntervals: ${SW_STORAGE_BANYANDB_OVERRIDE_GROUP_INTERVALS:""""} # For example, group1,4,1;group2,2,2","[{'comment': 'What is `overrideGroupIntervals`?', 'commenter': 'wu-sheng'}, {'comment': '> What is `overrideGroupIntervals`?\r\n\r\nMentioned in issue https://github.com/apache/skywalking/issues/10102, we have to support setting the interval rule based on the group name more than global defaults.', 'commenter': 'lujiajing1126'}, {'comment': 'Do you mean a thing similar with index specific settings in elasticsearch?\r\n\r\n```\r\n    # Specify the settings for each index individually.\r\n    # If configured, this setting has the highest priority and overrides the generic settings.\r\n    specificIndexSettings: ${SW_STORAGE_ES_SPECIFIC_INDEX_SETTINGS:""""}\r\n```', 'commenter': 'wu-sheng'}, {'comment': '> Do you mean a thing similar with index specific settings in elasticsearch?\r\n> \r\n> ```\r\n>     # Specify the settings for each index individually.\r\n>     # If configured, this setting has the highest priority and overrides the generic settings.\r\n>     specificIndexSettings: ${SW_STORAGE_ES_SPECIFIC_INDEX_SETTINGS:""""}\r\n> ```\r\n\r\nI think so', 'commenter': 'lujiajing1126'}, {'comment': 'Then we should rename it to `specificGroupSettings`. And the value format should be in JSON for better extension in the future. What do you think?', 'commenter': 'wu-sheng'}, {'comment': '> Then we should rename it to `specificGroupSettings`. And the value format should be in JSON for better extension in the future. What do you think?\r\n\r\nMake sense to me', 'commenter': 'lujiajing1126'}, {'comment': 'Refactored now', 'commenter': 'lujiajing1126'}]"
10128,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/BanyanDBStorageConfig.java,"@@ -57,31 +57,24 @@ public class BanyanDBStorageConfig extends ModuleConfig {
      */
     private int superDatasetShardsFactor;
     /**
-     * block interval for Stream group.
-     * Unit is hours.
+     * Default global block interval.
+     * Unit is hour.
      *
-     * @since 9.3.0
+     * @since 9.4.0
      */
-    private int streamBlockInterval;
+    private int blockIntervalHours;
     /**
-     * segment interval for Stream group.
-     * Unit is hours.
+     * Default global segment interval.
+     * Unit is day.
      *
-     * @since 9.3.0
+     * @since 9.4.0
      */
-    private int streamSegmentInterval;
+    private int segmentIntervalDays;
     /**
-     * block interval for Measure group.
-     * Unit is hours.
+     * Override the default global configurations.
+     * It works for all groups except `measure-default`.","[{'comment': 'What do you mean `override` default? Who set the default?', 'commenter': 'wu-sheng'}, {'comment': '> What do you mean `override` default? Who set the default?\r\n\r\n`blockIntervalHours` and `segmentIntervalDays` are now global interval rules', 'commenter': 'lujiajing1126'}]"
10128,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/BanyanDBIndexInstaller.java,"@@ -60,9 +61,9 @@ public boolean isExists(Model model) throws StorageException {
             // then check entity schema
             if (metadata.findRemoteSchema(c).isPresent()) {
                 // register models only locally but not remotely
-                if (model.isTimeSeries() && model.isRecord()) { // stream
+                if (model.isRecord()) { // stream
                     MetadataRegistry.INSTANCE.registerStreamModel(model, config, configService);
-                } else if (model.isTimeSeries() && !model.isRecord()) { // measure","[{'comment': ""I don't think this could be removed. Not `model.isTimeSeries()` model exists."", 'commenter': 'wu-sheng'}, {'comment': ""I don't think we should register UI_TEMPLATE as a measure, right?"", 'commenter': 'wu-sheng'}, {'comment': ""We've already checked at the beginning of `isExists`,\r\n\r\n```java\r\n@Override\r\n    public boolean isExists(Model model) throws StorageException {\r\n        if (!model.isTimeSeries()) {\r\n            return true;\r\n        }\r\n        ...\r\n}\r\n```\r\n\r\nSo I think we can safely ignore other cases?"", 'commenter': 'lujiajing1126'}]"
10128,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/BanyanDBIndexInstaller.java,"@@ -78,20 +79,18 @@ public boolean isExists(Model model) throws StorageException {
     public void createTable(Model model) throws StorageException {
         try {
             ConfigService configService = moduleManager.find(CoreModule.NAME).provider().getService(ConfigService.class);
-            if (model.isTimeSeries() && model.isRecord()) { // stream
+            if (model.isRecord()) { // stream
                 Stream stream = MetadataRegistry.INSTANCE.registerStreamModel(model, config, configService);
                 if (stream != null) {
                     log.info(""install stream schema {}"", model.getName());
                     ((BanyanDBStorageClient) client).define(stream);
                 }
-            } else if (model.isTimeSeries() && !model.isRecord()) { // measure","[{'comment': 'Same as https://github.com/apache/skywalking/pull/10128/files#r1045088460', 'commenter': 'wu-sheng'}]"
10128,oap-server/server-starter/src/main/resources/application.yml,"@@ -235,10 +235,9 @@ storage:
     superDatasetShardsFactor: ${SW_STORAGE_BANYANDB_SUPERDATASET_SHARDS_FACTOR:2}
     concurrentWriteThreads: ${SW_STORAGE_BANYANDB_CONCURRENT_WRITE_THREADS:15}
     profileTaskQueryMaxSize: ${SW_STORAGE_BANYANDB_PROFILE_TASK_QUERY_MAX_SIZE:200} # the max number of fetch task in a request
-    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:4} # Unit is hour
-    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:24} # Unit is hour
-    measureBlockInterval: ${SW_STORAGE_BANYANDB_MEASURE_BLOCK_INTERVAL:4} # Unit is hour
-    measureSegmentInterval: ${SW_STORAGE_BANYANDB_MEASURE_SEGMENT_INTERVAL:24} # Unit is hour
+    blockIntervalHours: ${SW_STORAGE_BANYANDB_BLOCK_INTERVAL_HOURS:24} # Unit is hour
+    segmentIntervalDays: ${SW_STORAGE_BANYANDB_SEGMENT_INTERVAL_DAYS:1} # Unit is day","[{'comment': 'A question for @hanahmily, do we need a hard-coded specific setting for superset records? We had this for ElasticSearch.', 'commenter': 'wu-sheng'}, {'comment': 'Yes, we should add a superset dedicated settings here. We can override settings through the newly added `overrideGroupInterval`, but the group name will be changed from time to time. A compiling time flag, superset, might apply these settings to renamed groups. @lujiajing1126 ', 'commenter': 'hanahmily'}, {'comment': '`overrideGroupInterval` had been changed to `specificGroupSettings`.', 'commenter': 'wu-sheng'}, {'comment': '> Yes, we should add a superset dedicated settings here. We can override settings through the newly added `overrideGroupInterval`, but the group name will be changed from time to time. A compiling time flag, superset, might apply these settings to renamed groups. @lujiajing1126\r\n\r\nAdded', 'commenter': 'lujiajing1126'}]"
10128,oap-server/server-starter/src/main/resources/application.yml,"@@ -235,10 +235,9 @@ storage:
     superDatasetShardsFactor: ${SW_STORAGE_BANYANDB_SUPERDATASET_SHARDS_FACTOR:2}
     concurrentWriteThreads: ${SW_STORAGE_BANYANDB_CONCURRENT_WRITE_THREADS:15}
     profileTaskQueryMaxSize: ${SW_STORAGE_BANYANDB_PROFILE_TASK_QUERY_MAX_SIZE:200} # the max number of fetch task in a request
-    streamBlockInterval: ${SW_STORAGE_BANYANDB_STREAM_BLOCK_INTERVAL:4} # Unit is hour
-    streamSegmentInterval: ${SW_STORAGE_BANYANDB_STREAM_SEGMENT_INTERVAL:24} # Unit is hour
-    measureBlockInterval: ${SW_STORAGE_BANYANDB_MEASURE_BLOCK_INTERVAL:4} # Unit is hour
-    measureSegmentInterval: ${SW_STORAGE_BANYANDB_MEASURE_SEGMENT_INTERVAL:24} # Unit is hour
+    blockIntervalHours: ${SW_STORAGE_BANYANDB_BLOCK_INTERVAL_HOURS:24} # Unit is hour
+    segmentIntervalDays: ${SW_STORAGE_BANYANDB_SEGMENT_INTERVAL_DAYS:1} # Unit is day
+    specificGroupSettings: ${SW_STORAGE_BANYANDB_SPECIFIC_GROUP_SETTINGS:""""} # For example, {""group1"": {""blockIntervalHours"": 4, ""segmentIntervalDays"": 1}}","[{'comment': ""@lujiajing1126 Do we have the static group list? If so, we could add the group list here, and in the `field specificGroupSettings`'s comment."", 'commenter': 'wu-sheng'}, {'comment': 'We have several groups now: `measure-default`, `measure-sampled`, `stream-default` and `stream-{superdataset}`. We can add some comments here', 'commenter': 'lujiajing1126'}, {'comment': 'Done', 'commenter': 'lujiajing1126'}, {'comment': 'Could you refer to `https://skywalking.apache.org/docs/skywalking-banyandb/next/crud/group/#list-operation` in the comment? Users could use `bydbctl` to get all groups in the server.', 'commenter': 'hanahmily'}, {'comment': 'Added', 'commenter': 'lujiajing1126'}]"
10181,oap-server-bom/pom.xml,"@@ -73,7 +73,7 @@
         <awaitility.version>3.0.0</awaitility.version>
         <httpcore.version>4.4.13</httpcore.version>
         <commons-compress.version>1.21</commons-compress.version>
-        <banyandb-java-client.version>0.2.1</banyandb-java-client.version>
+        <banyandb-java-client.version>0.3.0-SNAPSHOT</banyandb-java-client.version>","[{'comment': 'A TODO before 9.4.0 release.', 'commenter': 'wu-sheng'}, {'comment': 'added', 'commenter': 'lujiajing1126'}]"
10181,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/measure/BanyanDBTopologyQueryDAO.java,"@@ -123,72 +118,77 @@ List<Call.CallDetail> queryServiceRelation(Duration duration,
             timestampRange = new TimestampRange(TimeBucket.getTimestamp(startTB), TimeBucket.getTimestamp(endTB));
         }
         final String modelName = detectPoint == DetectPoint.SERVER ? ServiceRelationServerSideMetrics.INDEX_NAME :
-            ServiceRelationClientSideMetrics.INDEX_NAME;
-        final Map<String, Call.CallDetail> callMap = new HashMap<>();
-        for (final QueryBuilder<MeasureQuery> q : queryBuilderList) {
-            MeasureQueryResponse resp = query(modelName,
-                                              ImmutableSet.of(
-                                                  ServiceRelationClientSideMetrics.COMPONENT_IDS,
-                                                  Metrics.ENTITY_ID
-                                              ),
-                                              Collections.emptySet(), timestampRange, q
-            );
-            if (resp.size() == 0) {
-                continue;
-            }
-            final Call.CallDetail call = new Call.CallDetail();
-            final String entityId = resp.getDataPoints().get(0).getTagValue(Metrics.ENTITY_ID);
+                ServiceRelationClientSideMetrics.INDEX_NAME;
+
+        MeasureQueryResponse resp = query(modelName,
+                ImmutableSet.of(
+                        ServiceRelationClientSideMetrics.COMPONENT_IDS,
+                        Metrics.ENTITY_ID
+                ),
+                Collections.emptySet(), timestampRange, queryBuilder
+        );
+        if (resp.size() == 0) {
+            return Collections.emptyList();
+        }
+        List<Call.CallDetail> calls = new ArrayList<>(resp.size());
+        for (final DataPoint dataPoint : resp.getDataPoints()) {
+            final String entityId = dataPoint.getTagValue(Metrics.ENTITY_ID);
             final IntList componentIds = new IntList(
-                resp.getDataPoints().get(0).getTagValue(ServiceRelationClientSideMetrics.COMPONENT_IDS));
+                    dataPoint.getTagValue(ServiceRelationClientSideMetrics.COMPONENT_IDS));
+            final Call.CallDetail call = new Call.CallDetail();
             for (int i = 0; i < componentIds.size(); i++) {
                 call.buildFromServiceRelation(entityId, componentIds.get(i), detectPoint);
-                callMap.putIfAbsent(entityId, call);
+                calls.add(call);
             }
         }
-        return new ArrayList<>(callMap.values());
+        return calls;
     }
 
     @Override
     public List<Call.CallDetail> loadInstanceRelationDetectedAtServerSide(String clientServiceId,
                                                                           String serverServiceId,
                                                                           Duration duration) throws IOException {
-        List<QueryBuilder<MeasureQuery>> queryBuilderList = buildInstanceRelationsQueries(
-            clientServiceId, serverServiceId);
-        return queryInstanceRelation(duration, queryBuilderList, DetectPoint.SERVER);
+        QueryBuilder<MeasureQuery> queryBuilder = buildInstanceRelationsQuery(
+                clientServiceId, serverServiceId);
+        return queryInstanceRelation(duration, queryBuilder, DetectPoint.SERVER);
     }
 
     @Override
     public List<Call.CallDetail> loadInstanceRelationDetectedAtClientSide(String clientServiceId,
                                                                           String serverServiceId,
                                                                           Duration duration) throws IOException {
-        List<QueryBuilder<MeasureQuery>> queryBuilderList = buildInstanceRelationsQueries(
-            clientServiceId, serverServiceId);
-        return queryInstanceRelation(duration, queryBuilderList, DetectPoint.CLIENT);
+        QueryBuilder<MeasureQuery> queryBuilder = buildInstanceRelationsQuery(
+                clientServiceId, serverServiceId);
+        return queryInstanceRelation(duration, queryBuilder, DetectPoint.CLIENT);
     }
 
-    private List<QueryBuilder<MeasureQuery>> buildInstanceRelationsQueries(String clientServiceId,
-                                                                           String serverServiceId) {
-        List<QueryBuilder<MeasureQuery>> queryBuilderList = new ArrayList<>(2);
-        queryBuilderList.add(new QueryBuilder<MeasureQuery>() {
+    private QueryBuilder<MeasureQuery> buildInstanceRelationsQuery(String clientServiceId,
+                                                                   String serverServiceId) {
+        return new QueryBuilder<MeasureQuery>() {
             @Override
             protected void apply(MeasureQuery query) {
-                query.and(eq(ServiceInstanceRelationServerSideMetrics.SOURCE_SERVICE_ID, clientServiceId))
-                     .and(eq(ServiceInstanceRelationServerSideMetrics.DEST_SERVICE_ID, serverServiceId));
-            }
-        });
+                List<AbstractCriteria> instanceRelationsQueryConditions = new ArrayList<>(2);
 
-        queryBuilderList.add(new QueryBuilder<MeasureQuery>() {
-            @Override
-            protected void apply(MeasureQuery query) {
-                query.and(eq(ServiceInstanceRelationServerSideMetrics.DEST_SERVICE_ID, clientServiceId))
-                     .and(eq(ServiceInstanceRelationServerSideMetrics.SOURCE_SERVICE_ID, serverServiceId));
+                instanceRelationsQueryConditions.add(
+                        // source_service_id = clientServiceId AND dest_service_id = serverServiceId","[{'comment': 'What is this commented code about?', 'commenter': 'wu-sheng'}, {'comment': 'The comment describes the query condition below ', 'commenter': 'lujiajing1126'}]"
10181,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/measure/BanyanDBTopologyQueryDAO.java,"@@ -303,25 +300,35 @@ List<Call.CallDetail> queryProcessRelation(Duration duration,
             timestampRange = new TimestampRange(TimeBucket.getTimestamp(startTB), TimeBucket.getTimestamp(endTB));
         }
         final String modelName = detectPoint == DetectPoint.SERVER ? ProcessRelationServerSideMetrics.INDEX_NAME :
-            ProcessRelationClientSideMetrics.INDEX_NAME;
-        final Map<String, Call.CallDetail> callMap = new HashMap<>();
+                ProcessRelationClientSideMetrics.INDEX_NAME;
+
         MeasureQueryResponse resp = query(modelName,
-                                          ImmutableSet.of(
-                                              Metrics.ENTITY_ID, ProcessRelationClientSideMetrics.COMPONENT_ID),
-                                          Collections.emptySet(), timestampRange, new QueryBuilder<MeasureQuery>() {
-                @Override
-                protected void apply(MeasureQuery query) {
-                    query.and(eq(ProcessRelationServerSideMetrics.SERVICE_INSTANCE_ID, serviceInstanceId));
+                ImmutableSet.of(Metrics.ENTITY_ID, ProcessRelationClientSideMetrics.COMPONENT_ID),
+                Collections.emptySet(), timestampRange, new QueryBuilder<MeasureQuery>() {
+                    @Override
+                    protected void apply(MeasureQuery query) {
+                        query.and(eq(ProcessRelationServerSideMetrics.SERVICE_INSTANCE_ID, serviceInstanceId));
+                        query.groupBy(Sets.newHashSet(Metrics.ENTITY_ID, ProcessRelationServerSideMetrics.COMPONENT_ID));","[{'comment': ""* The HashSet doesn't maintain the order of tags. Could you opt for a sortable set instead? \r\n* Please add `component_id` to the measure's entity list. The order of tags in groupBy should match the order of entities. That will help improve the memory overhead"", 'commenter': 'hanahmily'}, {'comment': 'You mean mark component_id and entity_id with `@SeriesID`?', 'commenter': 'lujiajing1126'}, {'comment': ""Yes. But the component_id doesn't exist in process_relation. From https://github.com/apache/skywalking/pull/10181#discussion_r1051883005, we could remove component_id from groupBy's tag list."", 'commenter': 'hanahmily'}, {'comment': ""> Yes. But the component_id doesn't exist in process_relation. From [#10181 (comment)](https://github.com/apache/skywalking/pull/10181#discussion_r1051883005), we could remove component_id from groupBy's tag list.\r\n\r\nIt is `ProcessRelationServerSideMetrics.COMPONENT_ID`. I think we need this in groupBy @wu-sheng, right? "", 'commenter': 'lujiajing1126'}, {'comment': 'Oops, sorry.', 'commenter': 'wu-sheng'}]"
10181,oap-server/server-storage-plugin/storage-banyandb-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/banyandb/measure/BanyanDBTopologyQueryDAO.java,"@@ -74,43 +78,34 @@ public List<Call.CallDetail> loadServiceRelationDetectedAtClientSide(Duration du
             throw new UnexpectedException(""Service id is empty"");
         }
 
-        List<QueryBuilder<MeasureQuery>> queryBuilderList = buildServiceRelationsQueries(serviceIds);
+        QueryBuilder<MeasureQuery> queryBuilder = buildServiceRelationsQuery(serviceIds);
 
-        return queryServiceRelation(duration, queryBuilderList, DetectPoint.CLIENT);
+        return queryServiceRelation(duration, queryBuilder, DetectPoint.CLIENT);
     }
 
     @Override
     public List<Call.CallDetail> loadServiceRelationsDetectedAtServerSide(Duration duration) throws IOException {
-        return queryServiceRelation(duration, Collections.singletonList(emptyMeasureQuery()), DetectPoint.SERVER);
+        return queryServiceRelation(duration, emptyMeasureQuery(), DetectPoint.SERVER);
     }
 
     @Override
     public List<Call.CallDetail> loadServiceRelationDetectedAtClientSide(Duration duration) throws IOException {
-        return queryServiceRelation(duration, Collections.singletonList(emptyMeasureQuery()), DetectPoint.CLIENT);
+        return queryServiceRelation(duration, emptyMeasureQuery(), DetectPoint.CLIENT);
     }
 
-    private List<QueryBuilder<MeasureQuery>> buildServiceRelationsQueries(List<String> serviceIds) {
-        List<QueryBuilder<MeasureQuery>> queryBuilderList = new ArrayList<>(serviceIds.size());
-        for (final String serviceId : serviceIds) {
-            queryBuilderList.add(new QueryBuilder<MeasureQuery>() {
-                @Override
-                protected void apply(MeasureQuery query) {
-                    query.and(eq(ServiceRelationServerSideMetrics.SOURCE_SERVICE_ID, serviceId));
-                }
-            });
-
-            queryBuilderList.add(new QueryBuilder<MeasureQuery>() {
-                @Override
-                protected void apply(MeasureQuery query) {
-                    query.and(eq(ServiceRelationServerSideMetrics.DEST_SERVICE_ID, serviceId));
-                }
-            });
-        }
-        return queryBuilderList;
+    private QueryBuilder<MeasureQuery> buildServiceRelationsQuery(List<String> serviceIds) {
+        return new QueryBuilder<MeasureQuery>() {
+            @Override
+            protected void apply(MeasureQuery query) {
+                query.or(in(ServiceRelationServerSideMetrics.SOURCE_SERVICE_ID, serviceIds))
+                        .or(in(ServiceRelationServerSideMetrics.DEST_SERVICE_ID, serviceIds));
+                query.groupBy(Sets.newHashSet(Metrics.ENTITY_ID, ServiceRelationServerSideMetrics.COMPONENT_IDS));","[{'comment': 'The same as the comment left at line:311', 'commenter': 'hanahmily'}, {'comment': 'component id exists in service topology only, now.', 'commenter': 'wu-sheng'}, {'comment': 'Fixed', 'commenter': 'lujiajing1126'}, {'comment': 'Please use `@SeriesID` to mark `entity_id` and `component_id`', 'commenter': 'hanahmily'}, {'comment': ""Could you upload the service_relation_server_side and service_relation_client_side measure's schema here for double-checking?"", 'commenter': 'hanahmily'}, {'comment': ""They don't have `SeriesID` for now, please add them. `component_id` don't have to be a part of `SeriesID`, because they have chances to update when service IDs are not changed. \r\n\r\n@hanahmily Is that OK to keep it out of `SeriesID` but query them out as `group by`."", 'commenter': 'wu-sheng'}, {'comment': 'For update, this could be `ServA->ServB with component 1`, then update to `ServA->ServB with component 1,2,3`. \r\nThis is the same entity from OAP perspective.', 'commenter': 'wu-sheng'}, {'comment': ""I've added missing `@Series` to only `entity_id`."", 'commenter': 'lujiajing1126'}, {'comment': ""> Could you upload the service_relation_server_side and service_relation_client_side measure's schema here for double-checking?\r\n\r\nPasted in the comment"", 'commenter': 'lujiajing1126'}, {'comment': '> @hanahmily Is that OK to keep it out of `SeriesID` but query them out as `group by`.\r\n\r\nYes. It is possible. But `groupBy` with entityID(s) saves much memory according to the current implementation. If groupBy keys are not entityIDs, then hash-based physical plan will be generated. Probably we may still need `componentIDs` as a part of the entity? @hanahmily \r\n', 'commenter': 'lujiajing1126'}, {'comment': ""> For update, this could be `ServA->ServB with component 1`, then update to `ServA->ServB with component 1,2,3`. \n> \n> This is the same entity from OAP perspective.\n\n`GroupBy` will output two items in this scenario if the components ids is a part of the group key, whether it belongs to the seriesID or not. In other words, marking component ids as a part of seriesID affects the performance, not the semantics. \n\nIf this is the case, I don't see any side effects to adding component ids to seriesID."", 'commenter': 'hanahmily'}, {'comment': 'Annotations added', 'commenter': 'lujiajing1126'}]"
10282,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/requests/search/SearchParams.java,"@@ -59,6 +62,13 @@ public SearchParams scroll(Duration contextRetention) {
         return this;
     }
 
+    public SearchParams routing(String routing) {
+        checkArgument(StringUtil.isNotBlank(routing),
+                ""routing must not blank"");","[{'comment': '```suggestion\n                ""routing must be not blank"");\n```\n', 'commenter': 'kezhenxu94'}]"
10282,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/ElasticSearch.java,"@@ -97,4 +98,13 @@ enum AnalyzerType {
         String columnAlias();
 
     }
+
+    /**
+     * Routing is to identify which field in {@link Record} is providing the routing for ElasticSearch.","[{'comment': '```suggestion\r\n     * Routing defines a filed of {@link Record} to control the sharding policy.\r\n```', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/ElasticSearchModelExtension.java,"@@ -0,0 +1,33 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.storage.model;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.analysis.record.Record;
+
+public class ElasticSearchModelExtension {
+
+    /**
+     * Routing is to identify which field in {@link Record} is providing the routing for ElasticSearch.","[{'comment': 'Please update comments accordingly.', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/ElasticSearchModelExtension.java,"@@ -0,0 +1,33 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.storage.model;
+
+import lombok.Getter;
+import lombok.Setter;
+import org.apache.skywalking.oap.server.core.analysis.record.Record;
+
+public class ElasticSearchModelExtension {
+
+    /**
+     * Routing is to identify which field in {@link Record} is providing the routing for ElasticSearch.
+     */
+    @Getter
+    @Setter
+    private String routing;","[{'comment': 'We should have a setter method to limit this could be set once for a model.', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/annotation/ElasticSearch.java,"@@ -97,4 +98,13 @@ enum AnalyzerType {
         String columnAlias();
 
     }
+
+    /**
+     * Routing is to identify which field in {@link Record} is providing the routing for ElasticSearch.
+     */
+    @Target(ElementType.TYPE)
+    @Retention(RetentionPolicy.RUNTIME)
+    @interface Routing {","[{'comment': ""This could be a `field` annotation to ensure we don't have to define `value()` duplicated. And we don't verify this column exists."", 'commenter': 'wu-sheng'}]"
10282,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/zipkin/ZipkinQueryEsDAO.java,"@@ -236,7 +238,9 @@ public List<List<Span>> getTraces(final Set<String> traceIds) {
         BoolQueryBuilder query = Query.bool().must(Query.terms(ZipkinSpanRecord.TRACE_ID, new ArrayList<>(traceIds)));
         SearchBuilder search = Search.builder().query(query).sort(ZipkinSpanRecord.TIMESTAMP_MILLIS, Sort.Order.DESC)
                                      .size(SCROLLING_BATCH_SIZE); //max span size for 1 scroll
-        final SearchParams params = new SearchParams().scroll(SCROLL_CONTEXT_RETENTION);
+        final SearchParams params = new SearchParams()
+                .scroll(SCROLL_CONTEXT_RETENTION)
+                .routing(String.join("","", traceIds));","[{'comment': '@kezhenxu94 Could you check this?', 'commenter': 'wu-sheng'}, {'comment': 'One last thing, should we expose API as Iterable rather than a string?', 'commenter': 'wu-sheng'}, {'comment': 'as Iterable, the param logic more cohesive.\r\nI change it ', 'commenter': 'shichaoyuan'}]"
10282,docs/en/changes/changes.md,"@@ -78,6 +78,7 @@
 * Fix TCP service instances are lack of instance properties like `pod` and `namespace`, which causes Pod log not to work for TCP workloads.
 * Add Python HBase happybase module component ID(94).
 * Fix gRPC alarm cannot update settings from dynamic configuration source.
+* [**Breaking Change**] Optimize single trace query performance by customizing routing in ElasticSearch","[{'comment': '```suggestion\r\n* [**Breaking Change**] Optimize single trace query performance by customizing routing in ElasticSearch. SkyWalking trace segments and Zipkin spans are using trace ID for routing.\r\n```', 'commenter': 'wu-sheng'}, {'comment': ""So, does this breaking mean, the existing trace segments/spans are not searchable anymore? Due to the routing is changed, it most likely can't hit the records."", 'commenter': 'wu-sheng'}, {'comment': 'yes', 'commenter': 'shichaoyuan'}, {'comment': ""Correct me if I'm wrong, although you declare this is a breaking change, users can still use the storage from previous version (without any warnings / errors), but they won't be able to search old traces by trace id because the routing field is absent when indexing but the routing field is present when querying from UI, is that the case?"", 'commenter': 'kezhenxu94'}, {'comment': 'yes', 'commenter': 'shichaoyuan'}, {'comment': '@wu-sheng read this thread, I believe this would cause user confusions when they upgrade from an older release. ', 'commenter': 'kezhenxu94'}, {'comment': 'Yes, I had read so. What do you suggest? Do you suggest we intend to breaking something or somehow raise a warning?\nI believe this change is forward positive improvement. ', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/StorageModels.java,"@@ -98,6 +99,7 @@ public Model add(Class<?> aClass, int scopeId, Storage storage, boolean record)
         }
 
         checker.check(storage.getModelName());
+        elasticSearchModelExtension.setRouting(storage.getModelName(), modelColumns);","[{'comment': '```suggestion\r\n        // Set routing rules for ElasticSearch\r\n        elasticSearchModelExtension.setRouting(storage.getModelName(), modelColumns);\r\n        \r\n        checker.check(storage.getModelName());\r\n```\r\n\r\nThe codes should follow existing code style', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/storage/model/ElasticSearchModelExtension.java,"@@ -0,0 +1,57 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.storage.model;
+
+import lombok.Getter;
+import org.apache.skywalking.oap.server.core.analysis.record.Record;
+import org.apache.skywalking.oap.server.library.util.CollectionUtils;
+
+import java.util.List;
+import java.util.stream.Collectors;
+
+public class ElasticSearchModelExtension {
+
+    /**
+     * Routing defines a field of {@link Record} to control the sharding policy.
+     */
+    @Getter
+    private String routing;","[{'comment': 'This may be better as `Optional`. Because mostly this would not have value.', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/base/RoutingUtils.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.storage.plugin.elasticsearch.base;
+
+import org.apache.skywalking.oap.server.core.storage.model.Model;
+
+import java.util.Map;
+import java.util.Optional;
+
+public class RoutingUtils {
+
+    public static Optional<String> getRouting(final Model model, final Map<String, Object> builder) {
+        Optional<String> routingField = model.getElasticSearchModelExtension().getRouting();
+        return routingField.map(v -> extractRoutingValue(v, builder));","[{'comment': 'What does this `map` mean? `Optional` -> `map` -> `Optional` again?', 'commenter': 'wu-sheng'}, {'comment': '```\r\nif `routingField` is empty:\r\n    just return emtpy\r\nelse\r\n    apply process func, either empty or some(value)\r\n```\r\n\r\ncommon patterns of functional programming', 'commenter': 'shichaoyuan'}, {'comment': 'I know what is `map` function. I think what you are trying to process?', 'commenter': 'wu-sheng'}, {'comment': 'check if the value of routingFiled is presented.', 'commenter': 'shichaoyuan'}, {'comment': ""OK, I think I am following the logic now.\r\n\r\nBut this is actually wrong. Check `ElasticSearchConverter#ToStorage#accept`. \r\n\r\nYour change actually works because this only works as the entity don't merge. Trace segment and Zipkin span are not merging with others, but the codes should not be written in this way.\r\n\r\nYou should ensure `IndexRequest` includes this `routingValue`(Optional). You can't rely on the builder's key as column name as always."", 'commenter': 'wu-sheng'}]"
10282,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/requests/IndexRequest.java,"@@ -29,5 +31,7 @@ public final class IndexRequest {
     private final String index;
     private final String type;
     private final String id;
+    @Builder.Default
+    private final Optional<String> routing = Optional.empty();","[{'comment': 'This should be the routing value, rather than the routing column name.\r\n\r\nPlease follow https://github.com/apache/skywalking/pull/10282#discussion_r1071853153, and update this and add comments.', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/requests/IndexRequest.java,"@@ -29,5 +31,10 @@ public final class IndexRequest {
     private final String index;
     private final String type;
     private final String id;
+    /**
+     * the routing value to control the sharding policy
+     */
+    @Builder.Default
+    private final Optional<String> routing = Optional.empty();","[{'comment': '```suggestion\r\n    /**\r\n     * The routing value of the request.\r\n     */\r\n    @Builder.Default\r\n    private final Optional<String> routing;\r\n```\r\n\r\nI think with @Builder.Default, this should have value as always.\r\nhttps://stackoverflow.com/questions/35739670/what-is-the-default-for-optional-data-members-in-lombok-using-builder', 'commenter': 'wu-sheng'}, {'comment': ""https://projectlombok.org/features/Builder\r\n> If a certain field/parameter is never set during a build session, then it always gets 0 / null / false. If you've put @Builder on a class (and not a method or constructor) you can instead specify the default directly on the field, and annotate the field with @Builder.Default:\r\n@Builder.Default private final long created = System.currentTimeMillis();\r\n\r\nas official document, both operations require:\r\n1. specify the default directly on the field\r\n2. and annotate the field with @Builder.Default:"", 'commenter': 'shichaoyuan'}, {'comment': 'OK, then please update the comments only.', 'commenter': 'wu-sheng'}]"
10282,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/requests/factory/v6/codec/V6IndexRequestSerializer.java,"@@ -38,6 +38,9 @@ public void serialize(final IndexRequest value, final JsonGenerator gen,
                 gen.writeStringField(""_index"", value.getIndex());
                 gen.writeStringField(""_type"", value.getType());
                 gen.writeStringField(""_id"", value.getId());
+                if (value.getRouting().isPresent()) {
+                    gen.writeStringField(""routing"", value.getRouting().get());","[{'comment': 'Is the key `routing` or `_routing`? \r\nHave you tested whether the routing works? \r\nhttps://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-routing-field.html', 'commenter': 'wu-sheng'}, {'comment': 'I have tested.\r\n\r\n#### in _bulk api, routing in index\r\nhttps://www.elastic.co/guide/en/elasticsearch/reference/8.6/docs-bulk.html#bulk-routing\r\n\r\n#### in search api, routing in params.\r\nhttps://github.com/elastic/elasticsearch/blob/main/docs/reference/mapping/fields/routing-field.asciidoc#searching-with-custom-routing ', 'commenter': 'shichaoyuan'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -177,9 +185,20 @@ private CompletableFuture<Void> doFlush(final List<Holder> batch) {
         return future;
     }
 
+
+    private byte[] toByteArray (Object obj) throws IOException {","[{'comment': 'This seems a code format issue..', 'commenter': 'wu-sheng'}, {'comment': 'ok i fix it\r\n', 'commenter': 'chenhaipeng'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -94,14 +100,16 @@ public CompletableFuture<Void> add(UpdateRequest request) {
     private CompletableFuture<Void> internalAdd(Object request) {
         requireNonNull(request, ""request"");
         final CompletableFuture<Void> f = new CompletableFuture<>();
+        int len = toByteArray(request).length;","[{'comment': '@kezhenxu94 I have a little concern about the payload of this, which pushed a request to byte[] but only for length.', 'commenter': 'wu-sheng'}, {'comment': 'I am feeling we want this feature, we should somehow work with ElasticSearch client, rather than run serialization twice for a bulk.', 'commenter': 'wu-sheng'}, {'comment': 'In another word, we should make `sizeOfBytes` a protection mechanism rather than a flush mechanism. Add this into `BulkProcessor#doFlush` to control the final size of the HTTP request.\r\n\r\n@chenhaipeng What do you think?', 'commenter': 'wu-sheng'}, {'comment': 'i think so , where is it better to control sizeOfBytes？', 'commenter': 'chenhaipeng'}, {'comment': '> i think so , where is it better to control sizeOfBytes？\r\n\r\nIf a protection mechanism is added when sending, then an unpacking may be required, maybe which increase the complexity \r\n', 'commenter': 'chenhaipeng'}, {'comment': ""I think `BulkProcessor#doFlush` includes all logic you need. You should have everything you need for. I don't think you need to unpack from there. You only have to do is adding the mechanism to build one request(current) or more.\r\n\r\nFrom my understanding, this mechanism is to resolve too large an HTTP body issue, right?"", 'commenter': 'wu-sheng'}, {'comment': 'yes , this mechanism is to resolve too large an HTTP body', 'commenter': 'chenhaipeng'}, {'comment': 'Then, changing `BulkProcessor#doFlush` should be good enough and easy enough. Could you try that?', 'commenter': 'wu-sheng'}, {'comment': 'I use elasticsearch in the production environment，I solved it simply as above，but this problem may also occur with other storage type', 'commenter': 'chenhaipeng'}, {'comment': '> Then, changing `BulkProcessor#doFlush` should be good enough and easy enough. Could you try that?\r\n\r\nok ,i try it', 'commenter': 'chenhaipeng'}, {'comment': ""> I use elasticsearch in the production environment，I solved it simply as above，but this problem may also occur with other storage type\r\n\r\nThat is fine. We don't need to resolve an issue that doesn't happen(at least in some known scenarios). Let's focus on fixing this on ElasticSearch."", 'commenter': 'wu-sheng'}, {'comment': '> I use elasticsearch in the production environment，I solved it simply as above，but this problem may also occur with other storage type\r\n\r\ni fix it ,please check again', 'commenter': 'chenhaipeng'}, {'comment': '> yes , this mechanism is to resolve too large an HTTP body\r\n\r\nAs you set the default value to 5M, could you share what is the size limitation?', 'commenter': 'wu-sheng'}, {'comment': '> > yes , this mechanism is to resolve too large an HTTP body\r\n> \r\n> As you set the default value to 5M, could you share what is the size limitation?\r\n\r\nthere is elastic http limit ,Defaults to 100mb, I think it should not exceed 10m. Kafka has a similar limit of 10m.\r\nhttps://www.elastic.co/guide/en/elasticsearch/reference/7.17/modules-network.html#http-settings', 'commenter': 'chenhaipeng'}, {'comment': 'So, you are facing a 100m limitation? I am feeling 5m is very small, and if there are many tags/logs in the segment/log, we may flush a few data into the storage.', 'commenter': 'wu-sheng'}, {'comment': 'In a production environment, 5m is about 3000 per dimension. I think in extreme cases, with too many tags, it might cause oversized. It is reasonable to set 10m, https://cloud.tencent.com/document/product/845/56274', 'commenter': 'chenhaipeng'}, {'comment': '>  5m is about 3000 per dimension\r\n\r\nWhat does this mean?', 'commenter': 'wu-sheng'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -129,57 +135,79 @@ public void flush() {
 
         final List<Holder> batch = new ArrayList<>(requests.size());
         requests.drainTo(batch);
-
-        final CompletableFuture<Void> flush = doFlush(batch);
-        flush.whenComplete((ignored1, ignored2) -> semaphore.release());
-        flush.join();
-
+        final List<CompletableFuture<Void>> futures = doFlush(batch);
+        for (final CompletableFuture<Void> future : futures) {
+            future.join();
+        }
+        futures.stream().map(future -> future.join());","[{'comment': 'Are these duplicated?', 'commenter': 'wu-sheng'}]"
10287,docs/en/changes/changes.md,"@@ -78,6 +78,8 @@
 * Fix TCP service instances are lack of instance properties like `pod` and `namespace`, which causes Pod log not to work for TCP workloads.
 * Add Python HBase happybase module component ID(94).
 * Fix gRPC alarm cannot update settings from dynamic configuration source.
+* Elasticsearch storage: Support batchOfBytes configuration to set up the batch bytes size of the record data.","[{'comment': '```suggestion\r\n* Add `batchOfBytes` configuration to limit the size of bulk flush.\r\n```', 'commenter': 'wu-sheng'}]"
10287,docs/en/setup/backend/configuration-vocabulary.md,"@@ -106,6 +106,7 @@ The Configuration Vocabulary lists all available configurations provided by `app
 | -                       | -             | superDatasetIndexReplicasNumber                                                                                                                                          | Represents the replicas number in the super size dataset record index.                                                                                                                                                                                                                                                                                                                                                                                          | SW_STORAGE_ES_SUPER_DATASET_INDEX_REPLICAS_NUMBER | 0                                                                                            |
 | -                       | -             | indexTemplateOrder                                                                                                                                                       | The order of index template.                                                                                                                                                                                                                                                                                                                                                                                                                                    | SW_STORAGE_ES_INDEX_TEMPLATE_ORDER                | 0                                                                                            |
 | -                       | -             | bulkActions                                                                                                                                                              | Async bulk size of the record data batch execution.                                                                                                                                                                                                                                                                                                                                                                                                             | SW_STORAGE_ES_BULK_ACTIONS                        | 5000                                                                                         |
+| -                       | -              | batchOfBytes                                                                                                                                                             | Async bulk byte size of the record data batch execution，If the batch data is too large, it will be split into the specified size.default is 5M                                                                                                                                                                                                                                                                                                                            | SW_STORAGE_ES_BATCH_OF_BYTES                      | 5242880                                                                                      |","[{'comment': '```suggestion\r\n| -                       | -              | batchOfBytes                                                                                                                                                             | A threshold to control the max body size of ElasticSearch Bulk flush.                                                                                                                                                                                                                                                                                                                           | SW_STORAGE_ES_BATCH_OF_BYTES                      | 5242880                                                                                      |\r\n```', 'commenter': 'wu-sheng'}]"
10287,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/StorageModuleElasticsearchConfig.java,"@@ -88,6 +88,8 @@ public class StorageModuleElasticsearchConfig extends ModuleConfig {
      * @since 8.7.0 This setting affects all traces/logs/metrics/metadata flush policy.
      */
     private int bulkActions = 5000;
+
+    private int batchOfBytes = 1024 * 1024 * 5;","[{'comment': '```suggestion\r\n    /**\r\n     * @since 9.4.0 A threshold to control the max body size of ElasticSearch Bulk flush. \r\n     */\r\n    private int batchOfBytes = 1024 * 1024 * 5;\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'Please update the `application.yml` comments accordingly.', 'commenter': 'wu-sheng'}, {'comment': '> Please update the `application.yml` comments accordingly.\r\n\r\ndone', 'commenter': 'chenhaipeng'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -129,57 +135,76 @@ public void flush() {
 
         final List<Holder> batch = new ArrayList<>(requests.size());
         requests.drainTo(batch);
-
-        final CompletableFuture<Void> flush = doFlush(batch);
-        flush.whenComplete((ignored1, ignored2) -> semaphore.release());
-        flush.join();
-
+        final List<CompletableFuture<Void>> futures = doFlush(batch);
+        futures.stream().map(future -> future.join());
+        semaphore.release();
         lastFlushTS = System.currentTimeMillis();
     }
 
-    private CompletableFuture<Void> doFlush(final List<Holder> batch) {
+    private List<CompletableFuture<Void>> doFlush(final List<Holder> batch) {
         log.debug(""Executing bulk with {} requests"", batch.size());
-
         if (batch.isEmpty()) {
-            return CompletableFuture.completedFuture(null);
+            return Collections.emptyList();
         }
-
-        final CompletableFuture<Void> future = es.get().version().thenCompose(v -> {
-            try {
-                final RequestFactory rf = v.requestFactory();
-                final List<byte[]> bs = new ArrayList<>();
-                for (final Holder holder : batch) {
-                    bs.add(v.codec().encode(holder.request));
-                    bs.add(""\n"".getBytes());
+        try {
+            int bufferOfBytes = 0;
+            Codec codec = es.get().version().get().codec();
+            final List<byte[]> bs = new ArrayList<>();
+            List<CompletableFuture<Void>> futures = new ArrayList<>();
+            List<ByteBuf> byteBufList = new ArrayList<>();
+            for (final Holder holder : batch) {
+                byte[] bytes = codec.encode(holder.request);
+                bs.add(bytes);
+                bs.add(""\n"".getBytes());
+                bufferOfBytes += bytes.length;
+                if (bufferOfBytes > batchOfBytes) {","[{'comment': '```suggestion\r\n                if (bufferOfBytes >= batchOfBytes) {\r\n```', 'commenter': 'kezhenxu94'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -129,57 +135,76 @@ public void flush() {
 
         final List<Holder> batch = new ArrayList<>(requests.size());
         requests.drainTo(batch);
-
-        final CompletableFuture<Void> flush = doFlush(batch);
-        flush.whenComplete((ignored1, ignored2) -> semaphore.release());
-        flush.join();
-
+        final List<CompletableFuture<Void>> futures = doFlush(batch);
+        futures.stream().map(future -> future.join());
+        semaphore.release();
         lastFlushTS = System.currentTimeMillis();
     }
 
-    private CompletableFuture<Void> doFlush(final List<Holder> batch) {
+    private List<CompletableFuture<Void>> doFlush(final List<Holder> batch) {
         log.debug(""Executing bulk with {} requests"", batch.size());
-
         if (batch.isEmpty()) {
-            return CompletableFuture.completedFuture(null);
+            return Collections.emptyList();
         }
-
-        final CompletableFuture<Void> future = es.get().version().thenCompose(v -> {
-            try {
-                final RequestFactory rf = v.requestFactory();
-                final List<byte[]> bs = new ArrayList<>();
-                for (final Holder holder : batch) {
-                    bs.add(v.codec().encode(holder.request));
-                    bs.add(""\n"".getBytes());
+        try {
+            int bufferOfBytes = 0;
+            Codec codec = es.get().version().get().codec();
+            final List<byte[]> bs = new ArrayList<>();
+            List<CompletableFuture<Void>> futures = new ArrayList<>();
+            List<ByteBuf> byteBufList = new ArrayList<>();
+            for (final Holder holder : batch) {
+                byte[] bytes = codec.encode(holder.request);
+                bs.add(bytes);
+                bs.add(""\n"".getBytes());
+                bufferOfBytes += bytes.length;
+                if (bufferOfBytes > batchOfBytes) {
+                    final ByteBuf content = Unpooled.wrappedBuffer(bs.toArray(new byte[0][]));
+                    byteBufList.add(content);
+                    bs.clear();","[{'comment': '```suggestion\r\n                    bs.clear();\r\n                    bufferOfBytes = 0;\r\n```', 'commenter': 'kezhenxu94'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -129,57 +135,76 @@ public void flush() {
 
         final List<Holder> batch = new ArrayList<>(requests.size());
         requests.drainTo(batch);
-
-        final CompletableFuture<Void> flush = doFlush(batch);
-        flush.whenComplete((ignored1, ignored2) -> semaphore.release());
-        flush.join();
-
+        final List<CompletableFuture<Void>> futures = doFlush(batch);
+        futures.stream().map(future -> future.join());
+        semaphore.release();
         lastFlushTS = System.currentTimeMillis();
     }
 
-    private CompletableFuture<Void> doFlush(final List<Holder> batch) {
+    private List<CompletableFuture<Void>> doFlush(final List<Holder> batch) {
         log.debug(""Executing bulk with {} requests"", batch.size());
-
         if (batch.isEmpty()) {
-            return CompletableFuture.completedFuture(null);
+            return Collections.emptyList();
         }
-
-        final CompletableFuture<Void> future = es.get().version().thenCompose(v -> {
-            try {
-                final RequestFactory rf = v.requestFactory();
-                final List<byte[]> bs = new ArrayList<>();
-                for (final Holder holder : batch) {
-                    bs.add(v.codec().encode(holder.request));
-                    bs.add(""\n"".getBytes());
+        try {
+            int bufferOfBytes = 0;
+            Codec codec = es.get().version().get().codec();
+            final List<byte[]> bs = new ArrayList<>();
+            List<CompletableFuture<Void>> futures = new ArrayList<>();
+            List<ByteBuf> byteBufList = new ArrayList<>();
+            for (final Holder holder : batch) {
+                byte[] bytes = codec.encode(holder.request);
+                bs.add(bytes);
+                bs.add(""\n"".getBytes());
+                bufferOfBytes += bytes.length;
+                if (bufferOfBytes > batchOfBytes) {
+                    final ByteBuf content = Unpooled.wrappedBuffer(bs.toArray(new byte[0][]));
+                    byteBufList.add(content);
+                    bs.clear();
                 }
+            }
+            if (CollectionUtils.isNotEmpty(bs)) {
                 final ByteBuf content = Unpooled.wrappedBuffer(bs.toArray(new byte[0][]));
-                return es.get().client().execute(rf.bulk().bulk(content))
-                         .aggregate().thenAccept(response -> {
-                        final HttpStatus status = response.status();
-                        if (status != HttpStatus.OK) {
-                            throw new RuntimeException(response.contentUtf8());
-                        }
-                    });
-            } catch (Exception e) {
-                return Exceptions.throwUnsafely(e);
+                byteBufList.add(content);
             }
-        });
-        future.whenComplete((ignored, exception) -> {
-            if (exception != null) {
-                batch.stream().map(it -> it.future)
-                     .forEach(it -> it.completeExceptionally(exception));
-                log.error(""Failed to execute requests in bulk"", exception);
-            } else {
-                log.debug(""Succeeded to execute {} requests in bulk"", batch.size());
-                batch.stream().map(it -> it.future).forEach(it -> it.complete(null));
+            for (final ByteBuf content : byteBufList) {
+                CompletableFuture future = es.get().version().thenCompose(v -> {","[{'comment': '```suggestion\r\n                CompletableFuture<Void> future = es.get().version().thenCompose(v -> {\r\n```', 'commenter': 'kezhenxu94'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -129,57 +135,76 @@ public void flush() {
 
         final List<Holder> batch = new ArrayList<>(requests.size());
         requests.drainTo(batch);
-
-        final CompletableFuture<Void> flush = doFlush(batch);
-        flush.whenComplete((ignored1, ignored2) -> semaphore.release());
-        flush.join();
-
+        final List<CompletableFuture<Void>> futures = doFlush(batch);
+        futures.stream().map(future -> future.join());
+        semaphore.release();","[{'comment': '```suggestion\r\n\r\n        final List<CompletableFuture<Void>> futures = doFlush(batch);\r\n        final CompletableFuture<Void> future = CompletableFuture\r\n            .allOf(futures.toArray(new CompletableFuture[futures.size()]));\r\n        future.whenComplete((v, t) -> semaphore.release());\r\n        future.join();\r\n\r\n```', 'commenter': 'kezhenxu94'}]"
10287,oap-server/server-library/library-elasticsearch-client/src/main/java/org/apache/skywalking/library/elasticsearch/bulk/BulkProcessor.java,"@@ -129,57 +135,76 @@ public void flush() {
 
         final List<Holder> batch = new ArrayList<>(requests.size());
         requests.drainTo(batch);
-
-        final CompletableFuture<Void> flush = doFlush(batch);
-        flush.whenComplete((ignored1, ignored2) -> semaphore.release());
-        flush.join();
-
+        final List<CompletableFuture<Void>> futures = doFlush(batch);
+        futures.stream().map(future -> future.join());
+        semaphore.release();
         lastFlushTS = System.currentTimeMillis();
     }
 
-    private CompletableFuture<Void> doFlush(final List<Holder> batch) {
+    private List<CompletableFuture<Void>> doFlush(final List<Holder> batch) {
         log.debug(""Executing bulk with {} requests"", batch.size());
-
         if (batch.isEmpty()) {
-            return CompletableFuture.completedFuture(null);
+            return Collections.emptyList();
         }
-
-        final CompletableFuture<Void> future = es.get().version().thenCompose(v -> {
-            try {
-                final RequestFactory rf = v.requestFactory();
-                final List<byte[]> bs = new ArrayList<>();
-                for (final Holder holder : batch) {
-                    bs.add(v.codec().encode(holder.request));
-                    bs.add(""\n"".getBytes());
+        try {
+            int bufferOfBytes = 0;
+            Codec codec = es.get().version().get().codec();
+            final List<byte[]> bs = new ArrayList<>();
+            List<CompletableFuture<Void>> futures = new ArrayList<>();
+            List<ByteBuf> byteBufList = new ArrayList<>();
+            for (final Holder holder : batch) {
+                byte[] bytes = codec.encode(holder.request);
+                bs.add(bytes);
+                bs.add(""\n"".getBytes());
+                bufferOfBytes += bytes.length;","[{'comment': 'You need to also add the `\\n`\r\n\r\n```suggestion\r\n                bufferOfBytes += bytes.length + 1;\r\n```', 'commenter': 'kezhenxu94'}]"
10300,docs/en/setup/backend/aws-firehouse-receiver.md,"@@ -0,0 +1,21 @@
+# AWS Firehouse receiver
+
+AWS Firehouse receiver provides a HTTP Endpoint that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html).","[{'comment': '```suggestion\nAWS Firehouse receiver provides an HTTP Endpoint that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html).\n```\n', 'commenter': 'kezhenxu94'}]"
10300,oap-server/server-receiver-plugin/aws-firehose-receiver/pom.xml,"@@ -0,0 +1,41 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  ~
+  -->
+
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.skywalking</groupId>
+        <artifactId>server-receiver-plugin</artifactId>
+        <version>9.4.0-SNAPSHOT</version>
+    </parent>
+
+    <artifactId>aws-firehose-receiver</artifactId>","[{'comment': '```suggestion\n    <artifactId>aws-firehouse-receiver</artifactId>\n```\n', 'commenter': 'kezhenxu94'}, {'comment': '`hose` is correct. Others are wrong.', 'commenter': 'wu-sheng'}, {'comment': 'I know, I wrote the word. Happy new year', 'commenter': 'pg-yang'}]"
10300,oap-server/server-receiver-plugin/aws-firehose-receiver/src/main/java/org/apache/skywalking/oap/server/receiver/aws/firehose/FirehoseHTTPHandler.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.aws.firehose;
+
+import com.linecorp.armeria.server.annotation.ConsumesJson;
+import com.linecorp.armeria.server.annotation.Post;
+import com.linecorp.armeria.server.annotation.ProducesJson;
+import io.grpc.stub.StreamObserver;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceRequest;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceResponse;
+import io.opentelemetry.proto.metrics.v1.ResourceMetrics;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.util.Base64;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.receiver.otel.otlp.OpenTelemetryMetricHandlerExporter;
+
+@Slf4j
+public class FirehoseHTTPHandler {
+
+    private final OpenTelemetryMetricHandlerExporter openTelemetryMetricHandlerExporter;
+
+    private static final StreamObserver<ExportMetricsServiceResponse> STREAM_OBSERVER = new StreamObserver<ExportMetricsServiceResponse>() {
+        @Override
+        public void onNext(final ExportMetricsServiceResponse exportMetricsServiceResponse) {
+        }
+
+        @Override
+        public void onError(final Throwable throwable) {
+        }
+
+        @Override
+        public void onCompleted() {
+        }
+    };
+
+    public FirehoseHTTPHandler(final OpenTelemetryMetricHandlerExporter openTelemetryMetricHandlerExporter) {
+        this.openTelemetryMetricHandlerExporter = openTelemetryMetricHandlerExporter;
+    }","[{'comment': 'Use Lombok annotation to replace this constructor', 'commenter': 'kezhenxu94'}]"
10300,oap-server/server-starter/pom.xml,"@@ -171,6 +171,11 @@
             <artifactId>skywalking-telegraf-receiver-plugin</artifactId>
             <version>${project.version}</version>
         </dependency>
+        <dependency>
+            <groupId>org.apache.skywalking</groupId>
+            <artifactId>aws-firehose-receiver</artifactId>","[{'comment': 'You should update dependencies and licenses, as new jars are added.', 'commenter': 'wu-sheng'}, {'comment': ' Dependencies and licenses?  `aws-firehose-receiver` is a new module of SkyWalking, and it only depends on `otel-receiver-plugin`. Please tell me where I should update.', 'commenter': 'pg-yang'}, {'comment': ""I saw dependencies check fails, if you don't add new dependencies, then we need to check why CI fails."", 'commenter': 'wu-sheng'}]"
10300,oap-server/server-receiver-plugin/otel-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/otel/OtelMetricReceiverProvider.java,"@@ -72,12 +82,10 @@ public void start() throws ServiceNotProvidedException, ModuleStartException {
             .provider()
             .getService(GRPCHandlerRegister.class);
         final MeterSystem meterSystem = getManager().find(CoreModule.NAME).provider().getService(MeterSystem.class);
-        final List<Handler> handlers =
-            Handler.all().stream()
-                .filter(h -> config.getEnabledHandlers().contains(h.type()))
-                .collect(toList());
-        for (Handler h : handlers) {
-            h.active(config, meterSystem, grpcHandlerRegister);
+        for (Handler handler : this.handlers) {
+            if (config.getEnabledHandlers().contains(handler.type())) {
+                handler.active(config, meterSystem, grpcHandlerRegister);
+            }","[{'comment': 'Why do you need this change? This is a breaking change that cause user-defined handlers not to work anymore ', 'commenter': 'kezhenxu94'}, {'comment': 'Sorry, I want to export `OpenTelemetryMetricHandler` as a service `OpenTelemetryMetricHandlerExporter`.\r\nHow about I put `Handler.all()` to prepare stage, and ` handler.active` to start stage?\r\n', 'commenter': 'pg-yang'}, {'comment': 'I think you should move part of `OpenTelemetryMetricHandler` logic out of it for reuse, rather than export a handler.\r\nHanlder could stay for RPC relative logic only.', 'commenter': 'wu-sheng'}, {'comment': 'I moved the logic to  `OpenTelemetryMetricRequestProcessor`\r\n', 'commenter': 'pg-yang'}]"
10300,oap-server/server-receiver-plugin/aws-firehose-receiver/src/main/java/org/apache/skywalking/oap/server/receiver/aws/firehose/FirehoseHTTPHandler.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.aws.firehose;
+
+import com.linecorp.armeria.server.annotation.ConsumesJson;
+import com.linecorp.armeria.server.annotation.Post;
+import com.linecorp.armeria.server.annotation.ProducesJson;
+import io.grpc.stub.StreamObserver;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceRequest;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceResponse;
+import io.opentelemetry.proto.metrics.v1.ResourceMetrics;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.util.Base64;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.receiver.otel.otlp.OpenTelemetryMetricHandlerExporter;
+
+@Slf4j
+public class FirehoseHTTPHandler {
+
+    private final OpenTelemetryMetricHandlerExporter openTelemetryMetricHandlerExporter;
+
+    private static final StreamObserver<ExportMetricsServiceResponse> STREAM_OBSERVER = new StreamObserver<ExportMetricsServiceResponse>() {
+        @Override
+        public void onNext(final ExportMetricsServiceResponse exportMetricsServiceResponse) {
+        }
+
+        @Override
+        public void onError(final Throwable throwable) {
+        }
+
+        @Override
+        public void onCompleted() {
+        }
+    };
+
+    public FirehoseHTTPHandler(final OpenTelemetryMetricHandlerExporter openTelemetryMetricHandlerExporter) {
+        this.openTelemetryMetricHandlerExporter = openTelemetryMetricHandlerExporter;
+    }
+
+    @Post(""/aws/firehose/metrics"")
+    @ConsumesJson
+    @ProducesJson
+    public FirehouseRes collectMetrics(final FirehouseReq firehouseReq) {
+        final ExportMetricsServiceRequest.Builder builder = ExportMetricsServiceRequest.newBuilder();
+        try {
+            for (RequestData record : firehouseReq.getRecords()) {
+                final ByteArrayInputStream byteInputStream = new ByteArrayInputStream(
+                    Base64.getDecoder().decode(record.getData()));
+                skipVarIntBytes(byteInputStream);
+                builder.addResourceMetrics(ResourceMetrics.parseFrom(byteInputStream));
+            }
+        } catch (IOException e) {
+            log.warn(""Only OpenTelemetry format is accepted"", e);
+            return new FirehouseRes(firehouseReq.getRequestId(), System.currentTimeMillis(),
+                                    ""Only OpenTelemetry format is accepted"");
+        }
+        openTelemetryMetricHandlerExporter.export(builder.build(), STREAM_OBSERVER);
+        return new FirehouseRes(firehouseReq.getRequestId(), System.currentTimeMillis(), null);
+
+    }
+
+    private static void skipVarIntBytes(final ByteArrayInputStream byteInputStream) {","[{'comment': 'Why is there a method for skipping `VarInt`? This seems strange.', 'commenter': 'wu-sheng'}, {'comment': 'The record starts with `VarInt` to indicate the data length in bytes, so I skip the bytes which are `VarInt`, the remaining bytes could be parsed to `ResourceMetrics`', 'commenter': 'pg-yang'}, {'comment': '<img width=""891"" alt=""image"" src=""https://user-images.githubusercontent.com/5441976/213861470-19bfb853-8801-44d0-ab5e-72b77af6c2f7.png"">\r\n\r\nAccording to this, we should\r\n1. Read the length as N\r\n2. Decode the following N bytes from the stream\r\n3. Back to <1> if the stream is not ended. \r\n\r\nBut currently, the implementation seems to assume there is only one ExportMetricsServiceRequest per stream, is this correct?', 'commenter': 'wu-sheng'}, {'comment': ""Yep, I'm wrong."", 'commenter': 'pg-yang'}]"
10300,docs/en/setup/backend/aws-firehose-receiver.md,"@@ -0,0 +1,21 @@
+# AWS Firehose receiver
+
+AWS Firehose receiver listen `127.0.0.1:13800` by default, and provides an HTTP Endpoint `/aws/firehose/metrics` that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)","[{'comment': 'As a k8s oriented setup, we should listen on 0.0.0.0.\n\n```suggestion\nAWS Firehose receiver listens on `0.0.0.0:13800` by default, and provides an HTTP Endpoint `/aws/firehose/metrics` that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)\n```\n', 'commenter': 'wu-sheng'}]"
10300,docs/en/setup/backend/aws-firehose-receiver.md,"@@ -0,0 +1,21 @@
+# AWS Firehose receiver
+
+AWS Firehose receiver listen `127.0.0.1:13800` by default, and provides an HTTP Endpoint `/aws/firehose/metrics` that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)
+You could leverage the receiver to collect [AWS CloudWatch metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html), and analysis it through [MAL](../../concepts-and-designs/mal.md) as the receiver bases on [OpenTelemetry receiver](./opentelemetry-receiver.md)
+
+## Setup(S3 example)
+
+1. Create CloudWatch metrics configuration for S3 (refer to [S3 CloudWatch metrics](https://docs.aws.amazon.com/AmazonS3/latest/userguide/configure-request-metrics-bucket.html)) 
+2. Stream CloudWatch metrics to AWS Kinesis Data Firehose delivery stream by [CloudWatch metrics stream](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-setup-datalake.html)
+3. Specify AWS Kinesis Data Firehose delivery stream HTTP Endpoint (refer to [Choose HTTP Endpoint for Your Destination](https://docs.aws.amazon.com/firehose/latest/dev/create-destination.html#create-destination-http))
+
+Usually, the [AWS CloudWatch metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html) process flow with OAP is as follows:
+```
+CloudWatch metrics with S3 -->  CloudWatch Metric Stream (OpenTelemetry formart) --> Kinesis Data Firehose Delivery Stream --> AWS Firehose receiver(OAP) --> OpenTelemetry receiver(OAP)
+```
+
+## Notice
+
+1. Only OpenTelemetry format is supported (refer to [Metric streams output formats](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-formats.html))
+2. Doesn't support HTTP Headers - Content-Encoding","[{'comment': ""```suggestion\n2. Don't support HTTP Headers - Content-Encoding\n```\n"", 'commenter': 'wu-sheng'}, {'comment': 'What does this mean? Where and how  could users setup this?', 'commenter': 'wu-sheng'}, {'comment': ""Our HTTPServer doesn't support Content-Encoding such as gzip,  the issue could be resolved through `ServerBuilder#decorator(DecodingService.newDecorator())`, I will submit it later"", 'commenter': 'pg-yang'}, {'comment': 'OK, got it. Felt strange when read this.', 'commenter': 'wu-sheng'}]"
10300,docs/en/setup/backend/aws-firehose-receiver.md,"@@ -0,0 +1,21 @@
+# AWS Firehose receiver
+
+AWS Firehose receiver listen `127.0.0.1:13800` by default, and provides an HTTP Endpoint `/aws/firehose/metrics` that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)
+You could leverage the receiver to collect [AWS CloudWatch metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html), and analysis it through [MAL](../../concepts-and-designs/mal.md) as the receiver bases on [OpenTelemetry receiver](./opentelemetry-receiver.md)
+
+## Setup(S3 example)","[{'comment': 'We will have a more specific doc for s3, right?', 'commenter': 'wu-sheng'}, {'comment': 'Yep, this doc introduces how the receiver works in common way,  S3 (or other AWS service) metrics doc should be provided in itself PR', 'commenter': 'pg-yang'}]"
10300,docs/en/setup/backend/aws-firehose-receiver.md,"@@ -0,0 +1,21 @@
+# AWS Firehose receiver
+
+AWS Firehose receiver listen `127.0.0.1:13800` by default, and provides an HTTP Endpoint `/aws/firehose/metrics` that follows [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)
+You could leverage the receiver to collect [AWS CloudWatch metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html), and analysis it through [MAL](../../concepts-and-designs/mal.md) as the receiver bases on [OpenTelemetry receiver](./opentelemetry-receiver.md)
+
+## Setup(S3 example)
+
+1. Create CloudWatch metrics configuration for S3 (refer to [S3 CloudWatch metrics](https://docs.aws.amazon.com/AmazonS3/latest/userguide/configure-request-metrics-bucket.html)) 
+2. Stream CloudWatch metrics to AWS Kinesis Data Firehose delivery stream by [CloudWatch metrics stream](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-setup-datalake.html)
+3. Specify AWS Kinesis Data Firehose delivery stream HTTP Endpoint (refer to [Choose HTTP Endpoint for Your Destination](https://docs.aws.amazon.com/firehose/latest/dev/create-destination.html#create-destination-http))
+
+Usually, the [AWS CloudWatch metrics](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/working_with_metrics.html) process flow with OAP is as follows:
+```
+CloudWatch metrics with S3 -->  CloudWatch Metric Stream (OpenTelemetry formart) --> Kinesis Data Firehose Delivery Stream --> AWS Firehose receiver(OAP) --> OpenTelemetry receiver(OAP)
+```
+
+## Notice
+
+1. Only OpenTelemetry format is supported (refer to [Metric streams output formats](https://docs.aws.amazon.com/AmazonCloudWatch/latest/monitoring/CloudWatch-metric-streams-formats.html))
+2. Doesn't support HTTP Headers - Content-Encoding
+3. Only HTTPS could be accepted, you could directly enable TSL and set the receiver to listen 443, or put the receiver behind a gateway with HTTPS (refer to [Amazon Kinesis Data Firehose Delivery Stream HTTP Endpoint Delivery Specifications](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html))","[{'comment': 'Is 443 or 13800 expected to set? I found inconsistent in the doc', 'commenter': 'wu-sheng'}, {'comment': 'The default port is `13800`. But if users want to directly use the receiver, they have to set the port to 443, because of require of AWS', 'commenter': 'pg-yang'}]"
10300,oap-server/server-receiver-plugin/aws-firehose-receiver/src/main/java/org/apache/skywalking/oap/server/receiver/aws/firehose/FirehoseHTTPHandler.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.aws.firehose;
+
+import com.linecorp.armeria.server.annotation.ConsumesJson;
+import com.linecorp.armeria.server.annotation.Post;
+import com.linecorp.armeria.server.annotation.ProducesJson;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceRequest;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.util.Base64;
+import lombok.AllArgsConstructor;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.receiver.otel.otlp.OpenTelemetryMetricRequestProcessor;
+
+@Slf4j
+@AllArgsConstructor
+public class FirehoseHTTPHandler {
+    @Post(""/aws/firehose/metrics"")
+    @ConsumesJson
+    @ProducesJson
+    public FirehoseRes collectMetrics(final FirehoseReq firehoseReq) {
+        try {
+            for (RequestData record : firehoseReq.getRecords()) {
+                final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(
+                    Base64.getDecoder().decode(record.getData()));
+                ExportMetricsServiceRequest request;
+                while ((request = ExportMetricsServiceRequest.parseDelimitedFrom(byteArrayInputStream)) != null) {
+                    OpenTelemetryMetricRequestProcessor.INSTANCE.processMetricsRequest(request);","[{'comment': 'It is a processor, why we need a singleton?', 'commenter': 'wu-sheng'}]"
10300,oap-server/server-receiver-plugin/aws-firehose-receiver/src/main/java/org/apache/skywalking/oap/server/receiver/aws/firehose/AWSFirehoseReceiverModuleProvider.java,"@@ -0,0 +1,99 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.receiver.aws.firehose;
+
+import com.linecorp.armeria.common.HttpMethod;
+import java.util.Collections;
+import org.apache.skywalking.oap.server.library.module.ModuleDefine;
+import org.apache.skywalking.oap.server.library.module.ModuleProvider;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.module.ServiceNotProvidedException;
+import org.apache.skywalking.oap.server.library.server.http.HTTPServer;
+import org.apache.skywalking.oap.server.library.server.http.HTTPServerConfig;
+import org.apache.skywalking.oap.server.receiver.otel.OtelMetricReceiverModule;
+
+public class AWSFirehoseReceiverModuleProvider extends ModuleProvider {
+    public static final String NAME = ""default"";
+
+    private AWSFirehoseReceiverModuleConfig moduleConfig;
+    private HTTPServer httpServer;
+
+    @Override
+    public String name() {
+        return NAME;
+    }
+
+    @Override
+    public Class<? extends ModuleDefine> module() {
+        return AWSFirehoseReceiverModule.class;
+    }
+
+    @Override
+    public ConfigCreator<AWSFirehoseReceiverModuleConfig> newConfigCreator() {
+        return new ConfigCreator<AWSFirehoseReceiverModuleConfig>() {
+            @Override
+            public Class<AWSFirehoseReceiverModuleConfig> type() {
+                return AWSFirehoseReceiverModuleConfig.class;
+            }
+
+            @Override
+            public void onInitialized(final AWSFirehoseReceiverModuleConfig initialized) {
+                moduleConfig = initialized;
+            }
+        };
+    }
+
+    @Override
+    public void prepare() throws ServiceNotProvidedException {
+        final HTTPServerConfig httpServerConfig = HTTPServerConfig.builder().host(moduleConfig.getHost())
+                                                                  .port(moduleConfig.getPort())
+                                                                  .contextPath(moduleConfig.getContextPath())
+                                                                  .maxThreads(moduleConfig.getMaxThreads())
+                                                                  .idleTimeOut(moduleConfig.getIdleTimeOut())
+                                                                  .acceptQueueSize(moduleConfig.getAcceptQueueSize())
+                                                                  .maxRequestHeaderSize(
+                                                                      moduleConfig.getMaxRequestHeaderSize())
+                                                                  .enableTLS(moduleConfig.isEnableTLS())
+                                                                  .tlsKeyPath(moduleConfig.getTlsKeyPath())
+                                                                  .tlsCertChainPath(moduleConfig.getTlsCertChainPath())
+                                                                  .build();
+        httpServer = new HTTPServer(httpServerConfig);
+        httpServer.initialize();
+    }
+
+    @Override
+    public void start() throws ServiceNotProvidedException, ModuleStartException {
+        httpServer.addHandler(
+            new FirehoseHTTPHandler(),
+            Collections.singletonList(HttpMethod.POST)
+        );
+    }
+
+    @Override
+    public void notifyAfterCompleted() throws ServiceNotProvidedException, ModuleStartException {
+        httpServer.start();
+    }
+
+    @Override
+    public String[] requiredModules() {
+        return new String[] {
+            OtelMetricReceiverModule.NAME","[{'comment': 'As you have decleared dependencies, please expose the otel processor as a service, and use in awsreceiver.', 'commenter': 'wu-sheng'}]"
10300,oap-server/server-receiver-plugin/otel-receiver-plugin/src/main/java/org/apache/skywalking/oap/server/receiver/otel/otlp/OpenTelemetryMetricRequestProcessor.java,"@@ -0,0 +1,255 @@
+/*
+ *  Licensed to the Apache Software Foundation (ASF) under one or more
+ *  contributor license agreements.  See the NOTICE file distributed with
+ *  this work for additional information regarding copyright ownership.
+ *  The ASF licenses this file to You under the Apache License, Version 2.0
+ *  (the ""License""); you may not use this file except in compliance with
+ *  the License.  You may obtain a copy of the License at
+ *
+ *       http://www.apache.org/licenses/LICENSE-2.0
+ *
+ *  Unless required by applicable law or agreed to in writing, software
+ *  distributed under the License is distributed on an ""AS IS"" BASIS,
+ *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ *  See the License for the specific language governing permissions and
+ *  limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.otel.otlp;
+
+import com.google.common.base.Splitter;
+import com.google.common.collect.ImmutableMap;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceRequest;
+import io.opentelemetry.proto.common.v1.KeyValue;
+import io.opentelemetry.proto.metrics.v1.Sum;
+import io.opentelemetry.proto.metrics.v1.SummaryDataPoint;
+import io.vavr.Function1;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.function.Function;
+import java.util.stream.Stream;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.meter.analyzer.MetricConvert;
+import org.apache.skywalking.oap.meter.analyzer.prometheus.PrometheusMetricConverter;
+import org.apache.skywalking.oap.meter.analyzer.prometheus.rule.Rule;
+import org.apache.skywalking.oap.meter.analyzer.prometheus.rule.Rules;
+import org.apache.skywalking.oap.server.core.analysis.meter.MeterSystem;
+import org.apache.skywalking.oap.server.library.module.ModuleStartException;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Counter;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Gauge;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Histogram;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Metric;
+import org.apache.skywalking.oap.server.library.util.prometheus.metrics.Summary;
+
+import static io.opentelemetry.proto.metrics.v1.AggregationTemporality.AGGREGATION_TEMPORALITY_CUMULATIVE;
+import static java.util.stream.Collectors.toList;
+import static java.util.stream.Collectors.toMap;
+
+@Slf4j
+public class OpenTelemetryMetricRequestProcessor {","[{'comment': 'This could be an service and only initialized once only in otel provider.', 'commenter': 'wu-sheng'}]"
10300,oap-server/server-receiver-plugin/aws-firehose-receiver/src/main/java/org/apache/skywalking/oap/server/receiver/aws/firehose/FirehoseHTTPHandler.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *      http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.skywalking.oap.server.receiver.aws.firehose;
+
+import com.linecorp.armeria.server.annotation.ConsumesJson;
+import com.linecorp.armeria.server.annotation.Post;
+import com.linecorp.armeria.server.annotation.ProducesJson;
+import io.opentelemetry.proto.collector.metrics.v1.ExportMetricsServiceRequest;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.util.Base64;
+import lombok.AllArgsConstructor;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.skywalking.oap.server.receiver.otel.otlp.OpenTelemetryMetricRequestProcessor;
+
+@Slf4j
+@AllArgsConstructor
+public class FirehoseHTTPHandler {
+    @Post(""/aws/firehose/metrics"")
+    @ConsumesJson
+    @ProducesJson
+    public FirehoseRes collectMetrics(final FirehoseReq firehoseReq) {
+        try {
+            for (RequestData record : firehoseReq.getRecords()) {
+                final ByteArrayInputStream byteArrayInputStream = new ByteArrayInputStream(
+                    Base64.getDecoder().decode(record.getData()));
+                ExportMetricsServiceRequest request;
+                while ((request = ExportMetricsServiceRequest.parseDelimitedFrom(byteArrayInputStream)) != null) {
+                    OpenTelemetryMetricRequestProcessor.INSTANCE.processMetricsRequest(request);
+                }
+            }
+        } catch (IOException e) {
+            log.warn(""Only OpenTelemetry format is accepted"", e);
+            return new FirehoseRes(firehoseReq.getRequestId(), System.currentTimeMillis(),
+                                   ""Only OpenTelemetry format is accepted""","[{'comment': ""In such case I don't think you want to return an error to AWS, they will retry to send the same records later according to their spec. You need to just omit the records and return a success. \n\n> In all error cases the Kinesis Data Firehose server reattempts delivery of the same batch of records using an exponential back-off algorithm."", 'commenter': 'kezhenxu94'}, {'comment': ""It still should return an error, as if the retries are exhausted, the message could be backup to S3. We shouldn't discard any message.\r\n\r\n>  For failed requests, a message explaining the failure.\r\n      If a request fails after exhausting all retries, the last \r\n      Instance of the error message is copied to error output\r\n      S3 bucket if configured."", 'commenter': 'pg-yang'}]"
10302,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/http/HTTPServer.java,"@@ -107,15 +149,51 @@ public void addHandler(Object handler, List<HttpMethod> httpMethods) {
             ""Bind handler {} into http server {}:{}"",
             handler.getClass().getSimpleName(), config.getHost(), config.getPort()
         );
-
+        if (config.isEnableTLS()) {
+            handlers.add(handler);
+        }
         sb.annotatedService()
           .pathPrefix(config.getContextPath())
           .build(handler);
         this.allowedMethods.addAll(httpMethods);
     }
 
+    public void updateCert() {
+        FileTime lastModifiedTimeCertNow;
+        FileTime lastModifiedTimeKeyNow;
+        try {
+            lastModifiedTimeCertNow = Files.getLastModifiedTime(tlsCertChainPath);
+            lastModifiedTimeKeyNow = Files.getLastModifiedTime(tlsKeyPath);
+        } catch (IOException e) {
+            throw new RuntimeException(e);
+        }
+        if (lastModifiedTimeCertNow.equals(lastModifiedTimeCert)
+                && lastModifiedTimeKeyNow.equals(lastModifiedTimeKey)) {
+            return;
+        }
+        log.info(""TLS cert chain file or TLS key file has been updated, reloading..."");
+        httpServer.reconfigure(sb -> {
+            try (InputStream cert = new FileInputStream(tlsCertChainPath.toFile());
+                 InputStream key = PrivateKeyUtil.loadDecryptionKey(tlsKeyPath.toString())) {
+                sb.tls(cert, key);
+            } catch (IOException e) {
+                throw new IllegalArgumentException(e);
+            }
+            normalInitialize(sb);
+            sb.annotatedService()
+              .pathPrefix(config.getContextPath())
+              .build(handlers.toArray());
+        });
+        lastModifiedTimeCert = lastModifiedTimeCertNow;
+        lastModifiedTimeKey = lastModifiedTimeKeyNow;
+    }
+
     @Override
     public void start() {
-        sb.build().start().join();
+        httpServer = sb.build();
+        httpServer.start().join();
+        if (config.isEnableTLS()) {
+            scheduledExecutorService.schedule(this::updateCert, 10, TimeUnit.SECONDS);","[{'comment': 'Reuse the existing classes please https://github.com/apache/skywalking/blob/master/oap-server/server-library/library-util/src/main/java/org/apache/skywalking/oap/server/library/util/MultipleFilesChangeMonitor.java', 'commenter': 'kezhenxu94'}]"
10302,oap-server/server-library/library-server/src/main/java/org/apache/skywalking/oap/server/library/server/http/HTTPServer.java,"@@ -107,15 +149,51 @@ public void addHandler(Object handler, List<HttpMethod> httpMethods) {
             ""Bind handler {} into http server {}:{}"",
             handler.getClass().getSimpleName(), config.getHost(), config.getPort()
         );
-
+        if (config.isEnableTLS()) {
+            handlers.add(handler);
+        }
         sb.annotatedService()
           .pathPrefix(config.getContextPath())
           .build(handler);
         this.allowedMethods.addAll(httpMethods);
     }
 
+    public void updateCert() {
+        FileTime lastModifiedTimeCertNow;
+        FileTime lastModifiedTimeKeyNow;
+        try {
+            lastModifiedTimeCertNow = Files.getLastModifiedTime(tlsCertChainPath);
+            lastModifiedTimeKeyNow = Files.getLastModifiedTime(tlsKeyPath);
+        } catch (IOException e) {
+            throw new RuntimeException(e);
+        }
+        if (lastModifiedTimeCertNow.equals(lastModifiedTimeCert)
+                && lastModifiedTimeKeyNow.equals(lastModifiedTimeKey)) {
+            return;
+        }
+        log.info(""TLS cert chain file or TLS key file has been updated, reloading..."");
+        httpServer.reconfigure(sb -> {
+            try (InputStream cert = new FileInputStream(tlsCertChainPath.toFile());
+                 InputStream key = PrivateKeyUtil.loadDecryptionKey(tlsKeyPath.toString())) {
+                sb.tls(cert, key);
+            } catch (IOException e) {
+                throw new IllegalArgumentException(e);
+            }
+            normalInitialize(sb);
+            sb.annotatedService()
+              .pathPrefix(config.getContextPath())
+              .build(handlers.toArray());","[{'comment': ""Can you confirm this is needed when we only want to reconfigure the tls cert? I think Armeria will maintain the existing service endpoint if we didn't add new or remove existing service. "", 'commenter': 'kezhenxu94'}, {'comment': '`reconfigure` method will creat a new ServerBuild. So I think it is needed.\r\n![image](https://user-images.githubusercontent.com/74546965/214071296-4489a8df-caab-4d82-afbc-bb2ef577edbb.png)\r\n![image](https://user-images.githubusercontent.com/74546965/214071354-9cd61611-7bb6-4681-a5fb-dc4033673b7e.png)\r\n', 'commenter': 'yswdqz'}, {'comment': '`sb.buildServerConfig(config())` only set the host and port.\r\n\r\n[unit test of Armeria](https://github.com/line/armeria/blob/871d87297e4d051241589cb1ae95641cbc83f880/core/src/test/java/com/linecorp/armeria/client/ReconfigurableServerTest.java#L120) can also prove it.', 'commenter': 'yswdqz'}]"
10420,oap-server/server-core/src/main/java/org/apache/skywalking/oap/server/core/analysis/metrics/CPM5DecimalsMetrics.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis.metrics;
+
+import org.apache.skywalking.oap.server.core.analysis.metrics.annotation.MetricsFunction;
+
+@MetricsFunction(functionName = ""cpm5d"")
+public abstract class CPM5DecimalsMetrics extends CPMMetrics implements LongValueHolder {
+
+    @Override
+    public void calculate() {
+        this.setValue((this.getTotal() * 100000) / getDurationInMinute());","[{'comment': '```suggestion\r\n        this.setValue((this.getTotal() * 100_000) / getDurationInMinute());\r\n```', 'commenter': 'wu-sheng'}, {'comment': 'Applied. Thanks for the suggestion.', 'commenter': 'toffentoffen'}]"
10420,oap-server/server-core/src/test/java/org/apache/skywalking/oap/server/core/analysis/metrics/CPM5DecimalsMetricsTest.java,"@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.analysis.metrics;
+
+import org.apache.skywalking.oap.server.core.remote.grpc.proto.RemoteData;
+import org.apache.skywalking.oap.server.core.storage.StorageID;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
+
+public class CPM5DecimalsMetricsTest {
+
+    public static final long TIME_BUCKET = 2015_11_07_1130L;","[{'comment': 'Does this date look familiar to anyone?', 'commenter': 'toffentoffen'}]"
10420,oap-server/server-starter/src/main/resources/oal/core.oal,"@@ -19,15 +19,15 @@
 // Service scope metrics
 service_resp_time = from(Service.latency).longAvg();
 service_sla = from(Service.*).percent(status == true);
-service_cpm = from(Service.*).cpm();
+service_cpm = from(Service.*).cpm5d();","[{'comment': ""```suggestion\r\nservice_cpm5d = from(Service.*).cpm5d();\r\n```\r\n\r\nLet's follow this to update settings. @wankai123 Once this is merged, Grafana setup should be updated according on showcase."", 'commenter': 'wu-sheng'}]"
10423,docs/en/changes/changes.md,"@@ -104,6 +104,7 @@
 * `Scope` in the Entity of Metrics query v1 protocol is not required and automatical correction. The scope is determined based on the metric itself.
 * Add explicit `ReadTimeout` for ConsulConfigurationWatcher to avoid `IllegalArgumentException: Cache watchInterval=10sec >= networkClientReadTimeout=10000ms`.
 * Fix `DurationUtils.getDurationPoints` exceed, when `startTimeBucket` equals `endTimeBucket`.
+* Storage-elasticsearch-plugin supports query of selected fields.","[{'comment': '```suggestion\r\n* Read the name and properties of the instance only in `getInstance` service.\r\n```', 'commenter': 'wu-sheng'}]"
10557,oap-server/server-query-plugin/query-graphql-plugin/src/main/java/org/apache/skywalking/oap/query/graphql/resolver/MetadataQueryV2.java,"@@ -67,6 +67,10 @@ public List<Service> listServices(final String layer) throws IOException {
         return getMetadataQueryService().listServices(layer, null);
     }
 
+    public List<Service> listGroupServices(final String layer, final String group) throws IOException {","[{'comment': ""Where is the approval of this new query API? I can't find this."", 'commenter': 'wu-sheng'}, {'comment': ""> And what is the reason of ElasticSearch change? A pull request must include the explanation. One pull request is about one thing. Please be clear about the change, otherwise, we don't know what do you mean, and how could we follow?\r\n\r\nSorry this the first to pull request for open source ,I will explain it carefully."", 'commenter': 'xiaozaiyuji'}, {'comment': ""> > And what is the reason of ElasticSearch change? A pull request must include the explanation. One pull request is about one thing. Please be clear about the change, otherwise, we don't know what do you mean, and how could we follow?\r\n> \r\n> Sorry this the first to pull request for open source ,I explain will explain it carefully.\r\n\r\nYou are replying on another context. Please the keep thread clear."", 'commenter': 'wu-sheng'}, {'comment': ""> Where is the approval of this new query API? I can't find this.\r\n\r\nI add the group and layer search condition,because the performance for oap server is very sufficient.In product,I as the user with 10000 agent and use the group classify the search result will be limit by the query max size with min(metadataSize and scrollsize) with 5000,but the scroll query will help the user to search as many as the user want service to to search by the agent. In order to let the user to find the service sufficient,I want to modify the code.\r\n1.I give the user to find the service by group and layer when the user have classify the service by group.\r\n2.I give the user to query the service as they want the number they want but not limit by the elasticsearch maxWindowSize.\r\nSo I modify the word by change the two place,I think carefully and without to change the other,I think this will very flexible and will more sufficient."", 'commenter': 'xiaozaiyuji'}, {'comment': 'In product,If the user change the metadataSize 、scrollsize over the elasticserch maxWindowSize.  ,It also will be limit by  the elasticserch maxWindowSize and give an exception. So I change the limit logical to use the scrollSize and metadataSize .This change will not cause the exception.', 'commenter': 'xiaozaiyuji'}, {'comment': ""> .In product,I as the user with 10000 agent and use the group classify the search result will be limit by the query max size with min(metadataSize and scrollsize) with 5000,\r\n\r\nI can't follow this. 10k agents only mean 10k instances. Service must be much less than that. "", 'commenter': 'wu-sheng'}, {'comment': 'In fact the skywalking ui include  many different agent, kubenetes,istio and many, but the user may by just use the java agent service or the python agent, so they will write a ui by they use,the new query API will helpfully for this.This will help them to query the service sufficient and flexible.', 'commenter': 'xiaozaiyuji'}, {'comment': ""> metadataSize 、scrollsize over the elasticserch maxWindowSize\r\n\r\nAll these are open for you to change. Why don't you change them by your own?"", 'commenter': 'wu-sheng'}, {'comment': ""> In fact the skywalking ui include many different agent, kubenetes,istio and many, but the user may by just use the java agent service or the python agent, so they will write a ui by they use,the new query API wll helpfull for this.\r\n\r\nSo what? I can't see in any cases, you are limited by this. Set them as the number you want , "", 'commenter': 'wu-sheng'}, {'comment': ""> > .In product,I as the user with 10000 agent and use the group classify the search result will be limit by the query max size with min(metadataSize and scrollsize) with 5000,\r\n> \r\n> I can't follow this. 10k agents only mean 10k instances. Service must be much less than that.\r\n\r\nIn product, the metrics-all index will generate the data by day ,the service with the same name is added,does I setting something wrong for oap server.I  query the elasticsearch for index metrics-all and find the data is that.\r\nIn fact this will cause the service query will limit by the size,many service will can not the query ,the service will only show part of the service."", 'commenter': 'xiaozaiyuji'}, {'comment': ""> > metadataSize 、scrollsize over the elasticserch maxWindowSize\r\n> \r\n> All these are open for you to change. Why don't you change them by your own?\r\n\r\nI change the metadataSize 20000 but this param is also use by the other query ,this cause an exception.This is over the elasticserch limit 10000. I also try to change the elasticsearch maxWindowSize to 30000,but this is very low performance for the query,So I think to split the metadataSize  and maxWindowSize to by this."", 'commenter': 'xiaozaiyuji'}, {'comment': '> In product, the metrics-all index will generate the data by day ,the service with the same name is added\r\n\r\nNo, they are not. Service would be only added once. Check the data before guessing. That is not a fact.', 'commenter': 'wu-sheng'}, {'comment': ""> Where is the approval of this new query API? I can't find this.\r\n\r\n\r\n\r\n> > > And what is the reason of ElasticSearch change? A pull request must include the explanation. One pull request is about one thing. Please be clear about the change, otherwise, we don't know what do you mean, and how could we follow?\r\n> > \r\n> > \r\n> > Sorry this the first to pull request for open source ,I explain will explain it carefully.\r\n> \r\n> You are replying on another context. Please the keep thread clear.\r\n\r\n1.This will help the query to service by group which will classify the service by group,which had many services.This will more sufficient and flexible.\r\n2.Split the metadataSize and resultWindowMaxSize and aviod an exception when the user did not change elasticserch max size limit. And will find the query result as many as the user want to search,without reduce performance。"", 'commenter': 'xiaozaiyuji'}, {'comment': ""And your explanation doesn't make the sense even for your codes. \r\nYou added `resultWindowMaxSize`, but only `Math.min(metadataMaxSize, resultWindowMaxSize)`. Why just set a larger `metadataMaxSize`? `resultWindowMaxSize` isn't used in any place of this DAO. \r\nStill in all other places, `queryMaxSize`(`metadataMaxSize`) is still used. What is the point? What is changed?"", 'commenter': 'wu-sheng'}, {'comment': '> 2.Split the metadataSize and resultWindowMaxSize and aviod an exception when the user did not change elasticserch max size limit. And will find the query result as many as the user want to search,without reduce performance。\r\n\r\nI don\'t know how you get this conclusion. There is no `resultWindowMaxSize` used in any place other than NetworkAddressAliasEsDAO. \r\n\r\n<img width=""1072"" alt=""image"" src=""https://user-images.githubusercontent.com/5441976/226109506-e70dcb62-865e-4770-8217-2d30ba174d1b.png"">\r\n', 'commenter': 'wu-sheng'}, {'comment': 'This param resultWindowMaxSize is correspond the elasticsearch max limit size 10000. What I think is wrong?I am sorry for this.But this name is very confusion.\r\nBut the aim of sroll query is to query data not limit by elasticserach  limit 10000, In fact,If I didnot to change this to 20000.The other query will cause an exception. So I split them and can help the scroll query can query 20000 result,and other not scroll query will also query the data they want by the elasticsearch index max result limit.\r\nDid I should define a othe static param?', 'commenter': 'xiaozaiyuji'}, {'comment': ""Are you kidding? You are contributing to an open-source project, but understand a variable from the name rather than from codes.\r\n\r\nI am going to leave this PR, with no further steps. The conclusion is very clear, you even don't read the codes and debug the codes. Just guessing.\r\n\r\nI am out. "", 'commenter': 'wu-sheng'}, {'comment': 'I  am sorry for this.I will do it as you ask,I think what you see is right.As a coder,must to give the evidence carefully.', 'commenter': 'xiaozaiyuji'}]"
10557,oap-server/server-storage-plugin/storage-elasticsearch-plugin/src/main/java/org/apache/skywalking/oap/server/storage/plugin/elasticsearch/query/MetadataQueryEsDAO.java,"@@ -76,17 +78,19 @@ public MetadataQueryEsDAO(
         ElasticSearchClient client,
         StorageModuleElasticsearchConfig config) {
         super(client);
-        this.queryMaxSize = config.getMetadataQueryMaxSize();
+        this.metadataMaxSize = config.getMetadataQueryMaxSize();
+        this.resultWindowMaxSize = config.getResultWindowMaxSize();
         this.scrollingBatchSize = config.getScrollingBatchSize();
         this.layerSize = Layer.values().length;
+        this.queryMaxSize = Math.min(metadataMaxSize, resultWindowMaxSize);","[{'comment': ""Why do you have to run `min` between these two configurations? `metadataQueryMaxSize` is already open for your manual setup. I can't see your point of changing this."", 'commenter': 'wu-sheng'}, {'comment': 'I change this because this is also limit by the elasticsearch resultWindowMaxSize, if the metadataQueryMaxSize  setting by 20000 over the default limit by elasticserch it will cause an exception. The metadataQueryMaxSize is add to help the user to query  with elasticserch sroll query to avoid the limit 10000 of elasticserch.In order to fix this problem,I did this by not affect the other query,but support the  elasticserch sroll query, this will separate the queryMaxSize and metadataSize,when the metadataSize is litte than the resultWindowMaxSize, will query the data as the user setting, when the user setting the metadataSize over the resultWindowMaxSize, the elastic scroll query will give the metadataSize result as the user want, the other query will also limit by the resultWindowMaxSize and will not cause an exception.', 'commenter': 'xiaozaiyuji'}, {'comment': ""> I change this because this is also limit by the elasticsearch resultWindowMaxSize\r\n\r\nWhy don't you change the value to fix the expectation? The server setup matters too."", 'commenter': 'wu-sheng'}, {'comment': 'If it is a hardcode case, then we could fix it. But AFAIK, all these are exposed to you. Make them right, rather than adding more complex logic to cause further confusion.', 'commenter': 'wu-sheng'}, {'comment': 'Thanks for dear wu,I just want to help skywalking to become better and offer an effort.I will remember that not to adding more complex logic and further confusion. Thanks a lot.', 'commenter': 'xiaozaiyuji'}]"
10758,docs/en/setup/backend/dynamic-config.md,"@@ -37,6 +37,7 @@ Supported configurations are as follows:
 |core.default.apdexThreshold| The apdex threshold settings. Overrides `service-apdex-threshold.yml`. | Same as [`service-apdex-threshold.yml`](apdex-threshold.md). |
 |core.default.endpoint-name-grouping| The endpoint name grouping setting. Overrides `endpoint-name-grouping.yml`. | Same as [`endpoint-name-grouping.yml`](endpoint-grouping-rules.md). |
 |core.default.log4j-xml| The log4j xml configuration. Overrides `log4j2.xml`. | Same as [`log4j2.xml`](dynamical-logging.md). |
+|core.default.searchableTracesTags| The searchableTracesTags configuration. Overrides `core/default/searchableTracesTags` of `application.yml`. | http.method,http.status_code,rpc.status_code,db.type,db.instance,mq.queue,mq.topic,mq.broker |","[{'comment': '```suggestion\r\n|core.default.searchableTracesTags| The searchableTracesTags configuration. Override `core/default/searchableTracesTags` in the `application.yml`. | http.method,http.status_code,rpc.status_code,db.type,db.instance,mq.queue,mq.topic,mq.broker |\r\n```', 'commenter': 'wu-sheng'}]"
10760,docs/en/setup/backend/exporter.md,"@@ -81,6 +81,8 @@ exporter:
     # Kafka producer config, JSON format as Properties.
     kafkaProducerConfig: ${SW_EXPORTER_KAFKA_PRODUCER_CONFIG:""""}
     kafkaTopicTrace: ${SW_EXPORTER_KAFKA_TOPIC_TRACE:skywalking-trace}
+    # Trace filter
+    kafkaTraceFilterError: ${SW_EXPORTER_KAFKA_TRACE_FILTER_ERROR:false}","[{'comment': '```suggestion\r\n    exportErrorStatusTraceOnly: ${SW_EXPORTER_KAFKA_TRACE_FILTER_ERROR:false}\r\n```\r\n\r\nNotice, this is a filter at codes, but from user perspective, I would say this is an exporter configuration.\r\n\r\nPlease update the codes and docs according to the new propose name.', 'commenter': 'wu-sheng'}, {'comment': 'And you should update this doc to describe this feature, rather than only a config item', 'commenter': 'wu-sheng'}, {'comment': 'get it', 'commenter': 'yqjdcyy'}, {'comment': '> And you should update this doc to describe this feature, rather than only a config item\r\n\r\nany template for it ?', 'commenter': 'yqjdcyy'}, {'comment': 'I updated for you.', 'commenter': 'wu-sheng'}]"
10760,docs/en/setup/backend/configuration-vocabulary.md,"@@ -302,6 +302,7 @@ The Configuration Vocabulary lists all available configurations provided by `app
 | -                       | -             | kafkaProducerConfig                                                                                                                                                      | Kafka producer config, JSON format as Properties.                                                                                                                                                                                                                                                                                                                                                                                                                          | SW_EXPORTER_KAFKA_PRODUCER_CONFIG                             | -                                                                                            |
 | -                       | -             | kafkaTopicTrace                                                                                                                                                          | Kafka topic name for trace.                                                                                                                                                                                                                                                                                                                                                                                                                                                | SW_EXPORTER_KAFKA_TOPIC_TRACE                             | skywalking-export-trace                                                                      |
 | -                       | -             | kafkaTopicLog                                                                                                                                                            | Kafka topic name for log.                                                                                                                                                                                                                                                                                                                                                                                                                                                  | SW_EXPORTER_KAFKA_TOPIC_LOG                             | skywalking-export-log                                                                        |
+| -                       | -             | exportErrorStatusTraceOnly                                                                                                                                                    | Kafka trace exporter just produce error segment.                                                                                                                                                                                                                                                                                                                                                                                                                           | SW_EXPORTER_KAFKA_TRACE_FILTER_ERROR                             | false                                                                                        |","[{'comment': '```suggestion\r\n| -                       | -             | exportErrorStatusTraceOnly                                                                                                                                                    | Export error status trace segments through the Kafka channel.                                                                                                                                                                                                                                                                                                                                                                                                                           | SW_EXPORTER_KAFKA_TRACE_FILTER_ERROR                             | false                                                                                        |\r\n```', 'commenter': 'wu-sheng'}]"
10760,docs/en/setup/backend/exporter.md,"@@ -81,9 +82,12 @@ exporter:
     # Kafka producer config, JSON format as Properties.
     kafkaProducerConfig: ${SW_EXPORTER_KAFKA_PRODUCER_CONFIG:""""}
     kafkaTopicTrace: ${SW_EXPORTER_KAFKA_TOPIC_TRACE:skywalking-trace}
+    exportErrorStatusTraceOnly: ${SW_EXPORTER_KAFKA_TRACE_FILTER_ERROR:false}
     ...
 ```
 
+- `exportErrorStatusTraceOnly=true` represents that export the trace segments only through the Kafka channel.","[{'comment': '```suggestion\r\n- `exportErrorStatusTraceOnly=true` represents that only export the error status trace segments through the Kafka channel.\r\n```', 'commenter': 'wankai123'}]"
10760,oap-server/exporter/src/main/java/org/apache/skywalking/oap/server/exporter/provider/kafka/trace/KafkaTraceExporter.java,"@@ -90,6 +90,9 @@ public void consume(final List<SegmentRecord> data) {
             if (segmentRecord != null) {
                 try {
                     SegmentObject segmentObject = SegmentObject.parseFrom(segmentRecord.getDataBinary());
+                    if(setting.exportErrorStatusTraceOnly() && !isError(segmentObject)){","[{'comment': '```suggestion\r\n                    if (setting.exportErrorStatusTraceOnly() && !isError(segmentObject)) {\r\n```', 'commenter': 'wankai123'}, {'comment': 'thx', 'commenter': 'yqjdcyy'}]"
11102,docs/en/changes/changes.md,"@@ -7,6 +7,7 @@
 
 #### OAP Server
 
+* Add Echo component ID(5015) language: Golang.","[{'comment': 'Please keep the original changes file style, and add this changes to the latest.', 'commenter': 'mrproliu'}]"
11120,oap-server/server-starter/src/main/java/org/apache/skywalking/oap/server/starter/config/ApplicationConfigLoader.java,"@@ -40,6 +43,15 @@
  */
 @Slf4j
 public class ApplicationConfigLoader implements ConfigLoader<ApplicationConfiguration> {
+    static final Set<String> SENSITIVE_PROPERTY_NAMES =
+        ImmutableSet.<String>builder()
+                    .add(""password"")
+                    .add(""authentication"")
+                    .add(""accessKey"")
+                    .add(""secretKey"")","[{'comment': 'NIT: Check against https://skywalking.apache.org/docs/main/next/en/setup/backend/configuration-vocabulary/ and I think 1 is missing.\r\n```suggestion\r\n                    .add(""secretKey"")\r\n                    .add(""firehoseAccessKey"")\r\n```', 'commenter': 'toffentoffen'}, {'comment': '@toffentoffen thank you!!', 'commenter': 'kezhenxu94'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -223,85 +271,95 @@ message KeyStringValuePair {
 }
 ```
 
-## Slack Chat Hook
+### Slack Chat Hook
 Follow the [Getting Started with Incoming Webhooks guide](https://api.slack.com/messaging/webhooks) and create new Webhooks.
 
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured Slack Incoming Webhooks as follows:
 ```yml
 slackHooks:
-  textTemplate: |-
+  default:
+    isGlobal: true
+    textTemplate: |-
     {
       ""type"": ""section"",
       ""text"": {
         ""type"": ""mrkdwn"",
         ""text"": "":alarm_clock: *Apache Skywalking Alarm* \n **%s**.""
       }
     }","[{'comment': '```suggestion\r\n      {\r\n        ""type"": ""section"",\r\n        ""text"": {\r\n          ""type"": ""mrkdwn"",\r\n          ""text"": "":alarm_clock: *Apache Skywalking Alarm* \\n **%s**.""\r\n        }\r\n      }\r\n```', 'commenter': 'kezhenxu94'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -223,85 +271,95 @@ message KeyStringValuePair {
 }
 ```
 
-## Slack Chat Hook
+### Slack Chat Hook
 Follow the [Getting Started with Incoming Webhooks guide](https://api.slack.com/messaging/webhooks) and create new Webhooks.
 
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured Slack Incoming Webhooks as follows:
 ```yml
 slackHooks:
-  textTemplate: |-
+  default:
+    isGlobal: true
+    textTemplate: |-
     {
       ""type"": ""section"",
       ""text"": {
         ""type"": ""mrkdwn"",
         ""text"": "":alarm_clock: *Apache Skywalking Alarm* \n **%s**.""
       }
     }
-  webhooks:
+    webhooks:
     - https://hooks.slack.com/services/x/y/z
 ```
 
-## WeChat Hook
+### WeChat Hook
 Note that only the WeChat Company Edition (WeCom) supports WebHooks. To use the WeChat WebHook, follow the [Wechat Webhooks guide](https://work.weixin.qq.com/help?doc_id=13376).
 The alarm message will be sent through HTTP post by `application/json` content type after you have set up Wechat Webhooks as follows:
 ```yml
 wechatHooks:
-  textTemplate: |-
+  default:
+    isGlobal: true
+    textTemplate: |-
     {
       ""msgtype"": ""text"",
       ""text"": {
         ""content"": ""Apache SkyWalking Alarm: \n %s.""
       }
     }","[{'comment': '```suggestion\r\n      {\r\n        ""msgtype"": ""text"",\r\n        ""text"": {\r\n          ""content"": ""Apache SkyWalking Alarm: \\n %s.""\r\n        }\r\n      }\r\n```', 'commenter': 'kezhenxu94'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -223,85 +271,95 @@ message KeyStringValuePair {
 }
 ```
 
-## Slack Chat Hook
+### Slack Chat Hook
 Follow the [Getting Started with Incoming Webhooks guide](https://api.slack.com/messaging/webhooks) and create new Webhooks.
 
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured Slack Incoming Webhooks as follows:
 ```yml
 slackHooks:
-  textTemplate: |-
+  default:
+    isGlobal: true
+    textTemplate: |-
     {
       ""type"": ""section"",
       ""text"": {
         ""type"": ""mrkdwn"",
         ""text"": "":alarm_clock: *Apache Skywalking Alarm* \n **%s**.""
       }
     }
-  webhooks:
+    webhooks:
     - https://hooks.slack.com/services/x/y/z
 ```
 
-## WeChat Hook
+### WeChat Hook
 Note that only the WeChat Company Edition (WeCom) supports WebHooks. To use the WeChat WebHook, follow the [Wechat Webhooks guide](https://work.weixin.qq.com/help?doc_id=13376).
 The alarm message will be sent through HTTP post by `application/json` content type after you have set up Wechat Webhooks as follows:
 ```yml
 wechatHooks:
-  textTemplate: |-
+  default:
+    isGlobal: true
+    textTemplate: |-
     {
       ""msgtype"": ""text"",
       ""text"": {
         ""content"": ""Apache SkyWalking Alarm: \n %s.""
       }
     }
-  webhooks:
+    webhooks:
     - https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=dummy_key
 ```
 
-## DingTalk Hook
+### DingTalk Hook
 Follow the [Dingtalk Webhooks guide](https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq/uKPlK) and create new Webhooks.
 You can configure an optional secret for an individual webhook URL for security purposes.
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured DingTalk Webhooks as follows:
 ```yml
 dingtalkHooks:
-  textTemplate: |-
+  default:
+    isGlobal: true
+    textTemplate: |-
     {
       ""msgtype"": ""text"",
       ""text"": {
         ""content"": ""Apache SkyWalking Alarm: \n %s.""
       }
     }","[{'comment': '```suggestion\r\n      {\r\n        ""msgtype"": ""text"",\r\n        ""text"": {\r\n          ""content"": ""Apache SkyWalking Alarm: \\n %s.""\r\n        }\r\n      }\r\n```', 'commenter': 'kezhenxu94'}]"
11137,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/AlarmHookSettings.java,"@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.server.core.alarm.provider;
+
+import lombok.Getter;
+import org.apache.skywalking.oap.server.core.Const;
+
+public abstract class AlarmHookSettings {
+    private final String name;
+    @Getter
+    private final AlarmHooksType type;
+    @Getter
+    private final boolean isGlobal;
+
+   public AlarmHookSettings(String name, AlarmHooksType type, boolean isGlobal) {
+        this.name = name;
+        this.type = type;
+        this.isGlobal = isGlobal;
+    }","[{'comment': 'Replace with `@RequiredArgsConstructor`', 'commenter': 'kezhenxu94'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -123,13 +129,20 @@ rules:
     silence-period: 5
     message: The request number of entity {name} non-200 status is more than expected.
     only-as-condition: false
+    specific-hooks:","[{'comment': '```suggestion\n   hooks:\n```\n\nI think hooks is a good name already.', 'commenter': 'wu-sheng'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -152,7 +165,42 @@ Currently, metrics from the **Service**, **Service Instance**, **Endpoint**, **S
 
 Submit an issue or a pull request if you want to support any other scopes in Alarm.
 
-## Webhook
+## Hooks
+Hooks are a way to send alarm messages to the outside world. SkyWalking supports multiple hooks of the same type, each hook can support different configurations. 
+For example, you can configure two Slack hooks, one named `default` and set `isGlobal: true` means this hook will apply on all `Alarm Rules` **without config** `specific-hooks`.
+Another named `custom1` will only apply on the `Alarm Rules` which **with config** `specific-hooks` and include the name `slackHooks.custom1`.
+
+```yaml
+hooks:
+  slackHooks:
+    default:
+      isGlobal: true # if true, this hook will apply on all rules, unless a rule has its own specific hook.","[{'comment': 'Will mutiple global rules conflict? Or we will pick one randomly?', 'commenter': 'wu-sheng'}, {'comment': 'support multiple global hooks in one type, if they have different names', 'commenter': 'wankai123'}, {'comment': 'So, how would we react when conflicts? Are we still forwarding all as users say so?', 'commenter': 'wu-sheng'}, {'comment': ""If use the `yaml` settings, we can't config the same name under one item. such as we can't define 2 `default` name under slackHooks"", 'commenter': 'wankai123'}, {'comment': 'Syntactic restriction', 'commenter': 'wankai123'}, {'comment': 'The `default` is just a name and has no special meaning, users can define it themself. ', 'commenter': 'wankai123'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -368,4 +430,5 @@ the sliding window will be destroyed and re-created, causing the Alarm of this s
 | Count                | count                      | int            |                    |
 | Only as condition    | only-as-condition          | boolean        |                    |
 | Silence period       | silence-period             | int            |                    |
-| Message              | message                    | string         |                    |
\ No newline at end of file
+| Message              | message                    | string         |                    |
+| Specific Hooks       | specific-hooks             | string array   |                    |","[{'comment': ""I think we don't specific hook name, as users are set the server side as known. "", 'commenter': 'wu-sheng'}]"
11137,oap-server/server-starter/src/main/resources/alarm-settings.yml,"@@ -41,81 +41,128 @@ rules:
     tags:
       level: WARNING
 
-webhooks:
-#  - http://127.0.0.1/notify/
-#  - http://127.0.0.1/go-wechat/
-
-gRPCHook:
-#  target_host: 127.0.0.1
-#  target_port: 9888
-
-slackHooks:
-  textTemplate: |-
-    {
-      ""type"": ""section"",
-      ""text"": {
-        ""type"": ""mrkdwn"",
-        ""text"": "":alarm_clock: *Apache Skywalking Alarm* \n **%s**.""
-      }
-    }
-  webhooks:
-#    - https://hooks.slack.com/services/x/y/zssss
-
-wechatHooks:
-  textTemplate: |-
-    {
-      ""msgtype"": ""text"",
-      ""text"": {
-        ""content"": ""Apache SkyWalking Alarm: \n %s.""
-      }
-    }
-  webhooks:
-#    - https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=dummy_key
-
-dingtalkHooks:
-  textTemplate: |-
-    {
-      ""msgtype"": ""text"",
-      ""text"": {
-        ""content"": ""Apache SkyWalking Alarm: \n %s.""
-      }
-    }
-  webhooks:
-#    - url: https://oapi.dingtalk.com/robot/send?access_token=dummy_token
-#      secret: dummysecret
-
-feishuHooks:
-  textTemplate: |-
-    {
-    ""msg_type"": ""text"",
-    # at someone with feishu_user_ids
-    # ""ats"": ""feishu_user_id_1,feishu_user_id_2"",
-    ""content"": {
-      ""text"": ""Apache SkyWalking Alarm: \n %s.""
-      }
-    }
-  webhooks:
-#    - url: https://open.feishu.cn/open-apis/bot/v2/hook/dummy_token
-#      secret: dummysecret
-
-welinkHooks:
-  textTemplate: ""Apache SkyWalking Alarm: \n %s.""
-  webhooks:
-#    # you may find your own client_id and client_secret in your app, below are dummy, need to change.
-#    - client_id: ""dummy_client_id""
-#      client_secret: dummy_secret_key
-#      access_token_url: https://open.welink.huaweicloud.com/api/auth/v2/tickets
-#      message_url: https://open.welink.huaweicloud.com/api/welinkim/v1/im-service/chat/group-chat
-#      # if you send to multi group at a time, separate group_ids with commas, e.g. ""123xx"",""456xx""
-#      group_ids: ""dummy_group_id""
-#      # make a name you like for the robot, it will display in group
-#      robot_name: robot
+  service_cpm_rule:
+    metrics-name: service_cpm
+    # [Optional] Default, match all services in this metrics
+    threshold: 1
+    op: "">""
+    period: 10
+    count: 1
+    tags:
+      level: WARNING
 
-pagerDutyHooks:
-  textTemplate: ""Apache SkyWalking Alarm: \n %s.""
-  integrationKeys:
-#    # you can find your integration key(s) on the Events API V2 integration page for your PagerDuty service(s).
-#    # (you may need to create an Events API V2 integration for your PagerDuty service if you don't have one yet)
-#    # below are dummy keys that should be replaced with your own integration keys.
-#    - dummy_key
-#    - dummy_key2
+hooks:","[{'comment': 'Why do we want to add a section level `hooks` here? The following sections all have a `**hooks` suffix already and this looks pretty verbose', 'commenter': 'kezhenxu94'}]"
11137,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/discord/DiscordHookCallback.java,"@@ -43,17 +44,28 @@ public class DiscordHookCallback extends HttpAlarmCallback {
      */
     @Override
     public void doAlarm(List<AlarmMessage> alarmMessages) throws Exception {
-        final var discordSettings = alarmRulesWatcher.getDiscordSettings();
-        if (discordSettings == null || discordSettings.getWebhooks().isEmpty()) {
+        Map<String, DiscordSettings> settingsMap = alarmRulesWatcher.getDiscordSettings();
+        if (settingsMap == null || settingsMap.isEmpty()) {
             return;
         }
-        for (final var webHookUrl : discordSettings.getWebhooks()) {
-            for (final var alarmMessage : alarmMessages) {
-                final var content = String.format(
-                        discordSettings.getTextTemplate(),
+
+        Map<String, List<AlarmMessage>> groupedMessages = groupMessagesByHook(alarmMessages);
+        for (Map.Entry<String, List<AlarmMessage>> entry : groupedMessages.entrySet()) {
+            var hookName = entry.getKey();
+            var messages = entry.getValue();
+            var setting = settingsMap.get(hookName);
+            if (setting == null || CollectionUtils.isEmpty(setting.getWebhooks()) || CollectionUtils.isEmpty(
+                messages)) {
+                continue;
+            }","[{'comment': ""You can't simply skip if `settings == null`, `settings` being null has high possibility that the users configure a wrong name that doesn't exist at all (e.g. typo), you should check the hook names exist when reading the configs and bail out as a startup exception."", 'commenter': 'kezhenxu94'}, {'comment': 'Added', 'commenter': 'wankai123'}]"
11137,oap-server/server-alarm-plugin/src/main/java/org/apache/skywalking/oap/server/core/alarm/provider/webhook/WebhookCallback.java,"@@ -39,13 +41,24 @@ public class WebhookCallback extends HttpAlarmCallback {
     private final Gson gson = new Gson();
 
     @Override
-    public void doAlarm(List<AlarmMessage> alarmMessage) throws IOException, InterruptedException {
-        if (alarmRulesWatcher.getWebHooks().isEmpty()) {
+    public void doAlarm(List<AlarmMessage> alarmMessages) throws IOException, InterruptedException {
+        Map<String, WebhookSettings> settingsMap = alarmRulesWatcher.getWebHooks();
+        if (settingsMap == null || settingsMap.isEmpty()) {
             return;
         }
 
-        for (String url : alarmRulesWatcher.getWebHooks()) {
-            post(URI.create(url), gson.toJson(alarmMessage), Map.of());
+        Map<String, List<AlarmMessage>> groupedMessages = groupMessagesByHook(alarmMessages);
+        for (Map.Entry<String, List<AlarmMessage>> entry : groupedMessages.entrySet()) {
+            var hookName = entry.getKey();
+            var messages = entry.getValue();
+            var setting = settingsMap.get(hookName);","[{'comment': '~The `hookName` from the `groupMessagesByHook(alarmMessages);` is something like `slackHooks.custom1`, but the keys in `settingsMap` is something like `custom1`, how can you get the setting with `settingsMap.get(hookName);`? Did you process the hook name somewhere I missed?~\r\n\r\nOK just found the key is formatted name with the hook type\r\n\r\nAnd the tests only covers global webhooks, please test the rule-level web hooks', 'commenter': 'kezhenxu94'}, {'comment': 'The full name is `{hookType}.{hookName}`,  define and get from `AlarmHookSettings.java`', 'commenter': 'wankai123'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -152,7 +165,42 @@ Currently, metrics from the **Service**, **Service Instance**, **Endpoint**, **S
 
 Submit an issue or a pull request if you want to support any other scopes in Alarm.
 
-## Webhook
+## Hooks
+Hooks are a way to send alarm messages to the outside world. SkyWalking supports multiple hooks of the same type, each hook can support different configurations. 
+For example, you can configure two Slack hooks, one named `default` and set `is-global: true` means this hook will apply on all `Alarm Rules` **without config** `hooks`.
+Another named `custom1` will only apply on the `Alarm Rules` which **with config** `hooks` and include the name `slack.custom1`.
+
+```yaml
+hooks:
+  slackHooks:","[{'comment': '```suggestion\r\n  slack:\r\n```', 'commenter': 'kezhenxu94'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -223,120 +271,134 @@ message KeyStringValuePair {
 }
 ```
 
-## Slack Chat Hook
+### Slack Chat
 Follow the [Getting Started with Incoming Webhooks guide](https://api.slack.com/messaging/webhooks) and create new Webhooks.
 
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured Slack Incoming Webhooks as follows:
 ```yml
-slackHooks:
-  textTemplate: |-
-    {
-      ""type"": ""section"",
-      ""text"": {
-        ""type"": ""mrkdwn"",
-        ""text"": "":alarm_clock: *Apache Skywalking Alarm* \n **%s**.""
+slack:
+  default:
+    is-global: true
+    text-template: |-
+      {
+        ""type"": ""section"",
+        ""text"": {
+          ""type"": ""mrkdwn"",
+          ""text"": "":alarm_clock: *Apache Skywalking Alarm* \n **%s**.""
+        }
       }
-    }
-  webhooks:
+    webhooks:
     - https://hooks.slack.com/services/x/y/z
 ```
 
-## WeChat Hook
+### WeChat
 Note that only the WeChat Company Edition (WeCom) supports WebHooks. To use the WeChat WebHook, follow the [Wechat Webhooks guide](https://work.weixin.qq.com/help?doc_id=13376).
 The alarm message will be sent through HTTP post by `application/json` content type after you have set up Wechat Webhooks as follows:
 ```yml
-wechatHooks:
-  textTemplate: |-
-    {
-      ""msgtype"": ""text"",
-      ""text"": {
-        ""content"": ""Apache SkyWalking Alarm: \n %s.""
+wechat:
+  default:
+    is-global: true
+    text-template: |-
+      {
+        ""msgtype"": ""text"",
+        ""text"": {
+          ""content"": ""Apache SkyWalking Alarm: \n %s.""
+        }
       }
-    }
-  webhooks:
+    webhooks:
     - https://qyapi.weixin.qq.com/cgi-bin/webhook/send?key=dummy_key
 ```
 
-## DingTalk Hook
+### DingTalk
 Follow the [Dingtalk Webhooks guide](https://ding-doc.dingtalk.com/doc#/serverapi2/qf2nxq/uKPlK) and create new Webhooks.
 You can configure an optional secret for an individual webhook URL for security purposes.
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured DingTalk Webhooks as follows:
 ```yml
-dingtalkHooks:
-  textTemplate: |-
-    {
-      ""msgtype"": ""text"",
-      ""text"": {
-        ""content"": ""Apache SkyWalking Alarm: \n %s.""
+dingtalk:
+  default:
+    is-global: true
+    text-template: |-
+      {
+        ""msgtype"": ""text"",
+        ""text"": {
+          ""content"": ""Apache SkyWalking Alarm: \n %s.""
+        }
       }
-    }
-  webhooks:
+    webhooks:
     - url: https://oapi.dingtalk.com/robot/send?access_token=dummy_token
       secret: dummysecret
 ```
 
-## Feishu Hook
+### Feishu
 Follow the [Feishu Webhooks guide](https://www.feishu.cn/hc/zh-cn/articles/360024984973) and create new Webhooks.
 You can configure an optional secret for an individual webhook URL for security purposes.
 If you want to direct a text to a user, you can configure `ats`, which is Feishu's user_id and separated by "","" .
 The alarm message will be sent through HTTP post by `application/json` content type if you have configured Feishu Webhooks as follows:
 ```yml
-feishuHooks:
-  textTemplate: |-
+feishu:
+  default:
+    is-global: true
+    text-template: |-
     {
       ""msg_type"": ""text"",
       ""content"": {
         ""text"": ""Apache SkyWalking Alarm: \n %s.""
       },
       ""ats"":""feishu_user_id_1,feishu_user_id_2""
     }","[{'comment': '```suggestion\r\n      {\r\n        ""msg_type"": ""text"",\r\n        ""content"": {\r\n          ""text"": ""Apache SkyWalking Alarm: \\n %s.""\r\n        },\r\n        ""ats"":""feishu_user_id_1,feishu_user_id_2""\r\n      }\r\n```', 'commenter': 'kezhenxu94'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -152,7 +165,42 @@ Currently, metrics from the **Service**, **Service Instance**, **Endpoint**, **S
 
 Submit an issue or a pull request if you want to support any other scopes in Alarm.
 
-## Webhook
+## Hooks
+Hooks are a way to send alarm messages to the outside world. SkyWalking supports multiple hooks of the same type, each hook can support different configurations. 
+For example, you can configure two Slack hooks, one named `default` and set `is-global: true` means this hook will apply on all `Alarm Rules` **without config** `hooks`.
+Another named `custom1` will only apply on the `Alarm Rules` which **with config** `hooks` and include the name `slack.custom1`.
+
+```yaml
+hooks:
+  slack:
+    default:
+      is-global: true # if true, this hook will apply on all rules, unless a rule has its own specific hook.","[{'comment': '> unless a rule has its own specific hook.\r\n\r\nSo, if there are `hooks` specified in the rules, the `is-global` is not working.\r\nAm I right? If so, the name `global` seems not proper, it is more like a default rule. We should consider not to set `default` as name in the demo, and change this to `is-default : true`.', 'commenter': 'wu-sheng'}, {'comment': '> So, if there are hooks specified in the rules, the is-global is not working. Am I right?\r\n\r\nyes\r\n\r\n> If so, the name global seems not proper, it is more like a default rule. We should consider not to set default as name in the demo, and change this to is-default : true\r\n\r\nI think `is-global` means you can define more than one global hook in one type. `is-default` mostly means only one?', 'commenter': 'wankai123'}, {'comment': 'But `global` seems not to be able to be overridden.', 'commenter': 'wu-sheng'}, {'comment': 'make sense, changed ', 'commenter': 'wankai123'}]"
11137,docs/en/setup/backend/backend-alarm.md,"@@ -152,7 +165,43 @@ Currently, metrics from the **Service**, **Service Instance**, **Endpoint**, **S
 
 Submit an issue or a pull request if you want to support any other scopes in Alarm.
 
-## Webhook
+## Hooks
+Hooks are a way to send alarm messages to the outside world. SkyWalking supports multiple hooks of the same type, each hook can support different configurations. 
+For example, you can configure two Slack hooks, one named `default` and set `is-default: true` means this hook will apply on all `Alarm Rules` **without config** `hooks`.
+Another named `custom1` will only apply on the `Alarm Rules` which **with config** `hooks` and include the name `slack.custom1`.
+
+```yaml
+hooks:
+  slack:
+    default:","[{'comment': '```suggestion\n    # default here is just a name, set the field default: true if this notification hook is expected to be default globally.\n    default:\n```\n', 'commenter': 'wu-sheng'}]"
11168,docs/en/setup/backend/ui-grafana.md,"@@ -55,6 +60,27 @@ General settings:
 #### Sampled Records
 Same as the Sort Metrics.
 
+## Configure Log Dashboard
+### Dashboards Settings
+The following steps are the example of config a log dashboard:
+1. Create a dashboard named `Log`.
+2. Configure variables for the dashboard:
+<img src=""./grafana-loki-variables1.jpg""/>
+3. Please make sure `service_instance` and `endpoint` variable enabled `Include All` option and set `Custom all value` to blank (typed by space button on the keyboard):
+<img src=""./grafana-loki-variables2.jpg""/>
+4. `Tags` variable is a little different from others, for more details, please refer [Ad hoc filters](https://grafana.com/docs/grafana/latest/dashboards/variables/add-template-variables/#add-ad-hoc-filters):
+<img src=""./grafana-loki-variables3.jpg""/>
+6. After configure, you can select log query variables on the top of the dashboard:
+<img src=""./grafana-loki-variables4.jpg""/>
+
+### Add Log Panel
+The following steps show how to add a log panel.
+1. Choose `Logs` chart.
+2. Set the `Line limit` value (The max number of logs to return in a query) and `Order` value (Determines the sort order of logs).
+3. Add LogQL expressions, use the variables configured above for the labels and searching keyword.
+4. Test query and save the panel.
+<img src=""./grafana-log-panel.jpg""/>
+
 ## Preview on demo.skywalking.a.o","[{'comment': 'Preview section is also expected later.', 'commenter': 'wu-sheng'}]"
11168,oap-server/server-starter/src/main/resources/application.yml,"@@ -431,6 +431,18 @@ promql:
     restMaxThreads: ${SW_PROMQL_REST_MAX_THREADS:200}
     restIdleTimeOut: ${SW_PROMQL_REST_IDLE_TIMEOUT:30000}
     restAcceptQueueSize: ${SW_PROMQL_REST_QUEUE_SIZE:0}
+    
+#This module is for LogQL API.
+logql:
+  selector: ${SW_LOGQL:default}
+  default:
+    # For HTTP server
+    restHost: ${SW_LOGQL_REST_HOST:0.0.0.0}
+    restPort: ${SW_LOGQL_REST_PORT:3100}","[{'comment': 'With this, `showcase` and `helm` codes need to be updated to expose the new port, right? @kezhenxu94 @wankai123 ', 'commenter': 'wu-sheng'}, {'comment': ""I suggest we don't enable logql, and promql which I missed before, they are occupying too many ports and are not common cases where users would use, just let the users enable these when they want"", 'commenter': 'kezhenxu94'}, {'comment': 'I am fine about enabling or not by default. It seems not much different. Are you concern about network security impact?', 'commenter': 'wu-sheng'}, {'comment': ""> I am fine about enabling or not by default. It seems not much different. Are you concern about network security impact?\r\n\r\nit's much different, enabling an unused plugin creates an extra HTTP server, consuming more resources, and security impact is the most important concern of mine."", 'commenter': 'kezhenxu94'}]"
11168,oap-server/server-query-plugin/logql-plugin/src/main/java/org/apache/skywalking/oap/query/logql/handler/LogQLApiHandler.java,"@@ -0,0 +1,233 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.query.logql.handler;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.linecorp.armeria.common.HttpData;
+import com.linecorp.armeria.common.HttpResponse;
+import com.linecorp.armeria.common.HttpStatus;
+import com.linecorp.armeria.common.MediaType;
+import com.linecorp.armeria.common.ResponseHeaders;
+import com.linecorp.armeria.server.annotation.Get;
+import com.linecorp.armeria.server.annotation.Param;
+import com.linecorp.armeria.server.annotation.Path;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.stream.Collectors;
+import org.antlr.v4.runtime.CharStreams;
+import org.antlr.v4.runtime.CommonTokenStream;
+import org.antlr.v4.runtime.misc.ParseCancellationException;
+import org.antlr.v4.runtime.tree.ParseTree;
+import org.apache.skywalking.logql.rt.grammar.LogQLLexer;
+import org.apache.skywalking.logql.rt.grammar.LogQLParser;
+import org.apache.skywalking.oap.query.logql.entity.LabelName;
+import org.apache.skywalking.oap.query.logql.entity.LogDirection;
+import org.apache.skywalking.oap.query.logql.entity.ResultStatus;
+import org.apache.skywalking.oap.query.logql.entity.response.LabelValuesQueryRsp;
+import org.apache.skywalking.oap.query.logql.entity.response.LabelsQueryRsp;
+import org.apache.skywalking.oap.query.logql.entity.response.LogRangeQueryRsp;
+import org.apache.skywalking.oap.query.logql.entity.response.QueryResponse;
+import org.apache.skywalking.oap.query.logql.entity.response.ResultType;
+import org.apache.skywalking.oap.query.logql.entity.response.StreamLog;
+import org.apache.skywalking.oap.query.logql.entity.response.TimeValuePair;
+import org.apache.skywalking.oap.query.logql.rt.LogQLExprVisitor;
+import org.apache.skywalking.oap.query.logql.rt.exception.ParseErrorListener;
+import org.apache.skywalking.oap.query.logql.rt.result.LogQLParseResult;
+import org.apache.skywalking.oap.server.core.CoreModule;
+import org.apache.skywalking.oap.server.core.analysis.IDManager;
+import org.apache.skywalking.oap.server.core.analysis.manual.searchtag.Tag;
+import org.apache.skywalking.oap.server.core.analysis.manual.searchtag.TagType;
+import org.apache.skywalking.oap.server.core.query.DurationUtils;
+import org.apache.skywalking.oap.server.core.query.LogQueryService;
+import org.apache.skywalking.oap.server.core.query.TagAutoCompleteQueryService;
+import org.apache.skywalking.oap.server.core.query.input.Duration;
+import org.apache.skywalking.oap.server.core.query.input.TraceScopeCondition;
+import org.apache.skywalking.oap.server.core.query.type.Log;
+import org.apache.skywalking.oap.server.core.query.type.Logs;
+import org.apache.skywalking.oap.server.core.query.type.Pagination;
+import org.apache.skywalking.oap.server.library.module.ModuleManager;
+import org.apache.skywalking.oap.server.library.util.StringUtil;
+
+public class LogQLApiHandler {
+
+    private final LogQueryService logQueryService;
+    private final TagAutoCompleteQueryService tagAutoCompleteQueryService;
+    private static final ObjectMapper MAPPER = new ObjectMapper();
+
+    public LogQLApiHandler(ModuleManager moduleManager) {
+        this.logQueryService = moduleManager.find(CoreModule.NAME)
+                                            .provider()
+                                            .getService(LogQueryService.class);
+        this.tagAutoCompleteQueryService = moduleManager.find(CoreModule.NAME)
+                                                        .provider()
+                                                        .getService(TagAutoCompleteQueryService.class);
+    }
+
+    @Get
+    @Path(""/loki/api/v1/labels"")
+    public HttpResponse labels(
+        @Param(""start"") Long start,
+        @Param(""end"") Long end) throws IOException {
+        LabelsQueryRsp labelsQueryRsp = new LabelsQueryRsp();
+        labelsQueryRsp.setStatus(ResultStatus.SUCCESS);
+
+        Duration duration = DurationUtils.timestamp2Duration(nano2Millis(start), nano2Millis(end));
+        tagAutoCompleteQueryService.queryTagAutocompleteKeys(TagType.LOG, duration)
+                                   .forEach(tag -> labelsQueryRsp.getData().add(tag));
+
+        return successResponse(labelsQueryRsp);
+    }
+
+    @Get
+    @Path(""/loki/api/v1/label/{label_name}/values"")
+    public HttpResponse labelValues(
+        @Param(""label_name"") String labelName,
+        @Param(""start"") Long start,
+        @Param(""end"") Long end) throws IOException {
+        LabelValuesQueryRsp response = new LabelValuesQueryRsp();
+        response.setStatus(ResultStatus.SUCCESS);
+
+        Duration duration = DurationUtils.timestamp2Duration(nano2Millis(start), nano2Millis(end));
+        tagAutoCompleteQueryService.queryTagAutocompleteValues(TagType.LOG, labelName, duration)
+                                   .forEach(value -> response.getData().add(value));
+
+        return successResponse(response);
+    }
+
+    @Get
+    @Path(""/loki/api/v1/query_range"")
+    public HttpResponse rangeQuery(
+        @Param(""start"") Long start,
+        @Param(""end"") Long end,
+        @Param(""query"") String query,
+        @Param(""limit"") Integer limit,
+        @Param(""direction"") LogDirection direction) throws IOException {
+        LogRangeQueryRsp logRangeQueryRsp = new LogRangeQueryRsp();
+        logRangeQueryRsp.setStatus(ResultStatus.SUCCESS);
+
+        LogQLLexer lexer = new LogQLLexer(CharStreams.fromString(query));
+        lexer.addErrorListener(new ParseErrorListener());
+        LogQLParser parser = new LogQLParser(new CommonTokenStream(lexer));
+        parser.addErrorListener(new ParseErrorListener());
+        ParseTree tree;
+        try {
+            tree = parser.root();
+        } catch (ParseCancellationException e) {
+            return badResponse(e.getMessage());
+        }
+
+        LogQLExprVisitor visitor = new LogQLExprVisitor();
+        LogQLParseResult parseResult = visitor.visit(tree);
+        Map<String, String> labelMap = parseResult.getLabelMap();
+
+        String serviceId = labelMap.containsKey(LabelName.SERVICE.getLabel()) ?
+            IDManager.ServiceID.buildId(labelMap.get(LabelName.SERVICE.getLabel()), true) : null;
+        String serviceInstanceId = labelMap.containsKey(LabelName.SERVICE_INSTANCE.getLabel()) ?
+            IDManager.ServiceInstanceID.buildId(serviceId, labelMap.get(LabelName.SERVICE_INSTANCE.getLabel())) : null;
+        String endpointId = labelMap.containsKey(LabelName.ENDPOINT.getLabel()) ?
+            IDManager.EndpointID.buildId(serviceId, labelMap.get(LabelName.ENDPOINT.getLabel())) : null;","[{'comment': 'If `serviceId` is null, build instanceId and endpointId will get unexpected id with `_blank`.', 'commenter': 'wankai123'}, {'comment': 'Ok, thanks. I will add a check.', 'commenter': 'weixiang1862'}]"
11168,test/e2e-v2/cases/logql/logql-cases.yaml,"@@ -0,0 +1,28 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+cases:
+  # log tag query
+  - query: curl -X GET http://${oap_host}:${oap_3100}/loki/api/v1/labels -d 'start='$(($(($(date +%s)-1800))*1000000000))'&end='$(($(date +%s)*1000000000))
+    expected: expected/logql-log-tags.yml
+  # log tag value query
+  - query: curl -X GET http://${oap_host}:${oap_3100}/loki/api/v1/label/level/values -d 'start='$(($(($(date +%s)-1800))*1000000000))'&end='$(($(date +%s)*1000000000))
+    expected: expected/logql-log-tag-values.yml
+  # log range query FORWARD
+  - query: curl -X GET http://${oap_host}:${oap_3100}/loki/api/v1/query_range -d 'query={service=""e2e-service-provider""}&start='$(($(($(date +%s)-1800))*1000000000))'&end='$(($(date +%s)*1000000000))'&limit=100&direction=FORWARD'
+    expected: expected/logql-logs.yml
+  # log range query BACKWARD
+  - query: curl -X GET http://${oap_host}:${oap_3100}/loki/api/v1/query_range -d 'query={service=""e2e-service-provider""}&start='$(($(($(date +%s)-1800))*1000000000))'&end='$(($(date +%s)*1000000000))'&limit=100&direction=BACKWARD'","[{'comment': 'Could the query expr cover more cases such as include serviceInstance / traceId / tags', 'commenter': 'wankai123'}, {'comment': 'Ok, I will add more cases.', 'commenter': 'weixiang1862'}, {'comment': 'Added.', 'commenter': 'weixiang1862'}]"
11168,oap-server/server-query-plugin/logql-plugin/src/main/java/org/apache/skywalking/oap/query/logql/entity/LabelName.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.query.logql.entity;
+
+import com.fasterxml.jackson.annotation.JsonValue;
+import com.fasterxml.jackson.databind.annotation.JsonSerialize;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
+
+@JsonSerialize()","[{'comment': ""```suggestion\r\n\r\n```\r\nI think don't need this."", 'commenter': 'wankai123'}, {'comment': 'Yes, you all right. It is useless in logql.', 'commenter': 'weixiang1862'}]"
11168,oap-server/server-query-plugin/logql-plugin/src/main/java/org/apache/skywalking/oap/query/logql/entity/LabelName.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ *
+ */
+
+package org.apache.skywalking.oap.query.logql.entity;
+
+import com.fasterxml.jackson.annotation.JsonValue;
+import com.fasterxml.jackson.databind.annotation.JsonSerialize;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.Map;
+
+@JsonSerialize()
+public enum LabelName {
+    SERVICE(""service""),
+    SERVICE_INSTANCE(""service_instance""),
+    ENDPOINT(""endpoint""),
+    TRACE_ID(""trace_id"");
+
+    final String label;
+
+    private static final Map<String, LabelName> DICTIONARY = new HashMap<>();
+
+    static {
+        Arrays.stream(LabelName.values()).forEach(l -> {
+            DICTIONARY.put(l.label, l);
+        });
+    }
+
+    LabelName(final String label) {
+        this.label = label;
+    }
+
+    public static boolean containsLabel(String label) {
+        return DICTIONARY.containsKey(label);
+    }
+
+    @JsonValue","[{'comment': '```suggestion\r\n\r\n```', 'commenter': 'wankai123'}]"
11168,docs/en/setup/backend/ui-grafana.md,"@@ -55,6 +60,27 @@ General settings:
 #### Sampled Records
 Same as the Sort Metrics.
 
+## Configure Log Dashboard
+### Dashboards Settings
+The following steps are the example of config a log dashboard:
+1. Create a dashboard named `Log`.
+2. Configure variables for the dashboard:
+<img src=""./grafana-loki-variables1.jpg""/>
+3. Please make sure `service_instance` and `endpoint` variable enabled `Include All` option and set `Custom all value` to blank (typed by space button on the keyboard):
+<img src=""./grafana-loki-variables2.jpg""/>
+4. `Tags` variable is a little different from others, for more details, please refer [Ad hoc filters](https://grafana.com/docs/grafana/latest/dashboards/variables/add-template-variables/#add-ad-hoc-filters):","[{'comment': '`Ad hoc filters` markdown format seems not working well. \r\n\r\n<img width=""896"" alt=""image"" src=""https://github.com/apache/skywalking/assets/5441976/6773ed4a-7593-4d63-a9d4-c513e65c0379"">\r\n\r\nIt should be a link. Maybe the `:` breaks it? Please recheck.\r\nThe preview is on GitHub preview page. https://github.com/apache/skywalking/blob/e519edc71c8635f8a3dde9fdffc7af8e8b3da6d2/docs/en/setup/backend/ui-grafana.md', 'commenter': 'wu-sheng'}, {'comment': 'I adjust it in many ways, it fails. Seems github preview page cant not rendering a link in markdown list. It rendering well in idea and other markdown editor.', 'commenter': 'weixiang1862'}]"
11168,docs/en/changes/changes.md,"@@ -59,6 +59,7 @@
 * Bump up Armeria to 1.24.3.
 * Apply MQE on APISIX, AWS_EKS, AWS_GATEWAY and AWS_S3 layer UI templates.
 * Fix BooleanMatch and BooleanNotEqualMatch doing Boolean comparison.
+* Support LogQL http query api.","[{'comment': '```suggestion\r\n* Support LogQL HTTP query APIs.\r\n```', 'commenter': 'wu-sheng'}]"
11282,test/e2e-v2/cases/kafkamq/docker-compose.yml,"@@ -0,0 +1,137 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '3'
+
+services:","[{'comment': 'missing oap service deployment', 'commenter': 'wankai123'}]"
11282,test/e2e-v2/cases/kafkamq/otel-collector-config.yaml,"@@ -0,0 +1,56 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+receivers:
+  prometheus:
+    config:
+      scrape_configs:
+        - job_name: ""kafka-monitoring"" # make sure to use this in the vm.yaml to filter only VM metrics
+          scrape_interval: 10s
+          static_configs:
+            - targets: 
+                - broker1:7071
+                - broker2:7072
+          relabel_configs:
+            - source_labels: [ ]
+              target_label: cluster
+              replacement: kafka-cluster
+            - source_labels: [ __address__ ]
+              regex: (.+)
+              target_label: broker
+              replacement: $$1
+
+processors:
+  batch:
+
+exporters:
+  otlp:
+    # endpoint: ""10.0.0.120:11800"" # The OAP Server address
+    endpoint: ""192.168.0.120:11800""","[{'comment': '```suggestion\r\n    # The OAP Server address\r\n    endpoint: oap:11800\r\n```', 'commenter': 'wankai123'}]"
11282,oap-server/server-starter/src/main/resources/application.yml,"@@ -393,7 +393,7 @@ query:
     # abort a query if the total number of data fields queried exceeds the defined threshold.
     maxQueryComplexity: ${SW_QUERY_MAX_QUERY_COMPLEXITY:3000}
     # Allow user add, disable and update UI template
-    enableUpdateUITemplate: ${SW_ENABLE_UPDATE_UI_TEMPLATE:false}
+    enableUpdateUITemplate: ${SW_ENABLE_UPDATE_UI_TEMPLATE:true}","[{'comment': 'Why modify the default values? Please confirm if this modification is related to this feature.\r\nIf necessary, please modify the corresponding document. (`skywalking/docs/en/setup/backend/Configuration vocabulary.md`)', 'commenter': 'wuwen5'}, {'comment': 'This should not open by default.\nI believe this is a local change, please revert.', 'commenter': 'wu-sheng'}, {'comment': 'Sorry, this is just for local testing convenience. I will turn it off before the final version', 'commenter': 'ZhuWang1112'}, {'comment': 'The best practice is, you should revert this, and change the local system environment variable to set as true.', 'commenter': 'wu-sheng'}]"
11282,oap-server/server-starter/src/main/resources/otel-rules/kafka/kafka-cluster.yaml,"@@ -0,0 +1,67 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+# This will parse a textual representation of a duration. The formats
+# accepted are based on the ISO-8601 duration format {@code PnDTnHnMn.nS}
+# with days considered to be exactly 24 hours.
+# <p>
+# Examples:
+# <pre>
+#    ""PT20.345S"" -- parses as ""20.345 seconds""
+#    ""PT15M""     -- parses as ""15 minutes"" (where a minute is 60 seconds)
+#    ""PT10H""     -- parses as ""10 hours"" (where an hour is 3600 seconds)
+#    ""P2D""       -- parses as ""2 days"" (where a day is 24 hours or 86400 seconds)
+#    ""P2DT3H4M""  -- parses as ""2 days, 3 hours and 4 minutes""
+#    ""P-6H3M""    -- parses as ""-6 hours and +3 minutes""
+#    ""-P6H3M""    -- parses as ""-6 hours and -3 minutes""
+#    ""-P-6H+3M""  -- parses as ""+6 hours and -3 minutes""
+# </pre>
+filter: ""{ tags -> tags.job_name == 'kafka-monitoring' }"" # The OpenTelemetry job name
+expSuffix: tag({tags -> tags.cluster = 'kafka::' + tags.cluster}).service(['cluster'], Layer.KAFKA)
+metricPrefix: meter_kafka
+metricsRules:
+
+  - name: under_replicated_partitions
+    exp: kafka_server_replicamanager_underreplicatedpartitions.sum(['cluster','broker'])
+
+  - name: offline_partitions_count
+    exp: kafka_controller_kafkacontroller_offlinepartitionscount.sum(['cluster','broker'])
+
+  - name: partition_count
+    exp: kafka_server_replicamanager_partitioncount.sum(['cluster', 'broker'])
+
+  - name: leader_count
+    exp: kafka_server_replicamanager_leadercount.sum(['cluster', 'broker'])
+
+  - name: active_controller_count
+    exp: kafka_controller_kafkacontroller_activecontrollercount.sum(['cluster', 'broker'])
+
+  - name: leader_election_rate
+    exp: kafka_controller_controllerstats_leaderelectionrateandtimems_count.sum(['cluster', 'broker']).rate('PT1M')
+
+  - name: unclean_leader_elections_per_second
+    exp: kafka_controller_controllerstats_uncleanleaderelections_total.sum(['cluster', 'broker']).rate('PT1M')
+
+  - name: max_lag
+    exp: kafka_server_replicafetchermanager_maxlag.sum(['cluster', 'broker'])
+
+
+
+
+
+
+
+
+","[{'comment': ""```suggestion\r\n    exp: kafka_server_replicafetchermanager_maxlag.sum(['cluster', 'broker'])\r\n\r\n```"", 'commenter': 'wankai123'}]"
11282,test/e2e-v2/cases/kafka/kafka-monitoring/docker-compose.yml,"@@ -0,0 +1,131 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '3'
+
+services:
+  oap:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: oap
+    ports:
+      - ""12800:12800""
+    networks:
+      - e2e
+
+  zookeeper:
+    image: zookeeper:latest
+    expose:
+      - 2181
+    networks:
+      - e2e
+    environment:
+      - ALLOW_ANONYMOUS_LOGIN=yes
+    healthcheck:
+      test: [""CMD"", ""sh"", ""-c"", ""nc -nz 127.0.0.1 2181""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  broker1:
+    build:
+      context: .
+    expose:
+      - 9092
+      - 7071
+    ports:
+      - '9092:9092'
+      - '7071:7071'
+    networks:
+      - e2e
+    environment:
+      - KAFKA_ENABLE_KRAFT=no
+      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
+      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
+      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://broker1:9092
+      - ALLOW_PLAINTEXT_LISTENER=yes
+      - KAFKA_OPTS=-javaagent:/etc/jmx_prometheus_javaagent-0.18.0.jar=7071:/etc/kafka-2_0_0.yml
+    depends_on:
+      zookeeper:
+        condition: service_healthy
+    # healthcheck:
+    #   test: [""CMD"", ""kafka-topics.sh"", ""--list"", ""--zookeeper"", ""zookeeper:2181""]
+    #   interval: 5s
+    #   timeout: 60s
+    #   retries: 120","[{'comment': '```suggestion\r\n    health check:\r\n      test: [""CMD"", ""kafka-topics.sh"", ""--list"", ""--zookeeper"", ""zookeeper:2181""]\r\n      interval: 5s\r\n      timeout: 60s\r\n      retries: 120\r\n```', 'commenter': 'wankai123'}]"
11282,test/e2e-v2/cases/kafka/kafka-monitoring/docker-compose.yml,"@@ -0,0 +1,131 @@
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+
+version: '3'
+
+services:
+  oap:
+    extends:
+      file: ../../../script/docker-compose/base-compose.yml
+      service: oap
+    ports:
+      - ""12800:12800""
+    networks:
+      - e2e
+
+  zookeeper:
+    image: zookeeper:latest
+    expose:
+      - 2181
+    networks:
+      - e2e
+    environment:
+      - ALLOW_ANONYMOUS_LOGIN=yes
+    healthcheck:
+      test: [""CMD"", ""sh"", ""-c"", ""nc -nz 127.0.0.1 2181""]
+      interval: 5s
+      timeout: 60s
+      retries: 120
+
+  broker1:
+    build:
+      context: .
+    expose:
+      - 9092
+      - 7071
+    ports:
+      - '9092:9092'
+      - '7071:7071'
+    networks:
+      - e2e
+    environment:
+      - KAFKA_ENABLE_KRAFT=no
+      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
+      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
+      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://broker1:9092
+      - ALLOW_PLAINTEXT_LISTENER=yes
+      - KAFKA_OPTS=-javaagent:/etc/jmx_prometheus_javaagent-0.18.0.jar=7071:/etc/kafka-2_0_0.yml
+    depends_on:
+      zookeeper:
+        condition: service_healthy
+    # healthcheck:
+    #   test: [""CMD"", ""kafka-topics.sh"", ""--list"", ""--zookeeper"", ""zookeeper:2181""]
+    #   interval: 5s
+    #   timeout: 60s
+    #   retries: 120
+    
+  broker2:
+    build:
+      context: .
+    expose:
+      - 9093
+      - 7072
+    ports:
+      - '9093:9093'
+      - '7072:7072'
+    networks:
+      - e2e
+    environment:
+      - KAFKA_ENABLE_KRAFT=no
+      - KAFKA_CFG_ZOOKEEPER_CONNECT=zookeeper:2181
+      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9093
+      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://broker2:9093
+      - ALLOW_PLAINTEXT_LISTENER=yes
+      - KAFKA_OPTS=-javaagent:/etc/jmx_prometheus_javaagent-0.18.0.jar=7072:/etc/kafka-2_0_0.yml
+    depends_on:
+      zookeeper:
+        condition: service_healthy","[{'comment': '```suggestion\r\n        condition: service_healthy\r\n    health check:\r\n      test: [""CMD"", ""kafka-topics.sh"", ""--list"", ""--zookeeper"", ""zookeeper:2181""]\r\n      interval: 5s\r\n      timeout: 60s\r\n      retries: 120\r\n```', 'commenter': 'wankai123'}]"
11282,oap-server/server-starter/src/main/resources/ui-initialized-templates/kafka/kafka-cluster.json,"@@ -0,0 +1,232 @@
+[{
+	""id"": ""Kafka-Cluster"",
+	""configuration"": {
+		""children"": [{
+			""x"": 0,
+			""y"": 0,
+			""w"": 24,
+			""h"": 59,
+			""i"": ""16"",
+			""type"": ""Tab"",
+			""children"": [{
+				""name"": ""Overview"",
+				""children"": [{
+					""x"": 16,
+					""y"": 10,
+					""w"": 8,
+					""h"": 10,
+					""i"": ""13"",
+					""type"": ""Widget"",
+					""metricTypes"": [""readLabeledMetricsValues""],
+					""metrics"": [""meter_kafka_partition_count""],","[{'comment': 'we should use MQE for queries in the new feature ', 'commenter': 'wankai123'}]"
11282,.github/workflows/skywalking.yaml,"@@ -676,7 +676,9 @@ jobs:
           name: docker-images-11
           path: docker-images
       - name: Load docker images
-        run: find docker-images -name ""*.tar"" -exec docker load -i {} \;
+        run: |
+          find docker-images -name ""*.tar"" -exec docker load -i {} \;
+          find docker-images -name ""*.tar"" -exec rm {} \;","[{'comment': '@ZhuWang1112 We helped you to fix this. New downloads seem to be over the volume size limitation, which causes the failure.', 'commenter': 'wu-sheng'}, {'comment': 'Really appreciate your help, and I will be mindful of the volume size limitation in the future.', 'commenter': 'ZhuWang1112'}]"
11389,pom.xml,"@@ -170,7 +170,7 @@
 
         <!-- core lib dependency -->
         <grpc.version>1.53.0</grpc.version>
-        <netty.version>4.1.86.Final</netty.version>
+        <netty.version>4.1.94.Final</netty.version>","[{'comment': 'What about 4.1.97. As it is used by grpc-java\r\n\r\nhttps://github.com/grpc/grpc-java/commit/88b3484a602336b6688ca943d29b033c127dc533', 'commenter': 'lujiajing1126'}, {'comment': '@lujiajing1126 We manage netty version separately AFAIK. We ignore the gRPC-Java dependency. The skywalking-eye license check verified the final use.', 'commenter': 'wu-sheng'}]"
