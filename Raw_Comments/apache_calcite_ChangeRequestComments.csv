Pull,Path,Diff_hunk,Comment
426,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -1421,7 +1421,6 @@ public Void apply(ResultSet resultSet) {
         + ""    BindableFilter(condition=[AND(>=(/INT(Reinterpret($0), 86400000), 1997-01-01), <(/INT(Reinterpret($0), 86400000), 1998-01-01), OR(AND(>=(/INT(Reinterpret($0), 86400000), 1997-04-01), <(/INT(Reinterpret($0), 86400000), 1997-05-01)), AND(>=(/INT(Reinterpret($0), 86400000), 1997-06-01), <(/INT(Reinterpret($0), 86400000), 1997-07-01))))])\n""
         + ""      DruidQuery(table=[[foodmart, foodmart]], intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], projects=[[$0]])"";
     sql(sql)
-        .explainContains(explain)","[{'comment': 'Why did you remove this?', 'commenter': 'jcamachor'}, {'comment': 'good catch ', 'commenter': 'b-slim'}]"
426,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -1695,28 +1694,120 @@ public Void apply(ResultSet resultSet) {
         + ""where EXTRACT( year from \""timestamp\"") = 1997 and ""
         + ""\""cases_per_pallet\"" >= 8 and \""cases_per_pallet\"" <= 10 and ""
         + ""\""units_per_case\"" < 15 "";
-    String druidQuery = ""{'queryType':'select','dataSource':'foodmart','descending':false,""
-        + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
-        + ""'filter':{'type':'and',""
-        + ""'fields':[{'type':'bound','dimension':'cases_per_pallet','lower':'8',""
-        + ""'lowerStrict':false,'ordering':'numeric'},""
-        + ""{'type':'bound','dimension':'cases_per_pallet','upper':'10','upperStrict':false,""
-        + ""'ordering':'numeric'},{'type':'bound','dimension':'units_per_case','upper':'15',""
-        + ""'upperStrict':true,'ordering':'numeric'}]},'dimensions':[],'metrics':['store_sales'],""
-        + ""'granularity':'all','pagingSpec':{'threshold':16384,'fromNext':true},""
-        + ""'context':{'druid.query.fetch':false}}"";
+    String druidQuery = ""{\""queryType\"":\""timeseries\"",\""dataSource\"":\""foodmart\"",""
+        + ""\""descending\"":false,\""granularity\"":\""all\"",\""filter\"":{\""type\"":\""and\"",""
+        + ""\""fields\"":[{\""type\"":\""bound\"",\""dimension\"":\""cases_per_pallet\"",\""lower\"":\""8\"",""
+        + ""\""lowerStrict\"":false,\""ordering\"":\""numeric\""},{\""type\"":\""bound\"",""
+        + ""\""dimension\"":\""cases_per_pallet\"",\""upper\"":\""10\"",\""upperStrict\"":false,""
+        + ""\""ordering\"":\""numeric\""},{\""type\"":\""bound\"",\""dimension\"":\""units_per_case\"",""
+        + ""\""upper\"":\""15\"",\""upperStrict\"":true,\""ordering\"":\""numeric\""},""
+        + ""{\""type\"":\""selector\"",\""dimension\"":\""__time\"",\""value\"":\""1997\"",""
+        + ""\""extractionFn\"":{\""type\"":\""timeFormat\"",\""format\"":\""yyyy\"",\""timeZone\"":\""UTC\"",""
+        + ""\""locale\"":\""en-US\""}}]},\""aggregations\"":[{\""type\"":\""doubleSum\"",""
+        + ""\""name\"":\""EXPR$0\"",\""fieldName\"":\""store_sales\""}],""
+        + ""\""intervals\"":[\""1900-01-09T00:00:00.000/2992-01-10T00:00:00.000\""],""
+        + ""\""context\"":{\""skipEmptyBuckets\"":true}}"";
     sql(sql)
         .queryContains(druidChecker(druidQuery))
-        .explainContains(""PLAN=EnumerableInterpreter\n""","[{'comment': 'Why? It would be good to still check the complete explain plan', 'commenter': 'jcamachor'}, {'comment': 'the druid query has all the plan, so not sure why have both ? i think one is enough if the query is fully executed by druid.', 'commenter': 'b-slim'}, {'comment': 'How do we know we do not have any computation in Calcite side if we do not check the explain plan? For instance, if there is a bug in the rewriting rules, we might push computation to Druid and still leave (useless) operators on top of the DruidQuery?', 'commenter': 'jcamachor'}, {'comment': 'because i read the druid query and it matches exactly the sql query this means all is pushed and the query make sense, so not sure what is the issue here ? ', 'commenter': 'b-slim'}, {'comment': ""We have a rule that can push an operator _partially_ into Druid, i.e., some computation is pushed to Druid and some part stays in the plan. I want to double check that we do not compute anything twice, as _pushing everything to Druid_ is not equal to _not leaving the same operation in the plan_. Why don't we add the explain plan check to extend the test coverage and be certain now and in the future that this is working correctly, even if I get your point that current rule should not be doing that?"", 'commenter': 'jcamachor'}, {'comment': 'i will add it to please you. ', 'commenter': 'b-slim'}, {'comment': 'Thanks', 'commenter': 'jcamachor'}]"
426,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -1695,28 +1694,120 @@ public Void apply(ResultSet resultSet) {
         + ""where EXTRACT( year from \""timestamp\"") = 1997 and ""
         + ""\""cases_per_pallet\"" >= 8 and \""cases_per_pallet\"" <= 10 and ""
         + ""\""units_per_case\"" < 15 "";
-    String druidQuery = ""{'queryType':'select','dataSource':'foodmart','descending':false,""
-        + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
-        + ""'filter':{'type':'and',""
-        + ""'fields':[{'type':'bound','dimension':'cases_per_pallet','lower':'8',""
-        + ""'lowerStrict':false,'ordering':'numeric'},""
-        + ""{'type':'bound','dimension':'cases_per_pallet','upper':'10','upperStrict':false,""
-        + ""'ordering':'numeric'},{'type':'bound','dimension':'units_per_case','upper':'15',""
-        + ""'upperStrict':true,'ordering':'numeric'}]},'dimensions':[],'metrics':['store_sales'],""
-        + ""'granularity':'all','pagingSpec':{'threshold':16384,'fromNext':true},""
-        + ""'context':{'druid.query.fetch':false}}"";
+    String druidQuery = ""{\""queryType\"":\""timeseries\"",\""dataSource\"":\""foodmart\"",""","[{'comment': 'Is it possible to use single quotes for DruidQuery instead of escaping the double quotes?', 'commenter': 'jcamachor'}, {'comment': 'does it make any difference ? ', 'commenter': 'b-slim'}, {'comment': 'Readability + having uniform code base.', 'commenter': 'jcamachor'}]"
426,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -1695,28 +1694,120 @@ public Void apply(ResultSet resultSet) {
         + ""where EXTRACT( year from \""timestamp\"") = 1997 and ""
         + ""\""cases_per_pallet\"" >= 8 and \""cases_per_pallet\"" <= 10 and ""
         + ""\""units_per_case\"" < 15 "";
-    String druidQuery = ""{'queryType':'select','dataSource':'foodmart','descending':false,""
-        + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
-        + ""'filter':{'type':'and',""
-        + ""'fields':[{'type':'bound','dimension':'cases_per_pallet','lower':'8',""
-        + ""'lowerStrict':false,'ordering':'numeric'},""
-        + ""{'type':'bound','dimension':'cases_per_pallet','upper':'10','upperStrict':false,""
-        + ""'ordering':'numeric'},{'type':'bound','dimension':'units_per_case','upper':'15',""
-        + ""'upperStrict':true,'ordering':'numeric'}]},'dimensions':[],'metrics':['store_sales'],""
-        + ""'granularity':'all','pagingSpec':{'threshold':16384,'fromNext':true},""
-        + ""'context':{'druid.query.fetch':false}}"";
+    String druidQuery = ""{\""queryType\"":\""timeseries\"",\""dataSource\"":\""foodmart\"",""
+        + ""\""descending\"":false,\""granularity\"":\""all\"",\""filter\"":{\""type\"":\""and\"",""
+        + ""\""fields\"":[{\""type\"":\""bound\"",\""dimension\"":\""cases_per_pallet\"",\""lower\"":\""8\"",""
+        + ""\""lowerStrict\"":false,\""ordering\"":\""numeric\""},{\""type\"":\""bound\"",""
+        + ""\""dimension\"":\""cases_per_pallet\"",\""upper\"":\""10\"",\""upperStrict\"":false,""
+        + ""\""ordering\"":\""numeric\""},{\""type\"":\""bound\"",\""dimension\"":\""units_per_case\"",""
+        + ""\""upper\"":\""15\"",\""upperStrict\"":true,\""ordering\"":\""numeric\""},""
+        + ""{\""type\"":\""selector\"",\""dimension\"":\""__time\"",\""value\"":\""1997\"",""
+        + ""\""extractionFn\"":{\""type\"":\""timeFormat\"",\""format\"":\""yyyy\"",\""timeZone\"":\""UTC\"",""
+        + ""\""locale\"":\""en-US\""}}]},\""aggregations\"":[{\""type\"":\""doubleSum\"",""
+        + ""\""name\"":\""EXPR$0\"",\""fieldName\"":\""store_sales\""}],""
+        + ""\""intervals\"":[\""1900-01-09T00:00:00.000/2992-01-10T00:00:00.000\""],""
+        + ""\""context\"":{\""skipEmptyBuckets\"":true}}"";
     sql(sql)
         .queryContains(druidChecker(druidQuery))
-        .explainContains(""PLAN=EnumerableInterpreter\n""
-             + ""  BindableAggregate(group=[{}], EXPR$0=[SUM($1)])\n""
-             + ""    BindableFilter(condition=[AND(>=(/INT(Reinterpret($0), 86400000), 1997-01-01), ""
-             + ""<(/INT(Reinterpret($0), 86400000), 1998-01-01))])\n""
-             + ""      DruidQuery(table=[[foodmart, foodmart]], ""
-             + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
-             + ""filter=[AND(>=(CAST($11):BIGINT, 8), <=(CAST($11):BIGINT, 10), ""
-             + ""<(CAST($10):BIGINT, 15))], projects=[[$0, $90]])\n"")
         .returnsUnordered(""EXPR$0=75364.09998679161"");
   }
+
+  @Test public void testPushOfFilterExtractionOnDayAndMonth() {
+    String sql = ""SELECT \""product_id\"" , EXTRACT(day from \""timestamp\""), EXTRACT(month from ""
+        + ""\""timestamp\"") from \""foodmart\"" WHERE  EXTRACT(day from \""timestamp\"") >= 30 AND ""
+        + ""EXTRACT(month from \""timestamp\"") = 11 ""
+        + ""AND  \""product_id\"" >= 1549 group by \""product_id\"", EXTRACT(day from ""
+        + ""\""timestamp\""), EXTRACT(month from \""timestamp\"")"";
+    sql(sql)","[{'comment': 'We should add the DruidQuery in this case too, even if we verify that we are actually pushing the EXTRACT for other queries below.', 'commenter': 'jcamachor'}, {'comment': 'ok', 'commenter': 'b-slim'}]"
426,druid/src/main/java/org/apache/calcite/adapter/druid/ExtractionFunctionUtil.java,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.druid;
+
+
+import org.apache.calcite.avatica.util.TimeUnitRange;
+import org.apache.calcite.rex.RexCall;
+import org.apache.calcite.rex.RexLiteral;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlKind;
+
+
+/**
+ * Utility class for extraction function mapping between SQL and Druid
+ */
+public class ExtractionFunctionUtil {
+
+  private ExtractionFunctionUtil() {
+  }
+
+  /**
+   * @param rexNode RexNode that might contains an extraction function","[{'comment': 'A short description would be nice.', 'commenter': 'jcamachor'}]"
426,druid/src/main/java/org/apache/calcite/adapter/druid/ExtractionFunctionUtil.java,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.druid;
+
+
+import org.apache.calcite.avatica.util.TimeUnitRange;
+import org.apache.calcite.rex.RexCall;
+import org.apache.calcite.rex.RexLiteral;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlKind;
+
+
+/**
+ * Utility class for extraction function mapping between SQL and Druid
+ */
+public class ExtractionFunctionUtil {","[{'comment': 'You can make the class _final_.', 'commenter': 'jcamachor'}, {'comment': 'ok\r\n', 'commenter': 'b-slim'}]"
426,druid/src/main/java/org/apache/calcite/adapter/druid/DruidRules.java,"@@ -205,12 +205,12 @@ public void onMatch(RelOptRuleCall call) {
         intervals = DruidDateTimeUtils.createInterval(
             query.getRowType().getFieldList().get(timestampFieldIdx).getType(),
             RexUtil.composeConjunction(rexBuilder, triple.getLeft(), false));
-        if (intervals == null) {
-          // We can't push anything useful to Druid.
-          residualPreds.addAll(triple.getLeft());
+        if (intervals == null || intervals.isEmpty()) {
+          // Case we have an filter with extract that can not be written as interval push down
+          triple.getMiddle().addAll(triple.getLeft());","[{'comment': 'Cool! ', 'commenter': 'jcamachor'}]"
426,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -980,35 +997,43 @@ private JsonFilter translateFilter(RexNode e) {
         final boolean numeric =
             call.getOperands().get(posRef).getType().getFamily()
                 == SqlTypeFamily.NUMERIC;
+
+        final ExtractionFunction extractionFunction = ExtractionFunctionUtil.buildExtraction(call
+            .getOperands().get(posRef));
+        String dimName = tr(e, posRef);
+        if (dimName.equals(DruidConnectionImpl.DEFAULT_RESPONSE_TIMESTAMP_COLUMN)) {
+          dimName = ""__time"";","[{'comment': 'Please, use DruidTable.DEFAULT_TIMESTAMP_COLUMN here and leave a comment explaining why we are renaming the dimension column.', 'commenter': 'jcamachor'}, {'comment': 'ok', 'commenter': 'b-slim'}]"
426,druid/src/main/java/org/apache/calcite/adapter/druid/DruidRules.java,"@@ -205,12 +205,12 @@ public void onMatch(RelOptRuleCall call) {
         intervals = DruidDateTimeUtils.createInterval(
             query.getRowType().getFieldList().get(timestampFieldIdx).getType(),
             RexUtil.composeConjunction(rexBuilder, triple.getLeft(), false));
-        if (intervals == null) {
-          // We can't push anything useful to Druid.
-          residualPreds.addAll(triple.getLeft());
+        if (intervals == null || intervals.isEmpty()) {
+          // Case we have an filter with extract that can not be written as interval push down
+          triple.getMiddle().addAll(triple.getLeft());
         }
       }
-      if (intervals == null && triple.getMiddle().isEmpty()) {
+      if ((intervals == null || intervals.isEmpty()) && triple.getMiddle().isEmpty()) {","[{'comment': 'This _if_ block can be removed now: we will never enter.', 'commenter': 'jcamachor'}, {'comment': 'i am sure we have cases where the intervals are empty so not sure what you mean by removing it ? ', 'commenter': 'b-slim'}, {'comment': 'This condition will never be true: if intervals are null or empty, we will have put the corresponding predicates in triple.getMiddle. If they are empty because triple.getLeft was empty and triple.getMiddle is empty too, we will have entered in L198.', 'commenter': 'jcamachor'}]"
433,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -377,9 +381,10 @@ public DruidTable getDruidTable() {
         // A plan where all extra columns are pruned will be preferred.
         .multiplyBy(
             RelMdUtil.linear(querySpec.fieldNames.size(), 2, 100, 1d, 2d))
-        .multiplyBy(getQueryTypeCostMultiplier());
+        .multiplyBy(getQueryTypeCostMultiplier())
+        // a plan with sort pushed to druid is better than doing sort outside of druid
+        .multiplyBy(Util.last(rels) instanceof Bindables.BindableSort ? 0.1 : 0.2);","[{'comment': 'We should use the superclass in case other rules do not generate a Sort with bindable convention, i.e., use _instanceof Sort_ instead of _BindableSort_.\r\n\r\nFurther, if last operator is not a SortLimit, we should just leave cost as it is, i.e., multiply by _1_ instead of _0.2_.', 'commenter': 'jcamachor'}, {'comment': 'ok\r\n', 'commenter': 'b-slim'}]"
433,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -525,63 +531,67 @@ protected QuerySpec getQuery(RelDataType rowType, RexNode filter, List<RexNode>
       assert aggCalls.size() == aggNames.size();
 
       int timePositionIdx = -1;
-      int extractNumber = -1;
       final ImmutableList.Builder<String> builder = ImmutableList.builder();
       if (projects != null) {
         for (int groupKey : groupSet) {
-          final String s = fieldNames.get(groupKey);
+          final String fieldName = fieldNames.get(groupKey);
           final RexNode project = projects.get(groupKey);
           if (project instanceof RexInputRef) {
             // Reference could be to the timestamp or druid dimension but no druid metric
             final RexInputRef ref = (RexInputRef) project;
-            final String origin = druidTable.getRowType(getCluster().getTypeFactory())
+            final String originalFieldName = druidTable.getRowType(getCluster().getTypeFactory())
                 .getFieldList().get(ref.getIndex()).getName();
-            if (origin.equals(druidTable.timestampFieldName)) {
-              granularity = Granularity.ALL;
-              // Generate unique name as timestampFieldName is taken
-              String extractColumnName = EXTRACT_COLUMN_NAME_PREFIX + ""_"" + (++extractNumber);
-              while (fieldNames.contains(extractColumnName)) {
-                extractColumnName = EXTRACT_COLUMN_NAME_PREFIX + ""_"" + (++extractNumber);
-              }
+            if (originalFieldName.equals(druidTable.timestampFieldName)) {
+              finalGranularity = Granularity.ALL;
+              String extractColumnName = SqlValidatorUtil.uniquify(EXTRACT_COLUMN_NAME_PREFIX","[{'comment': 'Cool!', 'commenter': 'jcamachor'}]"
433,druid/src/main/java/org/apache/calcite/adapter/druid/DruidRules.java,"@@ -590,32 +589,21 @@ private static boolean validSortLimit(Sort sort, DruidQuery query) {
         int metricsRefs = 0;
         for (RelFieldCollation col : sort.collation.getFieldCollations()) {
           int idx = col.getFieldIndex();
+          //computes the number of metrics in the sort
           if (idx >= topAgg.getGroupCount()) {
             metricsRefs++;","[{'comment': '_metricsRefs_ is not used anymore (and it seems it is not needed). If it became useless, could we get rid of it?', 'commenter': 'jcamachor'}, {'comment': 'ok\r\n', 'commenter': 'b-slim'}]"
433,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -503,15 +493,25 @@ public Void apply(ResultSet input) {
             ""gender=F; state_province=OR"",
             ""gender=M; state_province=WA"",
             ""gender=F; state_province=WA"")
+        .queryContains(
+            druidChecker(""{'queryType':'groupBy','dataSource':'foodmart',""
+            + ""'granularity':'all','dimensions':[{'type':'default',""
+            + ""'dimension':'gender'},{'type':'default',""
+            + ""'dimension':'state_province'}],'limitSpec':{'type':'default',""
+            + ""'columns':[{'dimension':'state_province','direction':'ascending'},""
+            + ""{'dimension':'gender','direction':'descending'}]},""
+            + ""'aggregations':[{'type':'longSum','name':'dummy_agg',""
+            + ""'fieldName':'dummy_agg'}],""
+            + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000']}""))
         .explainContains(explain);
   }
 
   @Test public void testSortLimit() {
-    // Note: We do not push down SORT-LIMIT into Druid ""groupBy"" query yet
-    final String explain = ""PLAN=""
-        + ""EnumerableInterpreter\n""
-        + ""  BindableSort(sort0=[$1], sort1=[$0], dir0=[ASC], dir1=[DESC], offset=[2], fetch=[3])\n""
-        + ""    DruidQuery(table=[[foodmart, foodmart]], intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], projects=[[$39, $30]], groups=[{0, 1}], aggs=[[]])"";
+    final String explain = ""PLAN=EnumerableLimit(offset=[2], fetch=[3])\n""","[{'comment': 'It seems we do not push the limit because of the _offset_? In that case, we could just push the _fetch_ part and keep the offset/limit on top of the DruidQuery as it is right now, I think that would still be beneficial. Since this is not a blocker, we could tackle that in a follow-up. Could you create a JIRA case to keep track of the issue?', 'commenter': 'jcamachor'}, {'comment': 'i guess this can be tricky, since druid does not support offsets -> i need to alter the limit and return let say 5 instead of 3 and let calcite do the offset ?\r\n', 'commenter': 'b-slim'}, {'comment': 'Exactly, that is what I meant. But in any case, it can be part of a follow-up as this patch is almost ready; we can create the issue and tackle later.', 'commenter': 'jcamachor'}, {'comment': '👍 ', 'commenter': 'b-slim'}]"
436,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -634,9 +634,19 @@ protected QuerySpec getQuery(RelDataType rowType, RexNode filter, List<RexNode>
         ImmutableList.Builder<JsonCollation> colBuilder =
             ImmutableList.builder();
         for (Pair<Integer, Direction> p : Pair.zip(collationIndexes, collationDirections)) {
+          boolean isNumericSort = false;","[{'comment': ""Why don't we extract the _types_ in the loop in L464 into a list  _collationTypes_, we pass the list to _getQuery_ method, and then just use the following check?\r\n\r\n``if (collationTypes.get(x).getType().getFamily() == SqlTypeFamily.NUMERIC) { ... } ``\r\n\r\nThat would be less ad-hoc than just using group by column position and then falling back to checking projects (plus it should work even if dimensions are not of character type in future)."", 'commenter': 'jcamachor'}, {'comment': 'i thought about that, but looked a bigger more intrusive change than this one, but i can do it that way.', 'commenter': 'b-slim'}]"
449,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -114,9 +114,9 @@ public Result visit(Join e) {
     SqlNode sqlCondition = null;
     SqlLiteral condType = JoinConditionType.ON.symbol(POS);
     JoinType joinType = joinType(e.getJoinType());
-    if (e.getJoinType() == JoinRelType.INNER && e.getCondition().isAlwaysTrue()) {
-      joinType = JoinType.COMMA;
-      condType = JoinConditionType.NONE.symbol(POS);
+    if ((e.getJoinType() == JoinRelType.INNER || e.getJoinType() == JoinRelType.FULL)","[{'comment': 'just remove both of these and leave `isAlwaysTrue()`', 'commenter': 'jbalint'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidConnectionImpl.java,"@@ -338,8 +338,40 @@ private void parseField(List<String> fieldNames, List<ColumnMetaData.Rep> fieldT
       break;
     case VALUE_STRING:
     default:
-      rowBuilder.set(i, parser.getText());
-      break;
+      String s = parser.getText();
+      if (type != null) {
+        switch (type) {
+        case LONG:
+        case PRIMITIVE_LONG:
+        case SHORT:
+        case PRIMITIVE_SHORT:
+        case INTEGER:
+        case PRIMITIVE_INT:
+          if (s.equals(""Infinity"") || s.equals(""-Infinity"") || s.equals(""NaN"")) {
+            throw new RuntimeException(""/ by zero"");
+          }
+        case FLOAT:
+        case PRIMITIVE_FLOAT:
+        case PRIMITIVE_DOUBLE:
+        case NUMBER:
+        case DOUBLE:
+          if (s.equals(""Infinity"")) {
+            rowBuilder.set(i, Double.POSITIVE_INFINITY);
+            break;","[{'comment': 'Could you move the three ```break;``` clauses to the end of the ```case``` block? No need to have three.', 'commenter': 'jcamachor'}, {'comment': 'The reason I put break in each branch is because when the String calcite received is not ""Infinite"", ""-Inifinty\' and ""NaN"", it is possible that the String is a String representing float number. This case will be dealt in the default branch. I can change it to a switch cases to keep this logic. Or is it actually all return of Float calcite type can only be String when return is one of ""Infinity"", ""NaN"" and ""-Infinity""?', 'commenter': 'axeisghost'}, {'comment': 'Thanks, I did not realize about the fall through. I guess it is matter of style, usually I prefer to nest switch statements within default case in this scenario, as I find it more readable, but this is valid too.\r\nIf you leave it as it is, maybe you could add ```//fallthrough``` at the end of the each such ```case``` to make it more evident, as you prefer.', 'commenter': 'jcamachor'}, {'comment': 'I am not sure what do you mean. Do you prefer:\r\n```java\r\ncase FLOAT:\r\n  //fallthrough\r\ncase PRIMITIVE_FLOAT:\r\n  //fallthrough\r\ncase PRIMITIVE_DOUBLE:\r\n  //fallthrough\r\ncase NUMBER:\r\n  //fallthrough\r\ncase DOUBLE:\r\n          if (s.equals(""Infinity"")) {\r\n            rowBuilder.set(i, Double.POSITIVE_INFINITY);\r\n            break;\r\n          } else if (s.equals(""-Infinity"")) {\r\n            rowBuilder.set(i, Double.NEGATIVE_INFINITY);\r\n            break;\r\n          } else if (s.equals(""NaN"")) {\r\n            rowBuilder.set(i, Double.NaN);\r\n            break;\r\n          }\r\n        //fallthrough\r\n        default:\r\n```\r\nor just:\r\n```java\r\n  case FLOAT:\r\n  case PRIMITIVE_FLOAT:\r\n  case PRIMITIVE_DOUBLE:\r\n  case NUMBER:\r\n  case DOUBLE:\r\n          if (s.equals(""Infinity"")) {\r\n            rowBuilder.set(i, Double.POSITIVE_INFINITY);\r\n            break;\r\n          } else if (s.equals(""-Infinity"")) {\r\n            rowBuilder.set(i, Double.NEGATIVE_INFINITY);\r\n            break;\r\n          } else if (s.equals(""NaN"")) {\r\n            rowBuilder.set(i, Double.NaN);\r\n            break;\r\n          }\r\n         //fallthrough\r\n        default:\r\n```\r\nI think the first one is what you mean, but it seems a little bit cumbersome. The second is good enough to clarify the confusion in here.', 'commenter': 'axeisghost'}, {'comment': 'I meant the second option :)', 'commenter': 'jcamachor'}, {'comment': 'Thank you very much. I will push commit soon. ', 'commenter': 'axeisghost'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -833,6 +863,54 @@ protected JsonAggregation getJsonAggregation(List<String> fieldNames,
     }
   }
 
+  public JsonPostAggregation getJsonPostAggregation(String name, RexNode rexNode, RelNode rel) {
+    if (rexNode instanceof RexCall) {
+      List<JsonPostAggregation> fields = new ArrayList<>();
+      for (RexNode ele : ((RexCall) rexNode).getOperands()) {
+        JsonPostAggregation field = getJsonPostAggregation("""", ele, rel);
+        if (field == null) {
+          return null;","[{'comment': 'What has happened in order to return null from this method? This should never happen as we have done all checks before, right?\r\nIf we return null because we hit an unexpected condition, please throw an Exception. Same for all return nulls in this method.', 'commenter': 'jcamachor'}, {'comment': 'Thanks. Yes I should do that, will include this fix in the next commit.', 'commenter': 'axeisghost'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -833,6 +863,54 @@ protected JsonAggregation getJsonAggregation(List<String> fieldNames,
     }
   }
 
+  public JsonPostAggregation getJsonPostAggregation(String name, RexNode rexNode, RelNode rel) {
+    if (rexNode instanceof RexCall) {
+      List<JsonPostAggregation> fields = new ArrayList<>();
+      for (RexNode ele : ((RexCall) rexNode).getOperands()) {
+        JsonPostAggregation field = getJsonPostAggregation("""", ele, rel);
+        if (field == null) {
+          return null;
+        }
+        fields.add(field);
+      }
+      switch (rexNode.getKind()) {
+      case PLUS:
+        return new JsonArithmetic(name, ""+"", fields, null);
+      case MINUS:
+        return new JsonArithmetic(name, ""-"", fields, null);
+      case DIVIDE:
+        return new JsonArithmetic(name, ""quotient"", fields, null);
+      case TIMES:
+        return new JsonArithmetic(name, ""*"", fields, null);
+      case CAST:
+        return getJsonPostAggregation(name, ((RexCall) rexNode).getOperands().get(0),
+            rel);
+      default:
+      }
+    } else if (rexNode instanceof RexInputRef) {
+      if (rel instanceof Aggregate) {","[{'comment': 'Could this be other than ```Aggregate```? It seems to me from L101 in this same class that the OrderBy/Limit is applied after the PostAggregation Project. If this can be any other operator, which ones? Otherwise, the ```if``` clause should go away.', 'commenter': 'jcamachor'}, {'comment': 'Yes. I used this before I used signature to check input DruidQuery. Thanks', 'commenter': 'axeisghost'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -833,6 +863,54 @@ protected JsonAggregation getJsonAggregation(List<String> fieldNames,
     }
   }
 
+  public JsonPostAggregation getJsonPostAggregation(String name, RexNode rexNode, RelNode rel) {
+    if (rexNode instanceof RexCall) {
+      List<JsonPostAggregation> fields = new ArrayList<>();
+      for (RexNode ele : ((RexCall) rexNode).getOperands()) {
+        JsonPostAggregation field = getJsonPostAggregation("""", ele, rel);
+        if (field == null) {
+          return null;
+        }
+        fields.add(field);
+      }
+      switch (rexNode.getKind()) {
+      case PLUS:
+        return new JsonArithmetic(name, ""+"", fields, null);
+      case MINUS:
+        return new JsonArithmetic(name, ""-"", fields, null);
+      case DIVIDE:
+        return new JsonArithmetic(name, ""quotient"", fields, null);
+      case TIMES:
+        return new JsonArithmetic(name, ""*"", fields, null);
+      case CAST:
+        return getJsonPostAggregation(name, ((RexCall) rexNode).getOperands().get(0),
+            rel);
+      default:
+      }
+    } else if (rexNode instanceof RexInputRef) {
+      if (rel instanceof Aggregate) {
+        Integer indexSkipGroup = ((RexInputRef) rexNode).getIndex()","[{'comment': 'The schema of the Aggregate is grouping columns, followed by indicator columns, followed by aggregate calls. Since Aggregate pushed to Druid cannot have grouping sets at the moment, indicator columns size will be zero. Could you add a comment stating this as the reason why we only subtract the number of grouping columns?', 'commenter': 'jcamachor'}, {'comment': 'Will add in next commit', 'commenter': 'axeisghost'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -833,6 +863,54 @@ protected JsonAggregation getJsonAggregation(List<String> fieldNames,
     }
   }
 
+  public JsonPostAggregation getJsonPostAggregation(String name, RexNode rexNode, RelNode rel) {
+    if (rexNode instanceof RexCall) {
+      List<JsonPostAggregation> fields = new ArrayList<>();
+      for (RexNode ele : ((RexCall) rexNode).getOperands()) {
+        JsonPostAggregation field = getJsonPostAggregation("""", ele, rel);
+        if (field == null) {
+          return null;
+        }
+        fields.add(field);
+      }
+      switch (rexNode.getKind()) {
+      case PLUS:
+        return new JsonArithmetic(name, ""+"", fields, null);
+      case MINUS:
+        return new JsonArithmetic(name, ""-"", fields, null);
+      case DIVIDE:
+        return new JsonArithmetic(name, ""quotient"", fields, null);
+      case TIMES:
+        return new JsonArithmetic(name, ""*"", fields, null);
+      case CAST:
+        return getJsonPostAggregation(name, ((RexCall) rexNode).getOperands().get(0),
+            rel);
+      default:
+      }
+    } else if (rexNode instanceof RexInputRef) {
+      if (rel instanceof Aggregate) {
+        Integer indexSkipGroup = ((RexInputRef) rexNode).getIndex()
+            - ((Aggregate) rel).getGroupSet().cardinality();","[{'comment': 'Use ```Aggregate.getGroupCount()``` instead.', 'commenter': 'jcamachor'}, {'comment': 'Sure, I was following the code [here](https://github.com/apache/calcite/blob/56d5261abb893dd92b0a2cc4893292876a2b7880/core/src/main/java/org/apache/calcite/sql2rel/SqlToRelConverter.java#L2760) when I am reading the codebase.', 'commenter': 'axeisghost'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidQuery.java,"@@ -833,6 +863,54 @@ protected JsonAggregation getJsonAggregation(List<String> fieldNames,
     }
   }
 
+  public JsonPostAggregation getJsonPostAggregation(String name, RexNode rexNode, RelNode rel) {
+    if (rexNode instanceof RexCall) {
+      List<JsonPostAggregation> fields = new ArrayList<>();
+      for (RexNode ele : ((RexCall) rexNode).getOperands()) {
+        JsonPostAggregation field = getJsonPostAggregation("""", ele, rel);
+        if (field == null) {
+          return null;
+        }
+        fields.add(field);
+      }
+      switch (rexNode.getKind()) {
+      case PLUS:
+        return new JsonArithmetic(name, ""+"", fields, null);
+      case MINUS:
+        return new JsonArithmetic(name, ""-"", fields, null);
+      case DIVIDE:
+        return new JsonArithmetic(name, ""quotient"", fields, null);
+      case TIMES:
+        return new JsonArithmetic(name, ""*"", fields, null);
+      case CAST:
+        return getJsonPostAggregation(name, ((RexCall) rexNode).getOperands().get(0),
+            rel);
+      default:
+      }
+    } else if (rexNode instanceof RexInputRef) {
+      if (rel instanceof Aggregate) {
+        Integer indexSkipGroup = ((RexInputRef) rexNode).getIndex()
+            - ((Aggregate) rel).getGroupSet().cardinality();
+        AggregateCall aggCall = ((Aggregate) rel).getAggCallList().get(indexSkipGroup);
+        if (aggCall.isDistinct() && aggCall.getAggregation().getKind().equals(SqlKind.COUNT)) {
+          // Will be a hyper unique cardinality column.
+          // Use hyperUniqueCardinality post aggregator instead of field Accessor.
+          // TODO: Expect to change after CALC-1787
+          return new JsonHyperUniqueCardinality("""",
+              rel.getRowType().getFieldNames().get(((RexInputRef) rexNode).getIndex()));
+        }
+      }
+      return new JsonFieldAccessor("""",
+          rel.getRowType().getFieldNames().get(((RexInputRef) rexNode).getIndex()));
+    } else if (rexNode instanceof RexLiteral) {
+      if (((RexLiteral) rexNode).getValue3() instanceof BigDecimal) {","[{'comment': 'Why this special processing only for ```BigDecimal```? What happens if the literal is a constant but it is not of type ```BigDecimal```? Should you throw an Exception? As of now, method will return null then.\r\n\r\nFurther, could you add a comment explaining it?', 'commenter': 'jcamachor'}, {'comment': 'Constant Post aggregator only support number type constant, according to the [Documentation of RexLiteral](https://github.com/apache/calcite/blob/419b810fe67539cf7a3d653e918352fbaf10e8b0/core/src/main/java/org/apache/calcite/rex/RexLiteral.java#L171-L177), the numeric value of RexLiteral could be only BigDecimal type, so I only allow BigDecimal value in RexLiteral to be pushed in. Will add comment to clarify.', 'commenter': 'axeisghost'}]"
471,druid/src/main/java/org/apache/calcite/adapter/druid/DruidRules.java,"@@ -604,30 +798,36 @@ private static boolean validSortLimit(Sort sort, DruidQuery query) {
         // offset not supported by Druid
         return false;
       }
-      if (query.getTopNode() instanceof Aggregate) {
-        final Aggregate topAgg = (Aggregate) query.getTopNode();
-        final ImmutableBitSet.Builder positionsReferenced = ImmutableBitSet.builder();
-        for (RelFieldCollation col : sort.collation.getFieldCollations()) {
-          int idx = col.getFieldIndex();
-          if (idx >= topAgg.getGroupCount()) {
-            continue;
-          }
-          // has the indexes of the columns used for sorts
-          positionsReferenced.set(topAgg.getGroupSet().nth(idx));
-        }
-        // Case it is a timeseries query
-        if (checkIsFlooringTimestampRefOnQuery(topAgg.getGroupSet(), topAgg.getInput(), query)
-            && topAgg.getGroupCount() == 1) {
-          // do not push if it has a limit or more than one sort key or we have sort by
-          // metric/dimension
-          return !RelOptUtil.isLimit(sort) && sort.collation.getFieldCollations().size() == 1
-              && checkTimestampRefOnQuery(positionsReferenced.build(), topAgg.getInput(), query);
+      // Use a different logic to push down Sort RelNode because the top node could be a Project now
+      RelNode topNode = query.getTopNode();
+      Aggregate topAgg;
+      if (topNode instanceof Project && ((Project) topNode).getInput() instanceof Aggregate) {
+        topAgg = (Aggregate) ((Project) topNode).getInput();
+      } else if (topNode instanceof Aggregate) {
+        topAgg = (Aggregate) topNode;
+      } else {
+        // If it is going to be a Druid select operator, we push the limit if
+        // it does not contain a sort specification (required by Druid)
+        return RelOptUtil.isPureLimit(sort);
+      }
+      final ImmutableBitSet.Builder positionsReferenced = ImmutableBitSet.builder();
+      for (RelFieldCollation col : sort.collation.getFieldCollations()) {
+        int idx = col.getFieldIndex();
+        if (idx >= topAgg.getGroupCount()) {","[{'comment': 'I am confused here. If ```topNode``` is a Project (L804), then the Sort operator will reference the Project, not the Aggregate operator. Thus, I think now we need more complex checking here, as Project operator might be doing reordering of columns, computing expressions, etc.', 'commenter': 'jcamachor'}, {'comment': 'I read the logic of `DruidSortRule`. It checks the type of Druid Query (GroupBy, Timeseries, TopN, etc.) by checking the input of aggregate in the druid query. The project after aggregate that is pushed in can only have input reference or math operation on numeric columns. Even if it changes the order of column, the type of druid query will not be changed and moreover we can still check the type of DruidQuery by checking aggregate in the Druid Query, so Sort will be still valid to be pushed in.\r\n\r\nThe sort pushed in will take the last relNode in DQ as input (in this branch, it will be the post-project that get pushed in).  In the rendering time, the fieldNames of DQ already set correctly before the render of Sort Node, so it will get the right field names to render correct JsonCollation.\r\n\r\nFor other cases that post project does not get pushed in, the rule will be identical to the rule in before, so I think complexing checking is not necessary. Will add more test cases to verify it.', 'commenter': 'axeisghost'}, {'comment': 'See my comment below in the testcases.', 'commenter': 'jcamachor'}]"
471,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -2155,6 +2155,310 @@ public RelNode apply(RelBuilder b) {
         .queryContains(druidChecker(""'queryType':'timeseries'""));
   }
 
+  @Test public void testPlusArithmeticOperation() {
+    final String sqlQuery = ""select sum(\""store_sales\"") + sum(\""store_cost\"") as a, ""
+        + ""\""store_state\"" from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0','fn':'+',""
+        + ""'fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},{'type':'fieldAccess','""
+        + ""name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+        + ""groups=[{63}], aggs=[[SUM($90), SUM($91)]], projects=[[+($1, $2), $0]], ""
+        + ""sort0=[0], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""A=369117.525390625; store_state=WA"",
+            ""A=222698.26513671875; store_state=CA"",
+            ""A=199049.57055664062; store_state=OR"");
+  }
+
+  @Test public void testDivideArithmeticOperation() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_sales\"") / sum(\""store_cost\"") ""
+        + ""as a from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'quotient','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+            + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+            + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+            + ""groups=[{63}], aggs=[[SUM($90), SUM($91)]], projects=[[$0, /($1, $2)]], ""
+            + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=OR; A=2.5060913241562606"",
+            ""store_state=CA; A=2.505379731203625"",
+            ""store_state=WA; A=2.5045805694710124"");
+  }
+
+  @Test public void testMultiplyArithmeticOperation() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_sales\"") * sum(\""store_cost\"") ""
+        + ""as a from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'*','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+            + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+            + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+            + ""groups=[{63}], aggs=[[SUM($90), SUM($91)]], projects=[[$0, *($1, $2)]], ""
+            + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=WA; A=2.778383817085206E10"",
+            ""store_state=CA; A=1.0112000558236574E10"",
+            ""store_state=OR; A=8.077425009052019E9"");
+  }
+
+  @Test public void testMinusArithmeticOperation() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_sales\"") - sum(\""store_cost\"") ""
+        + ""as a from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'-','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+            + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+            + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+            + ""groups=[{63}], aggs=[[SUM($90), SUM($91)]], projects=[[$0, -($1, $2)]], ""
+            + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=WA; A=158468.908203125"",
+            ""store_state=CA; A=95637.41455078125"",
+            ""store_state=OR; A=85504.57006835938"");
+  }
+
+  @Test public void testConstantPostAggregator() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_sales\"") + 100 as a from ""
+        + ""\""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""{'type':'constant','name':'','value':100.0}"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+            + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+            + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+            + ""groups=[{63}], aggs=[[SUM($90)]], projects=[[$0, +($1, 100)]], ""
+            + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=WA; A=263893.216796875"",
+            ""store_state=CA; A=159267.83984375"",
+            ""store_state=OR; A=142377.0703125"");
+  }
+
+  @Test public void testRecursiveArithmeticOperation() {
+    final String sqlQuery = ""select \""store_state\"", -1 * (a + b) as c from (select ""
+        + ""(sum(\""store_sales\"")-sum(\""store_cost\"")) / (count(*) * 3) ""
+        + ""AS a,sum(\""unit_sales\"") AS b, \""store_state\""  from \""foodmart\""  group ""
+        + ""by \""store_state\"") order by c desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'*','fields':[{'type':'constant','name':'','value':-1.0},{'type':""
+        + ""'arithmetic','name':'','fn':'+','fields':[{'type':'arithmetic','name':""
+        + ""'','fn':'quotient','fields':[{'type':'arithmetic','name':'','fn':'-',""
+        + ""'fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},{'type':""
+        + ""'fieldAccess','name':'','fieldName':'$f2'}]},{'type':'arithmetic','name':""
+        + ""'','fn':'*','fields':[{'type':'fieldAccess','name':'','fieldName':'$f3'},""
+        + ""{'type':'constant','name':'','value':3.0}]}]},{'type':'fieldAccess','name'""
+        + "":'','fieldName':'B'}]}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+            + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], groups=[{63}], ""
+            + ""aggs=[[SUM($90), SUM($91), COUNT(), SUM($89)]], ""
+            + ""projects=[[$0, *(-1, +(/(-($1, $2), *($3, 3)), $4))]], sort0=[1], dir0=[DESC])"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=OR; C=-67660.31890436632"",
+            ""store_state=CA; C=-74749.30433035406"",
+            ""store_state=WA; C=-124367.29537911131"");
+  }
+
+  /**
+   * Skipped for now because count(distinct ) will not get pushed in because of CALC-1805
+   */
+  @Ignore @Test public void testHyperUniquePostAggregator() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_cost\"") / count(distinct ""
+        + ""\""brand_name\"") as a from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0','fn':""
+        + ""'quotient','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'hyperUniqueCardinality','name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], intervals=""
+        + ""[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], groups=[{63}], "";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=WA; A=940.3956124441964"",
+            ""store_state=CA; A=567.2359401157925"",
+            ""store_state=OR; A=506.89732360839844"");
+  }
+
+  @Test public void testExtractFilterWorkWithPostAggregations() {
+    final String sql = ""SELECT \""store_state\"", \""brand_name\"", sum(\""store_sales\"") - ""
+        + ""sum(\""store_cost\"") as a  from \""foodmart\"" where extract (week from \""timestamp\"")""
+        + "" IN (10,11) and \""brand_name\""='Bird Call' group by \""store_state\"", \""brand_name\"""";
+
+    final String druidQuery = ""'filter':{'type':'and','fields':[{'type':'selector','dimension'""
+        + "":'brand_name','value':'Bird Call'},{'type':'or','fields':[{'type':'selector',""
+        + ""'dimension':'__time','value':'10','extractionFn':{'type':'timeFormat','format'""
+        + "":'w','timeZone':'UTC','locale':'en-US'}},{'type':'selector','dimension':'__time'""
+        + "",'value':'11','extractionFn':{'type':'timeFormat','format':'w','timeZone':'UTC'""
+        + "",'locale':'en-US'}}]}]},'aggregations':[{'type':'doubleSum','name':'$f2',""
+        + ""'fieldName':'store_sales'},{'type':'doubleSum','name':'$f3','fieldName':""
+        + ""'store_cost'}],'postAggregations':[{'type':'arithmetic','name':'postagg#0'""
+        + "",'fn':'-','fields':[{'type':'fieldAccess','name':'','fieldName':'$f2'},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f3'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], filter=[AND(=("";
+    sql(sql, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(druidQuery));
+  }
+
+  @Test public void testSingleAverageFunction() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_cost\"") / count(*) as a from ""
+        + ""\""foodmart\"" group by \""store_state\"" order by a desc"";
+    String postAggString = ""'aggregations':[{'type':'doubleSum','name':'$f1','fieldName':""
+        + ""'store_cost'},{'type':'count','name':'$f2'}],""
+        + ""'postAggregations':[{'type':'arithmetic','name':'postagg#0','fn':'quotient'""
+        + "",'fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+        + ""groups=[{63}], aggs=[[SUM($91), COUNT()]], projects=[[$0, /($1, $2)]], ""
+        + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=OR; A=2.627140224161991"",
+            ""store_state=CA; A=2.5993382141879935"",
+            ""store_state=WA; A=2.5828708762997206"");
+  }
+
+  @Test public void testPartiallyPostAggregation() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_sales\"") / sum(\""store_cost\"")""
+            + "" as a, case when sum(\""unit_sales\"")=0 then 1.0 else sum(\""unit_sales\"") ""
+            + ""end as b from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+            + ""'fn':'quotient','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'}""
+            + "",{'type':'fieldAccess','name':'','fieldName':'$f2'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+            + ""  BindableProject(store_state=[$0], A=[$1], B=[CASE(=($2, 0), ""
+            + ""1.0, CAST($2):DECIMAL(19, 0))])\n""
+            + ""    DruidQuery(table=[[foodmart, foodmart]], ""
+            + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+            + ""groups=[{63}], aggs=[[SUM($90), SUM($91), SUM($89)]], ""
+            + ""projects=[[$0, /($1, $2), $3]], sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=OR; A=2.5060913241562606; B=67659"",
+            ""store_state=CA; A=2.505379731203625; B=74748"",
+            ""store_state=WA; A=2.5045805694710124; B=124366"");
+  }
+
+  @Test public void testDuplicateReferenceOnPostAggregation() {
+    final String sqlQuery = ""select \""store_state\"", a, a - b as c from (select \""store_state\"", ""
+        + ""sum(\""store_sales\"") + 100 as a, sum(\""store_cost\"") as b from \""foodmart\""  group by ""
+        + ""\""store_state\"") order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'+','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'constant','name':'','value':100.0}]},{'type':'arithmetic',""
+        + ""'name':'postagg#1','fn':'-','fields':[{'type':'arithmetic','name':'',""
+        + ""'fn':'+','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'constant','name':'','value':100.0}]},{'type':'fieldAccess',""
+        + ""'name':'','fieldName':'B'}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], groups=[{63}], ""
+        + ""aggs=[[SUM($90), SUM($91)]], projects=[[$0, +($1, 100), -(+($1, 100), $2)]], ""
+        + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=WA; A=263893.216796875; C=158568.908203125"",
+            ""store_state=CA; A=159267.83984375; C=95737.41455078125"",
+            ""store_state=OR; A=142377.0703125; C=85604.57006835938"");
+  }
+
+  @Test public void testDivideByZeroDoubleTypeInfinity() {
+    final String sqlQuery = ""select \""store_state\"", sum(\""store_cost\"") / 0 as a from ""
+        + ""\""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'quotient','fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'constant','name':'','value':0.0}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+        + ""groups=[{63}], aggs=[[SUM($91)]], projects=[[$0, /($1, 0)]]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=CA; A=Infinity"",
+            ""store_state=OR; A=Infinity"",
+            ""store_state=WA; A=Infinity"");
+  }
+
+  @Test public void testDivideByZeroDoubleTypeNegInfinity() {
+    final String sqlQuery = ""select \""store_state\"", -1.0 * sum(\""store_cost\"") / 0 as ""
+        + ""a from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'quotient','fields':[{'type':'arithmetic','name':'',""
+        + ""'fn':'*','fields':[{'type':'constant','name':'','value':-1.0},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f1'}]},""
+        + ""{'type':'constant','name':'','value':0.0}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+        + ""groups=[{63}], aggs=[[SUM($91)]], projects=[[$0, /(*(-1.0, $1), 0)]]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=CA; A=-Infinity"",
+            ""store_state=OR; A=-Infinity"",
+            ""store_state=WA; A=-Infinity"");
+  }
+
+  @Test public void testDivideByZeroDoubleTypeNaN() {
+    final String sqlQuery = ""select \""store_state\"", (sum(\""store_cost\"") - sum(\""store_cost\"")) ""
+        + ""/ 0 as a from \""foodmart\""  group by \""store_state\"" order by a desc"";
+    String postAggString = ""'postAggregations':[{'type':'arithmetic','name':'postagg#0',""
+        + ""'fn':'quotient','fields':[{'type':'arithmetic','name':'','fn':'-',""
+        + ""'fields':[{'type':'fieldAccess','name':'','fieldName':'$f1'},""
+        + ""{'type':'fieldAccess','name':'','fieldName':'$f1'}]},""
+        + ""{'type':'constant','name':'','value':0.0}]}]"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+        + ""groups=[{63}], aggs=[[SUM($91)]], projects=[[$0, /(-($1, $1), 0)]], ""
+        + ""sort0=[1], dir0=[DESC]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .queryContains(druidChecker(postAggString))
+        .returnsOrdered(""store_state=CA; A=NaN"",
+            ""store_state=OR; A=NaN"",
+            ""store_state=WA; A=NaN"");
+
+
+  }
+
+  @Test public void testDivideByZeroIntegerType() {
+    final String sqlQuery = ""select \""store_state\"", (count(*) - ""
+        + ""count(*)) / 0 as a from \""foodmart\""  group by \""store_state\"" ""
+        + ""order by a desc"";
+    final String plan = ""PLAN=EnumerableInterpreter\n""
+        + ""  DruidQuery(table=[[foodmart, foodmart]], ""
+        + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+        + ""groups=[{63}], aggs=[[COUNT()]], projects=[[$0, /(-($1, $1), 0)]]"";
+    sql(sqlQuery, FOODMART)
+        .explainContains(plan)
+        .throws_(""/ by zero"");
+  }
+
   /**","[{'comment': 'Could you add tests where you interleave aggregate calls between grouping columns in the SELECT clause? And combine that with OrderBy on dimensions for some tests and metrics on some others. This will be needed to test new code introduced for checking code that pushes down Sort operator.  ', 'commenter': 'jcamachor'}, {'comment': 'I am not sure whether I get you right or not. One extra test case I can come up with is:\r\n`select ""store_state"", sum(""store_sales"")+sum(""store_cost"") as a, ""brand_name"" from ""foodmart"" group by ""store_state"", ""brand_name"" order by ""store_state"";`\r\nHere I interleave summation aggregate and two grouping columns, then I OrderBy \r\n`brand_name` which is a dimension columns.\r\nI cannot come up with a case that combine OrderBy on metrics with interleaving aggregate calls and grouping, because we can only OrderBy on grouped columns or aggregated columns and I think aggregated metrics are not considered as metrics columns. One example of OrderBy aggregated metric will be:\r\n`select ""store_state"", sum(""store_sales"")+sum(""store_cost"") as a, ""brand_name"" from ""foodmart"" group by ""store_state"", ""brand_name"" order by a;`\r\nTo run OrderBy on metrics columns, we can only do Select druid query and then no sort and post project will be get pushed in, then the plan will stay the same.\r\nExample of OrderBy on metrics:\r\n`select ""store_sales"", ""store_cost"", ""store_sales"" - ""store_cost"" as a from ""foodmart"" where ""timestamp"" >= \'1997-01-01 00:00:00\' and ""timestamp"" < \'1997-09-01 00:00:00\' order by a`', 'commenter': 'axeisghost'}, {'comment': 'Taking your original example, you could modify it as follows to order by the computation on the metrics:\r\n```\r\nselect ""a"" from (\r\n  select sum(""store_sales"")+sum(""store_cost"") as a, ""store_state"", ""brand_name""\r\n  from ""foodmart""\r\n  group by ""store_state"", ""brand_name"" ) subq\r\norder by ""a"";\r\n```\r\nI think that example is also useful to verify whether the concern wrt to DruidSortRule is valid. If I understand correctly, the PostProject will have a single column ```sum(""store_sales"")+sum(""store_sales"")```, the Sort operator will reference that column (position 0), but when the Project is ignored in L805 in ```DruidSortRule```, we will end up assuming that we are referencing the first column in the GroupBy (```store_state```) which is not correct. Is that right? Could you add this test and another one where we would end up thinking that we are referencing the metric, e.g.,\r\n```\r\nselect ""store_state"", ""brand_name"", ""a"" from (\r\n  select ""store_state"", ""brand_name"", sum(""store_sales"")-sum(""store_cost"") as a\r\n  from ""foodmart""\r\n  group by ""store_state"", ""brand_name"" ) subq\r\norder by ""a"";\r\n```', 'commenter': 'jcamachor'}, {'comment': 'Thanks for the reply, I will add those test cases right now. I tried on my implementation and they works. Since the optimizer of planner will combine multiple projects (which including all columns) into one and when the `DruidPostAggregationProjectRule` catch the post project, it already has all the output columns and ordinal position reference in there. It then will match all output fields of `DruidQuery` to the project that get consumed.\r\nIn `DruidSortRule`, the post project is skipped just for checking the type of `DruidQuery`, when the sort get pushed in, it still takes the post project as input, the result of the test case will be evidence.', 'commenter': 'axeisghost'}]"
472,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -2156,6 +2156,308 @@ public RelNode apply(RelBuilder b) {
   }
 
   /**
+   * Tests whether an aggregate with a filter clause has it's filter factored out
+   * when there is no outer filter
+   * */
+  @Test public void testFilterClauseFactoredOut() {
+    // Logically equivalent to
+    // select sum(""store_sales"") from ""foodmart"" where ""the_year"" >= 1997
+    String sql = ""select sum(\""store_sales\"") ""
+            + ""filter (where \""the_year\"" >= 1997) from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'bound','dimension':'the_year','lower':'1997',""
+            + ""'lowerStrict':false,'ordering':'numeric'},'aggregations':[{'type':'doubleSum','name'""
+            + "":'EXPR$0','fieldName':'store_sales'}],'intervals':['1900-01-09T00:00:00.000/2992-01""
+            + ""-10T00:00:00.000'],'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether filter clauses with filters that are always true disappear or not
+   * */
+  @Test public void testFilterClauseAlwaysTrueGone() {
+    // Logically equivalent to
+    // select sum(""store_sales"") from ""foodmart""
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1) from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName':""
+            + ""'store_sales'}],'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether filter clauses with filters that are always true disappear in the presence
+   * of another aggregate without a filter clause
+   * */
+  @Test public void testFilterClauseAlwaysTrueWithAggGone1() {
+    // Logically equivalent to
+    // select sum(""store_sales""), sum(""store_cost"") from ""foodmart""
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1), ""
+            + ""sum(\""store_cost\"") from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName':""
+            + ""'store_sales'},{'type':'doubleSum','name':'EXPR$1','fieldName':'store_cost'}],""
+            + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether filter clauses with filters that are always true disappear in the presence
+   * of another aggregate with a filter clause
+   * */
+  @Test public void testFilterClauseAlwaysTrueWithAggGone2() {
+    // Logically equivalent to
+    // select sum(""store_sales""),
+    // sum(""store_cost"") filter (where ""store_state"" = 'CA') from ""foodmart""
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1), ""
+            + ""sum(\""store_cost\"") filter (where \""store_state\"" = 'CA') ""
+            + ""from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName'""
+            + "":'store_sales'},{'type':'filtered','filter':{'type':'selector','dimension':""
+            + ""'store_state','value':'CA'},'aggregator':{'type':'doubleSum','name':'EXPR$1',""
+            + ""'fieldName':'store_cost'}}],'intervals':""
+            + ""['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether an existing outer filter is untouched when an aggregate has a filter clause
+   * that is always true
+   * */
+  @Test public void testOuterFilterRemainsWithAlwaysTrueClause() {
+    // Logically equivalent to
+    // select sum(""store_sales""), sum(""store_cost"") from ""foodmart"" where ""store_city"" = 'Seattle'
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1), sum(\""store_cost\"") ""
+            + ""from \""foodmart\"" where \""store_city\"" = 'Seattle'"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'selector','dimension':'store_city',""
+            + ""'value':'Seattle'},'aggregations':[{'type':'doubleSum','name':'EXPR$0',""
+            + ""'fieldName':'store_sales'},{'type':'doubleSum','name':'EXPR$1',""
+            + ""'fieldName':'store_cost'}],'intervals':""
+            + ""['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests that an aggregate with a filter clause that is always false does not get pushed in
+   * */
+  @Test public void testFilterClauseAlwaysFalseNotPushed() {
+    String sql = ""select sum(\""store_sales\"") filter (where 1 > 1) from \""foodmart\"""";
+    // Calcite takes care of the unsatisfiable filter
+    String expectedSubExplain =
+            ""  BindableAggregate(group=[{}], EXPR$0=[SUM($0) FILTER $1])\n""
+            + ""    BindableProject(store_sales=[$0], $f1=[false])\n"";
+    sql(sql).explainContains(expectedSubExplain);
+  }
+
+  /**
+   * Tests that an aggregate with a filter clause that is always false does not get pushed when
+   * there is already an outer filter
+   * */
+  @Test public void testFilterClauseAlwaysFalseNotPushedWithFilter() {
+    String sql = ""select sum(\""store_sales\"") filter (where 1 > 1) ""
+            + ""from \""foodmart\"" where \""store_city\"" = 'Seattle'"";
+    String expectedSubExplain =
+            ""  BindableAggregate(group=[{}], EXPR$0=[SUM($0) FILTER $1])\n""
+            + ""    BindableProject(store_sales=[$0], $f1=[false])\n""
+            + ""      DruidQuery(table=[[foodmart, foodmart]], ""
+                    + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+                    // Make sure the original filter is still there
+                    + ""filter=[=($62, 'Seattle')], projects=[[$90]])"";
+
+    sql(sql).explainContains(expectedSubExplain);
+
+  }
+
+  /**
+   * Tests that an aggregate with a filter clause that is the same as the outer filter has no
+   * references to that filter, and that the original outer filter remains
+   * */
+  @Test public void testFilterClauseSameAsOuterFilterGone() {
+    // Logically equivalent to
+    // select sum(""store_sales"") from ""foodmart"" where ""store_city"" = 'Seattle'
+    String sql = ""select sum(\""store_sales\"") filter (where \""store_city\"" = 'Seattle') ""
+            + ""from \""foodmart\"" where \""store_city\"" = 'Seattle'"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'selector','dimension':'store_city','value':""
+            + ""'Seattle'},'aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName':""
+            + ""'store_sales'}],'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Test to ensure that an aggregate with a filter clause in the presence of another aggregate
+   * without a filter clause does not have it's filter factored out into the outer filter
+   * */
+  @Test public void testFilterClauseNotFactoredOut1() {
+    String sql = ""select sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_cost\"") from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'filtered','filter':{'type':'selector',""
+            + ""'dimension':'store_state','value':'CA'},'aggregator':{'type':'doubleSum','name':""
+            + ""'EXPR$0','fieldName':'store_sales'}},{'type':'doubleSum','name':'EXPR$1','fieldName'""
+            + "":'store_cost'}],'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Test to ensure that an aggregate with a filter clause in the presence of another aggregate
+   * without a filter clause, and an outer filter does not have it's
+   * filter factored out into the outer filter
+   * */
+  @Test public void testFilterClauseNotFactoredOut2() {
+    String sql = ""select sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_cost\"") from \""foodmart\"" where \""the_year\"" >= 1997"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'bound','dimension':'the_year','lower':'1997',""
+            + ""'lowerStrict':false,'ordering':'numeric'},'aggregations':[{'type':'filtered',""
+            + ""'filter':{'type':'selector','dimension':'store_state','value':'CA'},'aggregator':{""
+            + ""'type':'doubleSum','name':'EXPR$0','fieldName':'store_sales'}},{'type':'doubleSum',""
+            + ""'name':'EXPR$1','fieldName':'store_cost'}],""
+            + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Test to ensure that multiple aggregates with filter clauses have their filters extracted to
+   * the outer filter field for data pruning
+   * */
+  @Test public void testFilterClausesFactoredForPruning1() {
+    String sql = ""select ""
+            + ""sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_sales\"") filter (where \""store_state\"" = 'WA') ""
+            + ""from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""","[{'comment': 'Could we execute some of this queries, e.g., using ```returnsUnordered```, to verify that they are executed correctly?', 'commenter': 'jcamachor'}, {'comment': 'Will do.', 'commenter': 'zhumayun'}, {'comment': ""I've added code to execute the queries and check their results. Let me know if there's anything else you'd like me to add/remove."", 'commenter': 'zhumayun'}, {'comment': 'Thanks, LGTM.', 'commenter': 'jcamachor'}]"
472,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -2156,6 +2156,317 @@ public RelNode apply(RelBuilder b) {
   }
 
   /**
+   * Tests whether an aggregate with a filter clause has it's filter factored out
+   * when there is no outer filter
+   * */
+  @Test public void testFilterClauseFactoredOut() {
+    // Logically equivalent to
+    // select sum(""store_sales"") from ""foodmart"" where ""the_year"" >= 1997
+    String sql = ""select sum(\""store_sales\"") ""
+            + ""filter (where \""the_year\"" >= 1997) from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'bound','dimension':'the_year','lower':'1997',""
+            + ""'lowerStrict':false,'ordering':'numeric'},'aggregations':[{'type':'doubleSum','name'""
+            + "":'EXPR$0','fieldName':'store_sales'}],'intervals':['1900-01-09T00:00:00.000/2992-01""
+            + ""-10T00:00:00.000'],'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether filter clauses with filters that are always true disappear or not
+   * */
+  @Test public void testFilterClauseAlwaysTrueGone() {
+    // Logically equivalent to
+    // select sum(""store_sales"") from ""foodmart""
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1) from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName':""
+            + ""'store_sales'}],'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether filter clauses with filters that are always true disappear in the presence
+   * of another aggregate without a filter clause
+   * */
+  @Test public void testFilterClauseAlwaysTrueWithAggGone1() {
+    // Logically equivalent to
+    // select sum(""store_sales""), sum(""store_cost"") from ""foodmart""
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1), ""
+            + ""sum(\""store_cost\"") from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName':""
+            + ""'store_sales'},{'type':'doubleSum','name':'EXPR$1','fieldName':'store_cost'}],""
+            + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether filter clauses with filters that are always true disappear in the presence
+   * of another aggregate with a filter clause
+   * */
+  @Test public void testFilterClauseAlwaysTrueWithAggGone2() {
+    // Logically equivalent to
+    // select sum(""store_sales""),
+    // sum(""store_cost"") filter (where ""store_state"" = 'CA') from ""foodmart""
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1), ""
+            + ""sum(\""store_cost\"") filter (where \""store_state\"" = 'CA') ""
+            + ""from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName'""
+            + "":'store_sales'},{'type':'filtered','filter':{'type':'selector','dimension':""
+            + ""'store_state','value':'CA'},'aggregator':{'type':'doubleSum','name':'EXPR$1',""
+            + ""'fieldName':'store_cost'}}],'intervals':""
+            + ""['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests whether an existing outer filter is untouched when an aggregate has a filter clause
+   * that is always true
+   * */
+  @Test public void testOuterFilterRemainsWithAlwaysTrueClause() {
+    // Logically equivalent to
+    // select sum(""store_sales""), sum(""store_cost"") from ""foodmart"" where ""store_city"" = 'Seattle'
+    String sql = ""select sum(\""store_sales\"") filter (where 1 = 1), sum(\""store_cost\"") ""
+            + ""from \""foodmart\"" where \""store_city\"" = 'Seattle'"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'selector','dimension':'store_city',""
+            + ""'value':'Seattle'},'aggregations':[{'type':'doubleSum','name':'EXPR$0',""
+            + ""'fieldName':'store_sales'},{'type':'doubleSum','name':'EXPR$1',""
+            + ""'fieldName':'store_cost'}],'intervals':""
+            + ""['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Tests that an aggregate with a filter clause that is always false does not get pushed in
+   * */
+  @Test public void testFilterClauseAlwaysFalseNotPushed() {
+    String sql = ""select sum(\""store_sales\"") filter (where 1 > 1) from \""foodmart\"""";
+    // Calcite takes care of the unsatisfiable filter
+    String expectedSubExplain =
+            ""  BindableAggregate(group=[{}], EXPR$0=[SUM($0) FILTER $1])\n""
+            + ""    BindableProject(store_sales=[$0], $f1=[false])\n"";
+    sql(sql).explainContains(expectedSubExplain);
+  }
+
+  /**
+   * Tests that an aggregate with a filter clause that is always false does not get pushed when
+   * there is already an outer filter
+   * */
+  @Test public void testFilterClauseAlwaysFalseNotPushedWithFilter() {
+    String sql = ""select sum(\""store_sales\"") filter (where 1 > 1) ""
+            + ""from \""foodmart\"" where \""store_city\"" = 'Seattle'"";
+    String expectedSubExplain =
+            ""  BindableAggregate(group=[{}], EXPR$0=[SUM($0) FILTER $1])\n""
+            + ""    BindableProject(store_sales=[$0], $f1=[false])\n""
+            + ""      DruidQuery(table=[[foodmart, foodmart]], ""
+                    + ""intervals=[[1900-01-09T00:00:00.000/2992-01-10T00:00:00.000]], ""
+                    // Make sure the original filter is still there
+                    + ""filter=[=($62, 'Seattle')], projects=[[$90]])"";
+
+    sql(sql).explainContains(expectedSubExplain);
+
+  }
+
+  /**
+   * Tests that an aggregate with a filter clause that is the same as the outer filter has no
+   * references to that filter, and that the original outer filter remains
+   * */
+  @Test public void testFilterClauseSameAsOuterFilterGone() {
+    // Logically equivalent to
+    // select sum(""store_sales"") from ""foodmart"" where ""store_city"" = 'Seattle'
+    String sql = ""select sum(\""store_sales\"") filter (where \""store_city\"" = 'Seattle') ""
+            + ""from \""foodmart\"" where \""store_city\"" = 'Seattle'"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'selector','dimension':'store_city','value':""
+            + ""'Seattle'},'aggregations':[{'type':'doubleSum','name':'EXPR$0','fieldName':""
+            + ""'store_sales'}],'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql)
+        .queryContains(druidChecker(expectedQuery))
+        .returnsUnordered(""EXPR$0=52644.07004201412"");
+  }
+
+  /**
+   * Test to ensure that an aggregate with a filter clause in the presence of another aggregate
+   * without a filter clause does not have it's filter factored out into the outer filter
+   * */
+  @Test public void testFilterClauseNotFactoredOut1() {
+    String sql = ""select sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_cost\"") from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','aggregations':[{'type':'filtered','filter':{'type':'selector',""
+            + ""'dimension':'store_state','value':'CA'},'aggregator':{'type':'doubleSum','name':""
+            + ""'EXPR$0','fieldName':'store_sales'}},{'type':'doubleSum','name':'EXPR$1','fieldName'""
+            + "":'store_cost'}],'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Test to ensure that an aggregate with a filter clause in the presence of another aggregate
+   * without a filter clause, and an outer filter does not have it's
+   * filter factored out into the outer filter
+   * */
+  @Test public void testFilterClauseNotFactoredOut2() {
+    String sql = ""select sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_cost\"") from \""foodmart\"" where \""the_year\"" >= 1997"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'bound','dimension':'the_year','lower':'1997',""
+            + ""'lowerStrict':false,'ordering':'numeric'},'aggregations':[{'type':'filtered',""
+            + ""'filter':{'type':'selector','dimension':'store_state','value':'CA'},'aggregator':{""
+            + ""'type':'doubleSum','name':'EXPR$0','fieldName':'store_sales'}},{'type':'doubleSum',""
+            + ""'name':'EXPR$1','fieldName':'store_cost'}],""
+            + ""'intervals':['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql).queryContains(druidChecker(expectedQuery));
+  }
+
+  /**
+   * Test to ensure that multiple aggregates with filter clauses have their filters extracted to
+   * the outer filter field for data pruning
+   * */
+  @Test public void testFilterClausesFactoredForPruning1() {
+    String sql = ""select ""
+            + ""sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_sales\"") filter (where \""store_state\"" = 'WA') ""
+            + ""from \""foodmart\"""";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'or','fields':[{'type':'selector','dimension':""
+            + ""'store_state','value':'CA'},{'type':'selector','dimension':'store_state',""
+            + ""'value':'WA'}]},'aggregations':[{'type':'filtered','filter':{'type':'selector',""
+            + ""'dimension':'store_state','value':'CA'},'aggregator':{'type':'doubleSum','name':""
+            + ""'EXPR$0','fieldName':'store_sales'}},{'type':'filtered','filter':{'type':'selector',""
+            + ""'dimension':'store_state','value':'WA'},'aggregator':{'type':'doubleSum','name':""
+            + ""'EXPR$1','fieldName':'store_sales'}}],'intervals':""
+            + ""['1900-01-09T00:00:00.000/2992-01-10T00:00:00.000'],""
+            + ""'context':{'skipEmptyBuckets':true}}"";
+
+    sql(sql)
+        .queryContains(druidChecker(expectedQuery))
+        .returnsUnordered(""EXPR$0=159167.840144217; EXPR$1=263793.2202244997"");
+  }
+
+  /**
+   * Test to ensure that multiple aggregates with filter clauses have their filters extracted to
+   * the outer filter field for data pruning in the presence of an outer filter
+   * */
+  @Test public void testFilterClausesFactoredForPruning2() {
+    String sql = ""select ""
+            + ""sum(\""store_sales\"") filter (where \""store_state\"" = 'CA'), ""
+            + ""sum(\""store_sales\"") filter (where \""store_state\"" = 'WA') ""
+            + ""from \""foodmart\"" where \""brand_name\"" = 'Super'"";
+    String expectedQuery = ""{'queryType':'timeseries','dataSource':'foodmart','descending':false,""
+            + ""'granularity':'all','filter':{'type':'and','fields':[{'type':'or','fields':[{'type':""
+            + ""'selector','dimension':'store_state','value':'CA'},{'type':'selector','dimension':""
+            + ""'store_state','value':'WA'}]},{'type':'selector','dimension':'brand_name','value':""
+            + ""'Super'}]},'aggregations':[{'type':'filtered','filter':{'type':'selector',""
+            + ""'dimension':'store_state','value':'CA'},'aggregator':{'type':'doubleSum','name':""
+            + ""'EXPR$0','fieldName':'store_sales'}},{'type':'filtered','filter':{'type':'selector',""","[{'comment': 'can we add at least one test where we have a nested filter ? like where store = ca or store = il ', 'commenter': 'b-slim'}]"
478,druid/src/main/java/org/apache/calcite/adapter/druid/DruidRules.java,"@@ -113,20 +113,36 @@ private DruidRules() {}
           SORT_PROJECT_TRANSPOSE);
 
   /** Predicate that returns whether Druid can not handle an aggregate. */
-  private static final Predicate<Aggregate> BAD_AGG =
-      new PredicateImpl<Aggregate>() {
-        public boolean test(Aggregate aggregate) {
+  private static final Predicate<Pair<Aggregate, DruidTable>> BAD_AGG =
+      new PredicateImpl<Pair<Aggregate, DruidTable>>() {
+        public boolean test(Pair<Aggregate, DruidTable> pair) {
+          final Aggregate aggregate = pair.left;
+          final DruidTable druidTable = pair.right;
           final CalciteConnectionConfig config =
                   aggregate.getCluster().getPlanner().getContext()
                       .unwrap(CalciteConnectionConfig.class);
+          RelNode input = aggregate.getInput();
           for (AggregateCall aggregateCall : aggregate.getAggCallList()) {
             switch (aggregateCall.getAggregation().getKind()) {
             case COUNT:
-              if (!aggregateCall.getArgList().isEmpty()) {
-                // Cannot handle this aggregate function
+              // Druid can handle 2 scenarios:
+              // 1. count(distinct col) when approximate results
+              //    are acceptable and col is not a metric
+              // 2. count(*)
+
+              // Make sure no column name is a metric
+              for (int index : aggregateCall.getArgList()) {
+                String name = input.getRowType().getFieldNames().get(index);","[{'comment': 'This might not be correct, since a Project below the Aggregate might rename the columns.\r\n\r\nIn fact, you should rely on _checkAggregateOnMetric_ method in DruidQuery, passing in the first parameter an ImmutableBitSet with the references used by the aggregateCall.', 'commenter': 'jcamachor'}, {'comment': ""I don't see a field inside of `AggregateCall` of type `ImmutableBitSet`. Did you mean the aggregateCall's `argList` (type `ImmutableList<Integer>`)?"", 'commenter': 'zhumayun'}, {'comment': 'Yes, I meant that first parameter for ```checkAggregateOnMetric``` should be ```ImmutableBitSet.of(argList)``` (or alike) and that should work.', 'commenter': 'jcamachor'}, {'comment': 'Does the query\r\n\r\n```sql\r\nselect ""B"", count(""A"") from (select ""unit_sales"" as ""A"", ""customer_id"" as ""B"" from ""foodmart"") group by ""B"";\r\n```\r\n\r\nSatisfy your above comment for an additional test? (I\'ll also add a count distinct variant)', 'commenter': 'zhumayun'}, {'comment': 'I would have to see the plan, but indeed that is what I meant (we should end up with Aggregate on top of Project where the Project renames some of the columns).', 'commenter': 'jcamachor'}]"
502,core/src/main/java/org/apache/calcite/sql/validate/SqlUserDefinedAggFunction.java,"@@ -54,7 +54,8 @@ public SqlUserDefinedAggFunction(SqlIdentifier opName,
       SqlOperandTypeInference operandTypeInference,
       SqlOperandTypeChecker operandTypeChecker, AggregateFunction function,
       boolean requiresOrder, boolean requiresOver, RelDataTypeFactory typeFactory) {
-    super(Util.last(opName.names), opName, SqlKind.OTHER_FUNCTION,
+    super(Util.last(opName.names), opName, SqlKind.getSqlKindByName(opName.names.get(0)) != null
+                    ? SqlKind.valueOf(opName.names.get(0)) : SqlKind.OTHER_FUNCTION,","[{'comment': 'I\'m not sure this is the right approach. What you do is you make ""user-defined SUM function"" to be treated as standard SUM function without giving a single check on the actual implementation.\r\n\r\nThat might trigger some optimization rules that alter results. For instance, Calcite could replace user-defined `AVG(...)` with standard `SUM(...)/COUNT(...)`.', 'commenter': 'vlsi'}, {'comment': 'I just want to defined a user-defind agg function with the name SUM, for example, add a sum function of String type, however, the sql kind of this function is other function, which will be filtered when find the name of SUM,  i can\'t find a better solution than this, if you have any idea about this, do not hesitate to help. \r\nBy the way, I am not very clear about your answer "" without giving a single check on the actual implementation"", could you explain it in detail ?', 'commenter': 'yuqi1129'}, {'comment': ""I agree with @vlsi. It's OK to have a UDAF with the same name as a built-in, but it's not OK for it to impersonate it by taking on its SqlKind value.\r\n\r\nWhat happens if you leave its SqlKind as OTHER_FUNCTION?"", 'commenter': 'julianhyde'}, {'comment': ""@julianhyde @vlsi  .I see, if this is not OK,  i can change another method. The reason that causes this problem is that in parser phase, the parser directly convert 'SUM' to SqlSumAggFunction not SqlUnresolvedFuntion by name and at this time user-defined aggregate function has not been registered. this should be done in the validate phase as at this time converting 'Sum' to SqlSumAggFunction will cause calcite filters all function that is not SqlKind.SUM like user-defined aggregate funcion. Converting in the early phase may accelerate the validate phase later, but it will omit the user-defined aggregate function, which will lead validator can't find function.\r\nMy resolution:\r\nMethod of createCall in  SqlAbstractParserImpl.java directly returns SqlUnresolvedFunction not a clear specific function like SqlSumAggFunction. But if do like this, hundreds of test case fail as createCall has changed and sql changed greatly after parser. this is quite troublesome.\r\nIs that OK? advice is appreciate, thanks \r\n\r\n "", 'commenter': 'yuqi1129'}, {'comment': ""Let's discuss at https://issues.apache.org/jira/browse/CALCITE-1882."", 'commenter': 'julianhyde'}]"
503,core/src/main/java/org/apache/calcite/prepare/CalciteCatalogReader.java,"@@ -81,30 +82,32 @@
   protected final RelDataTypeFactory typeFactory;
   private final List<List<String>> schemaPaths;
   protected final SqlNameMatcher nameMatcher;
+  protected final CalciteConnectionConfig config;
 
   public CalciteCatalogReader(CalciteSchema rootSchema, boolean caseSensitive,","[{'comment': 'To avoid overloading the constructor too much, could this constructor accept ```CalciteConnectionConfig config``` and not ```boolean caseSensitive```, and then obtain ```caseSensitive``` from ```config``` within the constructor?', 'commenter': 'jcamachor'}, {'comment': ""Yeah that makes sense. I'll remove the extra parameter"", 'commenter': 'zhumayun'}]"
503,druid/src/test/java/org/apache/calcite/test/DruidAdapterIT.java,"@@ -755,28 +779,16 @@ private void checkGroupBySingleSortLimit(boolean approx) {
   /** Tests a query that contains no GROUP BY and is therefore executed as a
    * Druid ""select"" query. */
   @Test public void testFilterSortDesc() {
-    final String sql = ""select * from \""foodmart\""\n""","[{'comment': 'Why is ```select *...``` not working?\r\nI would expect it to work as usual but to project out automatically those columns that are virtual (e.g. complex metrics). Is this the case? We would not want to fail in these cases.', 'commenter': 'jcamachor'}, {'comment': ""`select *` is expanded to `select col_1, col_2, ..., col_n` in the validation phase, so by the time the code that checks for roll ups sees it, it will throw an error because we're not supposed to select a virtual column. I thought about skipping cases with `select *` in them, but then queries like `select virtualcol from (select * from table)` would be allowed when they shouldn't be."", 'commenter': 'zhumayun'}, {'comment': 'I would say that failing for ```select *...``` is not an option, since user just wants ""all visible columns"".\r\n\r\nThus, could the expansion logic check the table metadata to skip virtual columns?', 'commenter': 'jcamachor'}, {'comment': ""Sure, I'll look into implementing that. "", 'commenter': 'zhumayun'}, {'comment': 'I added another test case to test for this, instead of reverting the existing ones because I need to use wiki to test it. ', 'commenter': 'zhumayun'}]"
503,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3198,6 +3220,227 @@ public String apply(String s) {
     // dialects you can refer to columns of the select list, e.g.
     // ""SELECT empno AS x FROM emp ORDER BY x""
     validateOrderList(select);
+
+    if (shouldCheckForRollUp(select.getFrom())) {
+      checkRollUpInSelectList(select);
+      checkRollUp(null, select, select.getWhere(), getWhereScope(select));
+      checkRollUp(null, select, select.getHaving(), getHavingScope(select));
+      checkRollUpInWindowDecl(select);
+      checkRollUpInGroupBy(select);
+      checkRollUpInOrderBy(select);
+    }
+  }
+
+  private void checkRollUpInSelectList(SqlSelect select) {
+    SqlValidatorScope scope = getSelectScope(select);
+    for (SqlNode item : select.getSelectList()) {
+      checkRollUp(null, select, item, scope);
+    }
+  }
+
+  private void checkRollUpInGroupBy(SqlSelect select) {
+    SqlNodeList group = select.getGroup();
+    if (group != null) {
+      for (SqlNode node : group) {
+        checkRollUp(null, select, node, getGroupScope(select), ""GROUP BY"");
+      }
+    }
+  }
+
+  private void checkRollUpInOrderBy(SqlSelect select) {
+    SqlNodeList orderList = select.getOrderList();
+    if (orderList != null) {
+      for (SqlNode node : orderList) {
+        checkRollUp(null, select, node, getOrderScope(select), ""ORDER BY"");
+      }
+    }
+  }
+
+  private void checkRollUpInWindow(SqlWindow window, SqlValidatorScope scope) {
+    if (window != null) {
+      for (SqlNode node : window.getPartitionList()) {
+        checkRollUp(null, window, node, scope, ""PARTITION BY"");
+      }
+
+      for (SqlNode node : window.getOrderList()) {
+        checkRollUp(null, window, node, scope, ""ORDER BY"");
+      }
+    }
+  }
+
+  private void checkRollUpInWindowDecl(SqlSelect select) {
+    for (SqlNode decl : select.getWindowList()) {
+      checkRollUpInWindow((SqlWindow) decl, getSelectScope(select));
+    }
+  }
+
+  private void checkRollUp(SqlNode grandParent, SqlNode parent,
+                           SqlNode current, SqlValidatorScope scope, String optionalClause) {
+    current = stripAs(current);
+    if (current instanceof SqlCall && !(current instanceof SqlSelect)) {
+      // Validate OVER separately
+      checkRollUpInWindow(getWindowInOver(current), scope);
+      current = stripOver(current);
+
+      List<SqlNode> children = ((SqlCall) current).getOperandList();
+      for (SqlNode child : children) {
+        checkRollUp(parent, current, child, scope, optionalClause);
+      }
+    } else if (current instanceof SqlIdentifier) {
+      SqlIdentifier id = (SqlIdentifier) current;
+      if (!id.isStar() && isRolledUpColumn(id, scope)) {
+        if (!isAggregation(parent.getKind())
+                || !isRolledUpColumnAllowedInAgg(id, scope, (SqlCall) parent, grandParent)) {
+          String context = optionalClause != null ? optionalClause : parent.getKind().toString();
+          throw newValidationError(id,
+                  RESOURCE.rolledUpNotAllowed(deriveAlias(id, 0), context));
+        }
+      }
+    }
+  }
+
+  private void checkRollUp(SqlNode grandParent, SqlNode parent,
+                           SqlNode current, SqlValidatorScope scope) {
+    checkRollUp(grandParent, parent, current, scope, null);
+  }
+
+  private SqlWindow getWindowInOver(SqlNode over) {
+    if (over.getKind() == SqlKind.OVER) {
+      SqlNode window = ((SqlCall) over).getOperandList().get(1);
+      if (window instanceof SqlWindow) {
+        return (SqlWindow) window;
+      }
+      // SqlIdentifier, gets validated elsewhere
+      return null;
+    }
+    return null;
+  }
+
+  private static SqlNode stripOver(SqlNode node) {
+    switch (node.getKind()) {
+    case OVER:
+      return ((SqlCall) node).getOperandList().get(0);
+    default:
+      return node;
+    }
+  }
+
+  private Pair<String, String> findTableColumnPair(SqlIdentifier identifier,
+                                                   SqlValidatorScope scope) {
+    SqlCall call = SqlUtil.makeCall(getOperatorTable(), identifier);
+    if (call != null) {
+      return null;
+    }
+    SqlQualified qualified = scope.fullyQualify(identifier);
+    List<String> names = qualified.identifier.names;
+
+    if (names.size() < 2) {
+      return null;
+    }
+
+    return new Pair<>(names.get(names.size() - 2), Util.last(names));
+  }
+
+  // Returns true iff the given column is valid inside the given aggCall.
+  private boolean isRolledUpColumnAllowedInAgg(SqlIdentifier identifier, SqlValidatorScope scope,
+                                               SqlCall aggCall, SqlNode parent) {
+    Pair<String, String> pair = findTableColumnPair(identifier, scope);
+
+    if (pair == null) {
+      return true;
+    }
+
+    String tableAlias = pair.left;
+    String columnName = pair.right;
+
+    Table table = findTable(tableAlias);
+    if (table != null) {
+      return table.rolledUpColumnValidInsideAgg(columnName, aggCall, parent,
+              catalogReader.getConfig());
+    }
+    return true;
+  }
+
+
+  // Returns true iff the given column is actually rolled up.
+  private boolean isRolledUpColumn(SqlIdentifier identifier, SqlValidatorScope scope) {
+    Pair<String, String> pair = findTableColumnPair(identifier, scope);
+
+    if (pair == null) {
+      return false;
+    }
+
+    String tableAlias = pair.left;
+    String columnName = pair.right;
+
+    Table table = findTable(tableAlias);
+    if (table != null) {
+      return table.isRolledUp(columnName);
+    }
+    return false;
+  }
+
+  private Table findTable(CalciteSchema schema, String tableName, boolean caseSensitive) {
+    CalciteSchema.TableEntry entry = schema.getTable(tableName, caseSensitive);
+    if (entry != null) {
+      return entry.getTable();
+    }
+
+    // Check sub schemas
+    for (CalciteSchema subSchema : schema.getSubSchemaMap().values()) {
+      Table table = findTable(subSchema, tableName, caseSensitive);
+      if (table != null) {
+        return table;
+      }
+    }
+
+    return null;
+  }
+
+  /**
+   * Given a table alias, find the corresponding {@link Table} associated with it
+   * */
+  private Table findTable(String alias) {
+    List<String> names = null;
+    if (tableScope == null) {
+      // no tables to find
+      return null;
+    }
+
+    for (ScopeChild child : tableScope.children) {
+      if (catalogReader.nameMatcher().matches(child.name, alias)) {
+        names = ((SqlIdentifier) child.namespace.getNode()).names;
+        break;
+      }
+    }
+    if (names == null || names.size() == 0) {
+      return null;
+    } else if (names.size() == 1) {
+      return findTable(catalogReader.getRootSchema(), names.get(0),
+              catalogReader.nameMatcher().isCaseSensitive());
+    }
+
+    String schemaName = names.get(0);
+    String tableName = names.get(1);","[{'comment': '@zhumayun , @jcamacho, this seems to support just one schema level.\r\nIn other words, if table is located in a subschema, then table is not found.\r\n\r\nIn my case, tables are located in `schema.subschema..table`, and this code is unable to find the table.\r\n\r\nI\'m not very familiar with SqlValidator code, however the proper way to resolve tables seems to be `scope.resolveTable`\r\n\r\nIf ""findTable"" is a proper approach at all.\r\n', 'commenter': 'vlsi'}, {'comment': '@vlsi , I was waiting in case @zhumayun could reply... I am not that familiar with the validator code either, but I thought that follow-up lines in change deal with subschemas correctly. If this is a bug, could you create a JIRA case for this? Further, if you have a clear idea on how to solve it, e.g., via scope.resolveTable, maybe we can try to check this in before 1.14 release.', 'commenter': 'jcamachor'}]"
503,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3198,6 +3220,227 @@ public String apply(String s) {
     // dialects you can refer to columns of the select list, e.g.
     // ""SELECT empno AS x FROM emp ORDER BY x""
     validateOrderList(select);
+
+    if (shouldCheckForRollUp(select.getFrom())) {
+      checkRollUpInSelectList(select);
+      checkRollUp(null, select, select.getWhere(), getWhereScope(select));
+      checkRollUp(null, select, select.getHaving(), getHavingScope(select));
+      checkRollUpInWindowDecl(select);
+      checkRollUpInGroupBy(select);
+      checkRollUpInOrderBy(select);
+    }
+  }
+
+  private void checkRollUpInSelectList(SqlSelect select) {
+    SqlValidatorScope scope = getSelectScope(select);
+    for (SqlNode item : select.getSelectList()) {
+      checkRollUp(null, select, item, scope);
+    }
+  }
+
+  private void checkRollUpInGroupBy(SqlSelect select) {
+    SqlNodeList group = select.getGroup();
+    if (group != null) {
+      for (SqlNode node : group) {
+        checkRollUp(null, select, node, getGroupScope(select), ""GROUP BY"");
+      }
+    }
+  }
+
+  private void checkRollUpInOrderBy(SqlSelect select) {
+    SqlNodeList orderList = select.getOrderList();
+    if (orderList != null) {
+      for (SqlNode node : orderList) {
+        checkRollUp(null, select, node, getOrderScope(select), ""ORDER BY"");
+      }
+    }
+  }
+
+  private void checkRollUpInWindow(SqlWindow window, SqlValidatorScope scope) {
+    if (window != null) {
+      for (SqlNode node : window.getPartitionList()) {
+        checkRollUp(null, window, node, scope, ""PARTITION BY"");
+      }
+
+      for (SqlNode node : window.getOrderList()) {
+        checkRollUp(null, window, node, scope, ""ORDER BY"");
+      }
+    }
+  }
+
+  private void checkRollUpInWindowDecl(SqlSelect select) {
+    for (SqlNode decl : select.getWindowList()) {
+      checkRollUpInWindow((SqlWindow) decl, getSelectScope(select));
+    }
+  }
+
+  private void checkRollUp(SqlNode grandParent, SqlNode parent,
+                           SqlNode current, SqlValidatorScope scope, String optionalClause) {
+    current = stripAs(current);
+    if (current instanceof SqlCall && !(current instanceof SqlSelect)) {
+      // Validate OVER separately
+      checkRollUpInWindow(getWindowInOver(current), scope);
+      current = stripOver(current);
+
+      List<SqlNode> children = ((SqlCall) current).getOperandList();
+      for (SqlNode child : children) {
+        checkRollUp(parent, current, child, scope, optionalClause);
+      }
+    } else if (current instanceof SqlIdentifier) {
+      SqlIdentifier id = (SqlIdentifier) current;
+      if (!id.isStar() && isRolledUpColumn(id, scope)) {
+        if (!isAggregation(parent.getKind())
+                || !isRolledUpColumnAllowedInAgg(id, scope, (SqlCall) parent, grandParent)) {
+          String context = optionalClause != null ? optionalClause : parent.getKind().toString();
+          throw newValidationError(id,
+                  RESOURCE.rolledUpNotAllowed(deriveAlias(id, 0), context));
+        }
+      }
+    }
+  }
+
+  private void checkRollUp(SqlNode grandParent, SqlNode parent,
+                           SqlNode current, SqlValidatorScope scope) {
+    checkRollUp(grandParent, parent, current, scope, null);
+  }
+
+  private SqlWindow getWindowInOver(SqlNode over) {
+    if (over.getKind() == SqlKind.OVER) {
+      SqlNode window = ((SqlCall) over).getOperandList().get(1);
+      if (window instanceof SqlWindow) {
+        return (SqlWindow) window;
+      }
+      // SqlIdentifier, gets validated elsewhere
+      return null;
+    }
+    return null;
+  }
+
+  private static SqlNode stripOver(SqlNode node) {
+    switch (node.getKind()) {
+    case OVER:
+      return ((SqlCall) node).getOperandList().get(0);
+    default:
+      return node;
+    }
+  }
+
+  private Pair<String, String> findTableColumnPair(SqlIdentifier identifier,
+                                                   SqlValidatorScope scope) {
+    SqlCall call = SqlUtil.makeCall(getOperatorTable(), identifier);
+    if (call != null) {
+      return null;
+    }
+    SqlQualified qualified = scope.fullyQualify(identifier);
+    List<String> names = qualified.identifier.names;
+
+    if (names.size() < 2) {
+      return null;
+    }
+
+    return new Pair<>(names.get(names.size() - 2), Util.last(names));
+  }
+
+  // Returns true iff the given column is valid inside the given aggCall.
+  private boolean isRolledUpColumnAllowedInAgg(SqlIdentifier identifier, SqlValidatorScope scope,
+                                               SqlCall aggCall, SqlNode parent) {
+    Pair<String, String> pair = findTableColumnPair(identifier, scope);
+
+    if (pair == null) {
+      return true;
+    }
+
+    String tableAlias = pair.left;
+    String columnName = pair.right;
+
+    Table table = findTable(tableAlias);
+    if (table != null) {
+      return table.rolledUpColumnValidInsideAgg(columnName, aggCall, parent,
+              catalogReader.getConfig());
+    }
+    return true;
+  }
+
+
+  // Returns true iff the given column is actually rolled up.
+  private boolean isRolledUpColumn(SqlIdentifier identifier, SqlValidatorScope scope) {
+    Pair<String, String> pair = findTableColumnPair(identifier, scope);
+
+    if (pair == null) {
+      return false;
+    }
+
+    String tableAlias = pair.left;
+    String columnName = pair.right;
+
+    Table table = findTable(tableAlias);
+    if (table != null) {
+      return table.isRolledUp(columnName);
+    }
+    return false;
+  }
+
+  private Table findTable(CalciteSchema schema, String tableName, boolean caseSensitive) {
+    CalciteSchema.TableEntry entry = schema.getTable(tableName, caseSensitive);
+    if (entry != null) {
+      return entry.getTable();
+    }
+
+    // Check sub schemas
+    for (CalciteSchema subSchema : schema.getSubSchemaMap().values()) {","[{'comment': 'This would fail in case multiple schemas contain a table with the same name. Would some sort of `scope.resolveTable` be better here?', 'commenter': 'vlsi'}]"
527,core/src/main/java/org/apache/calcite/prepare/Prepare.java,"@@ -143,10 +143,18 @@ protected RelRoot optimize(RelRoot root,
 
     final List<RelOptMaterialization> materializationList = new ArrayList<>();
     for (Materialization materialization : materializations) {
+      RelOptTable table = materialization.tableRel.getTable();
+      List<String> qualifiedTableName;
+      if (table == null) {
+        qualifiedTableName = materialization.materializedTable.path();","[{'comment': 'Just to confirm, can {{qualifiedTableName = materialization.materializedTable.path();}} work for both situations or this if-else block is inevitable?', 'commenter': 'maryannxue'}, {'comment': ""Seems it should work, I'll test that and push the change if it works."", 'commenter': 'beikov'}]"
527,core/src/main/java/org/apache/calcite/materialize/MaterializationService.java,"@@ -126,6 +126,10 @@ public MaterializationKey defineMaterialization(final CalciteSchema schema,
     if (tableEntry == null) {
       tableEntry = schema.getTableBySql(viewSql);
     }
+    if (tableEntry == null) {","[{'comment': 'Can we use the {{existing}} flag as we do for pre-populated materialization table, and move this if block into the {{if (existing)}} block?', 'commenter': 'maryannxue'}, {'comment': 'Sounds like a good idea.', 'commenter': 'beikov'}]"
535,core/src/main/java/org/apache/calcite/rel/metadata/RelMetadataQuery.java,"@@ -537,6 +537,9 @@ public Boolean areColumnsUnique(RelNode rel, ImmutableBitSet columns) {
    */
   public Boolean areColumnsUnique(RelNode rel, ImmutableBitSet columns,
       boolean ignoreNulls) {
+    if (columns.length() > rel.getInputs().size()) {","[{'comment': 'Would you please add a comment describing an edge case?\r\nFrom a first glance it is not clear why the condition is like that.', 'commenter': 'vlsi'}]"
545,core/src/main/java/org/apache/calcite/sql/dialect/HiveSqlDialect.java,"@@ -16,19 +16,28 @@
  */
 package org.apache.calcite.sql.dialect;
 
+import org.apache.calcite.config.NullCollation;
 import org.apache.calcite.sql.SqlDialect;
+import org.apache.calcite.sql.SqlNode;
 
 /**
  * A <code>SqlDialect</code> implementation for the Apache Hive database.
  */
 public class HiveSqlDialect extends SqlDialect {
   public static final SqlDialect DEFAULT =
-      new HiveSqlDialect(
-          EMPTY_CONTEXT.withDatabaseProduct(DatabaseProduct.HIVE));
+      new HiveSqlDialect(EMPTY_CONTEXT
+          .withDatabaseProduct(DatabaseProduct.HIVE)
+          .withNullCollation(NullCollation.LOW));
 
-  /** Creates a HiveSqlDialect. */
+  private boolean emulateNullDirection;","[{'comment': 'Please make it `final` as dialects should be immutable', 'commenter': 'beikov'}]"
545,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -532,12 +535,29 @@ public SqlNode rewriteSingleValueExpr(SqlNode aggCall) {
    *
    * @param node The SqlNode representing the expression
    * @param nullsFirst <code>true</code> if nulls should come first, <code>false</code> otherwise
+   * @param desc <code>true</code> if the sort direction is RelFieldCollation.Direction.DESCENDING
+   *             or RelFieldCollation.Direction.STRICTLY_DESCENDING
    * @return A SqlNode for null direction emulation or <code>null</code> if not required
    */
-  public SqlNode emulateNullDirection(SqlNode node, boolean nullsFirst) {
+  public SqlNode emulateNullDirection(SqlNode node, boolean nullsFirst, boolean desc) {
     return null;
   }
 
+  protected SqlNode emulateNullDirectionForLowNulls(","[{'comment': ""How about considering the `nullCollation` already present in `SqlDialect`?\r\nRename this method to `emulateNullDirectionWithIsNull` and skip the  null emulation based on the `nullCollation` and the given `nullsFirst` and `desc` settings. It's not relevant for your purposes but is a nice and small generalization that we could use later for other DBMS."", 'commenter': 'beikov'}]"
545,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -757,16 +780,19 @@ public SqlDialect getDialect() {
   private static class ContextImpl implements Context {
     private final DatabaseProduct databaseProduct;
     private final String databaseProductName;
-    private final String databaseVersion;
+    private final int databaseMajorVersion;
+    private final int databaseMinorVersion;
     private final String identifierQuoteString;
     private final NullCollation nullCollation;
 
     private ContextImpl(DatabaseProduct databaseProduct,
-        String databaseProductName, String databaseVersion,
-        String identifierQuoteString, NullCollation nullCollation) {
+                        String databaseProductName,
+                        Integer databaseMajorVersion, Integer databaseMinorVersion,
+                        String identifierQuoteString, NullCollation nullCollation) {
       this.databaseProduct = Preconditions.checkNotNull(databaseProduct);","[{'comment': 'I think the new parameters should be `int` not `Integer`.\r\n\r\nAlso, please remove the added whitespace; house style is to indent parameters just 4 spaces.', 'commenter': 'julianhyde'}, {'comment': 'Also, I think you should keep the old `databaseVersion` parameter, even as you add `databaseMinorVersion` and `databaseMajorVersion`.', 'commenter': 'julianhyde'}, {'comment': 'I think keeping the old databaseVersion parameter might be confusing. If there are 2 things representing the same information, and those 2 things are nullable, a user may be confused which of those things is available while he/she writes the code. This I say because the current contract of creating the ""ContextImpl"" allows me to create an object that may have null fields, such as a dialect of a database whose version is unknown.\r\n\r\nFor example, if inside a dialect, if i need to check whether the version is 2.3, i could do it in 2 ways, by checking the string or the int values. And since the fields are nullable, i would also have to checks nulls in both places, which would make the code very messy', 'commenter': 'abbas-gadhia'}, {'comment': 'I disagree. databaseVersion, databaseMajorVersion and databaseMinorVersion all come from the JDBC driver and drivers seem to provide all of them correctly. I don\'t think the person writing the dialect will be ""confused""; they can come up with a strategy that works for that particular DB, and that will be good enough and robust, I think. The more information the better; the only reason we don\'t use the DatabaseMetaData (which has lots of information) is because of memory leaks.', 'commenter': 'julianhyde'}]"
545,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -656,13 +676,14 @@ public static String replace(
     ACCESS(""Access"", ""\"""", NullCollation.HIGH),
     CALCITE(""Apache Calcite"", ""\"""", NullCollation.HIGH),
     MSSQL(""Microsoft SQL Server"", ""["", NullCollation.HIGH),
-    MYSQL(""MySQL"", ""`"", NullCollation.HIGH),
+    MYSQL(""MySQL"", ""`"", NullCollation.LOW),","[{'comment': 'Did you intend to make this change? If so, change MySqlDialect.DEFAULT as well.', 'commenter': 'julianhyde'}]"
545,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -656,13 +676,14 @@ public static String replace(
     ACCESS(""Access"", ""\"""", NullCollation.HIGH),
     CALCITE(""Apache Calcite"", ""\"""", NullCollation.HIGH),
     MSSQL(""Microsoft SQL Server"", ""["", NullCollation.HIGH),
-    MYSQL(""MySQL"", ""`"", NullCollation.HIGH),
+    MYSQL(""MySQL"", ""`"", NullCollation.LOW),
     ORACLE(""Oracle"", ""\"""", NullCollation.HIGH),
     DERBY(""Apache Derby"", null, NullCollation.HIGH),
     DB2(""IBM DB2"", null, NullCollation.HIGH),
     FIREBIRD(""Firebird"", null, NullCollation.HIGH),
     H2(""H2"", ""\"""", NullCollation.HIGH),
-    HIVE(""Apache Hive"", null, NullCollation.HIGH),
+    HIVE(""Apache Hive"", null, NullCollation.LOW),
+    BIGQUERY(""Google BigQuery"", ""`"", NullCollation.LOW),","[{'comment': ""please move this into alphabetical order (but don't re-order existing entries)"", 'commenter': 'julianhyde'}]"
600,pom.xml,"@@ -411,6 +411,11 @@ limitations under the License.
         <artifactId>hsqldb</artifactId>
         <version>${hsqldb.version}</version>
       </dependency>
+		<dependency>
+			<groupId>org.hsqldb</groupId>","[{'comment': 'Would you please use spaces instead of tabs for indentation like used in the file?', 'commenter': 'vlsi'}, {'comment': 'done', 'commenter': 'ptrbojko'}]"
600,plus/pom.xml,"@@ -81,8 +81,23 @@ limitations under the License.
       <artifactId>hamcrest-core</artifactId>
       <scope>test</scope>
     </dependency>
+    <dependency>
+      <groupId>org.hsqldb</groupId>
+      <artifactId>hsqldb</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>org.hsqldb</groupId>
+      <artifactId>sqltool</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>net.hydromatic</groupId>
+      <artifactId>quidem</artifactId>
+    </dependency>
+    <dependency>
+        <groupId>org.apache.commons</groupId>","[{'comment': 'Please remove 2 extra spaces', 'commenter': 'vlsi'}, {'comment': 'done', 'commenter': 'ptrbojko'}]"
660,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -1065,6 +1067,157 @@ private void reduceCasts(RexCall outerCast) {
       }
     }
   }
+
+  /** Pushes a condition into an OR if they reference only 1 variable
+   *
+   * Example: a=1 && (a=1 || a=2)
+   */
+  protected static class PushConditionIntoOrShuttle extends RexShuttle {
+
+    private RexBuilder rexBuilder;
+    private RexSimplify simplify;
+
+    public PushConditionIntoOrShuttle(RexSimplify simplify) {
+      super();
+      this.rexBuilder = simplify.rexBuilder;
+      this.simplify = simplify;
+    }
+
+    @Override public RexNode visitCall(RexCall call) {
+      for (;;) {
+        call = (RexCall) super.visitCall(call);
+        final RexCall old = call;
+        call = processCall(call);
+        if (call == old) {
+          return call;
+        }
+      }
+    }
+
+    /** Helper class to represent compareOps / disjunctive forms which are connected to
+     * the same variable */
+    class CandidateGroup {
+
+      List<RexNode> compareOp = new ArrayList<>();
+      List<RexNode> dfs = new ArrayList<>();
+      private RexNode result = null;
+
+      public void addMember(RexNode rexNode) {
+        if (rexNode.getKind() == SqlKind.OR) {
+          dfs.add(rexNode);
+        } else {
+          compareOp.add(rexNode);
+        }
+      }
+
+      public boolean pushIn() {
+        if (dfs.size() != 1 || compareOp.size() != 1) {
+          return false;
+        }
+        // in case this pushIn is not successfull; someone might pull out the ""AND-ed operands""
+        boolean reduced = false;
+        List<RexNode> orOps = ((RexCall) dfs.get(0)).getOperands();
+        RexCall cmpOp = (RexCall) compareOp.get(0);
+        List<RexNode> newOps = new ArrayList<>();
+        for (RexNode rexNode : orOps) {
+          RexNode newCall = rexBuilder.makeCall(SqlStdOperatorTable.AND, rexNode, cmpOp);
+          newCall = simplify.simplify(newCall);
+          if (newCall.isAlwaysFalse() || newCall.isAlwaysTrue()) {
+            // we have successfully burried an operand
+            reduced = true;
+          }
+          newOps.add(newCall);
+        }
+        result = rexBuilder.makeCall(SqlStdOperatorTable.OR, newOps);
+        result = simplify.simplify(result);
+        if (result.getKind() != SqlKind.OR) {
+          reduced = true;
+        }
+        return reduced;
+      }
+
+      public List<RexNode> getResults() {
+        if (result != null) {
+          return Lists.newArrayList(result);
+        }
+        List<RexNode> ret = new ArrayList<>();
+        ret.addAll(compareOp);
+        ret.addAll(dfs);
+        return ret;
+      }
+
+    }
+
+    private RexCall processCall(RexCall call) {
+      List<RexNode> others = new ArrayList<>();
+
+      if (call.getKind() != SqlKind.AND) {
+        return call;
+      }
+
+      List<RexNode> ops = call.getOperands();
+      Map<ImmutableBitSet, CandidateGroup> candidateMap = new HashMap<>();
+
+      for (RexNode rexNode : ops) {
+        ImmutableBitSet k = RelOptUtil.InputFinder.bits(rexNode);","[{'comment': 'Does this look like a O(N^2)?\r\n\r\n`visitCall` visits every node in the tree, and `RelOptUtil.InputFinder.bits` processes the whole subtree.\r\n\r\nI wonder if the overhead is worth the optimization produced.', 'commenter': 'vlsi'}, {'comment': 'sorry @vlsi  this is an old PR; this approach was abandoned.....\r\nI will now look around and close any pr which seem outdated.', 'commenter': 'kgyrtkirk'}]"
683,core/src/main/java/org/apache/calcite/runtime/FlatLists.java,"@@ -1079,7 +1095,11 @@ public boolean equals(Object o) {
             && Objects.equals(this.t4, that.t4)
             && Objects.equals(this.t5, that.t5);
       }
-      return o.equals(this);
+      if (o instanceof List) {
+        List lo = (List) o;
+        return lo.size() == 6 && o.equals(this);","[{'comment': 'It is better to change the constant number to `this.size()`, and other places.', 'commenter': 'hsyuan'}]"
683,core/src/test/java/org/apache/calcite/runtime/FlatListsTest.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.runtime;
+
+import org.apache.calcite.runtime.FlatLists.Flat3List;
+import org.apache.calcite.runtime.FlatLists.Flat4List;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * Tests {@link FlatLists}.
+ */
+public class FlatListsTest {
+
+  @Test
+  public void testFlat34Equals() {
+    Flat3List f3list = new Flat3List(1, 2, 3);
+    Flat4List f4list = new Flat4List(1, 2, 3, 4);
+    Assert.assertFalse(f3list.equals(f4list));
+  }","[{'comment': 'No need to add a new file. Consider add tests in function `testFlatList` https://github.com/apache/calcite/blob/master/core/src/test/java/org/apache/calcite/util/UtilTest.java#L1081', 'commenter': 'hsyuan'}]"
693,plus/src/main/resources/chinook/chinook.json,"@@ -65,6 +65,10 @@
         {
           ""name"": ""ASCONCATOFPARAMS"",
           ""className"": ""org.apache.calcite.chinook.StringConcatFunction""
+        },
+        {
+          ""name"": ""CHOOSENCUSTOMER"",
+          ""className"": ""org.apache.calcite.chinook.ChoosenCustomEmail""","[{'comment': ""The name `CHOOSENCUSTOMER` doesn't seem to match the UDF."", 'commenter': 'michaelmior'}, {'comment': 'CHOOSENCUSTOMER (CHOSENCUSTOMER after fix) is used in plus/src/test/resources/sql/functions.iq testm where it proves that the fix work.', 'commenter': 'ptrbojko'}]"
693,plus/src/main/java/org/apache/calcite/chinook/ChoosenCustomEmail.java,"@@ -0,0 +1,30 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.chinook;
+
+/**
+ * Example UDF for where clause to check pushing to JDBC
+ */
+public class ChoosenCustomEmail {","[{'comment': 'This should be spelled `Chosen` (single o) including in the filename.', 'commenter': 'michaelmior'}, {'comment': 'Will fix', 'commenter': 'ptrbojko'}]"
701,example/csv/src/main/java/org/apache/calcite/adapter/csv/CsvTableFactory.java,"@@ -43,8 +44,8 @@ public CsvTableFactory() {
   public CsvTable create(SchemaPlus schema, String name,
       Map<String, Object> operand, RelDataType rowType) {
     String fileName = (String) operand.get(""file"");
-    final File base =
-        (File) operand.get(ModelHandler.ExtraOperand.BASE_DIRECTORY.camelName);
+    final URI uri = (URI) operand.get(ModelHandler.ExtraOperand.BASE_DIRECTORY.camelName);","[{'comment': ""@walterddr , this looks like a backward-incompatible change. In other words, clients have to update their code even though they don't use URIs yet.\r\n\r\nHave you though of a possibility to keep previous code intact while allowing to leverage new API if required?"", 'commenter': 'vlsi'}, {'comment': 'hmm. this was confusing to me. I was not sure about the original implementation to directly convert the `Object` to `File`. \r\n\r\nHow about:\r\n```\r\nObject baseDirObj = operand.get(ModelHandler.ExtraOperand.BASE_DIRECTORY.camelName);\r\nFinal File base;\r\nif (baseDirObj instanceof URI) {\r\n  uri = (URI) baseDirObj;\r\n  base = new File(uri);\r\n} else if (baseDirObj instanceof File) {\r\n  base = (File) baseDirObj;\r\n} else {\r\n  throw IllegalArgumentException(...);\r\n}\r\n```\r\n', 'commenter': 'walterddr'}]"
701,core/src/main/java/org/apache/calcite/model/ModelHandler.java,"@@ -303,13 +314,12 @@ public void visit(JsonCustomSchema jsonSchema) {
           builder.put(extraOperand.camelName, modelUri);
           break;
         case BASE_DIRECTORY:
-          File f = null;
+          URI f;","[{'comment': '@vlsi one more comment on this is that I changed this to always use URI as `Object` type in the `operandMap`. I am assuming this is also a backward-incompatible change since other users who directly alter the operandMap will also have to change `File` type to `URI` type. \r\n\r\nAny suggestions on how to make it backward compatible. My initial thought would be to give another key, say: \r\n```\r\ncase BASE_DIRECTORY:\r\n  // ...\r\ncase BASE_DIRECTORY_URI:\r\n  // ... \r\n```\r\nand mark `BASE_DIRECTORY` as deprecated key', 'commenter': 'walterddr'}]"
707,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -703,10 +708,12 @@ RexNode simplifyAnd2(List<RexNode> terms, List<RexNode> notTerms) {
     // Example #1. x AND y AND z AND NOT (x AND y)  - not satisfiable
     // Example #2. x AND y AND NOT (x AND y)        - not satisfiable
     // Example #3. x AND y AND NOT (x AND y AND z)  - may be satisfiable
-    for (RexNode notDisjunction : notTerms) {
-      final List<RexNode> terms2 = RelOptUtil.conjunctions(notDisjunction);
-      if (terms.containsAll(terms2)) {
-        return rexBuilder.makeLiteral(false);
+    if (unknownAsFalse) {","[{'comment': 'This method should only be called when ```unknownAsFalse``` is false, right? It is very confusing that this method checks the value of this boolean, given that we should only be in it if ```unknownAsFalse``` is false.\r\nIt would be more clear to change the boolean value before calling ```simplifyAnd```, that would fix the issue.', 'commenter': 'jcamachor'}, {'comment': 'Just to make sure my comment is understood: since we have two variants for the method, ideal solution is to prevent any method from calling ```simplifyAnd2``` if ```unknownAsFalse``` is true.', 'commenter': 'jcamachor'}, {'comment': ""correct; these duplicate methods are not making it easier...\r\nI'll removed this block"", 'commenter': 'kgyrtkirk'}]"
716,elasticsearch5/src/test/java/org/elasticsearch/node/LocalNode.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.elasticsearch.node;","[{'comment': 'Is it intended that this class is in this package rather than in the `org.apache.calcite` namespace?', 'commenter': 'beikov'}, {'comment': 'Hmm somehow I though that particular Node constructor is package private (which is not the case) `LocalNode` has been moved as inner class of `EmbeddedNode`. No more `org.elasticsearch` packages.', 'commenter': 'asereda-gs'}]"
744,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -0,0 +1,135 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.elasticsearch;
+
+import org.apache.calcite.linq4j.Enumerable;
+import org.apache.calcite.linq4j.Linq4j;
+import org.apache.calcite.linq4j.function.Function1;
+import org.apache.calcite.util.Util;
+
+import org.apache.http.HttpEntity;
+import org.apache.http.HttpStatus;
+import org.apache.http.entity.ContentType;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.util.EntityUtils;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Preconditions;
+
+import org.elasticsearch.client.Response;
+import org.elasticsearch.client.RestClient;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.UncheckedIOException;
+import java.util.Collections;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+
+/**
+ * Table based on an Elasticsearch5 type.
+ */
+public class ElasticsearchTable extends AbstractElasticsearchTable {
+  private final RestClient restClient;
+  private final ElasticsearchVersion version;
+  private final ObjectMapper mapper;
+
+  /**
+   * Creates an Elasticsearch5Table.","[{'comment': 'Rename', 'commenter': 'beikov'}, {'comment': 'Done', 'commenter': 'asereda-gs'}]"
744,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -49,15 +58,37 @@ public Elasticsearch5SchemaFactory() {
       final Map<String, Integer> coordinates =
           mapper.readValue((String) map.get(""coordinates""),
               new TypeReference<Map<String, Integer>>() { });
+
+      final RestClient client = connect(coordinates);
+
       final Map<String, String> userConfig =
           mapper.readValue((String) map.get(""userConfig""),
               new TypeReference<Map<String, String>>() { });
+
       final String index = (String) map.get(""index"");
-      return new Elasticsearch5Schema(coordinates, userConfig, index);","[{'comment': ""What's with the userConfig map? Before, a user was able to specify driver settings through this like e.g. `bulk.flush.max.actions`, `bulk.flush.max.size.mb` and `bulk.flush.interval.ms`. Are there any settings that we could allow users to do through this?"", 'commenter': 'beikov'}, {'comment': 'Those changes were applicable only for legacy transport client. New low-level rest client is [configured programatically](https://www.elastic.co/guide/en/elasticsearch/client/java-rest/current/_common_configuration.html). We may add some parameters in future (like timeout).', 'commenter': 'asereda-gs'}]"
744,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -0,0 +1,135 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.elasticsearch;
+
+import org.apache.calcite.linq4j.Enumerable;
+import org.apache.calcite.linq4j.Linq4j;
+import org.apache.calcite.linq4j.function.Function1;
+import org.apache.calcite.util.Util;
+
+import org.apache.http.HttpEntity;
+import org.apache.http.HttpStatus;
+import org.apache.http.entity.ContentType;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.util.EntityUtils;
+
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Preconditions;
+
+import org.elasticsearch.client.Response;
+import org.elasticsearch.client.RestClient;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.UncheckedIOException;
+import java.util.Collections;
+import java.util.List;
+import java.util.Locale;
+import java.util.Map;
+
+/**
+ * Table based on an Elasticsearch5 type.
+ */
+public class ElasticsearchTable extends AbstractElasticsearchTable {
+  private final RestClient restClient;
+  private final ElasticsearchVersion version;
+  private final ObjectMapper mapper;","[{'comment': 'I think ObjectMapper can be used as static final field. It has no state and it caches metadata so it usually it is a good deal', 'commenter': 'eolivelli'}, {'comment': ""I've left `ObjectMapper` as instance field because it is being injected externally (see constructor for `ElasticsearchSchema`). Some clients might want to customize how JSON is being parsed, and this allows them to provide a pre-configured parser. \r\n\r\nSame instance is used across all ES tables (created by identical ElasticsearchSchema) so internal cache is being re-used.\r\n"", 'commenter': 'asereda-gs'}, {'comment': '@asereda-gs  \r\nokay to me, thank you for your explanation', 'commenter': 'eolivelli'}]"
762,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -2352,6 +2354,35 @@ public static int subtractMonths(long t0, long t1) {
     return x;
   }
 
+  /**
+   * Implements the {@code .} (field access) operator on an object whose type is not known until
+   * runtime.
+   *
+   * A struct object can be represented in various ways by the runtime and depends on the
+   * {@link org.apache.calcite.adapter.enumerable.JavaRowFormat}.
+   */
+  public static Object structAccess(Object structObject, int index) {
+    if (structObject == null) {
+      return null;
+    }
+
+    if (structObject instanceof Object[]) {
+      return ((Object[]) structObject)[index];
+    } else if (structObject instanceof List) {
+      return ((List) structObject).get(index);
+    } else if (structObject instanceof Row) {
+      return ((Row) structObject).getObject(index);
+    } else {
+      Class<?> beanClass = structObject.getClass();
+      Field structField = beanClass.getDeclaredFields()[index];","[{'comment': '@zabetak ,\r\n1) `getDeclaredFeilds()` does not guarantee the order of returned fields.\r\n2) `getDeclaredFields()` per access is bad performance-wise', 'commenter': 'vlsi'}]"
762,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -7094,7 +7094,6 @@ public MockDdlDriver() {
     public MyTable[] mytable = { new MyTable() };
     public MyTable2[] mytable2 = { new MyTable2() };
   }
-","[{'comment': 'was that intended?', 'commenter': 'vlsi'}, {'comment': 'Nope. Thanks for noticing! I fixed it.', 'commenter': 'zabetak'}]"
762,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -2361,6 +2364,36 @@ public static int subtractMonths(long t0, long t1) {
     return x;
   }
 
+  /**
+   * Implements the {@code .} (field access) operator on an object whose type is not known until
+   * runtime.
+   *
+   * A struct object can be represented in various ways by the runtime and depends on the
+   * {@link org.apache.calcite.adapter.enumerable.JavaRowFormat}.
+   */
+  @Experimental
+  public static Object structAccess(Object structObject, int index, String fieldName) {
+    if (structObject == null) {
+      return null;
+    }
+
+    if (structObject instanceof Object[]) {
+      return ((Object[]) structObject)[index];
+    } else if (structObject instanceof List) {
+      return ((List) structObject).get(index);
+    } else if (structObject instanceof Row) {
+      return ((Row) structObject).getObject(index);
+    } else {
+      Class<?> beanClass = structObject.getClass();
+      try {
+        Field structField = beanClass.getDeclaredField(fieldName);
+        return structField.get(structObject);
+      } catch (NoSuchFieldException | IllegalAccessException ex) {
+        throw new IllegalStateException(ex);","[{'comment': 'Would you please add relevant exception message?\r\nThat is `fieldName`/`index` that triggered the failure.', 'commenter': 'vlsi'}, {'comment': 'I added fieldName but not index since the latter is not going to be used to raise this exception.', 'commenter': 'zabetak'}]"
778,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -2170,6 +2170,22 @@ private RexNode simplify(RexNode e) {
         is(false));
   }
 
+  @Test public void testIsAlwaysTrueAndFalse() {
+    final RelDataType booleanNullableType =
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.BOOLEAN), true);
+    RexNode node = rexBuilder.makeInputRef(booleanNullableType, 0);","[{'comment': 'I am sure it makes no sense to clutter test code with boiler-plate creation of `RelDataType` and `inputrefs`', 'commenter': 'vlsi'}]"
778,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -2170,6 +2170,22 @@ private RexNode simplify(RexNode e) {
         is(false));
   }
 
+  @Test public void testIsAlwaysTrueAndFalse() {
+    final RelDataType booleanNullableType =
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.BOOLEAN), true);
+    RexNode node = rexBuilder.makeInputRef(booleanNullableType, 0);
+
+    RexNode exp1 = rexBuilder.makeCall(SqlStdOperatorTable.IS_FALSE, isNotNull(isNull(node)));","[{'comment': 'IS_FALSE should be refactored to a method like `isNull` for consistency and test brevity', 'commenter': 'vlsi'}]"
778,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -2170,6 +2170,22 @@ private RexNode simplify(RexNode e) {
         is(false));
   }
 
+  @Test public void testIsAlwaysTrueAndFalse() {
+    final RelDataType booleanNullableType =
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.BOOLEAN), true);
+    RexNode node = rexBuilder.makeInputRef(booleanNullableType, 0);
+
+    RexNode exp1 = rexBuilder.makeCall(SqlStdOperatorTable.IS_FALSE, isNotNull(isNull(node)));
+    assertEquals(exp1.isAlwaysTrue(), false);","[{'comment': 'Please use `message` parameter for `assertEquals` or other means to make exception message clear.\r\n\r\nCurrent one would be like ""expected false, got true at line 2180.\r\nIt would be extremely hard to maintain if ever this test goes off the rails.\r\n\r\nThe same applies to all `assertEquals` in this test', 'commenter': 'vlsi'}]"
778,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -228,6 +228,18 @@ private RexNode isNotNull(RexNode node) {
     return rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, node);
   }
 
+  private RexNode isFalse(RexNode node) {
+    return rexBuilder.makeCall(SqlStdOperatorTable.IS_FALSE, node);
+  }
+
+  private RexNode isTrue(RexNode node) {
+    return rexBuilder.makeCall(SqlStdOperatorTable.IS_TRUE, node);
+  }
+
+  private RexNode isNotTrue(RexNode node) {","[{'comment': 'Could you please co-locate `is*True/False` methods? It looks like `isNotFalse` is declared elsewhere', 'commenter': 'vlsi'}, {'comment': 'Thanks! I have added the isNotFalse method after isNotTrue.', 'commenter': 'jiayuanv127'}]"
778,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -2170,6 +2182,49 @@ private RexNode simplify(RexNode e) {
         is(false));
   }
 
+  @Test public void testIsAlwaysTrueAndFalse() {
+    final RelDataType type =
+        typeFactory.createSqlType(SqlTypeName.BOOLEAN);
+    RexNode inputRef = rexBuilder.makeInputRef(type, 0);
+
+    RexNode isFalseExp = isFalse(isNotNull(isNull(inputRef)));
+    assertEquals(""isAlwaysTrue should return false,but get true"",","[{'comment': 'Please make the test fail (e.g. by replacing `isAlwaysTrue` with a simple `return false`), then see how the test reports the problem.\r\nWould you be able to tell the nature of the issue from the error message/stacktrace then?', 'commenter': 'vlsi'}, {'comment': 'Thanks for you suggestion,I have make a change to make the error message more clear.', 'commenter': 'jiayuanv127'}]"
780,plus/src/main/java/org/apache/calcite/chinook/CodesFunction.java,"@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.chinook;
+
+import org.apache.calcite.adapter.java.AbstractQueryableTable;
+import org.apache.calcite.linq4j.Linq4j;
+import org.apache.calcite.linq4j.QueryProvider;
+import org.apache.calcite.linq4j.Queryable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.schema.QueryableTable;
+import org.apache.calcite.schema.SchemaPlus;
+import org.apache.calcite.sql.type.SqlTypeName;
+
+import org.apache.commons.codec.binary.Base64;
+
+import java.nio.charset.Charset;
+
+/**
+ * Example Table Function for lateral join checks
+ */
+public class CodesFunction {
+
+  private CodesFunction(){
+  }
+
+  public static QueryableTable getTable(String name) {
+
+    return new AbstractQueryableTable(Object[].class) {
+      @Override public RelDataType getRowType(RelDataTypeFactory typeFactory) {
+        return typeFactory.builder()
+            .add(""TYPE"", SqlTypeName.VARCHAR)
+            .add(""CODEVALUE"", SqlTypeName.VARCHAR)
+            .build();
+      }
+
+      @Override public Queryable<String[]> asQueryable(QueryProvider queryProvider,
+                                                       SchemaPlus schema,
+                                                       String tableName) {
+        if (name == null) {
+          return Linq4j.asEnumerable(new String[][]{}).asQueryable();
+        }
+        return Linq4j.asEnumerable(new String[][]{
+            new String[]{""HASHCODE"", """" + name.hashCode()},
+            new String[]{""BASE64"",
+                Base64.encodeBase64String(name.getBytes(Charset.defaultCharset()))}","[{'comment': 'Please refrain from using `defaultCharset` in tests', 'commenter': 'vlsi'}]"
780,plus/src/main/java/org/apache/calcite/chinook/CodesFunction.java,"@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.chinook;
+
+import org.apache.calcite.adapter.java.AbstractQueryableTable;
+import org.apache.calcite.linq4j.Linq4j;
+import org.apache.calcite.linq4j.QueryProvider;
+import org.apache.calcite.linq4j.Queryable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.schema.QueryableTable;
+import org.apache.calcite.schema.SchemaPlus;
+import org.apache.calcite.sql.type.SqlTypeName;
+
+import org.apache.commons.codec.binary.Base64;
+
+import java.nio.charset.Charset;
+
+/**
+ * Example Table Function for lateral join checks
+ */
+public class CodesFunction {
+
+  private CodesFunction(){
+  }
+
+  public static QueryableTable getTable(String name) {
+
+    return new AbstractQueryableTable(Object[].class) {
+      @Override public RelDataType getRowType(RelDataTypeFactory typeFactory) {
+        return typeFactory.builder()
+            .add(""TYPE"", SqlTypeName.VARCHAR)
+            .add(""CODEVALUE"", SqlTypeName.VARCHAR)
+            .build();
+      }
+
+      @Override public Queryable<String[]> asQueryable(QueryProvider queryProvider,
+                                                       SchemaPlus schema,
+                                                       String tableName) {
+        if (name == null) {
+          return Linq4j.asEnumerable(new String[][]{}).asQueryable();","[{'comment': 'Should this be `emptyEnumerable` ?', 'commenter': 'vlsi'}]"
780,plus/pom.xml,"@@ -55,6 +55,11 @@ limitations under the License.
       <groupId>org.apache.calcite.avatica</groupId>
       <artifactId>avatica-core</artifactId>
     </dependency>
+    <dependency>
+      <groupId>commons-codec</groupId>
+      <artifactId>commons-codec</artifactId>","[{'comment': ""It does look more like a `<scope>test</scope>` dependency, doesn't it?\r\nI would like to refrain from adding regular dependencies for test purposes."", 'commenter': 'vlsi'}]"
780,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -2049,7 +2049,7 @@ private SqlNode registerFrom(
               extendList,
               forceNullable,
               lateral);
-      if (newExpr != expr) {
+      if (newExpr != expr) { // && (isLateral(expr) && !isLateral(newExpr))","[{'comment': ""I'm afraid this comment does not clarify much."", 'commenter': 'vlsi'}]"
780,core/src/test/java/org/apache/calcite/util/Smalls.java,"@@ -126,6 +126,29 @@ public RelDataType getRowType(RelDataTypeFactory typeFactory) {
     };
   }
 
+  private static QueryableTable simpleTable(String s) {","[{'comment': 'Is `simpleTable` vital for the test?\r\nCan you reuse existing table function?', 'commenter': 'vlsi'}]"
781,core/src/test/java/org/apache/calcite/test/HepPlannerTest.java,"@@ -242,6 +247,53 @@ private void assertIncludesExactlyOnce(String message, String digest, String sub
     assertThat(listener.getApplyTimes() == 1, is(true));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2454"">[CALCITE-2454]
+   * HepPlanner should not pick cached RelNode when type mismatch while digest matches</a>. */
+  @Test public void testRelNodeCacheWithDigest() {
+    HepProgramBuilder programBuilder = HepProgram.builder();
+    programBuilder.addRuleInstance(ReduceExpressionsRule.PROJECT_INSTANCE); // dummy rules.
+    programBuilder.addRuleInstance(ReduceExpressionsRule.CALC_INSTANCE);
+    programBuilder.addRuleInstance(ProjectMergeRule.INSTANCE);
+    HepPlanner planner = new HepPlanner(programBuilder.build());
+
+    RelBuilder relBuilder = RelBuilder.create(RelBuilderTest.config().build());
+    RelDataTypeFactory typeFactory = relBuilder.getTypeFactory();
+    RelDataType longType = typeFactory.createSqlType(SqlTypeName.BIGINT);
+    RelDataType intType = typeFactory.createSqlType(SqlTypeName.INTEGER);
+    RelDataType doubleType = typeFactory.createSqlType(SqlTypeName.DOUBLE);
+
+    RelNode values = relBuilder
+        .values(new String[] {""f1"", ""f2"", ""f3""}, 1, 2, 3)
+        .build();
+
+    // schema: 1, 2, 3.0D | int, bigint, double
+    RelNode p1 = relBuilder
+        .push(values)
+        .project(relBuilder.getRexBuilder().makeLiteral(1, intType, false),
+            relBuilder.getRexBuilder().makeLiteral(2, longType, false),
+            relBuilder.getRexBuilder().makeLiteral(3.0D, doubleType, false))
+        .build();
+    // schema: 1, 2, 3.0D | bigint, int, double
+    RelNode p2 = relBuilder
+        .push(values)
+        .project(relBuilder.getRexBuilder().makeLiteral(1, longType, false),
+            relBuilder.getRexBuilder().makeLiteral(2, intType, false),
+            relBuilder.getRexBuilder().makeLiteral(3.0D, doubleType, false))
+        .build();
+    RelNode r = relBuilder
+        .push(p1)
+        .push(p2)
+        .union(true)
+        .build();
+    planner.setRoot(r);
+    RelNode bestRel = planner.findBestExp();
+
+    assertThat(r.getInput(0).getRowType().equals(r.getInput(1).getRowType()), is(false));","[{'comment': '@danny0405 , thanks for the test. Would you please add relevant messages so the assertion failure is human readable?\r\n\r\nFor instance, current test fails (without the fix) as follows:\r\n\r\n```\r\njava.lang.AssertionError: \r\nExpected: is <false>\r\n     but: was <true>\r\nExpected :is <false>\r\nActual   :<true>\r\n\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n\tat org.junit.Assert.assertThat(Assert.java:956)\r\n\tat org.junit.Assert.assertThat(Assert.java:923)\r\n\tat org.apache.calcite.test.HepPlannerTest.testRelNodeCacheWithDigest(HepPlannerTest.java:100)\r\n```\r\n\r\nIt is not really helpful, and it will be really hard to maintain that kind of tests.\r\nGood failure should look like a good bug report.', 'commenter': 'vlsi'}, {'comment': '@vlsi  I have added some comment and assert msg, thx for the review.', 'commenter': 'danny0405'}, {'comment': 'Do you think the following is terribly better?\r\n\r\n```\r\njava.lang.AssertionError: The two inputs should have different row types after planner promotion.\r\nExpected: is <false>\r\n     but: was <true>\r\nExpected :is <false>\r\nActual   :<true>\r\n\tat org.hamcrest.MatcherAssert.assertThat(MatcherAssert.java:20)\r\n\tat org.junit.Assert.assertThat(Assert.java:956)\r\n\tat org.apache.calcite.test.HepPlannerTest.testRelNodeCacheWithDigest(HepPlannerTest.java:102)\r\n```\r\n', 'commenter': 'vlsi'}, {'comment': '@vlsi I just use the assert api so.\r\nWhat kind of failure do want this test failure to be ?', 'commenter': 'danny0405'}, {'comment': 'The one that does not require full understanding of the test code in order to understand the failure.\r\n\r\nFor instance:\r\n\r\n```\r\njava.lang.AssertionError: COALESCE(+(CAST(-626799667):INTEGER, null), ?0.notNullInt1, -(null))\r\ncoalesce(plus(rexBuilder.makeCall(SqlStdOperatorTable.CAST, literal(-626799667)), nullInt), vIntNotNull(1), unaryMinus(nullInt)) had non-nullable type INTEGER, and it was optimized to null\r\nnullInt that has nullable type INTEGER, unknownAsFalse\r\n\r\n\tat org.junit.Assert.fail(Assert.java:88)\r\n\tat org.apache.calcite.test.fuzzer.RexProgramFuzzyTest.checkUnknownAs(RexProgramFuzzyTest.java:266)\r\n\tat org.apache.calcite.test.fuzzer.RexProgramFuzzyTest.checkUnknownAs(RexProgramFuzzyTest.java:163)\r\n\tat org.apache.calcite.test.fuzzer.RexProgramFuzzyTest.generateRexAndCheckTrueFalse(RexProgramFuzzyTest.java:412)\r\n\tat org.apache.calcite.test.fuzzer.RexProgramFuzzyTest.runRexFuzzer(RexProgramFuzzyTest.java:344)\r\n\tat org.apache.calcite.test.fuzzer.RexProgramFuzzyTest.testFuzzy(RexProgramFuzzyTest.java:315)\r\n```\r\n\r\nOne doesn\'t even need to look into RexProgramFuzzyTest code (and/or understand it) in order to understand the nature of the failure. It is clear that a specific expression had `non-nullable` type and it somehow was optimized to `null`.\r\n\r\nYour message says ""The two inputs should have different row types after planner promotion"", however it is not clear what is promotion, why the types should be different, etc, etc. The actual and expected values are lost, so the only way to understand the test failure is to set a breakpoint in debugger.\r\n', 'commenter': 'vlsi'}, {'comment': ""@vlsi \r\n\r\n> Hep should not change node type after we found best plan for passed in tree nodes, for this case, the bestRel's two projects should keep row type as they originally was, cause data type is an important factor for RelNode equivalence.\r\n\r\nWhat do you thing about this msg ?"", 'commenter': 'danny0405'}, {'comment': ""\r\n> What do you thing about this msg ?\r\n\r\n@danny0405 , the message is better, however it gives very little information when combined with expected/actual. You lose both expected and actual types, so this long message very little info on the nature of the failure.\r\n\r\n\r\nHere's what I mean: https://github.com/apache/calcite/pull/1002/commits/d49690660227f99545e3f6bc25afa7f97b43fcc7"", 'commenter': 'vlsi'}]"
782,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -1703,6 +1703,26 @@ private void checkExponentialCnf(int n) {
     assertThat(result.getOperands().get(2), is((RexNode) falseLiteral));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2455"">[CALCITE-2455]
+   * simplifyCoalesce of constant should match nullability</a>. */
+  @Test public void testSimplifyCoalesceWithConstant() {
+    RexNode inputRef1 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 0);
+    RexNode inputRef2 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 1);
+    RexCall coalesceNode = (RexCall) coalesce(inputRef2, inputRef1);
+
+    ImmutableList.Builder<RexNode> newOperands = ImmutableList.builder();
+    newOperands.add(rexBuilder.makeLiteral(""S"")).add(coalesceNode.operands.get(1));
+    coalesceNode = coalesceNode.clone(coalesceNode.getType(), newOperands.build());","[{'comment': 'Is this `clone` required?\r\nIsn\'t it sufficient to create the proper `coalesce` in the first place?\r\n\r\nIt looks like `coalesce(literal(""S""), vVarchar())` should be just enough for the test.\r\n\r\nIf `ImmutableList` and `copy` is extremely important, please add comments to the test code that would clarify why the code is important.\r\n\r\nOtherwise the  code might be silently refactored later, and we lose the precious test.', 'commenter': 'vlsi'}, {'comment': 'hi, @vlsi \r\nThe calling site is ReducingExpressionRule and it uses `RexSimplify.simplify`. I will add more comments here.', 'commenter': 'danny0405'}]"
782,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -1703,6 +1703,26 @@ private void checkExponentialCnf(int n) {
     assertThat(result.getOperands().get(2), is((RexNode) falseLiteral));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2455"">[CALCITE-2455]
+   * simplifyCoalesce of constant should match nullability</a>. */
+  @Test public void testSimplifyCoalesceWithConstant() {
+    RexNode inputRef1 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 0);
+    RexNode inputRef2 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 1);
+    RexCall coalesceNode = (RexCall) coalesce(inputRef2, inputRef1);
+
+    ImmutableList.Builder<RexNode> newOperands = ImmutableList.builder();
+    newOperands.add(rexBuilder.makeLiteral(""S"")).add(coalesceNode.operands.get(1));
+    coalesceNode = coalesceNode.clone(coalesceNode.getType(), newOperands.build());
+    RexNode result = simplify.simplify(coalesceNode);
+    assertThat(result.getType().isNullable(), is(true));","[{'comment': 'please add assert message.\r\nE.g. `""simplify of "" + coalesceNode + "" is Nullable""`', 'commenter': 'vlsi'}]"
782,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -1703,6 +1703,26 @@ private void checkExponentialCnf(int n) {
     assertThat(result.getOperands().get(2), is((RexNode) falseLiteral));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2455"">[CALCITE-2455]
+   * simplifyCoalesce of constant should match nullability</a>. */
+  @Test public void testSimplifyCoalesceWithConstant() {
+    RexNode inputRef1 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 0);
+    RexNode inputRef2 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 1);
+    RexCall coalesceNode = (RexCall) coalesce(inputRef2, inputRef1);
+
+    ImmutableList.Builder<RexNode> newOperands = ImmutableList.builder();
+    newOperands.add(rexBuilder.makeLiteral(""S"")).add(coalesceNode.operands.get(1));
+    coalesceNode = coalesceNode.clone(coalesceNode.getType(), newOperands.build());
+    RexNode result = simplify.simplify(coalesceNode);
+    assertThat(result.getType().isNullable(), is(true));
+    assertThat(result.getType().getSqlTypeName(), is(SqlTypeName.VARCHAR));","[{'comment': 'Please add message as well', 'commenter': 'vlsi'}]"
782,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -1703,6 +1703,26 @@ private void checkExponentialCnf(int n) {
     assertThat(result.getOperands().get(2), is((RexNode) falseLiteral));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2455"">[CALCITE-2455]
+   * simplifyCoalesce of constant should match nullability</a>. */
+  @Test public void testSimplifyCoalesceWithConstant() {
+    RexNode inputRef1 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 0);
+    RexNode inputRef2 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 1);","[{'comment': 'These type declarations would not be required if https://github.com/apache/calcite/pull/788 was used. Is there a chance you can review #788?', 'commenter': 'vlsi'}]"
782,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -540,6 +540,10 @@ private RexNode simplifyCoalesce(RexCall call) {
     case 0:
       return rexBuilder.makeNullLiteral(call.type);
     case 1:
+      // ensure type consistency, especially nullability.
+      if (!call.getType().equals(operands.get(0).getType())) {","[{'comment': 'Please revert the change and add a comment:\r\n``\r\n// below might change the type of the call (e.g. from nullable to non-nullable)\r\n// however simplify(..) is allowed to return node with different type\r\n// if the type should match, then `simplifyPreservingType` should be used', 'commenter': 'vlsi'}, {'comment': 'Sorry, i think `simplifyCoalesce` should keep nullability just like `simplifyCase`. \r\n```java\r\n    if (newOperands.size() == 1 || values.size() == 1) {\r\n      final RexNode last = Util.last(newOperands);\r\n      if (!call.getType().equals(last.getType())) {\r\n        return rexBuilder.makeAbstractCast(call.getType(), last);\r\n      }\r\n      return last;\r\n    }`\r\n```\r\nCause we use `RexSimplify.simplify` directly in rules but `simplifyPreservingType` is only a tool method for now.\r\n\r\nIf we assert that `RexSimplify.simplify` can modify nullability, at least we should have a parameter to control it but not do it silently.', 'commenter': 'danny0405'}, {'comment': '> Cause we use RexSimplify.simplify directly in rules but simplifyPreservingType is only a tool method for now\r\n\r\nWhy do you think `simplifyCoalesce` should preserve types?\r\n\r\nWhy bother with types of **internal** expressions if the only thing Volcano cares is the type of OVERALL expression?\r\n\r\nMaking internal types (that is types of nested `coalesce` expressions) simpler enables faster operation, and it might open more possibilities for optimizations.', 'commenter': 'vlsi'}, {'comment': 'Okey, got you idea, then how can we use the Rules that use `simplify` during volcano planning. i.e. ReduceExpressionRule. If we have a better way to support nullability for rules them selfs, it may be a better way.', 'commenter': 'danny0405'}, {'comment': 'AFAIK `simplifyCoalesce` is a `private` method, and it cannot be used in `ReduceExpressionRule`.\r\n\r\nCould you please clarify?\r\n\r\n`ReduceExpressionRule` does have `matchNullability`, so either it does not work or it is misused.', 'commenter': 'vlsi'}, {'comment': 'It is `simplify`, `ReduceExpressionRule` does have a flag to control nullability for` ExprSimplifier` but not `RexSimplify`, that is the case.', 'commenter': 'danny0405'}]"
782,core/src/test/java/org/apache/calcite/test/RexProgramTest.java,"@@ -1703,6 +1703,26 @@ private void checkExponentialCnf(int n) {
     assertThat(result.getOperands().get(2), is((RexNode) falseLiteral));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2455"">[CALCITE-2455]
+   * simplifyCoalesce of constant should match nullability</a>. */
+  @Test public void testSimplifyCoalesceWithConstant() {
+    RexNode inputRef1 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 0);
+    RexNode inputRef2 = rexBuilder.makeInputRef(
+        typeFactory.createTypeWithNullability(
+            typeFactory.createSqlType(SqlTypeName.VARCHAR), true), 1);
+    RexCall coalesceNode = (RexCall) coalesce(inputRef2, inputRef1);
+
+    ImmutableList.Builder<RexNode> newOperands = ImmutableList.builder();
+    newOperands.add(rexBuilder.makeLiteral(""S"")).add(coalesceNode.operands.get(1));
+    coalesceNode = coalesceNode.clone(coalesceNode.getType(), newOperands.build());
+    RexNode result = simplify.simplify(coalesceNode);","[{'comment': ""Note: there's `simplify` and `simplifyPreservingType`.\r\nIt looks like it is important to add tests for both cases so we know how each of those behave."", 'commenter': 'vlsi'}]"
784,core/src/test/java/org/apache/calcite/plan/volcano/VolcanoRuleCallTest.java,"@@ -0,0 +1,153 @@
+
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.*;
+import org.apache.calcite.rel.logical.LogicalUnion;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.util.Arrays;
+
+import static org.apache.calcite.plan.volcano.PlannerTests.newCluster;
+
+public class VolcanoRuleCallTest {
+
+  public static class DummyUnionRule extends RelOptRule {
+
+    public DummyUnionRule() {
+      super(operand(LogicalUnion.class, unordered(operand(RelTypeB.class, any()))));
+    }
+
+    @Override
+    public void onMatch(RelOptRuleCall call) {
+      // do nothing
+    }
+  }
+
+  public static class RelTypeA extends PlannerTests.NoneLeafRel {
+    RelTypeA(RelOptCluster cluster, String label) {
+      super(cluster, label);
+    }
+  }
+
+  public static class RelTypeB extends PlannerTests.NoneLeafRel {
+    RelTypeB(RelOptCluster cluster, String label) {
+      super(cluster, label);
+    }
+  }
+
+
+  @Test
+  public void testUnorderedVolcanoDescending() {
+    VolcanoPlanner planner = new VolcanoPlanner();
+    planner.addRelTraitDef(ConventionTraitDef.INSTANCE);
+    planner.addRule(new DummyUnionRule());
+
+    RelOptCluster cluster = newCluster(planner);
+
+        /*
+        test plan:
+        LogicalUnion
+            RelTypeA
+            RelTypeB
+         */
+
+    RelTypeA relA1 =
+        new RelTypeA(
+            cluster,
+            ""a1"");
+    RelTypeB relB1 =
+        new RelTypeB(
+            cluster,
+            ""b1"");
+
+    int matchCounter;
+
+
+    planner.ensureRegistered(relA1, null);
+    planner.ensureRegistered(relB1, null);
+
+    LogicalUnion union = LogicalUnion.create(Arrays.asList(relA1, relB1), true);
+
+    // add the original union to planner
+    planner.ensureRegistered(union, null);
+
+    matchCounter = 0;
+    while (planner.ruleQueue.popMatch(VolcanoPlannerPhase.OPTIMIZE) != null) {
+      matchCounter++;
+    }
+    // expected: should match 1 time (incorrect)
+    Assert.assertEquals(1, matchCounter);","[{'comment': ""Please add relevant message for `assertEquals`.\r\nYou do have a message in comment above, so why don't you put it into the assertion message?\r\n\r\nIf I understand your test right, the message should be something like `DummyUnionRule should fire 1 time since there's 1 LogicalUnion in the plan`. Is that right?\r\n\r\nPS. It is not clear what `1 time (incorrect)` means. Is 1 correct or incorrect?"", 'commenter': 'vlsi'}, {'comment': '1 is the correct expected result. (incorrect) is removed because it can be confusing', 'commenter': 'zuozhiw'}]"
784,core/src/test/java/org/apache/calcite/plan/volcano/VolcanoRuleCallTest.java,"@@ -0,0 +1,153 @@
+
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.*;
+import org.apache.calcite.rel.logical.LogicalUnion;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.util.Arrays;
+
+import static org.apache.calcite.plan.volcano.PlannerTests.newCluster;
+
+public class VolcanoRuleCallTest {
+
+  public static class DummyUnionRule extends RelOptRule {
+
+    public DummyUnionRule() {
+      super(operand(LogicalUnion.class, unordered(operand(RelTypeB.class, any()))));
+    }
+
+    @Override
+    public void onMatch(RelOptRuleCall call) {
+      // do nothing
+    }
+  }
+
+  public static class RelTypeA extends PlannerTests.NoneLeafRel {
+    RelTypeA(RelOptCluster cluster, String label) {
+      super(cluster, label);
+    }
+  }
+
+  public static class RelTypeB extends PlannerTests.NoneLeafRel {
+    RelTypeB(RelOptCluster cluster, String label) {
+      super(cluster, label);
+    }
+  }
+
+
+  @Test
+  public void testUnorderedVolcanoDescending() {
+    VolcanoPlanner planner = new VolcanoPlanner();
+    planner.addRelTraitDef(ConventionTraitDef.INSTANCE);
+    planner.addRule(new DummyUnionRule());
+
+    RelOptCluster cluster = newCluster(planner);
+
+        /*
+        test plan:
+        LogicalUnion
+            RelTypeA
+            RelTypeB
+         */
+
+    RelTypeA relA1 =
+        new RelTypeA(
+            cluster,
+            ""a1"");
+    RelTypeB relB1 =
+        new RelTypeB(
+            cluster,
+            ""b1"");
+
+    int matchCounter;
+
+
+    planner.ensureRegistered(relA1, null);
+    planner.ensureRegistered(relB1, null);
+
+    LogicalUnion union = LogicalUnion.create(Arrays.asList(relA1, relB1), true);
+
+    // add the original union to planner
+    planner.ensureRegistered(union, null);
+
+    matchCounter = 0;
+    while (planner.ruleQueue.popMatch(VolcanoPlannerPhase.OPTIMIZE) != null) {
+      matchCounter++;
+    }
+    // expected: should match 1 time (incorrect)
+    Assert.assertEquals(1, matchCounter);
+
+  }
+
+
+  @Test
+  public void testUnorderedVolcanoAscending() {
+    VolcanoPlanner planner = new VolcanoPlanner();
+    planner.addRelTraitDef(ConventionTraitDef.INSTANCE);
+    planner.addRule(new DummyUnionRule());
+
+    RelOptCluster cluster = newCluster(planner);
+
+        /*
+        test plan:
+        LogicalUnion
+            RelTypeA
+            RelTypeB
+         */
+
+    RelTypeA relA1 =
+        new RelTypeA(
+            cluster,
+            ""a1"");
+    RelTypeB relB1 =
+        new RelTypeB(
+            cluster,
+            ""b1"");
+
+    int matchCounter;
+
+
+    planner.ensureRegistered(relA1, null);
+    planner.ensureRegistered(relB1, null);
+
+    LogicalUnion union = LogicalUnion.create(Arrays.asList(relA1, relB1), true);
+
+    // add the original union to planner
+    planner.ensureRegistered(union, null);
+
+    matchCounter = 0;
+    while (planner.ruleQueue.popMatch(VolcanoPlannerPhase.OPTIMIZE) != null) {
+      matchCounter++;
+    }
+
+        /*
+        test plan:
+        add RelTypeB2 as RelTypeB1's equivalent rel
+        LogicalUnion
+            RelTypeA1
+            (RelTypeB1, RelTypeB2)
+
+        expected: should also trigger the rule
+        the rule specifies unordered - t should trigger the match for any child
+        actual: rule is *not* triggered now
+         */
+    RelTypeB relB2 =
+        new RelTypeB(
+            cluster,
+            ""b2"");
+    planner.ensureRegistered(relB2, relB1);
+
+    matchCounter = 0;
+    while (planner.ruleQueue.popMatch(VolcanoPlannerPhase.OPTIMIZE) != null) {
+      matchCounter++;
+    }
+    // expected: should match 1 time
+    // because the rule specifies unordered, it should trigger the match for any child
+    Assert.assertEquals(1, matchCounter);","[{'comment': 'Please add a message to `assertEquals`. The comment in the code would not be visible in `mvn test`, it would not be visible in `CI`, etc.', 'commenter': 'vlsi'}]"
784,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleCall.java,"@@ -285,26 +286,38 @@ private void matchRecurse(int solve) {
         final int parentOrdinal = operand.getParent().ordinalInRule;
         final RelNode parentRel = rels[parentOrdinal];
         final List<RelNode> inputs = parentRel.getInputs();
-        if (operand.ordinalInParent < inputs.size()) {
-          final RelSubset subset =
-              (RelSubset) inputs.get(operand.ordinalInParent);
-          if (operand.getMatchedClass() == RelSubset.class) {
-            successors = subset.set.subsets;
-          } else {
-            successors = subset.getRelList();
+        // if the child is unordered, then add all rels in all subsets to the successor list
+        // unordered can match child in any ordinal
+        if (parentOperand.childPolicy.equals(RelOptRuleOperandChildPolicy.UNORDERED)) {
+          List<RelNode> allRelsInAllSubsets = new ArrayList<>();
+          for (RelNode input : inputs) {
+            RelSubset inputSubset = (RelSubset) input;
+            allRelsInAllSubsets.addAll(inputSubset.getRelList());
           }
+          successors = allRelsInAllSubsets;
         } else {
-          // The operand expects parentRel to have a certain number
-          // of inputs and it does not.
-          successors = ImmutableList.of();
+          if (operand.ordinalInParent < inputs.size()) {","[{'comment': 'Is this extra nesting level required?\r\nIt looks like `else { if (...) ` could be replaced with `else if (...)`.\r\n\r\nPS. I would put `if (operand.ordinalInParent >= inputs.size()) {` as the first `if` branch since it contains less code than the alternative, so it would be easier to read.', 'commenter': 'vlsi'}]"
784,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleCall.java,"@@ -285,26 +286,38 @@ private void matchRecurse(int solve) {
         final int parentOrdinal = operand.getParent().ordinalInRule;
         final RelNode parentRel = rels[parentOrdinal];
         final List<RelNode> inputs = parentRel.getInputs();
-        if (operand.ordinalInParent < inputs.size()) {
-          final RelSubset subset =
-              (RelSubset) inputs.get(operand.ordinalInParent);
-          if (operand.getMatchedClass() == RelSubset.class) {
-            successors = subset.set.subsets;
-          } else {
-            successors = subset.getRelList();
+        // if the child is unordered, then add all rels in all subsets to the successor list
+        // unordered can match child in any ordinal
+        if (parentOperand.childPolicy.equals(RelOptRuleOperandChildPolicy.UNORDERED)) {","[{'comment': 'This looks like the most interesting part of the change, however I am not familiar with this part, so it is hard for me to review it :-/', 'commenter': 'vlsi'}]"
784,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleCall.java,"@@ -285,11 +288,38 @@ private void matchRecurse(int solve) {
         final int parentOrdinal = operand.getParent().ordinalInRule;
         final RelNode parentRel = rels[parentOrdinal];
         final List<RelNode> inputs = parentRel.getInputs();
-        if (operand.ordinalInParent < inputs.size()) {
+        // if the child is unordered, then add all rels in all input subsets to the successors list
+        // because unordered can match child in any ordinal
+        if (parentOperand.childPolicy == RelOptRuleOperandChildPolicy.UNORDERED) {
+          if (operand.getMatchedClass() == RelSubset.class) {
+            successors = inputs;
+          } else {
+            List<RelNode> allRelsInAllSubsets = new ArrayList<>();
+            Set<RelNode> duplicates = new HashSet<>();
+            for (RelNode input : inputs) {
+              if (!duplicates.add(input)) {
+                // Ignore duplicate subsets
+                continue;
+              }
+              RelSubset inputSubset = (RelSubset) input;
+              for (RelNode rel : inputSubset.getRels()) {
+                if (!duplicates.add(rel)) {
+                  // Ignore duplicate relations
+                  continue;
+                }
+                allRelsInAllSubsets.add(rel);
+              }
+            }
+            successors = allRelsInAllSubsets;
+          }
+        } else if (operand.ordinalInParent < inputs.size()) {
+          // child policy is not unordered
+          // we need to find the exact input node based on child operand's ordinalInParent
           final RelSubset subset =
               (RelSubset) inputs.get(operand.ordinalInParent);
           if (operand.getMatchedClass() == RelSubset.class) {
-            successors = subset.set.subsets;","[{'comment': '@julianhyde , I don\'t think `operand(RelSubset.class)` was often used in practice, however I don\'t think `subset.set.subsets` is a valid `successors`.\r\nWhat it does, it provides all the subsets of a set, no matter which was the actual input for the relation.\r\n\r\nI guess the only viable solution here is `ImmutableList.of(subset)`. In other words, it should provide the subset itself rather than trying to iterate over relations in the subset.\r\n\r\nSee relevant test correction `VolcanoPlannerTest.java`:  the rule no longer fires for `""PhysSingleRel:Subset#0.NONE""` which was impossible (PhysSingleRel always conumes `.PHYS` subset, and it makes no sense to fire a rule for non-existing combination of `Phys` top level relation and `NONE` downstream subset.', 'commenter': 'vlsi'}, {'comment': ""> I don't think subset.set.subsets is a valid successors. [...] I guess the only viable solution here is ImmutableList.of(subset).\r\n\r\nI agree."", 'commenter': 'julianhyde'}]"
784,core/src/test/java/org/apache/calcite/tools/PlannerTest.java,"@@ -372,6 +376,148 @@ private void checkMetadataPredicates(String sql,
             + ""  EnumerableTableScan(table=[[hr, emps]])\n""));
   }
 
+  /** Unit test that parses, validates, converts and plans. */
+  @Test public void trimEmptyUnion2() throws Exception {
+    checkUnionPruning(""values(1) union all select * from (values(2)) where false"",
+        ""EnumerableValues(type=[RecordType(INTEGER EXPR$0)], tuples=[[{ 1 }]])\n"");
+
+    checkUnionPruning(""select * from (values(2)) where false union all values(1)"",
+        ""EnumerableValues(type=[RecordType(INTEGER EXPR$0)], tuples=[[{ 1 }]])\n"");
+  }
+
+  @Test public void trimEmptyUnion31() throws Exception {
+    emptyUnions31();
+  }
+
+  @Test public void trimEmptyUnion31withUnionMerge() throws Exception {
+    emptyUnions31(UnionMergeRule.INSTANCE);
+  }
+
+  private void emptyUnions31(UnionMergeRule... extraRules)
+      throws SqlParseException, ValidationException, RelConversionException {
+    String plan = ""EnumerableValues(type=[RecordType(INTEGER EXPR$0)], tuples=[[{ 1 }]])\n"";
+    checkUnionPruning(""values(1)""
+            + "" union all select * from (values(2)) where false""
+            + "" union all select * from (values(3)) where false"",
+        plan, extraRules);
+
+    checkUnionPruning(""select * from (values(2)) where false""
+            + "" union all values(1)""
+            + "" union all select * from (values(3)) where false"",
+        plan, extraRules);
+
+    checkUnionPruning(""select * from (values(2)) where false""
+            + "" union all select * from (values(3)) where false""
+            + "" union all values(1)"",
+        plan, extraRules);
+  }
+
+  @Ignore(""[CALCITE-2773] java.lang.AssertionError: rel""","[{'comment': 'Did you forget to import `Ignore`?', 'commenter': 'hsyuan'}]"
785,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -810,6 +824,642 @@ private void thereAndBack(byte[] bytes) {
     assertThat(SqlFunctions.multisetUnionDistinct(z, addc),
         is(Arrays.asList(""a"", ""c"", ""d"")));
   }
+
+  @Test public void testJsonValueExpression() {
+    assertThat(SqlFunctions.jsonValueExpression(""{}""), is(Collections.emptyMap()));
+  }
+
+  @Test public void testJsonStructuredValueExpression() {
+    assertThat(SqlFunctions.jsonStructuredValueExpression(""bar""),
+        is(""bar""));
+    assertThat(SqlFunctions.jsonStructuredValueExpression(100),
+        is(100));
+  }
+
+  @Test public void testJsonApiCommonSyntax() {
+    assertThat(
+        SqlFunctions.
+            jsonApiCommonSyntax(ImmutableMap.of(""foo"", ""bar""),
+                ""lax $.foo"").pathReturned,
+        is(""bar""));","[{'comment': 'Please factor that to `assertJsonApiCommonSyntax_pathReturned` method so the exception message contains input, expected and actual values.', 'commenter': 'vlsi'}, {'comment': '+1 thanks.', 'commenter': 'zhztheplayer'}, {'comment': ""I'm afraid you miss the point.\r\n\r\nThe idea was to create a method for testing `jsonApiCommonSyntax` with arguments like `Map input, String jsonPath, Object expectedValue`.\r\nYou can use `Matcher expectedValue` it does not matter.\r\n\r\nHowever, the point is that `message` argument must include human readable context for the analysis in case the test ever fails."", 'commenter': 'vlsi'}]"
785,core/pom.xml,"@@ -96,6 +96,14 @@ limitations under the License.
       <groupId>com.yahoo.datasketches</groupId>
       <artifactId>sketches-core</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.ow2.asm</groupId>
+      <artifactId>asm</artifactId>","[{'comment': 'Is `asm` dependency really required?', 'commenter': 'vlsi'}, {'comment': ""Jayway jsonpath is dependent on asm 5.0.x where elasticsearch-lang-painless uses 5.1, these two version has conflict producing NoSuchMethodError when running unit tests of calcite-elasticsearch.\r\n\r\nWhat I have found is that jsonpath-2.4.0 is also working well with 5.1 version of asm, so I define this asm dependency explicitly to avoid the unit test failure.\r\n\r\nA problem is that elasticsearch-lang-painless's asm is called `asm-debug-all` 5.1, and the jsonpath's asm is `asm` 5.1.\r\n\r\nI am not sure the negative effect to have both of them included in dependency sets, but unit tests work well with that."", 'commenter': 'zhztheplayer'}, {'comment': ""That looks very odd.\r\n\r\n1) `asm` is not used in Calcite code, so it should not be in `<dependency>`\r\n2) Here's dependency tree:\r\n```\r\n[INFO] +- com.jayway.jsonpath:json-path:jar:2.4.0:compile\r\n[INFO] |  \\- net.minidev:json-smart:jar:2.3:compile\r\n[INFO] |     \\- net.minidev:accessors-smart:jar:1.2:compile\r\n[INFO] |        \\- org.ow2.asm:asm:jar:5.0.4:compile\r\n```\r\n\r\nLooking into https://github.com/netplex/json-smart-v2/blob/master/accessors-smart/src/main/java/net/minidev/asm/BeansAccess.java#L54 , I am sure it could result in memory leaks, since it keeps strong references to the Class objects.\r\n\r\nIs `accessors-smart` truly important? Are there other alternatives?"", 'commenter': 'vlsi'}, {'comment': 'Thanks for your comment, and you are right, the `asm-debug-all` is just a test dependency in current version of calcite, so `asm` is newly introduced compile dependency in my code. Does the `asm` itself have any problems to use?\r\n\r\nAnd thanks for the notice about memory leak possibility of `accessors-smart`, I will try to deal with this problem.', 'commenter': 'zhztheplayer'}, {'comment': ""I have take a look at the code of json-smart.\r\n\r\nThe ConcurrentHashMap java type cache seems to be safe in most senarios, unless:\r\n\r\n1. the referenced type passed to json-smart is auto generated;\r\n2. the referenced type passed to json-smart is varing dramatically.\r\n\r\nAs we don't need to pass any type reference to json-smart, and json-path does not generate class in runtime, I think the memory leak will not be triggered in general cases. What do you think?\r\n\r\nAfter this I found that Json-Path has JSON provider configurations, as Jackson is already included by calcite, I have excluded json-smart from dependency set and use Jackson JSON provider instead.\r\n\r\nThen there will be only 1 new jar `json-path:2.4.0` added to calcite, I think this is anyway better than introducing 4 new jars."", 'commenter': 'zhztheplayer'}, {'comment': '>Does the asm itself have any problems to use?\r\n\r\nASM 5 does not support Java 9/10/11.\r\nAdding ASM 5 now is a nonsense.\r\n\r\n> The ConcurrentHashMap java type cache seems to be safe in most senarios\r\n\r\n`Class` instance holds a string reference to its `ClassLoader`, so just a single strong reference to `java.lang.Class` is enough to keep the whole `ClassLoader` alive.\r\n\r\nThat is why `Cache<Class>` and/or `Cache<ClassLoader>` (which is the same thing) is almost always results in a memory leak unless the code is very robust.\r\n\r\nIf you can refrain from adding `asm` as a transitive dependency, that would be way easier to reason about (== no need to invent counter-cases, etc).', 'commenter': 'vlsi'}, {'comment': 'Thanks, I am now clear with this after reading your comment, and excluded use of json-smart and asm now.', 'commenter': 'zhztheplayer'}]"
785,example/csv/sqlline,"@@ -41,6 +41,8 @@ if [ ""$cygwin"" ]; then
   VM_OPTS=-Djline.terminal=jline.UnixTerminal
 fi
 
+export TERM=xterm-color","[{'comment': 'Is it intentional?', 'commenter': 'vlsi'}, {'comment': 'Not intentional, I will remove this.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -419,6 +440,59 @@ public Expression implement(RexToLixTranslator translator,
         new SequenceImplementor(BuiltInMethod.SEQUENCE_NEXT_VALUE.method),
         false);
 
+    // Json Operators
+    defineMethod(JSON_VALUE_EXPRESSION,
+        BuiltInMethod.JSON_VALUE_EXPRESSION.method, NullPolicy.STRICT);
+    defineMethod(JSON_STRUCTURED_VALUE_EXPRESSION,
+        BuiltInMethod.JSON_STRUCTURED_VALUE_EXPRESSION.method, NullPolicy.STRICT);
+    defineMethod(JSON_API_COMMON_SYNTAX, BuiltInMethod.JSON_API_COMMON_SYNTAX.method,
+        NullPolicy.NONE);
+    defineMethod(JSON_EXISTS, BuiltInMethod.JSON_EXISTS.method, NullPolicy.NONE);
+    defineMethod(JSON_VALUE_ANY, BuiltInMethod.JSON_VALUE_ANY.method, NullPolicy.NONE);
+    defineMethod(JSON_QUERY, BuiltInMethod.JSON_QUERY.method, NullPolicy.NONE);
+    defineMethod(JSON_OBJECT, BuiltInMethod.JSON_OBJECT.method, NullPolicy.NONE);
+    aggMap.put(JSON_OBJECTAGG_NULL_ON_NULL, new Supplier<AggImplementor>() {","[{'comment': 'Could you please use `() -> ` syntax here?\r\nOr something like `aggMap.put(JSON_OBJECTAGG_NULL_ON_NULL, JsonObjectAggImplementor.for(BuiltInMethod.JSON_OBJECTAGG_ADD_ABSENT_ON_NULL))`', 'commenter': 'vlsi'}, {'comment': '+1 thanks.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/sql/fun/SqlJsonValueFunction.java,"@@ -0,0 +1,196 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlDataTypeSpec;
+import org.apache.calcite.sql.SqlFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlIdentifier;
+import org.apache.calcite.sql.SqlJsonValueEmptyOrErrorBehavior;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlLiteral;
+import org.apache.calcite.sql.SqlNode;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.SqlOperatorBinding;
+import org.apache.calcite.sql.SqlWriter;
+import org.apache.calcite.sql.parser.SqlParserPos;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlOperandTypeInference;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.sql.type.SqlTypeUtil;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import static org.apache.calcite.util.Static.RESOURCE;
+
+/**
+ * The <code>JSON_VALUE</code> function.
+ */
+public class SqlJsonValueFunction extends SqlFunction {
+
+  private final boolean returnAny;
+
+  public SqlJsonValueFunction(String name, boolean returnAny) {
+    super(
+        name,
+        SqlKind.OTHER_FUNCTION,
+        null,
+        new SqlOperandTypeInference() {
+          @Override public void inferOperandTypes(SqlCallBinding callBinding,
+                                                  RelDataType returnType,
+                                                  RelDataType[] operandTypes) {
+            RelDataTypeFactory typeFactory = callBinding.getTypeFactory();
+            for (int i = 0; i < operandTypes.length; ++i) {
+              operandTypes[i] =
+                  typeFactory.createSqlType(SqlTypeName.ANY);
+            }
+          }
+        },
+        null,
+        SqlFunctionCategory.SYSTEM
+    );
+    this.returnAny = returnAny;
+  }
+
+  @Override public SqlCall createCall(SqlLiteral functionQualifier, SqlParserPos pos,
+                                      SqlNode... operands) {
+    List<SqlNode> operandList = new ArrayList<>();
+    operandList.add(operands[0]);
+    if (operands[1] == null) {
+      operandList.add(SqlLiteral.createSymbol(SqlJsonValueEmptyOrErrorBehavior.NULL, pos));
+      operandList.add(SqlLiteral.createNull(pos));
+    } else {
+      operandList.add(operands[1]);
+      operandList.add(operands[2]);
+    }
+    if (operands[3] == null) {
+      operandList.add(SqlLiteral.createSymbol(SqlJsonValueEmptyOrErrorBehavior.NULL, pos));
+      operandList.add(SqlLiteral.createNull(pos));
+    } else {
+      operandList.add(operands[3]);
+      operandList.add(operands[4]);
+    }
+    if (operands[5] != null) {
+      if (returnAny) {
+        throw new IllegalArgumentException(""illegal returning clause in json_value_any function"");
+      }
+      operandList.add(operands[5]);
+    } else if (!returnAny) {
+      SqlDataTypeSpec defaultTypeSpec = new SqlDataTypeSpec(
+          new SqlIdentifier(""VARCHAR"", pos), 2000, -1,
+          null, null, pos);
+      operandList.add(
+          defaultTypeSpec);
+    }
+    return super.createCall(functionQualifier, pos,
+        operandList.toArray(SqlNode.EMPTY_ARRAY));
+  }
+
+  @Override public SqlOperandCountRange getOperandCountRange() {
+    return SqlOperandCountRanges.between(5, 6);
+  }
+
+  @Override public boolean checkOperandTypes(SqlCallBinding callBinding,
+                                             boolean throwOnFailure) {
+    RelDataType defaultValueOnEmptyType =
+        callBinding.getValidator().getValidatedNodeType(callBinding.operand(2));
+    RelDataType defaultValueOnErrorType =
+        callBinding.getValidator().getValidatedNodeType(callBinding.operand(4));
+    RelDataType returnType = callBinding.getValidator().deriveType(
+        callBinding.getScope(), callBinding.operand(5));
+    if (canCastFrom(callBinding, throwOnFailure, defaultValueOnEmptyType, returnType)) {
+      return false;
+    }
+    if (canCastFrom(callBinding, throwOnFailure, defaultValueOnErrorType, returnType)) {
+      return false;
+    }
+    return true;
+  }
+
+  @Override public RelDataType inferReturnType(SqlOperatorBinding opBinding) {
+    assert opBinding.getOperandCount() == 5 || opBinding.getOperandCount() == 6;
+    RelDataType ret;
+    if (opBinding.getOperandCount() == 6) {
+      ret = opBinding.getOperandType(5);
+    } else {
+      ret = opBinding.getTypeFactory().createSqlType(SqlTypeName.ANY);
+    }
+    return opBinding.getTypeFactory().createTypeWithNullability(
+        ret,
+        true);
+  }
+
+  @Override public String getSignatureTemplate(int operandsCount) {
+    assert operandsCount == 5 || operandsCount == 6;
+    if (operandsCount == 6) {
+      return ""{0}({1} RETURNING {6} {2} {3} ON EMPTY {4} {5} ON ERROR)"";
+    }
+    return ""{0}({1} {2} {3} ON EMPTY {4} {5} ON ERROR)"";
+  }
+
+  @Override public void unparse(SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {
+    assert call.operandCount() == 5 || call.operandCount() == 6;
+    final SqlWriter.Frame frame = writer.startFunCall(getName());
+    call.operand(0).unparse(writer, 0, 0);
+    if (!returnAny) {
+      writer.keyword(""RETURNING"");
+      call.operand(5).unparse(writer, 0, 0);
+    }
+    unparseEnum(writer, call.operand(1));
+    if (isDefaultLiteral(call.operand(1))) {
+      call.operand(2).unparse(writer, 0, 0);
+    }
+    writer.keyword(""ON"");
+    writer.keyword(""EMPTY"");
+    unparseEnum(writer, call.operand(3));
+    if (isDefaultLiteral(call.operand(3))) {
+      call.operand(4).unparse(writer, 0, 0);
+    }
+    writer.keyword(""ON"");
+    writer.keyword(""ERROR"");
+    writer.endFunCall(frame);
+  }
+
+  private void unparseEnum(SqlWriter writer, SqlLiteral literal) {
+    writer.keyword(((Enum) literal.getValue()).name());
+  }
+
+  private boolean isDefaultLiteral(SqlLiteral literal) {
+    return literal.getValueAs(SqlJsonValueEmptyOrErrorBehavior.class)
+        == SqlJsonValueEmptyOrErrorBehavior.DEFAULT;
+  }
+
+  private boolean canCastFrom(SqlCallBinding callBinding, boolean throwOnFailure,
+                              RelDataType inType, RelDataType outType) {
+    if (!SqlTypeUtil.canCastFrom(outType, inType, true)) {","[{'comment': 'Please invert `if` condition and put shorter branches to the top in the cases like that.\r\n\r\nThe following is better than heavily nested code:\r\n```\r\nif (canCastFrom){\r\n  return true;\r\n}\r\nif (!throwOnFailure) {\r\n  return false;\r\n}\r\nthrow ...\r\n```', 'commenter': 'vlsi'}, {'comment': '+1 thanks, and found a bug in line 120 and line 123 in the same file: the condition in if clause should be negative: ` if(canCastFrom) -> if (!canCastFrom)`\r\n\r\nI will fix and add unit test for that.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1723,6 +1789,97 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code JSON_OBJECTAGG} windowed aggregate function. */
+  static class JsonObjectAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonObjectAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonObjectAggImplementor> supplierFor(Method m) {
+      return () -> new JsonObjectAggImplementor(m);
+    }
+
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(HashMap.class);","[{'comment': 'Should it be `Map`?', 'commenter': 'vlsi'}, {'comment': 'Yes.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1726,6 +1792,97 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code JSON_OBJECTAGG} windowed aggregate function. */
+  static class JsonObjectAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonObjectAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonObjectAggImplementor> supplierFor(Method m) {
+      return () -> new JsonObjectAggImplementor(m);
+    }
+
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(Map.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                                   AggResetContext reset) {
+      // acc[0] = new HashMap();","[{'comment': 'Looks like this can be removed', 'commenter': 'michaelmior'}, {'comment': 'Done.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1726,6 +1792,97 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code JSON_OBJECTAGG} windowed aggregate function. */
+  static class JsonObjectAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonObjectAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonObjectAggImplementor> supplierFor(Method m) {
+      return () -> new JsonObjectAggImplementor(m);
+    }
+
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(Map.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                                   AggResetContext reset) {
+      // acc[0] = new HashMap();
+      reset.currentBlock().add(
+          Expressions.statement(
+              Expressions.assign(reset.accumulator().get(0),
+                  Expressions.new_(HashMap.class))));
+    }
+
+    @Override public void implementAdd(AggContext info,
+                                              AggAddContext add) {
+      // acc[0].put(arg0, arg1);","[{'comment': 'Looks like this can be removed', 'commenter': 'michaelmior'}, {'comment': 'Done.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1726,6 +1792,97 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code JSON_OBJECTAGG} windowed aggregate function. */
+  static class JsonObjectAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonObjectAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonObjectAggImplementor> supplierFor(Method m) {
+      return () -> new JsonObjectAggImplementor(m);
+    }
+
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(Map.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                                   AggResetContext reset) {
+      // acc[0] = new HashMap();
+      reset.currentBlock().add(
+          Expressions.statement(
+              Expressions.assign(reset.accumulator().get(0),
+                  Expressions.new_(HashMap.class))));
+    }
+
+    @Override public void implementAdd(AggContext info,
+                                              AggAddContext add) {
+      // acc[0].put(arg0, arg1);
+      add.currentBlock().add(
+          Expressions.statement(
+              Expressions.call(
+                  m,
+                  Iterables.concat(
+                      Collections.singletonList(
+                          add.accumulator().get(0)),
+                      add.arguments()))));
+    }
+
+    @Override public Expression implementResult(AggContext info,
+                                                       AggResultContext result) {
+      return Expressions.call(BuiltInMethod.JSONIZE.method,
+          result.accumulator().get(0));
+    }
+  }
+
+  /** Implementor for the {@code JSON_ARRAYAGG} windowed aggregate function. */
+  static class JsonArrayAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonArrayAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonArrayAggImplementor> supplierFor(Method m) {
+      return () -> new JsonArrayAggImplementor(m);
+    }
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(List.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                         AggResetContext reset) {
+      // acc[0] = new HashMap();","[{'comment': 'Looks like this can be removed', 'commenter': 'michaelmior'}, {'comment': 'Done.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1726,6 +1792,97 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code JSON_OBJECTAGG} windowed aggregate function. */
+  static class JsonObjectAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonObjectAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonObjectAggImplementor> supplierFor(Method m) {
+      return () -> new JsonObjectAggImplementor(m);
+    }
+
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(Map.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                                   AggResetContext reset) {
+      // acc[0] = new HashMap();
+      reset.currentBlock().add(
+          Expressions.statement(
+              Expressions.assign(reset.accumulator().get(0),
+                  Expressions.new_(HashMap.class))));
+    }
+
+    @Override public void implementAdd(AggContext info,
+                                              AggAddContext add) {
+      // acc[0].put(arg0, arg1);
+      add.currentBlock().add(
+          Expressions.statement(
+              Expressions.call(
+                  m,
+                  Iterables.concat(
+                      Collections.singletonList(
+                          add.accumulator().get(0)),
+                      add.arguments()))));
+    }
+
+    @Override public Expression implementResult(AggContext info,
+                                                       AggResultContext result) {
+      return Expressions.call(BuiltInMethod.JSONIZE.method,
+          result.accumulator().get(0));
+    }
+  }
+
+  /** Implementor for the {@code JSON_ARRAYAGG} windowed aggregate function. */
+  static class JsonArrayAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonArrayAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonArrayAggImplementor> supplierFor(Method m) {
+      return () -> new JsonArrayAggImplementor(m);
+    }
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(List.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                         AggResetContext reset) {
+      // acc[0] = new HashMap();
+      reset.currentBlock().add(
+          Expressions.statement(
+              Expressions.assign(reset.accumulator().get(0),
+                  Expressions.new_(ArrayList.class))));
+    }
+
+    @Override public void implementAdd(AggContext info,
+                                       AggAddContext add) {
+      // acc[0].put(arg0, arg1);","[{'comment': 'Looks like this can be removed', 'commenter': 'michaelmior'}, {'comment': 'Done.', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/sql/SqlKind.java,"@@ -721,6 +721,26 @@
    */
   MULTISET_QUERY_CONSTRUCTOR,
 
+  /**
+   * The JSON value expression.
+   */
+  JSON_VALUE_EXPRESSION,
+
+  /**
+   * The JSON API common syntax.
+   */
+  JSON_API_COMMON_SYNTAX,
+
+  /**
+   *","[{'comment': 'Seems like a comment is missing here (and below)', 'commenter': 'michaelmior'}, {'comment': 'Done, thanks!', 'commenter': 'zhztheplayer'}]"
785,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1726,6 +1792,93 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code JSON_OBJECTAGG} windowed aggregate function. */
+  static class JsonObjectAggImplementor implements AggImplementor {
+
+    private final Method m;
+
+    JsonObjectAggImplementor(Method m) {
+      this.m = m;
+    }
+
+    static Supplier<JsonObjectAggImplementor> supplierFor(Method m) {
+      return () -> new JsonObjectAggImplementor(m);
+    }
+
+    @Override public List<Type> getStateType(AggContext info) {
+      return Collections.singletonList(Map.class);
+    }
+
+    @Override public void implementReset(AggContext info,
+                                                   AggResetContext reset) {
+      reset.currentBlock().add(
+          Expressions.statement(
+              Expressions.assign(reset.accumulator().get(0),
+                  Expressions.new_(HashMap.class))));
+    }
+
+    @Override public void implementAdd(AggContext info,
+                                              AggAddContext add) {
+      add.currentBlock().add(
+          Expressions.statement(
+              Expressions.call(
+                  m,
+                  Iterables.concat(
+                      Collections.singletonList(
+                          add.accumulator().get(0)),
+                      add.arguments()))));
+    }
+
+    @Override public Expression implementResult(AggContext info,
+                                                       AggResultContext result) {
+      return Expressions.call(BuiltInMethod.JSONIZE.method,
+          result.accumulator().get(0));
+    }
+  }
+
+  /** Implementor for the {@code JSON_ARRAYAGG} windowed aggregate function. */","[{'comment': 'Do you really mean `windowed` here?', 'commenter': 'vlsi'}, {'comment': 'Mistaken here，it‘s corrected now.', 'commenter': 'zhztheplayer'}]"
805,core/src/main/java/org/apache/calcite/rel/rel2sql/SqlImplementor.java,"@@ -560,17 +560,27 @@ public SqlNode toSql(RexProgram program, RexNode rex) {
         return new SqlDynamicParam(caseParam.getIndex(), POS);
 
       case IN:
-        subQuery = (RexSubQuery) rex;
-        sqlSubQuery = visitChild(0, subQuery.rel).asQueryOrValues();
-        List<RexNode> operands = subQuery.operands;
-        SqlNode op0;
-        if (operands.size() == 1) {
-          op0 = toSql(program, operands.get(0));
+        if (rex instanceof RexSubQuery) {
+          subQuery = (RexSubQuery) rex;
+          sqlSubQuery = visitChild(0, subQuery.rel).asQueryOrValues();","[{'comment': 'e, can we have two separate lines here ?', 'commenter': 'zinking'}, {'comment': ""Thank you for taking a look.\r\nI think you've probably meaned splitting it like this:\r\n```\r\n   sqlSubQuery =\r\n        visitChild(0, subQuery.rel).asQueryOrValues();\r\n```\r\nI've updated the patch."", 'commenter': 'kgyrtkirk'}]"
805,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -364,6 +369,83 @@ private static MysqlSqlDialect mySqlDialect(NullCollation nullCollation) {
     sql(query).withHive().ok(expected);
   }
 
+  @Test public void testHiveIn() {
+    // this can't be tested using ""sql""
+    // because Calcite's sql parser replaces INs with ORs or subqueries.
+    final RelBuilder builder = RelBuilder.create(RelBuilderTest.config().build());
+    RexBuilder rexBuilder = builder.getRexBuilder();
+    RelNode root =
+            builder.scan(""EMP"")
+                    .filter(
+                            rexBuilder.makeCall(SqlStdOperatorTable.IN,
+                                    builder.field(""DEPTNO""),
+                                    builder.literal(20),
+                                    builder.literal(21)))
+                    .build();
+    RelNode rel = root;
+
+    SqlDialect dialect = SqlDialect.DatabaseProduct.HIVE.getDialect();
+    final RelToSqlConverter converter = new RelToSqlConverter(dialect);
+    final SqlNode sqlNode = converter.visitChild(0, rel).asStatement();
+    String sqlStr = sqlNode.toSqlString(dialect).getSql();
+    assertEquals(""SELECT *\n""
+            + ""FROM scott.EMP\n""
+            + ""WHERE DEPTNO IN (20, 21)"", sqlStr);
+  }
+
+  @Test public void testHiveIn1() {
+    // this can't be tested using ""sql""
+    // because Calcite's sql parser replaces INs with ORs or subqueries.
+    final RelBuilder builder = RelBuilder.create(RelBuilderTest.config().build());
+    RexBuilder rexBuilder = builder.getRexBuilder();
+    RelNode root =
+            builder.scan(""EMP"")
+                    .filter(
+                            rexBuilder.makeCall(SqlStdOperatorTable.IN,
+                                    builder.field(""DEPTNO""),
+                                    builder.literal(21)))
+                    .build();
+    RelNode rel = root;
+
+    SqlDialect dialect = SqlDialect.DatabaseProduct.HIVE.getDialect();
+    final RelToSqlConverter converter = new RelToSqlConverter(dialect);
+    final SqlNode sqlNode = converter.visitChild(0, rel).asStatement();
+    String sqlStr = sqlNode.toSqlString(dialect).getSql();
+    assertEquals(""SELECT *\n""
+            + ""FROM scott.EMP\n""
+            + ""WHERE DEPTNO IN (21)"", sqlStr);
+  }
+
+  @Test public void testHiveIn2() {
+    // this can't be tested using ""sql""
+    // because Calcite's sql parser replaces INs with ORs or subqueries.
+    final RelBuilder builder = RelBuilder.create(RelBuilderTest.config().build());
+    RexBuilder rexBuilder = builder.getRexBuilder();
+    RelNode root =
+            builder.scan(""EMP"")
+                    .filter(
+                            rexBuilder.makeCall(SqlStdOperatorTable.IN,
+                            rexBuilder.makeCall(SqlStdOperatorTable.ROW,
+                                    builder.field(""DEPTNO""), builder.field(""JOB"")),
+                            rexBuilder.makeCall(SqlStdOperatorTable.ROW,
+                                    builder.literal(1), builder.literal(""PRESIDENT"")),
+                            rexBuilder.makeCall(SqlStdOperatorTable.ROW,
+                                    builder.literal(2), builder.literal(""PRESIDENT""))
+                            )
+                            )
+                    .build();
+    RelNode rel = root;
+
+    SqlDialect dialect = SqlDialect.DatabaseProduct.HIVE.getDialect();
+    final RelToSqlConverter converter = new RelToSqlConverter(dialect);
+    final SqlNode sqlNode = converter.visitChild(0, rel).asStatement();
+    String sqlStr = sqlNode.toSqlString(dialect).getSql();
+    assertEquals(""SELECT *\n""
+            + ""FROM scott.EMP\n""
+            + ""WHERE ROW(DEPTNO, JOB) IN (ROW(1, 'PRESIDENT'), ROW(2, 'PRESIDENT'))""","[{'comment': 'Please add a test for one element here as well', 'commenter': 'vlsi'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSort.java,"@@ -57,48 +54,22 @@
 
   @Override public void implement(Implementor implementor) {
     implementor.visitChild(0, getInput());
-    if (!collation.getFieldCollations().isEmpty()) {
-      final List<String> keys = new ArrayList<>();
-      if (input instanceof Project) {
-        final List<RexNode> projects = ((Project) input).getProjects();
+    final List<RelDataTypeField> fields = getRowType().getFieldList();
 
-        for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
-          RexNode project = projects.get(fieldCollation.getFieldIndex());
-          String name = project.accept(MapProjectionFieldVisitor.INSTANCE);
-          keys.add(ElasticsearchRules.quote(name) + "": "" + direction(fieldCollation));
-        }
-      } else {
-        final List<RelDataTypeField> fields = getRowType().getFieldList();
-
-        for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
-          final String name = fields.get(fieldCollation.getFieldIndex()).getName();
-          keys.add(ElasticsearchRules.quote(name) + "": "" + direction(fieldCollation));
-        }
-      }
-
-      implementor.add(""\""sort\"": [ "" + Util.toString(keys, ""{"", ""}, {"", ""}"") + ""]"");
+    for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
+      final String name = fields.get(fieldCollation.getFieldIndex()).getName();
+      implementor.addSort(name, fieldCollation.getDirection());","[{'comment': 'IMO you should pass the NullDirection here as well.', 'commenter': 'beikov'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchRel.java,"@@ -39,19 +43,75 @@
    * {@link ElasticsearchRel} nodes into an Elasticsearch query.
    */
   class Implementor {
+
     final List<String> list = new ArrayList<>();
 
+    /**
+     * Sorting clauses.
+     * @see <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/current/search-request-sort.html"">Sort</a>
+     */
+    final List<Map.Entry<String, RelFieldCollation.Direction>> sort = new ArrayList<>();","[{'comment': 'Handle NullDirection. Here is an example for how this could be done: https://stackoverflow.com/questions/29714992/elasticsearch-sort-by-field-with-null-values-last', 'commenter': 'beikov'}, {'comment': ""Regarding `NullDirection` I would like to do it in a separate effort (PR) for the following reasons:\r\n\r\n1. `NullDirection` functionality is not currently supported by ES adapter.\r\n2. This PR is more about aggregations not sorting (although they're related).\r\n3. Sorting with and without aggregations (terms buckets) might need to be coded differently. Nulls in terms aggregation is in fact a missing value (constant `__MISSING_VALUE__') not null.\r\n4. Performance implications of adding `function_score`. Sorting on derived field **might** mean scanning the whole index and applying the function for each document (meaning some internal indices might not be re-used).\r\n\r\nPerhaps [Bucket Sort Aggregation will help](https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-pipeline-bucket-sort-aggregation.html) but this was introduced in v6.1\r\n\r\nOverall aggregations and sorting (with null values) require more thought and probably can be done independently of this PR.\r\n\r\n"", 'commenter': 'asereda-gs'}, {'comment': 'Oh ok, I had the impression that this would be easy, but I see your point. Could you please create a separate JIRA for this?', 'commenter': 'beikov'}, {'comment': 'Added [CALCITE-2553](https://issues.apache.org/jira/browse/CALCITE-2553) to track this.', 'commenter': 'asereda-gs'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -87,37 +126,216 @@ private static ElasticsearchVersion detectVersion(RestClient client, ObjectMappe
     return ElasticsearchVersion.fromString(node.get(""version"").get(""number"").asText());
   }
 
-  @Override protected String scriptedFieldPrefix() {
+  /**
+   * In ES 5.x scripted fields start with {@code params._source.foo} while in ES2.x
+   * {@code _source.foo}. Helper method to build correct query based on runtime version of elastic.
+   * Used to keep backwards compatibility with ES2.
+   *
+   * @see <a href=""https://github.com/elastic/elasticsearch/issues/20068"">_source variable</a>
+   * @see <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-fields.html"">Scripted Fields</a>
+   * @return string to be used for scripted fields
+   */
+  String scriptedFieldPrefix() {
     // ES2 vs ES5 scripted field difference
     return version == ElasticsearchVersion.ES2
         ? ElasticsearchConstants.SOURCE_GROOVY
         : ElasticsearchConstants.SOURCE_PAINLESS;
   }
 
-  @Override protected Enumerable<Object> find(String index, List<String> ops,
-      List<Map.Entry<String, Class>> fields) {
+  /**
+   * Executes a ""find"" operation on the underlying type.
+   *
+   * <p>For example,
+   * <code>client.prepareSearch(index).setTypes(type)
+   * .setSource(""{\""fields\"" : [\""state\""]}"")</code></p>
+   *
+   * @param ops List of operations represented as Json strings.
+   * @param fields List of fields to project; or null to return map
+   * @param sort list of fields to sort and their direction (asc/desc)
+   * @param aggregations aggregation functions
+   * @return Enumerator of results
+   */
+  protected Enumerable<Object> find(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (!aggregations.isEmpty()) {
+      // process aggregations separately
+      return aggregate(ops, fields, sort, groupBy, aggregations, offset, fetch);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
 
-    final String query;
-    if (!ops.isEmpty()) {
-      query = ""{"" + Util.toString(ops, """", "", "", """") + ""}"";
-    } else {
-      query = ""{}"";
+    // manually parse from previously concatenated string
+    query.setAll(
+        (ObjectNode) mapper.readTree(""{""
+            + Util.toString(ops, """", "", "", """") + ""}""));
+
+    if (!sort.isEmpty()) {
+      ArrayNode sortNode = mapper.createArrayNode();
+      query.set(""sort"", sortNode);
+      sort.forEach(e ->
+          sortNode.add(
+            mapper.createObjectNode().put(e.getKey(), e.getValue().isDescending() ? ""desc"" : ""asc""))
+      );
+    }
+
+    if (offset != null) {
+      query.put(""from"", offset);
+    }
+
+    if (fetch != null) {
+      query.put(""size"", fetch);
     }
 
     try {
-      ElasticsearchSearchResult result = httpRequest(query);
-      final Function1<ElasticsearchSearchResult.SearchHit, Object> getter =
+      ObjectNode result = httpRequest(query);
+      ElasticsearchJson.Result search = mapper.treeToValue(result, ElasticsearchJson.Result.class);
+      final Function1<ElasticsearchJson.SearchHit, Object> getter =
           ElasticsearchEnumerators.getter(fields);
-      return Linq4j.asEnumerable(result.searchHits().hits()).select(getter);
+      return Linq4j.asEnumerable(search.searchHits().hits()).select(getter);
     } catch (IOException e) {
       throw new UncheckedIOException(e);
     }
   }
 
-  private ElasticsearchSearchResult httpRequest(String query) throws IOException {
+  private Enumerable<Object> aggregate(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (aggregations.isEmpty()) {
+      throw new IllegalArgumentException(""Missing Aggregations"");
+    }
+
+    if (!groupBy.isEmpty() && offset != null) {","[{'comment': 'You could instead fetch `fetch + offset` elements and just skip the first `offset` to support this.', 'commenter': 'beikov'}, {'comment': 'That would mean fetching unnecessary data. Perhaps let user make the call ?\r\n```sql\r\nselect * from (select * from elastic limit $fetch + $offset) skip $offset\r\n```\r\nAssuming calcite will not make optimizations on its own.\r\n\r\n[Bucket aggregation sorting](https://www.elastic.co/guide/en/elasticsearch/reference/6.1/search-aggregations-pipeline-bucket-sort-aggregation.html) might help (it has `from / size`)  but it was introduced in v.6.1', 'commenter': 'asereda-gs'}, {'comment': ""Maybe we could introduce a configuration property for this? It's unnecessary data, but if a user really wants to do this, there is no other way than doing it like that. Again, could please open a separate JIRA for this if you want to do this separately?"", 'commenter': 'beikov'}, {'comment': 'Created [CALCITE-2557](https://issues.apache.org/jira/browse/CALCITE-2557)', 'commenter': 'asereda-gs'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -87,37 +126,216 @@ private static ElasticsearchVersion detectVersion(RestClient client, ObjectMappe
     return ElasticsearchVersion.fromString(node.get(""version"").get(""number"").asText());
   }
 
-  @Override protected String scriptedFieldPrefix() {
+  /**
+   * In ES 5.x scripted fields start with {@code params._source.foo} while in ES2.x
+   * {@code _source.foo}. Helper method to build correct query based on runtime version of elastic.
+   * Used to keep backwards compatibility with ES2.
+   *
+   * @see <a href=""https://github.com/elastic/elasticsearch/issues/20068"">_source variable</a>
+   * @see <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-fields.html"">Scripted Fields</a>
+   * @return string to be used for scripted fields
+   */
+  String scriptedFieldPrefix() {
     // ES2 vs ES5 scripted field difference
     return version == ElasticsearchVersion.ES2
         ? ElasticsearchConstants.SOURCE_GROOVY
         : ElasticsearchConstants.SOURCE_PAINLESS;
   }
 
-  @Override protected Enumerable<Object> find(String index, List<String> ops,
-      List<Map.Entry<String, Class>> fields) {
+  /**
+   * Executes a ""find"" operation on the underlying type.
+   *
+   * <p>For example,
+   * <code>client.prepareSearch(index).setTypes(type)
+   * .setSource(""{\""fields\"" : [\""state\""]}"")</code></p>
+   *
+   * @param ops List of operations represented as Json strings.
+   * @param fields List of fields to project; or null to return map
+   * @param sort list of fields to sort and their direction (asc/desc)
+   * @param aggregations aggregation functions
+   * @return Enumerator of results
+   */
+  protected Enumerable<Object> find(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (!aggregations.isEmpty()) {
+      // process aggregations separately
+      return aggregate(ops, fields, sort, groupBy, aggregations, offset, fetch);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
 
-    final String query;
-    if (!ops.isEmpty()) {
-      query = ""{"" + Util.toString(ops, """", "", "", """") + ""}"";
-    } else {
-      query = ""{}"";
+    // manually parse from previously concatenated string
+    query.setAll(
+        (ObjectNode) mapper.readTree(""{""
+            + Util.toString(ops, """", "", "", """") + ""}""));
+
+    if (!sort.isEmpty()) {
+      ArrayNode sortNode = mapper.createArrayNode();
+      query.set(""sort"", sortNode);
+      sort.forEach(e ->
+          sortNode.add(
+            mapper.createObjectNode().put(e.getKey(), e.getValue().isDescending() ? ""desc"" : ""asc""))
+      );
+    }
+
+    if (offset != null) {
+      query.put(""from"", offset);
+    }
+
+    if (fetch != null) {
+      query.put(""size"", fetch);
     }
 
     try {
-      ElasticsearchSearchResult result = httpRequest(query);
-      final Function1<ElasticsearchSearchResult.SearchHit, Object> getter =
+      ObjectNode result = httpRequest(query);
+      ElasticsearchJson.Result search = mapper.treeToValue(result, ElasticsearchJson.Result.class);
+      final Function1<ElasticsearchJson.SearchHit, Object> getter =
           ElasticsearchEnumerators.getter(fields);
-      return Linq4j.asEnumerable(result.searchHits().hits()).select(getter);
+      return Linq4j.asEnumerable(search.searchHits().hits()).select(getter);
     } catch (IOException e) {
       throw new UncheckedIOException(e);
     }
   }
 
-  private ElasticsearchSearchResult httpRequest(String query) throws IOException {
+  private Enumerable<Object> aggregate(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (aggregations.isEmpty()) {
+      throw new IllegalArgumentException(""Missing Aggregations"");
+    }
+
+    if (!groupBy.isEmpty() && offset != null) {
+      String message = ""Currently ES doesn't support generic pagination ""
+          + ""with aggregations. You can still use LIMIT keyword (without OFFSET). ""
+          + ""For more details see https://github.com/elastic/elasticsearch/issues/4915"";
+      throw new IllegalStateException(message);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
+
+    // manually parse into JSON from previously concatenated strings
+    query.setAll((ObjectNode) mapper.readTree(""{"" + Util.toString(ops, """", "", "", """") + ""}""));
+
+    // remove / override attributes which are not applicable to aggregations
+    query.put(""_source"", false);
+    query.put(""size"", 0);
+    query.remove(""script_fields"");
+
+    // allows to detect aggregation for count(*)
+    final Predicate<Map.Entry<String, String>> isCountStar = e -> e.getValue()
+            .contains(""\"""" + ElasticsearchConstants.ID + ""\"""");
+
+    // list of expressions which are count(*)
+    final Set<String> countAll = aggregations.stream()
+            .filter(isCountStar)
+        .map(Map.Entry::getKey).collect(Collectors.toSet());
+
+    final Map<String, String> fieldMap = new HashMap<>();
+
+    // due to ES aggregation format. fields in ""order by"" clause should go first
+    // if ""order by"" is missing. order in ""group by"" is un-important
+    final Set<String> orderedGroupBy = new LinkedHashSet<>();
+    orderedGroupBy.addAll(sort.stream().map(Map.Entry::getKey).collect(Collectors.toList()));
+    orderedGroupBy.addAll(groupBy);
+
+    // construct nested aggregations node(s)
+    ObjectNode parent = query.with(AGGREGATIONS);
+    for (String name: orderedGroupBy) {
+      final String aggName = ""g_"" + name;
+      fieldMap.put(aggName, name);
+
+      final ObjectNode section = parent.with(aggName);
+      final ObjectNode terms = section.with(""terms"");
+      terms.put(""field"", name);
+      terms.set(""missing"", ElasticsearchJson.MISSING_VALUE); // expose missing terms
+
+      if (fetch != null) {
+        terms.put(""size"", fetch);
+      }
+
+      sort.stream().filter(e -> e.getKey().equals(name)).findAny().ifPresent(s -> {
+        terms.with(""order"").put(""_key"", s.getValue().isDescending() ? ""desc"" : ""asc"");
+      });
+
+      parent = section.with(AGGREGATIONS);
+    }
+
+    // simple version for queries like ""select count(*), max(col1) from table"" (without GROUP BY)
+    if (!(aggregations.stream().allMatch(isCountStar) && groupBy.isEmpty())) {","[{'comment': 'Move this expensive check outside of the loop and rewrite to `!groupBy.isEmpty() || !aggregations.stream().allMatch(isCountStar)`', 'commenter': 'beikov'}, {'comment': 'This check is outside `orderedGroupBy` loop. I will rewrite the boolean logic.', 'commenter': 'asereda-gs'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -87,37 +126,216 @@ private static ElasticsearchVersion detectVersion(RestClient client, ObjectMappe
     return ElasticsearchVersion.fromString(node.get(""version"").get(""number"").asText());
   }
 
-  @Override protected String scriptedFieldPrefix() {
+  /**
+   * In ES 5.x scripted fields start with {@code params._source.foo} while in ES2.x
+   * {@code _source.foo}. Helper method to build correct query based on runtime version of elastic.
+   * Used to keep backwards compatibility with ES2.
+   *
+   * @see <a href=""https://github.com/elastic/elasticsearch/issues/20068"">_source variable</a>
+   * @see <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-fields.html"">Scripted Fields</a>
+   * @return string to be used for scripted fields
+   */
+  String scriptedFieldPrefix() {
     // ES2 vs ES5 scripted field difference
     return version == ElasticsearchVersion.ES2
         ? ElasticsearchConstants.SOURCE_GROOVY
         : ElasticsearchConstants.SOURCE_PAINLESS;
   }
 
-  @Override protected Enumerable<Object> find(String index, List<String> ops,
-      List<Map.Entry<String, Class>> fields) {
+  /**
+   * Executes a ""find"" operation on the underlying type.
+   *
+   * <p>For example,
+   * <code>client.prepareSearch(index).setTypes(type)
+   * .setSource(""{\""fields\"" : [\""state\""]}"")</code></p>
+   *
+   * @param ops List of operations represented as Json strings.
+   * @param fields List of fields to project; or null to return map
+   * @param sort list of fields to sort and their direction (asc/desc)
+   * @param aggregations aggregation functions
+   * @return Enumerator of results
+   */
+  protected Enumerable<Object> find(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (!aggregations.isEmpty()) {
+      // process aggregations separately
+      return aggregate(ops, fields, sort, groupBy, aggregations, offset, fetch);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
 
-    final String query;
-    if (!ops.isEmpty()) {
-      query = ""{"" + Util.toString(ops, """", "", "", """") + ""}"";
-    } else {
-      query = ""{}"";
+    // manually parse from previously concatenated string
+    query.setAll(
+        (ObjectNode) mapper.readTree(""{""
+            + Util.toString(ops, """", "", "", """") + ""}""));
+
+    if (!sort.isEmpty()) {
+      ArrayNode sortNode = mapper.createArrayNode();
+      query.set(""sort"", sortNode);
+      sort.forEach(e ->
+          sortNode.add(
+            mapper.createObjectNode().put(e.getKey(), e.getValue().isDescending() ? ""desc"" : ""asc""))
+      );
+    }
+
+    if (offset != null) {
+      query.put(""from"", offset);
+    }
+
+    if (fetch != null) {
+      query.put(""size"", fetch);
     }
 
     try {
-      ElasticsearchSearchResult result = httpRequest(query);
-      final Function1<ElasticsearchSearchResult.SearchHit, Object> getter =
+      ObjectNode result = httpRequest(query);
+      ElasticsearchJson.Result search = mapper.treeToValue(result, ElasticsearchJson.Result.class);
+      final Function1<ElasticsearchJson.SearchHit, Object> getter =
           ElasticsearchEnumerators.getter(fields);
-      return Linq4j.asEnumerable(result.searchHits().hits()).select(getter);
+      return Linq4j.asEnumerable(search.searchHits().hits()).select(getter);
     } catch (IOException e) {
       throw new UncheckedIOException(e);
     }
   }
 
-  private ElasticsearchSearchResult httpRequest(String query) throws IOException {
+  private Enumerable<Object> aggregate(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (aggregations.isEmpty()) {
+      throw new IllegalArgumentException(""Missing Aggregations"");
+    }
+
+    if (!groupBy.isEmpty() && offset != null) {
+      String message = ""Currently ES doesn't support generic pagination ""
+          + ""with aggregations. You can still use LIMIT keyword (without OFFSET). ""
+          + ""For more details see https://github.com/elastic/elasticsearch/issues/4915"";
+      throw new IllegalStateException(message);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
+
+    // manually parse into JSON from previously concatenated strings
+    query.setAll((ObjectNode) mapper.readTree(""{"" + Util.toString(ops, """", "", "", """") + ""}""));
+
+    // remove / override attributes which are not applicable to aggregations
+    query.put(""_source"", false);
+    query.put(""size"", 0);
+    query.remove(""script_fields"");
+
+    // allows to detect aggregation for count(*)
+    final Predicate<Map.Entry<String, String>> isCountStar = e -> e.getValue()
+            .contains(""\"""" + ElasticsearchConstants.ID + ""\"""");
+
+    // list of expressions which are count(*)
+    final Set<String> countAll = aggregations.stream()
+            .filter(isCountStar)
+        .map(Map.Entry::getKey).collect(Collectors.toSet());
+
+    final Map<String, String> fieldMap = new HashMap<>();
+
+    // due to ES aggregation format. fields in ""order by"" clause should go first
+    // if ""order by"" is missing. order in ""group by"" is un-important
+    final Set<String> orderedGroupBy = new LinkedHashSet<>();
+    orderedGroupBy.addAll(sort.stream().map(Map.Entry::getKey).collect(Collectors.toList()));
+    orderedGroupBy.addAll(groupBy);
+
+    // construct nested aggregations node(s)
+    ObjectNode parent = query.with(AGGREGATIONS);
+    for (String name: orderedGroupBy) {
+      final String aggName = ""g_"" + name;
+      fieldMap.put(aggName, name);
+
+      final ObjectNode section = parent.with(aggName);
+      final ObjectNode terms = section.with(""terms"");
+      terms.put(""field"", name);
+      terms.set(""missing"", ElasticsearchJson.MISSING_VALUE); // expose missing terms
+
+      if (fetch != null) {
+        terms.put(""size"", fetch);
+      }
+
+      sort.stream().filter(e -> e.getKey().equals(name)).findAny().ifPresent(s -> {
+        terms.with(""order"").put(""_key"", s.getValue().isDescending() ? ""desc"" : ""asc"");
+      });
+
+      parent = section.with(AGGREGATIONS);
+    }
+
+    // simple version for queries like ""select count(*), max(col1) from table"" (without GROUP BY)
+    if (!(aggregations.stream().allMatch(isCountStar) && groupBy.isEmpty())) {
+      for (Map.Entry<String, String> aggregation : aggregations) {
+        JsonNode value = mapper.readTree(""{"" + aggregation.getValue()  + ""}"");
+        parent.set(aggregation.getKey(), value);
+      }
+    }
+
+    // cleanup query. remove empty AGGREGATIONS element (if empty)
+    JsonNode agg = query;
+    while (agg.has(AGGREGATIONS) && agg.get(AGGREGATIONS).elements().hasNext()) {
+      agg = agg.get(AGGREGATIONS);
+    }
+    ((ObjectNode) agg).remove(AGGREGATIONS);
+
+    ObjectNode node = httpRequest(query);
+    ElasticsearchJson.Result res = mapper.treeToValue(node,
+                ElasticsearchJson.Result.class);
+
+
+    final List<Map<String, Object>> result = new ArrayList<>();
+    if (res.aggregations() != null) {
+      // collect values
+      ElasticsearchJson.visitValueNodes(res.aggregations(), m -> {
+        Map<String, Object> newMap = new LinkedHashMap<>();
+        for (String key: m.keySet()) {
+          newMap.put(fieldMap.getOrDefault(key, key), m.get(key));
+        }
+        result.add(newMap);
+      });
+    } else {
+      // probably no group by. add single result
+      result.add(new LinkedHashMap<>());
+    }
+
+    // elastic exposes total number of documents matching a query in ""/hits/total"" path
+    // this can be used for simple ""select count(*) from table""
+    final long total = res.searchHits().total();
+
+    if (groupBy.isEmpty()) {
+      // put totals automatically for count(*) expression(s), unless they contain group by
+      for (String expr : countAll) {
+        result.forEach(m -> m.put(expr, total));
+      }
+    }
+
+    final Function1<ElasticsearchJson.SearchHit, Object> getter =
+        ElasticsearchEnumerators.getter(fields);
+
+    ElasticsearchJson.SearchHits hits =
+        new ElasticsearchJson.SearchHits(total, result.stream()
+            .map(r -> new ElasticsearchJson.SearchHit(""_id"", r, null))
+            .collect(Collectors.toList()));
+
+    return Linq4j.asEnumerable(hits.hits()).select(getter);
+  }
+
+  private ObjectNode httpRequest(ObjectNode query) throws IOException {","[{'comment': 'IMO this should always return `ElasticseachrJson.Result`.', 'commenter': 'beikov'}, {'comment': 'fixed', 'commenter': 'asereda-gs'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -128,8 +346,74 @@ private ElasticsearchSearchResult httpRequest(String query) throws IOException {
     }
 
     try (InputStream is = response.getEntity().getContent()) {
-      return mapper.readValue(is, ElasticsearchSearchResult.class);
+      return (ObjectNode) mapper.readTree(is);","[{'comment': 'I think it would be better to cache an `ObjectReader` and use that to consume the input stream directly to avoid unnecessary copying.', 'commenter': 'beikov'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchAggregate.java,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.elasticsearch;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.plan.RelOptPlanner;
+import org.apache.calcite.plan.RelTraitSet;
+import org.apache.calcite.rel.InvalidRelException;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Aggregate;
+import org.apache.calcite.rel.core.AggregateCall;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.util.ImmutableBitSet;
+
+import java.util.ArrayList;
+import java.util.EnumSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Set;
+
+/**
+ * Implementation of
+ * {@link org.apache.calcite.rel.core.Aggregate} relational expression
+ * for ElasticSearch.
+ */
+public class ElasticsearchAggregate extends Aggregate implements ElasticsearchRel {
+
+  private static final Set<SqlKind> SUPPORTED_AGGREGATIONS =
+      EnumSet.of(SqlKind.COUNT, SqlKind.MAX, SqlKind.MIN, SqlKind.AVG, SqlKind.SUM);
+
+  /** Creates a GeodeAggregate. */
+  ElasticsearchAggregate(RelOptCluster cluster,
+      RelTraitSet traitSet,
+      RelNode input,
+      boolean indicator,
+      ImmutableBitSet groupSet,
+      List<ImmutableBitSet> groupSets,
+      List<AggregateCall> aggCalls) throws InvalidRelException  {
+    super(cluster, traitSet, input, indicator, groupSet, groupSets, aggCalls);
+
+    if (getConvention() != input.getConvention()) {
+      String message = String.format(Locale.ROOT, ""%s != %s"", getConvention(),
+          input.getConvention());
+      throw new AssertionError(message);
+    }
+
+    assert getConvention() == input.getConvention();
+    assert getConvention() == ElasticsearchRel.CONVENTION;
+    assert this.groupSets.size() == 1 : ""Grouping sets not supported"";
+
+    for (AggregateCall aggCall : aggCalls) {
+      if (aggCall.isDistinct()) {
+        throw new InvalidRelException(""distinct aggregation not supported"");
+      }
+
+      SqlKind kind = aggCall.getAggregation().getKind();
+      if (!SUPPORTED_AGGREGATIONS.contains(kind)) {
+        final String message = String.format(Locale.ROOT,
+            ""Aggregation %s not supported (use one of %s)"", kind, SUPPORTED_AGGREGATIONS);
+        throw new InvalidRelException(message);
+      }
+    }
+
+    if (getGroupType() != Group.SIMPLE) {
+      final String message = String.format(Locale.ROOT, ""Only %s grouping is supported. ""
+              + ""Yours is %s"", Group.SIMPLE, getGroupType());
+      throw new InvalidRelException(message);
+    }
+
+  }
+
+  @Override public Aggregate copy(RelTraitSet traitSet, RelNode input, boolean indicator,
+      ImmutableBitSet groupSet, List<ImmutableBitSet> groupSets,
+      List<AggregateCall> aggCalls) {
+    try {
+      return new ElasticsearchAggregate(getCluster(), traitSet, input,
+          indicator, groupSet, groupSets,
+          aggCalls);
+    } catch (InvalidRelException e) {
+      throw new AssertionError(e);
+    }
+  }
+
+  @Override public RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {
+    return super.computeSelfCost(planner, mq).multiplyBy(0.1);
+  }
+
+  @Override public void implement(Implementor implementor) {
+    implementor.visitChild(0, getInput());
+    List<String> inputFields = fieldNames(getInput().getRowType());
+
+    if (groupSet.cardinality() == 1) {
+      final String groupByFieldName = inputFields.get(groupSet.nth(0));
+      implementor.addGroupBy(groupByFieldName);
+    } else {
+      for (int group : groupSet) {
+        implementor.addGroupBy(inputFields.get(group));
+      }
+    }
+
+    for (AggregateCall aggCall : aggCalls) {
+      List<String> names = new ArrayList<>();
+      for (int i : aggCall.getArgList()) {
+        names.add(inputFields.get(i));
+      }
+
+      final String name = names.isEmpty() ? ElasticsearchConstants.ID : names.get(0);
+
+      String op = String.format(Locale.ROOT, ""\""%s\"":{\""field\"": \""%s\""}"",
+          toElasticAggregate(aggCall),
+          name);
+
+      implementor.addAggregation(aggCall.getName(), op);
+    }
+  }
+
+  /**
+   * Most of the aggregations can be retrieved with single
+   * <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/current/search-aggregations-metrics-stats-aggregation.html"">stats</a>
+   * function. But currently only one-to-one mapping is supported between sql agg and elastic
+   * aggregation.
+   */
+  private String toElasticAggregate(AggregateCall call) {
+    SqlKind kind = call.getAggregation().getKind();
+    switch (kind) {
+    case COUNT:
+      return call.isApproximate() ? ""cardinality"" : ""value_count"";
+    case SUM:
+      return ""sum"";
+    case MIN:
+      return ""min"";
+    case MAX:
+      return ""max"";
+    case AVG:
+      return ""avg"";
+    default:","[{'comment': 'SUM0 is not going to be supported?', 'commenter': 'hsyuan'}, {'comment': ""Should `SUM0` be identical to `SUM` in ES context ? I didn't see `SUM0` being used except for jdbc adapter.  "", 'commenter': 'asereda-gs'}, {'comment': 'Hi @hsyuan I would like to close all open questions with this PR. Can you please let me know how exactly `SUM0` should be implemented ? ', 'commenter': 'asereda-gs'}, {'comment': '@asereda-gs Sorry for my late response. It is fine to not support SUM0 if SUM0 is identical to SUM in ES context. This question can be closed. Thanks!', 'commenter': 'hsyuan'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchAggregate.java,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.elasticsearch;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.plan.RelOptPlanner;
+import org.apache.calcite.plan.RelTraitSet;
+import org.apache.calcite.rel.InvalidRelException;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Aggregate;
+import org.apache.calcite.rel.core.AggregateCall;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.util.ImmutableBitSet;
+
+import java.util.ArrayList;
+import java.util.EnumSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Set;
+
+/**
+ * Implementation of
+ * {@link org.apache.calcite.rel.core.Aggregate} relational expression
+ * for ElasticSearch.
+ */
+public class ElasticsearchAggregate extends Aggregate implements ElasticsearchRel {
+
+  private static final Set<SqlKind> SUPPORTED_AGGREGATIONS =
+      EnumSet.of(SqlKind.COUNT, SqlKind.MAX, SqlKind.MIN, SqlKind.AVG, SqlKind.SUM);
+
+  /** Creates a GeodeAggregate. */","[{'comment': 'Update this comment.', 'commenter': 'hsyuan'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchAggregate.java,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.elasticsearch;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.plan.RelOptPlanner;
+import org.apache.calcite.plan.RelTraitSet;
+import org.apache.calcite.rel.InvalidRelException;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Aggregate;
+import org.apache.calcite.rel.core.AggregateCall;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.util.ImmutableBitSet;
+
+import java.util.ArrayList;
+import java.util.EnumSet;
+import java.util.List;
+import java.util.Locale;
+import java.util.Set;
+
+/**
+ * Implementation of
+ * {@link org.apache.calcite.rel.core.Aggregate} relational expression
+ * for ElasticSearch.
+ */
+public class ElasticsearchAggregate extends Aggregate implements ElasticsearchRel {
+
+  private static final Set<SqlKind> SUPPORTED_AGGREGATIONS =
+      EnumSet.of(SqlKind.COUNT, SqlKind.MAX, SqlKind.MIN, SqlKind.AVG, SqlKind.SUM);
+
+  /** Creates a GeodeAggregate. */
+  ElasticsearchAggregate(RelOptCluster cluster,
+      RelTraitSet traitSet,
+      RelNode input,
+      boolean indicator,
+      ImmutableBitSet groupSet,
+      List<ImmutableBitSet> groupSets,
+      List<AggregateCall> aggCalls) throws InvalidRelException  {
+    super(cluster, traitSet, input, indicator, groupSet, groupSets, aggCalls);
+
+    if (getConvention() != input.getConvention()) {
+      String message = String.format(Locale.ROOT, ""%s != %s"", getConvention(),
+          input.getConvention());
+      throw new AssertionError(message);
+    }
+
+    assert getConvention() == input.getConvention();
+    assert getConvention() == ElasticsearchRel.CONVENTION;
+    assert this.groupSets.size() == 1 : ""Grouping sets not supported"";
+
+    for (AggregateCall aggCall : aggCalls) {
+      if (aggCall.isDistinct()) {
+        throw new InvalidRelException(""distinct aggregation not supported"");
+      }
+
+      SqlKind kind = aggCall.getAggregation().getKind();
+      if (!SUPPORTED_AGGREGATIONS.contains(kind)) {
+        final String message = String.format(Locale.ROOT,
+            ""Aggregation %s not supported (use one of %s)"", kind, SUPPORTED_AGGREGATIONS);
+        throw new InvalidRelException(message);
+      }
+    }
+
+    if (getGroupType() != Group.SIMPLE) {
+      final String message = String.format(Locale.ROOT, ""Only %s grouping is supported. ""
+              + ""Yours is %s"", Group.SIMPLE, getGroupType());
+      throw new InvalidRelException(message);
+    }
+
+  }
+
+  @Override public Aggregate copy(RelTraitSet traitSet, RelNode input, boolean indicator,
+      ImmutableBitSet groupSet, List<ImmutableBitSet> groupSets,
+      List<AggregateCall> aggCalls) {
+    try {
+      return new ElasticsearchAggregate(getCluster(), traitSet, input,
+          indicator, groupSet, groupSets,
+          aggCalls);
+    } catch (InvalidRelException e) {
+      throw new AssertionError(e);
+    }
+  }
+
+  @Override public RelOptCost computeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {
+    return super.computeSelfCost(planner, mq).multiplyBy(0.1);
+  }
+
+  @Override public void implement(Implementor implementor) {
+    implementor.visitChild(0, getInput());
+    List<String> inputFields = fieldNames(getInput().getRowType());
+
+    if (groupSet.cardinality() == 1) {","[{'comment': 'Why do we need this for single group, better performance? Will L114~L116 do the same work?', 'commenter': 'hsyuan'}, {'comment': 'Will fix that', 'commenter': 'asereda-gs'}]"
822,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTable.java,"@@ -87,37 +126,211 @@ private static ElasticsearchVersion detectVersion(RestClient client, ObjectMappe
     return ElasticsearchVersion.fromString(node.get(""version"").get(""number"").asText());
   }
 
-  @Override protected String scriptedFieldPrefix() {
+  /**
+   * In ES 5.x scripted fields start with {@code params._source.foo} while in ES2.x
+   * {@code _source.foo}. Helper method to build correct query based on runtime version of elastic.
+   * Used to keep backwards compatibility with ES2.
+   *
+   * @see <a href=""https://github.com/elastic/elasticsearch/issues/20068"">_source variable</a>
+   * @see <a href=""https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-scripting-fields.html"">Scripted Fields</a>
+   * @return string to be used for scripted fields
+   */
+  String scriptedFieldPrefix() {
     // ES2 vs ES5 scripted field difference
     return version == ElasticsearchVersion.ES2
         ? ElasticsearchConstants.SOURCE_GROOVY
         : ElasticsearchConstants.SOURCE_PAINLESS;
   }
 
-  @Override protected Enumerable<Object> find(String index, List<String> ops,
-      List<Map.Entry<String, Class>> fields) {
+  /**
+   * Executes a ""find"" operation on the underlying type.
+   *
+   * <p>For example,
+   * <code>client.prepareSearch(index).setTypes(type)
+   * .setSource(""{\""fields\"" : [\""state\""]}"")</code></p>
+   *
+   * @param ops List of operations represented as Json strings.
+   * @param fields List of fields to project; or null to return map
+   * @param sort list of fields to sort and their direction (asc/desc)
+   * @param aggregations aggregation functions
+   * @return Enumerator of results
+   */
+  protected Enumerable<Object> find(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (!aggregations.isEmpty()) {
+      // process aggregations separately
+      return aggregate(ops, fields, sort, groupBy, aggregations, offset, fetch);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
 
-    final String query;
-    if (!ops.isEmpty()) {
-      query = ""{"" + Util.toString(ops, """", "", "", """") + ""}"";
-    } else {
-      query = ""{}"";
+    // manually parse from previously concatenated string
+    query.setAll(
+        (ObjectNode) mapper.readTree(""{""
+            + Util.toString(ops, """", "", "", """") + ""}""));
+
+    if (!sort.isEmpty()) {
+      ArrayNode sortNode = query.withArray(""sort"");
+      sort.forEach(e ->
+          sortNode.add(
+            mapper.createObjectNode().put(e.getKey(), e.getValue().isDescending() ? ""desc"" : ""asc""))
+      );
+    }
+
+    if (offset != null) {
+      query.put(""from"", offset);
+    }
+
+    if (fetch != null) {
+      query.put(""size"", fetch);
     }
 
     try {
-      ElasticsearchSearchResult result = httpRequest(query);
-      final Function1<ElasticsearchSearchResult.SearchHit, Object> getter =
+      ElasticsearchJson.Result search = httpRequest(query);
+      final Function1<ElasticsearchJson.SearchHit, Object> getter =
           ElasticsearchEnumerators.getter(fields);
-      return Linq4j.asEnumerable(result.searchHits().hits()).select(getter);
+      return Linq4j.asEnumerable(search.searchHits().hits()).select(getter);
     } catch (IOException e) {
       throw new UncheckedIOException(e);
     }
   }
 
-  private ElasticsearchSearchResult httpRequest(String query) throws IOException {
+  private Enumerable<Object> aggregate(List<String> ops,
+      List<Map.Entry<String, Class>> fields,
+      List<Map.Entry<String, RelFieldCollation.Direction>> sort,
+      List<String> groupBy,
+      List<Map.Entry<String, String>> aggregations,
+      Long offset, Long fetch) throws IOException {
+
+    if (aggregations.isEmpty()) {
+      throw new IllegalArgumentException(""Missing Aggregations"");
+    }
+
+    if (!groupBy.isEmpty() && offset != null) {
+      String message = ""Currently ES doesn't support generic pagination ""
+          + ""with aggregations. You can still use LIMIT keyword (without OFFSET). ""
+          + ""For more details see https://github.com/elastic/elasticsearch/issues/4915"";
+      throw new IllegalStateException(message);
+    }
+
+    final ObjectNode query = mapper.createObjectNode();
+
+    // manually parse into JSON from previously concatenated strings
+    query.setAll((ObjectNode) mapper.readTree(""{"" + Util.toString(ops, """", "", "", """") + ""}""));
+
+    // remove / override attributes which are not applicable to aggregations
+    query.put(""_source"", false);
+    query.put(""size"", 0);
+    query.remove(""script_fields"");
+
+    // allows to detect aggregation for count(*)
+    final Predicate<Map.Entry<String, String>> isCountStar = e -> e.getValue()
+            .contains(""\"""" + ElasticsearchConstants.ID + ""\"""");
+
+    // list of expressions which are count(*)
+    final Set<String> countAll = aggregations.stream()
+            .filter(isCountStar)
+        .map(Map.Entry::getKey).collect(Collectors.toSet());
+
+    final Map<String, String> fieldMap = new HashMap<>();
+
+    // due to ES aggregation format. fields in ""order by"" clause should go first
+    // if ""order by"" is missing. order in ""group by"" is un-important
+    final Set<String> orderedGroupBy = new LinkedHashSet<>();
+    orderedGroupBy.addAll(sort.stream().map(Map.Entry::getKey).collect(Collectors.toList()));
+    orderedGroupBy.addAll(groupBy);
+
+    // construct nested aggregations node(s)
+    ObjectNode parent = query.with(AGGREGATIONS);
+    for (String name: orderedGroupBy) {
+      final String aggName = ""g_"" + name;
+      fieldMap.put(aggName, name);
+
+      final ObjectNode section = parent.with(aggName);
+      final ObjectNode terms = section.with(""terms"");
+      terms.put(""field"", name);
+      terms.set(""missing"", ElasticsearchJson.MISSING_VALUE); // expose missing terms
+
+      if (fetch != null) {
+        terms.put(""size"", fetch);
+      }
+
+      sort.stream().filter(e -> e.getKey().equals(name)).findAny().ifPresent(s -> {
+        terms.with(""order"").put(""_key"", s.getValue().isDescending() ? ""desc"" : ""asc"");
+      });
+
+      parent = section.with(AGGREGATIONS);
+    }
+
+    // simple version for queries like ""select count(*), max(col1) from table"" (without GROUP BY)
+    if (!aggregations.stream().allMatch(isCountStar) || !groupBy.isEmpty()) {","[{'comment': 'The change of the order of disjuncts was intentional to avoid the rather costly stream operation if there is a group by. Please swap the two disjuncts.', 'commenter': 'beikov'}, {'comment': 'OK. Now I see what you mean. Fixed', 'commenter': 'asereda-gs'}]"
828,core/src/main/java/org/apache/calcite/rex/RexInterpreter.java,"@@ -175,6 +175,14 @@ public Comparable visitCall(RexCall call) {
       return ceil(call, values);
     case EXTRACT:
       return extract(call, values);
+    case IS_DISTINCT_FROM:","[{'comment': 'Please merge that `case` branches with relevant `EQUALS` and `NOT_EQUALS` via `// fall through`', 'commenter': 'vlsi'}, {'comment': 'Done. Thanks for the quick response.', 'commenter': 'hsyuan'}]"
828,core/src/main/java/org/apache/calcite/rex/RexInterpreter.java,"@@ -175,6 +175,14 @@ public Comparable visitCall(RexCall call) {
       return ceil(call, values);
     case EXTRACT:
       return extract(call, values);
+    case IS_DISTINCT_FROM:
+      return containsNull(values)
+          ? (!values.get(0).equals(N) || !values.get(1).equals(N))","[{'comment': 'Please just use `equals` between 0 and 1 argument', 'commenter': 'vlsi'}]"
828,core/src/main/java/org/apache/calcite/rex/RexInterpreter.java,"@@ -175,6 +175,14 @@ public Comparable visitCall(RexCall call) {
       return ceil(call, values);
     case EXTRACT:
       return extract(call, values);
+    case IS_DISTINCT_FROM:
+      return containsNull(values)
+          ? (!values.get(0).equals(N) || !values.get(1).equals(N))
+          : compare(values, c -> c != 0);
+    case IS_NOT_DISTINCT_FROM:
+      return containsNull(values)
+          ? (values.get(0).equals(N) && values.get(1).equals(N))","[{'comment': 'Please just use equals between 0 and 1 argument', 'commenter': 'vlsi'}]"
878,core/src/main/java/org/apache/calcite/adapter/jdbc/JdbcRules.java,"@@ -946,6 +957,26 @@ public boolean containsUserDefinedFunction() {
     }
 
   }
+  /**
+   * Visitor for checking whether part of filter contains dynamic param
+   */
+  private static class CheckingDynamicParamVisitor extends RexVisitorImpl<Void> {
+
+    private boolean containsDynamicParam = false;
+
+    CheckingDynamicParamVisitor() {
+      super(true);
+    }
+
+    public boolean containsDynamicParam() {
+      return containsDynamicParam;
+    }
+
+    @Override public Void visitDynamicParam(RexDynamicParam dynamicParam) {
+      containsDynamicParam |= true;","[{'comment': ""Is this intentional? You are forcing the value to 'true'\r\nMaybe a simple assignment is clearer"", 'commenter': 'eolivelli'}, {'comment': 'It is not intentional - I can simplify this.', 'commenter': 'ptrbojko'}]"
878,core/src/main/java/org/apache/calcite/prepare/CalcitePrepareImpl.java,"@@ -943,7 +943,7 @@ private int getTypeOrdinal(RelDataType type) {
   }
 
   private static String getClassName(RelDataType type) {
-    return null;
+    return Object.class.getName();","[{'comment': 'Can we add a comment to explain this behavior?', 'commenter': 'eolivelli'}, {'comment': 'Will do', 'commenter': 'ptrbojko'}]"
878,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -6574,14 +6574,82 @@ public void testGetDate() throws Exception {
 
       rs.close();
 
-      final String sql = ""update t2 set vals=? where id=?"";","[{'comment': ""Why are you dropping this case?\r\nI remember I recently (calcite 1.15) fixed a problem with jsbc params and UPDATE.\r\n\r\nCan't we keep this test and add a new one"", 'commenter': 'eolivelli'}, {'comment': ""I am considering this a main issue of change. Before the patch former update query was planned in underlying jdbc schema as a subquery. After the patch - such query is not pushed to underying jdbc through jdbcrules logic, but stays in calcite. Calcite itself does not implement in a planner UDPATES - so it throws exception. \r\n\r\nI believe this part of a test was a little hack'y - it relied on the invalid behaviour of calcite planner."", 'commenter': 'ptrbojko'}, {'comment': 'From the change it seems to me that we are losing one of the most common cases, that is an UPDATE by PRIMARY KEY.\r\nMaybe I am missing something.\r\n\r\nAnyway it would be better to add an explicit testcase which tells what it is expected to happen with the query you dropped from the test case.\r\nWDYT?', 'commenter': 'eolivelli'}, {'comment': 'I will try to look at this next week. Maybe rewrite the mentioned test not to use the Connection.prepareStatement but some internals.', 'commenter': 'ptrbojko'}, {'comment': ""@eolivelli  I've recreated the test case. But now rather based on PreparedStatement it uses directly planner and traversing through Rel nodes. \r\n\r\nThe former test worked by hack - it was relying on that the whole query was pushed to jdbc schema, thus omitting the ling4j implementation. \r\n\r\nWhen PreparedStatement is being prepared - whole query is compiled and update clause is not supported. So the former test worked only because update was pushed to jdbc subschema. \r\n\r\nCurrent tests - checks the same query as former and validates whether dynamic parameters exists and are specified. But it uses for that traversing through rel nodes directly.\r\n\r\nI hope this clarifies the thing.\r\n "", 'commenter': 'ptrbojko'}]"
878,core/src/main/java/org/apache/calcite/prepare/CalcitePrepareImpl.java,"@@ -943,7 +943,8 @@ private int getTypeOrdinal(RelDataType type) {
   }
 
   private static String getClassName(RelDataType type) {
-    return null;
+    // AvaticaParameter requires className field to be not null, see CALCITE-2613
+    return Object.class.getName();","[{'comment': 'Is there a method on RelDataType which we could use already to determine the appropriate `Class`? If not, do you think it makes sense to introduce that to the `RelDataType` interface?', 'commenter': 'joshelser'}, {'comment': 'There is no mapping from SQL types to Java types now. Having it (maybe on RelDataType level, maybe simple static mapping somewhere close to SqlTypeName) could be a good thing but I think that Calcite use cases for that narrows only to satisfy exposing through avatica.  Although this propably will change and then some can think how to implement the mapping.', 'commenter': 'ptrbojko'}]"
878,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -6574,14 +6574,82 @@ public void testGetDate() throws Exception {
 
       rs.close();
 
-      final String sql = ""update t2 set vals=? where id=?"";
+      final String sql = ""update t2 set vals=? where id=1"";
       try (PreparedStatement ps =
                calciteConnection.prepareStatement(sql)) {
         ParameterMetaData pmd = ps.getParameterMetaData();
-        assertThat(pmd.getParameterCount(), is(2));
+        assertThat(pmd.getParameterCount(), is(1));
         assertThat(pmd.getParameterType(1), is(Types.DOUBLE));
-        assertThat(pmd.getParameterType(2), is(Types.INTEGER));
-        ps.close();
+      }
+      calciteConnection.close();
+    }
+  }
+
+  /**
+   * Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2609"">[CALCITE-2609]
+   * Dynamic parameters ? pushed to underlying jdbc schema causing error </a>.
+   */
+  @Test public void testQueryWithParameter() throws Exception {","[{'comment': 'Nice test :)', 'commenter': 'joshelser'}, {'comment': 'Bug reproduction :)', 'commenter': 'ptrbojko'}]"
878,plus/pom.xml,"@@ -55,6 +55,14 @@ limitations under the License.
       <groupId>org.apache.calcite.avatica</groupId>
       <artifactId>avatica-core</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.apache.calcite.avatica</groupId>
+      <artifactId>avatica-server</artifactId>
+    </dependency>
+    <dependency>
+      <groupId>org.eclipse.jetty</groupId>
+      <artifactId>jetty-server</artifactId>","[{'comment': ""I'm not seeing any explicit additions of jetty-server classes to `plus/src` as a part of this changeset. Why did you add `jetty-server` here?"", 'commenter': 'joshelser'}, {'comment': 'This is for satisfying the maven checks. Avatica server indirectly imports this, so the checker fails with indirect dependency.', 'commenter': 'ptrbojko'}, {'comment': ""The point of transitive dependencies is that they come in automatically. You should not add them as a dependency unless you are using classes from them which I don't see added by this PR. What is the error you're seeing without this?"", 'commenter': 'joshelser'}, {'comment': '> [INFO] --- maven-dependency-plugin:3.1.1:analyze-only (analyze) @ calcite-plus ---\r\n[WARNING] Used undeclared dependencies found:\r\n[WARNING]    org.eclipse.jetty:jetty-server:jar:9.2.19.v20160908:compile', 'commenter': 'ptrbojko'}]"
878,plus/src/main/java/org/apache/calcite/chinook/ChinookAvaticaServer.java,"@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.chinook;
+
+import org.apache.calcite.avatica.Meta;
+import org.apache.calcite.avatica.jdbc.JdbcMeta;
+import org.apache.calcite.avatica.remote.Driver;
+import org.apache.calcite.avatica.remote.Service;
+import org.apache.calcite.avatica.server.AvaticaProtobufHandler;
+import org.apache.calcite.avatica.server.HttpServer;
+import org.apache.calcite.avatica.server.Main;
+
+import net.hydromatic.chinook.data.hsqldb.ChinookHsqldb;
+
+import java.io.IOException;
+import java.sql.SQLException;
+import java.util.List;
+
+/**
+ * Wrapping Calcite engine with Avatica tansport for testing JDBC capabilities between
+ * Avatica JDBC transport and Calcite
+ */
+public class ChinookAvaticaServer {","[{'comment': 'Nice!', 'commenter': 'joshelser'}]"
883,core/src/main/java/org/apache/calcite/util/NlsString.java,"@@ -88,6 +91,25 @@ public NlsString(
     this.value = value;
   }
 
+  /**
+   * Creates a string in a specified character set.
+   *
+   * @param value       String constant, must not be null
+   * @param charsetName Name of the character set, may be null
+   * @param collation   Collation, may be null
+   * @throws IllegalCharsetNameException If the given charset name is illegal
+   * @throws UnsupportedCharsetException If no support for the named charset
+   *     is available in this instance of the Java virtual machine
+   * @throws RuntimeException If the given value cannot be represented in the
+   *     given charset
+   */
+  public NlsString(","[{'comment': 'what does NlsString mean ?', 'commenter': 'zinking'}]"
883,core/src/main/java/org/apache/calcite/util/NlsString.java,"@@ -61,7 +62,8 @@
   public NlsString(
       String value,
       String charsetName,
-      SqlCollation collation) {
+      SqlCollation collation,
+      boolean unsafe) {","[{'comment': 'This new constructor seems not used, just by looking at the diff', 'commenter': 'eolivelli'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -77,10 +83,19 @@ protected JoinToCorrelateRule(RelFactories.FilterFactory filterFactory) {
     this(RelBuilder.proto(Contexts.of(filterFactory)));
   }
 
+  /**
+   * Creates a JoinToCorrelateRule for a certain sub-class of
+   * {@link org.apache.calcite.rel.core.Join}
+   */
+  public JoinToCorrelateRule(Class<? extends Join> clazz,","[{'comment': ""If we can treat any kind of join with this rule then we shouldn't have to perform casts afterwards. I am OK with adding such a constructor if we can achieve that. "", 'commenter': 'zabetak'}, {'comment': 'I think we should be a bit conservative regarding the public API. The goal of this PR is to allow semi joins to be transformed to correlates. This can be also achieved by keeping this constructor private so I would propose to reduce its visibility.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/SemiJoinToCorrelateRule.java,"@@ -0,0 +1,44 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.rel.core.RelFactories;
+import org.apache.calcite.rel.core.SemiJoin;
+import org.apache.calcite.tools.RelBuilderFactory;
+
+/**
+ * Rule that converts a {@link org.apache.calcite.rel.core.SemiJoin}
+ * into a {@link org.apache.calcite.rel.logical.LogicalCorrelate}, which can
+ * then be implemented using nested loops.
+ */
+public class SemiJoinToCorrelateRule extends JoinToCorrelateRule {","[{'comment': 'The way is the code right now there is no reason to add a new subclass. You could put the singleton instance directly in the superclass.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -127,7 +142,7 @@ public void onMatch(RelOptRuleCall call) {
             relBuilder.build(),
             correlationId,
             requiredColumns.build(),
-            SemiJoinType.of(join.getJoinType()));
+            join instanceof SemiJoin ? SemiJoinType.SEMI : SemiJoinType.of(join.getJoinType()));","[{'comment': 'Maybe we could avoid this cast by introducing a more general method in Join which can bring back all the necessary types (SEMI, ANTI, etc.).', 'commenter': 'zabetak'}, {'comment': 'What about a semiJoinTypeFunction lambda? New version committed with this approach', 'commenter': 'rubenada'}, {'comment': ""I didn't have a function in mind but it can do the job. \r\n\r\n@julianhyde, I've seen that you had some concerns against a lamda function in the Jira issue so I am waiting for your input. From my perspective, if we keep this function and its configuration private I don't see a real problem."", 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of
+ * {@link org.apache.calcite.rel.core.Join}, not just
+ * {@link org.apache.calcite.rel.logical.LogicalJoin}.</p>
  */
 public class JoinToCorrelateRule extends RelOptRule {
+
+  private final Function<Join, SemiJoinType> semiJoinTypeFunction;
+
   //~ Static fields/initializers ---------------------------------------------
 
   public static final JoinToCorrelateRule INSTANCE =
       new JoinToCorrelateRule(RelFactories.LOGICAL_BUILDER);
 
+  /**
+   * Rule that converts a {@link org.apache.calcite.rel.core.SemiJoin}
+   * into a {@link org.apache.calcite.rel.logical.LogicalCorrelate}
+   */
+  public static final JoinToCorrelateRule SEMI =
+      new JoinToCorrelateRule(SemiJoin.class,
+              RelFactories.LOGICAL_BUILDER, join -> SemiJoinType.SEMI);
+
   //~ Constructors -----------------------------------------------------------
 
   /**
    * Creates a JoinToCorrelateRule.
    */
   public JoinToCorrelateRule(RelBuilderFactory relBuilderFactory) {
-    super(operand(LogicalJoin.class, any()), relBuilderFactory, null);
+    this(LogicalJoin.class, relBuilderFactory, join -> SemiJoinType.of(join.getJoinType()));
   }
 
   @Deprecated // to be removed before 2.0
   protected JoinToCorrelateRule(RelFactories.FilterFactory filterFactory) {
     this(RelBuilder.proto(Contexts.of(filterFactory)));
   }
 
+  /**
+   * Creates a JoinToCorrelateRule for a certain sub-class of
+   * {@link org.apache.calcite.rel.core.Join}
+   */
+  public JoinToCorrelateRule(Class<? extends Join> clazz,
+                             RelBuilderFactory relBuilderFactory,
+                             Function<Join, SemiJoinType> semiJoinTypeFunction) {","[{'comment': '(Minor suggestion) Maybe rename the `semiJoinTypeFunction` to something better illustrating what does it do. Something like `semiJoinTypeExtractor`, `semiJoinTypeMapper`, etc.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of
+ * {@link org.apache.calcite.rel.core.Join}, not just
+ * {@link org.apache.calcite.rel.logical.LogicalJoin}.</p>
  */
 public class JoinToCorrelateRule extends RelOptRule {
+
+  private final Function<Join, SemiJoinType> semiJoinTypeFunction;
+
   //~ Static fields/initializers ---------------------------------------------
 
   public static final JoinToCorrelateRule INSTANCE =
       new JoinToCorrelateRule(RelFactories.LOGICAL_BUILDER);
 
+  /**
+   * Rule that converts a {@link org.apache.calcite.rel.core.SemiJoin}
+   * into a {@link org.apache.calcite.rel.logical.LogicalCorrelate}
+   */
+  public static final JoinToCorrelateRule SEMI =
+      new JoinToCorrelateRule(SemiJoin.class,
+              RelFactories.LOGICAL_BUILDER, join -> SemiJoinType.SEMI);
+
   //~ Constructors -----------------------------------------------------------
 
   /**
    * Creates a JoinToCorrelateRule.
    */
   public JoinToCorrelateRule(RelBuilderFactory relBuilderFactory) {
-    super(operand(LogicalJoin.class, any()), relBuilderFactory, null);
+    this(LogicalJoin.class, relBuilderFactory, join -> SemiJoinType.of(join.getJoinType()));
   }
 
   @Deprecated // to be removed before 2.0
   protected JoinToCorrelateRule(RelFactories.FilterFactory filterFactory) {
     this(RelBuilder.proto(Contexts.of(filterFactory)));
   }
 
+  /**
+   * Creates a JoinToCorrelateRule for a certain sub-class of
+   * {@link org.apache.calcite.rel.core.Join}
+   */
+  public JoinToCorrelateRule(Class<? extends Join> clazz,
+                             RelBuilderFactory relBuilderFactory,
+                             Function<Join, SemiJoinType> semiJoinTypeFunction) {
+    super(operand(clazz, any()), relBuilderFactory, null);","[{'comment': 'Leaving the description parameter as null is not a good idea. The rules used by the planner need to have a unique description. INSTANCE and SEMI above will end up with the description which means that they cannot be used together in the same planner.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of
+ * {@link org.apache.calcite.rel.core.Join}, not just
+ * {@link org.apache.calcite.rel.logical.LogicalJoin}.</p>
  */
 public class JoinToCorrelateRule extends RelOptRule {
+
+  private final Function<Join, SemiJoinType> semiJoinTypeFunction;
+
   //~ Static fields/initializers ---------------------------------------------
 
   public static final JoinToCorrelateRule INSTANCE =","[{'comment': 'Now that the class has more static fields INSTANCE is no longer a good name.', 'commenter': 'zabetak'}, {'comment': 'Renamed as JOIN', 'commenter': 'rubenada'}, {'comment': ""I am afraid I was bit hasty, sorry for that. In order not too break backward compatibility let's also keep INSTANCE and mark it as deprecated with a pointer to JOIN. "", 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -35,6 +37,8 @@
 import org.apache.calcite.util.ImmutableBitSet;
 import org.apache.calcite.util.Util;
 
+import java.util.function.Function;
+
 /**
  * Rule that converts a {@link org.apache.calcite.rel.logical.LogicalJoin}","[{'comment': 'I think the javadoc here should not explicitly refer to LogicalJoin and LogicalCorrelate. This part should be moved directly above the INSTANCE field.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of","[{'comment': 'Since the parameterized constructor is going to be private we should not put this part of documentation here.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of
+ * {@link org.apache.calcite.rel.core.Join}, not just
+ * {@link org.apache.calcite.rel.logical.LogicalJoin}.</p>
  */
 public class JoinToCorrelateRule extends RelOptRule {
+","[{'comment': 'Please add a small javadoc to explain the purpose of this function.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of
+ * {@link org.apache.calcite.rel.core.Join}, not just
+ * {@link org.apache.calcite.rel.logical.LogicalJoin}.</p>
  */
 public class JoinToCorrelateRule extends RelOptRule {
+
+  private final Function<Join, SemiJoinType> semiJoinTypeFunction;
+
   //~ Static fields/initializers ---------------------------------------------
 
   public static final JoinToCorrelateRule INSTANCE =
       new JoinToCorrelateRule(RelFactories.LOGICAL_BUILDER);
 
+  /**
+   * Rule that converts a {@link org.apache.calcite.rel.core.SemiJoin}
+   * into a {@link org.apache.calcite.rel.logical.LogicalCorrelate}
+   */
+  public static final JoinToCorrelateRule SEMI =
+      new JoinToCorrelateRule(SemiJoin.class,
+              RelFactories.LOGICAL_BUILDER, join -> SemiJoinType.SEMI);
+
   //~ Constructors -----------------------------------------------------------
 
   /**
    * Creates a JoinToCorrelateRule.","[{'comment': 'Please, update the javadoc to indicate that it concerns a logical join.', 'commenter': 'zabetak'}]"
884,core/src/main/java/org/apache/calcite/rel/rules/JoinToCorrelateRule.java,"@@ -56,31 +60,57 @@
  *
  * <p>would require emitting a NULL emp row if a certain department contained no
  * employees, and Correlator cannot do that.</p>
+ *
+ * <p>There is a constructor parameterized to allow any sub-class of
+ * {@link org.apache.calcite.rel.core.Join}, not just
+ * {@link org.apache.calcite.rel.logical.LogicalJoin}.</p>
  */
 public class JoinToCorrelateRule extends RelOptRule {
+
+  private final Function<Join, SemiJoinType> semiJoinTypeFunction;
+
   //~ Static fields/initializers ---------------------------------------------
 
   public static final JoinToCorrelateRule INSTANCE =
       new JoinToCorrelateRule(RelFactories.LOGICAL_BUILDER);
 
+  /**
+   * Rule that converts a {@link org.apache.calcite.rel.core.SemiJoin}
+   * into a {@link org.apache.calcite.rel.logical.LogicalCorrelate}
+   */
+  public static final JoinToCorrelateRule SEMI =
+      new JoinToCorrelateRule(SemiJoin.class,
+              RelFactories.LOGICAL_BUILDER, join -> SemiJoinType.SEMI);
+
   //~ Constructors -----------------------------------------------------------
 
   /**
    * Creates a JoinToCorrelateRule.
    */
   public JoinToCorrelateRule(RelBuilderFactory relBuilderFactory) {
-    super(operand(LogicalJoin.class, any()), relBuilderFactory, null);
+    this(LogicalJoin.class, relBuilderFactory, join -> SemiJoinType.of(join.getJoinType()));
   }
 
   @Deprecated // to be removed before 2.0
   protected JoinToCorrelateRule(RelFactories.FilterFactory filterFactory) {
     this(RelBuilder.proto(Contexts.of(filterFactory)));
   }
 
+  /**
+   * Creates a JoinToCorrelateRule for a certain sub-class of
+   * {@link org.apache.calcite.rel.core.Join}","[{'comment': 'Please, add a few lines explaining how the three parameters play together. Even if the constructor becomes private, I think it is worth mentioning.', 'commenter': 'zabetak'}]"
884,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableCorrelateTest.java,"@@ -77,6 +77,32 @@
             ""empid=150; name=Sebastian"");
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2621"">[CALCITE-2621]
+   * New rule: SemiJoinToCorrelateRule (SemiJoin => LogicalCorrelate)</a> */","[{'comment': 'Adapt comment based on new title.', 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/rel/type/RelRecordType.java,"@@ -53,7 +53,13 @@ public RelRecordType(List<RelDataTypeField> fields) {
   }
 
   @Override public boolean isNullable() {
-    return false;
+    // [CALCITE-2464] RelRecordType nullable if all its fields are nullable
+    for (RelDataTypeField field : getFieldList()) {","[{'comment': 'According to the SQL standard nullability of structured fileds does not depend on the field but can be set independently. Thus instead of checking the fields of the RelRecordType, I would add a new attribute in the class that can be set appropriately.', 'commenter': 'zabetak'}]"
898,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -5698,7 +5698,7 @@ private void checkNegWindow(String s, String msg) {
             + "" INTEGER DEPTNO,""
             + "" BOOLEAN SLACKER,""
             + "" INTEGER DEPTNO0,""
-            + "" VARCHAR(10) NAME) NOT NULL"");
+            + "" VARCHAR(10) NAME)"");","[{'comment': 'I think that a structured type representing the result of a query does not make sense to be nullable (and cannot really be). I guess this change came from the fact that all returned fields are nullable. Maybe by introducing a separate field solves this problem. Same remark for the tests below.', 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -270,12 +278,6 @@ private RelDataType copyRecordType(
       final RelRecordType type,
       final boolean ignoreNullable,
       final boolean nullable) {
-    // REVIEW: angel 18-Aug-2005 dtbug336
-    // Shouldn't null refer to the nullability of the record type
-    // not the individual field types?
-    // For flattening and outer joins, it is desirable to change","[{'comment': 'The code part below can still changes the nullability of individual fields so I would suggest to keep lines 276, 277.', 'commenter': 'zabetak'}, {'comment': 'Agree, I will put back lines 276, 277', 'commenter': 'rubenada'}]"
898,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -658,23 +657,26 @@ public SqlTypeName getSqlTypeName() {
     private final StructKind kind;
     private final List<String> names;
     private final List<RelDataType> types;
+    private final boolean nullable;","[{'comment': ""Before introducing this change the cache didn't distinguish between nullable and not nullable types. Was it a bug or there was another reason behind it?"", 'commenter': 'zabetak'}, {'comment': 'It was not a bug, it was just that this Key was used to create a RelRecordType (see line 73), and before this change the RelRecordType did not have a nullable instance variable, so there was no need to have a nullable in this Key', 'commenter': 'rubenada'}, {'comment': 'OK, I see, thanks for the explanation!', 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/rel/type/RelRecordType.java,"@@ -29,19 +29,29 @@
 public class RelRecordType extends RelDataTypeImpl implements Serializable {
   /** Name resolution policy; usually {@link StructKind#FULLY_QUALIFIED}. */
   private final StructKind kind;
+  private final boolean nullable;
 
   //~ Constructors -----------------------------------------------------------
 
   /**
    * Creates a <code>RecordType</code>. This should only be called from a
    * factory method.
    */
-  public RelRecordType(StructKind kind, List<RelDataTypeField> fields) {
+  public RelRecordType(StructKind kind, List<RelDataTypeField> fields, boolean nullable) {","[{'comment': 'Minor: maybe it would be better to add the new constructor after the old one. Usually the telescoping constructor pattern puts constructor in increasing argument order.', 'commenter': 'zabetak'}, {'comment': 'I agree with your logic, but I just kept the existing one: the class already defined the 2-parameter constructor before the 1-parameter constructor, so I just added the 3-parameter one before both of them. I could re-arrange the constructors into an increasing argument order, though.', 'commenter': 'rubenada'}, {'comment': ""No don't bother, I didn't see that there were already two constructors. Maybe just add a bit of Javadoc. "", 'commenter': 'zabetak'}]"
898,core/src/test/java/org/apache/calcite/rel/type/RelDataTypeFactoryImplTest.java,"@@ -0,0 +1,53 @@
+/*","[{'comment': 'The new test cannot fit under SqlTypeFactoryTest?\r\nCan you add also a test in JdbcTest or ReflectiveSchemaTest (or somewhere else) involving IS NULL on structured types which fails without this fix?', 'commenter': 'zabetak'}, {'comment': 'Tests refactored', 'commenter': 'rubenada'}]"
898,server/src/main/java/org/apache/calcite/sql/ddl/SqlCreateTable.java,"@@ -176,6 +176,9 @@ public void execute(CalcitePrepare.Context context) {
             type = typeEntry.getType().apply(typeFactory);
           }
         }
+        if (type != null && !type.isNullable() && d.strategy == ColumnStrategy.NULLABLE) {","[{'comment': '@rubenada I have a few concerns with the following lines.\r\n\r\nFirst of all, is it possible to arrive here with a type==null? I guess not so I think the first condition can go away and possibly add an assertion. \r\n\r\nSecond the nullability of simple types is already set in d.dataType.deriveType (a few lines above). I can see that the code there does not handle at all struct types since this is done by TypeEntry. I am wondering why it is done like that but maybe the best person to answer this would be @suez1224 .\r\n\r\nThird, I see that for simple types the nullability information is set by considering first SqlDataTypeSpec.nullable field and then the boolean parameter passed in the method deriveType. ColumnStrategy is not used for this purpose so I am wondering if it is correct to set the nullability based on this.\r\n\r\nFinally, I am thinking that if deriveType cannot handle struct types then maybe the nullability info (for structs) should be set in typeEntry.getType().apply(typeFactory).', 'commenter': 'zabetak'}, {'comment': '@zabetak I agree this is not the cleanest way to get nullable struct types, but as you say, at the point when the struct type is created, the nullability info does not get propagated. So, I think this is the simplest solution, because it does not require any side changes.\r\nI have committed a new version that relies on `d.dataType.nullable` instead of `d.strategy` to set the correct nullability. Let me know what you think.', 'commenter': 'rubenada'}, {'comment': ""I don't see a better option at the moment so I agree with you. "", 'commenter': 'zabetak'}]"
898,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -4679,6 +4679,21 @@ public boolean moveNext() {
             ""deptno=null; deptno=40"");
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2464"">[CALCITE-2464]
+   * Struct types are always not nullable</a>. */","[{'comment': 'The title of the ticket has changed.', 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -317,16 +320,12 @@ public RelDataType createTypeWithNullability(
     } else if (type instanceof RelRecordType) {
       // REVIEW: angel 18-Aug-2005 dtbug 336 workaround
       // Changed to ignore nullable parameter if nullable is false since
-      // copyRecordType implementation is doubtful
-      if (nullable) {
-        // Do a deep copy, setting all fields of the record type
-        // to be nullable regardless of initial nullability
-        newType = copyRecordType((RelRecordType) type, false, true);
-      } else {
-        // Keep same type as before, ignore nullable parameter
-        // RelRecordType currently always returns a nullability of false
-        newType = copyRecordType((RelRecordType) type, true, false);
-      }
+      // copyRecordType implementation is doubtful:
+      // If nullable -> Do a deep copy, setting all fields of the record type
+      // to be nullable regardless of initial nullability
+      // If not nullable -> set not nullable at top RelRecordType level only,","[{'comment': 'According to the SQL standard nullability for struct types can be defined only for **columns** which translates to top level structs. Nested struct attributes are always nullable, so in principle we could always set the nested attributes to be nullable. However, this might create regressions so we could skip this for now. Should we at least update a bit the comment?', 'commenter': 'zabetak'}, {'comment': 'Comment updated', 'commenter': 'rubenada'}]"
898,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -244,10 +244,11 @@ public RelDataType toSql(RelDataType type) {
   public static RelDataType toSql(final RelDataTypeFactory typeFactory,
       RelDataType type) {
     if (type instanceof RelRecordType) {
-      return typeFactory.createStructType(
-          Lists.transform(type.getFieldList(),
-              field -> toSql(typeFactory, field.getType())),
-          type.getFieldNames());
+      return typeFactory.createTypeWithNullability(","[{'comment': 'How many times are we going to visit each field? I have the impression that this recursion will visit attributes multiple times for no reason but maybe I am wrong.', 'commenter': 'zabetak'}, {'comment': 'Another possibility will be avoiding the `createTypeWithNullability` call and create the struct type directly with the appropriate nullability via the typeFactory:\r\n```\r\ntypeFactory.createStructType(\r\n    StructKind.FULLY_QUALIFIED,\r\n    Lists.transform(type.getFieldList(), field -> toSql(typeFactory, field.getType())),\r\n    type.getFieldNames(),\r\n    type.isNullable());\r\n```\r\nThis is totally possible, but it would require to add a new method to RelDataTypeFactory interface:\r\n```\r\nprivate RelDataType createStructType(\r\n      final StructKind kind,\r\n      final List<RelDataType> typeList,\r\n      final List<String> fieldNameList,\r\n      final boolean nullable)\r\n```\r\nThis method is already defined (though for the moment as `private`) in RelDataTypeFactoryImpl.', 'commenter': 'rubenada'}, {'comment': 'Since for the moment there is no other createType method who takes nullability as a parameter I would say not to add a new one in the public API. On the other hand maybe we can avoid the problem of multiple traversals by adding a new \r\n`private static RelDataType toSql(final RelDataTypeFactory typeFactory, RelDataType type, boolean changeNullability) `\r\nwith which we can control when we have to change nullability. In any case only the top-level nullability is important for structs since the nullability of nested fields can be erased by the current code in createTypeWithNullability.\r\n\r\nWhat do you think?\r\n', 'commenter': 'zabetak'}, {'comment': 'Ok, modified with new private method to change nullability only at ""root"" level.', 'commenter': 'rubenada'}]"
898,core/src/test/java/org/apache/calcite/sql/type/SqlTypeFactoryTest.java,"@@ -112,6 +121,26 @@ private void checkPrecision(int p0, int p1, int expectedMax,
     assertThat(SqlTypeUtil.comparePrecision(p1, p1), is(0));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2464"">[CALCITE-2464]
+   * Allow to set nullability for columns of structured types</a>. */
+  @Test
+  public void createTypeWithNullability() {","[{'comment': ""Shouldn't the name of the test reflect the fact that it only tests stuctured types?"", 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -243,11 +243,24 @@ public RelDataType toSql(RelDataType type) {
   /** Converts a type in Java format to a SQL-oriented type. */
   public static RelDataType toSql(final RelDataTypeFactory typeFactory,
       RelDataType type) {
+    return toSql(typeFactory, type, true);
+  }
+
+  private static RelDataType toSql(final RelDataTypeFactory typeFactory,
+      RelDataType type, boolean isRootType) {","[{'comment': 'I would rename `isRootType` to `mustConsiderNullability` or `mustSetNullability` or something similar.', 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -243,11 +243,24 @@ public RelDataType toSql(RelDataType type) {
   /** Converts a type in Java format to a SQL-oriented type. */
   public static RelDataType toSql(final RelDataTypeFactory typeFactory,
       RelDataType type) {
+    return toSql(typeFactory, type, true);
+  }
+
+  private static RelDataType toSql(final RelDataTypeFactory typeFactory,
+      RelDataType type, boolean isRootType) {
     if (type instanceof RelRecordType) {
-      return typeFactory.createStructType(
-          Lists.transform(type.getFieldList(),
-              field -> toSql(typeFactory, field.getType())),
-          type.getFieldNames());
+      RelDataType structType = typeFactory.createStructType(
+              Lists.transform(type.getFieldList(),
+                field -> toSql(typeFactory, field.getType(), false)),
+              type.getFieldNames());
+
+      // struct types are created by default with nullability false, so if we are dealing","[{'comment': 'I would move the comment before line 252 and explain why we do not want to change the nullability of nested fields.', 'commenter': 'zabetak'}]"
898,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -243,11 +243,24 @@ public RelDataType toSql(RelDataType type) {
   /** Converts a type in Java format to a SQL-oriented type. */
   public static RelDataType toSql(final RelDataTypeFactory typeFactory,
       RelDataType type) {
+    return toSql(typeFactory, type, true);
+  }
+
+  private static RelDataType toSql(final RelDataTypeFactory typeFactory,
+      RelDataType type, boolean isRootType) {
     if (type instanceof RelRecordType) {
-      return typeFactory.createStructType(
-          Lists.transform(type.getFieldList(),
-              field -> toSql(typeFactory, field.getType())),
-          type.getFieldNames());
+      RelDataType structType = typeFactory.createStructType(
+              Lists.transform(type.getFieldList(),
+                field -> toSql(typeFactory, field.getType(), false)),
+              type.getFieldNames());
+
+      // struct types are created by default with nullability false, so if we are dealing
+      // with the ""root"" type and it should be nullable, change its nullability
+      if (isRootType && type.isNullable()) {","[{'comment': 'I would move this if at the end of the method and unify setting the nullability for struct and java types. Checking if the type is nullable is not necessary since the control is already incorporated inside `createTypeWithNullability` method.', 'commenter': 'zabetak'}]"
925,geode/src/main/java/org/apache/calcite/adapter/geode/rel/GeodeFilter.java,"@@ -233,6 +272,85 @@ private String translateOp2(String op, String name, RexLiteral right) {
       }
       return name + "" "" + op + "" "" + valueString;
     }
+
+    /**
+     *  Get the field name for the left node to use for IN SET query
+     */
+    private String getLeftNodeFieldName(RexNode left) {
+      switch (left.getKind()) {
+      case INPUT_REF:
+        final RexInputRef left1 = (RexInputRef) left;
+        return fieldNames.get(left1.getIndex());
+      case CAST:
+        // FIXME This will not work in all cases (for example, we ignore string encoding)
+        return getLeftNodeFieldName(((RexCall) left).operands.get(0));
+      case OTHER_FUNCTION:
+        return left.accept(new GeodeRules.RexToGeodeTranslator(this.fieldNames));
+      default:
+        return null;
+      }
+    }
+
+    /**
+     *  Check if we can use IN SET Query clause to improve query performance
+     */
+    private boolean useInSetQueryClause(List<RexNode> disjunctions) {
+      if (disjunctions.size() == 0) {","[{'comment': 'probably `isEmpty()` is better here', 'commenter': 'asereda-gs'}, {'comment': 'Fixed it by checking for size less than equal to 1', 'commenter': 'chadasa'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeZipsTest.java,"@@ -45,6 +47,25 @@ public static void setUp() throws Exception {
     Cache cache = POLICY.cache();
     Region<?, ?> region =  cache.<String, Object>createRegionFactory().create(""zips"");
     new JsonLoader(region).loadClasspathResource(""/zips-mini.json"");
+    createTestRegion();
+  }
+
+  private static void createTestRegion() throws Exception {","[{'comment': 'Can you pls create a separate test class for this ? I think `GeodeZipsTest` should only be used for zips model.', 'commenter': 'asereda-gs'}, {'comment': 'created a new test class with all data types ', 'commenter': 'chadasa'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeZipsTest.java,"@@ -186,6 +207,103 @@ public void testItemPredicate() {
             + ""      GeodeFilter(condition=[>(ITEM($2, 0), 0)])\n""
             + ""        GeodeTableScan(table=[[geode, zips]])\n"");
   }
+
+  @Test
+  public void testWhereWithOrForStringField() {
+    String expectedQuery = ""SELECT state AS state FROM /zips ""
+        + ""WHERE state IN SET('RI', 'MA')"";
+    calciteAssert()
+        .query(""SELECT state as state ""
+            + ""FROM view WHERE state = 'MA' OR state = 'RI'"")
+        .returnsCount(6)
+        .queryContains(
+            GeodeAssertions.query(expectedQuery));
+  }
+
+  @Test
+  public void testWhereWithOrForNumericField() {
+    calciteAssert()
+        .query(""SELECT pop as pop ""
+            + ""FROM view WHERE pop = 34035 OR pop = 40173"")
+        .returnsCount(2)
+        .queryContains(
+            GeodeAssertions.query(""SELECT pop AS pop FROM /zips WHERE pop IN SET(40173, 34035)""));
+  }
+
+  @Test
+  public void testWhereWithOrForNestedNumericField() {
+    String expectedQuery = ""SELECT loc[1] AS lan FROM /zips ""
+        + ""WHERE loc[1] IN SET(44.098538, 43.218525)"";
+
+    calciteAssert()
+        .query(""SELECT loc[1] as lan ""
+            + ""FROM view WHERE loc[1] = 43.218525 OR loc[1] = 44.098538"")
+        .returnsCount(2)
+        .queryContains(
+            GeodeAssertions.query(expectedQuery));
+  }
+
+  @Test
+  public void testWhereWithOrForLargeValueList() {
+    String stateListPredicate = ""state = 'IL' OR state = 'UT' OR state = 'NJ' OR state = 'AL' ""","[{'comment': 'This should probably be `List<String>` which is then expanded to a big string. \r\nFull list of states you can get dynamically directly from region.', 'commenter': 'asereda-gs'}, {'comment': 'Fixed it', 'commenter': 'chadasa'}]"
925,geode/src/main/java/org/apache/calcite/adapter/geode/rel/GeodeFilter.java,"@@ -233,6 +272,85 @@ private String translateOp2(String op, String name, RexLiteral right) {
       }
       return name + "" "" + op + "" "" + valueString;
     }
+
+    /**
+     *  Get the field name for the left node to use for IN SET query
+     */
+    private String getLeftNodeFieldName(RexNode left) {
+      switch (left.getKind()) {
+      case INPUT_REF:
+        final RexInputRef left1 = (RexInputRef) left;
+        return fieldNames.get(left1.getIndex());
+      case CAST:
+        // FIXME This will not work in all cases (for example, we ignore string encoding)
+        return getLeftNodeFieldName(((RexCall) left).operands.get(0));
+      case OTHER_FUNCTION:
+        return left.accept(new GeodeRules.RexToGeodeTranslator(this.fieldNames));
+      default:
+        return null;
+      }
+    }
+
+    /**
+     *  Check if we can use IN SET Query clause to improve query performance
+     */
+    private boolean useInSetQueryClause(List<RexNode> disjunctions) {
+      if (disjunctions.size() == 0) {
+        return false;
+      }
+
+      return disjunctions.stream().allMatch(node -> {
+        // IN SET query can only be used for EQUALS
+        if (node.getKind() != SqlKind.EQUALS) {
+          return false;
+        }
+
+        RexCall call = (RexCall) node;
+        final RexNode left = call.operands.get(0);
+        final RexNode right = call.operands.get(1);
+
+        // The right node should always be literal
+        if (right.getKind() != SqlKind.LITERAL) {
+          return false;
+        }
+
+        String name = getLeftNodeFieldName(left);
+        if (name == null) {
+          return false;
+        }
+
+        return true;
+      });
+    }
+
+    /**
+     * Creates OQL IN SET predicate string
+     */
+    private String translateInSet(List<RexNode> disjunctions) {
+      RexNode firstNode = disjunctions.get(0);
+      RexCall firstCall = (RexCall) firstNode;
+
+      final RexNode left = firstCall.operands.get(0);
+      String name = getLeftNodeFieldName(left);
+
+      Set<String> rightLiteralValueList = new HashSet<>();","[{'comment': 'I would instantiate `LinkedHashSet` here, to preserve the order.', 'commenter': 'asereda-gs'}, {'comment': 'Fixed it', 'commenter': 'chadasa'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeZipsTest.java,"@@ -186,6 +207,103 @@ public void testItemPredicate() {
             + ""      GeodeFilter(condition=[>(ITEM($2, 0), 0)])\n""
             + ""        GeodeTableScan(table=[[geode, zips]])\n"");
   }
+
+  @Test
+  public void testWhereWithOrForStringField() {
+    String expectedQuery = ""SELECT state AS state FROM /zips ""","[{'comment': ""Is there a test with a single element ? Just \r\n```sql\r\nwhere state in ('NY')\r\n```\r\n\r\nWhat about edge cases like `IN ('')` , `IN (null)`, `IN (true)` ? "", 'commenter': 'asereda-gs'}, {'comment': 'Added test for single state and also empty null true values', 'commenter': 'chadasa'}]"
925,geode/src/main/java/org/apache/calcite/adapter/geode/rel/GeodeFilter.java,"@@ -233,6 +272,85 @@ private String translateOp2(String op, String name, RexLiteral right) {
       }
       return name + "" "" + op + "" "" + valueString;
     }
+
+    /**
+     *  Get the field name for the left node to use for IN SET query
+     */
+    private String getLeftNodeFieldName(RexNode left) {
+      switch (left.getKind()) {
+      case INPUT_REF:
+        final RexInputRef left1 = (RexInputRef) left;
+        return fieldNames.get(left1.getIndex());
+      case CAST:
+        // FIXME This will not work in all cases (for example, we ignore string encoding)
+        return getLeftNodeFieldName(((RexCall) left).operands.get(0));
+      case OTHER_FUNCTION:
+        return left.accept(new GeodeRules.RexToGeodeTranslator(this.fieldNames));
+      default:
+        return null;
+      }
+    }
+
+    /**
+     *  Check if we can use IN SET Query clause to improve query performance
+     */
+    private boolean useInSetQueryClause(List<RexNode> disjunctions) {
+      if (disjunctions.size() == 0) {
+        return false;
+      }
+
+      return disjunctions.stream().allMatch(node -> {
+        // IN SET query can only be used for EQUALS
+        if (node.getKind() != SqlKind.EQUALS) {
+          return false;
+        }
+
+        RexCall call = (RexCall) node;
+        final RexNode left = call.operands.get(0);
+        final RexNode right = call.operands.get(1);
+
+        // The right node should always be literal
+        if (right.getKind() != SqlKind.LITERAL) {
+          return false;
+        }
+
+        String name = getLeftNodeFieldName(left);
+        if (name == null) {
+          return false;
+        }
+
+        return true;
+      });
+    }
+
+    /**
+     * Creates OQL IN SET predicate string
+     */
+    private String translateInSet(List<RexNode> disjunctions) {
+      RexNode firstNode = disjunctions.get(0);","[{'comment': 'I would add `Preconditions.checkArgument(!disjunctions.isEmpty(), ""empty disjunctions"")` to fail early', 'commenter': 'asereda-gs'}]"
925,core/src/main/java/org/apache/calcite/rex/RexLiteral.java,"@@ -785,6 +785,31 @@ public Comparable getValue4() {
     }
   }
 
+  /**
+   * Returns the value of this literal, in the form of GeodeFilter
+   * translator wants it.
+   */
+  public Object getValue5() {","[{'comment': ""That's interesting.\r\n@asereda-gs , should `Geode`-specific bits be added to `RexLiteral`?\r\nIt looks weird to me."", 'commenter': 'vlsi'}, {'comment': 'Deleted the RexLiteral.java file change', 'commenter': 'chadasa'}, {'comment': ""@vlsi I think it was an oversight. This PR shouldn't change anything in `core` module (only `geode`). "", 'commenter': 'asereda-gs'}]"
925,core/src/main/java/org/apache/calcite/rex/RexLiteral.java,"@@ -457,7 +457,7 @@ private static void printAsJava(
         boolean includeCharset =
             (nlsString.getCharsetName() != null)
                 && !nlsString.getCharsetName().equals(
-                    SaffronProperties.INSTANCE.defaultCharset().get());
+                SaffronProperties.INSTANCE.defaultCharset().get());","[{'comment': 'Any reason to change `RexLiteral` ? ', 'commenter': 'asereda-gs'}, {'comment': 'It is only indentation will fix it', 'commenter': 'chadasa'}]"
925,geode/src/main/java/org/apache/calcite/adapter/geode/rel/GeodeFilter.java,"@@ -94,7 +105,28 @@
      * @return String representation of the literal
      */
     private static String literalValue(RexLiteral literal) {
-      Object value = literal.getValue2();
+      Comparable valueComparable = literal.getValueAs(Comparable.class);","[{'comment': 'Are we sure it will always be Comparable ? ', 'commenter': 'asereda-gs'}, {'comment': 'It will always be Comaparble because the value is of type Comparable. This call will run below code\r\nif (value == null || clazz.isInstance(value)) {\r\n      return clazz.cast(value);\r\n    }\r\nbasically it returns the value', 'commenter': 'chadasa'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeBookstoreTest.java,"@@ -413,71 +479,132 @@ public void testFilterWithNestedField() {
         .explainContains(""PLAN=GeodeToEnumerableConverter\n""
             + ""  GeodeProject(postalCode=[ITEM($3, 'postalCode')])\n""
             + ""    GeodeFilter(condition=[>(ITEM($3, 'postalCode'), '0')])\n""
-            + ""      GeodeTableScan(table=[[geode, BookCustomer]])\n"");
+            + ""      GeodeTableScan(table=[[geode, BookCustomer]])\n"")
+        .queryContains(
+            GeodeAssertions.query(""SELECT primaryAddress.postalCode AS postalCode ""
+            + ""FROM /BookCustomer WHERE primaryAddress.postalCode > '0'""));
   }
 
   @Test
-  public void testSqlSimple() throws SQLException {
+  public void testSqlSimple() {
     calciteAssert()
         .query(""SELECT itemNumber FROM geode.BookMaster WHERE itemNumber > 123"")
-        .runs();
+        .runs()
+        .queryContains(
+            GeodeAssertions.query(""SELECT itemNumber AS itemNumber ""
+            + ""FROM /BookMaster WHERE itemNumber > 123""));
   }
 
   @Test
-  public void testSqlSingleNumberWhereFilter() throws SQLException {
+  public void testSqlSingleNumberWhereFilter() {
     calciteAssert().query(""SELECT * FROM geode.BookMaster ""
-        + ""WHERE itemNumber = 123"").runs();
+        + ""WHERE itemNumber = 123"")
+        .runs()
+        .queryContains(
+            GeodeAssertions.query(""SELECT * FROM /BookMaster ""
+            + ""WHERE itemNumber = 123""));
   }
 
   @Test
-  public void testSqlDistinctSort() throws SQLException {
+  public void testSqlDistinctSort() {
     calciteAssert().query(""SELECT DISTINCT itemNumber, author ""
-        + ""FROM geode.BookMaster ORDER BY itemNumber, author"").runs();
+        + ""FROM geode.BookMaster ORDER BY itemNumber, author"")
+        .runs()
+        .queryContains(
+            GeodeAssertions.query(""SELECT itemNumber AS ""
+            + ""itemNumber, author AS author FROM /BookMaster GROUP BY ""
+            + ""itemNumber, author ORDER BY itemNumber ASC, author ASC""));
   }
 
   @Test
-  public void testSqlDistinctSort2() throws SQLException {
+  public void testSqlDistinctSort2() {
     calciteAssert().query(""SELECT itemNumber, author ""
         + ""FROM geode.BookMaster GROUP BY itemNumber, author ORDER BY itemNumber, ""
-        + ""author"").runs();
+        + ""author"")
+        .runs()
+        .queryContains(
+            GeodeAssertions.query(""SELECT itemNumber AS itemNumber, ""
+            + ""author AS author FROM /BookMaster GROUP BY itemNumber, ""
+            + ""author ORDER BY itemNumber ASC, author ASC""));
   }
 
   @Test
-  public void testSqlDistinctSort3() throws SQLException {
-    calciteAssert().query(""SELECT DISTINCT * FROM geode.BookMaster"").runs();
+  public void testSqlDistinctSort3() {
+    calciteAssert().query(""SELECT DISTINCT * FROM geode.BookMaster"")
+        .runs()
+        .queryContains(
+            GeodeAssertions.query(""SELECT itemNumber AS itemNumber, ""","[{'comment': 'There is no `DISTINCT` keyword in OQL ? ', 'commenter': 'asereda-gs'}, {'comment': 'The DISTINCT keyword is existing code, I just added the query assertion', 'commenter': 'chadasa'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeZipsTest.java,"@@ -160,7 +176,10 @@ public void testSelectLocItem() {
         .explainContains(""PLAN=GeodeToEnumerableConverter\n""
             + ""  GeodeProject(lat=[ITEM($2, 0)], lon=[ITEM($2, 1)])\n""
             + ""    GeodeSort(fetch=[1])\n""
-            + ""      GeodeTableScan(table=[[geode, zips]])\n"");
+            + ""      GeodeTableScan(table=[[geode, zips]])\n"")
+        .queryContains(
+            GeodeAssertions.query(""SELECT loc[0] AS lat, ""","[{'comment': 'Do you really need to be that strict and enforce OQL comparison ? \r\nIf there are changes in future all tests would have to be changed ', 'commenter': 'asereda-gs'}, {'comment': 'What is the harm in adding GeodeAssertions query, adding these did help in getting some edge cases. In case there is a future change these can be useful to ensure that the behavior is expected ', 'commenter': 'chadasa'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeZipsTest.java,"@@ -184,7 +206,105 @@ public void testItemPredicate() {
             + ""  GeodeProject(lat=[ITEM($2, 0)], lon=[ITEM($2, 1)])\n""
             + ""    GeodeSort(fetch=[1])\n""
             + ""      GeodeFilter(condition=[>(ITEM($2, 0), 0)])\n""
-            + ""        GeodeTableScan(table=[[geode, zips]])\n"");
+            + ""        GeodeTableScan(table=[[geode, zips]])\n"")
+        .queryContains(
+            GeodeAssertions.query(""SELECT loc[0] AS lat, ""
+            + ""loc[1] AS lon FROM /zips WHERE loc[0] > 0 LIMIT 1""));
+  }
+
+  @Test
+  public void testWhereWithOrForStringField() {
+    String expectedQuery = ""SELECT state AS state FROM /zips ""
+        + ""WHERE state IN SET('MA', 'RI')"";
+    calciteAssert()
+        .query(""SELECT state as state ""
+            + ""FROM view WHERE state = 'MA' OR state = 'RI'"")
+        .returnsCount(6)
+        .queryContains(
+            GeodeAssertions.query(expectedQuery));
+  }
+
+  @Test
+  public void testWhereWithOrForNumericField() {
+    calciteAssert()
+        .query(""SELECT pop as pop ""
+            + ""FROM view WHERE pop = 34035 OR pop = 40173"")
+        .returnsCount(2)
+        .queryContains(
+            GeodeAssertions.query(""SELECT pop AS pop FROM /zips WHERE pop IN SET(34035, 40173)""));
+  }
+
+  @Test
+  public void testWhereWithOrForNestedNumericField() {
+    String expectedQuery = ""SELECT loc[1] AS lan FROM /zips ""
+        + ""WHERE loc[1] IN SET(43.218525, 44.098538)"";
+
+    calciteAssert()
+        .query(""SELECT loc[1] as lan ""
+            + ""FROM view WHERE loc[1] = 43.218525 OR loc[1] = 44.098538"")
+        .returnsCount(2)
+        .queryContains(
+            GeodeAssertions.query(expectedQuery));
+  }
+
+  @Test
+  public void testWhereWithOrForLargeValueList() throws Exception {
+    Cache cache = POLICY.cache();
+    QueryService queryService = cache.getQueryService();
+    Query query = queryService.newQuery(""select state as state from /zips"");
+    SelectResults results = (SelectResults) query.execute();
+
+    Set<String> stateList = new LinkedHashSet<>();","[{'comment': '[SelectResults](https://geode.apache.org/releases/latest/javadoc/org/apache/geode/cache/query/SelectResults.html) already implements Collection so you can convert it to stream:\r\n```java\r\nSet<String> states = results.stream()\r\n      .map(s -> (String) s.get(""state""))\r\n       .collect(Collectors.toCollection(LinkedHashSet::new))\r\n```', 'commenter': 'asereda-gs'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeZipsTest.java,"@@ -184,7 +206,105 @@ public void testItemPredicate() {
             + ""  GeodeProject(lat=[ITEM($2, 0)], lon=[ITEM($2, 1)])\n""
             + ""    GeodeSort(fetch=[1])\n""
             + ""      GeodeFilter(condition=[>(ITEM($2, 0), 0)])\n""
-            + ""        GeodeTableScan(table=[[geode, zips]])\n"");
+            + ""        GeodeTableScan(table=[[geode, zips]])\n"")
+        .queryContains(
+            GeodeAssertions.query(""SELECT loc[0] AS lat, ""
+            + ""loc[1] AS lon FROM /zips WHERE loc[0] > 0 LIMIT 1""));
+  }
+
+  @Test
+  public void testWhereWithOrForStringField() {
+    String expectedQuery = ""SELECT state AS state FROM /zips ""
+        + ""WHERE state IN SET('MA', 'RI')"";
+    calciteAssert()
+        .query(""SELECT state as state ""
+            + ""FROM view WHERE state = 'MA' OR state = 'RI'"")
+        .returnsCount(6)
+        .queryContains(
+            GeodeAssertions.query(expectedQuery));
+  }
+
+  @Test
+  public void testWhereWithOrForNumericField() {
+    calciteAssert()
+        .query(""SELECT pop as pop ""
+            + ""FROM view WHERE pop = 34035 OR pop = 40173"")
+        .returnsCount(2)
+        .queryContains(
+            GeodeAssertions.query(""SELECT pop AS pop FROM /zips WHERE pop IN SET(34035, 40173)""));
+  }
+
+  @Test
+  public void testWhereWithOrForNestedNumericField() {
+    String expectedQuery = ""SELECT loc[1] AS lan FROM /zips ""
+        + ""WHERE loc[1] IN SET(43.218525, 44.098538)"";
+
+    calciteAssert()
+        .query(""SELECT loc[1] as lan ""
+            + ""FROM view WHERE loc[1] = 43.218525 OR loc[1] = 44.098538"")
+        .returnsCount(2)
+        .queryContains(
+            GeodeAssertions.query(expectedQuery));
+  }
+
+  @Test
+  public void testWhereWithOrForLargeValueList() throws Exception {
+    Cache cache = POLICY.cache();
+    QueryService queryService = cache.getQueryService();
+    Query query = queryService.newQuery(""select state as state from /zips"");
+    SelectResults results = (SelectResults) query.execute();
+
+    Set<String> stateList = new LinkedHashSet<>();
+
+    Iterator iterator = results.iterator();
+    while (iterator.hasNext()) {
+      StructImpl struct = (StructImpl) iterator.next();
+      stateList.add((String) struct.get(""state""));
+    }
+
+    List<String> statePredicateList = new ArrayList<>();","[{'comment': 'Similarly, I would rather use stream here:\r\n```java\r\nString predicates = states.stream()\r\n    .map(s -> String.format(Locale.ROOT, ""state = \'%s\'"", s))\r\n    .collect(Collectors.joining("" OR ""));\r\n```', 'commenter': 'asereda-gs'}]"
925,geode/src/test/java/org/apache/calcite/adapter/geode/rel/JsonLoader.java,"@@ -51,12 +53,20 @@
   private void load(Reader reader) throws IOException {
     Objects.requireNonNull(reader, ""reader"");
     try (BufferedReader br = new BufferedReader(reader)) {
-      int key = 0;
+      List<Map> mapList = new ArrayList<>();
       for (String line; (line = br.readLine()) != null;) {
         Map jsonMap = mapper.readValue(line, Map.class);
-        PdxInstance pdxInstance = mapToPdx(rootPackage, jsonMap);
-        region.put(key++, pdxInstance);
+        mapList.add(jsonMap);
       }
+      loadMapList(mapList);
+    }
+  }
+
+  void loadMapList(List<Map> mapList) {","[{'comment': ""Now when I think, maybe it's better to have [ObjectNode](https://fasterxml.github.io/jackson-databind/javadoc/2.8/com/fasterxml/jackson/databind/node/ObjectNode.html) instead of Map. It it closer to JSON format.\r\n\r\nYou can make another method:\r\n```java\r\nloadAll(Iterable<ObjectNode> data); // OR \r\nloadAll(Stream<ObjectNode> data);\r\n```"", 'commenter': 'asereda-gs'}, {'comment': 'ObjectNode is not supporting to put java.sql objects like Date, Time, Timestamp which I am testing in the new Test class. I am able to create those objects with Map. \r\n', 'commenter': 'chadasa'}]"
928,core/src/test/java/org/apache/calcite/rex/RexBuilderTest.java,"@@ -489,6 +490,34 @@ private void checkDate(RexNode node) {
     }
   }
 
+  /** Tests {@link RexBuilder#makeExactLiteral(java.math.BigDecimal)}. */
+  @Test public void testBigDecimalLiteral() {
+    final RelDataTypeFactory typeFactory =
+            new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    final RexNode literal1 = builder.makeExactLiteral(new BigDecimal(""25""));
+    assertThat(((RexLiteral) literal1).getValueAs(BigDecimal.class)","[{'comment': ""Would you please factor  the common logic to `assertBigDecimalLiteral(String inputText, String expectedOutputText)`?\r\n\r\nThat would make test much more readable (it won't include repeated `builder.makeExactLiteral...`), and the failure message would be much easier to understand.\r\n\r\nThanks."", 'commenter': 'vlsi'}, {'comment': 'Modified.', 'commenter': 'rubenada'}]"
928,core/src/test/java/org/apache/calcite/rex/RexBuilderTest.java,"@@ -489,6 +490,26 @@ private void checkDate(RexNode node) {
     }
   }
 
+  /** Tests {@link RexBuilder#makeExactLiteral(java.math.BigDecimal)}. */
+  @Test public void testBigDecimalLiteral() {
+    final RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    assertBigDecimalLiteral(builder, ""25"");
+    assertBigDecimalLiteral(builder, ""9.9"");
+    assertBigDecimalLiteral(builder, ""0"");
+    assertBigDecimalLiteral(builder, ""-75.5"");
+    assertBigDecimalLiteral(builder, ""10000000"");
+    assertBigDecimalLiteral(builder, ""100000.111111111111111111"");
+    assertBigDecimalLiteral(builder, ""-100000.111111111111111111"");
+    assertBigDecimalLiteral(builder, ""73786976294838206464""); // 2^66
+    assertBigDecimalLiteral(builder, ""-73786976294838206464"");
+  }
+
+  private void assertBigDecimalLiteral(RexBuilder builder, String val) {
+    final RexNode literal = builder.makeExactLiteral(new BigDecimal(val));
+    assertThat(((RexLiteral) literal).getValueAs(BigDecimal.class).toString(), is(val));","[{'comment': 'Please add `message` parameter to `assertThat` so it is clear WHAT is test testing', 'commenter': 'vlsi'}, {'comment': 'Message parameter included.', 'commenter': 'rubenada'}]"
928,core/src/test/java/org/apache/calcite/rex/RexBuilderTest.java,"@@ -489,6 +490,27 @@ private void checkDate(RexNode node) {
     }
   }
 
+  /** Tests {@link RexBuilder#makeExactLiteral(java.math.BigDecimal)}. */
+  @Test public void testBigDecimalLiteral() {
+    final RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    assertBigDecimalLiteral(builder, ""25"");
+    assertBigDecimalLiteral(builder, ""9.9"");
+    assertBigDecimalLiteral(builder, ""0"");
+    assertBigDecimalLiteral(builder, ""-75.5"");
+    assertBigDecimalLiteral(builder, ""10000000"");
+    assertBigDecimalLiteral(builder, ""100000.111111111111111111"");
+    assertBigDecimalLiteral(builder, ""-100000.111111111111111111"");
+    assertBigDecimalLiteral(builder, ""73786976294838206464""); // 2^66
+    assertBigDecimalLiteral(builder, ""-73786976294838206464"");
+  }
+
+  private void assertBigDecimalLiteral(RexBuilder builder, String val) {
+    final RexNode literal = builder.makeExactLiteral(new BigDecimal(val));
+    assertThat(""Generated wrong BigDecimal RexLiteral"",","[{'comment': '`""Generated wrong BigDecimal RexLiteral""` does not clarify much.  `testBigDecimalLiteral` clarifies much neither.\r\n\r\nException message should provide clear (to a developer who never looked into the test method source) indication on why the test failed.\r\n\r\nFor instance:\r\n`assertThat(""builder.makeExactLiteral(new BigDecimal("" + val + "")).toString()"", ..., is(val))`', 'commenter': 'vlsi'}, {'comment': 'Thanks for the suggestion, I agree.\r\nCode modified.', 'commenter': 'rubenada'}]"
928,core/src/test/java/org/apache/calcite/rex/RexBuilderTest.java,"@@ -489,6 +490,27 @@ private void checkDate(RexNode node) {
     }
   }
 
+  /** Tests {@link RexBuilder#makeExactLiteral(java.math.BigDecimal)}. */
+  @Test public void testBigDecimalLiteral() {
+    final RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    assertBigDecimalLiteral(builder, ""25"");
+    assertBigDecimalLiteral(builder, ""9.9"");
+    assertBigDecimalLiteral(builder, ""0"");
+    assertBigDecimalLiteral(builder, ""-75.5"");
+    assertBigDecimalLiteral(builder, ""10000000"");
+    assertBigDecimalLiteral(builder, ""100000.111111111111111111"");
+    assertBigDecimalLiteral(builder, ""-100000.111111111111111111"");
+    assertBigDecimalLiteral(builder, ""73786976294838206464""); // 2^66
+    assertBigDecimalLiteral(builder, ""-73786976294838206464"");
+  }
+
+  private void assertBigDecimalLiteral(RexBuilder builder, String val) {
+    final RexNode literal = builder.makeExactLiteral(new BigDecimal(val));
+    assertThat(""builder.makeExactLiteral(new BigDecimal("" + val + "")).toString()"",","[{'comment': ""Ah, there's `.getValueAs(BigDecimal.class)` as well.\r\nWould you please add it to the message?"", 'commenter': 'vlsi'}, {'comment': 'Sure, done.', 'commenter': 'rubenada'}]"
928,core/src/main/java/org/apache/calcite/rex/RexBuilder.java,"@@ -926,12 +926,11 @@ public RexLiteral makeLiteral(boolean b) {
   public RexLiteral makeExactLiteral(BigDecimal bd) {
     RelDataType relType;
     int scale = bd.scale();
-    long l = bd.unscaledValue().longValue();
     assert scale >= 0;","[{'comment': 'why is this required?', 'commenter': 'jbalint'}]"
951,core/src/main/java/org/apache/calcite/plan/RelTraitDef.java,"@@ -56,34 +52,12 @@
 public abstract class RelTraitDef<T extends RelTrait> {
   //~ Instance fields --------------------------------------------------------
 
-  private final LoadingCache<T, T> canonicalMap =
-      CacheBuilder.newBuilder()
-          .softValues()
-          .build(CacheLoader.from(key -> key));
-
-  /** Cache of composite traits.
-   *
-   * <p>Uses soft values to allow GC.
+  /**
+   * Cache of traits.
    *
-   * <p>You can look up using a {@link RelCompositeTrait} whose constituent
-   * traits are not canonized.
+   * <p>Uses weak interner to allow GC.
    */
-  private final LoadingCache<Object, RelCompositeTrait> canonicalCompositeMap =
-      CacheBuilder.newBuilder()
-          .softValues()
-          .build(
-              new CacheLoader<Object, RelCompositeTrait>() {
-                @Override public RelCompositeTrait load(@Nonnull Object key) {
-                  if (key instanceof RelCompositeTrait) {
-                    return (RelCompositeTrait) key;
-                  }
-                  @SuppressWarnings(""unchecked"")
-                  final List<RelMultipleTrait> list =
-                      (List<RelMultipleTrait>) key;
-                  final RelTraitDef def = list.get(0).getTraitDef();","[{'comment': 'Was this logic useless?\r\n\r\nIMHO we should add some specific test case about the functions you are changing?', 'commenter': 'eolivelli'}, {'comment': 'Yes, it is useless. There are test cases covering the changes, see RelTraitTest.', 'commenter': 'hsyuan'}, {'comment': '@hsyuan , RelTraitTest does not cover `List<RelMultipleTrait>` logic.', 'commenter': 'vlsi'}]"
963,core/src/main/java/org/apache/calcite/runtime/ResultSetEnumerable.java,"@@ -162,69 +165,81 @@ private ResultSetEnumerable(
     return new ResultSetEnumerable<>(dataSource, sql, rowBuilderFactory, consumer);
   }
 
-  /** Called from generated code that proposes to create a
-   * {@code ResultSetEnumerable} over a prepared statement. */
+  /**
+   * Called from generated code that proposes to create a
+   * {@code ResultSetEnumerable} over a prepared statement.
+   */
   public static PreparedStatementEnricher createEnricher(Integer[] indexes,
-      DataContext context) {
+                                                         DataContext context) {
     return preparedStatement -> {
       for (int i = 0; i < indexes.length; i++) {
         final int index = indexes[i];
         setDynamicParam(preparedStatement, i + 1,
-            context.get(""?"" + index));
+            (TypedValue) context.get(""?"" + index));
       }
     };
   }
 
-  /** Assigns a value to a dynamic parameter in a prepared statement, calling
-   * the appropriate {@code setXxx} method based on the type of the value. */
+  /**
+   * Assigns a value to a dynamic parameter in a prepared statement, calling
+   * the appropriate {@code setXxx} method based on the type of the value.
+   */
   private static void setDynamicParam(PreparedStatement preparedStatement,
-      int i, Object value) throws SQLException {
+                                      int i, TypedValue value) throws SQLException {
     if (value == null) {","[{'comment': 'Is it the proper way to handle nulls?\r\nI guess in case of nulls, `TypedValue value` will be non-null, and `null` will be stored inside.', 'commenter': 'vlsi'}]"
969,core/src/main/java/org/apache/calcite/rex/RexCopier.java,"@@ -90,11 +90,11 @@ public RexNode visitLiteral(RexLiteral literal) {
   }
 
   public RexNode visitDynamicParam(RexDynamicParam dynamicParam) {
-    throw new UnsupportedOperationException();
+    return new RexDynamicParam(copy(dynamicParam.getType()), dynamicParam.getIndex());","[{'comment': 'Please use `builder.xxx(...)` instead of `new ...`.', 'commenter': 'vlsi'}]"
969,core/src/main/java/org/apache/calcite/rex/RexCopier.java,"@@ -90,11 +90,11 @@ public RexNode visitLiteral(RexLiteral literal) {
   }
 
   public RexNode visitDynamicParam(RexDynamicParam dynamicParam) {
-    throw new UnsupportedOperationException();
+    return new RexDynamicParam(copy(dynamicParam.getType()), dynamicParam.getIndex());
   }
 
   public RexNode visitRangeRef(RexRangeRef rangeRef) {
-    throw new UnsupportedOperationException();
+    return new RexRangeRef(copy(rangeRef.getType()), rangeRef.getOffset());","[{'comment': 'Please use `builder.xxx(...)` instead of `new ...`.', 'commenter': 'vlsi'}]"
969,core/src/test/java/org/apache/calcite/rex/RexBuilderTest.java,"@@ -556,6 +556,28 @@ private void checkDate(RexNode node) {
     checkBigDecimalLiteral(builder, ""-73786976294838206464"");
   }
 
+  /** Tests {@link RexCopier#visitDynamicParam(RexDynamicParam)} */
+  @Test public void testCopyDynamicParam() {
+    final RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    final RelDataType type = typeFactory.createSqlType(SqlTypeName.VARCHAR);
+    final RexDynamicParam node = builder.makeDynamicParam(type, 1);
+    final RexDynamicParam copiedNode = (RexDynamicParam) builder.copy(node);","[{'comment': 'I would put an additional assertion before performing the cast. That way the test will never fail with a ClassCastException which seems like a programming error but with an AssertionError which explicitly shows that the test is broken.', 'commenter': 'zabetak'}]"
969,core/src/test/java/org/apache/calcite/rex/RexBuilderTest.java,"@@ -556,6 +556,28 @@ private void checkDate(RexNode node) {
     checkBigDecimalLiteral(builder, ""-73786976294838206464"");
   }
 
+  /** Tests {@link RexCopier#visitDynamicParam(RexDynamicParam)} */
+  @Test public void testCopyDynamicParam() {
+    final RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    final RelDataType type = typeFactory.createSqlType(SqlTypeName.VARCHAR);
+    final RexDynamicParam node = builder.makeDynamicParam(type, 1);
+    final RexDynamicParam copiedNode = (RexDynamicParam) builder.copy(node);
+    assertThat(copiedNode.getType(), is(node.getType()));
+    assertThat(copiedNode.getIndex(), is(node.getIndex()));
+  }
+
+  /** Tests {@link RexCopier#visitRangeRef(RexRangeRef)} */
+  @Test public void testCopyRange() {
+    final RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
+    final RexBuilder builder = new RexBuilder(typeFactory);
+    final RelDataType type = typeFactory.createSqlType(SqlTypeName.VARCHAR);
+    final RexRangeRef node = builder.makeRangeReference(type, 10, false);
+    final RexRangeRef copiedNode = (RexRangeRef) builder.copy(node);","[{'comment': 'Same comment as above.', 'commenter': 'zabetak'}]"
973,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -1069,6 +1139,117 @@ private void reduceCasts(RexCall outerCast) {
       }
     }
   }
+
+  /**
+   * An immutable object capturing the set of options to be used for reducing
+   * expressions.
+   */
+  public static final class ReductionOptions {
+    private final boolean matchNullability;
+    private final boolean unknownAsFalse;
+    private final boolean treatDynamicCallsAsNonConstant;
+
+    private ReductionOptions(
+        boolean matchNullability,
+        boolean unknownAsFalse,","[{'comment': 'We do have `RexUnknownAs` have you considered use that instead of `boolean`?', 'commenter': 'vlsi'}]"
973,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -1069,6 +1139,117 @@ private void reduceCasts(RexCall outerCast) {
       }
     }
   }
+
+  /**
+   * An immutable object capturing the set of options to be used for reducing
+   * expressions.
+   */
+  public static final class ReductionOptions {
+    private final boolean matchNullability;
+    private final boolean unknownAsFalse;
+    private final boolean treatDynamicCallsAsNonConstant;
+
+    private ReductionOptions(
+        boolean matchNullability,","[{'comment': 'Have you considered adding a enum?', 'commenter': 'vlsi'}]"
973,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -1069,6 +1139,117 @@ private void reduceCasts(RexCall outerCast) {
       }
     }
   }
+
+  /**
+   * An immutable object capturing the set of options to be used for reducing
+   * expressions.
+   */
+  public static final class ReductionOptions {
+    private final boolean matchNullability;
+    private final boolean unknownAsFalse;
+    private final boolean treatDynamicCallsAsNonConstant;
+
+    private ReductionOptions(
+        boolean matchNullability,
+        boolean unknownAsFalse,
+        boolean treatDynamicCallsAsNonConstant) {","[{'comment': 'Have you considered adding a enum?\r\nFrankly speaking, method calls like `(true, true, false)` are hard to read, and they are prone to errors.', 'commenter': 'vlsi'}]"
973,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -1069,6 +1139,117 @@ private void reduceCasts(RexCall outerCast) {
       }
     }
   }
+
+  /**
+   * An immutable object capturing the set of options to be used for reducing
+   * expressions.
+   */
+  public static final class ReductionOptions {
+    private final boolean matchNullability;
+    private final boolean unknownAsFalse;
+    private final boolean treatDynamicCallsAsNonConstant;
+
+    private ReductionOptions(
+        boolean matchNullability,
+        boolean unknownAsFalse,
+        boolean treatDynamicCallsAsNonConstant) {
+      this.matchNullability = matchNullability;
+      this.unknownAsFalse = unknownAsFalse;
+      this.treatDynamicCallsAsNonConstant = treatDynamicCallsAsNonConstant;
+    }
+
+    /**
+     * Update the options to control dynamic treatment.
+     *
+     * @param treatDynamicCallsAsNonConstant Whether to treat dynamic functions as
+     *                                       non-constants (defaults to true)
+     * @return A new set of ReductionOptions
+     */
+    public ReductionOptions treatDynamicCallsAsNonConstant(
+        boolean treatDynamicCallsAsNonConstant) {
+      return new ReductionOptions(
+          this.matchNullability,
+          this.unknownAsFalse,
+          treatDynamicCallsAsNonConstant);
+    }
+
+    /**
+     * <p> Update the options to control nullability matching.
+     *
+     * <p>The {@code matchNullability} flag comes into play when reducing a
+     * expression whose type is nullable. Suppose we are reducing an expression
+     * {@code CASE WHEN 'a' = 'a' THEN 1 ELSE NULL END}. Before reduction the
+     * type is {@code INTEGER} (nullable), but after reduction the literal 1 has
+     * type {@code INTEGER NOT NULL}.
+     *
+     * <p>In some situations it is more important to preserve types; in this","[{'comment': 'It would be great if you could provide a case or two when it is really important to preserve types. Since it is not trivial to understand.', 'commenter': 'vlsi'}, {'comment': 'This functionality and comment already existed. This patch simply moved the comment. If you think this should be improved I suggest that you open a ticket to address separately.', 'commenter': 'jacques-n'}]"
973,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1951,6 +1952,20 @@ public static TimeZone timeZone(DataContext root) {
     return (TimeZone) DataContext.Variable.TIME_ZONE.get(root);
   }
 
+  /** SQL {@code USER} function. */
+  @NonDeterministic
+  public static String user(DataContext root) {
+    return Optional.ofNullable((String) DataContext.Variable.USER.get(root))
+        .orElse(""sa"");
+  }
+
+  /** SQL {@code SYSTEM_USER} function. */
+  @NonDeterministic
+  public static String systemUser(DataContext root) {
+    return Optional.ofNullable((String) DataContext.Variable.SYSTEM_USER.get(root))
+        .orElse(System.getProperty(""user.name""));","[{'comment': 'Technically speaking, I would prefer regular `if (..)` here.', 'commenter': 'vlsi'}]"
973,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1951,6 +1952,20 @@ public static TimeZone timeZone(DataContext root) {
     return (TimeZone) DataContext.Variable.TIME_ZONE.get(root);
   }
 
+  /** SQL {@code USER} function. */
+  @NonDeterministic
+  public static String user(DataContext root) {
+    return Optional.ofNullable((String) DataContext.Variable.USER.get(root))
+        .orElse(""sa"");
+  }
+
+  /** SQL {@code SYSTEM_USER} function. */
+  @NonDeterministic","[{'comment': 'Does it really need `NonDeterministic` here?\r\nI guess the function is more-or-less pure as it just reads the value of data context.', 'commenter': 'vlsi'}, {'comment': 'This is stay consistent with the other dynamic functions. I have no idea why any of them are annotated this way but felt the new ones should be consistent.', 'commenter': 'jacques-n'}, {'comment': ""Conceivably (I know it's a stretch) a query could be prepared by one user and executed by another. The NonDeterministic prevents constant-reduction."", 'commenter': 'julianhyde'}]"
973,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -485,50 +557,43 @@ protected ReduceExpressionsRule(Class<? extends RelNode> clazz,
    * @param predicates Constraints known to hold on input expressions
    * @return whether reduction found something to change, and succeeded
    */
+  @Deprecated // to be removed before 2.0
   protected static boolean reduceExpressions(RelNode rel, List<RexNode> expList,
       RelOptPredicateList predicates) {
-    return reduceExpressions(rel, expList, predicates, false, true);
+    return reduceExpressions(rel, expList, predicates,
+        DEFAULT_OPTIONS.matchNullability(true).unknownAsFalse(false));
   }
 
   @Deprecated // to be removed before 2.0
   protected static boolean reduceExpressions(RelNode rel, List<RexNode> expList,
       RelOptPredicateList predicates, boolean unknownAsFalse) {
-    return reduceExpressions(rel, expList, predicates, unknownAsFalse, true);
+    return reduceExpressions(rel, expList, predicates,
+        DEFAULT_OPTIONS.matchNullability(true).unknownAsFalse(unknownAsFalse));
+  }
+
+  @Deprecated
+  protected static boolean reduceExpressions(RelNode rel, List<RexNode> expList,
+      RelOptPredicateList predicates, boolean unknownAsFalse,
+      boolean matchNullability) {
+    return reduceExpressions(rel, expList, predicates,
+        DEFAULT_OPTIONS.matchNullability(matchNullability)
+          .treatDynamicCallsAsNonConstant(true)
+          .matchNullability(matchNullability)
+        );","[{'comment': ""House style is for ')' to be on the same line, not preceded by space. Please fix. I think I saw some other occurrences."", 'commenter': 'julianhyde'}]"
981,core/src/test/java/org/apache/calcite/sql/test/SqlAdvisorTest.java,"@@ -175,6 +175,7 @@
           ""KEYWORD(LAG)"",
           ""KEYWORD(LAST_VALUE)"",
           ""KEYWORD(LEAD)"",
+          ""KEYWORD(LISTAGG)"",","[{'comment': ""why? If this is keyword, I can't use it as column alias or table name. Is that what you want?"", 'commenter': 'hsyuan'}]"
981,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -1334,6 +1338,31 @@ public Expression implementResult(AggContext info,
     }
   }
 
+  /** Implementor for the {@code LISTAGG} aggregate function. */
+  static class ListaggImplementor extends StrictAggImplementor {
+    @Override protected void implementNotNullReset(AggContext info,
+        AggResetContext reset) {
+      reset.currentBlock().add(
+          Expressions.statement(
+              Expressions.assign(reset.accumulator().get(0), NULL_EXPR)));
+    }
+
+    @Override public void implementNotNullAdd(AggContext info,
+        AggAddContext add) {
+      final Expression accValue = add.accumulator().get(0);
+      final Expression arg0 = add.arguments().get(0);
+      final Expression arg1 = add.arguments().size() == 2
+          ? add.arguments().get(1) : COMMA_EXPR;
+      final Expression result = Expressions.condition(
+          Expressions.equal(NULL_EXPR, accValue),
+          arg0,
+          Expressions.call(BuiltInMethod.STRING_CONCAT.method, accValue,","[{'comment': 'Would you please use `StringBuilder` for the aggregation state?', 'commenter': 'vlsi'}]"
1020,core/src/main/java/org/apache/calcite/jdbc/CalciteConnectionImpl.java,"@@ -420,6 +421,7 @@ public CalciteServerStatement getStatement(Meta.StatementHandle h)
           .put(Variable.TIME_ZONE.camelName, timeZone)
           .put(Variable.STDIN.camelName, streamHolder.get()[0])
           .put(Variable.STDOUT.camelName, streamHolder.get()[1])
+          .put(""#DELTA#"", new LinkedList<>()) // TODO rql cleaner way?","[{'comment': 'I guess this can be done inside EnumerableDeltaTableScan#implement, no?', 'commenter': 'zabetak'}, {'comment': 'I think when we arrive there it is ""too late"": at that point, we can only read from the DataContext via \'get\' method, but we cannot put new parameters in there.', 'commenter': 'rubenada'}, {'comment': ""What if we have recursive (recursive) query?\r\nThen a single DELTA would be not enough.\r\n\r\nBy the way: please never ever use `LinkedList`.\r\nHere's what the author says: https://twitter.com/joshbloch/status/583813919019573248"", 'commenter': 'vlsi'}, {'comment': 'Another alternative would be to add a new Table during EnumerableDeltaTableScan#implement using DataContext#getRootSchema. This can solve also the problem of having multiple levels of recursion since each different scan can establish a different table name. How about something in these lines?', 'commenter': 'zabetak'}, {'comment': ""Is it really required to add a table?\r\n\r\nFor instance, EnumerableJoin manages to operate yet it doesn't require adding a table for that."", 'commenter': 'vlsi'}, {'comment': 'In this case data have to shared/transferred between different operators (i.e., Union + Scan) which do not necessarily have parent-child relationships. Due to this I would say that it is necessary to introduce ""something"" that can be shared between operators and I think that a Table would be a good abstraction but maybe I am missing something.  ', 'commenter': 'zabetak'}, {'comment': '@zabetak , I wonder if we should add a new `RelNode` subtype for ""recursive with delta"" table instead.\r\n\r\nAdding tables to the schema for a sake of a single query on the fly does not seem right.', 'commenter': 'vlsi'}, {'comment': 'The current solution is a naive one, which, as you say, does not support multiple recursive declarations.\r\nIn order to address this issue, and following the current approach, we could create each deltaScan with a certain parameter to provide a unique identifier (what about a ModifiableTable?), and then this parameter will have to be transferred also in the moment of the recursiveUnion creation, so that it can be aware of ""where to put"" the result data (so that it can be picked by the deltaScan in the next iteration).', 'commenter': 'rubenada'}, {'comment': ""We don't really need an additional table. In Postgres' implementation, RecursiveUnion and DeltaTableScan both have a common param id representing the delta table, because we may have multiple recursive queries. RecursiveUnion stores the intermediate data that DeltaTableScan can access through the pointer pointing to RecursiveUnion."", 'commenter': 'hsyuan'}, {'comment': ""Committed new version:\r\n- deltaTableScan and recursiveUnion share an identifier (the shared delta table name) to carry out the data transfer, this allows to have multiple (nested) recursive unions, provided unit test showing this scenario.\r\n- implemented (although not used yet) new parameter maxDepth in deltaTableScan (might be useful for graph traversal)\r\n\r\nStill TODO: \r\n- Data transfer between deltaTableScan and recursiveUnion is still done via a parameter in the DataContext, this has to be modified. I'll explore the approach proposed by @zabetak of using the SchemaPlus via DataContext#getRootSchema"", 'commenter': 'rubenada'}, {'comment': 'Committed a new version that addresses the TODO mentioned in the comment above: instead of using the DataContext, now the data store / transfer between recursiveUnion and deltaTableScan is done via a transient table (a simple ModifiableTable) that gets added to the schema.', 'commenter': 'rubenada'}, {'comment': ""Thanks @rubenada! I like the new approach. Let's see what @vlsi , and @hsyuan have to say about this."", 'commenter': 'zabetak'}]"
1020,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -1616,6 +1619,68 @@ public RelBuilder minus(boolean all, int n) {
     return setOp(all, SqlKind.EXCEPT, n);
   }
 
+  /**
+   * Creates a {@link LogicalDeltaTableScan} of a delta work table (used to accumulate results in
+   * recursive union operation), using as its row type the top of the stack, and not max depth
+   * Returns this builder.
+   */
+  public RelBuilder deltaScan(String tableName) {
+    return this.deltaScan(tableName, this.peek().getRowType());
+  }
+
+  /**
+   * Creates a {@link LogicalDeltaTableScan} of a delta work table (used to accumulate results in
+   * recursive union operation), using as its row type the top of the stack, and a certain max depth
+   * Returns this builder.
+   */
+  public RelBuilder deltaScan(String tableName, int maxDepth) {","[{'comment': 'I was expecting that `maxDepth` would be a parameter of the recursiveunion operator. Why is it part of the scan?', 'commenter': 'zabetak'}, {'comment': ""@zabetak you're right, I have committed a new version with a refactoring using this approach."", 'commenter': 'rubenada'}]"
1020,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableRecursiveUnionTest.java,"@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.test.enumerable;
+
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.test.CalciteAssert;
+
+import org.junit.Test;
+
+import java.util.Arrays;
+
+/**
+ * Unit tests for
+ * {@link org.apache.calcite.adapter.enumerable.EnumerableRecursiveUnion}
+ * and {@link org.apache.calcite.adapter.enumerable.EnumerableDeltaTableScan}
+ * <a href=""https://issues.apache.org/jira/browse/CALCITE-2812"">[CALCITE-2812]
+ * Add algebraic operators to allow expressing recursive queries</a>.
+ */
+public class EnumerableRecursiveUnionTest {","[{'comment': '@rubenada can you add also a few tests where the recursive part is a bit more complicated (for instance a join between a delta scan and a regular table)? ', 'commenter': 'zabetak'}, {'comment': 'New unit tests have been added', 'commenter': 'rubenada'}]"
1020,linq4j/src/main/java/org/apache/calcite/linq4j/EnumerableDefaults.java,"@@ -3329,6 +3329,167 @@ public void reset() {
     public void close() {
     }
   }
+
+  /**
+   * Enumerator that performs a recursive union. Inspired by PostgreSQL's ""WITH RECURSIVE""
+   * implementation. See https://www.postgresql.org/docs/11/queries-with.html
+   *
+   * The general form of a recursive WITH query is always: a non-recursive term, then UNION [ALL]
+   * (in our case only UNION ALL is supported for the moment), then a recursive term;
+   * where only the recursive term can contain a reference to the query's own output.
+   * Such an operation is executed as follows:
+   *   - Evaluate the non-recursive term (seed). Include all rows in the result of the recursive
+   *   union, and also place them in a transient work table (aka delta table) that gets added to
+   *   the schema.
+   *     - So long as the working table is not empty, repeat:
+   *       - Evaluate the recursive term, using the current content of the transient table for
+   *       the recursive self-reference. Include all resulting rows in the result of the recursive
+   *       union, and also place them in the transient table, they will be the input for the
+   *       next iteration.
+   *
+   * Note: strictly speaking, this process is iteration not recursion, but RECURSIVE is the
+   * terminology chosen by the SQL standards committee.
+   */
+  public static <TSource> Enumerable<TSource> recursiveUnion(
+          Enumerable<TSource> seed,
+          Enumerable<TSource> recursion,
+          Collection<TSource> deltaCollection) {
+    return new AbstractEnumerable<TSource>() {
+      @Override public Enumerator<TSource> enumerator() {
+        return new Enumerator<TSource>() {
+          private TSource current = null;
+          private boolean seedProcessed = false;
+          private final Enumerator<TSource> seedEnumerator = seed.enumerator();
+          private final Enumerator<TSource> recursionEnumerator = recursion.enumerator();
+          private final Collection<TSource> delta = deltaCollection;
+
+          // flag to avoid adding the current item multiple times to delta collection
+          // in case of consecutive current() calls
+          private boolean currentAddedToDelta = false;
+
+          @Override public TSource current() {
+            if (this.current == null) {
+              throw new NoSuchElementException();
+            }
+
+            if (!this.currentAddedToDelta) {
+              // add 'current' to the delta work table (so that it will be fetched
+              // by the delta table scan later)
+              this.delta.add(this.current);
+              this.currentAddedToDelta = true;
+            }
+
+            return this.current;
+          }
+
+          @Override public boolean moveNext() {
+            // if we are not done with the seed (non-recursive term) moveNext on it
+            if (!this.seedProcessed) {
+              if (this.seedEnumerator.moveNext()) {
+                this.currentAddedToDelta = false;
+                this.current = this.seedEnumerator.current();
+                return true;
+              } else {
+                this.seedProcessed = true;
+              }
+            }
+
+            // if we are done with the seed, moveNext on the recursive part
+            if (this.recursionEnumerator.moveNext()) {","[{'comment': 'From this line it seems that the recursive part can contain only certain kind of operators. It seems that all operators above the delta scan table must allow pipelined execution (i.e., read rows one by one). If for some reason there is an operator that reads all rows before producing any result then probably the result of the recursive union may not be correct. \r\n\r\nIf what I described above is true then we could try the alternative below.\r\nWhen `this.recursionEnumerator.moveNext()` returns false then we obtain a new enumerator and keep repeating this procedure till there are not really any new rows (e.g., the new enumerator returns directly false?).\r\nIf `maxDepth` was part of the recursive union then we could stop after obtaining a new enumerator a certain number of times. \r\n\r\nWhat do you think @rubenada ?', 'commenter': 'zabetak'}, {'comment': '@zabetak I agree, I have committed a new version with a refactoring using this approach.', 'commenter': 'rubenada'}]"
1020,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -6837,6 +6837,36 @@ public TranslatableTable view(String s) {
     }
   }
 
+  public static class HierarchySchema {","[{'comment': 'The JdbcTest class is already quite big thus it would be better to avoid adding more (not directly related) elements inside. Possibly make it a top-level class under org.apache.calcite.test package?', 'commenter': 'zabetak'}]"
1020,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -6837,6 +6837,36 @@ public TranslatableTable view(String s) {
     }
   }
 
+  public static class HierarchySchema {
+    @Override public String toString() {
+      return ""HierarchySchema"";
+    }
+
+    public final Employee[] emps = {
+            new Employee(1, 10, ""Emp1"", 10000, 1000),
+            new Employee(2, 10, ""Emp2"", 8000, 500),
+            new Employee(3, 10, ""Emp3"", 7000, null),
+            new Employee(4, 10, ""Emp4"", 8000, 500),
+            new Employee(5, 10, ""Emp5"", 7000, null),
+    };
+    public final Department[] depts = {
+            new Department(10, ""Dept"", Arrays.asList(emps[0], emps[1], emps[2], emps[3], emps[4]),
+                    new Location(-122, 38)),
+    };
+
+    //      Emp1
+    //      /  \
+    //    Emp2  Emp4
+    //    /  \
+    // Emp3   Emp5
+    public final Hierarchy[] hierarchies = {","[{'comment': 'Is there a particular reason why the relation between employee and manager is kept in a separate table? If not then it seems more intuitive to follow the most common scenario where the employee table has also a manager id.', 'commenter': 'zabetak'}, {'comment': 'I think this design has two (small) advantages:\r\n- It can represent more complicated hierarchies, e.g. one employee with more than one manager (although this is currently not used in the test cases)\r\n- It requires 2 joins (instead of 1) to compute the hierarchy paths, so it allows us to show a trickier use case of recursive union + transient table scan', 'commenter': 'rubenada'}]"
1020,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -6935,6 +6965,27 @@ public Dependent(int empid, String name) {
     }
   }
 
+  public static class Hierarchy {","[{'comment': 'If the class is not removed entirely, consider moving it elsewhere along HierarchySchema.', 'commenter': 'zabetak'}]"
1020,core/src/main/java/org/apache/calcite/schema/impl/TransientTable.java,"@@ -0,0 +1,102 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.schema.impl;
+
+import org.apache.calcite.config.CalciteConnectionConfig;
+import org.apache.calcite.linq4j.QueryProvider;
+import org.apache.calcite.linq4j.Queryable;
+import org.apache.calcite.linq4j.tree.Expression;
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptTable;
+import org.apache.calcite.prepare.Prepare;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.TableModify;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.schema.ModifiableTable;
+import org.apache.calcite.schema.Schema;
+import org.apache.calcite.schema.SchemaPlus;
+import org.apache.calcite.schema.Statistic;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlNode;
+
+import java.lang.reflect.Type;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.List;
+
+/**
+ * Simple modifiable table whose elements can be accessed / altered via
+ * {@link #getModifiableCollection()} method (the rest of the methods are not supported).
+ * It can be used, for example, in a recursive union to accumulate all intermediate results.
+ * @param <T> table content type
+ */
+public class TransientTable<T> implements ModifiableTable {","[{'comment': ""Although I proposed transient table as a name, seeing the implementation/javadoc a name like ListModifiableTable seems more appropriate. \r\n\r\nOther than that the fact that the class is public and does not add anything new to ModifiableTable (plus it throws an exception almost in every case) makes me a bit skeptical. I am not sure if we should really invest on this but it could be nice if could reduce the visibility of this class or come up with a solution where we don't really introduce a new public class (e.g., static factory method returning a ModifiableTable)?"", 'commenter': 'zabetak'}]"
1020,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -1616,6 +1619,58 @@ public RelBuilder minus(boolean all, int n) {
     return setOp(all, SqlKind.EXCEPT, n);
   }
 
+  /**
+   * Creates a {@link LogicalDeltaTableScan} of a delta work table (used to accumulate results in
+   * recursive union operation), using as its row type the top of the stack.
+   * Returns this builder.
+   */
+  public RelBuilder deltaScan(String tableName) {","[{'comment': 'Since the notion of Delta already exists for the case of streams I would suggest to use the notion of transient tables for the new operators. For example deltaScan becomes transientScan, LogicalDeltaTableScan becomes LogicalTransientTableScan etc.', 'commenter': 'zabetak'}, {'comment': '+1\r\nDelta would indeed confuse.\r\nEspecially for `LogicalDeltaDeltaScan`', 'commenter': 'vlsi'}]"
1020,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableRecursiveUnionTest.java,"@@ -0,0 +1,357 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.test.enumerable;
+
+import org.apache.calcite.adapter.java.ReflectiveSchema;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.JoinRelType;
+import org.apache.calcite.schema.Schema;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.test.CalciteAssert;
+import org.apache.calcite.test.JdbcTest;
+import org.apache.calcite.tools.RelBuilder;
+
+import org.junit.Test;
+
+import java.util.Arrays;
+import java.util.function.Function;
+
+/**
+ * Unit tests for
+ * {@link org.apache.calcite.adapter.enumerable.EnumerableRecursiveUnion}
+ * and {@link org.apache.calcite.adapter.enumerable.EnumerableDeltaTableScan}
+ * <a href=""https://issues.apache.org/jira/browse/CALCITE-2812"">[CALCITE-2812]
+ * Add algebraic operators to allow expressing recursive queries</a>.
+ */
+public class EnumerableRecursiveUnionTest {
+
+  @Test public void testGenerateNumbers() {
+    CalciteAssert.that()
+            .query(""?"")
+            .withRel(
+                    //   WITH RECURSIVE delta(n) AS (
+                    //     VALUES (1)
+                    //     UNION ALL
+                    //     SELECT n+1 FROM delta WHERE n < 10
+                    //   )
+                    //   SELECT * FROM delta
+                    builder -> builder
+                        .values(new String[] { ""i"" }, 1)
+                        .deltaScan(""DELTA"")
+                        .filter(
+                                builder.call(
+                                       SqlStdOperatorTable.LESS_THAN,
+                                        builder.field(0),
+                                        builder.literal(10)))
+                        .project(
+                                builder.call(SqlStdOperatorTable.PLUS,
+                                        builder.field(0),
+                                        builder.literal(1)))
+                        .recursiveUnion(""DELTA"")
+                        .build()
+            )
+            .returnsOrdered(""i=1"", ""i=2"", ""i=3"", ""i=4"", ""i=5"", ""i=6"", ""i=7"", ""i=8"", ""i=9"", ""i=10"");
+  }
+
+  @Test public void testFactorial() {
+    CalciteAssert.that()
+            .query(""?"")
+            .withRel(
+                    //   WITH RECURSIVE delta (n, fact) AS (
+                    //     VALUES (0, 1)
+                    //     UNION ALL
+                    //     SELECT n+1, (n+1)*fact FROM delta WHERE n < 7
+                    //   )
+                    //   SELECT * FROM delta
+                    builder -> builder
+                        .values(new String[] { ""n"", ""fact"" }, 0, 1)
+                        .deltaScan(""D"")
+                        .filter(
+                                builder.call(
+                                        SqlStdOperatorTable.LESS_THAN,
+                                        builder.field(""n""),
+                                        builder.literal(7)))
+                        .project(
+                                Arrays.asList(
+                                        builder.call(SqlStdOperatorTable.PLUS,
+                                                builder.field(""n""),
+                                                builder.literal(1)),
+                                        builder.call(SqlStdOperatorTable.MULTIPLY,
+                                                builder.call(SqlStdOperatorTable.PLUS,
+                                                        builder.field(""n""),
+                                                        builder.literal(1)),
+                                                builder.field(""fact""))),
+                                Arrays.asList(""n"", ""fact""))
+                        .recursiveUnion(""D"")
+                        .build()
+            )
+            .returnsOrdered(""n=0; fact=1"",
+                    ""n=1; fact=1"",
+                    ""n=2; fact=2"",
+                    ""n=3; fact=6"",
+                    ""n=4; fact=24"",
+                    ""n=5; fact=120"",
+                    ""n=6; fact=720"",
+                    ""n=7; fact=5040"");
+  }
+
+  @Test public void testGenerateNumbersNestedRecursion() {
+    CalciteAssert.that()
+            .query(""?"")
+            .withRel(
+                    //   WITH RECURSIVE t_out(n) AS (
+                    //     WITH RECURSIVE t_in(n) AS (
+                    //       VALUES (1)
+                    //       UNION ALL
+                    //       SELECT n+1 FROM t_in WHERE n < 9
+                    //     )
+                    //     SELECT n FROM t_in
+                    //     UNION ALL
+                    //     SELECT n*10 FROM t_out WHERE n < 100
+                    //   )
+                    //   SELECT n FROM t_out
+                    builder -> builder
+                        .values(new String[] { ""n"" }, 1)
+                        .deltaScan(""T_IN"")
+                    .filter(
+                            builder.call(
+                                    SqlStdOperatorTable.LESS_THAN,
+                                    builder.field(""n""),
+                                    builder.literal(9)))
+                    .project(
+                            builder.call(
+                                    SqlStdOperatorTable.PLUS,
+                                    builder.field(""n""),
+                                    builder.literal(1)))
+                    .recursiveUnion(""T_IN"")
+
+                    .deltaScan(""T_OUT"")
+                    .filter(
+                            builder.call(
+                                    SqlStdOperatorTable.LESS_THAN,
+                                    builder.field(""n""),
+                                    builder.literal(100)))
+                    .project(
+                            builder.call(
+                                    SqlStdOperatorTable.MULTIPLY,
+                                    builder.field(""n""),
+                                    builder.literal(10)))
+                    .recursiveUnion(""T_OUT"")
+                    .build()
+            )
+            .returnsOrdered(
+                    ""n=1"",   ""n=2"",   ""n=3"",   ""n=4"",   ""n=5"",   ""n=6"",   ""n=7"",   ""n=8"",   ""n=9"",
+                    ""n=10"",  ""n=20"",  ""n=30"",  ""n=40"",  ""n=50"",  ""n=60"",  ""n=70"",  ""n=80"",  ""n=90"",
+                    ""n=100"", ""n=200"", ""n=300"", ""n=400"", ""n=500"", ""n=600"", ""n=700"", ""n=800"", ""n=900""
+      );
+  }
+
+  // Tests for the following hierarchy:
+  //      Emp1
+  //      /  \
+  //    Emp2  Emp4
+  //    /  \
+  // Emp3   Emp5
+  @Test public void testHierarchy() {","[{'comment': 'The test looks like a good candidate for being parameterized (see classes anotated with @RunWith(Parameterized.class)).', 'commenter': 'zabetak'}, {'comment': '+1', 'commenter': 'vlsi'}, {'comment': 'Refactored', 'commenter': 'rubenada'}]"
1020,core/src/main/java/org/apache/calcite/adapter/enumerable/EnumerableDeltaTableScan.java,"@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.adapter.enumerable;
+
+import org.apache.calcite.linq4j.tree.BlockBuilder;
+import org.apache.calcite.linq4j.tree.Expression;
+import org.apache.calcite.linq4j.tree.Expressions;
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptTable;
+import org.apache.calcite.rel.core.TableScan;
+import org.apache.calcite.schema.ModifiableTable;
+import org.apache.calcite.util.BuiltInMethod;
+
+
+/**
+ * Implementation of delta table (used to accumulate results in a recursive query) in
+ * {@link org.apache.calcite.adapter.enumerable.EnumerableConvention enumerable calling convention}.
+ */
+public class EnumerableDeltaTableScan extends TableScan implements EnumerableRel {","[{'comment': 'I wonder if this new subtype of `TableScan` would backfire when non-expecting rules would fire.\r\nI think it would be better to have a standalone rel type.', 'commenter': 'vlsi'}]"
1020,linq4j/src/main/java/org/apache/calcite/linq4j/EnumerableDefaults.java,"@@ -3329,6 +3329,168 @@ public void reset() {
     public void close() {
     }
   }
+
+  /**
+   * Enumerator that performs a recursive union. Inspired by PostgreSQL's ""WITH RECURSIVE""
+   * implementation. See https://www.postgresql.org/docs/11/queries-with.html
+   *
+   * The general form of a recursive WITH query is always: a non-recursive term, then UNION [ALL]
+   * (in our case only UNION ALL is supported for the moment), then a recursive term;
+   * where only the recursive term can contain a reference to the query's own output.
+   * Such an operation is executed as follows:
+   *   - Evaluate the non-recursive term (seed). Include all rows in the result of the recursive
+   *   union, and also place them in a transient work table (aka delta table) that gets added to
+   *   the schema.
+   *     - So long as the working table is not empty, repeat:
+   *       - Evaluate the recursive term, using the current content of the transient table for
+   *       the recursive self-reference. Include all resulting rows in the result of the recursive
+   *       union, and also place them in the transient table, they will be the input for the
+   *       next iteration.
+   *
+   * Note: strictly speaking, this process is iteration not recursion, but RECURSIVE is the
+   * terminology chosen by the SQL standards committee.
+   */
+  public static <TSource> Enumerable<TSource> recursiveUnion(
+          Enumerable<TSource> seed,
+          Enumerable<TSource> recursion,
+          Collection<TSource> deltaCollection,
+          int maxDepth) {
+    return new AbstractEnumerable<TSource>() {
+      @Override public Enumerator<TSource> enumerator() {
+        return new Enumerator<TSource>() {
+          private TSource current = null;
+          private boolean seedProcessed = false;
+          private int currentDepth = 0;
+          private final Enumerator<TSource> seedEnumerator = seed.enumerator();
+          private Enumerator<TSource> recursionEnumerator = null;
+          private final Collection<TSource> delta = deltaCollection;
+          private final Collection<TSource> nextDelta = new ArrayList<>();
+
+          @Override public TSource current() {
+            if (this.current == null) {
+              throw new NoSuchElementException();
+            }
+
+            return this.current;
+          }
+
+          @Override public boolean moveNext() {
+
+            // if we are not done with the seed (non-recursive term) moveNext on it
+            if (!this.seedProcessed) {
+              if (this.seedEnumerator.moveNext()) {
+                this.current = this.seedEnumerator.current();
+                this.nextDelta.add(this.current);
+                return true;
+              } else {
+                this.seedProcessed = true;
+                this.swapDeltas();
+              }
+            }
+
+            // if we are done with the seed, moveNext on the recursive part
+            while (true) {
+              if (maxDepth != -1 && this.currentDepth == maxDepth) {
+                // maxDepth reached, we are done
+                this.current = null;
+                return false;
+              }
+
+              if (this.recursionEnumerator == null) {
+                this.recursionEnumerator = recursion.enumerator();
+              }
+
+              if (this.recursionEnumerator.moveNext()) {
+                this.current = this.recursionEnumerator.current();
+                this.nextDelta.add(this.current);
+                return true;
+              }
+
+              if (this.nextDelta.isEmpty()) {
+                // recursive part is finished (it did not return any new item), we are done
+                this.current = null;
+                return false;
+              }
+
+              // we have finished the current depth level of the recursive part, go to next level
+              this.swapDeltas();
+              this.recursionEnumerator.close();
+              this.recursionEnumerator = null;
+              this.currentDepth++;
+            }
+          }
+
+          private void swapDeltas() {
+            this.delta.clear();
+            this.delta.addAll(this.nextDelta);
+            this.nextDelta.clear();
+          }
+
+          @Override public void reset() {
+            throw new UnsupportedOperationException();
+          }
+
+          @Override public void close() {
+            this.seedEnumerator.close();
+            if (this.recursionEnumerator != null) {
+              this.recursionEnumerator.close();
+              this.recursionEnumerator = null;
+            }
+          }
+        };
+      }
+    };
+  }
+
+  /**
+   * Enumerator that implements the scan of a temporary working table (DELTA),
+   * used in recursive union.
+   * See {@link #recursiveUnion(Enumerable, Enumerable, Collection, int)}
+   */
+  public static <TSource> Enumerable<TSource> deltaTableScan(Collection<TSource> delta) {","[{'comment': ""Do we really need a new method in EnumerableDefaults for this?\r\nCan't we re-use `org.apache.calcite.linq4j.Linq4j#asEnumerable(java.util.Collection<T>)` method instead of implementing the enumerator from scratch?"", 'commenter': 'zabetak'}]"
1029,core/src/main/java/org/apache/calcite/rex/RexExecutor.java,"@@ -32,6 +34,22 @@
    * @param reducedValues List to which reduced expressions are appended
    */
   void reduce(RexBuilder rexBuilder, List<RexNode> constExps, List<RexNode> reducedValues);
+
+  /**
+   * Checks if condition first implies (&rArr;) condition second.
+   *
+   * <p>This reduces to SAT problem which is NP-Complete.
+   * When this method says first implies second then it is definitely true.
+   * But it cannot prove that first does not imply second.
+   *
+   * @param rexBuilder Rex builder
+   * @param rowType row type
+   * @param first first condition
+   * @param second second condition
+   * @return true if it can prove first &rArr; second; otherwise false i.e.,
+   * it doesn't know if implication holds
+   */
+  boolean implies(RexBuilder rexBuilder, RelDataType rowType, RexNode first, RexNode second);","[{'comment': 'I am not in favor of adding this method in the RexExecutor interface. Many similar methods exist in RexImplicationChecker which is already public API. ', 'commenter': 'zabetak'}]"
1029,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1407,14 +1406,10 @@ protected boolean isWeaker(MutableRel rel0, MutableRel rel) {
       return false;
     }
 
-    RexExecutorImpl rexImpl =
-        (RexExecutorImpl) (rel.cluster.getPlanner().getExecutor());
-    RexImplicationChecker rexImplicationChecker =","[{'comment': 'Instead of removing RexImplicationChecker and hiding it behind the RexExecutor, it could be better to improve RexImplicationChecker to work with a RexExecutor and not only with a RexExecutorImpl.', 'commenter': 'zabetak'}]"
1030,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -4292,6 +4293,21 @@ private Sql checkSubQuery(String sql) {
     checkPlanning(program, sql);
   }
 
+  @Test public void testFilterAndProjectWithMultiJoin() throws Exception {
+    final FilterMultiJoinMergeRule filterMultiJoinMergeRule =
+        new FilterMultiJoinMergeRule(LogicalFilter.class, RelFactories.LOGICAL_BUILDER);
+    final ProjectMultiJoinMergeRule projectMultiJoinMergeRule =
+        new ProjectMultiJoinMergeRule(LogicalProject.class, RelFactories.LOGICAL_BUILDER);","[{'comment': 'Well, LogicalProject was the default class, so this test does not seem to validate anything new. Does it just duplicate the existing tests?', 'commenter': 'vlsi'}, {'comment': 'I added a new constructor in FilterMultiJoinMergeRule and ProjectMultiJoinMergeRule that take a generic Filter.class and Project.class as arguments respectively. The unit test just uses the new constructors with LogicalFilter and LogicalProject', 'commenter': 'siddharthteotia'}, {'comment': 'Assume the implementation is ""ignore the parameter and always use `LogicalProject.class`""\r\nDoes the test catch that?', 'commenter': 'vlsi'}]"
1030,core/src/main/java/org/apache/calcite/plan/RelOptUtil.java,"@@ -2611,12 +2611,12 @@ private static RexShuttle pushShuttle(final Project project) {
    * {@link org.apache.calcite.rel.rules.MultiJoin}.","[{'comment': 'The previous line mentions LogicalProject which is no longer true.', 'commenter': 'zabetak'}, {'comment': 'done', 'commenter': 'siddharthteotia'}]"
1030,core/src/main/java/org/apache/calcite/rel/rules/FilterMultiJoinMergeRule.java,"@@ -52,10 +55,24 @@ public FilterMultiJoinMergeRule(RelBuilderFactory relBuilderFactory) {
         relBuilderFactory, null);
   }
 
+  /**
+   * Creates a FilterMultiJoinMergeRule that uses a generic
+   * {@link Filter}
+   * @param filterClass filter class
+   * @param relBuilderFactory builder factory for relational expressions
+   */
+  public FilterMultiJoinMergeRule(Class<? extends Filter> filterClass,","[{'comment': 'The main Javadoc of the class (around line 34) has to be adapted too.', 'commenter': 'zabetak'}, {'comment': 'done', 'commenter': 'siddharthteotia'}]"
1030,core/src/main/java/org/apache/calcite/rel/rules/FilterMultiJoinMergeRule.java,"@@ -43,7 +44,9 @@
   //~ Constructors -----------------------------------------------------------
 
   /**
-   * Creates a FilterMultiJoinMergeRule.
+   * Creates a FilterMultiJoinMergeRule that uses {@link Filter}
+   * of type {@link LogicalFilter}
+   * @param relBuilderFactory builder factory for relational expressions
    */
   public FilterMultiJoinMergeRule(RelBuilderFactory relBuilderFactory) {
     super(","[{'comment': 'I think it is better to use the telescoping constructor pattern here. ', 'commenter': 'zabetak'}, {'comment': 'done', 'commenter': 'siddharthteotia'}]"
1030,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -4321,12 +4331,12 @@ private Sql checkSubQuery(String sql) {
     RelNode root = builder
         .scan(""EMP"")
         .filter(
-            builder.call(SqlStdOperatorTable.EQUALS,
-                builder.field(""EMPNO""), builder.literal(10)))","[{'comment': 'Did you modify the formatting on purpose?', 'commenter': 'zabetak'}, {'comment': 'Sorry this change was not on purpose. I think this may have happened in IntellIJ', 'commenter': 'siddharthteotia'}, {'comment': 'I think it would be better to revert formatting changes that were not intentional.', 'commenter': 'zabetak'}, {'comment': 'done', 'commenter': 'siddharthteotia'}]"
1030,core/src/main/java/org/apache/calcite/adapter/enumerable/EnumerableRel.java,"@@ -27,9 +26,6 @@
  */
 public interface EnumerableRel
     extends RelNode {
-  RelFactories.FilterFactory FILTER_FACTORY = EnumerableFilter::create;","[{'comment': 'The changes here break backward compatibility.', 'commenter': 'zabetak'}, {'comment': 'done', 'commenter': 'siddharthteotia'}]"
1030,core/src/main/java/org/apache/calcite/rel/core/RelFactories.java,"@@ -295,6 +296,10 @@ public RelNode createAggregate(RelNode input, boolean indicator,
   public interface FilterFactory {
     /** Creates a filter. */
     RelNode createFilter(RelNode input, RexNode condition);
+
+    /** Creates a filter */
+    RelNode createFilter(RelNode input, RexNode condition,","[{'comment': 'Adding new methods in interfaces also breaks backward compatibility.', 'commenter': 'zabetak'}, {'comment': 'removed', 'commenter': 'siddharthteotia'}]"
1030,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -2623,6 +2623,10 @@ public RexNode visitInputRef(RexInputRef inputRef) {
       }
     }
   }
+
+  public RelFactories.FilterFactory getFilterFactory() {","[{'comment': ""I don't know if it is worth adding a new public method in RelBuilder just for the sake of a test."", 'commenter': 'zabetak'}, {'comment': 'removed', 'commenter': 'siddharthteotia'}]"
1030,core/src/main/java/org/apache/calcite/rel/rules/MultiJoinProjectTransposeRule.java,"@@ -128,7 +129,7 @@ protected LogicalProject getRightChild(RelOptRuleCall call) {
   // override JoinProjectTransposeRule","[{'comment': 'Minor detail: maybe this is a good opportunity to replace all four comments `// override JoinProjectTransposeRule` in this class with the proper annotation `@Override`', 'commenter': 'rubenada'}, {'comment': ""I'd happy to post a patch to fix it: I think @siddharthteotia has been really patient, so let's not abuse his time"", 'commenter': 'laurentgo'}, {'comment': 'Sure, no problem.', 'commenter': 'rubenada'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -94,15 +94,23 @@
 
   /** The singleton. */
   public static final AggregateReduceFunctionsRule INSTANCE =
-      new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()), true,
           RelFactories.LOGICAL_BUILDER);
 
+  /** The singleton. */
+  public static final AggregateReduceFunctionsRule NO_REDUCE_SUM =
+          new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()), false,
+                                           RelFactories.LOGICAL_BUILDER);
+
+  private final boolean reduceSum;
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
-  public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
+  public AggregateReduceFunctionsRule(RelOptRuleOperand operand, boolean reduceSum,","[{'comment': ""Changing a public constructor brakes backward compatibility. I don't think this is desired for this reason."", 'commenter': 'zabetak'}, {'comment': ""Moreover, I don't like a lot the idea of making the rule configurable **just** for a single function (i.e., SUM). If we go this direction, I would prefer to be able to configure the behavior of this rule for all functions that it handles."", 'commenter': 'zabetak'}, {'comment': 'To address the backward compatibility part, is it okay to add this as a new constructor as opposed to changing the current constructor?', 'commenter': 'siddharthteotia'}, {'comment': 'It is ok to add a new constructor if it is well-documented and general enough to handle more than just the SUM function. ', 'commenter': 'zabetak'}, {'comment': 'done.', 'commenter': 'siddharthteotia'}, {'comment': 'Thanks, I added a few more comments.', 'commenter': 'zabetak'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -94,15 +94,23 @@
 
   /** The singleton. */
   public static final AggregateReduceFunctionsRule INSTANCE =
-      new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()), true,
           RelFactories.LOGICAL_BUILDER);
 
+  /** The singleton. */
+  public static final AggregateReduceFunctionsRule NO_REDUCE_SUM =","[{'comment': 'In particular project there may be a use-case that does not need to reduce sum. If necessary the singleton should be added there and not here. From my perspective it is unlikely that there will be many people who are going to use this rule.', 'commenter': 'zabetak'}, {'comment': 'Rather than adding a new singleton instance, is it okay to add a new constructor to get this behavior?', 'commenter': 'siddharthteotia'}, {'comment': ""There can't be two singletons. By definition of the word 'singleton'."", 'commenter': 'julianhyde'}, {'comment': 'done.', 'commenter': 'siddharthteotia'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,12 +98,96 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final AggregateFunctionsToReduce functionsToReduce;
+
+  /**
+   * Used to create a non-default version of this rule
+   * where we can be specific about which functions
+   * should be reduced by the rule
+   */
+  public static class AggregateFunctionsToReduce {
+    private final boolean reduceAvg;
+    private final boolean reduceSum;
+    private final boolean reduceStddevPop;
+    private final boolean reduceStddevSamp;
+    private final boolean reduceVarPop;
+    private final boolean reduceVarSamp;
+    private final boolean reduceCovarPop;
+    private final boolean reduceCovarSamp;
+    private final boolean reduceRegrSxx;
+    private final boolean reduceRegrSyy;
+
+    private AggregateFunctionsToReduce() {
+      this.reduceAvg = true;
+      this.reduceSum = true;
+      this.reduceStddevPop = true;
+      this.reduceStddevSamp = true;
+      this.reduceVarPop = true;
+      this.reduceVarSamp = true;
+      this.reduceCovarPop = true;
+      this.reduceCovarSamp = true;
+      this.reduceRegrSxx = true;
+      this.reduceRegrSyy = true;
+    }
+
+    public AggregateFunctionsToReduce(final boolean reduceAvg, final boolean reduceSum,
+        final boolean reduceStddevPop, final boolean reduceStddevSamp,
+        final boolean reduceVarPop, final boolean reduceVarSamp,
+        final boolean reduceCovarPop, final boolean reduceCovarSamp,
+        final boolean reduceRegrSxx, final boolean reduceRegrSyy) {
+      this.reduceAvg = reduceAvg;
+      this.reduceSum = reduceSum;
+      this.reduceStddevPop = reduceStddevPop;
+      this.reduceStddevSamp = reduceStddevSamp;
+      this.reduceVarPop = reduceVarPop;
+      this.reduceVarSamp = reduceVarSamp;
+      this.reduceCovarPop = reduceCovarPop;
+      this.reduceCovarSamp = reduceCovarSamp;
+      this.reduceRegrSxx = reduceRegrSxx;
+      this.reduceRegrSyy = reduceRegrSyy;
+    }
+  }
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final AggregateFunctionsToReduce functionsToReduce) {
+    Preconditions.checkArgument(functionsToReduce != null,
+          ""Error: expecting a valid handle for AggregateFunctionsToReduce"");
+    return new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      RelFactories.LOGICAL_BUILDER, functionsToReduce);
+  }
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
   public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
       RelBuilderFactory relBuilderFactory) {
     super(operand, relBuilderFactory, null);
+    // by default, this rule will reduce all functions it handles
+    this.functionsToReduce = new AggregateFunctionsToReduce();
+  }
+
+  /**
+   * Creates an AggregateReduceFunctionsRule with client
+   * provided information on which specific functions will
+   * be reduced by this rule
+   * @param operand root operand
+   * @param relBuilderFactory builder for relational expressions
+   * @param functionsToReduce client provided information
+   *                          on which specific functions
+   *                          will be reduced by this rule
+   */
+  public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
+      RelBuilderFactory relBuilderFactory, final AggregateFunctionsToReduce functionsToReduce) {","[{'comment': ""I see you created a new object for holding the information of which functions to reduce. Wouldn't be simpler to just pass a `Set<SqlKind> functionsToReduce`? "", 'commenter': 'zabetak'}, {'comment': 'Thanks. I am using a Set<SqlKind> now.', 'commenter': 'siddharthteotia'}, {'comment': 'Great, thanks!', 'commenter': 'zabetak'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,12 +98,96 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final AggregateFunctionsToReduce functionsToReduce;
+
+  /**
+   * Used to create a non-default version of this rule
+   * where we can be specific about which functions
+   * should be reduced by the rule
+   */
+  public static class AggregateFunctionsToReduce {
+    private final boolean reduceAvg;
+    private final boolean reduceSum;
+    private final boolean reduceStddevPop;
+    private final boolean reduceStddevSamp;
+    private final boolean reduceVarPop;
+    private final boolean reduceVarSamp;
+    private final boolean reduceCovarPop;
+    private final boolean reduceCovarSamp;
+    private final boolean reduceRegrSxx;
+    private final boolean reduceRegrSyy;
+
+    private AggregateFunctionsToReduce() {
+      this.reduceAvg = true;
+      this.reduceSum = true;
+      this.reduceStddevPop = true;
+      this.reduceStddevSamp = true;
+      this.reduceVarPop = true;
+      this.reduceVarSamp = true;
+      this.reduceCovarPop = true;
+      this.reduceCovarSamp = true;
+      this.reduceRegrSxx = true;
+      this.reduceRegrSyy = true;
+    }
+
+    public AggregateFunctionsToReduce(final boolean reduceAvg, final boolean reduceSum,
+        final boolean reduceStddevPop, final boolean reduceStddevSamp,
+        final boolean reduceVarPop, final boolean reduceVarSamp,
+        final boolean reduceCovarPop, final boolean reduceCovarSamp,
+        final boolean reduceRegrSxx, final boolean reduceRegrSyy) {
+      this.reduceAvg = reduceAvg;
+      this.reduceSum = reduceSum;
+      this.reduceStddevPop = reduceStddevPop;
+      this.reduceStddevSamp = reduceStddevSamp;
+      this.reduceVarPop = reduceVarPop;
+      this.reduceVarSamp = reduceVarSamp;
+      this.reduceCovarPop = reduceCovarPop;
+      this.reduceCovarSamp = reduceCovarSamp;
+      this.reduceRegrSxx = reduceRegrSxx;
+      this.reduceRegrSyy = reduceRegrSyy;
+    }
+  }
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final AggregateFunctionsToReduce functionsToReduce) {","[{'comment': 'Having both a public constructor and a public factory method seems a bit redundant. In general, I like static factories but since the existing rule base does not have many such factories, I would prefer to keep only the constructor mostly for homogeneity. What do you think?', 'commenter': 'zabetak'}, {'comment': ""The reason why I used a static factory method is because I wasn't sure if the callers will always be able to create a constructor themselves if they don't have knowledge of the arguments RelOptRuleOperand and RelBuilderFactory. \r\n\r\nUntil now the callers always grab instance as AggregateReduceFunctionsRule.INSTANCE and they will continue to do so to get the default instance of this rule that reduces all functions.\r\n\r\nFor callers interested in reducing specific functions, they can call the factory method with Set<SqlKind> functionsToReduce. \r\n\r\nI am just not sure if the knowledge of the constructor's arguments is there in the client. Like do they always know what to pass in for RelOptRuleOperand and RelBuilderFactory. So I thought public factory method is the way to go. Is that fine?"", 'commenter': 'siddharthteotia'}, {'comment': ""You raised a valid point which remind me a few more stuff to take into account in the constructor. I will add more comments.  \r\n\r\nHowever, I'm still not very much in favor of the static factory. It creates a very specialized rule that applies only for LogicalAggregates and uses a factory of Logical expressions which I am not sure if it corresponds to the most common use case. Moreover, helping the client use the constructor could also be part of the Javadoc. "", 'commenter': 'zabetak'}, {'comment': 'Done. ', 'commenter': 'siddharthteotia'}]"
1033,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -4292,6 +4292,37 @@ private Sql checkSubQuery(String sql) {
     checkPlanning(program, sql);
   }
 
+  @Test public void testReduceAverageWithNoReduceSum() {
+    final AggregateReduceFunctionsRule.AggregateFunctionsToReduce functionsToReduce =
+        new AggregateReduceFunctionsRule.AggregateFunctionsToReduce(
+        true, false, true,
+        true, true, true,
+        true, true, true,
+        true);
+    checkPlanning(
+        AggregateReduceFunctionsRule.getInstanceWithSpecificFunctionsToReduce(
+          functionsToReduce),
+                  ""select name, max(name), avg(deptno), min(name)""
+                          + "" from sales.dept group by name"");
+  }
+
+  @Test public void testNoReduceSum() {","[{'comment': 'If it is not too much effort can you add a test for each relevant function? Possibly a `@RunWith(Parameterized.class)` test? ', 'commenter': 'zabetak'}, {'comment': 'I have added more tests. Please let me know if the new tests are not added the way you were thinking/suggesting.', 'commenter': 'siddharthteotia'}, {'comment': 'done.', 'commenter': 'siddharthteotia'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,16 +100,66 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final Set<SqlKind> functionsToReduce;
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final Set<SqlKind> functionsToReduce) {
+    Preconditions.checkArgument(functionsToReduce != null,
+        ""Error: expecting a valid handle for AggregateFunctionsToReduce"");
+    return new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      RelFactories.LOGICAL_BUILDER, functionsToReduce);
+  }
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
   public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
       RelBuilderFactory relBuilderFactory) {
     super(operand, relBuilderFactory, null);
+    // by default, this rule will reduce all functions it handles
+    this.functionsToReduce = new HashSet<>();
+    addDefaultSetOfFunctionsToReduce();
+  }
+
+  /**
+   * Creates an AggregateReduceFunctionsRule with client
+   * provided information on which specific functions will
+   * be reduced by this rule
+   * @param operand root operand
+   * @param relBuilderFactory builder for relational expressions
+   * @param functionsToReduce client provided information
+   *                          on which specific functions
+   *                          will be reduced by this rule
+   */
+  public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
+      RelBuilderFactory relBuilderFactory, Set<SqlKind> functionsToReduce) {
+    super(operand, relBuilderFactory, null);
+    this.functionsToReduce = functionsToReduce;
   }
 
   //~ Methods ----------------------------------------------------------------
 
+  private void addDefaultSetOfFunctionsToReduce() {
+    functionsToReduce.add(SqlKind.AVG);
+    functionsToReduce.add(SqlKind.SUM);
+    functionsToReduce.add(SqlKind.STDDEV_POP);
+    functionsToReduce.add(SqlKind.STDDEV_SAMP);
+    functionsToReduce.add(SqlKind.VAR_POP);
+    functionsToReduce.add(SqlKind.VAR_SAMP);
+    functionsToReduce.add(SqlKind.COVAR_POP);
+    functionsToReduce.add(SqlKind.COVAR_SAMP);
+    functionsToReduce.add(SqlKind.REGR_SXX);
+    functionsToReduce.add(SqlKind.REGR_SYY);","[{'comment': 'I think it may be better to put this into a static block, and make functionsToReduce a static member.', 'commenter': 'hsyuan'}, {'comment': 'Revoke my comment, I see there is a param that may want to override the default functions to reduce. So it is OK.', 'commenter': 'hsyuan'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,16 +100,66 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final Set<SqlKind> functionsToReduce;
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final Set<SqlKind> functionsToReduce) {
+    Preconditions.checkArgument(functionsToReduce != null,
+        ""Error: expecting a valid handle for AggregateFunctionsToReduce"");
+    return new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      RelFactories.LOGICAL_BUILDER, functionsToReduce);
+  }
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
   public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
       RelBuilderFactory relBuilderFactory) {
     super(operand, relBuilderFactory, null);
+    // by default, this rule will reduce all functions it handles
+    this.functionsToReduce = new HashSet<>();
+    addDefaultSetOfFunctionsToReduce();
+  }
+
+  /**
+   * Creates an AggregateReduceFunctionsRule with client
+   * provided information on which specific functions will
+   * be reduced by this rule
+   * @param operand root operand
+   * @param relBuilderFactory builder for relational expressions
+   * @param functionsToReduce client provided information
+   *                          on which specific functions
+   *                          will be reduced by this rule
+   */
+  public AggregateReduceFunctionsRule(RelOptRuleOperand operand,","[{'comment': 'Providing a public constuctor with operand directly is not a very good idea. Plus it is not correct since the rule expects to work only with Aggregate. I would prefer the pattern used in ProjectFilterTransposeRule for instance where the constructor takes as an argument the class of the matching operand (i.e., `Class<? extends Aggregate> aggregateClass`). This should make also the constructor slighly easier to use.', 'commenter': 'zabetak'}, {'comment': 'Done.', 'commenter': 'siddharthteotia'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,16 +100,66 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final Set<SqlKind> functionsToReduce;
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final Set<SqlKind> functionsToReduce) {
+    Preconditions.checkArgument(functionsToReduce != null,
+        ""Error: expecting a valid handle for AggregateFunctionsToReduce"");
+    return new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      RelFactories.LOGICAL_BUILDER, functionsToReduce);
+  }
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
   public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
       RelBuilderFactory relBuilderFactory) {
     super(operand, relBuilderFactory, null);
+    // by default, this rule will reduce all functions it handles
+    this.functionsToReduce = new HashSet<>();","[{'comment': 'Maybe EnumSet instead of HashSet?', 'commenter': 'zabetak'}, {'comment': 'Done.', 'commenter': 'siddharthteotia'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,16 +100,66 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final Set<SqlKind> functionsToReduce;
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final Set<SqlKind> functionsToReduce) {
+    Preconditions.checkArgument(functionsToReduce != null,
+        ""Error: expecting a valid handle for AggregateFunctionsToReduce"");
+    return new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      RelFactories.LOGICAL_BUILDER, functionsToReduce);
+  }
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
   public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
       RelBuilderFactory relBuilderFactory) {
     super(operand, relBuilderFactory, null);
+    // by default, this rule will reduce all functions it handles
+    this.functionsToReduce = new HashSet<>();
+    addDefaultSetOfFunctionsToReduce();
+  }
+
+  /**
+   * Creates an AggregateReduceFunctionsRule with client
+   * provided information on which specific functions will
+   * be reduced by this rule
+   * @param operand root operand
+   * @param relBuilderFactory builder for relational expressions
+   * @param functionsToReduce client provided information
+   *                          on which specific functions
+   *                          will be reduced by this rule
+   */
+  public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
+      RelBuilderFactory relBuilderFactory, Set<SqlKind> functionsToReduce) {
+    super(operand, relBuilderFactory, null);
+    this.functionsToReduce = functionsToReduce;","[{'comment': 'Defensive copy and use of EnumSet. Also it would be nice to verify that functions parameters are valid and can be handled by the rule (throw IllegalArgumentException if necessary).', 'commenter': 'zabetak'}, {'comment': 'Done.', 'commenter': 'siddharthteotia'}]"
1033,core/src/main/java/org/apache/calcite/rel/rules/AggregateReduceFunctionsRule.java,"@@ -97,16 +100,66 @@
       new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
           RelFactories.LOGICAL_BUILDER);
 
+  private final Set<SqlKind> functionsToReduce;
+
+  /**
+   * Gets an instance of AggregateReduceFunctionsRule
+   * with client provided specific functions to reduce
+   * @param functionsToReduce client provided information
+   *                          on which specific functions will be
+   *                          reduced by this rule
+   * @return an instance of AggregateReduceFunctionsRule
+   */
+  public static AggregateReduceFunctionsRule
+      getInstanceWithSpecificFunctionsToReduce(final Set<SqlKind> functionsToReduce) {
+    Preconditions.checkArgument(functionsToReduce != null,
+        ""Error: expecting a valid handle for AggregateFunctionsToReduce"");
+    return new AggregateReduceFunctionsRule(operand(LogicalAggregate.class, any()),
+      RelFactories.LOGICAL_BUILDER, functionsToReduce);
+  }
+
   //~ Constructors -----------------------------------------------------------
 
   /** Creates an AggregateReduceFunctionsRule. */
   public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
       RelBuilderFactory relBuilderFactory) {
     super(operand, relBuilderFactory, null);
+    // by default, this rule will reduce all functions it handles
+    this.functionsToReduce = new HashSet<>();
+    addDefaultSetOfFunctionsToReduce();
+  }
+
+  /**
+   * Creates an AggregateReduceFunctionsRule with client
+   * provided information on which specific functions will
+   * be reduced by this rule
+   * @param operand root operand
+   * @param relBuilderFactory builder for relational expressions
+   * @param functionsToReduce client provided information
+   *                          on which specific functions
+   *                          will be reduced by this rule
+   */
+  public AggregateReduceFunctionsRule(RelOptRuleOperand operand,
+      RelBuilderFactory relBuilderFactory, Set<SqlKind> functionsToReduce) {
+    super(operand, relBuilderFactory, null);
+    this.functionsToReduce = functionsToReduce;
   }
 
   //~ Methods ----------------------------------------------------------------
 
+  private void addDefaultSetOfFunctionsToReduce() {","[{'comment': 'Minor but why not reusing org.apache.calcite.sql.SqlKind#AVG_AGG_FUNCTIONS and org.apache.calcite.sql.SqlKind#COVAR_AVG_AGG_FUNCTIONS since they exist?', 'commenter': 'zabetak'}, {'comment': 'done.', 'commenter': 'siddharthteotia'}]"
1095,site/_docs/reference.md,"@@ -1447,10 +1448,10 @@ period:
 | {fn SUBSTRING(string, offset, length)} | Returns a character string that consists of *length* characters from *string* starting at the *offset* position
 | {fn UCASE(string)} | Returns a string in which all alphabetic characters in *string* have been converted to upper case
 | {fn REPLACE(string, search, replacement)} | Returns a string in which all the occurrences of *search* in *string* are replaced with *replacement*; if *replacement* is the empty string, the occurrences of *search* are removed
+| {fn ASCII(string)} | Returns the corresponding ASCII code of a single-character string","[{'comment': 'Pls detail what is happening when string is empty or has more than one character. \r\nFor instance [SQL-Server](https://docs.microsoft.com/en-us/sql/t-sql/functions/ascii-transact-sql?view=sql-server-2017) mentions  :\r\n> Returns the ASCII code value of the leftmost character of a character expression.\r\n\r\nSome concrete examples would be nice. \r\nWhat is the output for non-ASCII chars ? ', 'commenter': 'asereda-gs'}, {'comment': 'It may return negative number when meeting Chinese character because of  encoding with UTF-8.', 'commenter': 'chunweilei'}]"
1095,core/src/test/java/org/apache/calcite/sql/test/SqlOperatorBaseTest.java,"@@ -4247,6 +4247,14 @@ private void checkNullOperand(SqlTester tester, String op) {
     tester.checkNull(""CHARACTER_LENGTH(cast(null as varchar(1)))"");
   }
 
+  @Test public void testAsciiFunc() {
+    tester.setFor(SqlStdOperatorTable.ASCII);
+    tester.checkScalarExact(""ASCII('')"", ""0"");","[{'comment': ""Pls also add a test with single char: 'a' or '1'"", 'commenter': 'asereda-gs'}, {'comment': 'Also what happens when there is a non-ASCII character ? ', 'commenter': 'asereda-gs'}, {'comment': 'Ok, I will add more test cases.', 'commenter': 'chunweilei'}]"
1095,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -237,6 +238,12 @@ public static String initcap(String s) {
     return newS.toString();
   }
 
+  /** SQL ASCII(string) function. */
+  public static int ascii(String s) {
+    return s.length() == 0","[{'comment': 'Is it just me who prefers  `string.isEmpty()` over `string.length() > 0` ? ', 'commenter': 'asereda-gs'}, {'comment': 'You are right.', 'commenter': 'chunweilei'}]"
1095,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -237,6 +238,12 @@ public static String initcap(String s) {
     return newS.toString();
   }
 
+  /** SQL ASCII(string) function. */
+  public static int ascii(String s) {
+    return s.length() == 0
+        ? 0 : s.substring(0, 1).getBytes(StandardCharsets.UTF_8)[0];","[{'comment': 'why not use [charAt()](https://docs.oracle.com/javase/8/docs/api/java/lang/String.html#charAt-int-) ? ', 'commenter': 'asereda-gs'}, {'comment': 'Substring returns a string which has getBytes function and it can specify charset.  ', 'commenter': 'chunweilei'}, {'comment': 'I did a little test:\r\n```java\r\n  @Test\r\n  public void basic() {\r\n    final char[] chars = {0x00, 0x1B,\r\n        \'A\', \'a\', \'0\', \'{\', \'}\',\r\n        \'\\n\', \'\\r\', \'\\t\', \' \',\r\n        0x80, 0x99,\r\n        \'\\u0391\', \'\\u03A9\', \'\\u0391\'};\r\n\r\n    for (char ch: chars) {\r\n      final String value = String.valueOf(ch);\r\n      assertEquals(String.format(""for %s (ascii:%d hex:0x%02X)"", value, (int) ch, (int) ch),\r\n          ascii1(value), ascii2(value));\r\n    }\r\n  }\r\n\r\n  private static int ascii1(String str) {\r\n    return str.isEmpty() ? 0 : str.getBytes(StandardCharsets.UTF_8)[0];\r\n  }\r\n\r\n  private static int ascii2(String str) {\r\n    return str.isEmpty() ? 0 : str.charAt(0);\r\n  }\r\n```\r\nSo it is failing starting with extended ascii characters (> 127)  :  \r\n```\r\njava.lang.AssertionError: for \x80\x80 (ascii:128 hex:0x80) \r\nExpected :-62\r\nActual   :128\r\n```\r\nIt seems for standard ascii table (hex: 0x00 - 0x7E) `charAt()` produces identical results as UTF8 encoding. It is expected because UNICODE is identical to ASCII for first 128 characters (and UTF8 uses single byte for basic ASCII charset).\r\n\r\nThe question is how to define Calcite  `ASCII` function outside basic ASCII chars (0-127) ? Or explicitly say behaviour is undefined for non-basic ascii ? \r\n\r\n[Transact-SQL](https://docs.microsoft.com/en-us/sql/t-sql/functions/ascii-transact-sql?view=sql-server-2017) says ASCII works only for [printable chars](https://en.wikipedia.org/wiki/ASCII#Printable_characters) (0x20- 0x7E)', 'commenter': 'asereda-gs'}, {'comment': 'It looks like the behavior is vary from database system to database system.  Such as:\r\n\r\n[PostgreSQL](http://www.postgresqltutorial.com/postgresql-ascii/) says the ASCII() function returns the Unicode code point of the character in the case of UTF-8.', 'commenter': 'chunweilei'}, {'comment': 'Yes. We usually follow Postgres standards (eg. `extract` function). \r\nIn this case is `charAt()` is preferable ? ', 'commenter': 'asereda-gs'}, {'comment': 'Updated the PR in which I use `codePointAt` to get the Unicode code point of the character. \r\n\r\nIs it proper?', 'commenter': 'chunweilei'}, {'comment': 'Yes it is more generic than `charAt()`. ', 'commenter': 'asereda-gs'}]"
1095,core/src/main/codegen/templates/Parser.jj,"@@ -6126,6 +6126,7 @@ SqlPostfixOperator PostfixRowOperator() :
 |   < ARRAY_MAX_CARDINALITY: ""ARRAY_MAX_CARDINALITY"" >
 |   < AS: ""AS"" >
 |   < ASC: ""ASC"" >
+|   < ASCII: ""ASCII"" >","[{'comment': ""Can you also address [Julian's comment](https://issues.apache.org/jira/browse/CALCITE-2599?focusedCommentId=16788417&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-16788417) in JIRA :  \r\n\r\n> I don't think this needs a parser change. Just add a function. "", 'commenter': 'asereda-gs'}, {'comment': 'Updated.', 'commenter': 'chunweilei'}]"
1095,site/_docs/reference.md,"@@ -1447,10 +1448,10 @@ period:
 | {fn SUBSTRING(string, offset, length)} | Returns a character string that consists of *length* characters from *string* starting at the *offset* position
 | {fn UCASE(string)} | Returns a string in which all alphabetic characters in *string* have been converted to upper case
 | {fn REPLACE(string, search, replacement)} | Returns a string in which all the occurrences of *search* in *string* are replaced with *replacement*; if *replacement* is the empty string, the occurrences of *search* are removed
+| {fn ASCII(string)} | Returns the corresponding ASCII code of the first character of *string*; Returns 0 if *string* is empty; Returns NULL if *string* is NULL","[{'comment': ""Let's agree on behaviour of `ASCII` function for non-basic ASCII characters (> `0x7E`).  This includes extended ASCII (eg. LATIN) and UNICODE.\r\n\r\nShould we also support more generic [UNICODE](https://docs.microsoft.com/en-us/sql/t-sql/functions/unicode-transact-sql?view=sql-server-2017) function ? "", 'commenter': 'asereda-gs'}, {'comment': 'In my opinion,  explicitly saying that behavior is undefined for non-basic ascii looks like fine.', 'commenter': 'chunweilei'}]"
1099,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -373,6 +374,8 @@ public Expression implement(RexToLixTranslator translator,
             BuiltInMethod.UNIX_TIMESTAMP_CEIL.method,
             BuiltInMethod.UNIX_DATE_CEIL.method), false);
 
+    defineMethod(LAST_DAY, ""lastDay"", NullPolicy.STRICT);","[{'comment': '""lastday""? I see all the current method names are lower case.', 'commenter': 'xndai'}, {'comment': 'camelCase is fine. It just happens that there are no multi-word function names yet.', 'commenter': 'julianhyde'}]"
1099,core/src/test/java/org/apache/calcite/sql/test/SqlOperatorBaseTest.java,"@@ -5577,6 +5577,46 @@ private void checkNullOperand(SqlTester tester, String op) {
     }
   }
 
+  @Test public void testLastDayFunc() {","[{'comment': 'do you need an end to end test to verify this new function in a SQL query?', 'commenter': 'xndai'}, {'comment': 'if so, add a few queries to `misc.iq`', 'commenter': 'julianhyde'}, {'comment': 'Will do. Thanks.', 'commenter': 'chunweilei'}]"
1099,core/src/test/java/org/apache/calcite/sql/test/SqlOperatorBaseTest.java,"@@ -5577,6 +5577,46 @@ private void checkNullOperand(SqlTester tester, String op) {
     }
   }
 
+  @Test public void testLastDayFunc() {
+    tester.setFor(SqlStdOperatorTable.LAST_DAY);
+    tester.checkScalar(""last_day(DATE '2019-02-10')"",","[{'comment': ""Can tests more edge cases like below (last day of the month, leap year etc.) : \r\n1. `DATE '2019-02-28'`\r\n2.  `DATE '2020-02-20'` /  `DATE '2020-02-29'` (leap years: 2012 / 2020 / 2076). \r\n2. `DATE '2019-12-31'`\r\n3. `DATE '2019-01-01'`\r\n4. `DATE '2019-06-30'`\r\n4. `DATE '9999-12-31'`\r\n"", 'commenter': 'asereda-gs'}, {'comment': 'What about dates before 1970-01-01 ? ', 'commenter': 'asereda-gs'}, {'comment': 'I will add more tests about dates before 1970-01-01 .', 'commenter': 'chunweilei'}]"
1099,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1924,6 +1924,22 @@ public static int truncate(int v, int x) {
     return v - remainder;
   }
 
+  /** SQL {@code LAST_DAY} function. */
+  public static int lastDay(int date) {","[{'comment': 'Please add javadoc for `date` argument. Is it days since epoch ? ', 'commenter': 'asereda-gs'}, {'comment': 'Ok.', 'commenter': 'chunweilei'}]"
1099,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1924,6 +1924,22 @@ public static int truncate(int v, int x) {
     return v - remainder;
   }
 
+  /** SQL {@code LAST_DAY} function. */
+  public static int lastDay(int date) {
+    int y0 = (int) DateTimeUtils.unixDateExtract(TimeUnitRange.YEAR, date);
+    int m0 = (int) DateTimeUtils.unixDateExtract(TimeUnitRange.MONTH, date);
+    int last = lastDay(y0, m0);
+    return DateTimeUtils.ymdToUnixDate(y0, m0, last);
+  }
+
+  public static int lastDay(long timestamp) {","[{'comment': 'Pls add javadoc for `timestamp` argument. Is it millis since epoch ? ', 'commenter': 'asereda-gs'}, {'comment': 'Ok.', 'commenter': 'chunweilei'}]"
1099,site/_docs/reference.md,"@@ -1236,6 +1236,7 @@ Not implemented:
 | SECOND(date)              | Equivalent to `EXTRACT(SECOND FROM date)`. Returns an integer between 0 and 59.
 | TIMESTAMPADD(timeUnit, integer, datetime) | Returns *datetime* with an interval of (signed) *integer* *timeUnit*s added. Equivalent to `datetime + INTERVAL 'integer' timeUnit`
 | TIMESTAMPDIFF(timeUnit, datetime, datetime2) | Returns the (signed) number of *timeUnit* intervals between *datetime* and *datetime2*. Equivalent to `(datetime2 - datetime) timeUnit`
+| LAST_DAY(date)            | Returns the date of the last day of the month in a value of datatype DATE","[{'comment': 'Pls provide an example: \r\n1. `2020-02-10 -> 2020-02-29` (DATE type)\r\n2. `2020-02-10 10:10:10 -> 2020-02-29` (TIMESTAMP type)', 'commenter': 'asereda-gs'}, {'comment': 'Will do.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -1045,6 +1053,69 @@ public RelBuilder snapshot(RexNode period) {
     return this;
   }
 
+
+  /**
+   * Gets column mappings of the operator.
+   *
+   * @param op operator instance
+   * @return column mappings associated with this function
+   */
+  private Set<RelColumnMapping> getColumnMappings(SqlOperator op) {
+    SqlReturnTypeInference inference = op.getReturnTypeInference();
+    if (inference == null) {
+      return null;
+    }","[{'comment': 'L1065~1067  can be removed. If it is null, the instanceof will return false.', 'commenter': 'hsyuan'}, {'comment': 'Ok. Will do.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -1045,6 +1053,69 @@ public RelBuilder snapshot(RexNode period) {
     return this;
   }
 
+
+  /**
+   * Gets column mappings of the operator.
+   *
+   * @param op operator instance
+   * @return column mappings associated with this function
+   */
+  private Set<RelColumnMapping> getColumnMappings(SqlOperator op) {
+    SqlReturnTypeInference inference = op.getReturnTypeInference();
+    if (inference == null) {
+      return null;
+    }
+    if (inference instanceof TableFunctionReturnTypeInference) {
+      return ((TableFunctionReturnTypeInference) inference).getColumnMappings();
+    } else {
+      return null;
+    }
+  }
+
+  /**
+   * Create a RexCall to the CURSOR function by ordinal.
+   *
+   * @param ordinal the reference to the relational input
+   * @return RexCall to CURSOR function
+   */
+  public RexNode cursor(int ordinal) {
+    return getRexBuilder().makeCall(SqlStdOperatorTable.CURSOR, getRexBuilder()
+        .makeInputRef(peek(stack.size() - ordinal - 1).getRowType(), ordinal));
+  }
+
+  /**
+   * Creates a {@link TableFunctionScan}.
+   *
+   */
+  public RelBuilder functionScan(SqlOperator operator,
+      Iterable<? extends RexNode> operands) {
+    List<RelNode> inputs = new ArrayList<>();
+    int total = stack.size();
+
+    // Get inputs from operands.
+    for (RexNode operand : operands) {
+      if (operand instanceof RexCall) {
+        if (operand.getKind() == SqlKind.CURSOR) {
+          RexNode node = ((RexCall) operand).getOperands().get(0);
+          assert node instanceof RexInputRef;
+          inputs.add(peek(total - ((RexInputRef) node).getIndex() - 1));
+        }
+      }
+    }
+
+    RexNode call = getRexBuilder()
+        .makeCall(operator, ImmutableList.copyOf(operands));","[{'comment': ""You don't need to add make immutable copy. The RexCall constructor will do."", 'commenter': 'hsyuan'}, {'comment': 'It does not target to make immutable copy. It converts operands whose type is Iterable<? extends RexNode> to List using ImmutableList#copyOf. ', 'commenter': 'chunweilei'}, {'comment': 'Got it. Make sense.', 'commenter': 'hsyuan'}]"
1102,core/src/test/java/org/apache/calcite/test/RelBuilderTest.java,"@@ -298,6 +298,23 @@
     assertThat(root, hasTree(expected));
   }
 
+  @Test public void testTableFunctionScan() {
+    // Equivalent SQL:
+    //   SELECT *
+    //   FROM TABLE(DUP(CURSOR(select * from emp), CURSOR(select * from DEPT), 'NAME'))","[{'comment': 's/DUP/DEDUP/', 'commenter': 'hsyuan'}, {'comment': 'Oops, you are right.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/rel/core/RelFactories.java,"@@ -549,6 +555,34 @@ public RelNode createMatch(RelNode input, RexNode pattern,
           partitionKeys, orderKeys, interval);
     }
   }
+
+  /**
+   * Can create a {@link TableFunctionScan}
+   * of the appropriate type for a rule's calling convention.
+   */
+  public interface TableFunctionScanFactory {
+    /** Creates a {@link TableFunctionScan}. */
+    RelNode createTableFunctionScan(RelOptCluster cluster,
+        List<RelNode> inputs, RexNode rexCall, Type elementType,
+        RelDataType rowType, Set<RelColumnMapping> columnMappings);","[{'comment': 'Is `rowType` necessary? Is it possible to ask the table function to deduce its own row type?', 'commenter': 'julianhyde'}, {'comment': 'Yep, I think its rowType is same with function.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/rel/core/RelFactories.java,"@@ -549,6 +555,34 @@ public RelNode createMatch(RelNode input, RexNode pattern,
           partitionKeys, orderKeys, interval);
     }
   }
+
+  /**
+   * Can create a {@link TableFunctionScan}
+   * of the appropriate type for a rule's calling convention.
+   */
+  public interface TableFunctionScanFactory {
+    /** Creates a {@link TableFunctionScan}. */
+    RelNode createTableFunctionScan(RelOptCluster cluster,
+        List<RelNode> inputs, RexNode rexCall, Type elementType,","[{'comment': ""I don't think there should be an `inputs` parameter. You should pass 'int inputCount', and it will pop the right number of RelNodes off of the stack. See `union`, another relational operator that takes a variable number of inputs.\r\n\r\nThis impacts the `cursor` method. See my comments there."", 'commenter': 'julianhyde'}, {'comment': 'Note that it is a TableFunctionScanFactory. So I think it needs an `inputs` parameter.  But I think it may work in RelBuilder.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/rel/core/TableFunctionScan.java,"@@ -64,6 +64,7 @@
    *
    * @param cluster        Cluster that this relational expression belongs to
    * @param inputs         0 or more relational inputs
+   * @param traits         Traits","[{'comment': 'Can you rename this parameter to `traitSet`. That is the preferred name these days. Thanks for adding javadoc.', 'commenter': 'julianhyde'}, {'comment': 'With pleasure.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -1045,6 +1053,66 @@ public RelBuilder snapshot(RexNode period) {
     return this;
   }
 
+
+  /**
+   * Gets column mappings of the operator.
+   *
+   * @param op operator instance
+   * @return column mappings associated with this function
+   */
+  private Set<RelColumnMapping> getColumnMappings(SqlOperator op) {
+    SqlReturnTypeInference inference = op.getReturnTypeInference();
+    if (inference instanceof TableFunctionReturnTypeInference) {
+      return ((TableFunctionReturnTypeInference) inference).getColumnMappings();
+    } else {
+      return null;
+    }
+  }
+
+  /**
+   * Create a RexCall to the CURSOR function by ordinal.
+   *
+   * @param ordinal the reference to the relational input
+   * @return RexCall to CURSOR function
+   */
+  public RexNode cursor(int ordinal) {
+    return getRexBuilder().makeCall(SqlStdOperatorTable.CURSOR, getRexBuilder()
+        .makeInputRef(peek(stack.size() - ordinal - 1).getRowType(), ordinal));
+  }
+","[{'comment': 'Currently the cursor function accesses the `ordinal`th element from the top of the stack. So, if we create a table function with two inputs, the left input will be cursor(1) and the right input will be cursor(0).\r\n\r\nBut we actually want them to be the other way around.\r\n\r\nI suggest that you add an `inputCount` parameter (see: `field(inputCount, inputOrdinal, fieldOrdinal)`). Thus the left input would be `cursor(2, 0)`, and the right input would be `cursor(2, 1)`.\r\n\r\nBy the way, it is correct to call `peek` here. But `functionScan` should call pop for each input.', 'commenter': 'julianhyde'}, {'comment': 'Will do. But I am curious about why doing like that.', 'commenter': 'chunweilei'}]"
1102,core/src/test/java/org/apache/calcite/test/RelBuilderTest.java,"@@ -298,6 +298,23 @@
     assertThat(root, hasTree(expected));
   }
 
+  @Test public void testTableFunctionScan() {
+    // Equivalent SQL:
+    //   SELECT *
+    //   FROM TABLE(DEDUP(CURSOR(select * from emp), CURSOR(select * from DEPT), 'NAME'))
+    final RelBuilder builder = RelBuilder.create(config().build());
+    RelNode root = builder.scan(""EMP"").scan(""DEPT"")
+        .functionScan(new MockSqlOperatorTable.DedupFunction(),
+            Lists.newArrayList(builder.cursor(0),
+                builder.cursor(1))).build();
+    final String expected = ""LogicalTableFunctionScan(invocation=""
+        + ""[DEDUP(CURSOR($0), CURSOR($1))], ""
+        + ""rowType=[RecordType(VARCHAR(1024) NAME)])\n""
+        + ""  LogicalTableScan(table=[[scott, EMP]])\n""
+        + ""  LogicalTableScan(table=[[scott, DEPT]])\n"";
+    assertThat(root, hasTree(expected));
+  }","[{'comment': ""Add an assert that builder's stack is now empty. (functionScan should have popped both the EMP and DEPT scans, though I suspect it doesn't currently.)\r\n\r\nI think the best way to check is to call builder.build() and make sure that it throws. Or perhaps call builder.toString(), and make sure that it is empty."", 'commenter': 'julianhyde'}, {'comment': 'Got it. I will add an assert.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/rel/core/TableFunctionScan.java,"@@ -64,6 +64,7 @@
    *
    * @param cluster        Cluster that this relational expression belongs to
    * @param inputs         0 or more relational inputs
+   * @param traitSet       Traits","[{'comment': 'Should we update Traits here too?', 'commenter': 'hsyuan'}, {'comment': 'Done.', 'commenter': 'chunweilei'}]"
1102,core/src/main/java/org/apache/calcite/rel/logical/LogicalTableFunctionScan.java,"@@ -45,11 +45,12 @@
    *
    * @param cluster        Cluster that this relational expression belongs to
    * @param inputs         0 or more relational inputs
-   * @param rexCall        function invocation expression
-   * @param elementType    element type of the collection that will implement
+   * @param traitSet       Traits","[{'comment': 'and this', 'commenter': 'hsyuan'}, {'comment': 'Done.', 'commenter': 'chunweilei'}]"
1104,core/src/test/java/org/apache/calcite/tools/PlannerTest.java,"@@ -996,6 +997,66 @@ private void checkBushy(String sql, String expected) throws Exception {
     assertThat(toString(transform), containsString(expected));
   }
 
+  private void checkFlattenTypesOnNestedColumn(String sql, String expected) throws Exception {","[{'comment': 'As fas as I can see the method only checks that the query has the expected plan and has nothing specific with type checking or nested columns. I think the name is a bit confusing and should be changed. Moreover I see the method checkBushy just above and I can see that there is a good part of code that is repeated. It would be good to refactor a bit the two methods.', 'commenter': 'zabetak'}, {'comment': ""I could change the name checkQueryPlan or some other better names you could think of.\r\n\r\nI actually wanted to merge the checkBushy and the new helper together. But actually it may be cleaner to keep them both because \r\n1. FrameworkConfig is different because default will only identify table `BOOKSTORE` but not `bookstore` and similar things.\r\n2. defaultSchema is different.\r\n3. More importantly, flow is different. checkBushy needs `project`, convert traitSet and transform while my test do not need them.\r\n\r\nIf I force to merge them, it won't necessarily make it better. That's why I did not merge them."", 'commenter': 'my7ym'}]"
1104,core/src/test/java/org/apache/calcite/tools/PlannerTest.java,"@@ -996,6 +997,66 @@ private void checkBushy(String sql, String expected) throws Exception {
     assertThat(toString(transform), containsString(expected));
   }
 
+  private void checkFlattenTypesOnNestedColumn(String sql, String expected) throws Exception {
+    final SchemaPlus rootSchema = Frameworks.createRootSchema(true);
+    final SqlParser.Config sqlParserConfig = SqlParser.configBuilder()
+        .setCaseSensitive(false)
+        .setUnquotedCasing(Casing.UNCHANGED)
+        .setQuotedCasing(Casing.UNCHANGED)
+        .build();
+    final FrameworkConfig config = Frameworks.newConfigBuilder()
+        .parserConfig(sqlParserConfig)
+        .defaultSchema(
+            CalciteAssert.addSchema(rootSchema,
+                CalciteAssert.SchemaSpec.BOOKSTORE))
+        .traitDefs((List<RelTraitDef>) null)
+        .build();
+    final Planner planner = Frameworks.getPlanner(config);
+    SqlNode parse = planner.parse(sql);
+    SqlNode validate = planner.validate(parse);
+    RelNode convert = planner.rel(validate).rel;
+    assertThat(toString(convert), containsString(expected));
+  }
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2900"">[CALCITE-2900]
+   * RewriteRexShuttle generates wrong type during flatten for structured type when
+   * visitInputRef</a>. */
+  @Test
+  public void testFlattenTypesWithFieldAccessOnFirstLevel() throws Exception {
+    String sql = """"","[{'comment': 'Is this query the minimun that reproduces the problem? For example, I tried removing group by and avg and the query still fails. Maybe it can be reduced even more. In every case I think it is nice to have the bare minimum that reproduces the problem. ', 'commenter': 'zabetak'}, {'comment': 'The current tests are great! I was just wondering if you could add a few lower level tests which address directly the problematic part of the flattener or even directly the RewriteRexShuttle. ', 'commenter': 'zabetak'}, {'comment': 'Thanks for detailed review and good catch! Will make the tests simpler and will try to add low-level tests', 'commenter': 'my7ym'}, {'comment': ""On a second though why not moving all the tests in SqlToRelConverterTest? Like that you don't need to introduce a separate checkQueryPlan method."", 'commenter': 'zabetak'}]"
1104,core/src/test/java/org/apache/calcite/test/BookstoreSchema.java,"@@ -90,16 +96,50 @@ public Author(int aid, String name, Place birthPlace, List<Book> books) {
   /**
    */
   public static class Place {
-    public final Coordinate coords;
     public final String city;
     public final String country;
+    public final double elevationInMeters;
+    public final Coordinate coords;
+    public final Area area;","[{'comment': ""Are the new fields necessary for demonstrating the problem? I suppose yes but can you clarify why ? I don't see tests on third level field access so I am wondering if it is really necessary to introduce Area."", 'commenter': 'zabetak'}, {'comment': ""I tested against elevationInMeters and Area.number.\r\n\r\nThe reason why they are necessary because the targeted type has to be different than the first field's type of the current level. Here, elevationInMeters type has to be different than city, and area.number has to be different than areaUnit."", 'commenter': 'my7ym'}]"
1104,core/src/test/java/org/apache/calcite/test/BookstoreSchema.java,"@@ -90,16 +96,50 @@ public Author(int aid, String name, Place birthPlace, List<Book> books) {
   /**
    */
   public static class Place {
-    public final Coordinate coords;
     public final String city;
     public final String country;
+    public final double elevationInMeters;","[{'comment': 'Out of curiosity why did you introduce elevationInMeters? City and country are fields at the same level; is to have different types?', 'commenter': 'zabetak'}, {'comment': 'Exactly man.', 'commenter': 'my7ym'}]"
1104,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -303,9 +303,11 @@ protected int getNewForOldInput(int oldOrdinal) {
    * corresponding field post-flattening, and also returns its type.
    *
    * @param oldOrdinal Pre-flattening ordinal
+   * @param existingOffset offset already calculated the target column inside the oldOrdinal column.
+   *                       For unnested column, it should be 0.
    * @return Post-flattening ordinal and type
    */
-  protected Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal) {
+  protected Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal, int existingOffset) {","[{'comment': 'Why protected and not private? Is it meant to be subclassed? ', 'commenter': 'zabetak'}, {'comment': ""Hmmm, to your question YES and I did this because in the past it is protected and it's not a final class. So I could not eliminate the possibility that somebody subclasses it.\r\n\r\nAnd thanks man you do remind me that I need to keep the original function signature because someone may subclass it. if there is a @override annotation then this change is not backward compatible. "", 'commenter': 'my7ym'}, {'comment': ""Oh, I re-read the code and actually I did not delete the original method. I will make it private since I don't see any points that people will override it. Good catch!"", 'commenter': 'my7ym'}]"
1104,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -303,9 +303,11 @@ protected int getNewForOldInput(int oldOrdinal) {
    * corresponding field post-flattening, and also returns its type.
    *
    * @param oldOrdinal Pre-flattening ordinal
+   * @param existingOffset offset already calculated the target column inside the oldOrdinal column.
+   *                       For unnested column, it should be 0.
    * @return Post-flattening ordinal and type
    */
-  protected Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal) {
+  private Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal, int existingOffset) {","[{'comment': '@zabetak Changed to private.', 'commenter': 'my7ym'}]"
1104,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -328,13 +330,24 @@ protected int getNewForOldInput(int oldOrdinal) {
     assert newInput != null;
 
     RelDataType oldInputType = oldInput.getRowType();
-    final int newOffset = calculateFlattenedOffset(oldInputType, oldOrdinal);
+    final int newOffset = calculateFlattenedOffset(oldInputType, oldOrdinal) + existingOffset;
     newOrdinal += newOffset;
     final RelDataTypeField field =
         newInput.getRowType().getFieldList().get(newOffset);
     return Ord.of(newOrdinal, field.getType());
   }
 
+  /**
+   * Maps the ordinal of a field pre-flattening to the ordinal of the
+   * corresponding field post-flattening, and also returns its type.
+   *
+   * @param oldOrdinal Pre-flattening ordinal
+   * @return Post-flattening ordinal and type
+   */
+  protected Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal) {","[{'comment': '@zabetak This is the old function signature so I have to keep them to keep backward compatibility.', 'commenter': 'my7ym'}]"
1104,core/src/test/java/org/apache/calcite/test/SqlToRelConverterTest.java,"@@ -2559,6 +2559,18 @@ public void testDynamicStarInTableJoin() throws Exception {
     sql(sql).with(getTesterWithDynamicTable()).ok();
   }
 
+  /**
+   * Test case for <a href=""https://issues.apache.org/jira/browse/CALCITE-2900"">[CALCITE-2900]
+   * RewriteRexShuttle generates wrong type during flatten for structured type when
+   * visitInputRef</a>.
+   */
+  @Test
+  public void testNestedColumn() {","[{'comment': '@zabetak This is the new a little ""low-level"" test I added. SqlToRelConverter.flattenTypes is almost the lowest level entry point for this test. The other option is RelStructuredTypeFlattener.rewrite. But for this test, I have to write a lot of boilerplate code for this single test. Since there is almost no extra logic applied in SqlToRelConverter.flattenTypes, I think it should be OK.\r\n\r\nLet me know. Thanks!', 'commenter': 'my7ym'}, {'comment': 'SqlToRelConverterTest is a good place. Actually it seems that you can move all the tests here. Moreover this new test does not bring something significant in comparison with the previous ones so I would suggest to remove it. ', 'commenter': 'zabetak'}]"
1104,core/src/test/java/org/apache/calcite/test/catalog/Fixture.java,"@@ -109,16 +109,23 @@
             .build();
     empListType =
         typeFactory.createArrayType(empRecordType, -1);
+
+    // Subclass ObjectSqlType to make nested field queryable.
     addressType =
-        new ObjectSqlType(SqlTypeName.STRUCTURED,
+        new ObjectSqlType(
+            SqlTypeName.STRUCTURED,","[{'comment': 'Changing only the BookStore schema should be sufficient to demonstrate what you want. In RelToSqlConverterTest you should only pass the appropriate SchemaSpec before writting your sql. ', 'commenter': 'zabetak'}, {'comment': 'Hey @zabetak, I tried this Bookstore schema in SqlToRelConverterTest. The change is much bigger than the original one because to add Bookstore schema in SqlToRelTestBase takes:\r\n1. Change TesterImpl type factory to JavaTypeFactoryImpl -> add withTypeFactory method in both Tester interface and impl.\r\n2. Do the same thing for RelOptPlanner in TesterImpl and replace it with a subclass of MockRelOptPlanner with traitset related method overrided. \r\n3. To support the Bookstore schema, we need make the CalciteSchema to be cached instead of existing simple, and make it case insensitive -> change MockCatalogReader constructor signature and subclass it to register bookstore schema.\r\n\r\nI think there is no need that we stick to Bookstore because there is already existing nested fields in MockCatalogReaderSimple. Another approach is to adapt the existing changes on Bookstore schema to MockCatalogReaderSimple (basically add one more layer deeper in a nested schema). And migrate existing changes in PlannerTest to SqlToRelConverterTest. IMO this approach is cleanest and also aligned with the existing tests.\r\n\r\nWhat do you think?', 'commenter': 'my7ym'}, {'comment': ""@zabetak And if you think OK, we could just keep the existing second-level-access test I implemented in SqlToRelConverterTest. I don't think there is much difference between the second level and the third level.\r\n\r\nIf so, I will delete all changes made to Bookstore and PlannerTest.\r\n\r\nlet me know."", 'commenter': 'my7ym'}, {'comment': 'Thanks for your detailed explanation @my7ym! Indeed, I was not expecting it to be so complicated. I agree with you, probably the best place is SqlToRelConverterTest and there is no need to touch the Bookstore schema.', 'commenter': 'zabetak'}, {'comment': 'No problem. Learnt a lot actually and more familiar with the code base :). Pls take another look man. Thanks.', 'commenter': 'my7ym'}]"
1104,core/src/test/java/org/apache/calcite/test/catalog/Fixture.java,"@@ -109,16 +109,23 @@
             .build();
     empListType =
         typeFactory.createArrayType(empRecordType, -1);
+
+    // Subclass ObjectSqlType to make nested field queryable.
     addressType =
-        new ObjectSqlType(SqlTypeName.STRUCTURED,
+        new ObjectSqlType(
+            SqlTypeName.STRUCTURED,
             new SqlIdentifier(""ADDRESS"", SqlParserPos.ZERO),
             false,
             Arrays.asList(
                 new RelDataTypeFieldImpl(""STREET"", 0, varchar20Type),
                 new RelDataTypeFieldImpl(""CITY"", 1, varchar20Type),
                 new RelDataTypeFieldImpl(""ZIP"", 2, intType),
                 new RelDataTypeFieldImpl(""STATE"", 3, varchar20Type)),
-            RelDataTypeComparability.NONE);
+            RelDataTypeComparability.NONE) {
+          @Override public StructKind getStructKind() {
+            return StructKind.PEEK_FIELDS_DEFAULT;","[{'comment': ""I guess before it was StructKind.FULLY_QUALIFIED, wasn't this enough to demonstrate the problem?"", 'commenter': 'zabetak'}, {'comment': 'Sorry that it was not enough to do that. It will make the nested column unrecognizable by part of the flow. In my personal project I used PEEK_FIELDS_DEFAULT, so I stick to it here.', 'commenter': 'my7ym'}]"
1104,core/src/test/java/org/apache/calcite/test/SqlToRelConverterTest.java,"@@ -2559,6 +2559,18 @@ public void testDynamicStarInTableJoin() throws Exception {
     sql(sql).with(getTesterWithDynamicTable()).ok();
   }
 
+  /**
+   * Test case for <a href=""https://issues.apache.org/jira/browse/CALCITE-2900"">[CALCITE-2900]
+   * RewriteRexShuttle generates wrong type during flatten for structured type when
+   * visitInputRef</a>.
+   */
+  @Test
+  public void testNestedColumn() {
+    final String sql =
+        ""select HOME_ADDRESS.ZIP from SALES.EMP_ADDRESS where HOME_ADDRESS.CITY = 'abc'"";","[{'comment': 'Minor: I guess it is just a matter of style but since the majority of tests use lowercase formatting for table and column identifiers maybe it is worth doing the same. Of-course it is not consistent all over the place so I have no strong preference on this.', 'commenter': 'zabetak'}, {'comment': 'Good call. Done.', 'commenter': 'my7ym'}]"
1110,core/src/main/java/org/apache/calcite/tools/RelBuilder.java,"@@ -1733,6 +1733,47 @@ public RelBuilder semiJoin(RexNode... conditions) {
     return semiJoin(ImmutableList.copyOf(conditions));
   }
 
+  /** Creates an AntiJoin: since, for the moment, there is no ""AntiJoin"" expression, the only
+   *  possibility to build an AntiJoin is using a LogicalCorrelate with SemiJoinType.ANTI */","[{'comment': 'Can you make this into a comment that is useful to the user? Explain what an ant-join is. A SQL example works well. \r\n\r\nMaybe add a similar description to `semiJoin`.\r\n\r\nDescription of the limitations of the algebra can be moved to a non-javadoc comment.', 'commenter': 'julianhyde'}, {'comment': 'reviewed', 'commenter': 'rubenada'}]"
1110,core/src/test/java/org/apache/calcite/test/RelBuilderTest.java,"@@ -1428,6 +1428,27 @@ private void project1(int value, SqlTypeName sqlTypeName, String message, String
     assertThat(root, hasTree(expected));
   }
 
+  @Test public void testAntiJoin() {
+    // Equivalent SQL:
+    //   SELECT * FROM dept d WHERE NOT EXISTS (SELECT 1 FROM emp e WHERE e.deptno = d.deptno)
+    final RelBuilder builder = RelBuilder.create(config().build());
+    RelNode root = builder","[{'comment': 'Indent should be 4 not 8', 'commenter': 'julianhyde'}]"
1110,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableCorrelateTest.java,"@@ -133,6 +134,37 @@
             ""empid=200"");
   }
 
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-2920"">[CALCITE-2920]
+   * RelBuilder: new method to create an antijoin</a> */
+  @Ignore(""Using withRel causes the forceDecorrelate=false property to be lost"")
+  @Test public void antiJoinCorrelate() {
+    tester(false, new JdbcTest.HrSchema())
+        .query(""?"")
+        .withRel(
+                // Retrieve departments without employees. Equivalent SQL:
+                //   SELECT d.deptno, d.name FROM depts d
+                //   WHERE NOT EXISTS (SELECT 1 FROM emps e WHERE e.deptno = d.deptno)
+                //   ORDER by d.deptno
+                builder -> builder
+                        .scan(""s"", ""depts"").as(""d"")
+                        .scan(""s"", ""emps"").as(""e"")
+                        .antiJoin(
+                                builder.equals(
+                                        builder.field(2, ""d"", ""deptno""),
+                                        builder.field(2, ""e"", ""deptno"")))
+                        .project(
+                                builder.field(""deptno""),
+                                builder.field(""name""))
+                        .sort(builder.field(""deptno""))
+                        .build()
+        )","[{'comment': 'close parens should not be on their own line', 'commenter': 'julianhyde'}]"
1112,core/src/main/java/org/apache/calcite/rel/rules/FilterCorrelateRule.java,"@@ -86,8 +86,10 @@ public void onMatch(RelOptRuleCall call) {
         aboveFilters,
         JoinRelType.INNER,
         false,
-        !corr.getJoinType().toJoinType().generatesNullsOnLeft(),
-        !corr.getJoinType().toJoinType().generatesNullsOnRight(),
+        corr.getJoinType().returnsJustFirstInput()
+            || !corr.getJoinType().toJoinType().generatesNullsOnLeft(),
+        !corr.getJoinType().returnsJustFirstInput()
+            && !corr.getJoinType().toJoinType().generatesNullsOnRight(),","[{'comment': 'I see what you are trying to do, but it really took me a while to understand. :)', 'commenter': 'hsyuan'}, {'comment': 'The idea is to avoid the `getJoinType().toJoinType()` call for SEMI and ANTI, which can be differentiated because they both have `getJoinType().returnsJustFirstInput() == true`', 'commenter': 'rubenada'}]"
1112,core/src/main/java/org/apache/calcite/rel/rules/FilterCorrelateRule.java,"@@ -86,8 +86,10 @@ public void onMatch(RelOptRuleCall call) {
         aboveFilters,
         JoinRelType.INNER,
         false,
-        !corr.getJoinType().toJoinType().generatesNullsOnLeft(),
-        !corr.getJoinType().toJoinType().generatesNullsOnRight(),
+        corr.getJoinType().returnsJustFirstInput()","[{'comment': ""Can't this be replaced with `true`? The SemiJoinType can never be RIGHT or FULL so in any case the filters can be pushed into the left relation because it never generates nulls."", 'commenter': 'zabetak'}, {'comment': 'Stupid question: are we 100% sure that in the future we will never add new join types (RIGHT / FULL) to SemiJoinType enum?', 'commenter': 'rubenada'}, {'comment': 'No we are not sure yet adding new types in a public enumerations affects backward compatibility so I guess it will not happen often. If at some point in the future somebody does that he will have to consider usecases like this one.', 'commenter': 'zabetak'}, {'comment': ""Ok, I'll simplify then this line and the next one"", 'commenter': 'rubenada'}]"
1112,core/src/main/java/org/apache/calcite/rel/rules/FilterCorrelateRule.java,"@@ -86,8 +86,10 @@ public void onMatch(RelOptRuleCall call) {
         aboveFilters,
         JoinRelType.INNER,
         false,
-        !corr.getJoinType().toJoinType().generatesNullsOnLeft(),
-        !corr.getJoinType().toJoinType().generatesNullsOnRight(),
+        corr.getJoinType().returnsJustFirstInput()
+            || !corr.getJoinType().toJoinType().generatesNullsOnLeft(),
+        !corr.getJoinType().returnsJustFirstInput()","[{'comment': ""Can't this be replaced with `corr.getJoinType()==SemiJoinType.INNER`. The only time where we can push the filter into the right relation is for SemiJoinType.INNER. In any other the case the right side either generates nulls either does not exist. "", 'commenter': 'zabetak'}]"
1112,core/src/main/java/org/apache/calcite/plan/RelOptUtil.java,"@@ -2380,6 +2381,8 @@ public static boolean classifyFilters(
         joinRel.getInputs().get(1).getRowType().getFieldList();
     final int nFieldsRight = rightFields.size();
     assert nTotalFields == (joinRel instanceof SemiJoin","[{'comment': ""If I am not mistaken nSysFields is not used anymore and is always zero. If that's the case can you remove it please. Moreover the assertion looks a bit weird (plus a bit trivial). If the method cannot treat all kinds of joins then that should be a precondition with an IllegalArgumentException and not an assertion. I would be inclined to remove entirely this assertion. "", 'commenter': 'zabetak'}, {'comment': 'I agree, this assert starts to become too complex (a sort of ""switch"" to detect all the special cases where the joinRel generates only the left side fields) to verify something that is not the responsibility of this static method. Probably it would be better to just remove it.', 'commenter': 'rubenada'}, {'comment': 'The goal of the assert is to educate future readers and maintainers of this code. In this case, try refactoring the assert to improve clarity.\r\n\r\nThe maintainer of the code does need to know about all that complexity (in particular how complex the type hierarchy of Join, Correlate and SemiJoin has gotten). Removing the assert is just sweeping the issue under the rug. We should be embarrassed about the complexity and strive to fix it.', 'commenter': 'julianhyde'}, {'comment': '(I just discovered that `Correlate`, which is neither a Join nor a SemiJoin, uses `SemiJoinType`, but `SemiJoin` does not use `SemiJoinType`. Yuck.)', 'commenter': 'julianhyde'}, {'comment': ""I totally agree that the hierarchy of Correlate, Join, etc., needs to be redesigned but I don't think this can/should be done as part of this issue.\r\n\r\nRegarding the assertion, I think it is a bit misplaced; it verifies how many fields the join has in relation with its inputs (depending also on the type). Such an assertion would appear reasonable if it was introduced when the respective operators are created but not in a method which is a mere consumer of the operator. "", 'commenter': 'zabetak'}, {'comment': 'Hey @julianhyde, what do you think of my previous comment? Do you still think we should keep the assertion here? ', 'commenter': 'zabetak'}, {'comment': ""I think the assert is really useful. It tells the maintainer of the code what they are dealing with.\r\n\r\nIt's ugly because we have a mess to clean up. Leave it until we've cleaned up the mess.\r\n\r\nIf we wanted an invariant, then we'd use `Objects` or `Preconditions` methods that, unlike `assert`, do not disappear, and we'd add them to the constructor."", 'commenter': 'julianhyde'}, {'comment': ""Thanks all for your comments. The purpose of this PR is just to fix the IllegalStateException in FilterCorrelateRule.java, so I'd say let's keep the assert, and I'll squash the commits so this can be merged."", 'commenter': 'rubenada'}, {'comment': ""Fine by me although I have a small remark. The way you modified the code right now the if statements are going to be executed even if assertions are disabled. I don't know if JIT is intelligent enough to remove entirely the redundant if but I don't think we should rely on that. Furthemore, to make it more readable you could possibly extra the check into a method, but feel free to modify as you see fit I don't feel strongly about it."", 'commenter': 'zabetak'}, {'comment': ""Ok, I'll refactor the code to use an auxiliary method to check the condition"", 'commenter': 'rubenada'}]"
1143,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -2806,6 +2810,70 @@ private static Integer getJsonDepth(Object o) {
     return depth;
   }
 
+  private static String jsonPairsModify(Object jsonDoc, String type, Object... kvs) {
+    assert kvs.length % 2 == 0;","[{'comment': ""Please help me understand if there were challenges using JSON Path. I'm sorry if it too obvious. https://stackoverflow.com/questions/27244431/how-to-change-values-in-a-json-file-using-xpath-jsonpath-in-java"", 'commenter': 'ritesh-kapoor'}, {'comment': 'hi @ritesh-kapoor Thank you very much. I have seen that jsonpath source code has modified this PR.', 'commenter': 'XuQianJin-Stars'}]"
1143,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -95,6 +95,9 @@
   @BaseMessage(""Illegal identifier '':''. Was expecting ''VALUE''"")
   ExInst<CalciteException> illegalColon();
 
+  @BaseMessage(""Illegal identifier '',''. Was expecting ''VALUE''"")
+  ExInst<CalciteException> illegalComma();","[{'comment': ""I didn't find any usage of this new added method. Am I missing something?"", 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -888,6 +891,15 @@
 
   @BaseMessage(""Not a valid input for JSON_STORAGE_SIZE: ''{0}''"")
   ExInst<CalciteException> invalidInputForJsonStorageSize(String value);
+
+  @BaseMessage(""Not a valid input for JSON_INSERT: jsonDoc: ''{0}'', kvs: ''{1}''"")
+  ExInst<CalciteException> invalidInputForJsonInsert(String jsonDoc, String kvs);","[{'comment': 'Could you please use ""Invalid input"" rather than ""Not a valid input""? Following are several arguments, not just one.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -638,12 +641,120 @@ public static Integer jsonStorageSize(String input) {
   public static Integer jsonStorageSize(JsonValueContext input) {
     try {
       return JSON_PATH_JSON_PROVIDER.getObjectMapper()
-          .writeValueAsBytes(input.obj).length;
+              .writeValueAsBytes(input.obj).length;","[{'comment': 'Indent is not right, please redo the change.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -638,12 +641,120 @@ public static Integer jsonStorageSize(String input) {
   public static Integer jsonStorageSize(JsonValueContext input) {
     try {
       return JSON_PATH_JSON_PROVIDER.getObjectMapper()
-          .writeValueAsBytes(input.obj).length;
+              .writeValueAsBytes(input.obj).length;
     } catch (Exception e) {
       throw RESOURCE.invalidInputForJsonStorageSize(Objects.toString(input.obj)).ex();
     }
   }
 
+  private static String jsonPairsModify(Object jsonDoc, String type, Object... kvs) {
+    assert kvs.length % 2 == 0;
+    String result = """";
+    Map<String, Object> map = new HashMap<>();
+    DocumentContext ctx = JsonPath.parse(jsonDoc.toString(),
+            Configuration
+                    .builder()
+                    .options(Option.SUPPRESS_EXCEPTIONS)
+                    .jsonProvider(JSON_PATH_JSON_PROVIDER)
+                    .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
+                    .build());
+
+    for (int i = 0; i < kvs.length; i += 2) {
+      String k = (String) kvs[i];
+      Object v = kvs[i + 1];
+      if (JsonPath.isPathDefinite(k) && k.contains(JSON_ROOT_PATH)) {
+        map.put(k, v);
+      } else {
+        throw RESOURCE.validationError(k).ex();
+      }
+    }
+
+    for (Map.Entry<String, Object> entry : map.entrySet()) {
+      String k = entry.getKey();
+      Object v = entry.getValue();
+      switch (type) {
+      case ""replace"":","[{'comment': 'Any reason not to use an Enum instance to represent ""type""?', 'commenter': 'zhztheplayer'}, {'comment': 'Also, it would be better we can integrate JSON_REMOVE with a ""remove"" type.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -638,12 +641,120 @@ public static Integer jsonStorageSize(String input) {
   public static Integer jsonStorageSize(JsonValueContext input) {
     try {
       return JSON_PATH_JSON_PROVIDER.getObjectMapper()
-          .writeValueAsBytes(input.obj).length;
+              .writeValueAsBytes(input.obj).length;
     } catch (Exception e) {
       throw RESOURCE.invalidInputForJsonStorageSize(Objects.toString(input.obj)).ex();
     }
   }
 
+  private static String jsonPairsModify(Object jsonDoc, String type, Object... kvs) {
+    assert kvs.length % 2 == 0;
+    String result = """";
+    Map<String, Object> map = new HashMap<>();
+    DocumentContext ctx = JsonPath.parse(jsonDoc.toString(),
+            Configuration
+                    .builder()
+                    .options(Option.SUPPRESS_EXCEPTIONS)
+                    .jsonProvider(JSON_PATH_JSON_PROVIDER)
+                    .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
+                    .build());
+
+    for (int i = 0; i < kvs.length; i += 2) {
+      String k = (String) kvs[i];
+      Object v = kvs[i + 1];
+      if (JsonPath.isPathDefinite(k) && k.contains(JSON_ROOT_PATH)) {
+        map.put(k, v);
+      } else {
+        throw RESOURCE.validationError(k).ex();
+      }
+    }
+
+    for (Map.Entry<String, Object> entry : map.entrySet()) {
+      String k = entry.getKey();
+      Object v = entry.getValue();
+      switch (type) {
+      case ""replace"":
+        if (k.equals(JSON_ROOT_PATH)) {
+          result = jsonize(v);
+        } else {
+          if (ctx.read(k) != null) {
+            ctx.set(k, v);
+          }
+        }
+        break;
+      case ""insert"":
+        if ((!k.equals(JSON_ROOT_PATH)) && (ctx.read(k) == null)) {
+          insertToJson(ctx, k, v);
+        }
+        break;
+      case ""set"":
+        if (k.equals(JSON_ROOT_PATH)) {
+          result = jsonize(v);
+        } else {
+          if (ctx.read(k) != null) {
+            ctx.set(k, v);
+          } else {
+            insertToJson(ctx, k, v);
+          }
+        }
+        break;
+      }
+    }
+    result = Strings.isNullOrEmpty(result) ?  ctx.jsonString() : result;
+    return result;
+  }
+
+  private static void insertToJson(DocumentContext ctx, String path, Object value) {
+    final String preantPath;
+    final String key;
+    Integer dotIndex = path.lastIndexOf(""."");
+    Integer leftBracketIndex = path.lastIndexOf(""["");
+    if (dotIndex.equals(-1) && leftBracketIndex.equals(-1)) {
+      preantPath = path;
+      key = path;
+    } else if (!dotIndex.equals(-1) && leftBracketIndex.equals(-1)) {
+      preantPath = path.substring(0, dotIndex);
+      key = path.substring(dotIndex + 1);
+    } else if (dotIndex.equals(-1) && !leftBracketIndex.equals(-1)) {
+      preantPath = path.substring(0, leftBracketIndex);
+      key = path.substring(leftBracketIndex + 1);
+    } else {
+      Integer position = dotIndex > leftBracketIndex ? dotIndex : leftBracketIndex;
+      preantPath = path.substring(0, position);
+      key = path.substring(position);
+    }
+    Object obj = ctx.read(preantPath);
+    if (obj instanceof Map) {
+      ctx.put(preantPath, key, value.toString());
+    } else if (obj instanceof Collection) {
+      ctx.add(preantPath, value);
+    }
+  }
+
+  public static String jsonInsert(Object jsonDoc, Object... kvs) {","[{'comment': ""Please add support for string input. We should support both String and JsonValueContext as the first input argument for such methods. Don't use Object. You can take JSON_REMOVE as an example."", 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/sql/fun/SqlJsonInsertFunction.java,"@@ -0,0 +1,108 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.SqlWriter;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlOperandTypeChecker;
+import org.apache.calcite.sql.type.SqlTypeUtil;
+import org.apache.calcite.sql.validate.SqlValidator;
+
+import java.util.Locale;
+
+import static org.apache.calcite.util.Static.RESOURCE;
+
+/**
+ * The <code>JSON_INSERT</code> function.
+ */
+public class SqlJsonInsertFunction extends SqlFunction {
+  public SqlJsonInsertFunction() {
+    super(""JSON_INSERT"", SqlKind.OTHER_FUNCTION, ReturnTypes.VARCHAR_2000, null,","[{'comment': ""Sometimes we return null for JSON functions without necessarily any null input. Unless we are sure that the functions doesn't produce nulls, we should force the return type to nullable in validation. See  JSON_REMOVE as an example."", 'commenter': 'zhztheplayer'}]"
1143,core/src/test/java/org/apache/calcite/test/SqlJsonFunctionsTest.java,"@@ -521,13 +521,48 @@
 
   @Test public void testJsonRemove() {
     assertJsonRemove(
-        JsonFunctions.jsonValueExpression(""{\""a\"": 1, \""b\"": [2]}""),
-        new String[]{""$.a""},
-        is(""{\""b\"":[2]}""));
+            JsonFunctions.jsonValueExpression(""{\""a\"": 1, \""b\"": [2]}""),","[{'comment': 'Please make sure you use the right indent: the continuous indention is 4 in Calcite code. So do codes in other new added methods.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/sql/fun/SqlJsonInsertFunction.java,"@@ -0,0 +1,108 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.SqlWriter;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlOperandTypeChecker;
+import org.apache.calcite.sql.type.SqlTypeUtil;
+import org.apache.calcite.sql.validate.SqlValidator;
+
+import java.util.Locale;
+
+import static org.apache.calcite.util.Static.RESOURCE;
+
+/**
+ * The <code>JSON_INSERT</code> function.
+ */
+public class SqlJsonInsertFunction extends SqlFunction {
+  public SqlJsonInsertFunction() {
+    super(""JSON_INSERT"", SqlKind.OTHER_FUNCTION, ReturnTypes.VARCHAR_2000, null,
+        null, SqlFunctionCategory.SYSTEM);
+  }
+
+  @Override public SqlOperandCountRange getOperandCountRange() {
+    return SqlOperandCountRanges.from(3);
+  }
+
+  @Override protected void checkOperandCount(SqlValidator validator,
+      SqlOperandTypeChecker argType, SqlCall call) {
+    assert (call.operandCount() >= 3) && (call.operandCount() % 2 == 1);
+  }
+
+  @Override public boolean checkOperandTypes(SqlCallBinding callBinding,
+      boolean throwOnFailure) {
+    final int count = callBinding.getOperandCount();
+    for (int i = 1; i < count; i += 2) {
+      RelDataType nameType = callBinding.getOperandType(i);
+      if (!SqlTypeUtil.inCharFamily(nameType)) {
+        if (throwOnFailure) {
+          throw callBinding.newError(RESOURCE.expectedCharacter());
+        }
+        return false;
+      }
+      if (nameType.isNullable()) {
+        if (throwOnFailure) {
+          throw callBinding.newError(
+              RESOURCE.argumentMustNotBeNull(
+                  callBinding.operand(i).toString()));
+        }
+        return false;
+      }
+    }
+    return true;
+  }
+
+  @Override public String getSignatureTemplate(int operandsCount) {
+    assert operandsCount % 2 == 1;
+    StringBuilder sb = new StringBuilder();
+    sb.append(""{0}("");
+    for (int i = 1; i < operandsCount; i++) {
+      sb.append(String.format(Locale.ROOT, ""{%d} "", i + 1));
+    }
+    sb.append(""{1})"");
+    return sb.toString();
+  }
+
+  @Override public void unparse(SqlWriter writer, SqlCall call, int leftPrec,
+      int rightPrec) {
+    assert call.operandCount() % 2 == 1;
+    final SqlWriter.Frame frame = writer.startFunCall(getName());
+    call.operand(0).unparse(writer, 0, 0);
+    SqlWriter.Frame listFrame = writer.startList("""", """");
+    writer.sep("","");
+    for (int i = 1; i < call.operandCount(); i += 2) {
+      writer.sep("","");
+      writer.keyword(""KEY"");","[{'comment': ""I remember that the keywords `KEY`/`VALUE` are added for JSON_OBJECT(AGG) functions. I don't think MySQL's JSON functions have similar syntax. Could you please double check (the same to JSON_SET, JSON_REPLACE)? Also, if you copied codes from another place, please make sure every line you copied is reasonable for staying at the new place."", 'commenter': 'zhztheplayer'}]"
1143,core/src/test/java/org/apache/calcite/sql/test/SqlOperatorBaseTest.java,"@@ -4659,6 +4659,49 @@ private void checkNullOperand(SqlTester tester, String op) {
     tester.checkNull(""json_depth(cast(null as varchar))"");
   }
 
+  @Test public void testJsonInsert() {
+    tester.checkString(""json_insert('10', '$.a', 10, '$.c', '[true]')"",
+            ""10"", ""VARCHAR(2000) NOT NULL"");
+    tester.checkString(""json_insert('{ \""a\"": 1, \""b\"": [2]}', '$.a', 10, '$.c', '[true]')"",
+            ""{\""a\"":1,\""b\"":[2],\""c\"":\""[true]\""}"", ""VARCHAR(2000) NOT NULL"");
+    tester.checkString(""json_insert('{ \""a\"": 1, \""b\"": [2]}', '$', 10, '$', '[true]')"",
+            ""{\""a\"":1,\""b\"":[2]}"", ""VARCHAR(2000) NOT NULL"");
+    tester.checkString(""json_insert('{ \""a\"": 1, \""b\"": [2]}', '$.b[1]', 10)"",
+            ""{\""a\"":1,\""b\"":[2,10]}"", ""VARCHAR(2000) NOT NULL"");
+    tester.checkString(""json_insert('{\""a\"": 1, \""b\"": [2, 3, [true]]}', '$.b[3]', 'false')"",
+            ""{\""a\"":1,\""b\"":[2,3,[true],\""false\""]}"", ""VARCHAR(2000) NOT NULL"");
+    tester.checkFails(""json_insert('{\""a\"": 1, \""b\"": [2, 3, [true]]}', 'a', 'false')"",
+            ""(?s).*Not a valid input for.*"", true);","[{'comment': 'Please add some null checks as well as we have done for other methods (the checks are now always located at the tail of test method body).', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -791,6 +912,38 @@ public boolean hasException() {
     UNKNOWN,
     NONE
   }
+
+  /**
+   * Used in the JsonModify function.
+   */
+  public enum JsonModifyMode {
+    REPLACE(""replace""),
+
+    INSERT(""insert""),
+
+    SET(""set""),
+
+    REMOVE(""remove"");
+
+    String type;
+
+    JsonModifyMode(String type) {
+      this.type = type;
+    }
+
+    public String getType() {","[{'comment': 'We can remove this method (and the other `getType` method), then use the Enum instance directly.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -606,41 +608,160 @@ public static String jsonKeys(JsonPathContext context) {
     return jsonize(list);
   }
 
-  public static String jsonRemove(String input, String... pathSpecs) {
-    return jsonRemove(jsonValueExpression(input), pathSpecs);
+  public static Integer jsonStorageSize(String input) {
+    return jsonStorageSize(jsonValueExpression(input));
   }
 
-  public static String jsonRemove(JsonValueContext input, String... pathSpecs) {
+  public static Integer jsonStorageSize(JsonValueContext input) {
     try {
-      DocumentContext ctx = JsonPath.parse(input.obj,
-          Configuration
-              .builder()
-              .options(Option.SUPPRESS_EXCEPTIONS)
-              .jsonProvider(JSON_PATH_JSON_PROVIDER)
-              .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
-              .build());
-      for (String pathSpec : pathSpecs) {
+      return JSON_PATH_JSON_PROVIDER.getObjectMapper()
+          .writeValueAsBytes(input.obj).length;
+    } catch (Exception e) {
+      throw RESOURCE.invalidInputForJsonStorageSize(Objects.toString(input.obj)).ex();
+    }
+  }
+
+  private static String jsonModify(JsonValueContext jsonDoc, String type, Object... kvs) {
+    JsonModifyMode jsonPairsType = JsonModifyMode.getType(type);
+    if (jsonPairsType != JsonModifyMode.REMOVE) {
+        assert kvs.length % 2 == 0;
+    }
+    String result = """";","[{'comment': 'If I am not wrong. Per operator definition return types of all these methods are nullable. Please either use null or throw error rather than returning empty string when something unexpected occurs.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -606,41 +608,160 @@ public static String jsonKeys(JsonPathContext context) {
     return jsonize(list);
   }
 
-  public static String jsonRemove(String input, String... pathSpecs) {
-    return jsonRemove(jsonValueExpression(input), pathSpecs);
+  public static Integer jsonStorageSize(String input) {
+    return jsonStorageSize(jsonValueExpression(input));
   }
 
-  public static String jsonRemove(JsonValueContext input, String... pathSpecs) {
+  public static Integer jsonStorageSize(JsonValueContext input) {
     try {
-      DocumentContext ctx = JsonPath.parse(input.obj,
-          Configuration
-              .builder()
-              .options(Option.SUPPRESS_EXCEPTIONS)
-              .jsonProvider(JSON_PATH_JSON_PROVIDER)
-              .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
-              .build());
-      for (String pathSpec : pathSpecs) {
+      return JSON_PATH_JSON_PROVIDER.getObjectMapper()
+          .writeValueAsBytes(input.obj).length;
+    } catch (Exception e) {
+      throw RESOURCE.invalidInputForJsonStorageSize(Objects.toString(input.obj)).ex();
+    }
+  }
+
+  private static String jsonModify(JsonValueContext jsonDoc, String type, Object... kvs) {
+    JsonModifyMode jsonPairsType = JsonModifyMode.getType(type);
+    if (jsonPairsType != JsonModifyMode.REMOVE) {
+        assert kvs.length % 2 == 0;
+    }
+    String result = """";
+    DocumentContext ctx = JsonPath.parse(jsonDoc.obj,
+        Configuration
+            .builder()
+            .options(Option.SUPPRESS_EXCEPTIONS)
+            .jsonProvider(JSON_PATH_JSON_PROVIDER)
+            .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
+            .build());
+
+    if (jsonPairsType == JsonModifyMode.REMOVE) {
+      for (Object kv : kvs) {
+        String pathSpec = (String) kv;
         if ((pathSpec != null) && (ctx.read(pathSpec) != null)) {
           ctx.delete(pathSpec);
         }
       }
-      return ctx.jsonString();
+    } else {
+      Map<String, Object> map = new HashMap<>();
+      for (int i = 0; i < kvs.length; i += 2) {
+        String k = (String) kvs[i];
+        Object v = kvs[i + 1];
+        if (JsonPath.isPathDefinite(k) && k.contains(JSON_ROOT_PATH)) {
+          map.put(k, v);
+        } else {
+          throw RESOURCE.validationError(k).ex();
+        }
+      }
+
+      for (Map.Entry<String, Object> entry : map.entrySet()) {
+        String k = entry.getKey();
+        Object v = entry.getValue();
+        switch (jsonPairsType) {
+        case REPLACE:
+          if (k.equals(JSON_ROOT_PATH)) {
+            result = jsonize(v);
+          } else {
+            if (ctx.read(k) != null) {
+              ctx.set(k, v);
+            }
+          }
+          break;
+        case INSERT:
+          if ((!k.equals(JSON_ROOT_PATH)) && (ctx.read(k) == null)) {
+            insertToJson(ctx, k, v);
+          }
+          break;
+        case SET:
+          if (k.equals(JSON_ROOT_PATH)) {
+            result = jsonize(v);
+          } else {
+            if (ctx.read(k) != null) {
+              ctx.set(k, v);
+            } else {
+              insertToJson(ctx, k, v);
+            }
+          }
+          break;
+        }
+      }
+    }
+    result = Strings.isNullOrEmpty(result) ?  ctx.jsonString() : result;
+    return result;
+  }
+
+  private static void insertToJson(DocumentContext ctx, String path, Object value) {
+    final String preantPath;","[{'comment': 's/preant/parent', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -606,41 +608,160 @@ public static String jsonKeys(JsonPathContext context) {
     return jsonize(list);
   }
 
-  public static String jsonRemove(String input, String... pathSpecs) {
-    return jsonRemove(jsonValueExpression(input), pathSpecs);
+  public static Integer jsonStorageSize(String input) {
+    return jsonStorageSize(jsonValueExpression(input));
   }
 
-  public static String jsonRemove(JsonValueContext input, String... pathSpecs) {
+  public static Integer jsonStorageSize(JsonValueContext input) {
     try {
-      DocumentContext ctx = JsonPath.parse(input.obj,
-          Configuration
-              .builder()
-              .options(Option.SUPPRESS_EXCEPTIONS)
-              .jsonProvider(JSON_PATH_JSON_PROVIDER)
-              .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
-              .build());
-      for (String pathSpec : pathSpecs) {
+      return JSON_PATH_JSON_PROVIDER.getObjectMapper()
+          .writeValueAsBytes(input.obj).length;
+    } catch (Exception e) {
+      throw RESOURCE.invalidInputForJsonStorageSize(Objects.toString(input.obj)).ex();
+    }
+  }
+
+  private static String jsonModify(JsonValueContext jsonDoc, String type, Object... kvs) {
+    JsonModifyMode jsonPairsType = JsonModifyMode.getType(type);
+    if (jsonPairsType != JsonModifyMode.REMOVE) {
+        assert kvs.length % 2 == 0;
+    }
+    String result = """";
+    DocumentContext ctx = JsonPath.parse(jsonDoc.obj,
+        Configuration
+            .builder()
+            .options(Option.SUPPRESS_EXCEPTIONS)
+            .jsonProvider(JSON_PATH_JSON_PROVIDER)
+            .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
+            .build());
+
+    if (jsonPairsType == JsonModifyMode.REMOVE) {
+      for (Object kv : kvs) {
+        String pathSpec = (String) kv;
         if ((pathSpec != null) && (ctx.read(pathSpec) != null)) {
           ctx.delete(pathSpec);
         }
       }
-      return ctx.jsonString();
+    } else {
+      Map<String, Object> map = new HashMap<>();
+      for (int i = 0; i < kvs.length; i += 2) {
+        String k = (String) kvs[i];
+        Object v = kvs[i + 1];
+        if (JsonPath.isPathDefinite(k) && k.contains(JSON_ROOT_PATH)) {
+          map.put(k, v);
+        } else {
+          throw RESOURCE.validationError(k).ex();
+        }
+      }
+
+      for (Map.Entry<String, Object> entry : map.entrySet()) {
+        String k = entry.getKey();
+        Object v = entry.getValue();
+        switch (jsonPairsType) {
+        case REPLACE:
+          if (k.equals(JSON_ROOT_PATH)) {
+            result = jsonize(v);
+          } else {
+            if (ctx.read(k) != null) {
+              ctx.set(k, v);
+            }
+          }
+          break;
+        case INSERT:
+          if ((!k.equals(JSON_ROOT_PATH)) && (ctx.read(k) == null)) {
+            insertToJson(ctx, k, v);
+          }
+          break;
+        case SET:
+          if (k.equals(JSON_ROOT_PATH)) {
+            result = jsonize(v);
+          } else {
+            if (ctx.read(k) != null) {
+              ctx.set(k, v);
+            } else {
+              insertToJson(ctx, k, v);
+            }
+          }
+          break;
+        }
+      }
+    }
+    result = Strings.isNullOrEmpty(result) ?  ctx.jsonString() : result;
+    return result;
+  }
+
+  private static void insertToJson(DocumentContext ctx, String path, Object value) {
+    final String preantPath;
+    final String key;
+    Integer dotIndex = path.lastIndexOf(""."");
+    Integer leftBracketIndex = path.lastIndexOf(""["");
+    if (dotIndex.equals(-1) && leftBracketIndex.equals(-1)) {","[{'comment': 'The block of if...else if...else if... is hard to understand. I see you were trying to parse the jsonpath specification by your self. Can we avoid such a implementation? Or could you please explain a bit how it works?', 'commenter': 'zhztheplayer'}, {'comment': '> The block of if...else if...else if... is hard to understand. I see you were trying to parse the jsonpath specification by your self. Can we avoid such a implementation? Or could you please explain a bit how it works?\r\n\r\nUsed to get the parent node', 'commenter': 'XuQianJin-Stars'}]"
1143,core/src/main/java/org/apache/calcite/runtime/JsonFunctions.java,"@@ -606,41 +608,160 @@ public static String jsonKeys(JsonPathContext context) {
     return jsonize(list);
   }
 
-  public static String jsonRemove(String input, String... pathSpecs) {
-    return jsonRemove(jsonValueExpression(input), pathSpecs);
+  public static Integer jsonStorageSize(String input) {
+    return jsonStorageSize(jsonValueExpression(input));
   }
 
-  public static String jsonRemove(JsonValueContext input, String... pathSpecs) {
+  public static Integer jsonStorageSize(JsonValueContext input) {
     try {
-      DocumentContext ctx = JsonPath.parse(input.obj,
-          Configuration
-              .builder()
-              .options(Option.SUPPRESS_EXCEPTIONS)
-              .jsonProvider(JSON_PATH_JSON_PROVIDER)
-              .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
-              .build());
-      for (String pathSpec : pathSpecs) {
+      return JSON_PATH_JSON_PROVIDER.getObjectMapper()
+          .writeValueAsBytes(input.obj).length;
+    } catch (Exception e) {
+      throw RESOURCE.invalidInputForJsonStorageSize(Objects.toString(input.obj)).ex();
+    }
+  }
+
+  private static String jsonModify(JsonValueContext jsonDoc, String type, Object... kvs) {
+    JsonModifyMode jsonPairsType = JsonModifyMode.getType(type);
+    if (jsonPairsType != JsonModifyMode.REMOVE) {
+        assert kvs.length % 2 == 0;
+    }
+    String result = """";
+    DocumentContext ctx = JsonPath.parse(jsonDoc.obj,
+        Configuration
+            .builder()
+            .options(Option.SUPPRESS_EXCEPTIONS)
+            .jsonProvider(JSON_PATH_JSON_PROVIDER)
+            .mappingProvider(JSON_PATH_MAPPING_PROVIDER)
+            .build());
+
+    if (jsonPairsType == JsonModifyMode.REMOVE) {","[{'comment': 'Can we generalize JsonModifyMode.REMOVE into the switch block below?', 'commenter': 'zhztheplayer'}]"
1143,site/_docs/reference.md,"@@ -2099,8 +2099,11 @@ semantics.
 | m | JSON_DEPTH(jsonValue)                          | Returns an integer value indicating the depth of a *jsonValue*
 | m | JSON_PRETTY(jsonValue)                         | Returns a pretty-printing of *jsonValue*
 | m | JSON_LENGTH(jsonValue [, path ])               | Returns a integer indicating the length of *jsonValue*
+| m | JSON_INSERT(jsonValue, path, val[, path, val])  | Returns a JSON document insert a data of *jsonValue*, *path*, *val*
 | m | JSON_KEYS(jsonValue [, path ])                 | Returns a string indicating the keys of a JSON *jsonValue*
 | m | JSON_REMOVE(jsonValue, path[, path])           | Removes data from *jsonValue* using a series of *path* expressions and returns the result
+| m | JSON_REPLACE(jsonValue, path, val[, path, val])  | Returns a JSON document replace a data of *jsonValue*, *path*, *val*
+| m | JSON_SET(jsonValue, path, val[, path, val])  | Returns a JSON document set a data of *jsonValue*, *path*, *val*","[{'comment': 'Could you please update the explanation about null cases in the ""Note:"" section below accordingly?', 'commenter': 'zhztheplayer'}, {'comment': 'is `[, path, val]` part means we can have more than one pair of `path` -> `val`, if that is the case, please add a ""*"" after that.', 'commenter': 'danny0405'}]"
1143,core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties,"@@ -38,6 +38,7 @@ IllegalBinaryString=Illegal binary string {0}
 IllegalFromEmpty=''FROM'' without operands preceding it is illegal
 IllegalRowExpression=ROW expression encountered in illegal context
 IllegalColon=Illegal identifier '':''. Was expecting ''VALUE''
+IllegalComma=Illegal identifier '',''. Was expecting ''VALUE''","[{'comment': 'Is this line redundant?', 'commenter': 'zhztheplayer'}]"
1143,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -11067,6 +11067,30 @@ private void checkCustomColumnResolving(String table) {
             ""(?s).*Invalid number of arguments.*"");
   }
 
+  @Test public void testJsonInsert() {
+    checkExp(""json_insert('{ \""a\"": 1, \""b\"": [2]}', '$.a', 10, '$.c', '[true]')"");
+    checkExpType(""json_insert('{ \""a\"": 1, \""b\"": [2]}', '$.a', 10, '$.c', '[true]')"",
+            ""VARCHAR(2000)"");
+    checkFails(""select ^json_insert('{\""foo\"":\""bar\""}')^"",
+            ""(?s).*Invalid number of arguments.*"");
+  }
+
+  @Test public void testJsonReplace() {
+    checkExp(""json_replace('{ \""a\"": 1, \""b\"": [2]}', '$.a', 10, '$.c', '[true]')"");
+    checkExpType(""json_replace('{ \""a\"": 1, \""b\"": [2]}', '$.a', 10, '$.c', '[true]')"",
+            ""VARCHAR(2000)"");","[{'comment': 'The indents are still incorrect.', 'commenter': 'zhztheplayer'}]"
1143,core/src/main/java/org/apache/calcite/sql/fun/SqlJsonInsertFunction.java,"@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlOperandTypeChecker;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.sql.type.SqlTypeUtil;
+import org.apache.calcite.sql.validate.SqlValidator;
+
+import java.util.Locale;
+
+import static org.apache.calcite.util.Static.RESOURCE;
+
+/**
+ * The <code>JSON_INSERT</code> function.
+ */
+public class SqlJsonInsertFunction extends SqlFunction {
+  public SqlJsonInsertFunction() {
+    super(""JSON_INSERT"",","[{'comment': 'The 3 new `SqlJsonXXXFunction` you add almost have the same implementation, please abstract a base class for them.', 'commenter': 'danny0405'}]"
1143,core/src/main/java/org/apache/calcite/sql/fun/SqlJsonInsertFunction.java,"@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlOperandTypeChecker;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.sql.type.SqlTypeUtil;
+import org.apache.calcite.sql.validate.SqlValidator;
+
+import java.util.Locale;
+
+import static org.apache.calcite.util.Static.RESOURCE;
+
+/**
+ * The <code>JSON_INSERT</code> function.
+ */
+public class SqlJsonInsertFunction extends SqlFunction {
+  public SqlJsonInsertFunction() {
+    super(""JSON_INSERT"",
+        SqlKind.OTHER_FUNCTION,
+        ReturnTypes.cascade(ReturnTypes.VARCHAR_2000,
+            SqlTypeTransforms.FORCE_NULLABLE),
+        null,
+        null,
+        SqlFunctionCategory.SYSTEM);
+  }
+
+  @Override public SqlOperandCountRange getOperandCountRange() {
+    return SqlOperandCountRanges.from(3);
+  }
+
+  @Override protected void checkOperandCount(SqlValidator validator,
+      SqlOperandTypeChecker argType, SqlCall call) {
+    assert (call.operandCount() >= 3) && (call.operandCount() % 2 == 1);
+  }
+
+  @Override public boolean checkOperandTypes(SqlCallBinding callBinding,
+      boolean throwOnFailure) {
+    final int count = callBinding.getOperandCount();
+    for (int i = 1; i < count; i += 2) {
+      RelDataType nameType = callBinding.getOperandType(i);
+      if (!SqlTypeUtil.inCharFamily(nameType)) {
+        if (throwOnFailure) {","[{'comment': '`inCharFamiy` or `isCharacter`', 'commenter': 'danny0405'}]"
1143,core/src/main/java/org/apache/calcite/sql/fun/SqlStdOperatorTable.java,"@@ -1340,6 +1340,15 @@ public boolean argumentMustBeScalar(int ordinal) {
   @Deprecated // to be removed before 2.0
   public static final SqlFunction JSON_STORAGE_SIZE = SqlLibraryOperators.JSON_STORAGE_SIZE;
 
+  @Deprecated // to be removed before 2.0
+  public static final SqlFunction JSON_INSERT = SqlLibraryOperators.JSON_INSERT;
+
+  @Deprecated // to be removed before 2.0
+  public static final SqlFunction JSON_REPLACE = SqlLibraryOperators.JSON_REPLACE;","[{'comment': 'Revert the change.', 'commenter': 'danny0405'}, {'comment': '> Revert the change.\r\n\r\nCurrently, it cannot be temporarily deleted. I will modify the entire JSON function later.', 'commenter': 'XuQianJin-Stars'}, {'comment': '???', 'commenter': 'danny0405'}]"
1143,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -4023,6 +4023,27 @@ private void checkLiteral2(String expression, String expected) {
     sql(query).ok(expected);
   }
 
+  @Test public void testJsonInsert() {
+    String query = ""select json_insert(\""product_name\"", '$', 10) from \""product\"""";
+    final String expected = ""SELECT JSON_INSERT(\""product_name\"", '$', 10)\n""
+        + ""FROM \""foodmart\"".\""product\"""";","[{'comment': 'For all the tests, add 2 more kind of value test:\r\n\r\n1. null values\r\n2. character that needs to encode/decodes e.g. ""\\n \\"" ""\\t"" ""\\r"" ..', 'commenter': 'danny0405'}]"
1143,core/src/test/java/org/apache/calcite/sql/parser/SqlParserTest.java,"@@ -8548,6 +8548,21 @@ public void subTestIntervalSecondFailsValidation() {
         .ok(""JSON_STORAGE_SIZE(NULL)"");
   }
 
+  @Test public void testJsonInsert() {
+    checkExp(""json_insert('{ \""a\"": 1, \""b\"": [2]}', '$.c', '[true]')"",
+        ""JSON_INSERT('{ \""a\"": 1, \""b\"": [2]}', '$.c', '[true]')"");
+  }
+
+  @Test public void testJsonReplace() {","[{'comment': 'Why we need a SqlParserTest ?', 'commenter': 'danny0405'}]"
1143,core/src/main/java/org/apache/calcite/sql/fun/SqlJsonInsertFunction.java,"@@ -0,0 +1,26 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+/**
+ * The <code>JSON_INSERT</code> function.
+ */
+public class SqlJsonInsertFunction extends SqlJsonModifyFunction {
+  public SqlJsonInsertFunction(String name) {
+    super(name);","[{'comment': 'The sub-classes of `SqlJsonModifyFunction` can all be removed.', 'commenter': 'danny0405'}]"
1146,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -882,6 +882,9 @@
 
   @BaseMessage(""Not a valid input for JSON_KEYS: ''{0}''"")
   ExInst<CalciteException> invalidInputForJsonKeys(String value);
+
+  @BaseMessage(""Not a valid input for JSON_REMOVE: jsonDoc: ''{0}'', kvs: ''{1}''"")","[{'comment': 'This is good but I am afraid that the camel case is still not very friendly to end users.', 'commenter': 'zhztheplayer'}]"
1146,core/src/main/codegen/templates/Parser.jj,"@@ -5379,6 +5381,34 @@ SqlCall JsonLengthFunctionCall() :
     }
 }
 
+SqlCall JsonRemoveFunctionCall() :
+{
+    final List<SqlNode> elements = new ArrayList<SqlNode>();
+    final SqlNode[] otherArgs = new SqlNode[1];
+    SqlNode e;
+    final Span span;
+}
+{
+    <JSON_REMOVE> { span = span(); }
+    <LPAREN> [
+        e = JsonValueExpression(true) {
+            otherArgs[0] = e;
+        }
+        (
+            <COMMA>
+            e = JsonValueExpression(false) {","[{'comment': 'Per the doc[1] I think we can just use regular expression here. The argument is not a JSON in general.\r\n\r\n[1] https://dev.mysql.com/doc/refman/8.0/en/json-modification-functions.html#function_json-remove', 'commenter': 'zhztheplayer'}, {'comment': 'Well, I can parse it as a `Expression(ExprContext.ACCEPT_NON_QUERY)` and pass it through `ctx.read(element.tostring ())! = null` to determine whether the deletion condition is met.', 'commenter': 'XuQianJin-Stars'}]"
1146,core/src/main/codegen/templates/Parser.jj,"@@ -5379,6 +5381,34 @@ SqlCall JsonLengthFunctionCall() :
     }
 }
 
+SqlCall JsonRemoveFunctionCall() :
+{
+    final List<SqlNode> elements = new ArrayList<SqlNode>();
+    final SqlNode[] otherArgs = new SqlNode[1];","[{'comment': ""I think the variable names such as `elements`, `otherArgs` don't make sense. Could you please improve a bit? Since the JSON_REMOVE's arg definition is different from others. E.g. `jsonDoc`, `pathExprs`."", 'commenter': 'zhztheplayer'}, {'comment': ""well,I'll change it."", 'commenter': 'XuQianJin-Stars'}]"
1146,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -882,6 +882,9 @@
 
   @BaseMessage(""Not a valid input for JSON_KEYS: ''{0}''"")
   ExInst<CalciteException> invalidInputForJsonKeys(String value);
+
+  @BaseMessage(""Remove json error for JSON_REMOVE: jsonDoc: ''{0}'', jsonPaths: ''{1}''"")","[{'comment': ""The message is not much clear, could you please improve it? Maybe keeping it consistent with the others is enough. E.g.\r\n```\r\nInvalid input for JSON_REMOVE: jsonDoc: ''{0}'', jsonPaths: ''{1}''\r\n```"", 'commenter': 'zhztheplayer'}]"
1146,core/src/main/codegen/templates/Parser.jj,"@@ -5379,6 +5381,34 @@ SqlCall JsonLengthFunctionCall() :
     }
 }
 
+SqlCall JsonRemoveFunctionCall() :
+{
+    final List<SqlNode> elements = new ArrayList<SqlNode>();
+    final SqlNode[] otherArgs = new SqlNode[1];
+    SqlNode e;
+    final Span span;
+}
+{
+    <JSON_REMOVE> { span = span(); }
+    <LPAREN> [","[{'comment': 'The square brackets ""["", ""]"" mean ""ZERO OR ONE"". Are they intentional?', 'commenter': 'zhztheplayer'}, {'comment': 'Do we really need to change the parser for every single JSON_xxx function? I don\'t think so.\r\n\r\nEven if JSON values have radically different syntax than regular SQL values - and I\'m skeptical - many JSON functions have normal function syntax ""f(v1, v2, ...)"". For such functions, it\'s better to parse them using generic function syntax. Then the validation happens in the validator, which gives better error messages.', 'commenter': 'julianhyde'}, {'comment': ""I'm always +1 to make the parser simpler. @julianhyde - but how do we deal with the case `JSON_REMOVE('[1, 2, 3]' FORMAT JSON, '$[1]')`? The `'[1, 2, 3]' FORMAT JSON` is not a standard function parameter currently.\r\n\r\nI have suggested to introduce JSON data type support in [CALCITE-2869](https://issues.apache.org/jira/browse/CALCITE-2869). By which we can unify the syntax `JsonValueExpression()` to `Expression()`. Should we do that first? Or is there any other way to simplify them?"", 'commenter': 'zhztheplayer'}]"
1146,core/src/test/java/org/apache/calcite/test/SqlJsonFunctionsTest.java,"@@ -533,6 +533,13 @@ public void testJsonKeys() {
         is(""null""));
   }
 
+  @Test
+  public void testJsonRemove() {
+    assertJsonRemove(is(""{\""b\"":[2]}""),
+              SqlFunctions.dejsonize(""{\""a\"": 1, \""b\"": [2]}""),","[{'comment': 'Please use `SqlFunctions.jsonValueExpression(String ...)` instead.', 'commenter': 'zhztheplayer'}, {'comment': 'These `asssertXxx` methods are messed up. The point of the `assertThat` style is that you can read it like a sentence: ""assert that <value> is <predicate>"". So, the matcher has to be the last argument. Yes, even if that means you can\'t use varargs.', 'commenter': 'julianhyde'}, {'comment': 'Maybe we can add something like the `SqlTester#setFor()` method (see below) for both `SqlFunctuionsTest` and `SqlJsonFunctionsTest` for generating readable messages, so that we can remove these `assertXXX` methods.\r\n\r\nhttps://github.com/apache/calcite/blob/72e952d1a79ee2d7ba05de88cbc2ac11f65cd879/core/src/test/java/org/apache/calcite/sql/test/SqlTester.java#L298-L300', 'commenter': 'zhztheplayer'}]"
1146,site/_docs/reference.md,"@@ -2054,6 +2055,7 @@ Note:
 | JSON_PRETTY(jsonValue)            | Returns a pretty-printing of *jsonValue*
 | JSON_LENGTH(jsonValue [, path ])  | Returns a integer indicating the length of *jsonValue*
 | JSON_KEYS(jsonValue [, path ])    | Returns a string indicating the keys of a JSON *jsonValue*
+| JSON_INSERT(jsonValue, path[, path])  | Returns a JSON document insert a data of *jsonValue*, *path*","[{'comment': '`JSON_INSERT`?', 'commenter': 'zhztheplayer'}]"
1149,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -8112,6 +8112,11 @@ public void _testGroupExpressionEquivalenceParams() {
         .type(""RecordType(VARCHAR(10) OA) NOT NULL"");
   }
 
+  @Test public void testItemOperatorException() {
+    sql(""select ^name^[0] from dept"")
+        .fails(""Cannot apply item operator to 'VARCHAR' for field 'DEPT.NAME'"");","[{'comment': ""I'm afraid the message is not quite understandable.\r\nIt is way better than the original, however it is still confusing.\r\n\r\nHow the error message would like for case like  `select ^(2+2)^[0] from dept`?"", 'commenter': 'vlsi'}, {'comment': 'yes,in the case like `select ^(2+2)^[0] from dept`, the error message is really confusing. ', 'commenter': 'pengzhiwei2018'}, {'comment': ""I think error message like` Cannot apply item operator to 'VARCHAR' type` is enough."", 'commenter': 'chunweilei'}]"
1149,core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties,"@@ -287,4 +287,5 @@ InvalidInputForJsonDepth=Not a valid input for JSON_DEPTH: ''{0}''
 ExceptionWhileSerializingToJson=Cannot serialize object to JSON, and the object is: ''{0}''
 InvalidInputForJsonLength=Not a valid input for JSON_LENGTH: ''{0}''
 InvalidInputForJsonKeys=Not a valid input for JSON_KEYS: ''{0}''
+IllegalTypeForItemOperator=Cannot apply item operator to ''{0}'' who''s type is ''{1}''
 # End CalciteResource.properties","[{'comment': ""`who''s` should be `whose`?"", 'commenter': 'chunweilei'}, {'comment': 'Thanks for you correction.', 'commenter': 'pengzhiwei2018'}]"
1149,core/src/main/java/org/apache/calcite/sql/fun/SqlItemOperator.java,"@@ -89,6 +91,17 @@
     }
     final RelDataType operandType = callBinding.getOperandType(0);
     final SqlSingleOperandTypeChecker checker = getChecker(operandType);
+    if (checker == null) {
+      SqlNode node = callBinding.getCall()","[{'comment': 'There is a util method for generating readable signature error:\r\nhttps://github.com/apache/calcite/blob/986a2d579c8f9b9f08aa9bbbfe11efc4e7bb0809/core/src/main/java/org/apache/calcite/sql/SqlCallBinding.java#L279-L284\r\nIs it enough to use that method rather than manually create new error messages?', 'commenter': 'zhztheplayer'}, {'comment': 'Thanks hongze! The `newValidationSignatureError()` can solve the problem.', 'commenter': 'pengzhiwei2018'}]"
1149,core/src/main/java/org/apache/calcite/sql/fun/SqlItemOperator.java,"@@ -89,6 +88,9 @@
     }
     final RelDataType operandType = callBinding.getOperandType(0);
     final SqlSingleOperandTypeChecker checker = getChecker(operandType);
+    if (checker == null) {
+      throw callBinding.newValidationSignatureError();","[{'comment': 'Thank you very much for the change, @pengzhiwei2018!\r\n\r\nBut why using a null check rather than changing the default case in switch block? Seems they are effectively equivalent. Sorry to be a little picky ;)', 'commenter': 'zhztheplayer'}, {'comment': 'Thanks very much for you suggestions @zhztheplayer ! I have updated the code.', 'commenter': 'pengzhiwei2018'}]"
1171,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -3384,6 +3384,174 @@ private void transitiveInference(RelOptRule... extraRules) throws Exception {
     checkPlanning(tester, preProgram, new HepPlanner(program), sql);
   }
 
+  // outer join, group by on non-join keys, group by on non-null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin1() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on non-join keys, on null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin2() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by d.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on both side on non-join keys
+  @Test public void testPushAggregateThroughtOuterJoin3() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename, d.mgr\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by e.ename,d.mgr"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin4() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin5() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on both side
+  @Test public void testPushAggregateThroughtOuterJoin6() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job,d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job,d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin7() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""join sales.dept as d on e.job = d.name\n""","[{'comment': 'This should be outer.', 'commenter': 'jcamachor'}]"
1171,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -3384,6 +3384,174 @@ private void transitiveInference(RelOptRule... extraRules) throws Exception {
     checkPlanning(tester, preProgram, new HepPlanner(program), sql);
   }
 
+  // outer join, group by on non-join keys, group by on non-null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin1() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on non-join keys, on null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin2() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by d.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on both side on non-join keys
+  @Test public void testPushAggregateThroughtOuterJoin3() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename, d.mgr\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by e.ename,d.mgr"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin4() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin5() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on both side
+  @Test public void testPushAggregateThroughtOuterJoin6() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job,d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job,d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin7() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""join sales.dept as d on e.job = d.name\n""
+        + ""and e.deptno + e.empno = d.deptno + 5\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin8() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""join sales.dept as d on e.job = d.name\n""","[{'comment': 'This should be outer.', 'commenter': 'jcamachor'}]"
1171,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -3384,6 +3384,174 @@ private void transitiveInference(RelOptRule... extraRules) throws Exception {
     checkPlanning(tester, preProgram, new HepPlanner(program), sql);
   }
 
+  // outer join, group by on non-join keys, group by on non-null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin1() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on non-join keys, on null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin2() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by d.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on both side on non-join keys
+  @Test public void testPushAggregateThroughtOuterJoin3() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename, d.mgr\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by e.ename,d.mgr"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin4() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin5() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on both side
+  @Test public void testPushAggregateThroughtOuterJoin6() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job,d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job,d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin7() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""join sales.dept as d on e.job = d.name\n""
+        + ""and e.deptno + e.empno = d.deptno + 5\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin8() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""join sales.dept as d on e.job = d.name\n""
+        + ""and e.deptno + e.empno = d.deptno + 5\n""
+        + ""group by d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on both sides
+  @Test public void testPushAggregateThroughtOuterJoin9() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job, d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""join sales.dept as d on e.job = d.name\n""","[{'comment': 'This should be outer.', 'commenter': 'jcamachor'}]"
1171,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -3551,6 +3551,251 @@ private void transitiveInference(RelOptRule... extraRules) throws Exception {
     checkPlanning(tester, preProgram, new HepPlanner(program), sql);
   }
 
+  // outer join, group by on non-join keys, group by on non-null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin1() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on non-join keys, on null generating side only
+  @Test public void testPushAggregateThroughtOuterJoin2() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.ename\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by d.ename"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on both side on non-join keys
+  @Test public void testPushAggregateThroughtOuterJoin3() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename, d.mgr\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by e.ename,d.mgr"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin4() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin5() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by on key same as join key, group by on both side
+  @Test public void testPushAggregateThroughtOuterJoin6() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job,d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job,d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on non-null generating side
+  @Test public void testPushAggregateThroughtOuterJoin7() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""and e.deptno + e.empno = d.deptno + 5\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on null generating side
+  @Test public void testPushAggregateThroughtOuterJoin8() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""and e.deptno + e.empno = d.deptno + 5\n""
+        + ""group by d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, group by key is susbset of join keys, group by on both sides
+  @Test public void testPushAggregateThroughtOuterJoin9() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job, d.name\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""
+        + ""and e.deptno + e.empno = d.deptno + 5\n""
+        + ""group by e.job, d.name"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // outer join, with aggregate functions
+  @Test public void testPushAggregateThroughtOuterJoin10() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select count(e.ename) \n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.emp as d on e.job = d.job\n""
+        + ""group by e.ename,d.mgr"";
+    sql(sql).withPre(preProgram).with(program).checkUnchanged();
+  }
+
+  // non-equi outer join
+  @Test public void testPushAggregateThroughtOuterJoin11() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.empno,d.deptno\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.empno < d.deptno\n""
+        + ""group by e.empno,d.deptno"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql, true);
+  }
+
+  // right outer join, group by on key same as join key, group by on (left)null generating side
+  @Test public void testPushAggregateThroughtOuterJoin12() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""right outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // full outer join, group by on key same as join key, group by on one side
+  @Test public void testPushAggregateThroughtOuterJoin13() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""full outer join sales.dept as d on e.job = d.name\n""
+        + ""group by e.job"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // full outer join, group by on key same as join key, group by on both side
+  @Ignore(""[CALCITE-3012]"")
+  @Test public void testPushAggregateThroughtOuterJoin14() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.mgr, d.mgr\n""
+        + ""from sales.emp as e\n""
+        + ""full outer join sales.emp as d on e.mgr = d.mgr\n""
+        + ""group by d.mgr, e.mgr"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // full outer join, group by on both side on non-join keys
+  @Test public void testPushAggregateThroughtOuterJoin15() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.ename, d.mgr\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""full outer join sales.emp as d on e.job = d.job\n""
+        + ""group by e.ename,d.mgr"";
+    checkPlanning(tester, preProgram, new HepPlanner(program), sql);
+  }
+
+  // full outer join, group by key is susbset of join keys
+  @Test public void testPushAggregateThroughtOuterJoin16() {
+    final HepProgram preProgram = new HepProgramBuilder()
+        .addRuleInstance(AggregateProjectMergeRule.INSTANCE)
+        .build();
+    final HepProgram program = new HepProgramBuilder()
+        .addRuleInstance(AggregateJoinTransposeRule.EXTENDED)
+        .build();
+    final String sql = ""select e.job\n""
+        + ""from (select * from sales.emp where empno = 10) as e\n""
+        + ""left outer join sales.dept as d on e.job = d.name\n""","[{'comment': 'left outer?', 'commenter': 'hsyuan'}, {'comment': ""@hsyuan Sorry I didn't understand what do you mean by `left outer`?"", 'commenter': 'vineetgarg02'}]"
1171,core/src/main/java/org/apache/calcite/rel/rules/AggregateJoinTransposeRule.java,"@@ -146,12 +146,22 @@ private static boolean isAggregateSupported(Aggregate aggregate, boolean allowFu
     return true;
   }
 
+  // OUTER joins are supported for group by without aggregate functions
+  private boolean isJoinSupported(final Join join, final Aggregate aggregate) {
+    return join.getJoinType() != JoinRelType.FULL","[{'comment': '`&&` has higher precedence than `||`, hence this will not avoid execution of this rule for FULL OUTER joins in all cases. This should be rewritten to:\r\n```\r\nreturn join.getJoinType() == JoinRelType.INNER ||\r\n   aggregate.getAggCallList().isEmpty() && join.getJoinType() != JoinRelType.FULL;\r\n```\r\nPlease update comment above to describe why full outer join is not supported.', 'commenter': 'jcamachor'}, {'comment': ""> has higher precedence than ||\r\nParenthesis were left out by mistake. Thanks for noticing this. I'll update the pull request."", 'commenter': 'vineetgarg02'}]"
1171,core/src/main/java/org/apache/calcite/rel/rules/AggregateJoinTransposeRule.java,"@@ -336,8 +346,9 @@ public void onMatch(RelOptRuleCall call) {
     relBuilder.project(projects);
 
     boolean aggConvertedToProjects = false;
-    if (allColumnsInAggregate) {
+    if (allColumnsInAggregate && join.getJoinType() != JoinRelType.FULL) {","[{'comment': '`&& join.getJoinType() != JoinRelType.FULL) {` is not needed anymore if we bail out correctly above?', 'commenter': 'jcamachor'}, {'comment': ""@jcamachor Correct, I'll remove this."", 'commenter': 'vineetgarg02'}]"
1247,core/src/main/java/org/apache/calcite/rel/rules/FilterJoinRule.java,"@@ -49,7 +50,8 @@
 public abstract class FilterJoinRule extends RelOptRule {
   /** Predicate that always returns true. With this predicate, every filter
    * will be pushed into the ON clause. */
-  public static final Predicate TRUE_PREDICATE = (join, joinType, exp) -> true;
+  public static final Predicate TRUE_PREDICATE = (join, joinType, exp) ->
+      join.getConvention() != EnumerableConvention.INSTANCE;","[{'comment': 'This will be changed back once [CALCITE-2973](https://issues.apache.org/jira/browse/CALCITE-2973) is done.', 'commenter': 'hsyuan'}, {'comment': 'Maybe add a TODO comment in the code to not forget about it?', 'commenter': 'rubenada'}, {'comment': ""I don't think we should add in a Calcite convention to a logical rule, "", 'commenter': 'danny0405'}, {'comment': ""We thought it is logical rule. Unfortunately, this rule also applies to physical operators. And the default Enumerable operators don't support hash join with non-equi conditions, that is why we have to rule it out."", 'commenter': 'hsyuan'}, {'comment': 'Are we likely to see a fix to CALCITE-2973 reasonably soon? I agree that the code should not depend on EnumerableConvention, but we can live with it short-term.', 'commenter': 'julianhyde'}, {'comment': 'I checked with Lai Zhou, who said the fix to CALCITE-2973 can be done in a week.', 'commenter': 'hsyuan'}, {'comment': ""By the way, even if this is a short-term change, let's rename TRUE_PREDICATE.\r\n\r\nIt's bad form to redefine TRUE (or FALSE, 0, 1, Pi or most especially Planck's constant)."", 'commenter': 'julianhyde'}, {'comment': ""I saw you renamed TRUE_PREDICATE to TRUE. That doesn't solve the problem. It was called TRUE_PREDICATE because it always returned true. Now it doesn't, so its name is wrong.\r\n\r\nMaybe leave TRUE_PREDICATE as is (i.e. returning true), deprecate it, and use an inline lambda."", 'commenter': 'julianhyde'}]"
1247,core/src/main/java/org/apache/calcite/adapter/enumerable/EnumerableJoinRule.java,"@@ -58,35 +58,26 @@
     final RelNode right = newInputs.get(1);
     final JoinInfo info = JoinInfo.of(left, right, join.getCondition());
     if (!info.isEqui() && join.getJoinType() != JoinRelType.INNER) {
-      // EnumerableJoinRel only supports equi-join. We can put a filter on top
+      // EnumerableHashJoin only supports equi-join. We can put a filter on top
       // if it is an inner join.
-      try {
-        return EnumerableNestedLoopJoin.create(
-            left,
-            right,
-            join.getCondition(),
-            join.getVariablesSet(),
-            join.getJoinType());
-      } catch (InvalidRelException e) {
-        EnumerableRules.LOGGER.debug(e.toString());
-        return null;
-      }
+      return EnumerableNestedLoopJoin.create(
+          left,
+          right,
+          join.getCondition(),
+          join.getVariablesSet(),
+          join.getJoinType());
     } else {
       RelNode newRel;
-      try {
-        newRel = EnumerableHashJoin.create(
-            left,
-            right,
-            info.getEquiCondition(left, right, cluster.getRexBuilder()),
-            join.getVariablesSet(),
-            join.getJoinType());
-      } catch (InvalidRelException e) {
-        EnumerableRules.LOGGER.debug(e.toString());
-        return null;
-      }
-      if (!info.isEqui()) {
+      newRel = EnumerableHashJoin.create(
+          left,
+          right,
+          info.getEquiCondition(left, right, cluster.getRexBuilder()),
+          join.getVariablesSet(),
+          join.getJoinType());
+      RexNode nonEqui = info.getRemaining(cluster.getRexBuilder());
+      if (!nonEqui.isAlwaysTrue()) {","[{'comment': 'This if check is redundant.', 'commenter': 'danny0405'}, {'comment': ""I don't think so."", 'commenter': 'hsyuan'}, {'comment': 'This check is necessary. But I prefer use` !info.isEqui()` since it is more clear?.', 'commenter': 'chunweilei'}]"
1247,core/src/main/java/org/apache/calcite/rel/core/JoinInfo.java,"@@ -40,14 +40,16 @@
  * {@link org.apache.calcite.rel.core.EquiJoin}.</p>
  *
  * @see Join#analyzeCondition() */
-public abstract class JoinInfo {
+public class JoinInfo {
   public final ImmutableIntList leftKeys;
   public final ImmutableIntList rightKeys;
+  public final RexNode nonEqui;
 
   /** Creates a JoinInfo. */
-  protected JoinInfo(ImmutableIntList leftKeys, ImmutableIntList rightKeys) {
+  protected JoinInfo(ImmutableIntList leftKeys, ImmutableIntList rightKeys, RexNode nonEqui) {
     this.leftKeys = Objects.requireNonNull(leftKeys);
     this.rightKeys = Objects.requireNonNull(rightKeys);
+    this.nonEqui = nonEqui;
     assert leftKeys.size() == rightKeys.size();","[{'comment': 'nonEquiConditions or remaining ?', 'commenter': 'danny0405'}, {'comment': 'nonEquiConditions might be better.', 'commenter': 'hsyuan'}]"
1247,core/src/main/java/org/apache/calcite/rel/core/JoinInfo.java,"@@ -59,23 +61,21 @@ public static JoinInfo of(RelNode left, RelNode right, RexNode condition) {
     RexNode remaining =
         RelOptUtil.splitJoinCondition(left, right, condition, leftKeys,
             rightKeys, filterNulls);
-    if (remaining.isAlwaysTrue()) {
-      return new EquiJoinInfo(ImmutableIntList.copyOf(leftKeys),
-          ImmutableIntList.copyOf(rightKeys));
-    } else {
-      return new NonEquiJoinInfo(ImmutableIntList.copyOf(leftKeys),
-          ImmutableIntList.copyOf(rightKeys), remaining);
-    }
+    return new JoinInfo(ImmutableIntList.copyOf(leftKeys),
+        ImmutableIntList.copyOf(rightKeys), remaining);
   }
 
   /** Creates an equi-join. */
   public static JoinInfo of(ImmutableIntList leftKeys,
       ImmutableIntList rightKeys) {
-    return new EquiJoinInfo(leftKeys, rightKeys);
+    return new JoinInfo(leftKeys, rightKeys, null);
   }
 
   /** Returns whether this is an equi-join. */
-  public abstract boolean isEqui();
+  public boolean isEqui() {
+    return (nonEqui == null || nonEqui.isAlwaysTrue())
+        && leftKeys.size() == rightKeys.size();
+  }","[{'comment': '`leftKeys.size()` should always equals with `rightKeys.size()`', 'commenter': 'danny0405'}, {'comment': 'Correct, this is sanity check.', 'commenter': 'hsyuan'}]"
1247,core/src/main/java/org/apache/calcite/rel/rules/ReduceExpressionsRule.java,"@@ -346,15 +345,6 @@ public JoinReduceExpressionsRule(Class<? extends Join> joinClass,
           matchNullability)) {
         return;
       }
-      if (RelOptUtil.forceEquiJoin(join)) {
-        final JoinInfo joinInfo =
-            JoinInfo.of(join.getLeft(), join.getRight(), expList.get(0));
-        if (!joinInfo.isEqui()) {
-          // This kind of join must be an equi-join, and the condition is
-          // no longer an equi-join. SemiJoin is an example of this.
-          return;
-        }
-      }","[{'comment': 'We can not remove this, the behavior would be non-consistent, how about other systems use this rule and their join does not support non-equi conditions ?', 'commenter': 'danny0405'}, {'comment': 'Then the other systems should update their own implementation, as EquiJoin is deprecated.', 'commenter': 'hsyuan'}]"
1247,core/src/main/java/org/apache/calcite/adapter/enumerable/EnumerableJoinRule.java,"@@ -58,35 +58,26 @@
     final RelNode right = newInputs.get(1);
     final JoinInfo info = JoinInfo.of(left, right, join.getCondition());
     if (!info.isEqui() && join.getJoinType() != JoinRelType.INNER) {","[{'comment': 'use` join.analyzeCondition()`?', 'commenter': 'chunweilei'}, {'comment': 'done', 'commenter': 'hsyuan'}]"
1247,core/src/main/java/org/apache/calcite/adapter/enumerable/EnumerableHashJoin.java,"@@ -56,8 +55,7 @@ protected EnumerableHashJoin(
       RelNode right,
       RexNode condition,
       Set<CorrelationId> variablesSet,
-      JoinRelType joinType)
-      throws InvalidRelException {
+      JoinRelType joinType) {","[{'comment': 'Would it make sense to add in this constructor a check on the condition (to verify that it is actually an equi-join, which is required by the underlying implementation algorithm)?\r\n```\r\nif (!JoinInfo.of(left, right, condition).isEqui())\r\n  throw new IllegalArgumentException(""..."");\r\n```\r\nor maybe at least an assert\r\n`assert JoinInfo.of(left, right, condition).isEqui();`\r\nIdem for EnumerableMergeJoin.\r\n', 'commenter': 'rubenada'}, {'comment': 'Yes, make sense. Will do', 'commenter': 'hsyuan'}]"
1247,core/src/main/java/org/apache/calcite/rel/core/JoinInfo.java,"@@ -31,23 +31,25 @@
 
 /** An analyzed join condition.
  *
- * <p>It is useful for the many algorithms that care whether a join is an
- * equi-join.
+ * <p>It is useful for the many algorithms that care whether a join has an
+ * equi-join condition.
  *
  * <p>You can create one using {@link #of}, or call
  * {@link Join#analyzeCondition()}; many kinds of join cache their
- * join info, especially those that are equi-joins and sub-class
- * {@link org.apache.calcite.rel.core.EquiJoin}.</p>
+ * join info, especially those that are equi-joins.</p>
  *
  * @see Join#analyzeCondition() */
-public abstract class JoinInfo {
+public class JoinInfo {
   public final ImmutableIntList leftKeys;
   public final ImmutableIntList rightKeys;
+  protected final RexNode nonEquiCondition;","[{'comment': ""My instinct is to make everything non-null. I don't like the test `nonEquiCondition == null || nonEquiCondition.isAlwaysTrue()`, for instance.\r\n\r\nConsider making `nonEquiCondition` a conjunctive list (immutable, final and not null); if the list is empty, that means true. We do this in several other places, and it is useful, because caller can assume that ANDs have been flattened."", 'commenter': 'julianhyde'}, {'comment': '`getRemaining` is a public method and returns `RexNode`. If we make `nonEquiCondition` a conjunctive list, we have to convert to a `RexNode` every time we call `getRemainng`. How about checking the nullness of input `nonEquiCondition` in the `JoinInfo` constructor, set it to literal `TRUE` rexnode if it is `null`? At the same time, add `@Nonnull` to `getRemaining`.', 'commenter': 'hsyuan'}, {'comment': 'Revoke what I just said, the is no way to pass `RexBuilder` in the constructor.', 'commenter': 'hsyuan'}, {'comment': ""I don't think you should allow availability of `RexBuilder` to sway the design. When a `JoinInfo` is created, there is always a `RexBuilder` available, and that `RexBuilder` (and its `RelDataTypeFactory`) remain valid for the lifetime of the `JoinInfo`.\r\n\r\nRepresenting conditions as conjunctive lists seems to be very convenient. For example, consider the `RelOptUtil.splitJoinCondition` method, which is the source of `JoinInfo.remaining`. The last thing it does is to convert a conjunctive list into a `RexNode`. Other callers of that method either ignore the return, or immediately convert the `RexNode` back into a conjunctive list."", 'commenter': 'julianhyde'}, {'comment': 'Make sense. I will change nonEquiCondition to conjunctive list. But looks like we have to keep `public RexNode getRemaining(RexBuilder rexBuilder)` unchanged, since it is a public API.', 'commenter': 'hsyuan'}]"
1247,core/src/main/java/org/apache/calcite/rel/core/JoinInfo.java,"@@ -90,7 +98,9 @@ public ImmutableBitSet rightSet() {
     return ImmutableBitSet.of(rightKeys);
   }
 
-  public abstract RexNode getRemaining(RexBuilder rexBuilder);
+  public RexNode getRemaining(RexBuilder rexBuilder) {
+    return RexUtil.composeConjunction(rexBuilder, nonEquiConditions);
+  }","[{'comment': ""It's so weird that we pass in `nonEquiConditions` into the constructor and return a `RexNode` here, can we have a better solution ?"", 'commenter': 'danny0405'}, {'comment': ""I agree, but given this is a public API, we can't change it to returning list instead of a RexNode. What we can do is deprecating this method, and introduce another one returning conjunction list."", 'commenter': 'hsyuan'}, {'comment': ""I'm +1 on deprecate this method and introduce another one returning conjunction list."", 'commenter': 'danny0405'}]"
1257,core/src/test/java/org/apache/calcite/test/JdbcAdapterTest.java,"@@ -85,6 +85,31 @@
             + ""FROM \""foodmart\"".\""sales_fact_1998\"""");
   }
 
+  /**
+   * Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3115"">[CALCITE-3115]
+   * Cannot add JdbcRules which have different JdbcConvention
+   * to same VolcanoPlanner's RuleSet.</a>*/
+  @Test public void testUnionPlan2() {
+    CalciteAssert.model(JdbcTest.FOODMART_SCOTT_MODEL)
+        .query(""select \""store_name\"" from \""foodmart\"".\""store\""\n""","[{'comment': 'Can you make the query (adding some filter) slightly more complicated to show the effect of more rules. For instance  `""select \\""store_name\\"" from \\""foodmart\\"".\\""store\\""\\n""\r\n            + ""where \\""store_name\\"" = \'Store 1\'\\n""\r\n            + ""union all\\n""\r\n            + ""select ename from SCOTT.emp where sal > 0""`', 'commenter': 'zabetak'}]"
1257,core/src/main/java/org/apache/calcite/adapter/jdbc/JdbcRules.java,"@@ -270,7 +270,7 @@ public JdbcJoinRule(JdbcConvention out) {
     public JdbcJoinRule(JdbcConvention out,
         RelBuilderFactory relBuilderFactory) {
       super(Join.class, (Predicate<RelNode>) r -> true, Convention.NONE,
-          out, relBuilderFactory, ""JdbcJoinRule"");
+          out, relBuilderFactory, ""JdbcJoinRule:"" + out);","[{'comment': 'I have the impression that JdbcConvention#toString() may return a String that does not obey the description pattern of the rule and thus get a RuntimeException when instantiating the rule. Is it possible? Should we normalize somehow the string obtained from the convention?', 'commenter': 'zabetak'}]"
1257,core/src/main/java/org/apache/calcite/adapter/jdbc/JdbcConvention.java,"@@ -49,12 +51,23 @@
 
   public final SqlDialect dialect;
   public final Expression expression;
+  private final String signature;
 
   public JdbcConvention(SqlDialect dialect, Expression expression,
       String name) {
     super(""JDBC."" + name, JdbcRel.class);
     this.dialect = dialect;
     this.expression = expression;
+    this.signature = normalizeName();
+  }
+
+  private String normalizeName() {
+    String id = UUID.randomUUID().toString();
+    return getName().replaceAll(""[^-A-Za-z0-9_.():]"", ""."") + ""("" + id + "")"";
+  }","[{'comment': 'Why we use a uuid a part of the name ? So you mean for same name we can have different signature ?', 'commenter': 'danny0405'}, {'comment': 'I think it is done to avoid collisions that may occur after the normalization.', 'commenter': 'zabetak'}]"
1257,core/src/main/java/org/apache/calcite/adapter/jdbc/JdbcConvention.java,"@@ -49,12 +51,23 @@
 
   public final SqlDialect dialect;
   public final Expression expression;
+  private final String signature;
 
   public JdbcConvention(SqlDialect dialect, Expression expression,
       String name) {
     super(""JDBC."" + name, JdbcRel.class);
     this.dialect = dialect;
     this.expression = expression;
+    this.signature = normalizeName();
+  }
+
+  private String normalizeName() {
+    String id = UUID.randomUUID().toString();
+    return getName().replaceAll(""[^-A-Za-z0-9_.():]"", ""."") + ""("" + id + "")"";
+  }
+
+  @Override public String toString() {
+    return signature;
   }","[{'comment': 'maybe we should call this digest ', 'commenter': 'danny0405'}]"
1257,core/src/main/java/org/apache/calcite/adapter/jdbc/JdbcRules.java,"@@ -426,7 +426,7 @@ protected JdbcJoin(
     private JdbcCalcRule(JdbcConvention out,
         RelBuilderFactory relBuilderFactory) {
       super(Calc.class, (Predicate<RelNode>) r -> true, Convention.NONE,
-          out, relBuilderFactory, ""JdbcCalcRule"");
+          out, relBuilderFactory, ""JdbcCalcRule:"" + out);","[{'comment': 'Can we have a uniform method to generate the name pattern for JDBC rules ? Because the pattern rules for all the rules are the same.', 'commenter': 'danny0405'}]"
1283,plus/src/test/java/org/apache/calcite/adapter/tpcds/TpcdsTest.java,"@@ -164,30 +165,30 @@ private static String schema(String name, String scaleFactor) {
 
   @Test public void testTableCount() {
     final CalciteAssert.AssertThat with = with();
-//    foo(with, ""CALL_CENTER"", 6);
-//    foo(with, ""CATALOG_PAGE"", 11_718);
-//    foo(with, ""CATALOG_RETURNS"", 144_067);
-//    foo(with, ""CATALOG_SALES"", 1_441_548);
-//    foo(with, ""CUSTOMER"", 100_000);
-//    foo(with, ""CUSTOMER_ADDRESS"", 50_000);
-//    foo(with, ""CUSTOMER_DEMOGRAPHICS"", 1_920_800);
-//    foo(with, ""DATE_DIM"", 73_049);
-//    foo(with, ""HOUSEHOLD_DEMOGRAPHICS"", 7_200);
-//    foo(with, ""INCOME_BAND"", 20);
-//    foo(with, ""INVENTORY"", 11_745_000);
-//    foo(with, ""ITEM"", 18_000);
-//    foo(with, ""PROMOTION"", 300);
-//    foo(with, ""REASON"", 35);
-//    foo(with, ""SHIP_MODE"", 20);
-//    foo(with, ""STORE"", 12);
-//    foo(with, ""STORE_RETURNS"", 287_514);
-//    foo(with, ""STORE_SALES"", 2_880_404);
-//    foo(with, ""TIME_DIM"", 86_400);
-//    foo(with, ""WAREHOUSE"", 5);
-//    foo(with, ""WEB_PAGE"", 60);
-//    foo(with, ""WEB_RETURNS"", 71_763);
-//    foo(with, ""WEB_SALES"", 719_384);
-//    foo(with, ""WEB_SITE"", 30);","[{'comment': 'Why to open up these tests ? which seems has no relationship with the fix title.', 'commenter': 'danny0405'}, {'comment': ""Thanks for @danny0405 's replies. I just doubt why this should be commented。If it's not ok, i will keep original instead."", 'commenter': 'LiShuMing'}, {'comment': 'I see @julianhyde did the modification in https://github.com/apache/calcite/commit/93b8349895df2183864bc4bd7ef2fafa227b22e9, maybe he can answer you!', 'commenter': 'danny0405'}, {'comment': 'I would assume to avoid generating data for those tables just for the sake of count queries but I may be wrong.', 'commenter': 'zabetak'}, {'comment': ""Thanks for @zabetak 's replies.  Those tables' rowCounts are added in `org.apache.calcite.adapter.tpcds.TpcdsSchema`,  it uses TABLE_ROW_COUNTS mapping to maintaince tables' rowCounts. So I think there's no cost to generate data?\r\n\r\nMaybe it's better to open up these tests again? "", 'commenter': 'LiShuMing'}, {'comment': 'I see that `foo` method executes a query to the table passed as a parameter. If I remember well `TpcdsQueryableTable` which I think is involved on this query generates the respective data every time it is referenced.', 'commenter': 'zabetak'}, {'comment': 'If those codes are useless, so just remove them any more?  I wonder what I should do, maybe just keep it unchanged?', 'commenter': 'LiShuMing'}]"
1283,plus/src/test/java/org/apache/calcite/adapter/tpcds/TpcdsTest.java,"@@ -379,7 +380,23 @@ protected void foo(CalciteAssert.AssertThat with, String tableName,
                 builder.avg(false, ""AGG4"", builder.field(""SS_SALES_PRICE"")))
             .sortLimit(0, 100, builder.field(""I_ITEM_ID""), builder.field(""S_STATE""))
             .build();
-    System.out.println(RelOptUtil.toString(root));
+    String actualResult = RelOptUtil.toString(root);
+    String expectResult = """"
+        + ""LogicalSort(sort0=[$1], sort1=[$0], dir0=[ASC], dir1=[ASC], fetch=[100])\n""
+        + ""  LogicalAggregate(group=[{84, 90}], AGG1=[AVG($10)], AGG2=[AVG($12)], AGG3=[AVG($19)], AGG4=[AVG($13)])\n""
+        + ""    LogicalFilter(condition=[AND(=($0, $32), =($2, $89), =($7, $60), =($4, $23), =($24, 'M'), =($25, 'S'), =($26, 'HIGH SCHOOL'), =($38, 1998), IN($84, ARRAY('CA', 'OR', 'WA', 'TX', 'OK', 'MD')))])\n""
+        + ""      LogicalJoin(condition=[true], joinType=[inner])\n""
+        + ""        LogicalTableScan(table=[[TPCDS, STORE_SALES]])\n""
+        + ""        LogicalJoin(condition=[true], joinType=[inner])\n""
+        + ""          LogicalTableScan(table=[[TPCDS, CUSTOMER_DEMOGRAPHICS]])\n""
+        + ""          LogicalJoin(condition=[true], joinType=[inner])\n""
+        + ""            LogicalTableScan(table=[[TPCDS, DATE_DIM]])\n""
+        + ""            LogicalJoin(condition=[true], joinType=[inner])\n""
+        + ""              LogicalTableScan(table=[[TPCDS, STORE]])\n""
+        + ""              LogicalTableScan(table=[[TPCDS, ITEM]])\n"";
+
+    Assert.assertEquals(""Query27 of TPCDS should be equal to the expect result"",
+        actualResult, expectResult);","[{'comment': 'I would suggest to use the same mechanism for comparing plans that is used in `RelBuilderTest`. Moreover the assertion above is not written in the correct order:\r\n`Assert.assertEquals(""Query27 of TPCDS should be equal to the expect result"",\r\n        expectResult, actualResult);`', 'commenter': 'zabetak'}, {'comment': ""Yep, I'll fix it."", 'commenter': 'LiShuMing'}]"
1301,core/src/test/java/org/apache/calcite/plan/RelWriterTest.java,"@@ -59,7 +63,7 @@
 /**
  * Unit test for {@link org.apache.calcite.rel.externalize.RelJson}.
  */
-public class RelWriterTest {
+public class RelWriterTest extends SqlToRelTestBase {
   public static final String XX = ""{\n""","[{'comment': 'I know maybe you need some abstractions in SqlToRelTestBase, but do we really need to make this class extend SqlToRelTestBase ? This is writer test and seems has no relationship with sql-to-rel conversion.', 'commenter': 'danny0405'}, {'comment': 'Make this class extend SqlToRelTestBase to reuse the created Tester instance. The constructor of TesterImpl is protected, cannot just create an instance of TesterImpl without extending SqlToRelTestBase.', 'commenter': 'yanlin-Lynn'}, {'comment': 'All you need is just a relNode, you can construct it with a `RelBuilder` or new the RelNode directly.', 'commenter': 'danny0405'}, {'comment': ""I think this will make things complicated, it's better to choose a simple and  straight forward way to get the relnode tree."", 'commenter': 'yanlin-Lynn'}, {'comment': 'There is already some code snippet to construct the `RelNode` directly [1], so what do you mean by ""things complicated"" ?\r\n\r\n[1] https://github.com/apache/calcite/blob/18974ce8a945424a8a3465c03b253e292641f420/core/src/test/java/org/apache/calcite/plan/RelWriterTest.java#L313', 'commenter': 'danny0405'}, {'comment': 'I know there exists sample code snippet to do this. But what I mean is, we already have a simpler way to get the RelNode, why take the effort to build it manually.', 'commenter': 'yanlin-Lynn'}, {'comment': 'Can you take a look at what is `SqlToRelTestBase` used for ? Not just say that ""Oh, this extend works for me!"".', 'commenter': 'danny0405'}]"
1301,core/src/main/java/org/apache/calcite/rel/externalize/RelJson.java,"@@ -330,6 +330,9 @@ private Object toJson(RexNode node) {
       final Object value = literal.getValue3();
       map = jsonBuilder.map();
       map.put(""literal"", value);
+      if (value instanceof Enum) {
+        map.put(""flag"", value.getClass().getName());
+      }","[{'comment': 'Why we name the enum ""flag"" ? It makes me confused.', 'commenter': 'danny0405'}, {'comment': 'Actually, I have considered using ""type"" or ""enum"". And RexBuilder has the method [makeFlag](https://github.com/apache/calcite/blob/master/core/src/main/java/org/apache/calcite/rex/RexBuilder.java#L876) to convert an Enum object to a RexLiteral, which will be used in `RelJson.toRex` in this patch. So choose  ""flag"" to be in consistent with it.', 'commenter': 'yanlin-Lynn'}, {'comment': 'So can we add this explain as comment of the code ?', 'commenter': 'danny0405'}, {'comment': ""OK. That's good."", 'commenter': 'yanlin-Lynn'}]"
1301,core/src/main/java/org/apache/calcite/rel/externalize/RelJson.java,"@@ -517,6 +520,18 @@ RexNode toRex(RelInput relInput, Object o) {
           // we just interpret the literal
           return toRex(relInput, literal);
         }
+        if (map.containsKey(""flag"")) {
+          // rebuild flag.
+          String className = (String) map.get(""flag"");
+          try {
+            Class<Enum> clz = (Class<Enum>) Class.forName(className);
+            Enum flag = Enum.valueOf(clz, (String) literal);","[{'comment': 'clazz', 'commenter': 'danny0405'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactory.java,"@@ -308,6 +308,29 @@ RelDataType createDecimalQuotient(
   @SuppressWarnings(""deprecation"")
   FieldInfoBuilder builder();
 
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition, or null if decimal
+   * addition should not be applied to the operands.
+   */
+  RelDataType createDecimalAddition(RelDataType type1, RelDataType type2);
+
+  /**
+   * Infers the return type of a decimal mod operation. Currently only a hook point","[{'comment': ""The comment about hook point is unnecessary since this is an interface and there's no implementation. Similar to `createDecimalAddition`, should one of the operand be a decimal and the second one be an exact numeric type?\r\n\r\nOne could (should?) add a default implementation too: the expectation is that it should return something non-null if operands are valid as it might be used in a different context."", 'commenter': 'laurentgo'}, {'comment': ""I've fixed the comment but i do not want to provide a default implementation since that would be change in behavior for all existing clients of calcite.\r\nthe change i made preserves the existing behavior."", 'commenter': 'praveenbingo'}, {'comment': ""The default should have the same behavior as currently: if one of the operand types are decimal and both are exact numeric types, return the type of the second argument. It doesn't change existing behavior of the operand, and people who use {{RelDataTypeFactory}} can leverage the new method."", 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactory.java,"@@ -308,6 +308,29 @@ RelDataType createDecimalQuotient(
   @SuppressWarnings(""deprecation"")
   FieldInfoBuilder builder();
 
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition, or null if decimal
+   * addition should not be applied to the operands.
+   */
+  RelDataType createDecimalAddition(RelDataType type1, RelDataType type2);","[{'comment': 'should it be a default method to preserve source compatibility?', 'commenter': 'laurentgo'}, {'comment': 'very good point. it should be. moving the implementation to the interface. thanks !', 'commenter': 'praveenbingo'}]"
1311,core/src/main/java/org/apache/calcite/sql/type/ReturnTypes.java,"@@ -515,38 +515,17 @@ public int size() {
    *
    * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
    */
-  public static final SqlReturnTypeInference DECIMAL_SUM = opBinding -> {
-    RelDataType type1 = opBinding.getOperandType(0);
-    RelDataType type2 = opBinding.getOperandType(1);
-    if (SqlTypeUtil.isExactNumeric(type1)
-        && SqlTypeUtil.isExactNumeric(type2)) {
-      if (SqlTypeUtil.isDecimal(type1)
-          || SqlTypeUtil.isDecimal(type2)) {
-        int p1 = type1.getPrecision();
-        int p2 = type2.getPrecision();
-        int s1 = type1.getScale();
-        int s2 = type2.getScale();
-
-        final RelDataTypeFactory typeFactory = opBinding.getTypeFactory();
-        int scale = Math.max(s1, s2);
-        final RelDataTypeSystem typeSystem = typeFactory.getTypeSystem();
-        assert scale <= typeSystem.getMaxNumericScale();
-        int precision = Math.max(p1 - s1, p2 - s2) + scale + 1;
-        precision =
-            Math.min(
-                precision,
-                typeSystem.getMaxNumericPrecision());
-        assert precision > 0;
-
-        return typeFactory.createSqlType(
-            SqlTypeName.DECIMAL,
-            precision,
-            scale);
-      }
-    }
+  public static final SqlReturnTypeInference DECIMAL_SUM =","[{'comment': 'Please preserve the style and use lambda', 'commenter': 'laurentgo'}, {'comment': 'sure done.', 'commenter': 'praveenbingo'}]"
1311,core/src/main/java/org/apache/calcite/sql/type/ReturnTypes.java,"@@ -563,6 +542,26 @@ public int size() {
   public static final SqlReturnTypeInference NULLABLE_SUM =
       new SqlReturnTypeInferenceChain(DECIMAL_SUM_NULLABLE, LEAST_RESTRICTIVE);
 
+  public static final SqlReturnTypeInference DECIMAL_MOD =","[{'comment': 'please also use lambda to be consistent', 'commenter': 'laurentgo'}, {'comment': 'sure done.', 'commenter': 'praveenbingo'}]"
1311,core/src/test/java/org/apache/calcite/sql/type/RelDataTypeFactoryTest.java,"@@ -0,0 +1,67 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.type;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+
+import com.google.common.collect.Lists;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * Tests return type inference using RelDataTypeFactory
+ */
+public class RelDataTypeFactoryTest {
+
+  private static final SqlTypeFixture TYPE_FIXTURE = new SqlTypeFixture();
+  private static final SqlTypeFactoryImpl TYPE_FACTORY = TYPE_FIXTURE.typeFactory;","[{'comment': ""Can we also test return type inference with a custom typefactory to make sure it's not the previous behavior?"", 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -458,53 +457,11 @@ public static boolean isJavaType(RelDataType t) {
 
   /**
    * {@inheritDoc}
-   *
-   * <p>Implement RelDataTypeFactory with SQL 2003 compliant behavior. Let p1,","[{'comment': ""let's just point it now uses `RelDataTypeSystem#deriveDecimalMultiplyType`"", 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -516,66 +473,12 @@ public boolean useDoubleMultiplication(
   }
 
   /**
-   * Rules:","[{'comment': ""let's just point it now uses `RelDataTypeSystem#deriveDecimalDivideType(...)`"", 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystem.java,"@@ -100,6 +101,212 @@ RelDataType deriveCovarType(RelDataTypeFactory typeFactory,
   /** Whether the least restrictive type of a number of CHAR types of different
    * lengths should be a VARCHAR type. And similarly BINARY to VARBINARY. */
   boolean shouldConvertRaggedUnionTypesToVarying();
+
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition.
+   */
+  default RelDataType deriveDecimalPlusType(RelDataTypeFactory typeFactory,
+                                            RelDataType type1, RelDataType type2) {
+    /**
+     * Type-inference strategy whereby the result type of a call is the decimal
+     * sum of two exact numeric operands where at least one of the operands is a
+     * decimal. Let p1, s1 be the precision and scale of the first operand Let
+     * p2, s2 be the precision and scale of the second operand Let p, s be the
+     * precision and scale of the result, Then the result type is a decimal
+     * with:
+     *
+     * <ul>
+     * <li>s = max(s1, s2)</li>
+     * <li>p = max(p1 - s1, p2 - s2) + s + 1</li>
+     * </ul>
+     *
+     * <p>p and s are capped at their maximum values
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+        int scale = Math.max(s1, s2);
+        assert scale <= getMaxNumericScale();
+        int precision = Math.max(p1 - s1, p2 - s2) + scale + 1;
+        precision =
+                Math.min(
+                        precision,
+                        getMaxNumericPrecision());
+        assert precision > 0;
+
+        return typeFactory.createSqlType(
+                SqlTypeName.DECIMAL,
+                precision,
+                scale);
+      }
+    }
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal multiplication. Decimal
+   * multiplication involves at least one decimal operand and requires both
+   * operands to have exact numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal multiplication, or null if decimal
+   * multiplication should not be applied to the operands.
+   */
+  default RelDataType deriveDecimalMultiplyType(RelDataTypeFactory typeFactory,
+      RelDataType type1, RelDataType type2) {
+    /**
+     * <p>Implement RelDataTypeFactory with SQL 2003 compliant behavior. Let p1,
+     * s1 be the precision and scale of the first operand Let p2, s2 be the
+     * precision and scale of the second operand Let p, s be the precision and
+     * scale of the result, Then the result type is a decimal with:
+     *
+     * <ul>
+     * <li>p = p1 + p2</li>
+     * <li>s = s1 + s2</li>
+     * </ul>
+     *
+     * <p>p and s are capped at their maximum values
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+
+        int scale = s1 + s2;
+        scale = Math.min(scale, getMaxNumericScale());
+        int precision = p1 + p2;
+        precision =
+                Math.min(
+                        precision,
+                        getMaxNumericPrecision());
+
+        RelDataType ret;
+        ret = typeFactory.createSqlType(
+                        SqlTypeName.DECIMAL,
+                        precision,
+                        scale);
+
+        return ret;
+      }
+    }
+
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal division. Decimal division involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal division, or null if decimal
+   * division should not be applied to the operands.
+   */
+  default RelDataType deriveDecimalDivideType(RelDataTypeFactory typeFactory,
+      RelDataType type1, RelDataType type2) {
+    /**
+     * Rules:
+     *
+     * <ul>
+     * <li>Let p1, s1 be the precision and scale of the first operand
+     * <li>Let p2, s2 be the precision and scale of the second operand
+     * <li>Let p, s be the precision and scale of the result
+     * <li>Let d be the number of whole digits in the result
+     * <li>Then the result type is a decimal with:
+     *   <ul>
+     *   <li>d = p1 - s1 + s2</li>
+     *   <li>s &lt; max(6, s1 + p2 + 1)</li>
+     *   <li>p = d + s</li>
+     *   </ul>
+     * </li>
+     * <li>p and s are capped at their maximum values</li>
+     * </ul>
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+
+        final int maxNumericPrecision = getMaxNumericPrecision();
+        int dout =
+                Math.min(
+                        p1 - s1 + s2,
+                        maxNumericPrecision);
+
+        int scale = Math.max(6, s1 + p2 + 1);
+        scale =
+                Math.min(
+                        scale,
+                        maxNumericPrecision - dout);
+        scale = Math.min(scale, getMaxNumericScale());
+
+        int precision = dout + scale;
+        assert precision <= maxNumericPrecision;
+        assert precision > 0;
+
+        RelDataType ret;
+        ret = typeFactory.
+                createSqlType(
+                        SqlTypeName.DECIMAL,
+                        precision,
+                        scale);
+
+        return ret;
+      }
+    }
+
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal mod operation. Decimal mod involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *","[{'comment': ""let's mention the rules too"", 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystem.java,"@@ -100,6 +101,214 @@ RelDataType deriveCovarType(RelDataTypeFactory typeFactory,
   /** Whether the least restrictive type of a number of CHAR types of different
    * lengths should be a VARCHAR type. And similarly BINARY to VARBINARY. */
   boolean shouldConvertRaggedUnionTypesToVarying();
+
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand","[{'comment': '(javadoc) missing description for `typeFactory`', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystem.java,"@@ -100,6 +101,214 @@ RelDataType deriveCovarType(RelDataTypeFactory typeFactory,
   /** Whether the least restrictive type of a number of CHAR types of different
    * lengths should be a VARCHAR type. And similarly BINARY to VARBINARY. */
   boolean shouldConvertRaggedUnionTypesToVarying();
+
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition.
+   */
+  default RelDataType deriveDecimalPlusType(RelDataTypeFactory typeFactory,
+                                            RelDataType type1, RelDataType type2) {
+    /**","[{'comment': '(style): it should be a regular comment, and not a javadoc one. Since this is the default behavior, might want to move it from comment to proper javadoc.', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystem.java,"@@ -100,6 +101,214 @@ RelDataType deriveCovarType(RelDataTypeFactory typeFactory,
   /** Whether the least restrictive type of a number of CHAR types of different
    * lengths should be a VARCHAR type. And similarly BINARY to VARBINARY. */
   boolean shouldConvertRaggedUnionTypesToVarying();
+
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition.
+   */
+  default RelDataType deriveDecimalPlusType(RelDataTypeFactory typeFactory,
+                                            RelDataType type1, RelDataType type2) {
+    /**
+     * Type-inference strategy whereby the result type of a call is the decimal
+     * sum of two exact numeric operands where at least one of the operands is a
+     * decimal. Let p1, s1 be the precision and scale of the first operand Let
+     * p2, s2 be the precision and scale of the second operand Let p, s be the
+     * precision and scale of the result, Then the result type is a decimal
+     * with:
+     *
+     * <ul>
+     * <li>s = max(s1, s2)</li>
+     * <li>p = max(p1 - s1, p2 - s2) + s + 1</li>
+     * </ul>
+     *
+     * <p>p and s are capped at their maximum values
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+        int scale = Math.max(s1, s2);
+        assert scale <= getMaxNumericScale();
+        int precision = Math.max(p1 - s1, p2 - s2) + scale + 1;
+        precision =
+                Math.min(
+                        precision,
+                        getMaxNumericPrecision());
+        assert precision > 0;
+
+        return typeFactory.createSqlType(
+                SqlTypeName.DECIMAL,
+                precision,
+                scale);
+      }
+    }
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal multiplication. Decimal
+   * multiplication involves at least one decimal operand and requires both
+   * operands to have exact numeric types.
+   *
+   * @param type1 type of the first operand","[{'comment': '(javadoc) missing `typeFactory` argument', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystem.java,"@@ -100,6 +101,214 @@ RelDataType deriveCovarType(RelDataTypeFactory typeFactory,
   /** Whether the least restrictive type of a number of CHAR types of different
    * lengths should be a VARCHAR type. And similarly BINARY to VARBINARY. */
   boolean shouldConvertRaggedUnionTypesToVarying();
+
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition.
+   */
+  default RelDataType deriveDecimalPlusType(RelDataTypeFactory typeFactory,
+                                            RelDataType type1, RelDataType type2) {
+    /**
+     * Type-inference strategy whereby the result type of a call is the decimal
+     * sum of two exact numeric operands where at least one of the operands is a
+     * decimal. Let p1, s1 be the precision and scale of the first operand Let
+     * p2, s2 be the precision and scale of the second operand Let p, s be the
+     * precision and scale of the result, Then the result type is a decimal
+     * with:
+     *
+     * <ul>
+     * <li>s = max(s1, s2)</li>
+     * <li>p = max(p1 - s1, p2 - s2) + s + 1</li>
+     * </ul>
+     *
+     * <p>p and s are capped at their maximum values
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+        int scale = Math.max(s1, s2);
+        assert scale <= getMaxNumericScale();
+        int precision = Math.max(p1 - s1, p2 - s2) + scale + 1;
+        precision =
+                Math.min(
+                        precision,
+                        getMaxNumericPrecision());
+        assert precision > 0;
+
+        return typeFactory.createSqlType(
+                SqlTypeName.DECIMAL,
+                precision,
+                scale);
+      }
+    }
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal multiplication. Decimal
+   * multiplication involves at least one decimal operand and requires both
+   * operands to have exact numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal multiplication, or null if decimal
+   * multiplication should not be applied to the operands.
+   */
+  default RelDataType deriveDecimalMultiplyType(RelDataTypeFactory typeFactory,
+      RelDataType type1, RelDataType type2) {
+    /**","[{'comment': '(style): it should be a regular comment, and not a javadoc one. Since this is the default behavior, might want to move it from comment to proper javadoc', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystem.java,"@@ -100,6 +101,214 @@ RelDataType deriveCovarType(RelDataTypeFactory typeFactory,
   /** Whether the least restrictive type of a number of CHAR types of different
    * lengths should be a VARCHAR type. And similarly BINARY to VARBINARY. */
   boolean shouldConvertRaggedUnionTypesToVarying();
+
+  /**
+   * Infers the return type of a decimal addition. Decimal addition involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal addition.
+   */
+  default RelDataType deriveDecimalPlusType(RelDataTypeFactory typeFactory,
+                                            RelDataType type1, RelDataType type2) {
+    /**
+     * Type-inference strategy whereby the result type of a call is the decimal
+     * sum of two exact numeric operands where at least one of the operands is a
+     * decimal. Let p1, s1 be the precision and scale of the first operand Let
+     * p2, s2 be the precision and scale of the second operand Let p, s be the
+     * precision and scale of the result, Then the result type is a decimal
+     * with:
+     *
+     * <ul>
+     * <li>s = max(s1, s2)</li>
+     * <li>p = max(p1 - s1, p2 - s2) + s + 1</li>
+     * </ul>
+     *
+     * <p>p and s are capped at their maximum values
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+        int scale = Math.max(s1, s2);
+        assert scale <= getMaxNumericScale();
+        int precision = Math.max(p1 - s1, p2 - s2) + scale + 1;
+        precision =
+                Math.min(
+                        precision,
+                        getMaxNumericPrecision());
+        assert precision > 0;
+
+        return typeFactory.createSqlType(
+                SqlTypeName.DECIMAL,
+                precision,
+                scale);
+      }
+    }
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal multiplication. Decimal
+   * multiplication involves at least one decimal operand and requires both
+   * operands to have exact numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal multiplication, or null if decimal
+   * multiplication should not be applied to the operands.
+   */
+  default RelDataType deriveDecimalMultiplyType(RelDataTypeFactory typeFactory,
+      RelDataType type1, RelDataType type2) {
+    /**
+     * <p>Implement RelDataTypeFactory with SQL 2003 compliant behavior. Let p1,
+     * s1 be the precision and scale of the first operand Let p2, s2 be the
+     * precision and scale of the second operand Let p, s be the precision and
+     * scale of the result, Then the result type is a decimal with:
+     *
+     * <ul>
+     * <li>p = p1 + p2</li>
+     * <li>s = s1 + s2</li>
+     * </ul>
+     *
+     * <p>p and s are capped at their maximum values
+     *
+     * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+     */
+    if (SqlTypeUtil.isExactNumeric(type1)
+            && SqlTypeUtil.isExactNumeric(type2)) {
+      if (SqlTypeUtil.isDecimal(type1)
+              || SqlTypeUtil.isDecimal(type2)) {
+        int p1 = type1.getPrecision();
+        int p2 = type2.getPrecision();
+        int s1 = type1.getScale();
+        int s2 = type2.getScale();
+
+        int scale = s1 + s2;
+        scale = Math.min(scale, getMaxNumericScale());
+        int precision = p1 + p2;
+        precision =
+                Math.min(
+                        precision,
+                        getMaxNumericPrecision());
+
+        RelDataType ret;
+        ret = typeFactory.createSqlType(
+                        SqlTypeName.DECIMAL,
+                        precision,
+                        scale);
+
+        return ret;
+      }
+    }
+
+    return null;
+  }
+
+  /**
+   * Infers the return type of a decimal division. Decimal division involves
+   * at least one decimal operand and requires both operands to have exact
+   * numeric types.
+   *
+   * @param type1 type of the first operand
+   * @param type2 type of the second operand
+   * @return the result type for a decimal division, or null if decimal
+   * division should not be applied to the operands.
+   */
+  default RelDataType deriveDecimalDivideType(RelDataTypeFactory typeFactory,
+      RelDataType type1, RelDataType type2) {
+    /**","[{'comment': '(style): it should be a regular comment, and not a javadoc one. Since this is the default behavior, might want to move it from comment to proper javadoc', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/sql/type/ReturnTypes.java,"@@ -563,6 +538,23 @@ public int size() {
   public static final SqlReturnTypeInference NULLABLE_SUM =
       new SqlReturnTypeInferenceChain(DECIMAL_SUM_NULLABLE, LEAST_RESTRICTIVE);
 
+  public static final SqlReturnTypeInference DECIMAL_MOD = opBinding -> {
+    RelDataTypeFactory typeFactory = opBinding.getTypeFactory();
+    RelDataType type1 = opBinding.getOperandType(0);
+    RelDataType type2 = opBinding.getOperandType(1);
+    return typeFactory.getTypeSystem().deriveDecimalModType(typeFactory, type1, type2);
+  };
+
+  private static final SqlReturnTypeInference DECIMAL_MOD_NULLABLE =
+          cascade(DECIMAL_MOD, SqlTypeTransforms.TO_NULLABLE);
+  /**
+   * Type-inference strategy whereby the result type of a call is
+   * {@link #DECIMAL_SUM_NULLABLE} with a fallback to {@link #LEAST_RESTRICTIVE}","[{'comment': 'typo: should be `DECIMAL_MOD_NULLABLE` and `ARG1_NULLABLE`', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/sql/type/ReturnTypes.java,"@@ -563,6 +538,23 @@ public int size() {
   public static final SqlReturnTypeInference NULLABLE_SUM =
       new SqlReturnTypeInferenceChain(DECIMAL_SUM_NULLABLE, LEAST_RESTRICTIVE);
 
+  public static final SqlReturnTypeInference DECIMAL_MOD = opBinding -> {
+    RelDataTypeFactory typeFactory = opBinding.getTypeFactory();
+    RelDataType type1 = opBinding.getOperandType(0);
+    RelDataType type2 = opBinding.getOperandType(1);
+    return typeFactory.getTypeSystem().deriveDecimalModType(typeFactory, type1, type2);
+  };
+
+  private static final SqlReturnTypeInference DECIMAL_MOD_NULLABLE =
+          cascade(DECIMAL_MOD, SqlTypeTransforms.TO_NULLABLE);
+  /**
+   * Type-inference strategy whereby the result type of a call is
+   * {@link #DECIMAL_SUM_NULLABLE} with a fallback to {@link #LEAST_RESTRICTIVE}
+   * These rules are used for addition and subtraction.","[{'comment': 'for modulo', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -516,66 +474,13 @@ public boolean useDoubleMultiplication(
   }
 
   /**
-   * Rules:
-   *
-   * <ul>
-   * <li>Let p1, s1 be the precision and scale of the first operand
-   * <li>Let p2, s2 be the precision and scale of the second operand
-   * <li>Let p, s be the precision and scale of the result
-   * <li>Let d be the number of whole digits in the result
-   * <li>Then the result type is a decimal with:
-   *   <ul>
-   *   <li>d = p1 - s1 + s2</li>
-   *   <li>s &lt; max(6, s1 + p2 + 1)</li>
-   *   <li>p = d + s</li>
-   *   </ul>
-   * </li>
-   * <li>p and s are capped at their maximum values</li>
-   * </ul>
-   *
-   * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+   * Delegates to RelDataTypeSystem#deriveDecimalDivideType to get the return type","[{'comment': 'use `{@link ...}` to actually link to the method', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactoryImpl.java,"@@ -457,54 +456,13 @@ public static boolean isJavaType(RelDataType t) {
   }
 
   /**
-   * {@inheritDoc}
-   *
-   * <p>Implement RelDataTypeFactory with SQL 2003 compliant behavior. Let p1,
-   * s1 be the precision and scale of the first operand Let p2, s2 be the
-   * precision and scale of the second operand Let p, s be the precision and
-   * scale of the result, Then the result type is a decimal with:
-   *
-   * <ul>
-   * <li>p = p1 + p2</li>
-   * <li>s = s1 + s2</li>
-   * </ul>
-   *
-   * <p>p and s are capped at their maximum values
-   *
-   * @see Glossary#SQL2003 SQL:2003 Part 2 Section 6.26
+   * Delegates to RelDataTypeSystem#deriveDecimalMultiplyType to get the return type","[{'comment': 'use `{@link ...}` to actually link to the method', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactory.java,"@@ -271,6 +271,7 @@ RelDataType createSqlIntervalType(
    * @return the result type for a decimal multiplication, or null if decimal
    * multiplication should not be applied to the operands.
    */
+  @Deprecated // use RelDataTypeSystem#deriveDecimalMultiplyType instead.","[{'comment': 'use javadoc `@deprecated` tag to link to another method', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactory.java,"@@ -295,6 +296,7 @@ boolean useDoubleMultiplication(
    * @return the result type for a decimal division, or null if decimal
    * division should not be applied to the operands.
    */
+  @Deprecated // use RelDataTypeSystem#deriveDecimalDivideType instead.","[{'comment': 'use javadoc `@deprecated` tag to link to another method', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactory.java,"@@ -271,7 +271,8 @@ RelDataType createSqlIntervalType(
    * @return the result type for a decimal multiplication, or null if decimal
    * multiplication should not be applied to the operands.
    */
-  @Deprecated // use RelDataTypeSystem#deriveDecimalMultiplyType instead.
+  /** @deprecated Use {@link RelDataTypeSystem#deriveDecimalMultiplyType} */","[{'comment': '(javadoc) need to be merged with the previous javadoc section', 'commenter': 'laurentgo'}]"
1311,core/src/main/java/org/apache/calcite/rel/type/RelDataTypeFactory.java,"@@ -296,7 +297,8 @@ boolean useDoubleMultiplication(
    * @return the result type for a decimal division, or null if decimal
    * division should not be applied to the operands.
    */
-  @Deprecated // use RelDataTypeSystem#deriveDecimalDivideType instead.
+  /** @deprecated Use {@link RelDataTypeSystem#deriveDecimalDivideType} */","[{'comment': '(javadoc) need to be merged with the previous javadoc section', 'commenter': 'laurentgo'}]"
1319,linq4j/src/main/java/org/apache/calcite/linq4j/tree/TryStatement.java,"@@ -36,7 +37,17 @@ public TryStatement(Statement body, List<CatchBlock> catchBlocks,
   }
 
   @Override public Statement accept(Shuttle shuttle) {
-    return shuttle.visit(this);
+    shuttle = shuttle.preVisit(this);
+    Statement body1 = body.accept(shuttle);
+    List<CatchBlock> catchBlocks1 = new ArrayList<>();
+    for (CatchBlock cb: catchBlocks) {
+      Statement cbBody = cb.body.accept(shuttle);
+      catchBlocks1.add(
+          Expressions.catch_(cb.parameter, cbBody));
+    }
+    Statement fynally1 =
+        fynally == null ? null : fynally.accept(shuttle);","[{'comment': 'Looks like this should be `finally`?', 'commenter': 'michaelmior'}, {'comment': '@michaelmior Thanks for review! I addressed your comments. \r\nAs ""finally"" is a keyword, I follow the variable name **fynally** in `TryStatement`.', 'commenter': 'DonnyZone'}, {'comment': 'Of course. This slipped my mind when reviewing :)', 'commenter': 'michaelmior'}]"
1319,linq4j/src/test/java/org/apache/calcite/linq4j/test/InlinerTest.java,"@@ -194,6 +196,40 @@ void checkAssignInConditionOptimizedOut(int modifiers, String s) {
             + ""}\n"",
         Expressions.toString(builder.toBlock()));
   }
+
+  @Test public void testInlineInTryCatchStatement() {
+    // final int t = 1;
+    // final int u;
+    // try {
+    //   u = t + 2;
+    // } catch (Exception e) {
+    //   throw e;
+    // }
+    // return u;","[{'comment': 'The commented out code above should be removed.', 'commenter': 'michaelmior'}]"
1319,core/src/main/java/org/apache/calcite/adapter/enumerable/ReflectiveCallNotNullImplementor.java,"@@ -47,17 +47,34 @@ public Expression implement(RexToLixTranslator translator,
       RexCall call, List<Expression> translatedOperands) {
     translatedOperands =
         EnumUtils.fromInternal(method.getParameterTypes(), translatedOperands);
+    final Expression callExpr;
     if ((method.getModifiers() & Modifier.STATIC) != 0) {
-      return Expressions.call(method, translatedOperands);
+      callExpr = Expressions.call(method, translatedOperands);
     } else {
       // The UDF class must have a public zero-args constructor.
       // Assume that the validator checked already.
       final Expression target =
           Expressions.new_(method.getDeclaringClass());
-      return Expressions.call(target, method, translatedOperands);
+      callExpr = Expressions.call(target, method, translatedOperands);
     }
+    if (!containsCheckedException(method)) {
+      return callExpr;
+    }
+    return translator.handleMethodCheckedExceptions(callExpr);
   }
 
+  private boolean containsCheckedException(Method method) {
+    Class[] exceptions = method.getExceptionTypes();
+    if (exceptions == null || exceptions.length == 0) {
+      return false;
+    }
+    for (Class clazz: exceptions) {","[{'comment': 'Sorry this is getting really nitpicky, but there should be a space on either side of the `:`.', 'commenter': 'michaelmior'}]"
1319,core/src/main/java/org/apache/calcite/adapter/enumerable/RexToLixTranslator.java,"@@ -622,6 +624,35 @@ public Expression handleNull(Expression input, RexImpTable.NullAs nullAs) {
     return unboxed;
   }
 
+  /**
+   * Handle checked Exceptions declared in Method. In such case,
+   * method call should be wrapped in a try...catch block.
+   * ""
+   *      final Type method_call;
+   *      try {
+   *        method_call = callExpr
+   *      } catch (Exception e) {
+   *        throw new RuntimeException(e);
+   *      }
+   * ""
+   */
+  Expression handleMethodCheckedExceptions(Expression callExpr) {
+    // Try statement
+    ParameterExpression methodCall = Expressions.parameter(
+        callExpr.getType(), list.newName(""method_call""));
+    list.add(Expressions.declare(Modifier.FINAL, methodCall, null));
+    Statement st = Expressions.statement(
+        Expressions.assign(methodCall, callExpr));
+    // Catch Block, wrap checked exception in unchecked exception
+    ParameterExpression e = Expressions.parameter(0, Exception.class, ""e"");
+    Expression uncheckedException =
+        Expressions.new_(RuntimeException.class, e);
+    CatchBlock cb = Expressions.catch_(e,
+        Expressions.throw_(uncheckedException));","[{'comment': 'The line breaks here seem unnecessary as these L648-651 could fit on two lines without being too long. (L644-645 could also be collapsed to a single line.)', 'commenter': 'michaelmior'}]"
1319,core/src/test/java/org/apache/calcite/test/UdfTest.java,"@@ -219,6 +225,35 @@
     withUdf().query(sql).returns(expected);
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3195"">[CALCITE-3195]
+   * Handle UDF that throws checked exceptions in enumerable code generator</a>. */","[{'comment': 'I suggest rewording to ""Handle **a** UDF that throws in **the Enumerable** code generator""', 'commenter': 'michaelmior'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,57 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    boolean checkNull = isNeedCastNull(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Check whether null item in select need to be casted
+   * @param stack stack of visit
+   * @return If null need to be casted then return true, otherwise return false.
+   */
+  private static boolean isNeedCastNull(Deque<Frame> stack) {
+    final int stackSize = stack.size();
+    if (stackSize > 1) {","[{'comment': 'If I am not mistaken, this `if` is not really needed, just having a for loop:\r\n`for (int i = 1; i < stack.size(); i++) { ... }` should achieve the same result.\r\nAlso, we can get rid of `stackSize` local variable.', 'commenter': 'rubenada'}, {'comment': '1. Yes, ""if"" indeed need to be removed.\r\n2. I think stackSize is needed because that there is extra computation in  java.util.ArrayDeque#size', 'commenter': 'weidong3630'}, {'comment': 'Yep, agree on keeping stackSize local variable', 'commenter': 'rubenada'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,57 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    boolean checkNull = isNeedCastNull(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Check whether null item in select need to be casted
+   * @param stack stack of visit
+   * @return If null need to be casted then return true, otherwise return false.
+   */
+  private static boolean isNeedCastNull(Deque<Frame> stack) {
+    final int stackSize = stack.size();
+    if (stackSize > 1) {
+      int i = 1;
+      for (; i < stackSize; i++) {
+        RelNode currentNode = Iterables.get(stack, i).r;
+        if (!(currentNode instanceof SingleRel)) {
+          break;
+        } else if (currentNode instanceof Project) {
+          //direct or indirect input of Project need to cast null type
+          break;
+        } else if (currentNode instanceof TableModify) {
+          //direct or indirect input of TableModify do not need to cast null type
+          return false;
+        }
+      }
+    }
+
+    return true;
+  }
+
+  /**
+   * cast null with type
+   * @param sqlNodeNull null SqlNode
+   * @param field field description of sqlNodeNull
+   * @return SqlNode with cast to type.
+   */
+  private SqlNode  castNullType(SqlNode sqlNodeNull, RelDataTypeField field) {","[{'comment': 'extra whitespace before method name: `private SqlNode  castNullType(...`', 'commenter': 'rubenada'}, {'comment': 'Thanks, I will fix it.', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,57 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    boolean checkNull = isNeedCastNull(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Check whether null item in select need to be casted
+   * @param stack stack of visit
+   * @return If null need to be casted then return true, otherwise return false.
+   */
+  private static boolean isNeedCastNull(Deque<Frame> stack) {","[{'comment': 'IMHO, this method should be renamed, e.g. `isCastNullNeeded`', 'commenter': 'rubenada'}, {'comment': 'Thanks, I accept this.', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,54 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    boolean checkNull = isCastNullNeeded(stack);","[{'comment': 'to be consistent, please declare `checkNull` variable `final`', 'commenter': 'rubenada'}, {'comment': 'I wil fix it.', 'commenter': 'weidong3630'}, {'comment': 'I have fixed it and commit has been pushed.', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,54 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    boolean checkNull = isCastNullNeeded(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Check whether null item in select need to be casted
+   * @param stack stack of visit
+   * @return If null need to be casted then return true, otherwise return false.
+   */
+  private static boolean isCastNullNeeded(Deque<Frame> stack) {
+    final int stackSize = stack.size();
+    for (int i = 1; i < stackSize; i++) {
+      RelNode currentNode = Iterables.get(stack, i).r;
+      if (!(currentNode instanceof SingleRel)) {","[{'comment': ""I think it would be simpler to merge this condition and the next one into a single one linked by 'OR'."", 'commenter': 'rubenada'}, {'comment': 'I don\'t think it\'s ok to do this. The ""!(currentNode instanceof SingleRel)"" condition means that if currentNode which is not  instance of  SingleRel like Join was found before breaking or returning, null casting is needed, while the ""currentNode instanceof Project"" means that if project including the ""null"" literal is under another project, null casting is need. So according meaning, the two conditions cannot be merged regardless of java grammer.', 'commenter': 'weidong3630'}, {'comment': 'The consequence of both conditions is that ""null casting is needed"". I think the code will be more concise by combining the conditions, but if you think it is more clear to have them separate, I\'m not against it, let\'s keep it as it is.', 'commenter': 'rubenada'}, {'comment': 'OK. ', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,78 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    final boolean checkNull = isCastNullNeeded(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Returns whether a NULL literal in the SELECT clause needs to be wrapped in a CAST.
+   * @param stack stack of visit
+   * @return If null needs to be casted then return true, otherwise return false.
+   * There are several cases to handle :
+   * 1. If a Project is under a Join or other operator which not instance of SingleRel,
+   *    and there may be some SingleRel which is not Project between the project and none SingleRel,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) AS t1
+   *    JOIN (SELECT c3, c4 FROM t2) AS t2 ON c2 = c3""
+   *
+   * 2. If a Project is under another Project,
+   *    and there may be some SingleRel which is not Project between these two Project,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) as t1 WHERE c2 = 10""
+   *
+   * 3. If a Project is under a  TableModify,
+   *    and there may be some SingleRel which is not Project between the Project and TableModify,
+   *    because that the type of NULL can be inferred  by the target table of TableModify,
+   *    so NULL does not need to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""INSERT INTO t SELECT CAST(NULL AS INT) AS c1, c2 FROM t1""","[{'comment': 'What do you mean by ""SingleRel"", i didn\'t see any in your example.', 'commenter': 'danny0405'}, {'comment': 'Implemented done.', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,78 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    final boolean checkNull = isCastNullNeeded(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Returns whether a NULL literal in the SELECT clause needs to be wrapped in a CAST.
+   * @param stack stack of visit
+   * @return If null needs to be casted then return true, otherwise return false.
+   * There are several cases to handle :
+   * 1. If a Project is under a Join or other operator which not instance of SingleRel,
+   *    and there may be some SingleRel which is not Project between the project and none SingleRel,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) AS t1
+   *    JOIN (SELECT c3, c4 FROM t2) AS t2 ON c2 = c3""
+   *
+   * 2. If a Project is under another Project,
+   *    and there may be some SingleRel which is not Project between these two Project,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) as t1 WHERE c2 = 10""
+   *
+   * 3. If a Project is under a  TableModify,
+   *    and there may be some SingleRel which is not Project between the Project and TableModify,
+   *    because that the type of NULL can be inferred  by the target table of TableModify,
+   *    so NULL does not need to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""INSERT INTO t SELECT CAST(NULL AS INT) AS c1, c2 FROM t1""
+   *
+   * Please note that in the example mentioned above,
+   *  the Project converted by the select statement with ""CAST(NULL AS INT)""
+   *  is with no CAST call but a NULL expression and a data type described in RowType.
+   */
+  private static boolean isCastNullNeeded(Deque<Frame> stack) {
+    final int stackSize = stack.size();
+    for (int i = 1; i < stackSize; i++) {
+      RelNode currentNode = Iterables.get(stack, i).r;
+      if (!(currentNode instanceof SingleRel)) {
+        break;
+      } else if (currentNode instanceof Project) {
+        // direct or indirect input of Project need to cast null type
+        break;","[{'comment': 'Returns early instead of break seems more readable.', 'commenter': 'danny0405'}, {'comment': 'Fixed.', 'commenter': 'weidong3630'}]"
1338,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3533,6 +3533,51 @@ private void checkLiteral2(String expression, String expected) {
     assertTrue(postgresqlDialect.supportsDataType(integerDataType));
   }
 
+  @Test public void testSelectNull() {
+    String query = ""SELECT CAST(NULL AS INT)"";
+    final String expected = ""SELECT CAST(NULL AS INTEGER)\n""
+            + ""FROM (VALUES  (0)) AS \""t\"" (\""ZERO\"")"";
+    sql(query).ok(expected);
+    //validate
+    sql(expected).exec();
+  }
+
+  @Test public void testSelectNullWithCount() {
+    String query = ""SELECT COUNT(CAST(NULL AS INT))"";
+    final String expected = ""SELECT COUNT(CAST(NULL AS INTEGER))\n""
+            + ""FROM (VALUES  (0)) AS \""t\"" (\""ZERO\"")"";
+    sql(query).ok(expected);
+    //validate
+    sql(expected).exec();
+  }
+
+  @Test public void testSelectNullWithGroupBy() {
+    String query = ""SELECT COUNT(CAST(NULL AS INT)) FROM (VALUES  (0)) ""
+            + ""AS \""t\"" GROUP BY CAST(NULL AS VARCHAR CHARACTER SET \""ISO-8859-1\"")"";
+    final String expected = ""SELECT COUNT(CAST(NULL AS INTEGER))\n""
+            + ""FROM (VALUES  (0)) AS \""t\"" (\""EXPR$0\"")\nGROUP BY CAST(NULL ""
+            + ""AS VARCHAR CHARACTER SET \""ISO-8859-1\"")"";
+    sql(query).ok(expected);
+    //validate
+    sql(expected).exec();
+  }
+
+  @Test public void testSelectNullWithInsert() {
+    String query = ""insert into ""
+            + ""\""account\""(\""account_id\"",\""account_parent\"",\""account_type\"",\""account_rollup\"")""
+            + "" select 1, cast(NULL AS INT), cast(123 as varchar), cast(123 as varchar)"";
+    final String expected = ""INSERT INTO ""
+            + ""\""foodmart\"".\""account\"" (\""account_id\"", \""account_parent\"", \""account_description\"", ""
+            + ""\""account_type\"", \""account_rollup\"", \""Custom_Members\"")\n""
+            + ""(SELECT 1 AS \""account_id\"", NULL AS \""account_parent\"", ""
+            + ""NULL AS \""account_description\"", '123' AS \""account_type\"", ""
+            + ""'123' AS \""account_rollup\"", NULL AS \""Custom_Members\""\n""
+            + ""FROM (VALUES  (0)) AS \""t\"" (\""ZERO\""))"";
+    sql(query).ok(expected);
+    //validate
+    sql(expected).exec();","[{'comment': '// validate', 'commenter': 'danny0405'}, {'comment': 'Fixed.', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,78 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    final boolean checkNull = isCastNullNeeded(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Returns whether a NULL literal in the SELECT clause needs to be wrapped in a CAST.
+   * @param stack stack of visit
+   * @return If null needs to be casted then return true, otherwise return false.
+   * There are several cases to handle :
+   * 1. If a Project is under a Join or other operator which not instance of SingleRel,
+   *    and there may be some SingleRel which is not Project between the project and none SingleRel,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) AS t1
+   *    JOIN (SELECT c3, c4 FROM t2) AS t2 ON c2 = c3""
+   *
+   * 2. If a Project is under another Project,
+   *    and there may be some SingleRel which is not Project between these two Project,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) as t1 WHERE c2 = 10""
+   *
+   * 3. If a Project is under a  TableModify,
+   *    and there may be some SingleRel which is not Project between the Project and TableModify,
+   *    because that the type of NULL can be inferred  by the target table of TableModify,
+   *    so NULL does not need to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""INSERT INTO t SELECT CAST(NULL AS INT) AS c1, c2 FROM t1""
+   *
+   * Please note that in the example mentioned above,
+   *  the Project converted by the select statement with ""CAST(NULL AS INT)""
+   *  is with no CAST call but a NULL expression and a data type described in RowType.
+   */
+  private static boolean isCastNullNeeded(Deque<Frame> stack) {
+    final int stackSize = stack.size();
+    for (int i = 1; i < stackSize; i++) {
+      RelNode currentNode = Iterables.get(stack, i).r;
+      if (!(currentNode instanceof SingleRel)) {
+        break;
+      } else if (currentNode instanceof Project) {
+        // direct or indirect input of Project need to cast null type
+        break;
+      } else if (currentNode instanceof TableModify) {
+        // direct or indirect input of TableModify do not need to cast null type
+        return false;
+      }
+    }
+
+    return true;
+  }
+
+  /**
+   * cast null with type
+   * @param sqlNodeNull null SqlNode
+   * @param field field description of sqlNodeNull
+   * @return SqlNode with cast to type.
+   */
+  private SqlNode castNullType(SqlNode sqlNodeNull, RelDataTypeField field) {","[{'comment': '  /**\r\n   * Wrap the {code sqlNodeNull} in a CAST operator with target type as {code field}.\r\n   * @param sqlNodeNull null literal\r\n   * @param field field description of sqlNodeNull\r\n   * @return null literal wrapped in CAST call.\r\n   */', 'commenter': 'danny0405'}, {'comment': 'Fixed, thanks .', 'commenter': 'weidong3630'}, {'comment': 'javadoc minor details: you are missing the `*` at the beginning of each line; I think `{code foo}` should actually be `{@code foo}` ', 'commenter': 'rubenada'}, {'comment': 'Fixed, thanks.', 'commenter': 'weidong3630'}]"
1338,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -195,15 +198,81 @@ public Result visit(Project e) {
     final Builder builder =
         x.builder(e, Clause.SELECT);
     final List<SqlNode> selectList = new ArrayList<>();
+
+    final boolean checkNull = isCastNullNeeded(stack);
     for (RexNode ref : e.getChildExps()) {
       SqlNode sqlExpr = builder.context.toSql(null, ref);
+      if (checkNull && SqlUtil.isNullLiteral(sqlExpr, false)) {
+        sqlExpr = castNullType(sqlExpr, e.getRowType().getFieldList().get(selectList.size()));
+      }
       addSelect(selectList, sqlExpr, e.getRowType());
     }
 
     builder.setSelect(new SqlNodeList(selectList, POS));
     return builder.result();
   }
 
+  /**
+   * Returns whether a NULL literal in the SELECT clause needs to be wrapped in a CAST.
+   * @param stack stack of visit
+   * @return If null needs to be casted then return true, otherwise return false.
+   * There are several cases to handle :
+   * 1. If a Project is under a Join or other operator which not instance of SingleRel,
+   *    and there may be some SingleRel which is not Project between the project and none SingleRel,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) AS t1
+   *    JOIN (SELECT c3, c4 FROM t2) AS t2 ON c2 = c3""
+   *
+   * 2. If a Project is under another Project,
+   *    and there may be some SingleRel which is not Project between these two Project,
+   *    NULL needs to be wrapped in a CAST.
+   *    Here is an example,
+   *    ""SELECT * FROM (SELECT CAST(NULL AS INT) AS c1, c2 FROM t1) as t1 WHERE c2 = 10""
+   *
+   * 3. If a Project is under a  TableModify,
+   *    and there may be some SingleRel which is not Project between the Project and TableModify,
+   *    because that the type of NULL can be inferred  by the target table of TableModify,
+   *    so NULL does not need to be wrapped in a CAST.
+   *    Here is some examples,
+   *    3.1 ""INSERT INTO t SELECT CAST(NULL AS INT) AS c1, c2 FROM t1""
+   *    3.2 ""INSERT INTO t SELECT COUNT(CAST(NULL AS INT))""
+   *        In case3.2, there is an LogicalAggregate which is instance of SingleRel between
+   *           TableModify and Project.
+   *
+   * Please note that in the example mentioned above,
+   *  the Project converted by the select statement with ""CAST(NULL AS INT)""
+   *  is with no CAST call but a NULL expression and a data type described in RowType.
+   */
+  private static boolean isCastNullNeeded(Deque<Frame> stack) {
+    final int stackSize = stack.size();
+    for (int i = 1; i < stackSize; i++) {
+      RelNode currentNode = Iterables.get(stack, i).r;
+      if (!(currentNode instanceof SingleRel)) {
+        return true;
+      } else if (currentNode instanceof Project) {
+        // direct or indirect input of Project need to cast null type","[{'comment': ""I don't think we should have such decision here, AFAIK, Calcite does not support `select null from table_name` statement now, we should always wrap the null literal in a `CAST` operator in the project list.\r\n\r\nIt is not necessary to look up the input relational expressions, because the `NULL` literal can appear in the air in the `Project` project list."", 'commenter': 'danny0405'}, {'comment': ""The response for the first suggestion, `select null` can be a input of `insert`, so not all  `select null` is not supported.\r\nFor `It is not necessary to look up the input relational expressions`, I don't get it because I've done nothing about input relational expressions of `Project` but stack of `RelNode`."", 'commenter': 'weidong3630'}, {'comment': 'The stack elements are the inputs of the current relational expression, where for your case they are inputs of `Project` because this method is invoked when visiting `Project` node.\r\n\r\nFor table modify (insert or update), we can handle them separately here.', 'commenter': 'danny0405'}]"
1338,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3694,6 +3694,51 @@ private void checkLiteral2(String expression, String expected) {
     assertTrue(postgresqlDialect.supportsDataType(integerDataType));
   }
 
+  @Test public void testSelectNull() {
+    String query = ""SELECT CAST(NULL AS INT)"";
+    final String expected = ""SELECT CAST(NULL AS INTEGER)\n""
+            + ""FROM (VALUES  (0)) AS \""t\"" (\""ZERO\"")"";
+    sql(query).ok(expected);
+    // validate
+    sql(expected).exec();
+  }
+
+  @Test public void testSelectNullWithCount() {
+    String query = ""SELECT COUNT(CAST(NULL AS INT))"";
+    final String expected = ""SELECT COUNT(CAST(NULL AS INTEGER))\n""
+            + ""FROM (VALUES  (0)) AS \""t\"" (\""ZERO\"")"";
+    sql(query).ok(expected);
+    // validate
+    sql(expected).exec();
+  }
+
+  @Test public void testSelectNullWithGroupBy() {
+    String query = ""SELECT COUNT(CAST(NULL AS INT)) FROM (VALUES  (0)) ""
+            + ""AS \""t\"" GROUP BY CAST(NULL AS VARCHAR CHARACTER SET \""ISO-8859-1\"")"";","[{'comment': 'Can we give a test case that group by a normal table fields ? Not group by empty group set or constant. Also give a test case for `Join`.', 'commenter': 'danny0405'}, {'comment': 'I can do this, but I wonder that if there is some deferences?', 'commenter': 'weidong3630'}, {'comment': 'Grouping by constant means there is only one group globally so we can do some promotion of plan for some aggregate calls.', 'commenter': 'danny0405'}]"
1347,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -2372,12 +2372,12 @@ private void checkNullableTimestamp(CalciteAssert.Config config) {
     CalciteAssert.hr()
         .query(
             ""select upper((case when \""empid\"">\""deptno\""*10 then \""name\"" end)) T from \""hr\"".\""emps\"""")
-        .planContains(
-            ""final String inp2_ = current.name;"")
-        .planContains(""return current.empid <= current.deptno * 10 ""
-            + ""|| inp2_ == null ""
-            + ""? (String) null ""
-            + "": org.apache.calcite.runtime.SqlFunctions.upper(inp2_);"")
+//        .planContains(
+//            ""final String inp2_ = current.name;"")
+//        .planContains(""return current.empid <= current.deptno * 10 ""","[{'comment': 'Please fix relevant tests.\r\nIn other words, for now you comment the generated code, and it is not clear what code is produced out of a new genertor', 'commenter': 'vlsi'}, {'comment': '@vlsi Thanks for review! I have addressed your first comment.', 'commenter': 'DonnyZone'}]"
1347,core/src/test/java/org/apache/calcite/test/ReflectiveSchemaTest.java,"@@ -581,6 +581,12 @@ private void check(ResultSetMetaData metaData, String columnName,
         CalciteAssert.that().withSchema(""s"", CATCHALL);
     with.query(""select \""wrapperLong\"" / \""primitiveLong\"" as c\n""
         + "" from \""s\"".\""everyTypes\"" where \""primitiveLong\"" <> 0"")
+        .planContains(
+            ""final Long input_value = current.wrapperLong;"")
+        .planContains(
+            ""final boolean input_isNull = input_value == null;"")
+        .planContains(
+            ""return input_isNull ? (Long) null : Long.valueOf(input_isNull ? 0L : input_value / Long.valueOf(current.primitiveLong));"")","[{'comment': 'Technically speaking the second check of `input_isNull` is not required in `Long.valueOf(input_isNull `', 'commenter': 'vlsi'}, {'comment': 'I guess it was implemented in previous codegen.', 'commenter': 'vlsi'}, {'comment': ""Yes, it is the final step.\r\nWe need to wrap `(isNull, value)` as the Expression.\r\nAs there are some cases like` (isNull=true, value=0)`, in which the `value` a primitive's default value, we can not return `value` directly.\r\nTherefore, to avoid lossing nullable, generating:\r\n`isNull? (**)null, box(value)`\r\n\r\n"", 'commenter': 'DonnyZone'}, {'comment': 'What I mean is current codegen would likely produce\r\n`return input_isNull ? (Long) null : Long.valueOf(input_value / Long.valueOf(current.primitiveLong));`\r\n\r\nHow are you going to approach that?', 'commenter': 'vlsi'}, {'comment': 'Current implementation conduct a step-by-step manner, maybe the non-optimized code is more intuitive.\r\n\r\n**public Object current() {\r\n     final org.apache.calcite.test.ReflectiveSchemaTest.EveryType current = (org.apache.calcite.test.ReflectiveSchemaTest.EveryType) inputEnumerator.current();\r\n     final Long input_value = current.wrapperLong;\r\n     final boolean input_isNull = input_value == null;\r\n     final long input_value0 = current.primitiveLong;\r\n     final boolean input_isNull0 = false;\r\n     final long binary_call_value = input_isNull || input_isNull0 ? 0L : input_value / Long.valueOf(input_value0);\r\n     final boolean binary_call_isNull = input_isNull || input_isNull0;\r\n     final Long result = binary_call_isNull ? (Long) null : Long.valueOf(binary_call_value);\r\n     return result;\r\n }**\r\n\r\nThe implementation introduces some patterns that need be optimized in BlockBuilder.', 'commenter': 'DonnyZone'}, {'comment': '@vlsi I think we need to optimize this kind of code in BlockBuilder.', 'commenter': 'DonnyZone'}]"
1347,core/src/main/java/org/apache/calcite/adapter/enumerable/RexToLixTranslator.java,"@@ -741,8 +757,8 @@ public RexNode deref(RexNode expr) {
   /** Translates a call to an operator or function. */
   private Expression translateCall(RexCall call, RexImpTable.NullAs nullAs) {
     final SqlOperator operator = call.getOperator();
-    CallImplementor implementor =
-        RexImpTable.INSTANCE.get(operator);
+    CallImplementor implementor = null;","[{'comment': 'Could we have a comment explaining this change?', 'commenter': 'rubenada'}, {'comment': 'Thanks for review!\r\nThis is the commit just for functionality.  As `translateRexCall` will be never called under new implementation, I just set null here to pass the compilation. For review convenience, I try to minimize the changes as possible. In latter commits (e.g., cosmetic and refactor), these unused parts will be removed.', 'commenter': 'DonnyZone'}, {'comment': 'Ok, thanks for the clarification!', 'commenter': 'rubenada'}]"
1347,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -2451,12 +2451,14 @@ private void checkNullableTimestamp(CalciteAssert.Config config) {
     CalciteAssert.hr()
         .query(
             ""select upper((case when \""empid\"">\""deptno\""*10 then 'y' else null end)) T from \""hr\"".\""emps\"""")
-        .planContains(""static final String ""
-            + ""$L4J$C$org_apache_calcite_runtime_SqlFunctions_upper_y_ = ""
-            + ""org.apache.calcite.runtime.SqlFunctions.upper(\""y\"");"")
-        .planContains(""return current.empid <= current.deptno * 10 ""
-            + ""? (String) null ""
-            + "": $L4J$C$org_apache_calcite_runtime_SqlFunctions_upper_y_;"")
+        .planContains(""      String case_when_value;\n""","[{'comment': 'My understanding is that this and the following tests having the prefix `testReuseExpressionWhenNullChecking` are meant to verify that certain optimizations take place when we are generating code for nulls. \r\n\r\n1. Are these optimizations possible with the new code generator? \r\n2. Are these optimizations applied already? \r\n3. If not can we apply them in the future?\r\n', 'commenter': 'zabetak'}, {'comment': ""The new codegen framework can naturally reuses expressions, due to:\r\nIt removes the mutable state (i.e., `Map<? extends RexNode, Boolean> exprNullableMap`), and generates code strictly corresonding to RexNode in one-to-one manner. \r\n\r\nTherefore, the redundant code (including `null` checking) caused by tranversing with mutable state will not be produced again in the new codegen. On the other hand, we also keep a map in `RexToLixTranslator` for same RexNode's code reuse."", 'commenter': 'DonnyZone'}, {'comment': 'So the answer to my question is 2 since reuse is achieved by design, is that right?', 'commenter': 'zabetak'}, {'comment': 'Yes, I think so. Please correct me if I missed something :).', 'commenter': 'DonnyZone'}]"
1347,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -2544,35 +2556,117 @@ private void checkNullableTimestamp(CalciteAssert.Config config) {
             + ""from\n""
             + ""\""hr\"".\""emps\"""")
         .planContains(
-            ""final String inp2_ = current.name;"")
-        .planContains(
-            ""final int inp1_ = current.deptno;"")
-        .planContains(
-            ""static final int $L4J$C$5_2 = 5 - 2;"")
-        .planContains(
-            ""static final Integer $L4J$C$Integer_valueOf_5_2_ = Integer.valueOf($L4J$C$5_2);"")
-        .planContains(
-            ""static final int $L4J$C$Integer_valueOf_5_2_intValue_ = $L4J$C$Integer_valueOf_5_2_.intValue();"")
-        .planContains(""static final boolean ""
-            + ""$L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_ = ""
-            + ""org.apache.calcite.runtime.SqlFunctions.eq(\""\"", \""\"");"")
-        .planContains(""static final boolean ""
-            + ""$L4J$C$_org_apache_calcite_runtime_SqlFunctions_eq_ = ""
-            + ""!$L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_;"")
-        .planContains(""return inp2_ == null ""
-            + ""|| $L4J$C$_org_apache_calcite_runtime_SqlFunctions_eq_ ""
-            + ""|| current.empid <= inp1_ && inp1_ * 8 <= 8 ""
-            + ""? (String) null ""
-            + "": org.apache.calcite.runtime.SqlFunctions.substring(""
-            + ""org.apache.calcite.runtime.SqlFunctions.trim(true, true, \"" \"", ""
-            + ""org.apache.calcite.runtime.SqlFunctions.substring(inp2_, ""
-            + ""Integer.valueOf(inp1_ * 0 + 1).intValue()), true), $L4J$C$Integer_valueOf_5_2_intValue_);"")
+              ""              final org.apache.calcite.test.JdbcTest.Employee current = (org.apache.calcite.test.JdbcTest.Employee) inputEnumerator.current();\n""
+            + ""              final String input_value = current.name;\n""
+            + ""              final int input_value0 = current.deptno;\n""
+            + ""              Integer case_when_value;\n""
+            + ""              if ($L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_) {\n""
+            + ""                case_when_value = $L4J$C$Integer_valueOf_1_;\n""
+            + ""              } else {\n""
+            + ""                case_when_value = (Integer) null;\n""
+            + ""              }\n""
+            + ""              final Integer binary_call_value1 = case_when_value == null ? (Integer) null : Integer.valueOf(Integer.valueOf(input_value0 * 0) + case_when_value);\n""
+            + ""              final String method_call_value = input_value == null || binary_call_value1 == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.substring(input_value, binary_call_value1.intValue());\n""
+            + ""              final String trim_value = method_call_value == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.trim(true, true, \"" \"", method_call_value, true);\n""
+            + ""              Integer case_when_value0;\n""
+            + ""              if (current.empid > input_value0) {\n""
+            + ""                case_when_value0 = $L4J$C$Integer_valueOf_5_;\n""
+            + ""              } else {\n""
+            + ""                Integer case_when_value1;\n""
+            + ""                if (current.deptno * 8 > 8) {\n""
+            + ""                  case_when_value1 = $L4J$C$Integer_valueOf_5_;\n""
+            + ""                } else {\n""
+            + ""                  case_when_value1 = (Integer) null;\n""
+            + ""                }\n""
+            + ""                case_when_value0 = case_when_value1;\n""
+            + ""              }\n""
+            + ""              final Integer binary_call_value3 = case_when_value0 == null ? (Integer) null : Integer.valueOf(case_when_value0 - $L4J$C$Integer_valueOf_2_);\n""
+            + ""              return trim_value == null || binary_call_value3 == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.substring(trim_value, binary_call_value3.intValue());""
+        )
         .returns(""T=ll\n""
             + ""T=ic\n""
             + ""T=bastian\n""
             + ""T=eodore\n"");
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3142"">[CALCITE-3142]
+   * An NPE when rounding a nullable numeric</a>. */
+  @Test public void testRoundingNPE() {
+    CalciteAssert.that()
+        .query(""SELECT ROUND(CAST((X/Y) AS NUMERIC), 2) ""
+            + ""FROM (VALUES (1, 2), (NULLIF(5, 5), NULLIF(5, 5))) A(X, Y)"")
+        .planContains(""      final Object[] current = (Object[]) inputEnumerator.current();\n""","[{'comment': 'Is there a particular reason to verify that the generated code is exactly the one included in the test? I would say that for this test it suffices to verify that the query runs correctly without NPE and not really checking the code line by line.', 'commenter': 'zabetak'}, {'comment': ""No particular reason, just provide the generated code as @vlsi 's request."", 'commenter': 'DonnyZone'}, {'comment': 'There are at least two cases for verifying the generated code:\r\n1) Ensure the optimizations are there\r\n2) Ensure the code is safe (e.g. to check it does not dereference before checking for null)\r\n\r\nWe don\'t have ""performance regression"" tests yet, so it makes sense to add assertions for the generated source.', 'commenter': 'vlsi'}, {'comment': 'Code verification removed.', 'commenter': 'DonnyZone'}, {'comment': ""@vlsi I totally agree on you on the fact that we should verify the generated code in some cases, especially when it has to do with optimizations. \r\n\r\nOn the other hand, I would not put assertions with the generated code in every query. I've seen that @DonnyZone removed a few code assertions(thanks) and I prefer it this way. If you think that those were important we can add them back later before the final merge.  "", 'commenter': 'zabetak'}, {'comment': ""Essential assertions in `RexCall`'s implementors are preserved. We just remove some `Assert`/`AssertionError`/`AlwaysNull` in the framework, because they are introduced by the current algorithm which makes `RexNode`'s nullable state immutable. \r\n\r\nTechnically speaking, the nullable state of `RexNode` can be immutable during codegen. In the new one, each `RexNode` is visited only once. From its type, we can know whether it is nullable directly, without maintaining any states. Therefore, many checks (e.g., `isNullable(...)`) are not necessary again.\r\n\r\nTo conclude, the following things are extra and make the progress complicated. We removed them in the new one.\r\n\r\n1. `Map<? extends RexNode, Boolean> exprNullableMap` in `RexToLixTranslator`. Each `RexNode` is visited only once, we do not need it again.\r\n2. `RexToLixTranslator parent` in `RexToLixTranslator`. We do not need to recursively get a `RexNode`'s nullable state again.\r\n3. `AlwaysNull` exception. `AlwaysNull` in current codegen is the root cause of some underyling problems. It buries real problems and brings 'magic/undeterministic' results. From my personal point of view, I'm not in favour of `AlwaysNull`. According to document, it is proposed for 'unusual' situation. Since a `RexNode` is legal, the code generation progress should not step into such situation. What's worse is, the exception is catched and returns `null` aggressively in some places.\r\n\r\n> Thrown in the unusual (but not erroneous) situation where the expression\r\n> we are translating is the null literal but we have already checked that\r\n> it is not null."", 'commenter': 'DonnyZone'}]"
1347,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -2544,35 +2556,117 @@ private void checkNullableTimestamp(CalciteAssert.Config config) {
             + ""from\n""
             + ""\""hr\"".\""emps\"""")
         .planContains(
-            ""final String inp2_ = current.name;"")
-        .planContains(
-            ""final int inp1_ = current.deptno;"")
-        .planContains(
-            ""static final int $L4J$C$5_2 = 5 - 2;"")
-        .planContains(
-            ""static final Integer $L4J$C$Integer_valueOf_5_2_ = Integer.valueOf($L4J$C$5_2);"")
-        .planContains(
-            ""static final int $L4J$C$Integer_valueOf_5_2_intValue_ = $L4J$C$Integer_valueOf_5_2_.intValue();"")
-        .planContains(""static final boolean ""
-            + ""$L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_ = ""
-            + ""org.apache.calcite.runtime.SqlFunctions.eq(\""\"", \""\"");"")
-        .planContains(""static final boolean ""
-            + ""$L4J$C$_org_apache_calcite_runtime_SqlFunctions_eq_ = ""
-            + ""!$L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_;"")
-        .planContains(""return inp2_ == null ""
-            + ""|| $L4J$C$_org_apache_calcite_runtime_SqlFunctions_eq_ ""
-            + ""|| current.empid <= inp1_ && inp1_ * 8 <= 8 ""
-            + ""? (String) null ""
-            + "": org.apache.calcite.runtime.SqlFunctions.substring(""
-            + ""org.apache.calcite.runtime.SqlFunctions.trim(true, true, \"" \"", ""
-            + ""org.apache.calcite.runtime.SqlFunctions.substring(inp2_, ""
-            + ""Integer.valueOf(inp1_ * 0 + 1).intValue()), true), $L4J$C$Integer_valueOf_5_2_intValue_);"")
+              ""              final org.apache.calcite.test.JdbcTest.Employee current = (org.apache.calcite.test.JdbcTest.Employee) inputEnumerator.current();\n""
+            + ""              final String input_value = current.name;\n""
+            + ""              final int input_value0 = current.deptno;\n""
+            + ""              Integer case_when_value;\n""
+            + ""              if ($L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_) {\n""
+            + ""                case_when_value = $L4J$C$Integer_valueOf_1_;\n""
+            + ""              } else {\n""
+            + ""                case_when_value = (Integer) null;\n""
+            + ""              }\n""
+            + ""              final Integer binary_call_value1 = case_when_value == null ? (Integer) null : Integer.valueOf(Integer.valueOf(input_value0 * 0) + case_when_value);\n""
+            + ""              final String method_call_value = input_value == null || binary_call_value1 == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.substring(input_value, binary_call_value1.intValue());\n""
+            + ""              final String trim_value = method_call_value == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.trim(true, true, \"" \"", method_call_value, true);\n""
+            + ""              Integer case_when_value0;\n""
+            + ""              if (current.empid > input_value0) {\n""
+            + ""                case_when_value0 = $L4J$C$Integer_valueOf_5_;\n""
+            + ""              } else {\n""
+            + ""                Integer case_when_value1;\n""
+            + ""                if (current.deptno * 8 > 8) {\n""
+            + ""                  case_when_value1 = $L4J$C$Integer_valueOf_5_;\n""
+            + ""                } else {\n""
+            + ""                  case_when_value1 = (Integer) null;\n""
+            + ""                }\n""
+            + ""                case_when_value0 = case_when_value1;\n""
+            + ""              }\n""
+            + ""              final Integer binary_call_value3 = case_when_value0 == null ? (Integer) null : Integer.valueOf(case_when_value0 - $L4J$C$Integer_valueOf_2_);\n""
+            + ""              return trim_value == null || binary_call_value3 == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.substring(trim_value, binary_call_value3.intValue());""
+        )
         .returns(""T=ll\n""
             + ""T=ic\n""
             + ""T=bastian\n""
             + ""T=eodore\n"");
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3142"">[CALCITE-3142]
+   * An NPE when rounding a nullable numeric</a>. */
+  @Test public void testRoundingNPE() {
+    CalciteAssert.that()
+        .query(""SELECT ROUND(CAST((X/Y) AS NUMERIC), 2) ""
+            + ""FROM (VALUES (1, 2), (NULLIF(5, 5), NULLIF(5, 5))) A(X, Y)"")
+        .planContains(""      final Object[] current = (Object[]) inputEnumerator.current();\n""
+            + ""              final Integer input_value = (Integer) current[0];\n""
+            + ""              final Integer input_value0 = (Integer) current[1];\n""
+            + ""              final Integer binary_call_value = input_value == null || input_value0 == null ? (Integer) null : Integer.valueOf(input_value / input_value0);\n""
+            + ""              final java.math.BigDecimal cast_value = binary_call_value == null ? (java.math.BigDecimal) null : binary_call_value == null ? (java.math.BigDecimal) null : new java.math.BigDecimal(\n""
+            + ""                binary_call_value.intValue());\n""
+            + ""              return cast_value == null ? (java.math.BigDecimal) null : org.apache.calcite.runtime.SqlFunctions.sround(cast_value, 2);"")
+        .returns(""EXPR$0=0.00\n""
+            + ""EXPR$0=null\n"");
+  }
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3143"">[CALCITE-3143]
+   * Dividing NULLIF clause may cause Division by zero error</a>. */
+  @Test public void testDividingZero() {
+    CalciteAssert.that()
+        .query(""SELECT CASE WHEN \""Z\"" < 77 AND \""Z\"" > 0 THEN 99 ELSE 88 END FROM\n""
+            + ""(\n""
+            + "" SELECT SUM(\""X\"") / NULLIF(SUM(0),0) AS Z\n""
+            + "" FROM (VALUES (1.1, 2.5), (4.51, 32.5)) A(X, Y)\n""
+            + "" GROUP BY \""Y\""\n""
+            + "")"")
+        .planContains(""      int case_when_value;\n""","[{'comment': 'Same comment here: is verifying the code necessary?', 'commenter': 'zabetak'}]"
1347,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -2544,35 +2556,117 @@ private void checkNullableTimestamp(CalciteAssert.Config config) {
             + ""from\n""
             + ""\""hr\"".\""emps\"""")
         .planContains(
-            ""final String inp2_ = current.name;"")
-        .planContains(
-            ""final int inp1_ = current.deptno;"")
-        .planContains(
-            ""static final int $L4J$C$5_2 = 5 - 2;"")
-        .planContains(
-            ""static final Integer $L4J$C$Integer_valueOf_5_2_ = Integer.valueOf($L4J$C$5_2);"")
-        .planContains(
-            ""static final int $L4J$C$Integer_valueOf_5_2_intValue_ = $L4J$C$Integer_valueOf_5_2_.intValue();"")
-        .planContains(""static final boolean ""
-            + ""$L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_ = ""
-            + ""org.apache.calcite.runtime.SqlFunctions.eq(\""\"", \""\"");"")
-        .planContains(""static final boolean ""
-            + ""$L4J$C$_org_apache_calcite_runtime_SqlFunctions_eq_ = ""
-            + ""!$L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_;"")
-        .planContains(""return inp2_ == null ""
-            + ""|| $L4J$C$_org_apache_calcite_runtime_SqlFunctions_eq_ ""
-            + ""|| current.empid <= inp1_ && inp1_ * 8 <= 8 ""
-            + ""? (String) null ""
-            + "": org.apache.calcite.runtime.SqlFunctions.substring(""
-            + ""org.apache.calcite.runtime.SqlFunctions.trim(true, true, \"" \"", ""
-            + ""org.apache.calcite.runtime.SqlFunctions.substring(inp2_, ""
-            + ""Integer.valueOf(inp1_ * 0 + 1).intValue()), true), $L4J$C$Integer_valueOf_5_2_intValue_);"")
+              ""              final org.apache.calcite.test.JdbcTest.Employee current = (org.apache.calcite.test.JdbcTest.Employee) inputEnumerator.current();\n""
+            + ""              final String input_value = current.name;\n""
+            + ""              final int input_value0 = current.deptno;\n""
+            + ""              Integer case_when_value;\n""
+            + ""              if ($L4J$C$org_apache_calcite_runtime_SqlFunctions_eq_) {\n""
+            + ""                case_when_value = $L4J$C$Integer_valueOf_1_;\n""
+            + ""              } else {\n""
+            + ""                case_when_value = (Integer) null;\n""
+            + ""              }\n""
+            + ""              final Integer binary_call_value1 = case_when_value == null ? (Integer) null : Integer.valueOf(Integer.valueOf(input_value0 * 0) + case_when_value);\n""
+            + ""              final String method_call_value = input_value == null || binary_call_value1 == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.substring(input_value, binary_call_value1.intValue());\n""
+            + ""              final String trim_value = method_call_value == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.trim(true, true, \"" \"", method_call_value, true);\n""
+            + ""              Integer case_when_value0;\n""
+            + ""              if (current.empid > input_value0) {\n""
+            + ""                case_when_value0 = $L4J$C$Integer_valueOf_5_;\n""
+            + ""              } else {\n""
+            + ""                Integer case_when_value1;\n""
+            + ""                if (current.deptno * 8 > 8) {\n""
+            + ""                  case_when_value1 = $L4J$C$Integer_valueOf_5_;\n""
+            + ""                } else {\n""
+            + ""                  case_when_value1 = (Integer) null;\n""
+            + ""                }\n""
+            + ""                case_when_value0 = case_when_value1;\n""
+            + ""              }\n""
+            + ""              final Integer binary_call_value3 = case_when_value0 == null ? (Integer) null : Integer.valueOf(case_when_value0 - $L4J$C$Integer_valueOf_2_);\n""
+            + ""              return trim_value == null || binary_call_value3 == null ? (String) null : org.apache.calcite.runtime.SqlFunctions.substring(trim_value, binary_call_value3.intValue());""
+        )
         .returns(""T=ll\n""
             + ""T=ic\n""
             + ""T=bastian\n""
             + ""T=eodore\n"");
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3142"">[CALCITE-3142]
+   * An NPE when rounding a nullable numeric</a>. */
+  @Test public void testRoundingNPE() {
+    CalciteAssert.that()
+        .query(""SELECT ROUND(CAST((X/Y) AS NUMERIC), 2) ""
+            + ""FROM (VALUES (1, 2), (NULLIF(5, 5), NULLIF(5, 5))) A(X, Y)"")
+        .planContains(""      final Object[] current = (Object[]) inputEnumerator.current();\n""
+            + ""              final Integer input_value = (Integer) current[0];\n""
+            + ""              final Integer input_value0 = (Integer) current[1];\n""
+            + ""              final Integer binary_call_value = input_value == null || input_value0 == null ? (Integer) null : Integer.valueOf(input_value / input_value0);\n""
+            + ""              final java.math.BigDecimal cast_value = binary_call_value == null ? (java.math.BigDecimal) null : binary_call_value == null ? (java.math.BigDecimal) null : new java.math.BigDecimal(\n""
+            + ""                binary_call_value.intValue());\n""
+            + ""              return cast_value == null ? (java.math.BigDecimal) null : org.apache.calcite.runtime.SqlFunctions.sround(cast_value, 2);"")
+        .returns(""EXPR$0=0.00\n""
+            + ""EXPR$0=null\n"");
+  }
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3143"">[CALCITE-3143]
+   * Dividing NULLIF clause may cause Division by zero error</a>. */
+  @Test public void testDividingZero() {
+    CalciteAssert.that()
+        .query(""SELECT CASE WHEN \""Z\"" < 77 AND \""Z\"" > 0 THEN 99 ELSE 88 END FROM\n""
+            + ""(\n""
+            + "" SELECT SUM(\""X\"") / NULLIF(SUM(0),0) AS Z\n""
+            + "" FROM (VALUES (1.1, 2.5), (4.51, 32.5)) A(X, Y)\n""
+            + "" GROUP BY \""Y\""\n""
+            + "")"")
+        .planContains(""      int case_when_value;\n""
+            + ""              final Object[] current = (Object[]) inputEnumerator.current();\n""
+            + ""              final java.math.BigDecimal input_value = current[1] == null ? (java.math.BigDecimal) null : org.apache.calcite.runtime.SqlFunctions.toBigDecimal(current[1]);\n""
+            + ""              Integer case_when_value0;\n""
+            + ""              if (org.apache.calcite.runtime.SqlFunctions.toInt(current[2]) == 0) {\n""
+            + ""                case_when_value0 = (Integer) null;\n""
+            + ""              } else {\n""
+            + ""                case_when_value0 = Integer.valueOf(org.apache.calcite.runtime.SqlFunctions.toInt(current[2]));\n""
+            + ""              }\n""
+            + ""              final java.math.BigDecimal binary_call_value0 = input_value == null || case_when_value0 == null ? (java.math.BigDecimal) null : org.apache.calcite.runtime.SqlFunctions.divide(input_value, case_when_value0 == null ? (java.math.BigDecimal) null : new java.math.BigDecimal(\n""
+            + ""                case_when_value0.intValue()));\n""
+            + ""              final boolean binary_call_isNull0 = binary_call_value0 == null;\n""
+            + ""              final Boolean binary_call_value1 = binary_call_isNull0 ? (Boolean) null : Boolean.valueOf(org.apache.calcite.runtime.SqlFunctions.lt(binary_call_value0, $L4J$C$new_java_math_BigDecimal_77_));\n""
+            + ""              final boolean binary_call_isNull1 = binary_call_value1 == null;\n""
+            + ""              final Boolean binary_call_value2 = binary_call_isNull0 ? (Boolean) null : Boolean.valueOf(org.apache.calcite.runtime.SqlFunctions.gt(binary_call_value0, $L4J$C$new_java_math_BigDecimal_0_));\n""
+            + ""              final boolean binary_call_isNull2 = binary_call_value2 == null;\n""
+            + ""              final Boolean logical_and_value = (binary_call_isNull1 ? true : binary_call_value1) && (binary_call_isNull2 ? true : binary_call_value2) ? (binary_call_isNull1 || binary_call_isNull2 ? (Boolean) null : Boolean.TRUE) : Boolean.FALSE;\n""
+            + ""              if (logical_and_value != null && logical_and_value) {\n""
+            + ""                case_when_value = 99;\n""
+            + ""              } else {\n""
+            + ""                case_when_value = 88;\n""
+            + ""              }\n""
+            + ""              return case_when_value;"")
+        .returns(""EXPR$0=88\n""
+            + ""EXPR$0=88\n"");
+  }
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3150"">[CALCITE-3150]
+   * NPE in UPPER when repeated and combine with LIKE</a>. */
+  @Test public void testUpperLikeNPE() {
+    CalciteAssert.that()
+        .query(""SELECT \""NAME\"" ""
+            + ""FROM (VALUES ('Bill'), NULLIF('x', 'x'), ('Eric')) A(NAME) ""
+            + ""WHERE UPPER(\""NAME\"") LIKE 'B%' AND UPPER(\""NAME\"") LIKE '%L'"")
+        .planContains(","[{'comment': 'Same here?', 'commenter': 'zabetak'}]"
1347,core/src/test/java/org/apache/calcite/test/ReflectiveSchemaTest.java,"@@ -585,10 +585,9 @@ private void check(ResultSetMetaData metaData, String columnName,
     with.query(""select \""wrapperLong\"" / \""primitiveLong\"" as c\n""
         + "" from \""s\"".\""everyTypes\"" where \""primitiveLong\"" <> 0"")
         .planContains(
-            ""final Long inp13_ = current.wrapperLong;"")
+            ""final Long input_value = current.wrapperLong;"")
         .planContains(
-            ""return inp13_ == null ? (Long) null ""
-                + "": Long.valueOf(inp13_.longValue() / current.primitiveLong);"")
+            ""return input_value == null ? (Long) null : Long.valueOf(input_value / Long.valueOf(current.primitiveLong));"")","[{'comment': ""Isn't this unnecessary boxing/unboxing?"", 'commenter': 'zabetak'}, {'comment': 'The difference is \r\n```\r\nold: inp13_.longValue() / current.primitiveLong)\r\nnew: input_value / Long.valueOf(current.primitiveLong)\r\n```\r\nWe can conduct unboxing optimization before operands entering into `BinaryImplementor`.\r\nThanks, let me change it.', 'commenter': 'DonnyZone'}, {'comment': 'Hi @zabetak, comment addressed, unboxing optimization if necessary is conducted. Keep the same as that generated by current code generator. ', 'commenter': 'DonnyZone'}]"
1372,core/src/main/java/org/apache/calcite/rel/externalize/RelJson.java,"@@ -438,15 +438,17 @@ RexNode toRex(RelInput relInput, Object o) {
     } else if (o instanceof Map) {
       Map map = (Map) o;
       final Map<String, Object> opMap = (Map) map.get(""op"");
+      if (map.containsKey(""class"")) {
+        opMap.put(""class"", map.get(""class""));
+      }
       final RelDataTypeFactory typeFactory = cluster.getTypeFactory();","[{'comment': 'What if `opMap` is null?', 'commenter': 'chunweilei'}, {'comment': '@chunweilei I think even `opMap` is null, it does not matter. And for RexCall, it could not be null.', 'commenter': 'wangzzu'}, {'comment': '@chunweilei  thanks for point out. better to  move it down inside `if(opMap != null)` block.', 'commenter': 'yanlin-Lynn'}, {'comment': '@wangzzu It matters since it might throw NPE. It should put inside` if(opMap != null)` block.', 'commenter': 'chunweilei'}]"
1374,core/src/main/java/org/apache/calcite/sql/fun/SqlItemOperator.java,"@@ -125,6 +128,14 @@ private SqlSingleOperandTypeChecker getChecker(SqlCallBinding callBinding) {
     case MAP:
       return typeFactory.createTypeWithNullability(operandType.getValueType(),
           true);
+    case ROW:
+      int lastOperandIdx = opBinding.getOperandCount() - 1;
+      String fieldName = opBinding.getOperandLiteralValue(lastOperandIdx, String.class);
+      return operandType.getFieldList().stream()
+          .filter(field -> field.getName().equalsIgnoreCase(fieldName))
+          .findFirst().map(RelDataTypeField::getType)","[{'comment': '```suggestion\r\n          .findFirst()\r\n          .map(RelDataTypeField::getType)\r\n```', 'commenter': 'vvysotskyi'}, {'comment': 'You can get the `NameMatcher` from `CatalogReader` of `SqlValidator` to decide the case sensitivity.', 'commenter': 'danny0405'}, {'comment': ""I've used ```getField(...)``` method with case sensitivity ```false``` like in DOT operator. "", 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql/fun/SqlItemOperator.java,"@@ -125,6 +128,14 @@ private SqlSingleOperandTypeChecker getChecker(SqlCallBinding callBinding) {
     case MAP:
       return typeFactory.createTypeWithNullability(operandType.getValueType(),
           true);
+    case ROW:
+      int lastOperandIdx = opBinding.getOperandCount() - 1;","[{'comment': 'Please use literal 1 instead of obtaining its position, since `getOperandCountRange()` method allows 2 operands.', 'commenter': 'vvysotskyi'}, {'comment': 'How about the opBinding has 0 operands ?', 'commenter': 'danny0405'}, {'comment': 'As I pointed in the comment above, for this function allowed only 2 operands: `SqlOperandCountRanges.of(2)`', 'commenter': 'vvysotskyi'}, {'comment': 'Thanks for clarification. Fixed. ', 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql/fun/SqlItemOperator.java,"@@ -100,6 +101,8 @@ private SqlSingleOperandTypeChecker getChecker(SqlCallBinding callBinding) {
     case MAP:
       return OperandTypes.family(
           operandType.getKeyType().getSqlTypeName().getFamily());
+    case ROW:
+      return OperandTypes.STRING;","[{'comment': 'OperandTypeChecker for `STRING` allows also `BINARY` and `VARBINARY` types, are such types allowed there, or `CHARACTER` type checker should be used?', 'commenter': 'vvysotskyi'}, {'comment': 'Use `CHARACTER`.', 'commenter': 'danny0405'}, {'comment': 'Done. ', 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql/fun/SqlItemOperator.java,"@@ -125,6 +128,14 @@ private SqlSingleOperandTypeChecker getChecker(SqlCallBinding callBinding) {
     case MAP:
       return typeFactory.createTypeWithNullability(operandType.getValueType(),
           true);
+    case ROW:
+      int lastOperandIdx = opBinding.getOperandCount() - 1;
+      String fieldName = opBinding.getOperandLiteralValue(lastOperandIdx, String.class);
+      return operandType.getFieldList().stream()","[{'comment': 'Is it possible to use `operandType.getField()` method instead of iterating over all the fields explicitly?', 'commenter': 'vvysotskyi'}, {'comment': 'done, thanks.', 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -296,42 +273,42 @@ protected int getNewForOldInput(int oldOrdinal) {
   }
 
   /**
-   * Maps the ordinal of a field pre-flattening to the ordinal of the
-   * corresponding field post-flattening, and also returns its type.
+   * Finds type and new ordinal relative to new inputs by oldOrdinal and
+   * innerOrdinal indexes.
    *
-   * @param oldOrdinal Pre-flattening ordinal
-   * @param existingOffset offset already calculated the target column inside the oldOrdinal column.
-   *                       For unnested column, it should be 0.
-   * @return Post-flattening ordinal and type
+   * @param oldOrdinal   ordinal of the field relative to old inputs
+   * @param innerOrdinal when oldOrdinal points to struct and target field
+   *                     is inner field of struct, this argument should contain
+   *                     calculated field's ordinal within struct after flattening.
+   *                     Otherwise when oldOrdinal points to primitive field, this
+   *                     argument should be zero.
+   * @return flat type with new ordinal relative to new inputs
    */
-  private Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal, int existingOffset) {
+  private Ord<RelDataType> getNewFieldForOldInput(int oldOrdinal, int innerOrdinal) {
     assert currentRel != null;
-    int newOrdinal = 0;
-
-    // determine which input rel oldOrdinal references, and adjust
-    // oldOrdinal to be relative to that input rel
-    RelNode oldInput = null;
-    RelNode newInput = null;
-    for (RelNode oldInput1 : currentRel.getInputs()) {
-      newInput = getNewForOldRel(oldInput1);
-      RelDataType oldInputType = oldInput1.getRowType();
-      int n = oldInputType.getFieldCount();
-      if (oldOrdinal < n) {
-        oldInput = oldInput1;
-        break;
-      }
-      newOrdinal += newInput.getRowType().getFieldCount();
-      oldOrdinal -= n;
-    }
-    assert oldInput != null;
-    assert newInput != null;
-
-    RelDataType oldInputType = oldInput.getRowType();
-    final int newOffset = calculateFlattenedOffset(oldInputType, oldOrdinal) + existingOffset;
-    newOrdinal += newOffset;
-    final RelDataTypeField field =
-        newInput.getRowType().getFieldList().get(newOffset);
-    return Ord.of(newOrdinal, field.getType());
+    // sum of predecessors post flatten sizes points to new ordinal
+    // of flat field or first field of flattened struct
+    final int postFlatteningOrdinal = currentRel.getInputs().stream()
+        .flatMap(node -> node.getRowType().getFieldList().stream())","[{'comment': ""I'm not sure that it will work for all types of rel nodes. If I understand correctly, there was used assumption, that row type of current rel node consists of fields from the inputs, but for some kinds of operators, like semi-join, fields of one of the input aren't included into the resulting row type."", 'commenter': 'vvysotskyi'}, {'comment': ""The code is only called when it's exactly was input reference to field returned by previous node. I don't think that problems may be introduced here, because it's basically a little bit more readable version of the previous method. "", 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -581,68 +555,52 @@ public void rewriteGeneric(RelNode rel) {
   }
 
   private void flattenProjections(RewriteRexShuttle shuttle,
-      List<? extends RexNode> exps,
-      List<String> fieldNames,
-      String prefix,
-      List<Pair<RexNode, String>> flattenedExps) {
+                                  List<? extends RexNode> exps,","[{'comment': 'Please revert this change, Calcite uses such formatting.', 'commenter': 'vvysotskyi'}, {'comment': 'Fixed.', 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -581,68 +555,52 @@ public void rewriteGeneric(RelNode rel) {
   }
 
   private void flattenProjections(RewriteRexShuttle shuttle,
-      List<? extends RexNode> exps,
-      List<String> fieldNames,
-      String prefix,
-      List<Pair<RexNode, String>> flattenedExps) {
+                                  List<? extends RexNode> exps,
+                                  List<String> fieldNames,
+                                  String prefix,
+                                  List<Pair<RexNode, String>> flattenedExps) {
     for (int i = 0; i < exps.size(); ++i) {
       RexNode exp = exps.get(i);
-      String fieldName =
-          (fieldNames == null || fieldNames.get(i) == null)
-              ? (""$"" + i)
-              : fieldNames.get(i);
-      if (!prefix.equals("""")) {
-        fieldName = prefix + ""$"" + fieldName;
-      }
+      String fieldName = extractName(fieldNames, prefix, i);
       flattenProjection(shuttle, exp, fieldName, flattenedExps);
     }
   }
 
+  private String extractName(List<String> fieldNames, String prefix, int i) {
+    String fieldName = (fieldNames == null || fieldNames.get(i) == null)
+        ? (""$"" + i)
+        : fieldNames.get(i);
+    if (!prefix.equals("""")) {
+      fieldName = prefix + ""$"" + fieldName;
+    }
+    return fieldName;
+  }
+
   private void flattenProjection(RewriteRexShuttle shuttle,
-      RexNode exp,
-      String fieldName,
-      List<Pair<RexNode, String>> flattenedExps) {
+                                 RexNode exp,","[{'comment': 'And this one.', 'commenter': 'vvysotskyi'}, {'comment': 'Fixed.', 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -651,22 +609,57 @@ private void flattenProjection(RewriteRexShuttle shuttle,
         // NOTE jvs 10-Feb-2005:  This is a lame hack to keep special
         // functions which return row types working.
 
-        int j = 0;
         RexNode newExp = exp;
-        List<RexNode> oldOperands = ((RexCall) exp).getOperands();
-        if (oldOperands.get(0) instanceof RexInputRef) {
-          final RexInputRef inputRef = (RexInputRef) oldOperands.get(0);
-          final Ord<RelDataType> newField =
-              getNewFieldForOldInput(inputRef.getIndex());
-          newExp = rexBuilder.makeCall(exp.getType(),
-              ((RexCall) exp).getOperator(),
-              ImmutableList.of(rexBuilder.makeInputRef(newField.e, newField.i),
-                  oldOperands.get(1)));
-        }
-        for (RelDataTypeField field : newExp.getType().getFieldList()) {
-          flattenedExps.add(
-              Pair.of(rexBuilder.makeFieldAccess(newExp, field.getIndex()),
-                  fieldName + ""$"" + (j++)));
+        List<RexNode> operands = ((RexCall) exp).getOperands();
+
+        RexNode firstOp = operands.get(0);
+        RexNode secondOp = operands.get(1);","[{'comment': 'It may be not safe to obtain the first operand here for the case when we have non-ITEM operator which has single operand.', 'commenter': 'vvysotskyi'}, {'comment': 'Fixed.', 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -587,86 +561,103 @@ private void flattenProjections(RewriteRexShuttle shuttle,
       List<Pair<RexNode, String>> flattenedExps) {
     for (int i = 0; i < exps.size(); ++i) {
       RexNode exp = exps.get(i);
-      String fieldName =
-          (fieldNames == null || fieldNames.get(i) == null)
-              ? (""$"" + i)
-              : fieldNames.get(i);
-      if (!prefix.equals("""")) {
-        fieldName = prefix + ""$"" + fieldName;
-      }
+      String fieldName = extractName(fieldNames, prefix, i);
       flattenProjection(shuttle, exp, fieldName, flattenedExps);
     }
   }
 
+  private String extractName(List<String> fieldNames, String prefix, int i) {
+    String fieldName = (fieldNames == null || fieldNames.get(i) == null)
+        ? (""$"" + i)
+        : fieldNames.get(i);
+    if (!prefix.equals("""")) {
+      fieldName = prefix + ""$"" + fieldName;
+    }
+    return fieldName;
+  }
+
   private void flattenProjection(RewriteRexShuttle shuttle,
       RexNode exp,
       String fieldName,
       List<Pair<RexNode, String>> flattenedExps) {
     if (exp.getType().isStruct()) {
       if (exp instanceof RexInputRef) {
-        RexInputRef inputRef = (RexInputRef) exp;
-
-        // expand to range
-        RelDataType flattenedType =
-            SqlTypeUtil.flattenRecordType(
-                rexBuilder.getTypeFactory(),
-                exp.getType(),
-                null);
-        List<RelDataTypeField> fieldList = flattenedType.getFieldList();
-        int n = fieldList.size();
-        for (int j = 0; j < n; ++j) {
-          final Ord<RelDataType> newField =
-              getNewFieldForOldInput(inputRef.getIndex(), j);
-          flattenedExps.add(
-              Pair.of(new RexInputRef(newField.i, newField.e),
-                  fieldName));
+        final int oldOrdinal = ((RexInputRef) exp).getIndex();
+        final int flattenFieldsCount = postFlattenSize(exp.getType());
+        for (int innerOrdinal = 0; innerOrdinal < flattenFieldsCount; innerOrdinal++) {
+          Ord<RelDataType> newField = getNewFieldForOldInput(oldOrdinal, innerOrdinal);
+          RexInputRef newRef = new RexInputRef(newField.i, newField.e);
+          flattenedExps.add(Pair.of(newRef, fieldName));
         }
       } else if (isConstructor(exp) || exp.isA(SqlKind.CAST)) {
         // REVIEW jvs 27-Feb-2005:  for cast, see corresponding note
         // in RewriteRexShuttle
         RexCall call = (RexCall) exp;
-        if (exp.isA(SqlKind.NEW_SPECIFICATION)) {
-          // For object constructors, prepend a FALSE null
-          // indicator.
-          flattenedExps.add(
-              Pair.of(rexBuilder.makeLiteral(false),
-                  fieldName));
-        } else if (exp.isA(SqlKind.CAST)) {
-          if (RexLiteral.isNullLiteral(
-              ((RexCall) exp).operands.get(0))) {
-            // Translate CAST(NULL AS UDT) into
-            // the correct number of null fields.
-            flattenNullLiteral(
-                exp.getType(),
-                flattenedExps);
-            return;
-          }
+        if (exp.isA(SqlKind.CAST)
+            && RexLiteral.isNullLiteral(call.operands.get(0))) {
+          // Translate CAST(NULL AS UDT) into
+          // the correct number of null fields.
+          flattenNullLiteral(exp.getType(), flattenedExps);
+          return;
         }
-        flattenProjections(new RewriteRexShuttle(),
+        flattenProjections(shuttle,
             call.getOperands(),
             Collections.nCopies(call.getOperands().size(), null),
             fieldName,
             flattenedExps);
       } else if (exp instanceof RexCall) {
         // NOTE jvs 10-Feb-2005:  This is a lame hack to keep special
         // functions which return row types working.
-
-        int j = 0;
         RexNode newExp = exp;
-        List<RexNode> oldOperands = ((RexCall) exp).getOperands();
-        if (oldOperands.get(0) instanceof RexInputRef) {
-          final RexInputRef inputRef = (RexInputRef) oldOperands.get(0);
-          final Ord<RelDataType> newField =
-              getNewFieldForOldInput(inputRef.getIndex());
-          newExp = rexBuilder.makeCall(exp.getType(),
-              ((RexCall) exp).getOperator(),
-              ImmutableList.of(rexBuilder.makeInputRef(newField.e, newField.i),
-                  oldOperands.get(1)));
-        }
-        for (RelDataTypeField field : newExp.getType().getFieldList()) {
-          flattenedExps.add(
-              Pair.of(rexBuilder.makeFieldAccess(newExp, field.getIndex()),
-                  fieldName + ""$"" + (j++)));
+        List<RexNode> operands = ((RexCall) exp).getOperands();
+        SqlOperator operator = ((RexCall) exp).getOperator();
+
+        if (operator == SqlStdOperatorTable.ITEM
+            && operands.get(0).getType().isStruct()
+            && operands.get(1).isA(SqlKind.LITERAL)
+            && SqlTypeUtil.inCharFamily(operands.get(1).getType())) {
+          String literalString = ((RexLiteral) operands.get(1)).getValueAs(String.class);
+          RexNode firstOp = operands.get(0);
+
+          if (firstOp instanceof RexInputRef) {
+            // when performed getting field from struct exp by field name
+            // and new input is flattened it's enough to refer target field by index.
+            // But it's possible that requested field is also of type struct, that's
+            // why we're trying to get range from to. For primitive just one field will be in range.
+            int from = 0;
+            for (RelDataTypeField field : firstOp.getType().getFieldList()) {
+              if (literalString.equalsIgnoreCase(field.getName())) {
+                int oldOrdinal = ((RexInputRef) firstOp).getIndex();
+                int to = from + postFlattenSize(field.getType());
+                for (int newInnerOrdinal = from; newInnerOrdinal < to; newInnerOrdinal++) {
+                  Ord<RelDataType> newField = getNewFieldForOldInput(oldOrdinal, newInnerOrdinal);
+                  RexInputRef newRef = rexBuilder.makeInputRef(newField.e, newField.i);
+                  flattenedExps.add(Pair.of(newRef, fieldName));
+                }
+                break;
+              } else {
+                from += postFlattenSize(field.getType());
+              }
+            }
+          } else if (firstOp instanceof RexCall) {
+            // to get nested struct from return type of firstOp rex call,
+            // we need to flatten firstOp and get range of expressions which
+            // corresponding to desirable nested struct flattened fields
+            List<Pair<RexNode, String>> firstOpFlattenedExps = new ArrayList<>();
+            flattenProjection(shuttle, firstOp, fieldName, firstOpFlattenedExps);
+            int newInnerOrdinal = getNewInnerOrdinal(firstOp, literalString);","[{'comment': 'It does not seem right we still passed in the `fieldName ` which is the name of the `exp` but not the `firstOp` which does not have a explicit name.', 'commenter': 'danny0405'}, {'comment': ""I think passing old name here is better for preserving some history, although if you have reasonable alternative, I won't mind changing the code. "", 'commenter': 'ihuzenko'}, {'comment': 'We should not go into the recursive loop again with a wrong name `fieldName`, this name is used as a look up key( case insensitive) for `ITEM` operator.', 'commenter': 'danny0405'}, {'comment': ""Here the ```fieldName``` has meaning of result name of projection expression, when it's necessary to lookup field within struct (ITEM operator), then used ```literalString``` (value of ITEM's second operand). "", 'commenter': 'ihuzenko'}]"
1374,core/src/main/java/org/apache/calcite/sql2rel/RelStructuredTypeFlattener.java,"@@ -934,7 +968,21 @@ private RexNode flattenComparison(
         return conjunction;
       }
     }
+
+  }
+
+  private int getNewInnerOrdinal(RexNode firstOp, String literalString) {
+    int newInnerOrdinal = 0;
+    for (RelDataTypeField field : firstOp.getType().getFieldList()) {
+      if (literalString.equalsIgnoreCase(field.getName())) {
+        break;","[{'comment': ""I don't think this is right to match the fist flattened field just by name, how do you know what the (struct type field original) operator is ? It seems only right if they are all `ITEM` operators. "", 'commenter': 'danny0405'}, {'comment': 'Yes, the method only used for item with string second operand. ', 'commenter': 'ihuzenko'}, {'comment': ' That means this code snippet only works for full `ITEM` operator, but there is no any code can guarantee this, the most weird part is that you match the `first` field with name, that confused me a lot, why not the second ? the third ?', 'commenter': 'danny0405'}, {'comment': ""1) Every call to the method is performed only after the check. \r\n```\r\n      if (rexCall.op == SqlStdOperatorTable.ITEM\r\n          && rexCall.operands.get(0).getType().isStruct()\r\n          && rexCall.operands.get(1).isA(SqlKind.LITERAL)\r\n          && SqlTypeUtil.inCharFamily(rexCall.operands.get(1).getType())) {\r\n```\r\nSo I think it's enough to guarantee that we're looking for inner field within struct returned by first operand of ITEM.   \r\n\r\n2) What's actually wrong with matching of first field if iteration is performed for non flattened struct fields ? There is no threat that some nested field with same name will come up and match before the desired one. Maybe I misunderstand you and you're just worried about case insensitive match, then in my opinion it's unlikely that users will create structs, like ```STRUCT <aaa:INT, AAA:STRING>``` . \r\n"", 'commenter': 'ihuzenko'}, {'comment': ""1. You indeed do the check:\r\n```java\r\n      if (rexCall.op == SqlStdOperatorTable.ITEM\r\n          && rexCall.operands.get(0).getType().isStruct()\r\n          && rexCall.operands.get(1).isA(SqlKind.LITERAL)\r\n          && SqlTypeUtil.inCharFamily(rexCall.operands.get(1).getType())) {\r\n```\r\nbefore calling this method, but within the method, you still have a recursive logic to flatten all the struct fields, which i think has already exceed the limitation of the check.\r\n\r\n2. Assume we have an expression a(b(c, 'k1'), 'k2')['k1'] (a, b, c all return struct types), is it really right we return the field of field c['k1'] ? And how do you know that a, b, and c are all `ITEM` operators ?"", 'commenter': 'danny0405'}, {'comment': ""1. There is no further recursive calls within the ```getNewInnerOrdinal(RexNode firstOp, String literalString)``` method. Only recursion is applied to predict post flatten size of field which resides before desired one, and this ```postFlattenSize(field.getType())``` prediction doesn't require any matching. "", 'commenter': 'ihuzenko'}]"
1411,linq4j/src/main/java/org/apache/calcite/linq4j/tree/AbstractNode.java,"@@ -71,8 +71,12 @@ public Node accept(Shuttle shuttle) {
   }
 
   public Object evaluate(Evaluator evaluator) {
-    throw new RuntimeException(
-        ""evaluation not supported: "" + getClass() + "":"" + nodeType);
+    return evaluator.evaluate(this);
+  }
+
+  public Object evaluate() {","[{'comment': 'Could you please change the title and the commit message to make it clearer? Such as `Implement evaluate method of AbstractNode`?', 'commenter': 'chunweilei'}, {'comment': 'changed the title and the commit message.', 'commenter': 'xy2953396112'}]"
1411,linq4j/src/main/java/org/apache/calcite/linq4j/tree/Evaluator.java,"@@ -22,11 +22,11 @@
 /**
  * Holds context for evaluating expressions.
  */
-class Evaluator {
+public class Evaluator {
   final List<ParameterExpression> parameters = new ArrayList<>();
   final List<Object> values = new ArrayList<>();
 
-  Evaluator() {
+  public Evaluator() {
   }","[{'comment': 'FYI: Seems to be the same as this PR:  https://github.com/apache/calcite/pull/1387\r\n\r\nSee the discusstion in this jira: https://issues.apache.org/jira/projects/CALCITE/issues/CALCITE-3260', 'commenter': 'yanlin-Lynn'}]"
1414,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -79,6 +80,12 @@
     assertEquals(""nullb"", concat(null, ""b""));
   }
 
+  @Test public void testStrcmp() {
+    assert -1 == strcmp(""text"", ""text2"");
+    assert 1 == strcmp(""text2"", ""text"");
+    assert 0 == strcmp(""text"", ""text"");
+  }
+","[{'comment': 'Please correct the commit message. You should add issue id to it.', 'commenter': 'chunweilei'}]"
1414,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -396,6 +396,11 @@ public static ByteString concat(ByteString s0, ByteString s1) {
     return s0.concat(s1);
   }
 
+  /** SQL {@code string compare string} operator. */
+  public static Integer strcmp(String s0, String s1) {
+    return s0.compareTo(s1);
+  }","[{'comment': 'I thin It is better to return `int` instead of `Integer`.', 'commenter': 'chunweilei'}, {'comment': 'The doc is confusing, what is `{@code string compare string} operator` ?', 'commenter': 'danny0405'}, {'comment': '\r\nhad changed it.', 'commenter': 'xy2953396112'}]"
1414,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -253,6 +253,19 @@ private SqlLibraryOperators() {
               OperandTypes.STRING),
           SqlFunctionCategory.STRING);
 
+  /** The ""STRCMP(str, str)"" function that compare strings.
+   * For example, ""STRCMP('a', 'b')"" returns -1. */
+  @LibraryOperator(libraries = {MYSQL, POSTGRESQL, ORACLE})
+  public static final SqlFunction STRCMP =
+      new SqlFunction(""STRCMP"",
+          SqlKind.OTHER_FUNCTION,
+          ReturnTypes.cascade(ReturnTypes.explicit(SqlTypeName.INTEGER),
+              SqlTypeTransforms.TO_NULLABLE),
+          null,
+          OperandTypes.repeat(SqlOperandCountRanges.of(2),
+              OperandTypes.STRING_STRING),
+          SqlFunctionCategory.STRING);","[{'comment': 'Only `OperandTypes.STRING_STRING` is okey if you have exactly 2 `CHARACTER` arguments.', 'commenter': 'danny0405'}, {'comment': 'yes,It can', 'commenter': 'xy2953396112'}]"
1414,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -79,6 +80,12 @@
     assertEquals(""nullb"", concat(null, ""b""));
   }
 
+  @Test public void testStrcmp() {
+    assert -1 == strcmp(""text"", ""text2"");
+    assert 1 == strcmp(""text2"", ""text"");
+    assert 0 == strcmp(""text"", ""text"");","[{'comment': 'Can we also add some negative tests ? The invalid arguments and `binary/varbinary` type arguments.', 'commenter': 'danny0405'}, {'comment': 'the strcmp funciton has two arguments with string type.', 'commenter': 'xy2953396112'}]"
1437,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -984,6 +987,20 @@ public boolean supportsAliasedValues() {
     return true;
   }
 
+  /**
+   * Returns whether the dialect needs cast in string operands of comparison operator. for instance,","[{'comment': ""'for instance' --> 'For instance' , and 'but'  --> 'But' ?"", 'commenter': 'yanlin-Lynn'}, {'comment': 'I have fixed this.', 'commenter': 'soma-mondal'}]"
1437,core/src/main/java/org/apache/calcite/rel/rel2sql/SqlImplementor.java,"@@ -305,21 +305,19 @@ private static RexNode stripCastFromString(RexNode node) {
       final RexNode o1 = call.operands.get(1);
       if (o0.getKind() == SqlKind.CAST
           && o1.getKind() != SqlKind.CAST) {
-        final RexNode o0b = ((RexCall) o0).getOperands().get(0);
-        switch (o0b.getType().getSqlTypeName()) {
-        case CHAR:
-        case VARCHAR:
-          return call.clone(call.getType(), ImmutableList.of(o0b, o1));
+        if (dialect.castRequiredForStringOperand((RexCall) o0)) {
+          return node;","[{'comment': ""I'm considering if we should introduce a method like `SqlDialect#supportImplicitCast`, the `castRequiredForStringOperand` seems a little too related to the sql contexts. There are kinds of sql contexts for implicit type coercion, also not only for STRING type."", 'commenter': 'danny0405'}, {'comment': 'working on SqlDialect#supportImplicitCast method', 'commenter': 'soma-mondal'}]"
1437,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3854,6 +3854,24 @@ private void checkLiteral2(String expression, String expected) {
     sql(expected).exec();
   }
 
+  @Test public void testCastInStringOperandOfComparison() {
+    final String query = ""select \""employee_id\"" ""
+        + ""from \""foodmart\"".\""employee\"" ""
+        + ""where 10 = cast('10' as int) and \""birth_date\"" = cast('1914-02-02' as date) or ""
+        + ""\""hire_date\"" = cast('1996-01-01 '||'00:00:00' as timestamp)"";
+    final String expected = ""SELECT \""employee_id\""\n""
+        + ""FROM \""foodmart\"".\""employee\""\n""
+        + ""WHERE 10 = '10' AND \""birth_date\"" = '1914-02-02' OR \""hire_date\"" = '1996-01-01 ' || ""
+        + ""'00:00:00'"";
+    final String expectedBiqquery = ""SELECT employee_id\n""
+        + ""FROM foodmart.employee\n""
+        + ""WHERE 10 = CAST('10' AS INTEGER) AND birth_date = '1914-02-02' OR hire_date = ""","[{'comment': ""I am really new to calcite's RelToSql. Just curious, for `CAST('10' AS INTEGER)`, it is correct on the `INTEGER`? As far as I know BigQuery only supports `INT64` for integer type (see [1])\r\n\r\n[1] : https://cloud.google.com/bigquery/docs/reference/standard-sql/data-types#integer-type  "", 'commenter': 'amaliujia'}, {'comment': 'Ok. I think this comment is related to CALCITE-3381. The test case here is expected but it should be fixed by other JIRA.', 'commenter': 'amaliujia'}, {'comment': '#1482 is ongoing. ', 'commenter': 'amaliujia'}, {'comment': ""Hi, @amaliujia I agree this issue is related to CALCITE-3381 which is merged. But it's still expecting INTEGER. I went through the code changes for CALCITE-3381, but case INTEGER is not handled there. Do want me to add the changes in this PR? please let me know, thanks."", 'commenter': 'soma-mondal'}, {'comment': ""@soma-mondal. Because BigQuery does not have `INTEGER` or INT32. It only supports INT64. \r\n\r\nThe code leaves `INTEGER` unhandled because I wasn't sure if `INTEGER` should be cast to `INT64` or an exception should be thrown. "", 'commenter': 'amaliujia'}, {'comment': '@amaliujia  If BigQuery only has INT64 type, we should fix this, could you fire another issue and apply a patch ? You may need to override the `SqlDialect#getCastSpec` method.', 'commenter': 'danny0405'}, {'comment': ""I see. I will send an email to discuss how to handle unsupported type for BigQuery and then send a patch.\r\n\r\nBasically I will ask if people like to throw an exception directly or does a cast if that's compatible. \r\n\r\nTo me it makes sense to have a cast unless it is not possible. "", 'commenter': 'amaliujia'}]"
1437,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3854,6 +3854,24 @@ private void checkLiteral2(String expression, String expected) {
     sql(expected).exec();
   }
 
+  @Test public void testCastInStringOperandOfComparison() {
+    final String query = ""select \""employee_id\"" ""
+        + ""from \""foodmart\"".\""employee\"" ""
+        + ""where 10 = cast('10' as int) and \""birth_date\"" = cast('1914-02-02' as date) or ""
+        + ""\""hire_date\"" = cast('1996-01-01 '||'00:00:00' as timestamp)"";
+    final String expected = ""SELECT \""employee_id\""\n""
+        + ""FROM \""foodmart\"".\""employee\""\n""
+        + ""WHERE 10 = '10' AND \""birth_date\"" = '1914-02-02' OR \""hire_date\"" = '1996-01-01 ' || ""
+        + ""'00:00:00'"";
+    final String expectedBiqquery = ""SELECT employee_id\n""
+        + ""FROM foodmart.employee\n""
+        + ""WHERE 10 = CAST('10' AS INTEGER) AND birth_date = '1914-02-02' OR hire_date = ""
+        + ""CAST('1996-01-01 ' || '00:00:00' AS TIMESTAMP(0))"";","[{'comment': ""Honestly, I haven't seen `TIMESTAMP(0)` in BigQuery"", 'commenter': 'amaliujia'}, {'comment': 'Should be fixed by CALCITE-3381 or a equivalent one ', 'commenter': 'amaliujia'}, {'comment': 'Hi, I can see that CALCITE-3381 PR is merged. Resolving this conversion. Thanks for reviewing. ', 'commenter': 'soma-mondal'}]"
1437,core/src/main/java/org/apache/calcite/rel/rel2sql/SqlImplementor.java,"@@ -193,7 +193,7 @@ public Result setOpToSql(SqlSetOperator operator, RelNode rel) {
    * @param leftFieldCount  Number of fields on left result
    * @return SqlNode that represents the condition
    */
-  public static SqlNode convertConditionToSqlNode(RexNode node,
+  public SqlNode convertConditionToSqlNode(RexNode node,","[{'comment': 'why remove `static`?', 'commenter': 'yanlin-Lynn'}, {'comment': 'Sorry for the late reply. I have added dialect parameter in stripCastFromString method. As this method was static I could not use instance variable dialect to call stripCastFromString.', 'commenter': 'soma-mondal'}, {'comment': 'I would prefer to still make it static because it is a tool method, you can add a SqlDialect as additional argument.', 'commenter': 'danny0405'}, {'comment': 'I have modified my code and added SqlDialect as additional argument as you suggested. Thank you. ', 'commenter': 'soma-mondal'}]"
1437,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -984,6 +987,20 @@ public boolean supportsAliasedValues() {
     return true;
   }
 
+  /**
+   * Returns whether the dialect needs cast in string operands of comparison operator. For instance,
+   * where employee_id = '10' is comparable in most of the dialect, so doesn't need cast for string
+   * operand '10'. But in BiqQuery the above statement is not valid without cast.
+   * @param node Operand of comparison operator which contain cast.","[{'comment': 'contains ?', 'commenter': 'yanlin-Lynn'}, {'comment': 'Please limit the column width to 80 chars', 'commenter': 'hsyuan'}, {'comment': 'Thanks for pointing out, will update the description. ', 'commenter': 'soma-mondal'}, {'comment': 'Will update the description. ', 'commenter': 'soma-mondal'}]"
1437,core/src/main/java/org/apache/calcite/sql/dialect/BigQuerySqlDialect.java,"@@ -89,6 +94,22 @@ public BigQuerySqlDialect(SqlDialect.Context context) {
     return emulateNullDirectionWithIsNull(node, nullsFirst, desc);
   }
 
+  @Override public boolean castRequiredForStringOperand(RexCall node) {
+    if (super.castRequiredForStringOperand(node)) {
+      return true;
+    }
+    RexNode operand = node.getOperands().get(0);
+    RelDataType castType = node.type;
+    if (operand instanceof RexLiteral) {
+      if (SqlTypeFamily.NUMERIC.contains(castType)) {
+        return true;
+      }
+      return false;
+    } else {
+      return true;
+    }","[{'comment': '\r\nHow about this?\r\n```\r\nreturn !(operand instanceof RexLiteral)\r\n    || SqlTypeFamily.NUMERIC.contains(node.type);\r\n```', 'commenter': 'hsyuan'}, {'comment': 'Looks good. Will do the change. Thank you for pointing it out. ', 'commenter': 'soma-mondal'}]"
1437,core/src/main/java/org/apache/calcite/rel/rel2sql/SqlImplementor.java,"@@ -305,21 +305,19 @@ private static RexNode stripCastFromString(RexNode node) {
       final RexNode o1 = call.operands.get(1);
       if (o0.getKind() == SqlKind.CAST
           && o1.getKind() != SqlKind.CAST) {
-        final RexNode o0b = ((RexCall) o0).getOperands().get(0);
-        switch (o0b.getType().getSqlTypeName()) {
-        case CHAR:
-        case VARCHAR:
-          return call.clone(call.getType(), ImmutableList.of(o0b, o1));
+        if (dialect.castRequiredForStringOperand((RexCall) o0)) {
+          return node;
         }
+        final RexNode o0b = ((RexCall) o0).getOperands().get(0);
+        return call.clone(call.getType(), ImmutableList.of(o0b, o1));
       }
       if (o1.getKind() == SqlKind.CAST
           && o0.getKind() != SqlKind.CAST) {
-        final RexNode o1b = ((RexCall) o1).getOperands().get(0);
-        switch (o1b.getType().getSqlTypeName()) {
-        case CHAR:
-        case VARCHAR:
-          return call.clone(call.getType(), ImmutableList.of(o0, o1b));
+        if (dialect.castRequiredForStringOperand((RexCall) o1)) {
+          return node;
         }
+        final RexNode o1b = ((RexCall) o1).getOperands().get(0);
+        return call.clone(call.getType(), ImmutableList.of(o0, o1b));","[{'comment': 'The name `castRequiredForStringOperand` is confusing because in your patch it only works for `EQUALS` and `IS_NOT_DISTINCT_FROM`, can we rename it to `supportsImplicitTypeCoercion` ? Which i think can be reused by many sql contexts that can have implicit type coercion.', 'commenter': 'danny0405'}, {'comment': 'I have changed the method name and modified logic accordingly. Kindly check and let me know any other changes is required. Thanks. ', 'commenter': 'soma-mondal'}]"
1437,core/src/main/java/org/apache/calcite/sql/dialect/BigQuerySqlDialect.java,"@@ -99,6 +103,14 @@ public BigQuerySqlDialect(SqlDialect.Context context) {
     return emulateNullDirectionWithIsNull(node, nullsFirst, desc);
   }
 
+  @Override public boolean supportsImplicitTypeCoercion(RexCall node) {
+    if (!super.supportsImplicitTypeCoercion(node)) {
+      return false;
+    }
+    RexNode operand = node.getOperands().get(0);
+    return operand instanceof RexLiteral && !SqlTypeFamily.NUMERIC.contains(node.type);
+  }
+","[{'comment': 'From this code, you mean we can strip the cast for BigQuery only if:\r\n\r\n- The first operand is a STRING literal\r\n- The second operand is not a NUMERIC\r\n\r\nThis is weird, can you please conform the type coercion rules ? Especially for the operators we strip the cast from: `>` `>=` `<` `<=` `IS NOT DISTINCT FROM` `<>` and for the cases when STRING is casted to other type.\r\n', 'commenter': 'danny0405'}, {'comment': ""From the stripCastFromString method we are passing only the operands that has explicit cast applied. So it can be any of the operands. Now, the above code means, we can strip the cast for BigQuery if : \r\n\r\n- The RexNode on which we have applied the cast is a STRING LITERAL.\r\n- We are trying to cast it to anything apart from NUMERIC type. \r\n\r\nWe are not comparing between datatypes of operands of the comparison operators.\r\n\r\nI have checked the type coercion rules for the above conditions you have mentioned (except IS  NOT DISTINCT FROM, BiqQuery doesn't have this operator yet) . This is my observation, you can check this [sheet](https://docs.google.com/spreadsheets/d/1GJ_VuDY7GQS-aPbWf4EKj73dYCqaRaEqPTjmXLkPW_g/edit#gid=0) .\r\n\r\nFor example,\r\nhire_date = '1996-01-01 00:00:00' is valid in BiqQuery. But,\r\nhire_date = concat('1996-01-01 ','00:00:00') is not valid. Need casting.\r\n(hire_date is a TIMESTAMP column here)\r\n\r\nand \r\n\r\nFor Numeric datatype, \r\nemployee_id = '10' not valid\r\nemployee_id = concat('1','2') not valid\r\n10 = '10' is not valid. "", 'commenter': 'soma-mondal'}, {'comment': 'Thanks for the explain, i think we should match the cases that we exactly know well, because the implicit type coercion rules are relevant with many sql contexts.', 'commenter': 'danny0405'}]"
1462,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -63,8 +65,8 @@ public ProjectJoinTransposeRule(
       PushProjector.ExprCondition preserveExprCondition,
       RelBuilderFactory relFactory) {
     super(
-        operand(Project.class,
-            operand(Join.class, any())),
+        operand(LogicalProject.class,
+            operand(LogicalJoin.class, any())),","[{'comment': 'With this matching pattern changed, do we still need below change -- the way how join node is created.', 'commenter': 'jinxing64'}, {'comment': 'Agree. May better keep the below part unchanged.', 'commenter': 'yanlin-Lynn'}, {'comment': 'I think the way to go is to allow clients to specify their own `Project`, `Join` and `RelBuilderFactory` classes. I guess our default `INSTANCE` of this rule should be adapted to match only `LogicalProject` and `LogicalJoin` and the Javadoc should be changed accordingly.', 'commenter': 'zabetak'}]"
1462,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -142,13 +144,9 @@ public void onMatch(RelOptRuleCall call) {
 
     // create a new join with the projected children
     Join newJoinRel =
-        join.copy(
-            join.getTraitSet(),
-            newJoinFilter,
-            leftProjRel,
-            rightProjRel,
-            join.getJoinType(),
-            join.isSemiJoinDone());
+            (Join) RelFactories.DEFAULT_JOIN_FACTORY.createJoin(
+                    leftProjRel, rightProjRel, newJoinFilter, join.getVariablesSet(),","[{'comment': 'This change is not necessary.', 'commenter': 'danny0405'}]"
1462,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -142,13 +144,9 @@ public void onMatch(RelOptRuleCall call) {
 
     // create a new join with the projected children
     Join newJoinRel =
-        join.copy(","[{'comment': 'Creating new operators should always pass by the specialized `RelBuilderFactory` which should be responsible for doing things right.', 'commenter': 'zabetak'}, {'comment': 'Well, i agree, use `RelBuilder` to construct the relational expression.', 'commenter': 'danny0405'}, {'comment': ""There's a reason we use `RelNodeSubClass.copy`. We need to match the calling convention of the RelNode being copied. \r\n\r\nI couldn't find a JIRA case for removing AbstractRelNode.copy, but this is closely related: https://issues.apache.org/jira/browse/CALCITE-2064."", 'commenter': 'julianhyde'}, {'comment': ""I remember we had a discussion before about this. Because for rules that can match both logical and physical operators, `copy` method can keep it. `RelBuilderFacory` will most likely create logical relational nodes. I don't mind the default rule instance matching logical rel nodes only."", 'commenter': 'hsyuan'}, {'comment': 'For both way, i have no strong objections, since we have change this rule to match only logical nodes, i think `#copy` is not that necessary.', 'commenter': 'danny0405'}, {'comment': 'It seems that the reason for #EnumerableMergeJoin.copy throwing AssertionError is that the #join.copy use #join.getTraitSet() directly. But the collation may have offset since the new join has new left and new right. So the RelCollation of the TraitSet should be update. I am working for that.', 'commenter': 'wenhuitang'}, {'comment': ""Can you explain more, although the new join has new inputs, their type doesn't change, right ? So what do you mean by the offset ?"", 'commenter': 'danny0405'}, {'comment': 'I updated the collations when creating a copy of the join with the new inputs.', 'commenter': 'wenhuitang'}, {'comment': ""> Can you explain more, although the new join has new inputs, their type doesn't change, right ? So what do you mean by the offset ?\r\n\r\nFor example: \r\nEnumerableProject(age=[$3])\r\n  EnumerableMergeJoin(condition=[=($1, $2)], joinType=[inner])\r\n    EnumerableValues(tuples=[[{ '1', 'anna' }, { '2', 'bob' }, { '3', 'tom' }]])\r\n    EnumerableValues(tuples=[[{ 'anna', '14' }, { 'bob', '17' }, { 'tom', '22' }]])\r\nbefore Project is pushed down, the collations of MergeJoin is [1, 2] and the leftkey of the JoinInfo is [1], \r\nafter Project is pushed down, the left child of MergeJoin becomes LogicalProject#68 whose output rowtype is RecordType(CHAR(4) name), so the leftkey becomes [0] (The index of field was changed). So IMO, the collations of new Join should be updated due to changes of the inputs."", 'commenter': 'wenhuitang'}, {'comment': ""Thanks for the explain, @wenhuitang , then fixing the merge join is more acceptable. I kind of don't like the idea to fix the Collation if the logical rules, because collation is a physical trait."", 'commenter': 'danny0405'}, {'comment': ""I'm sorry @danny0405  but I don't understand what you mean by saying fixing the merge join. I don't see a problem with the join itself; from my understanding so far it is the bad use of copy that leads to this problem. I agree with you that having rules modify traits is not a very elegant solution but we are already doing it in a couple of places (other rules using copy method). In the absence of good alternative for copy the solution of leaving the rule treat the modification of traits seems like a decent option. "", 'commenter': 'zabetak'}]"
1462,core/src/test/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRuleTest.java,"@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.adapter.enumerable.EnumerableConvention;
+import org.apache.calcite.adapter.enumerable.EnumerableRules;
+import org.apache.calcite.plan.ConventionTraitDef;
+import org.apache.calcite.plan.RelOptRule;
+import org.apache.calcite.plan.RelTraitSet;
+import org.apache.calcite.rel.RelCollationTraitDef;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Join;
+import org.apache.calcite.rel.core.JoinRelType;
+import org.apache.calcite.rel.core.Project;
+import org.apache.calcite.rel.core.RelFactories;
+import org.apache.calcite.rex.RexOver;
+import org.apache.calcite.sql.parser.SqlParser;
+import org.apache.calcite.tools.FrameworkConfig;
+import org.apache.calcite.tools.Frameworks;
+import org.apache.calcite.tools.Program;
+import org.apache.calcite.tools.Programs;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RuleSet;
+import org.apache.calcite.tools.RuleSets;
+
+import com.google.common.collect.ImmutableList;
+
+import org.junit.Test;
+
+import static org.apache.calcite.plan.RelOptRule.any;
+import static org.apache.calcite.plan.RelOptRule.operand;
+
+import static org.junit.Assert.assertNull;
+import static org.junit.Assert.fail;
+
+/**
+ * Tests the application of the {@code ProjectJoinTransposeRule}.
+ */
+public class ProjectJoinTransposeRuleTest {
+
+  /**
+   * Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3353"">[CALCITE-3353]
+   * ProjectJoinTransposeRule caused AssertionError when creating a new Join</a>.
+   */
+  @Test
+  public void testProjectJoinTransposeWithMergeJoin() {
+    ProjectJoinTransposeRule testRule = new ProjectJoinTransposeRule(
+        operand(Project.class, operand(Join.class, any())),","[{'comment': 'Can we move this test case to `RelOptRulesTest` ?', 'commenter': 'danny0405'}, {'comment': 'Yes, we can move the test to RelOptRulesTest. I am working on correcting the RelCollation of TraitSets which used by new Join. So maybe I will remove the unit test reproducing the problem', 'commenter': 'wenhuitang'}]"
1462,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -62,10 +65,20 @@
   public ProjectJoinTransposeRule(
       PushProjector.ExprCondition preserveExprCondition,
       RelBuilderFactory relFactory) {
-    super(
-        operand(Project.class,
-            operand(Join.class, any())),
-        relFactory, null);
+    this(
+        operand(LogicalProject.class,
+            operand(LogicalJoin.class, any())),
+            preserveExprCondition, relFactory);
+  }
+
+  /**
+   * Creates a ProjectJoinTransposeRule.
+   */
+  public ProjectJoinTransposeRule(
+      RelOptRuleOperand operand,
+      PushProjector.ExprCondition preserveExprCondition,
+      RelBuilderFactory relFactory) {
+    super(operand, relFactory, null);","[{'comment': 'Do we really need a new constructor ?\r\n', 'commenter': 'jinxing64'}, {'comment': 'Just as @zabetak said ""I think the way to go is to allow clients to specify their own Project, Join and RelBuilderFactory classes. I guess our default INSTANCE of this rule should be adapted to match only LogicalProject and LogicalJoin""\r\nI think it\'s a good way, it gives more choice.', 'commenter': 'wenhuitang'}, {'comment': 'I really mean that only one constructor is enough. You can construct INSTANCE by \r\n```\r\n  public static final ProjectJoinTransposeRule INSTANCE =\r\n      new ProjectJoinTransposeRule(\r\n          operand(LogicalProject.class, operand(LogicalJoin.class, any())),\r\n          expr -> !(expr instanceof RexOver),\r\n          RelFactories.LOGICAL_BUILDER);', 'commenter': 'jinxing64'}, {'comment': 'The new constructor is more liberal than it should be; allowing to pass a RelOptRuleOperand means that the rule may match something else than Project and Join for which it was intended for. \r\n\r\n@jinxing64 Dropping a public constructor breaks backward compatibility so ideally it should remain as is (possibly deprecated). Other than that I agree with you that we can call directly the new constructor for creating the instance.', 'commenter': 'zabetak'}, {'comment': 'Thanks for explanation @zabetak \r\nI got it now :)', 'commenter': 'jinxing64'}, {'comment': 'Thanks a lot for reviewing , I have addressed it.', 'commenter': 'wenhuitang'}]"
1462,core/src/main/java/org/apache/calcite/adapter/enumerable/EnumerableCorrelate.java,"@@ -77,6 +78,13 @@ public static EnumerableCorrelate create(
   @Override public EnumerableCorrelate copy(RelTraitSet traitSet,
       RelNode left, RelNode right, CorrelationId correlationId,
       ImmutableBitSet requiredColumns, JoinRelType joinType) {
+    // Get new collations since the Correlate has new inputs and new condition.
+    ImmutableList<RelCollation> newCollations = ImmutableList.copyOf(
+            RelMdCollation.enumerableCorrelate(
+            getCluster().getMetadataQuery(), left, right, joinType));
+    if (!newCollations.isEmpty()) {
+      traitSet = traitSet.replace(newCollations);","[{'comment': 'I see what you are trying to do here but you are kinda violating the contract of `copy` (_Creates a copy of this relational expression, perhaps changing traits and inputs_); the client of the method can no longer change traits (at least collation). Furthermore, if you do this inside `copy` you could call the `create` method directly which brings me to my initial comment. Instead of using copy inside the rule you could opt for the RelBuilderFactory.', 'commenter': 'zabetak'}, {'comment': ""Maybe we're going at this the wrong way, and trying too hard. If you call `ProjectJoinTransposeRule` on a `MergeJoin` (which requires sorted input), and the `Project` does not, after being pushed down, give sorted output, then maybe the rule should just abort.\r\n\r\nJust a thought."", 'commenter': 'julianhyde'}, {'comment': 'Julian, should we just skip matching for `MergeJoin` if the project does not sort output ?', 'commenter': 'danny0405'}, {'comment': 'I got it, I thought too much when I tried to solve this problem. I understood that the other  enumerable join class should also have right collations considering the CALCITE-2554.  I will adjust this PR that only update the collations for MergeJoin. And abort the rule if the new inputs of MergeJoin are not sorted(the result of RelMdCollation.mergeJoin for new MergeJoin is  empty).\r\n\r\nIs this the suitable solution?', 'commenter': 'wenhuitang'}, {'comment': 'IMHO, `ProjectJoinTransposeRule` should just stop matching physical operators.', 'commenter': 'hsyuan'}, {'comment': ""Yes. Let's make ProjectJoinTransposeRule.INSTANCE just match LogicalJoin and LogicalProject. Add class arguments so that people can create other instances of the rule, if they wish."", 'commenter': 'julianhyde'}]"
1462,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -19,29 +19,40 @@
 import org.apache.calcite.plan.RelOptRule;
 import org.apache.calcite.plan.RelOptRuleCall;
 import org.apache.calcite.plan.RelOptUtil;
+import org.apache.calcite.plan.RelTraitSet;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollationTraitDef;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
 import org.apache.calcite.rel.RelNode;
 import org.apache.calcite.rel.core.Join;
 import org.apache.calcite.rel.core.Project;
 import org.apache.calcite.rel.core.RelFactories;
+import org.apache.calcite.rel.logical.LogicalJoin;
+import org.apache.calcite.rel.logical.LogicalProject;
 import org.apache.calcite.rel.type.RelDataTypeField;
 import org.apache.calcite.rex.RexCall;
 import org.apache.calcite.rex.RexNode;
 import org.apache.calcite.rex.RexOver;
 import org.apache.calcite.rex.RexShuttle;
+import org.apache.calcite.rex.RexUtil;
 import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.mapping.Mappings;
 
 import java.util.ArrayList;
 import java.util.List;
 
 /**
- * Planner rule that pushes a {@link org.apache.calcite.rel.core.Project}
- * past a {@link org.apache.calcite.rel.core.Join}
+ * Planner rule that pushes a {@link org.apache.calcite.rel.logical.LogicalProject}
+ * past a {@link org.apache.calcite.rel.logical.LogicalJoin}","[{'comment': 'We should keep the original comments but add move the comments you added to the default `INSTANCE`.', 'commenter': 'danny0405'}]"
1478,core/src/main/java/org/apache/calcite/rex/RexUtil.java,"@@ -302,7 +303,16 @@ public static RexNode removeCast(RexNode e) {
     for (;;) {
       switch (e.getKind()) {
       case CAST:
+        RelDataType destType = e.getType();
         e = ((RexCall) e).operands.get(0);
+        if (!SqlTypeUtil.canCastFrom(destType, e.getType(), true)) {
+          throw new UnsupportedOperationException(","[{'comment': ""AFAIK, the `removeCast` doesn't say that it would only remove the redundant casts, it just remove `any` casts, so i don't think we should add a `SqlTypeUtil.canCastFrom` check here and throws exception. It is the invoker that should apply these rules."", 'commenter': 'danny0405'}, {'comment': 'PR updated.\r\nI add the type check for cast in `InputUsageFinder`.', 'commenter': 'yanlin-Lynn'}, {'comment': '@danny0405 , how about this time, check cast in `InputUsageFinder`?', 'commenter': 'yanlin-Lynn'}]"
1519,core/src/test/java/org/apache/calcite/util/Smalls.java,"@@ -182,6 +184,10 @@ public void close() {
     };
   }
 
+  public static QueryableTable generateStrings2(final List<Integer> list) {
+    return generateStrings(list.size());","[{'comment': 'Can we give it a more meaning name ? not XXX2 ?', 'commenter': 'danny0405'}, {'comment': 'good catch, done.', 'commenter': 'ihuzenko'}]"
1519,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -251,13 +253,25 @@ public static RelDataType toSql(final RelDataTypeFactory typeFactory,
               type.getFieldNames()),
           type.isNullable());
     } else if (type instanceof JavaType) {
-      return typeFactory.createTypeWithNullability(
-          typeFactory.createSqlType(type.getSqlTypeName()),
-          type.isNullable());
+      Class javaClass = ((JavaType) type).getJavaClass();
+      final RelDataType nonNullType;
+      if (javaClass.isArray()) {
+        nonNullType = typeFactory.createArrayType(type.getComponentType(), -1);
+      } else if (isCollection(javaClass)) {
+        nonNullType = typeFactory.createArrayType(typeFactory.createSqlType(SqlTypeName.ANY), -1);
+      } else {
+        nonNullType = typeFactory.createSqlType(type.getSqlTypeName());
+      }
+      return typeFactory.createTypeWithNullability(nonNullType, type.isNullable());
     }
     return type;
   }
 
+  private static boolean isCollection(Class javaClass) {
+    return javaClass == Collection.class
+        || Arrays.stream(javaClass.getInterfaces()).anyMatch(JavaTypeFactoryImpl::isCollection);
+  }","[{'comment': ""This would form a n * n *.. recursion, i don't think we need that, for each super class, only `javaClass == Collection.class` is enough."", 'commenter': 'danny0405'}]"
1519,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -251,13 +253,25 @@ public static RelDataType toSql(final RelDataTypeFactory typeFactory,
               type.getFieldNames()),
           type.isNullable());
     } else if (type instanceof JavaType) {
-      return typeFactory.createTypeWithNullability(
-          typeFactory.createSqlType(type.getSqlTypeName()),
-          type.isNullable());
+      Class javaClass = ((JavaType) type).getJavaClass();
+      final RelDataType nonNullType;
+      if (javaClass.isArray()) {
+        nonNullType = typeFactory.createArrayType(type.getComponentType(), -1);
+      } else if (isCollection(javaClass)) {
+        nonNullType = typeFactory.createArrayType(typeFactory.createSqlType(SqlTypeName.ANY), -1);
+      } else {
+        nonNullType = typeFactory.createSqlType(type.getSqlTypeName());
+      }","[{'comment': 'Can you reference `JavaToSqlTypeConversionRules` for the type mapping ?', 'commenter': 'danny0405'}, {'comment': ""There is no need to use ```JavaToSqlTypeConversionRules``` here because ```type``` contains SqlTypeName. Most probably this check just need to be rewritten to switch case based on the enum values and further java class investigation isn't necessary here. To be honest the API of ```typeFactory``` which promises to ```createSqlType(...)``` for sqlTypeName and implicitly throws assertion errors is really bad. "", 'commenter': 'ihuzenko'}, {'comment': ""I didn't mean to use `JavaToSqlTypeConversionRules` directly, i meant to match all the java collection classes that synced with what `JavaToSqlTypeConversionRules` has already matched."", 'commenter': 'danny0405'}]"
1519,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -251,13 +253,25 @@ public static RelDataType toSql(final RelDataTypeFactory typeFactory,
               type.getFieldNames()),
           type.isNullable());
     } else if (type instanceof JavaType) {
-      return typeFactory.createTypeWithNullability(
-          typeFactory.createSqlType(type.getSqlTypeName()),
-          type.isNullable());
+      Class javaClass = ((JavaType) type).getJavaClass();
+      final RelDataType nonNullType;
+      if (javaClass.isArray()) {","[{'comment': 'what about map type?', 'commenter': 'yanlin-Lynn'}, {'comment': 'Issue described in Jira ticket relates to ARRAY assertion inside ```SqlTypeFactoryImpl```\'s assertBasic method: \r\n```java\r\n  private void assertBasic(SqlTypeName typeName) {\r\n    assert typeName != null;\r\n    assert typeName != SqlTypeName.MULTISET\r\n        : ""use createMultisetType() instead"";\r\n    assert typeName != SqlTypeName.ARRAY\r\n        : ""use createArrayType() instead"";\r\n    assert typeName != SqlTypeName.ROW\r\n        : ""use createStructType() instead"";\r\n    assert !SqlTypeName.INTERVAL_TYPES.contains(typeName)\r\n        : ""use createSqlIntervalType() instead"";\r\n  }\r\n```\r\nFor map type assertion isn\'t fired here and I think it\'s rare case that someone will accept map arguments (or others from the method body) into custom table function. ', 'commenter': 'ihuzenko'}, {'comment': ""I'm not sure is it a bug or is just designed like this.\r\nFor me, it's probably a bug.\r\nI create a PR(https://github.com/apache/calcite/pull/1521) trying to fix it."", 'commenter': 'yanlin-Lynn'}]"
1519,core/src/test/java/org/apache/calcite/test/TableFunctionTest.java,"@@ -105,6 +105,24 @@
     }
   }
 
+  @Test public void testTableFunctionWithArrayParameter() throws SQLException {","[{'comment': 'maybe add a case for map type parameter?', 'commenter': 'yanlin-Lynn'}, {'comment': 'I think array is enough, just like what the commit describes.', 'commenter': 'danny0405'}]"
1519,core/src/main/java/org/apache/calcite/jdbc/JavaTypeFactoryImpl.java,"@@ -251,9 +251,16 @@ public static RelDataType toSql(final RelDataTypeFactory typeFactory,
               type.getFieldNames()),
           type.isNullable());
     } else if (type instanceof JavaType) {
-      return typeFactory.createTypeWithNullability(
-          typeFactory.createSqlType(type.getSqlTypeName()),
-          type.isNullable());
+      SqlTypeName sqlTypeName = type.getSqlTypeName();
+      final RelDataType relDataType;
+      if (sqlTypeName == SqlTypeName.ARRAY) {
+        RelDataType elementType = type.getComponentType() == null
+            ? typeFactory.createSqlType(SqlTypeName.ANY) : type.getComponentType();","[{'comment': ""Does it need special consideration when it's a nested array, i.e. the element type of array is also of array"", 'commenter': 'jinxing64'}, {'comment': ""Could you please give an example of table function for which it's necessary to accept nested array as argument ? "", 'commenter': 'ihuzenko'}, {'comment': 'You can use `SqlTypeUtil#isArray` to decide if a type is `ARRAY` type.', 'commenter': 'danny0405'}]"
1567,core/src/test/java/org/apache/calcite/test/ScannableTableTest.java,"@@ -445,6 +469,20 @@ protected ConnectionPostProcessor newSchema(final String schemaName,
     };
   }
 
+  protected ConnectionPostProcessor newSchema(final String schemaName,
+                                                     final String tableName1, final Table table1,
+                                                     final String tableName2, final Table table2) {
+    return connection -> {
+      CalciteConnection con = connection.unwrap(CalciteConnection.class);
+      SchemaPlus rootSchema = con.getRootSchema();
+      SchemaPlus schema = rootSchema.add(schemaName, new AbstractSchema());
+      schema.add(tableName1, table1);","[{'comment': 'This method signature is weird, can we make more effort to refactor it out? Also be cautious to the indentation ', 'commenter': 'danny0405'}, {'comment': 'How about a list of tableNames and a list of Tables?', 'commenter': 'hsyuan'}, {'comment': ""That's good idea."", 'commenter': 'xndai'}]"
1567,core/src/test/java/org/apache/calcite/test/ScannableTableTest.java,"@@ -363,6 +364,30 @@ private static Integer getFilter(boolean cooperative, List<RexNode> filters) {
     assertThat(buf.toString(), is(""returnCount=4, projects=[2, 0]""));
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-3479"">[CALCITE-3479]
+   * Stack overflow error thrown when running join query</a>
+   * Test two ProjectableFilterableTable can join and produce right plan.
+   */
+  @Test public void testProjectableFilterableTableJoin() throws Exception {
+    final StringBuilder buf = new StringBuilder();
+    final String explain = ""PLAN=""
+        + ""EnumerableHashJoin(condition=[=($0, $3)], joinType=[inner])\n""
+        + ""  EnumerableInterpreter\n""
+        + ""    BindableTableScan(table=[[s, b1]], filters=[[=($0, 10)]])\n""
+        + ""  EnumerableInterpreter\n""
+        + ""    BindableTableScan(table=[[s, b2]], filters=[[=($0, 10)]])"";
+    CalciteAssert.that()
+            .with(
+              newSchema(""s"",
+                  Pair.of(""b1"", new BeatlesProjectableFilterableTable(buf, true)),","[{'comment': 'Can this table be shared?', 'commenter': 'hsyuan'}, {'comment': 'OK, no.', 'commenter': 'hsyuan'}]"
1568,core/src/test/java/org/apache/calcite/sql/parser/SqlParserTest.java,"@@ -3699,6 +3700,14 @@ void checkPeriodPredicate(Checker checker) {
         .ok(expected);
   }
 
+  @Test public void testInsertDialect() {
+    // See [CALCITE-3486] MysqlSqlDialect unparse ROW keyword does not exist","[{'comment': ""You don't need this comment. If you actually want to say this test is testing `ROW`, you can rename this test as `testInsertWithRowDialect`."", 'commenter': 'amaliujia'}, {'comment': 'Thank you.\r\nmodified\r\n', 'commenter': 'quxiucheng'}]"
1568,core/src/main/java/org/apache/calcite/sql/dialect/MysqlSqlDialect.java,"@@ -179,6 +179,9 @@ public boolean supportsAliasedValues() {
 
       unparseFloor(writer, call);
       break;
+    case ROW:
+      unparseRow(writer, call);","[{'comment': 'Thanks for the fix @quxiucheng, i think this patch can be promoted a little, we can move this logic to the parent class `SqlDialect`, you can get the `SqlConformance` from the dialect and decide if we should generates the `ROW` keyword based on method `SqlConformance#allowExplicitRowValueConstructor `.\r\n\r\n[1] https://github.com/apache/calcite/blob/4d1c3e54fc4172c7ff00db3326823c42f237cf04/core/src/main/java/org/apache/calcite/sql/validate/SqlConformance.java#L296\r\n\r\n', 'commenter': 'danny0405'}, {'comment': ""done.\r\nbut  the class `SqlDialect` can't get the method `SqlConformance#allowExplicitRowValueConstructor` correctly. I added a field in the class `SqlDialect`, Same as the field 'SqlConformance#allowExplicitRowValueConstructor'"", 'commenter': 'quxiucheng'}, {'comment': 'What do you mean by ""can not get method correctly"", for MySQL, the conformance is `SqlConformanceEnum.MYSQL_5` which i think is correct.\r\n\r\n[1] https://github.com/apache/calcite/blob/4d1c3e54fc4172c7ff00db3326823c42f237cf04/core/src/main/java/org/apache/calcite/sql/SqlDialect.java#L1092\r\n', 'commenter': 'danny0405'}, {'comment': 'We have two ways of creating dialects.\r\n1. XxxSqlDialect.DEFAULT\r\n2. SqlDialect.DatabaseProduct.XXX.getDialect()\r\n\r\nIf we only call `org.apache.calcite.sql.SqlDialect#getConformance` this method to get `conformance`.\r\nOnly compatible `SqlDialect.DatabaseProduct.XXX.getDialect()` method. So I reset a parameter `allowExplicitRowValueConstructor` to be compatible with both ways of creating the dialect.', 'commenter': 'quxiucheng'}, {'comment': '`XxxSqlDialect.DEFAULT` also works, if we have set up the `DatabaseProduct` correctly. There is no overridden of method `SqlDialect#getConformance`, so i believe the behavior is correct.', 'commenter': 'danny0405'}, {'comment': ""I see.Thanks.\r\n\r\nI have a question:\r\n\r\nthe method `SqlConformanceEnum#allowExplicitRowValueConstructor`\r\n```\r\n  public boolean allowExplicitRowValueConstructor() {\r\n    switch (this) {\r\n    case DEFAULT:\r\n    case LENIENT:\r\n      return true;\r\n    default:\r\n      return false;\r\n    }\r\n  }\r\n```\r\nOnly `SqlConformanceEnum#DEFAULT` and `SqlConformanceEnum#LENIENT` return values are true.\r\nIf this standard doesn't change. Test classes are mostly used by default method `SqlConformanceEnum#PRAGMATIC_2003`,\r\n`unparse` will then have a lot of `ROW` keyword changes. Because they don't support the `ROW` keyword.\r\nShould I add `SqlConformanceEnum#PRAGMATIC_2003` to a method `SqlConformanceEnum#allowExplicitRowValueConstructor` or change the test class."", 'commenter': 'quxiucheng'}, {'comment': 'The return value ""true"" means we would print the ""ROW"" keyword, for `SqlConformanceEnum#PRAGMATIC_2003`, it is expected to not allows that.', 'commenter': 'danny0405'}, {'comment': ""Okay, I'm going to rewrite the code"", 'commenter': 'quxiucheng'}]"
1568,core/src/test/java/org/apache/calcite/sql/parser/SqlParserTest.java,"@@ -3699,6 +3700,13 @@ void checkPeriodPredicate(Checker checker) {
         .ok(expected);
   }
 
+  @Test public void testInsertWithRowDialect() {
+    final String expected = ""INSERT INTO `emps`\n""","[{'comment': 'Maybe we can rename this method to `testRowValueExpression` and we should test dialect that allows/not allow explicit `ROW` keywords.', 'commenter': 'danny0405'}]"
1568,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -158,6 +158,7 @@
   private final Casing unquotedCasing;
   private final Casing quotedCasing;
   private final boolean caseSensitive;
+  private final boolean allowExplicitRowValueConstructor;
 ","[{'comment': 'Remove this `allowExplicitRowValueConstructor` flag, we expect to get this info from the `SqlConformance`.', 'commenter': 'danny0405'}]"
1568,core/src/test/java/org/apache/calcite/sql/parser/SqlParserTest.java,"@@ -1159,6 +1159,36 @@ protected boolean isUnparserTest() {
         .ok(""SELECT ((`TBL`.`FOO`(0).`COL`).`BAR`)\nFROM `TBL`"");
   }
 
+  @Test public void testRowValueExpression() {
+    String expected = ""INSERT INTO \""EMPS\""\n""
+            + ""VALUES (ROW(1, 'Fred')),\n""
+            + ""(ROW(2, 'Eric'))"";
+    sql(""insert into emps values ROW(1,'Fred'),ROW(2, 'Eric')"")
+            .withDialect(SqlDialect.DatabaseProduct.CALCITE.getDialect())
+            .ok(expected);
+
+    expected = ""INSERT INTO `emps`\n""
+            + ""VALUES (1, 'Fred'),\n""
+            + ""(2, 'Eric')"";
+    sql(""insert into emps values (1,'Fred'),(2, 'Eric')"")","[{'comment': 'Why different value for sql() method? Shall we use the same.', 'commenter': 'yanlin-Lynn'}, {'comment': ""sorry,I didn't notice that\r\nWrite the wrong"", 'commenter': 'quxiucheng'}]"
1568,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -448,6 +448,31 @@ public void unparseCall(SqlWriter writer, SqlCall call, int leftPrec,
     call.getOperator().unparse(writer, call, leftPrec, rightPrec);
   }
 
+  public void unparseRow(SqlWriter writer,
+      SqlCall call, int leftPrec,  int rightPrec) {
+    if (getConformance().allowExplicitRowValueConstructor()) {
+      SqlUtil.unparseFunctionSyntax(call.getOperator(), writer, call);
+    } else {
+      if ("" "".equals(call.getOperator().getName())) {
+        writer.print(call.getOperator().getName());
+      }
+      if (writer.isAlwaysUseParentheses()) {
+        for (SqlNode operand : call.getOperandList()) {
+          writer.sep("","");","[{'comment': 'Can you explain why we need this decision ?', 'commenter': 'danny0405'}, {'comment': ""This `isAlwaysUseParentheses` parameter will link operations with parentheses.\r\nFor example ,\r\n`(a + b) * c`.The fully-parenthesized expression, `((a + b) * c)`\r\n\r\nIf this parameter is in the `SqlRowOperator`. There will be extra parentheses\r\nFor example,\r\n`isAlwaysUseParentheses=true` and `allowExplicitRowValueConstructor=false`\r\n\r\ninput expression:\r\n`insert into emp valuse (1,'a')`\r\n\r\nunparse result:\r\n`insert into emp valuse ((1,'a'))`\r\n\r\nI think this is a wrong SQL."", 'commenter': 'quxiucheng'}]"
1568,core/src/main/java/org/apache/calcite/sql/fun/SqlRowOperator.java,"@@ -82,7 +82,7 @@ public void unparse(
       SqlCall call,
       int leftPrec,
       int rightPrec) {
-    SqlUtil.unparseFunctionSyntax(this, writer, call);
+    writer.getDialect().unparseRow(writer, call, leftPrec, rightPrec);
   }","[{'comment': 'We should not modify the unparse logic of `SqlRowOperator`, instead in `SqlDialect`, match the `ROW` call and unparse it specifically.', 'commenter': 'danny0405'}, {'comment': 'okay. done', 'commenter': 'quxiucheng'}]"
1586,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoPlanner.java,"@@ -1054,10 +1053,6 @@ private RelNode changeTraitsUsingConverters(
               allowInfiniteCostConverters);
       if (rel != null) {
         assert rel.getTraitSet().getTrait(traitDef).satisfies(toTrait);
-        rel =
-            completeConversion(
-                rel, allowInfiniteCostConverters, toTraits,
-                Expressions.list(traitDef));
         if (rel != null) {","[{'comment': ""We don't need this check anymore."", 'commenter': 'hsyuan'}]"
1586,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoPlanner.java,"@@ -1054,10 +1053,6 @@ private RelNode changeTraitsUsingConverters(
               allowInfiniteCostConverters);
       if (rel != null) {
         assert rel.getTraitSet().getTrait(traitDef).satisfies(toTrait);
-        rel =
-            completeConversion(
-                rel, allowInfiniteCostConverters, toTraits,
-                Expressions.list(traitDef));
         if (rel != null) {
           register(rel, converted);
         }","[{'comment': 'https://github.com/apache/calcite/pull/1586/files#diff-70d5035797baebe157bab8cbf860e456R1061 can be changed to `else if` and remove `rel == null` check.', 'commenter': 'hsyuan'}]"
1586,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoPlanner.java,"@@ -1081,60 +1072,6 @@ private RelNode changeTraitsUsingConverters(
     return converted;
   }
 
-  /**
-   * Converts traits using well-founded induction. We don't require that
-   * each conversion preserves all traits that have previously been converted,
-   * but if it changes ""locked in"" traits we'll try some other conversion.
-   *
-   * @param rel                         Relational expression
-   * @param allowInfiniteCostConverters Whether to allow infinite converters
-   * @param toTraits                    Target trait set
-   * @param usedTraits                  Traits that have been locked in
-   * @return Converted relational expression
-   */
-  private RelNode completeConversion(
-      RelNode rel,
-      boolean allowInfiniteCostConverters,
-      RelTraitSet toTraits,
-      Expressions.FluentList<RelTraitDef> usedTraits) {
-    if (true) {
-      return rel;","[{'comment': 'Please hold on for the fix, i\'m curious if this logic is left there intentionally. @julianhyde Can you please take a look at this code ? There are many places in Calcite with the special ""useless"" `if(true)` logic, for me, it makes the logic more clear because it illustrates how the logic evolves.', 'commenter': 'danny0405'}, {'comment': 'I already replied in the jira case', 'commenter': 'julianhyde'}]"
1619,core/src/main/java/org/apache/calcite/rel/rules/ProjectAggregateTransposeRule.java,"@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptRule;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Aggregate;
+import org.apache.calcite.rel.core.Project;
+import org.apache.calcite.rel.core.RelFactories;
+import org.apache.calcite.rel.logical.LogicalAggregate;
+import org.apache.calcite.rel.logical.LogicalProject;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.Pair;
+import org.apache.calcite.util.mapping.Mappings;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that pushes a {@link org.apache.calcite.rel.core.Project}
+ * past a {@link org.apache.calcite.rel.core.Aggregate}.
+ */
+public class ProjectAggregateTransposeRule extends RelOptRule {
+
+  public static final ProjectAggregateTransposeRule INSTANCE =
+      new ProjectAggregateTransposeRule(Project.class,
+          Aggregate.class, RelFactories.LOGICAL_BUILDER);
+
+  /**
+   * Creates a ProjectAggregateTransposeRule.
+   */
+  private ProjectAggregateTransposeRule(Class<? extends Project> project,
+      Class<? extends Aggregate> aggregate, RelBuilderFactory relBuilderFactory) {
+    super(operand(project, operand(aggregate, any())),
+        relBuilderFactory, ""ProjectAggregateTransposeRule"");
+  }
+
+  public void onMatch(RelOptRuleCall call) {
+    final LogicalProject proRel = call.rel(0);
+    final LogicalAggregate aggRel = call.rel(1);
+
+    final Mappings.TargetMapping mapping =
+        Project.getMapping(aggRel.getRowType().getFieldCount(), proRel.getProjects());
+    if (mapping == null || Mappings.keepsOrdering(mapping)) {
+      // do nothing
+      return;
+    }
+    // Project              Aggregate
+    //    Aggregate  --->      Project
+    final List<Pair<Integer, Integer>> pairs = new ArrayList<>();
+    final List<Integer> groupings = aggRel.getGroupSet().toList();
+    RelBuilder relBuilder = call.builder();
+    final List<Integer> posList = new ArrayList<>();
+
+    for (int i = 0; i < groupings.size(); i++) {
+      pairs.add(Pair.of(mapping.getTarget(groupings.get(i)), i));
+    }
+    Collections.sort(pairs);
+    pairs.forEach(pair -> posList.add(pair.right));
+
+    for (int i = posList.size(); i < aggRel.getInput().getRowType().getFieldCount(); i++) {
+      posList.add(i);
+    }
+    List<RexNode> newProj = posList.stream().map(
+        pos -> RexInputRef.of(pos, aggRel.getInput().getRowType()))
+        .collect(Collectors.toList());
+    final RelNode project = relBuilder.push(aggRel.getInput()).project(newProj).build();
+
+    RelNode newAgg = relBuilder.push(project).aggregate(relBuilder.groupKey(aggRel.getGroupSet()),
+        aggRel.getAggCallList()).build();
+
+    if (!rowTypesAreEquivalent(proRel, newAgg)) {
+      return;
+    }
+
+    call.transformTo(newAgg);
+  }
+
+  private boolean rowTypesAreEquivalent(
+      RelNode rel0, RelNode rel1) {
+    if (rel0.getRowType().getFieldCount() != rel1.getRowType().getFieldCount()) {
+      return false;
+    }","[{'comment': 'You can use `RelOptUtils#areRowTypesEqual` to compare whether two RelDataTypes equal.', 'commenter': 'chunweilei'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);","[{'comment': 'How about we define it as \r\n```\r\n    super(operand(query(0)),\r\n          operand(MutableCalc.class, target(0)), 1);\r\n```\r\nIt means `query` are equivalent to input of `target` and the only difference is that there is a `Calc` for permutation in the `target`', 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.","[{'comment': ""What's going on here ? \r\nThis doc here seems not consistent with the implementation."", 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);
+    }
+
+    public UnifyResult apply(UnifyRuleCall call) {
+      final MutableRel rel = call.query;
+      final MutableCalc target = (MutableCalc) call.target;
+      final MutableRel targetInput = target.getInput();
+      final Pair<RexNode, List<RexNode>> qInputExplained = explainCalc(target);
+      if (rel.getParent() != null || target.getParent() != null) {
+        return null;
+      }","[{'comment': 'why this ?', 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);
+    }
+
+    public UnifyResult apply(UnifyRuleCall call) {
+      final MutableRel rel = call.query;
+      final MutableCalc target = (MutableCalc) call.target;
+      final MutableRel targetInput = target.getInput();
+      final Pair<RexNode, List<RexNode>> qInputExplained = explainCalc(target);
+      if (rel.getParent() != null || target.getParent() != null) {
+        return null;
+      }
+      final Mappings.TargetMapping mapping =
+          Project.getMapping(target.getInput().rowType.getFieldCount(), qInputExplained.right);
+      if (mapping == null || Mappings.keepsOrdering(mapping)) {
+        return null;
+      }","[{'comment': ""why it's necessary to keep the ordering ?"", 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);
+    }
+
+    public UnifyResult apply(UnifyRuleCall call) {
+      final MutableRel rel = call.query;","[{'comment': 'How about name it as `query` ?', 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);
+    }
+
+    public UnifyResult apply(UnifyRuleCall call) {
+      final MutableRel rel = call.query;
+      final MutableCalc target = (MutableCalc) call.target;
+      final MutableRel targetInput = target.getInput();
+      final Pair<RexNode, List<RexNode>> qInputExplained = explainCalc(target);
+      if (rel.getParent() != null || target.getParent() != null) {
+        return null;
+      }
+      final Mappings.TargetMapping mapping =
+          Project.getMapping(target.getInput().rowType.getFieldCount(), qInputExplained.right);
+      if (mapping == null || Mappings.keepsOrdering(mapping)) {
+        return null;
+      }
+      MutableRel equalRel = rel.getInputs().get(0);
+      while (equalRel != targetInput) {","[{'comment': 'I think the equality checking of input should rely on the frame work, not check by yourself.\r\nIf the matching pattern is as below \r\n```\r\n super(operand(query(0)),\r\n          operand(MutableCalc.class, target(0)), 1);\r\n```\r\nSubstutitionVisitor will check the if `query` equals to the input of `target` for you', 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);
+    }
+
+    public UnifyResult apply(UnifyRuleCall call) {
+      final MutableRel rel = call.query;
+      final MutableCalc target = (MutableCalc) call.target;
+      final MutableRel targetInput = target.getInput();
+      final Pair<RexNode, List<RexNode>> qInputExplained = explainCalc(target);
+      if (rel.getParent() != null || target.getParent() != null) {
+        return null;
+      }
+      final Mappings.TargetMapping mapping =
+          Project.getMapping(target.getInput().rowType.getFieldCount(), qInputExplained.right);
+      if (mapping == null || Mappings.keepsOrdering(mapping)) {
+        return null;
+      }
+      MutableRel equalRel = rel.getInputs().get(0);
+      while (equalRel != targetInput) {
+        if (equalRel instanceof MutableScan) {
+          return null;
+        }
+        equalRel = equalRel.getInputs().get(0);
+      }
+      MutableRel parent = equalRel.getParent();
+      final RexBuilder rexBuilder = call.getCluster().getRexBuilder();
+
+      List<RexNode> rexNodes = (List<RexNode>) rexBuilder.identityProjects(equalRel.rowType);
+      try {
+        RexShuttle shuttle = getRexShuttle(qInputExplained.right);
+        List<RexNode> compenProj = shuttle.apply(rexNodes);","[{'comment': 'Rather than a shuttle, how about use mapping ?', 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {
+
+    public static final NothingToCalcUnifyRule INSTANCE =
+        new NothingToCalcUnifyRule();
+
+    private NothingToCalcUnifyRule() {
+      super(any(MutableRel.class),
+          any(MutableCalc.class), 0);
+    }
+
+    public UnifyResult apply(UnifyRuleCall call) {
+      final MutableRel rel = call.query;
+      final MutableCalc target = (MutableCalc) call.target;
+      final MutableRel targetInput = target.getInput();
+      final Pair<RexNode, List<RexNode>> qInputExplained = explainCalc(target);
+      if (rel.getParent() != null || target.getParent() != null) {
+        return null;
+      }
+      final Mappings.TargetMapping mapping =
+          Project.getMapping(target.getInput().rowType.getFieldCount(), qInputExplained.right);
+      if (mapping == null || Mappings.keepsOrdering(mapping)) {
+        return null;
+      }
+      MutableRel equalRel = rel.getInputs().get(0);
+      while (equalRel != targetInput) {
+        if (equalRel instanceof MutableScan) {
+          return null;
+        }
+        equalRel = equalRel.getInputs().get(0);
+      }
+      MutableRel parent = equalRel.getParent();
+      final RexBuilder rexBuilder = call.getCluster().getRexBuilder();
+
+      List<RexNode> rexNodes = (List<RexNode>) rexBuilder.identityProjects(equalRel.rowType);
+      try {
+        RexShuttle shuttle = getRexShuttle(qInputExplained.right);
+        List<RexNode> compenProj = shuttle.apply(rexNodes);
+        RexProgram rexProgram = RexProgram.create(target.rowType, compenProj, null,
+            equalRel.rowType, rexBuilder);
+        MutableCalc newProj = MutableCalc.of(target, rexProgram);
+        parent.setInput(0, newProj);
+        if (equalRel.getParent() instanceof MutableCalc) {","[{'comment': ""I don't think this check is right, we should use `tryMergeParentCalcAndGenResult`"", 'commenter': 'jinxing64'}]"
1619,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1070,6 +1071,70 @@ private ScanToCalcUnifyRule() {
     }
   }
 
+  /**
+   * A {@link SubstitutionVisitor.UnifyRule} that matches a {@link MutableCalc}
+   * which has {@link MutableAggregate} as  child.
+   * We try to compensate the {@link MutableCalc},
+   * then match the query to the top of {@link MutableCalc} in target.
+   */
+  private static class NothingToCalcUnifyRule extends AbstractUnifyRule {","[{'comment': 'How about `PermutationMatchingUnifyRule` ?', 'commenter': 'jinxing64'}]"
1692,core/src/test/java/org/apache/calcite/test/MaterializationTest.java,"@@ -2857,6 +2858,26 @@ private void checkSatisfiable(RexNode e, String s) {
     checkMaterialize(mv, query);
   }
 
+  @Test public void testIntersectToIntersect0() {
+    final String mv = """"
+        + ""select \""deptno\"" from\n""
+        + ""\""emps\"" intersect select \""deptno\""  from \""depts\"""";","[{'comment': 'Redundant spaces ?', 'commenter': 'jinxing64'}]"
1692,core/src/test/java/org/apache/calcite/test/MaterializationTest.java,"@@ -2857,6 +2858,26 @@ private void checkSatisfiable(RexNode e, String s) {
     checkMaterialize(mv, query);
   }
 
+  @Test public void testIntersectToIntersect0() {
+    final String mv = """"
+        + ""select \""deptno\"" from\n""
+        + ""\""emps\"" intersect select \""deptno\""  from \""depts\"""";
+    final String query = """"
+        + ""select \""deptno\"" from\n""
+        + ""\""depts\"" intersect select \""deptno\"" from \""emps\"""";
+    checkMaterialize(mv, query, true);
+  }
+
+  @Test public void testIntersectToIntersect1() {","[{'comment': 'How about format like below:\r\n```\r\nselect deptno from emps\r\nintersect\r\nselect deptno  from depts;', 'commenter': 'jinxing64'}, {'comment': 'thanks, update code.', 'commenter': 'xy2953396112'}]"
1704,core/src/main/java/org/apache/calcite/plan/RelOptMaterializations.java,"@@ -201,6 +202,7 @@
             .addRuleInstance(ProjectMergeRule.INSTANCE)
             .addRuleInstance(ProjectRemoveRule.INSTANCE)
             .addRuleInstance(ProjectJoinTransposeRule.INSTANCE)
+            .addRuleInstance(ProjectSetOpTransposeRule.INSTANCE)
             .addRuleInstance(FilterToCalcRule.INSTANCE)
             .addRuleInstance(ProjectToCalcRule.INSTANCE)","[{'comment': 'LGTM', 'commenter': 'chunweilei'}]"
1704,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1621,8 +1621,31 @@ public UnifyResult apply(UnifyRuleCall call) {
             }
           }
         }
+
+        // try to adjust RelDataType","[{'comment': ""What's this change for ?\r\nDo we have a test ?"", 'commenter': 'jinxing64'}, {'comment': 'Can we doc the change ?', 'commenter': 'jinxing64'}, {'comment': ""> What's this change for ?\r\n> Do we have a test ?\r\n\r\n@jinxing64 Thanks for you review, this change is used for adjusting RelDataType.\r\nSuch as  `java.lang.string` and  `VARCHAR`. Left comment in jira yesterday, Maybe we can discuss it in [jira](https://issues.apache.org/jira/browse/CALCITE-3644)"", 'commenter': 'xy2953396112'}]"
1704,core/src/main/java/org/apache/calcite/plan/RelOptMaterializations.java,"@@ -201,6 +202,7 @@
             .addRuleInstance(ProjectMergeRule.INSTANCE)
             .addRuleInstance(ProjectRemoveRule.INSTANCE)
             .addRuleInstance(ProjectJoinTransposeRule.INSTANCE)
+            .addRuleInstance(ProjectSetOpTransposeRule.INSTANCE)","[{'comment': '+1 for this change.', 'commenter': 'jinxing64'}]"
1704,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1621,8 +1621,31 @@ public UnifyResult apply(UnifyRuleCall call) {
             }
           }
         }
+
+        // try to adjust RelDataType
+        List<RexNode> projectExprs = new ArrayList<>();","[{'comment': 'Use `final` ?', 'commenter': 'jinxing64'}, {'comment': 'Thanks for you review.  create `createProjects` to adjust RelDataType.', 'commenter': 'xy2953396112'}]"
1704,core/src/main/java/org/apache/calcite/rel/mutable/MutableRels.java,"@@ -173,6 +173,23 @@ public RexNode get(int index) {
         .collect(Collectors.toList());
   }
 
+  /**
+   * Construct expression list of Project by the given fields of the input.
+   */
+  public static List<RexNode> createProjects(final MutableRel child,
+      final List<RexNode> projs) {","[{'comment': 'What does it do?\r\nIs it really a public API?\r\n\r\nWhat if I pass `+($0, 1)` as a project expression what would it do?', 'commenter': 'vlsi'}]"
1704,core/src/main/java/org/apache/calcite/rel/mutable/MutableRels.java,"@@ -173,6 +173,23 @@ public RexNode get(int index) {
         .collect(Collectors.toList());
   }
 
+  /**
+   * Construct expression list of Project by the given fields of the input.
+   */
+  public static List<RexNode> createProjects(final MutableRel child,
+      final List<RexNode> projs) {
+    List<RexNode> rexNodeList = new ArrayList<>();
+    for (int i = 0; i < projs.size(); i++) {
+      if (projs.get(i) instanceof RexInputRef) {
+        RexInputRef rexInputRef = (RexInputRef) projs.get(i);
+        rexNodeList.add(RexInputRef.of(rexInputRef.getIndex(), child.rowType));
+      } else {","[{'comment': 'What if `RexInputRef` is located inside a `RexCall`?', 'commenter': 'vlsi'}]"
1704,core/src/main/java/org/apache/calcite/rel/mutable/MutableRels.java,"@@ -173,6 +173,23 @@ public RexNode get(int index) {
         .collect(Collectors.toList());
   }
 
+  /**
+   * Construct expression list of Project by the given fields of the input.
+   */","[{'comment': 'Seems this method only converts the row type for `RexInputRef`, why this is taken into consideration specially ?\r\nBTW I can pass the test you provided in MaterializationTest.java without this change.', 'commenter': 'jinxing64'}]"
1766,core/src/main/java/org/apache/calcite/util/javac/CalciteCompilerArgs.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.javac;
+
+/**
+ * A <code>CalciteCompilerArgs</code> holds the arguments for a
+ * {@link org.codehaus.janino.SimpleCompiler} and its sub classes.
+ *
+ */
+public class CalciteCompilerArgs {
+
+  public static final CalciteCompilerArgs DEFAULT = new CalciteCompilerArgs();
+
+  private ClassLoader classLoader = CalciteCompilerArgs.class.getClassLoader();
+
+  public void setClassLoader(ClassLoader classLoader) {
+    if (classLoader != null) {
+      this.classLoader = classLoader;
+    }","[{'comment': 'Please, no. ""shared mutable state"" is not how Calcite is configured.\r\nIt looks like the classloader should be an extra argument to `RexExecutable` constructor or something like that', 'commenter': 'vlsi'}]"
1774,cassandra/src/main/java/org/apache/calcite/adapter/cassandra/CassandraSchema.java,"@@ -160,28 +169,57 @@ RelProtoDataType getRelDataType(String columnFamily, boolean view) {
         new SqlTypeFactoryImpl(RelDataTypeSystem.DEFAULT);
     final RelDataTypeFactory.Builder fieldInfo = typeFactory.builder();
     for (ColumnMetadata column : columns) {
-      final String columnName = column.getName();
-      final DataType type = column.getType();
-
-      // TODO: This mapping of types can be done much better
-      SqlTypeName typeName = SqlTypeName.ANY;
-      if (type == DataType.uuid() || type == DataType.timeuuid()) {
-        // We currently rely on this in CassandraFilter to detect UUID columns.
-        // That is, these fixed length literals should be unquoted in CQL.
-        typeName = SqlTypeName.CHAR;
-      } else if (type == DataType.ascii() || type == DataType.text()
-            || type == DataType.varchar()) {
-        typeName = SqlTypeName.VARCHAR;
-      } else if (type == DataType.cint() || type == DataType.varint()) {
-        typeName = SqlTypeName.INTEGER;
-      } else if (type == DataType.bigint()) {
-        typeName = SqlTypeName.BIGINT;
-      } else if (type == DataType.cdouble() || type == DataType.cfloat()
-          || type == DataType.decimal()) {
-        typeName = SqlTypeName.DOUBLE;
+      final SqlTypeName typeName =
+          CQL_TO_SQL_TYPE.lookup(column.getType().getName());
+
+      if (""ARRAY"".equals(typeName.getName())) {","[{'comment': ""Is there any reason the comparison can't be against `SqlTypeName.ARRAY`? (similar comment for other comparisons below)"", 'commenter': 'michaelmior'}, {'comment': 'Thanks Michael :) You are right, all those comparisons can be simplified and use directly `SqlTypeName`, nice catch!', 'commenter': 'asolimando'}]"
2016,core/src/main/java/org/apache/calcite/plan/Digest.java,"@@ -0,0 +1,245 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan;
+
+import org.apache.calcite.plan.hep.HepRelVertex;
+import org.apache.calcite.plan.volcano.RelSubset;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.hint.Hintable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.util.Pair;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+
+/**
+ * A short description of relational expression's type, inputs, and
+ * other properties. The digest uniquely identifies the node; another node
+ * is equivalent if and only if it has the same value.
+ *
+ * <p>Row type is part of the digest for the rare occasion that similar
+ * expressions have different types, e.g. variants of
+ * {@code Project(child=rel#1, a=null)} where a is a null INTEGER or a
+ * null VARCHAR(10). Row type is represented as fieldTypes only, so {@code RelNode}
+ * that differ with field names only are treated equal.
+ * For instance, {@code Project(input=rel#1,empid=$0)} and {@code Project(input=rel#1,deptno=$0)}
+ * are equal.
+ *
+ * <p>Computed by {@code org.apache.calcite.rel.AbstractRelNode#computeDigest},
+ * assigned by {@link org.apache.calcite.rel.AbstractRelNode#onRegister},
+ * returned by {@link org.apache.calcite.rel.AbstractRelNode#getDigest()}.
+ */
+public class Digest implements Comparable<Digest> {
+
+  //~ Instance fields --------------------------------------------------------
+
+  final int hashCode;
+  final List<Pair<String, Object>> items;
+  private final RelNode rel;
+
+  // Used for debugging, computed lazily.
+  private String digest = null;
+
+  //~ Constructors -----------------------------------------------------------
+
+  /**
+   * Creates a digest with given rel and properties.
+   *
+   * @param rel   The rel
+   * @param items The properties, e.g. the inputs, the type, the traits and so on
+   */
+  private Digest(RelNode rel, List<Pair<String, Object>> items) {
+    this.rel = rel;
+    this.items = normalizeContents(items);
+    this.hashCode = computeIdentity(rel, this.items);
+  }
+
+  /**
+   * Creates a digest with given rel, the digest is computed as simple,
+   * see {@link #simpleRelDigest(RelNode)}.
+   */
+  private Digest(RelNode rel) {
+    this(rel, simpleRelDigest(rel));
+  }
+
+  /** Creates a digest with given rel and string format digest. */
+  private Digest(RelNode rel, String digest) {
+    this.rel = rel;
+    this.items = Collections.emptyList();
+    this.digest = digest;
+    this.hashCode = this.digest.hashCode();
+  }
+
+  /** Returns the identity of this digest which is used to speedup hashCode and equals. */
+  private static int computeIdentity(RelNode rel, List<Pair<String, Object>> contents) {
+    return Objects.hash(collect(rel, contents));
+  }
+
+  private static Object[] collect(RelNode rel, List<Pair<String, Object>> contents) {","[{'comment': 'This seems to be resource-consuming. Should the result is not cached in the constructor?', 'commenter': 'vlsi'}, {'comment': 'This is used to resolve the hash code conflict, which expects to be rare case,  the cache would not bring much.', 'commenter': 'danny0405'}, {'comment': '`equals` is always executed (== in case `hashCode` matches), and equals would be called multiple times in case of a hash collision, so it is worth making both equals and hashCode fast.', 'commenter': 'vlsi'}, {'comment': 'I run all the cases and there are only 8 tests that have hash conflict, i would try to promote.', 'commenter': 'danny0405'}, {'comment': 'Finally i decide to keep it as is, because the conflict is very few, i also remove the row type when computing hashcode, because row type diff for equiv node is also rare case(usually because of nullability changes).', 'commenter': 'danny0405'}]"
2016,core/src/main/java/org/apache/calcite/plan/Digest.java,"@@ -0,0 +1,269 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan;
+
+import org.apache.calcite.plan.hep.HepRelVertex;
+import org.apache.calcite.plan.volcano.RelSubset;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.hint.Hintable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.util.Pair;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+
+/**
+ * A short description of relational expression's type, inputs, and
+ * other properties. The digest uniquely identifies the node; another node
+ * is equivalent if and only if it has the same value.
+ *
+ * <p>Row type is part of the digest for the rare occasion that similar
+ * expressions have different types, e.g. variants of
+ * {@code Project(child=rel#1, a=null)} where a is a null INTEGER or a
+ * null VARCHAR(10). Row type is represented as fieldTypes only, so {@code RelNode}
+ * that differ with field names only are treated equal.
+ * For instance, {@code Project(input=rel#1,empid=$0)} and {@code Project(input=rel#1,deptno=$0)}
+ * are equal.
+ *
+ * <p>Computed by {@code org.apache.calcite.rel.AbstractRelNode#computeDigest},
+ * assigned by {@link org.apache.calcite.rel.AbstractRelNode#onRegister},
+ * returned by {@link org.apache.calcite.rel.AbstractRelNode#getDigest()}.
+ */
+public class Digest implements Comparable<Digest> {
+
+  //~ Instance fields --------------------------------------------------------
+
+  final int hashCode;
+  final List<Pair<String, Object>> items;
+  private final RelNode rel;
+
+  // Used for debugging, computed lazily.
+  private String digest = null;
+
+  //~ Constructors -----------------------------------------------------------
+
+  /**
+   * Creates a digest with given rel and properties.
+   *
+   * @param rel   The rel
+   * @param items The properties, e.g. the inputs, the type, the traits and so on
+   */
+  private Digest(RelNode rel, List<Pair<String, Object>> items) {
+    this.rel = rel;
+    this.items = normalizeContents(items);
+    this.hashCode = computeIdentity(rel, this.items);
+  }
+
+  /**
+   * Creates a digest with given rel, the digest is computed as simple,
+   * see {@link #simpleRelDigest(RelNode)}.
+   */
+  private Digest(RelNode rel) {
+    this(rel, simpleRelDigest(rel));
+  }
+
+  /** Creates a digest with given rel and string format digest. */
+  private Digest(RelNode rel, String digest) {
+    this.rel = rel;
+    this.items = Collections.emptyList();
+    this.digest = digest;
+    this.hashCode = this.digest.hashCode();
+  }
+
+  /** Returns the identity of this digest which is used to speedup hashCode and equals. */
+  private static int computeIdentity(RelNode rel, List<Pair<String, Object>> contents) {
+    return Objects.hash(collect(rel, contents, false));
+  }
+
+  /**
+   * Collects the items used for {@link #hashCode} and {@link #equals}.
+   *
+   * <p>Generally, the items used for hashCode and equals should be the same. The exception
+   * is the row type of the relational expression: the row type is needed because during
+   * planning, new equivalent rels may be produced with changed fields nullability
+   * (i.e. most of them comes from the rex simplify or constant reduction).
+   * This expects to be rare case, so the hashcode is computed without row type
+   * but when it conflicts, we compare with the row type involved(sans field names).
+   *
+   * @param rel      The rel to compute digest
+   * @param contents The rel properties should be considered in digest
+   * @param withType Whether to involve the row type
+   */
+  private static Object[] collect(
+      RelNode rel,
+      List<Pair<String, Object>> contents,
+      boolean withType) {
+    List<Object> hashCodeItems = new ArrayList<>();
+    // The type name.
+    hashCodeItems.add(rel.getRelTypeName());
+    // The traits.
+    hashCodeItems.addAll(rel.getTraitSet());
+    // The hints.
+    if (rel instanceof Hintable) {
+      hashCodeItems.addAll(((Hintable) rel).getHints());
+    }
+    if (withType) {
+      // The row type sans field names.
+      RelDataType relType = rel.getRowType();
+      if (relType.isStruct()) {
+        hashCodeItems.addAll(Pair.right(relType.getFieldList()));
+      } else {
+        // Make a decision here because
+        // some downstream projects have custom rel type which has no explicit fields.
+        hashCodeItems.add(relType);
+      }
+    }
+    // The rel node contents(e.g. the inputs or exprs).
+    hashCodeItems.addAll(contents);
+    return hashCodeItems.toArray();
+  }
+
+  /** Normalizes the rel node properties, currently, just to replace the
+   * {@link RelNode} with a simple string format digest. **/
+  private static List<Pair<String, Object>> normalizeContents(
+      List<Pair<String, Object>> items) {
+    List<Pair<String, Object>> normalized = new ArrayList<>();
+    for (Pair<String, Object> item : items) {
+      if (item.right instanceof RelNode) {
+        RelNode input = (RelNode) item.right;
+        normalized.add(Pair.of(item.left, simpleRelDigest(input)));
+      } else {
+        normalized.add(item);
+      }
+    }
+    return normalized;
+  }
+
+  /**
+   * Returns a simple string format digest.
+   *
+   * <p>There are three kinds of nodes we need to handle:
+   *
+   * <ul>
+   * <li>RelSubset: composition of class name, set id and traits;</li>
+   * <li>HepRelVertex: composition of class name and current rel id;</li>
+   * <li>Normal rel: composition of class name and id.</li>
+   * </ul>
+   *
+   * @param rel The rel
+   */
+  private static String simpleRelDigest(RelNode rel) {
+    StringBuilder digest = new StringBuilder(rel.getRelTypeName());
+    digest.append('#');
+    if (rel instanceof RelSubset) {
+      RelSubset subset = (RelSubset) rel;
+      digest.append(subset.getSetId());
+      for (RelTrait trait : subset.getTraitSet()) {
+        digest.append('.').append(trait);
+      }
+    } else if (rel instanceof HepRelVertex) {
+      digest.append(((HepRelVertex) rel).getCurrentRel().getId());
+    } else {
+      digest.append(rel.getId());
+    }
+    return digest.toString();
+  }
+
+  @Override public String toString() {
+    if (null != digest) {
+      return digest;
+    }
+    StringBuilder sb = new StringBuilder();
+    sb.append(rel.getRelTypeName());
+
+    for (RelTrait trait : rel.getTraitSet()) {
+      sb.append('.');
+      sb.append(trait.toString());
+    }
+
+    sb.append('(');
+    int j = 0;
+    for (Pair<String, Object> item : items) {
+      if (j++ > 0) {
+        sb.append(',');
+      }
+      sb.append(item.left);
+      sb.append('=');
+      sb.append(item.right);
+    }
+    sb.append(')');
+    digest = sb.toString();
+    return digest;
+  }
+
+  @Override public int compareTo(Digest other) {
+    return this.rel.getId() - other.rel.getId();","[{'comment': 'This breaks the contract that if 2 objects are equal, then the method should return 0.', 'commenter': 'laurentgo'}, {'comment': 'This is only for debugging, strictly to say, i have no idea how to compare 2 nodes that are semantically equivalent (#equals) while have different members.', 'commenter': 'danny0405'}, {'comment': ""why is Comparable needed for debugging? Right now, I don't see how debuggability can justify breaking the contract"", 'commenter': 'laurentgo'}, {'comment': 'Well, i have fixed the consistency of `#equals`.', 'commenter': 'danny0405'}, {'comment': ""Maybe it would have been simpler not to implement `Comparable`? You didn't clarify why this is needed for debugging purposes..."", 'commenter': 'laurentgo'}]"
2016,core/src/main/java/org/apache/calcite/plan/Digest.java,"@@ -0,0 +1,269 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan;
+
+import org.apache.calcite.plan.hep.HepRelVertex;
+import org.apache.calcite.plan.volcano.RelSubset;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.hint.Hintable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.util.Pair;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+
+/**
+ * A short description of relational expression's type, inputs, and
+ * other properties. The digest uniquely identifies the node; another node
+ * is equivalent if and only if it has the same value.
+ *
+ * <p>Row type is part of the digest for the rare occasion that similar
+ * expressions have different types, e.g. variants of
+ * {@code Project(child=rel#1, a=null)} where a is a null INTEGER or a
+ * null VARCHAR(10). Row type is represented as fieldTypes only, so {@code RelNode}
+ * that differ with field names only are treated equal.
+ * For instance, {@code Project(input=rel#1,empid=$0)} and {@code Project(input=rel#1,deptno=$0)}
+ * are equal.
+ *
+ * <p>Computed by {@code org.apache.calcite.rel.AbstractRelNode#computeDigest},
+ * assigned by {@link org.apache.calcite.rel.AbstractRelNode#onRegister},
+ * returned by {@link org.apache.calcite.rel.AbstractRelNode#getDigest()}.
+ */
+public class Digest implements Comparable<Digest> {
+
+  //~ Instance fields --------------------------------------------------------
+
+  final int hashCode;
+  final List<Pair<String, Object>> items;
+  private final RelNode rel;
+
+  // Used for debugging, computed lazily.
+  private String digest = null;
+
+  //~ Constructors -----------------------------------------------------------
+
+  /**
+   * Creates a digest with given rel and properties.
+   *
+   * @param rel   The rel
+   * @param items The properties, e.g. the inputs, the type, the traits and so on
+   */
+  private Digest(RelNode rel, List<Pair<String, Object>> items) {
+    this.rel = rel;
+    this.items = normalizeContents(items);
+    this.hashCode = computeIdentity(rel, this.items);
+  }
+
+  /**
+   * Creates a digest with given rel, the digest is computed as simple,
+   * see {@link #simpleRelDigest(RelNode)}.
+   */
+  private Digest(RelNode rel) {
+    this(rel, simpleRelDigest(rel));
+  }
+
+  /** Creates a digest with given rel and string format digest. */
+  private Digest(RelNode rel, String digest) {
+    this.rel = rel;
+    this.items = Collections.emptyList();
+    this.digest = digest;
+    this.hashCode = this.digest.hashCode();
+  }
+
+  /** Returns the identity of this digest which is used to speedup hashCode and equals. */
+  private static int computeIdentity(RelNode rel, List<Pair<String, Object>> contents) {
+    return Objects.hash(collect(rel, contents, false));
+  }
+
+  /**
+   * Collects the items used for {@link #hashCode} and {@link #equals}.
+   *
+   * <p>Generally, the items used for hashCode and equals should be the same. The exception
+   * is the row type of the relational expression: the row type is needed because during
+   * planning, new equivalent rels may be produced with changed fields nullability
+   * (i.e. most of them comes from the rex simplify or constant reduction).
+   * This expects to be rare case, so the hashcode is computed without row type
+   * but when it conflicts, we compare with the row type involved(sans field names).
+   *
+   * @param rel      The rel to compute digest
+   * @param contents The rel properties should be considered in digest
+   * @param withType Whether to involve the row type
+   */
+  private static Object[] collect(
+      RelNode rel,
+      List<Pair<String, Object>> contents,
+      boolean withType) {
+    List<Object> hashCodeItems = new ArrayList<>();
+    // The type name.
+    hashCodeItems.add(rel.getRelTypeName());
+    // The traits.
+    hashCodeItems.addAll(rel.getTraitSet());
+    // The hints.
+    if (rel instanceof Hintable) {
+      hashCodeItems.addAll(((Hintable) rel).getHints());
+    }
+    if (withType) {
+      // The row type sans field names.
+      RelDataType relType = rel.getRowType();
+      if (relType.isStruct()) {
+        hashCodeItems.addAll(Pair.right(relType.getFieldList()));
+      } else {
+        // Make a decision here because
+        // some downstream projects have custom rel type which has no explicit fields.
+        hashCodeItems.add(relType);
+      }
+    }
+    // The rel node contents(e.g. the inputs or exprs).
+    hashCodeItems.addAll(contents);
+    return hashCodeItems.toArray();
+  }
+
+  /** Normalizes the rel node properties, currently, just to replace the
+   * {@link RelNode} with a simple string format digest. **/
+  private static List<Pair<String, Object>> normalizeContents(
+      List<Pair<String, Object>> items) {
+    List<Pair<String, Object>> normalized = new ArrayList<>();
+    for (Pair<String, Object> item : items) {
+      if (item.right instanceof RelNode) {
+        RelNode input = (RelNode) item.right;
+        normalized.add(Pair.of(item.left, simpleRelDigest(input)));
+      } else {
+        normalized.add(item);
+      }
+    }
+    return normalized;
+  }
+
+  /**
+   * Returns a simple string format digest.
+   *
+   * <p>There are three kinds of nodes we need to handle:
+   *
+   * <ul>
+   * <li>RelSubset: composition of class name, set id and traits;</li>
+   * <li>HepRelVertex: composition of class name and current rel id;</li>
+   * <li>Normal rel: composition of class name and id.</li>
+   * </ul>
+   *
+   * @param rel The rel
+   */
+  private static String simpleRelDigest(RelNode rel) {
+    StringBuilder digest = new StringBuilder(rel.getRelTypeName());
+    digest.append('#');
+    if (rel instanceof RelSubset) {
+      RelSubset subset = (RelSubset) rel;
+      digest.append(subset.getSetId());
+      for (RelTrait trait : subset.getTraitSet()) {
+        digest.append('.').append(trait);
+      }
+    } else if (rel instanceof HepRelVertex) {
+      digest.append(((HepRelVertex) rel).getCurrentRel().getId());
+    } else {
+      digest.append(rel.getId());
+    }
+    return digest.toString();
+  }
+
+  @Override public String toString() {
+    if (null != digest) {
+      return digest;
+    }
+    StringBuilder sb = new StringBuilder();
+    sb.append(rel.getRelTypeName());
+
+    for (RelTrait trait : rel.getTraitSet()) {
+      sb.append('.');
+      sb.append(trait.toString());
+    }
+
+    sb.append('(');
+    int j = 0;
+    for (Pair<String, Object> item : items) {
+      if (j++ > 0) {
+        sb.append(',');
+      }
+      sb.append(item.left);
+      sb.append('=');
+      sb.append(item.right);
+    }
+    sb.append(')');
+    digest = sb.toString();
+    return digest;
+  }
+
+  @Override public int compareTo(Digest other) {
+    return this.rel.getId() - other.rel.getId();
+  }
+
+  @Override public boolean equals(Object o) {
+    if (this == o) {
+      return true;
+    }
+    if (o == null || getClass() != o.getClass()) {
+      return false;
+    }
+    Digest that = (Digest) o;
+    return hashCode == that.hashCode && deepEquals(that);
+  }
+
+  /**
+   * The method is used to resolve hash conflict, in current 6000+ tests, there are about 8
+   * tests with conflict, so we do not cache the hash code items in order to
+   * reduce mem consumption.
+   */
+  private boolean deepEquals(Digest other) {
+    Object[] thisItems = collect(this.rel, this.items, true);
+    Object[] thatItems = collect(other.rel, other.items, true);
+    if (thisItems.length != thatItems.length) {","[{'comment': 'The whole check + loop could be replaced with `Arrays.equals(Object[], Object[])`', 'commenter': 'laurentgo'}, {'comment': ""Sorry, i would choose current code because it's simpler."", 'commenter': 'danny0405'}, {'comment': 'are you telling that 9 lines are simpler that one line of code which is `return Arrays.equals(thisItems, thatItems)`?', 'commenter': 'laurentgo'}, {'comment': 'Did you see the code in `Arrays.equals(thisItems, thatItems)` ? Here the `thisItems` and `thatItems` are both never null.', 'commenter': 'danny0405'}, {'comment': ""Considering null checks are often optimized out by the JVM, I'm not sure that the possible extra optimization is worth the extra code you wrote..."", 'commenter': 'laurentgo'}, {'comment': ""It is often but not always, if you are not sure also, let's keep it as it is, which is also straight-forward code."", 'commenter': 'danny0405'}, {'comment': 'Sorry, I am at a loss for arguments. The original reply was that the code was simpler than `Arrays.equals(Object[], Object[])`, a standard JDK method, whereas in fact, it is basically the same code, except for the check for null, which is often suppressed by the JVM compiler (cf https://shipilev.net/jvm/anatomy-quarks/25-implicit-null-checks/) and even so has minimal impact compared to the two calls to the `#collect` method where a list is created and converted later into an array...', 'commenter': 'laurentgo'}, {'comment': 'The test here https://github.com/apache/calcite/pull/2034 shows that there is negligible performance affect with `ArrayList.toArray`, so still, i would not follow you.', 'commenter': 'danny0405'}]"
2016,core/src/main/java/org/apache/calcite/plan/Digest.java,"@@ -0,0 +1,269 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan;
+
+import org.apache.calcite.plan.hep.HepRelVertex;
+import org.apache.calcite.plan.volcano.RelSubset;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.hint.Hintable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.util.Pair;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+
+/**
+ * A short description of relational expression's type, inputs, and
+ * other properties. The digest uniquely identifies the node; another node
+ * is equivalent if and only if it has the same value.
+ *
+ * <p>Row type is part of the digest for the rare occasion that similar
+ * expressions have different types, e.g. variants of
+ * {@code Project(child=rel#1, a=null)} where a is a null INTEGER or a
+ * null VARCHAR(10). Row type is represented as fieldTypes only, so {@code RelNode}
+ * that differ with field names only are treated equal.
+ * For instance, {@code Project(input=rel#1,empid=$0)} and {@code Project(input=rel#1,deptno=$0)}
+ * are equal.
+ *
+ * <p>Computed by {@code org.apache.calcite.rel.AbstractRelNode#computeDigest},
+ * assigned by {@link org.apache.calcite.rel.AbstractRelNode#onRegister},
+ * returned by {@link org.apache.calcite.rel.AbstractRelNode#getDigest()}.
+ */
+public class Digest implements Comparable<Digest> {
+
+  //~ Instance fields --------------------------------------------------------
+
+  final int hashCode;
+  final List<Pair<String, Object>> items;
+  private final RelNode rel;
+
+  // Used for debugging, computed lazily.
+  private String digest = null;
+
+  //~ Constructors -----------------------------------------------------------
+
+  /**
+   * Creates a digest with given rel and properties.
+   *
+   * @param rel   The rel
+   * @param items The properties, e.g. the inputs, the type, the traits and so on
+   */
+  private Digest(RelNode rel, List<Pair<String, Object>> items) {
+    this.rel = rel;
+    this.items = normalizeContents(items);
+    this.hashCode = computeIdentity(rel, this.items);
+  }
+
+  /**
+   * Creates a digest with given rel, the digest is computed as simple,
+   * see {@link #simpleRelDigest(RelNode)}.
+   */
+  private Digest(RelNode rel) {
+    this(rel, simpleRelDigest(rel));
+  }
+
+  /** Creates a digest with given rel and string format digest. */
+  private Digest(RelNode rel, String digest) {
+    this.rel = rel;
+    this.items = Collections.emptyList();
+    this.digest = digest;
+    this.hashCode = this.digest.hashCode();
+  }
+
+  /** Returns the identity of this digest which is used to speedup hashCode and equals. */
+  private static int computeIdentity(RelNode rel, List<Pair<String, Object>> contents) {
+    return Objects.hash(collect(rel, contents, false));
+  }
+
+  /**
+   * Collects the items used for {@link #hashCode} and {@link #equals}.
+   *
+   * <p>Generally, the items used for hashCode and equals should be the same. The exception
+   * is the row type of the relational expression: the row type is needed because during
+   * planning, new equivalent rels may be produced with changed fields nullability
+   * (i.e. most of them comes from the rex simplify or constant reduction).
+   * This expects to be rare case, so the hashcode is computed without row type
+   * but when it conflicts, we compare with the row type involved(sans field names).
+   *
+   * @param rel      The rel to compute digest
+   * @param contents The rel properties should be considered in digest
+   * @param withType Whether to involve the row type
+   */
+  private static Object[] collect(
+      RelNode rel,
+      List<Pair<String, Object>> contents,
+      boolean withType) {
+    List<Object> hashCodeItems = new ArrayList<>();
+    // The type name.
+    hashCodeItems.add(rel.getRelTypeName());
+    // The traits.
+    hashCodeItems.addAll(rel.getTraitSet());
+    // The hints.
+    if (rel instanceof Hintable) {
+      hashCodeItems.addAll(((Hintable) rel).getHints());
+    }
+    if (withType) {
+      // The row type sans field names.
+      RelDataType relType = rel.getRowType();
+      if (relType.isStruct()) {
+        hashCodeItems.addAll(Pair.right(relType.getFieldList()));
+      } else {
+        // Make a decision here because
+        // some downstream projects have custom rel type which has no explicit fields.
+        hashCodeItems.add(relType);
+      }
+    }
+    // The rel node contents(e.g. the inputs or exprs).
+    hashCodeItems.addAll(contents);
+    return hashCodeItems.toArray();
+  }
+
+  /** Normalizes the rel node properties, currently, just to replace the
+   * {@link RelNode} with a simple string format digest. **/
+  private static List<Pair<String, Object>> normalizeContents(
+      List<Pair<String, Object>> items) {
+    List<Pair<String, Object>> normalized = new ArrayList<>();
+    for (Pair<String, Object> item : items) {
+      if (item.right instanceof RelNode) {
+        RelNode input = (RelNode) item.right;
+        normalized.add(Pair.of(item.left, simpleRelDigest(input)));
+      } else {
+        normalized.add(item);
+      }
+    }
+    return normalized;
+  }
+
+  /**
+   * Returns a simple string format digest.
+   *
+   * <p>There are three kinds of nodes we need to handle:
+   *
+   * <ul>
+   * <li>RelSubset: composition of class name, set id and traits;</li>
+   * <li>HepRelVertex: composition of class name and current rel id;</li>
+   * <li>Normal rel: composition of class name and id.</li>
+   * </ul>
+   *
+   * @param rel The rel
+   */
+  private static String simpleRelDigest(RelNode rel) {
+    StringBuilder digest = new StringBuilder(rel.getRelTypeName());
+    digest.append('#');
+    if (rel instanceof RelSubset) {
+      RelSubset subset = (RelSubset) rel;
+      digest.append(subset.getSetId());
+      for (RelTrait trait : subset.getTraitSet()) {
+        digest.append('.').append(trait);
+      }
+    } else if (rel instanceof HepRelVertex) {
+      digest.append(((HepRelVertex) rel).getCurrentRel().getId());
+    } else {
+      digest.append(rel.getId());
+    }
+    return digest.toString();
+  }
+
+  @Override public String toString() {
+    if (null != digest) {
+      return digest;
+    }
+    StringBuilder sb = new StringBuilder();
+    sb.append(rel.getRelTypeName());
+
+    for (RelTrait trait : rel.getTraitSet()) {
+      sb.append('.');
+      sb.append(trait.toString());
+    }
+
+    sb.append('(');
+    int j = 0;
+    for (Pair<String, Object> item : items) {
+      if (j++ > 0) {
+        sb.append(',');
+      }
+      sb.append(item.left);
+      sb.append('=');
+      sb.append(item.right);
+    }
+    sb.append(')');
+    digest = sb.toString();
+    return digest;
+  }
+
+  @Override public int compareTo(Digest other) {
+    return this.rel.getId() - other.rel.getId();
+  }
+
+  @Override public boolean equals(Object o) {
+    if (this == o) {
+      return true;
+    }
+    if (o == null || getClass() != o.getClass()) {
+      return false;
+    }
+    Digest that = (Digest) o;
+    return hashCode == that.hashCode && deepEquals(that);
+  }
+
+  /**
+   * The method is used to resolve hash conflict, in current 6000+ tests, there are about 8
+   * tests with conflict, so we do not cache the hash code items in order to
+   * reduce mem consumption.
+   */
+  private boolean deepEquals(Digest other) {
+    Object[] thisItems = collect(this.rel, this.items, true);
+    Object[] thatItems = collect(other.rel, other.items, true);
+    if (thisItems.length != thatItems.length) {
+      return false;
+    }
+    for (int i = 0; i < thisItems.length; i++) {
+      if (!Objects.equals(thisItems[i], thatItems[i])) {","[{'comment': 'should Arrays.deepEquals be used if `thisItems[i]` is an array?', 'commenter': 'laurentgo'}, {'comment': 'I checked all the rels, they all have no array attributes in the digest, even it has, the `#equals` would output `false` which does not affect the semantics. So i choose current impl.', 'commenter': 'danny0405'}, {'comment': 'for now? what about external rels?', 'commenter': 'laurentgo'}, {'comment': ""I said outputs false does not affect the semantics, then what's the problem there, i do not want to make the logic a mess just for a non-sure assumption. \r\n\r\nIf you have strong opinion, please give specific cases, only assumption makes no sense to me."", 'commenter': 'danny0405'}, {'comment': 'Yes, there has some ""ifs"" there. There are 2 assumptions here as well:\r\n- there\'s no rel node using an array as a digest field, which is true for Calcite code, and probably true for code using the library although it\'s harder to verify\r\n- even so, return false when 2 array contents are identical has no impact on the semantic.\r\n\r\nFor the first point, maybe a more opinionated choice could be to disallow arrays as digest item?\r\nFor the second point, I\'m not sure that the assumption holds: if planner cannot identify that 2 rel nodes are identical (and so collapse them), it might cause some kind of infinite loop/plan explosion where the same node is created over and over.', 'commenter': 'laurentgo'}]"
2016,core/src/main/java/org/apache/calcite/plan/Digest.java,"@@ -0,0 +1,269 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan;
+
+import org.apache.calcite.plan.hep.HepRelVertex;
+import org.apache.calcite.plan.volcano.RelSubset;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.hint.Hintable;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.util.Pair;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Objects;
+
+/**
+ * A short description of relational expression's type, inputs, and
+ * other properties. The digest uniquely identifies the node; another node
+ * is equivalent if and only if it has the same value.
+ *
+ * <p>Row type is part of the digest for the rare occasion that similar
+ * expressions have different types, e.g. variants of
+ * {@code Project(child=rel#1, a=null)} where a is a null INTEGER or a
+ * null VARCHAR(10). Row type is represented as fieldTypes only, so {@code RelNode}
+ * that differ with field names only are treated equal.
+ * For instance, {@code Project(input=rel#1,empid=$0)} and {@code Project(input=rel#1,deptno=$0)}
+ * are equal.
+ *
+ * <p>Computed by {@code org.apache.calcite.rel.AbstractRelNode#computeDigest},
+ * assigned by {@link org.apache.calcite.rel.AbstractRelNode#onRegister},
+ * returned by {@link org.apache.calcite.rel.AbstractRelNode#getDigest()}.
+ */
+public class Digest implements Comparable<Digest> {
+
+  //~ Instance fields --------------------------------------------------------
+
+  final int hashCode;
+  final List<Pair<String, Object>> items;
+  private final RelNode rel;
+
+  // Used for debugging, computed lazily.
+  private String digest = null;
+
+  //~ Constructors -----------------------------------------------------------
+
+  /**
+   * Creates a digest with given rel and properties.
+   *
+   * @param rel   The rel
+   * @param items The properties, e.g. the inputs, the type, the traits and so on
+   */
+  private Digest(RelNode rel, List<Pair<String, Object>> items) {
+    this.rel = rel;
+    this.items = normalizeContents(items);
+    this.hashCode = computeIdentity(rel, this.items);
+  }
+
+  /**
+   * Creates a digest with given rel, the digest is computed as simple,
+   * see {@link #simpleRelDigest(RelNode)}.
+   */
+  private Digest(RelNode rel) {
+    this(rel, simpleRelDigest(rel));
+  }
+
+  /** Creates a digest with given rel and string format digest. */
+  private Digest(RelNode rel, String digest) {
+    this.rel = rel;
+    this.items = Collections.emptyList();
+    this.digest = digest;
+    this.hashCode = this.digest.hashCode();
+  }
+
+  /** Returns the identity of this digest which is used to speedup hashCode and equals. */
+  private static int computeIdentity(RelNode rel, List<Pair<String, Object>> contents) {
+    return Objects.hash(collect(rel, contents, false));
+  }
+
+  /**
+   * Collects the items used for {@link #hashCode} and {@link #equals}.
+   *
+   * <p>Generally, the items used for hashCode and equals should be the same. The exception
+   * is the row type of the relational expression: the row type is needed because during
+   * planning, new equivalent rels may be produced with changed fields nullability
+   * (i.e. most of them comes from the rex simplify or constant reduction).
+   * This expects to be rare case, so the hashcode is computed without row type
+   * but when it conflicts, we compare with the row type involved(sans field names).
+   *
+   * @param rel      The rel to compute digest
+   * @param contents The rel properties should be considered in digest
+   * @param withType Whether to involve the row type
+   */
+  private static Object[] collect(
+      RelNode rel,
+      List<Pair<String, Object>> contents,
+      boolean withType) {
+    List<Object> hashCodeItems = new ArrayList<>();
+    // The type name.
+    hashCodeItems.add(rel.getRelTypeName());
+    // The traits.
+    hashCodeItems.addAll(rel.getTraitSet());
+    // The hints.
+    if (rel instanceof Hintable) {
+      hashCodeItems.addAll(((Hintable) rel).getHints());
+    }
+    if (withType) {
+      // The row type sans field names.
+      RelDataType relType = rel.getRowType();
+      if (relType.isStruct()) {
+        hashCodeItems.addAll(Pair.right(relType.getFieldList()));
+      } else {
+        // Make a decision here because
+        // some downstream projects have custom rel type which has no explicit fields.
+        hashCodeItems.add(relType);
+      }
+    }
+    // The rel node contents(e.g. the inputs or exprs).
+    hashCodeItems.addAll(contents);
+    return hashCodeItems.toArray();
+  }
+
+  /** Normalizes the rel node properties, currently, just to replace the
+   * {@link RelNode} with a simple string format digest. **/
+  private static List<Pair<String, Object>> normalizeContents(
+      List<Pair<String, Object>> items) {
+    List<Pair<String, Object>> normalized = new ArrayList<>();
+    for (Pair<String, Object> item : items) {
+      if (item.right instanceof RelNode) {
+        RelNode input = (RelNode) item.right;
+        normalized.add(Pair.of(item.left, simpleRelDigest(input)));
+      } else {
+        normalized.add(item);
+      }
+    }
+    return normalized;
+  }
+
+  /**
+   * Returns a simple string format digest.
+   *
+   * <p>There are three kinds of nodes we need to handle:
+   *
+   * <ul>
+   * <li>RelSubset: composition of class name, set id and traits;</li>
+   * <li>HepRelVertex: composition of class name and current rel id;</li>
+   * <li>Normal rel: composition of class name and id.</li>
+   * </ul>
+   *
+   * @param rel The rel
+   */
+  private static String simpleRelDigest(RelNode rel) {
+    StringBuilder digest = new StringBuilder(rel.getRelTypeName());
+    digest.append('#');
+    if (rel instanceof RelSubset) {","[{'comment': 'Why not let the `rel` node itself handle how to create the digest vs having a non-extendable/overridable method using different behaviors based on the type of `rel` to do it? This looks like an anti design pattern.', 'commenter': 'laurentgo'}, {'comment': 'For current impl, the digest **is** handled by each `rel` node. Split the code everywhere is hard to maintain, let the `Digest` take care how the digest should be generated but the invoker is still each node.', 'commenter': 'danny0405'}, {'comment': 'Considering that method, the digest takes care how the digest should be generated for nodes it already knows about. Based on the current approach, if I create a new RelNode subclass in my project which has a very natural/efficient way of creating a digest, I would have no choice than to fork the Calcite project to modify that method.\r\nI would favor an approach which would let `HepRelVertex` itself decides what to use for its digest instead of hardcoding in this method that the current rel should be chosen.', 'commenter': 'laurentgo'}, {'comment': ""> RelNode subclass in my project which has a very natural/efficient way of creating a digest, I would have no choice than to fork the Calcite project to modify that method\r\n\r\nDid you notice that the `#computeDigest` and `#explainTerms` are both `API` for overriding the digest ?\r\n\r\n`HepRelVertex` is not a public API, i don't think there is necessity to customize its digest, if you have a sub-class, override the `#computeDigest` is till feasible."", 'commenter': 'danny0405'}, {'comment': 'why not using the `#computeDigest` with the vertex id then?\r\n\r\nAlso it is not possible to ""substract"" to the default digest. One can only add. The patch you proposed has some behavior which is not possible to change', 'commenter': 'laurentgo'}, {'comment': 'The current patch also supports pure string digest, which is same as before, if you think it is impossible, please give an example.\r\n\r\nThe digest of `HepRelVertex` and `RelSubSet` are the same as before, what do you mean by `using the #computeDigest with the vertex id then` ?', 'commenter': 'danny0405'}, {'comment': ""I guess I missed some update to your change (or missed the second constructor), but it looks like the choice is either:\r\n- provide rel + a list of extra items, and the logic to create the hashcode + digest is totally controlled by the digest class\r\n- provide rel + digest string to skip the whole hash computation logic\r\n\r\nI guess nothing in-between...\r\n\r\n> The digest of HepRelVertex and RelSubSet are the same as before, what do you mean by using the #computeDigest with the vertex id then ?\r\nIt's back to my comment about having the logic hardcoded into a single private static method which goes against OOP practices whereas instructing `HelpRexVertex` and `RelSubSet` instructing digest that the only field to consider for digest should be `id`"", 'commenter': 'laurentgo'}]"
2021,core/src/main/java/org/apache/calcite/rel/externalize/RelJson.java,"@@ -271,7 +271,9 @@ public RelDataType toType(RelDataTypeFactory typeFactory, Object o) {
 
   public Object toJson(AggregateCall node) {
     final Map<String, Object> map = jsonBuilder.map();
-    map.put(""agg"", toJson(node.getAggregation()));
+    Map<String, Object> aggMap = new HashMap(toJson(node.getAggregation()));
+    aggMap.put(""class"", node.getAggregation().getClass().getName());","[{'comment': ""Where is this `class` attribute used? It doesn't seem to be in [`RelJsonWriter#toAggCall`](https://github.com/apache/calcite/blob/e7d8d86dd3ab971921f5122de6c95868dec8739c/core/src/main/java/org/apache/calcite/rel/externalize/RelJsonReader.java#L278)."", 'commenter': 'michaelmior'}, {'comment': ""Thank you for your comments. This is a problem of lack of class information during udaf serialization. When we deserialize udaf, we will try to load udaf function through class attribute[1].If we can't load SqlAggregateFunction correctly, there will be an exception when creating AggregateCall.\r\n[1][RelJson#toOp](https://github.com/apache/calcite/blob/master/core/src/main/java/org/apache/calcite/rel/externalize/RelJson.java#L680)\r\n"", 'commenter': 'xy2953396112'}, {'comment': 'why new a map here, is it OK to do like this?\r\n```\r\nfinal Map<String, Object> aggMap = toJson(node.getAggregation());\r\naggMap.put(""class"", node.getAggregation().getClass().getName());\r\n```\r\nAnd you only need to add class info for UDAF, for system aggregate function, you do not need to add class info in the map.', 'commenter': 'yanlin-Lynn'}, {'comment': 'Thanks for review. ', 'commenter': 'xy2953396112'}]"
2021,core/src/test/java/org/apache/calcite/plan/RelWriterTest.java,"@@ -146,8 +147,9 @@
       + ""        {\n""
       + ""          \""agg\"": {\n""
       + ""            \""name\"": \""COUNT\"",\n""
-      + ""            \""kind\"": \""COUNT\"",\n""
-      + ""            \""syntax\"": \""FUNCTION_STAR\""\n""
+      + ""            \""syntax\"": \""FUNCTION_STAR\"",\n""
+      + ""            \""class\"": \""org.apache.calcite.sql.fun.SqlCountAggFunction\"",\n""
+      + ""            \""kind\"": \""COUNT\""\n""","[{'comment': ""I don't think class info is needed for system aggregate function"", 'commenter': 'yanlin-Lynn'}, {'comment': 'You are right. Code has been updated.\r\n\r\n', 'commenter': 'xy2953396112'}]"
2021,core/src/test/java/org/apache/calcite/test/MockSqlOperatorTable.java,"@@ -125,6 +125,18 @@ public RelDataType inferReturnType(SqlOperatorBinding opBinding) {
     }
   }
 
+  /** ""MYAGGFUNC"" user-defined aggregate function. This agg function accept one or more arguments
+   * in order to reproduce the throws of CALCITE-3929. */
+  public static class MyAggFunc extends SqlAggFunction {","[{'comment': 'extends `SqlUserDefinedAggFunction` might be better for your case', 'commenter': 'yanlin-Lynn'}, {'comment': ""@yanlin-Lynn\r\nThanks, `SqlUserDefinedAggFunction`  has an AggregateFunction argument, it's not convenient for reproduce this case.So it's better to extends SqlAggFunction and define it as a user-defined function.\r\n\r\n\r\n\r\n"", 'commenter': 'xy2953396112'}]"
2123,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -100,14 +106,27 @@ public ElasticsearchSchemaFactory() {
   /**
    * Builds elastic rest client from user configuration
    * @param hosts list of ES HTTP Hosts to connect to
+   * @param jdbcUser the username of ES
+   * @param jdbcPassword the password of ES
    * @return newly initialized low-level rest http client for ES
    */
-  private static RestClient connect(List<HttpHost> hosts, String pathPrefix) {
+  private static RestClient connect(List<HttpHost> hosts, String pathPrefix, String jdbcUser,
+                                    String jdbcPassword) {
 
     Objects.requireNonNull(hosts, ""hosts or coordinates"");
     Preconditions.checkArgument(!hosts.isEmpty(), ""no ES hosts specified"");
 
     RestClientBuilder builder = RestClient.builder(hosts.toArray(new HttpHost[hosts.size()]));
+
+    if (jdbcUser != null && !jdbcUser.isEmpty()
+        && jdbcPassword != null && !jdbcPassword.isEmpty()) {","[{'comment': 'you can use `Strings.isNullOrEmpty()`', 'commenter': 'danny0405'}]"
2123,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -100,14 +106,27 @@ public ElasticsearchSchemaFactory() {
   /**
    * Builds elastic rest client from user configuration
    * @param hosts list of ES HTTP Hosts to connect to
+   * @param jdbcUser the username of ES
+   * @param jdbcPassword the password of ES
    * @return newly initialized low-level rest http client for ES
    */
-  private static RestClient connect(List<HttpHost> hosts, String pathPrefix) {
+  private static RestClient connect(List<HttpHost> hosts, String pathPrefix, String jdbcUser,
+                                    String jdbcPassword) {","[{'comment': 'Fix the indentation. Is it easy to add a test case there ?', 'commenter': 'danny0405'}, {'comment': 'I don\'t know where to find the specification. Could you tell me where it is? \r\nI guess:\r\n```java\r\n  private static RestClient connect(List<HttpHost> hosts, String pathPrefix,\r\n                                    String jdbcUser, String jdbcPassword) {\r\n```\r\nI add a new class in test package. And I think I should add `@Disabled` to prevent it execute in build.\r\n```java\r\npackage org.apache.calcite.adapter.elasticsearch;\r\n\r\nimport org.junit.jupiter.api.Disabled;\r\nimport org.junit.jupiter.api.Test;\r\n\r\nimport java.sql.Connection;\r\nimport java.sql.DriverManager;\r\nimport java.sql.ResultSet;\r\nimport java.sql.SQLException;\r\nimport java.sql.Statement;\r\n\r\nimport static org.junit.jupiter.api.Assertions.assertEquals;\r\n\r\n/**\r\n * Testing Elasticsearch Authentication.\r\n */\r\n@Disabled(""need a elasticsearch cluster"")\r\npublic class AuthenticationTest {\r\n\r\n  /**\r\n   * You need specify jdbcUser/jdbcPassword in elasticsearch.json\r\n   */\r\n  @Test void select1() throws ClassNotFoundException, SQLException {\r\n    Class.forName(""org.apache.calcite.jdbc.Driver"");\r\n\r\n    try (Connection con = DriverManager\r\n        .getConnection(""jdbc:calcite:model=src/test/resources/elasticsearch.json"")) {\r\n      try (Statement stmt = con.createStatement()) {\r\n        String sql = ""select 1"";\r\n        try (ResultSet rs = stmt.executeQuery(sql)) {\r\n          if (rs.next()) {\r\n            assertEquals(rs.getObject(1), 1);\r\n          }\r\n        }\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n```json\r\n{\r\n  ""version"": ""1.0"",\r\n  ""defaultSchema"": ""elasticsearch"",\r\n  ""schemas"": [\r\n    {\r\n      ""type"": ""custom"",\r\n      ""name"": ""elasticsearch"",\r\n      ""factory"": ""org.apache.calcite.adapter.elasticsearch.ElasticsearchSchemaFactory"",\r\n      ""operand"": {\r\n        ""jdbcUser"": ""elastic"",\r\n        ""jdbcPassword"": ""elastic"",\r\n        ""coordinates"": ""{\'127.0.0.1\': 9200}""\r\n      }\r\n    }\r\n  ]\r\n}\r\n```', 'commenter': 'fageiguanbing'}]"
2123,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -88,7 +92,9 @@ public ElasticsearchSchemaFactory() {
       }
       final String pathPrefix = (String) map.get(""pathPrefix"");
       // create client
-      final RestClient client = connect(hosts, pathPrefix);
+      String jdbcUser = (String) map.get(""jdbcUser"");
+      String jdbcPassword = (String) map.get(""jdbcPassword"");
+      final RestClient client = connect(hosts, pathPrefix, jdbcUser, jdbcPassword);","[{'comment': 'Given that this refers to the username and password for Elasticsearch and is not directly related to JDBC, this should be changed to `username` and `password`.', 'commenter': 'michaelmior'}]"
2148,core/src/test/java/org/apache/calcite/materialize/NormalizationTrimFieldTest.java,"@@ -105,4 +107,25 @@
     final String relOptimizedStr = RelOptUtil.toString(relOptimized.get(0).getKey());
     assertThat(isLinux(optimized).matches(relOptimizedStr), is(true));
   }
+
+  @Test void testAggregateRelMdColumnOrigins() {
+    final RelBuilder relBuilder = RelBuilder.create(config().build());
+    final LogicalProject project = (LogicalProject) relBuilder.scan(""EMP"")
+        .project(relBuilder.field(""EMPNO""),
+            relBuilder.field(""ENAME""),
+            relBuilder.field(""JOB""),
+            relBuilder.field(""SAL""),
+            relBuilder.field(""DEPTNO"")).build();
+    final LogicalAggregate aggregate = (LogicalAggregate) relBuilder.push(project)
+        .aggregate(
+            relBuilder.groupKey(relBuilder.field(1, 0, ""DEPTNO"")),
+            relBuilder.count(relBuilder.field(1, 0, ""SAL"")))
+        .build();
+    RelMetadataQuery mq = aggregate.getCluster().getMetadataQuery();
+    final RelColumnOrigin nameColumn = mq.getColumnOrigin(aggregate, 0);
+    assertThat(nameColumn.getOriginTable().getRowType().
+        getFieldNames().get(7).equals(""DEPTNO""), is(true));
+    assertThat(nameColumn.getOriginColumnOrdinal() == 7, is(true));","[{'comment': 'Please, avoid `assertThat(..., is(true))` pattern because it results in very hard to understand test failures (... expected true got false).\r\n\r\nThe test failure message should be understandable without looking into the source code and/or JIRA.', 'commenter': 'vlsi'}, {'comment': 'Thanks, update the code.', 'commenter': 'xy2953396112'}]"
2148,core/src/test/java/org/apache/calcite/materialize/NormalizationTrimFieldTest.java,"@@ -105,4 +108,25 @@
     final String relOptimizedStr = RelOptUtil.toString(relOptimized.get(0).getKey());
     assertThat(isLinux(optimized).matches(relOptimizedStr), is(true));
   }
+
+  @Test void testAggregateRelMdColumnOrigins() {
+    final RelBuilder relBuilder = RelBuilder.create(config().build());
+    final LogicalProject project = (LogicalProject) relBuilder.scan(""EMP"")
+        .project(relBuilder.field(""EMPNO""),
+            relBuilder.field(""ENAME""),
+            relBuilder.field(""JOB""),
+            relBuilder.field(""SAL""),
+            relBuilder.field(""DEPTNO"")).build();
+    final LogicalAggregate aggregate = (LogicalAggregate) relBuilder.push(project)
+        .aggregate(
+            relBuilder.groupKey(relBuilder.field(1, 0, ""DEPTNO"")),","[{'comment': ""I think we'd better add the test case to `RelMetadataTest`."", 'commenter': 'chunweilei'}]"
2188,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1055,12 +1056,36 @@ private TrivialRule() {
       super(any(MutableRel.class), any(MutableRel.class), 0);
     }
 
-    @Override public @Nullable UnifyResult apply(UnifyRuleCall call) {
+    @Override
+    public @Nullable UnifyResult apply(UnifyRuleCall call) {
       if (call.query.equals(call.target)) {
         return call.result(call.target);
       }
+      if (isSpa(call.target) && MutableRels.descendants(call.query)
+          .containsAll(MutableRels.descendants(call.target))) {
+        return call.result(call.query);
+      }
       return null;
     }
+
+    private boolean isSpa(MutableRel rel) {","[{'comment': ""What does isSpa do? I'm not sure what Spa is in this context so it would help to have a more descriptive name."", 'commenter': 'michaelmior'}]"
2188,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1055,12 +1056,36 @@ private TrivialRule() {
       super(any(MutableRel.class), any(MutableRel.class), 0);
     }
 
-    @Override public @Nullable UnifyResult apply(UnifyRuleCall call) {
+    @Override
+    public @Nullable UnifyResult apply(UnifyRuleCall call) {
       if (call.query.equals(call.target)) {
         return call.result(call.target);
       }
+      if (isSpa(call.target) && MutableRels.descendants(call.query)
+          .containsAll(MutableRels.descendants(call.target))) {
+        return call.result(call.query);
+      }
       return null;
     }
+
+    private boolean isSpa(MutableRel rel) {
+      if (rel.getParent() != null) {
+        return false;
+      }
+      if (rel instanceof MutableCalc) {
+        MutableCalc topCalc = (MutableCalc) rel;
+        if (topCalc.getInput() instanceof MutableAggregate) {
+          MutableAggregate aggregate = (MutableAggregate) topCalc.getInput();
+          if (aggregate.getInput() instanceof MutableCalc) {
+            MutableCalc bottomCalc = (MutableCalc) aggregate.getInput();
+            if (bottomCalc.getInput() instanceof MutableScan) {
+              return true;
+            }
+          }
+        }
+      }","[{'comment': 'Instead of this deep nested if, I think it might be easier to follow if you just returned false when any of these conditions fail and then everything could be flattened.', 'commenter': 'michaelmior'}]"
2188,core/src/test/java/org/apache/calcite/test/MaterializedViewSubstitutionVisitorTest.java,"@@ -609,16 +609,16 @@
         .ok();
   }
 
-  @Test void testAggregateOnProjectAndFilter() {
+  @Test void testNoCalcOnAggregate() {","[{'comment': 'Is there any reason this existing test is removed instead of making a new one?', 'commenter': 'michaelmior'}]"
2229,site/_docs/howto.md,"@@ -990,6 +992,12 @@ address. You can use
 [the 1.20.0 announcement](https://mail-archives.apache.org/mod_mbox/www-announce/201906.mbox/%3CCA%2BEpF8tcJcZ41rVuwJODJmyRy-qAxZUQm9OxKsoDi07c2SKs_A%40mail.gmail.com%3E)
 as a template. Be sure to include a brief description of the project.
 
+Finally, increase the `calcite.version` value in `/gradle.properties` and commit & push","[{'comment': 'Give an example commit that people can cherry-pick.', 'commenter': 'julianhyde'}, {'comment': ""Remove 'finally'."", 'commenter': 'julianhyde'}, {'comment': 'Modified.', 'commenter': 'rubenada'}]"
2229,site/_docs/howto.md,"@@ -990,6 +992,12 @@ address. You can use
 [the 1.20.0 announcement](https://mail-archives.apache.org/mod_mbox/www-announce/201906.mbox/%3CCA%2BEpF8tcJcZ41rVuwJODJmyRy-qAxZUQm9OxKsoDi07c2SKs_A%40mail.gmail.com%3E)
 as a template. Be sure to include a brief description of the project.
 
+Finally, increase the `calcite.version` value in `/gradle.properties` and commit & push
+the change with the message ""Prepare for next development iteration"".
+
+Send an email to [dev@calcite.apache.org](mailto:dev@calcite.apache.org) notifying
+that `master` code freeze is over and commits can resume.","[{'comment': ""Change to 'Re-open the master branch. Send an email ...'. Documentation is clearer if you lead with the purpose/high-level action."", 'commenter': 'julianhyde'}, {'comment': 'Changed', 'commenter': 'rubenada'}]"
2229,site/_docs/howto.md,"@@ -684,8 +684,14 @@ Note: release artifacts (dist.apache.org and repository.apache.org) are managed
 
 Before you start:
 
+* Send an email to [dev@calcite.apache.org](mailto:dev@calcite.apache.org) notifying that RC build process
+  is starting and therefore `master` branch is in code freeze until further notice.
 * Set up signing keys as described above.
+* Upload your key to [https://keyserver.ubuntu.com](https://keyserver.ubuntu.com) and/or
+  [http://pool.sks-keyservers.net:11371](http://pool.sks-keyservers.net:11371) (keyservers used by Nexus).","[{'comment': ""Move the 'upload your key' to the 'set up signing keys' section. Maybe add a troubleshooting point 'If xxx happens make sure that you uploaded your key to ubuntu'."", 'commenter': 'julianhyde'}, {'comment': 'Also notice that upload the key is only needed for the first time release manager.', 'commenter': 'danny0405'}, {'comment': 'Changed.', 'commenter': 'rubenada'}]"
2229,site/_docs/howto.md,"@@ -684,8 +684,14 @@ Note: release artifacts (dist.apache.org and repository.apache.org) are managed
 
 Before you start:
 
+* Send an email to [dev@calcite.apache.org](mailto:dev@calcite.apache.org) notifying that RC build process
+  is starting and therefore `master` branch is in code freeze until further notice.
 * Set up signing keys as described above.
+* Upload your key to [https://keyserver.ubuntu.com](https://keyserver.ubuntu.com) and/or
+  [http://pool.sks-keyservers.net:11371](http://pool.sks-keyservers.net:11371) (keyservers used by Nexus).
 * Make sure you are using JDK 8 (not 9 or 10).
+* Make sure `master` branch and `site` branch are in sync, i.e. there is no commit on `site` that has not
+  been applied also to `master`. If this the case, cherry-pick the missing commit(s) into `master`.","[{'comment': ""You can check by doing something like 'git checkout site; git rebase -i master'."", 'commenter': 'julianhyde'}]"
2229,site/_docs/howto.md,"@@ -684,8 +688,13 @@ Note: release artifacts (dist.apache.org and repository.apache.org) are managed
 
 Before you start:
 
+* Send an email to [dev@calcite.apache.org](mailto:dev@calcite.apache.org) notifying that RC build process
+  is starting and therefore `master` branch is in code freeze until further notice.
 * Set up signing keys as described above.
 * Make sure you are using JDK 8 (not 9 or 10).
+* Make sure `master` branch and `site` branch are in sync, i.e. there is no commit on `site` that has not
+  been applied also to `master`. You can check by doing `git checkout site; git rebase -i master`.
+  If they are not in sync, cherry-pick the missing commit(s) into `master`.","[{'comment': '> If they are not in sync, cherry-pick the missing commit(s) into `master`.\r\n\r\nThis is exactly what `git checkout site; git rebase -i master` does, so it might be misleading to recommend `rebase -i master` and then suggest to cherry-pick.', 'commenter': 'vlsi'}, {'comment': ""You're right, I will re-phrase it."", 'commenter': 'rubenada'}, {'comment': 'It would be nice to publish documentation for all the versions (all released and the current development), then we could drop `site` branch altogether :)', 'commenter': 'vlsi'}, {'comment': 'Agree, there was a discussion about that some time ago [1], but I think no action has been taken in that direction.\r\n\r\n[1] https://lists.apache.org/thread.html/0d9829f7e32f51bc03fc350fe7c782c03dedb2ecca90e983917abf53%40%3Cdev.calcite.apache.org%3E', 'commenter': 'rubenada'}, {'comment': '@vlsi correct me if I\'m wrong. The goal of this point is to ensure that ""there is no commit on `site` that has not been applied also to `master`"", otherwise we should apply these commits (onto `master`).\r\nDoing a `git checkout site; git rebase -i master` will point the commits on `site` that are not in `master` (if any); but will not modify the `master` branch. That is why the `cherry-pick` tried to express; or am I wrong?', 'commenter': 'rubenada'}, {'comment': 'You are right. Something like `git checkout master; git reset --hard site` is required to update master to the ""new site"".', 'commenter': 'vlsi'}, {'comment': 'We need to be careful because there can be site-related commits in `master` that are not in `site`, this is ""allowed"" and we must not lose them.\r\nHaving commits in `site` that are not in `master` should not happen, but it can be possible if someone makes a (small) mistake.\r\nAll in all, I think the current phrase (`git checkout site; git rebase -i master` + `cherry-pick` any missing commits into master) might be the safest approach to achieve this without losing any master commit. wdyt?', 'commenter': 'rubenada'}, {'comment': 'AFAIK `git switch site; git rebase --empty=drop master; git switch master; git reset --hard site` should so the trick.\r\n\r\nFrankly speaking, the key problem for me was to understand the intention behind `site` vs `master` branch. The actual commands are not that hard once you understand why `site` and `master` can differ.', 'commenter': 'vlsi'}, {'comment': ""Ok, rephrased. I'll trust you on this git magic :)\r\n"", 'commenter': 'rubenada'}, {'comment': 'Oh, I guess it would be better to use `git switch site && git rebase --empty=drop master && git switch master && git reset --hard site` to avoid accidental `git reset --hard` in case one of the previous commands fail :)', 'commenter': 'vlsi'}, {'comment': 'OK, changed.', 'commenter': 'rubenada'}]"
2305,core/src/test/java/org/apache/calcite/test/TableInRootSchemaTest.java,"@@ -179,5 +185,21 @@ public RelNode toRel(RelOptTable.ToRelContext context,
         RelOptTable relOptTable) {
       return EnumerableTableScan.create(context.getCluster(), relOptTable);
     }
+
+    @Override public Expression getExpression(SchemaPlus schema, String tableName, Class clazz) {
+      try {
+        MethodCallExpression queryableExpression =
+            Expressions.call(Expressions.new_(SimpleTable.class.getConstructor()),
+                QueryableTable.class.getMethod(
+                    ""asQueryable"", QueryProvider.class, SchemaPlus.class, String.class),","[{'comment': 'Convert to a BuiltInMethod constant', 'commenter': 'julianhyde'}, {'comment': 'Thanks, used the constant from `BuiltInMethod`.', 'commenter': 'vvysotskyi'}]"
2305,core/src/test/java/org/apache/calcite/test/TableInRootSchemaTest.java,"@@ -97,7 +102,8 @@
     private Class[] columnTypes = { String.class, Integer.class };
     private Object[][] rows = new Object[3][];
 
-    SimpleTable() {
+    // CHECKSTYLE: IGNORE 1","[{'comment': 'what are we ignoring?', 'commenter': 'julianhyde'}, {'comment': 'We ignore the check for ""Redundant \'public\' modifier"", but the constructor should be public to be able to use it from the generated code. I\'ve just added a corresponding comment above this line.', 'commenter': 'vvysotskyi'}, {'comment': 'Did you try `@SuppressWarnings(""checkstyle:hideutilityclassconstructor"")` ?', 'commenter': 'vdiravka'}, {'comment': ""I wonder what changed; we were using this in tests before.\r\n\r\nI see you made `TableInRootSchemaTest` public. Maybe so that you could reference it from another test? I know that SimpleTable is referenced from a few tests already, but it's getting to be too much coupling. Better to move the sub-class into `Smalls`, or something.\r\n\r\nI also see that you are calling `Expressions.new_(Constructor)`. Maybe if you instead called `Expressions.new_(Type)` you would not need a public default constructor."", 'commenter': 'julianhyde'}, {'comment': ""In the new test, a `SimpleTable` table is returned by the table function, so it may actually not be present in the current schema. To simulate it, I've overridden `SimpleTable.getExpression()` to use table constructor directly, since the default implementation obtains it by name from the schema. So it was the change that required changing the modifier.\r\n\r\nI've moved `SimpleTable` to the `Smalls` class, also I've removed the suppression since now it is referenced from different packages, and the public modifier is legal. \r\nThanks for referring to the method that accepts type, I've used it now."", 'commenter': 'vvysotskyi'}]"
2305,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -461,6 +462,34 @@ private void addTableMacro(Connection connection, Method method) throws SQLExcep
     connection.close();
   }
 
+  @Test void testQueryableTableWithTableMacro() throws SQLException {
+    try (Connection connection =
+        DriverManager.getConnection(""jdbc:calcite:"")) {
+
+      CalciteConnection calciteConnection =
+          connection.unwrap(CalciteConnection.class);
+      SchemaPlus rootSchema = calciteConnection.getRootSchema();
+      SchemaPlus schema = rootSchema.add(""s"", new AbstractSchema());
+      schema.add(""simple"", new TableMacro() {","[{'comment': 'Consider adding to `Smalls` as a class or method. As an anonymous class, it is not clear what you are trying to achieve.', 'commenter': 'julianhyde'}, {'comment': 'Thanks, moved it there as a nested class.', 'commenter': 'vvysotskyi'}]"
2305,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -461,6 +462,34 @@ private void addTableMacro(Connection connection, Method method) throws SQLExcep
     connection.close();
   }
 
+  @Test void testQueryableTableWithTableMacro() throws SQLException {","[{'comment': 'JdbcTest is already huge. Is there a better place for this test. Say `TableFunctionTest`?', 'commenter': 'julianhyde'}, {'comment': 'Thanks, moved it to the `TableFunctionTest` class.', 'commenter': 'vvysotskyi'}]"
2305,core/src/main/java/org/apache/calcite/schema/Schemas.java,"@@ -183,6 +183,33 @@ public static Expression tableExpression(SchemaPlus schema, Type elementType,
     return EnumUtils.convert(expression, clazz);
   }
 
+  /**
+   * Generates an expression with which table can be referenced in
+   * generated code.
+   *
+   * @param schema    Schema
+   * @param tableName Table name (unique within schema)
+   * @param table     table to be referenced
+   * @param clazz     The desired collection class; for example {@code Queryable}.","[{'comment': ""`clazz` is always the class of `table`, right? It's not clear, reading the javadoc."", 'commenter': 'julianhyde'}, {'comment': 'Thanks for pointing to this, updated the comment to clarify that class may or may not be the class of the table, and added a more specific example.', 'commenter': 'vvysotskyi'}]"
2305,core/src/main/java/org/apache/calcite/prepare/RelOptTableImpl.java,"@@ -163,22 +160,7 @@ public RelOptTableImpl copy(RelDataType newRowType) {
 
   private static Function<Class, Expression> getClassExpressionFunction(","[{'comment': 'is the `getClassExpressionFunction` method now obsolete?', 'commenter': 'julianhyde'}, {'comment': 'Thanks, inlined the code and removed it.', 'commenter': 'vvysotskyi'}]"
2305,core/src/main/java/org/apache/calcite/prepare/RelOptTableImpl.java,"@@ -118,9 +115,9 @@ public static RelOptTableImpl create(
       RelDataType rowType,
       List<String> names,
       Table table,
-      Expression expression) {
+      Function<Class, Expression> expressionFunction) {","[{'comment': 'This is a breaking change to a public method. (Albeit a method that has no javadoc.) We need to keep the old method (deprecated) for compatibility.\r\n\r\nNew method needs javadoc.', 'commenter': 'julianhyde'}, {'comment': 'Added the method with the previous signature, marked it as deprecated and added JavaDoc for a new one.', 'commenter': 'vvysotskyi'}]"
2305,core/src/main/java/org/apache/calcite/prepare/RelOptTableImpl.java,"@@ -118,9 +115,9 @@ public static RelOptTableImpl create(
       RelDataType rowType,
       List<String> names,
       Table table,
-      Expression expression) {
+      Function<Class, Expression> expressionFunction) {
     return new RelOptTableImpl(schema, rowType, names, table,
-        c -> expression, table.getStatistic().getRowCount());
+        expressionFunction, table.getStatistic().getRowCount());","[{'comment': ""`expressionFunction` is not a very good abstraction. That didn't matter when it was private. But now it is public. How can we improve the abstraction?"", 'commenter': 'julianhyde'}, {'comment': ""Agree. I've introduced the `TableExpressionFactory` interface and use it instead of the previous `expressionFunction`."", 'commenter': 'vvysotskyi'}]"
2312,core/src/main/java/org/apache/calcite/sql/fun/SqlCastFunction.java,"@@ -93,6 +95,29 @@ public SqlCastFunction() {
 
   //~ Methods ----------------------------------------------------------------
 
+  @Override public void validateCall(final SqlCall call, final SqlValidator validator,
+      final SqlValidatorScope scope,
+      final SqlValidatorScope operandScope) {
+    try {
+      super.validateCall(call, validator, scope, operandScope);
+    } catch (UnsupportedOperationException ex) {
+      assert call.operandCount() == 2;","[{'comment': 'Could you please remove the assert from here?\r\nWhat is the purpose of the assert?', 'commenter': 'vlsi'}, {'comment': 'I forgot to remove the assert. This was added during development and test. \r\n\r\nI will remove it when I push the updates once the other comment is resolved.', 'commenter': 'xwkuang5'}]"
2312,core/src/main/java/org/apache/calcite/sql/fun/SqlCastFunction.java,"@@ -93,6 +95,29 @@ public SqlCastFunction() {
 
   //~ Methods ----------------------------------------------------------------
 
+  @Override public void validateCall(final SqlCall call, final SqlValidator validator,
+      final SqlValidatorScope scope,
+      final SqlValidatorScope operandScope) {
+    try {
+      super.validateCall(call, validator, scope, operandScope);
+    } catch (UnsupportedOperationException ex) {
+      assert call.operandCount() == 2;
+      throw validator.newValidationError(call,
+          RESOURCE.cannotCastToType(call.operand(1).toString()));
+    }
+  }
+
+  @Override public RelDataType deriveType(final SqlValidator validator,
+      final SqlValidatorScope scope, final SqlCall call) {
+    try {
+      return super.deriveType(validator, scope, call);
+    } catch (UnsupportedOperationException ex) {
+      assert call.operandCount() == 2;","[{'comment': 'Could you please remove the assert from here?\r\nWhat is the purpose of the assert?', 'commenter': 'vlsi'}]"
2312,core/src/main/java/org/apache/calcite/sql/fun/SqlCastFunction.java,"@@ -93,6 +95,29 @@ public SqlCastFunction() {
 
   //~ Methods ----------------------------------------------------------------
 
+  @Override public void validateCall(final SqlCall call, final SqlValidator validator,
+      final SqlValidatorScope scope,
+      final SqlValidatorScope operandScope) {
+    try {
+      super.validateCall(call, validator, scope, operandScope);
+    } catch (UnsupportedOperationException ex) {
+      assert call.operandCount() == 2;
+      throw validator.newValidationError(call,
+          RESOURCE.cannotCastToType(call.operand(1).toString()));","[{'comment': 'Should the original `UnsupportedOperationException` be kept as a `cause` of the exception?', 'commenter': 'vlsi'}, {'comment': 'no', 'commenter': 'julianhyde'}, {'comment': ""The doc string of `SqlValidatorException` [link](https://github.com/apache/calcite/blob/4d413bb21fb0a18882c5066f1d75a02d5b021bac/core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorException.java#L36) says that it is a checked exception. I'm guessing Julian is saying that wrapping `UnsupportedOperationException`, a runtime exception, in a checked exception does not make sense?"", 'commenter': 'xwkuang5'}, {'comment': ""As I said in the JIRA case, this is not an exceptional case, and UnsupportedOperationException should not be thrown anywhere along this code path.\r\n\r\nDon't approach this task with the framing 'how do we handle this exception?', but rather 'how do we make the validator do its job and clearly identify to the user types that are invalid?'."", 'commenter': 'julianhyde'}]"
2312,core/src/main/java/org/apache/calcite/sql/fun/SqlCastFunction.java,"@@ -93,6 +95,29 @@ public SqlCastFunction() {
 
   //~ Methods ----------------------------------------------------------------
 
+  @Override public void validateCall(final SqlCall call, final SqlValidator validator,
+      final SqlValidatorScope scope,
+      final SqlValidatorScope operandScope) {
+    try {
+      super.validateCall(call, validator, scope, operandScope);
+    } catch (UnsupportedOperationException ex) {
+      assert call.operandCount() == 2;
+      throw validator.newValidationError(call,
+          RESOURCE.cannotCastToType(call.operand(1).toString()));
+    }
+  }
+
+  @Override public RelDataType deriveType(final SqlValidator validator,
+      final SqlValidatorScope scope, final SqlCall call) {
+    try {
+      return super.deriveType(validator, scope, call);
+    } catch (UnsupportedOperationException ex) {
+      assert call.operandCount() == 2;
+      throw validator.newValidationError(call,
+          RESOURCE.cannotCastToType(call.operand(1).toString()));","[{'comment': 'Should the original `UnsupportedOperationException` be kept as a `cause` of the exception?', 'commenter': 'vlsi'}, {'comment': 'You are right, I think it should. \r\n\r\nHowever, I found that incorporating the cause will make this a much larger change than it is right now. Currently, `SqlValidator` interface only has a `newValidationError` method that takes an `ExInst`, which represents an exception without cause. We can add a new method `newValidationErrorWithCause` to the `SqlValidator` interface. There will need to be some refactoring for `SqlUtil.newContextException` as well. Note that hacking this by adding `initCause` to the resulting exception returned from `newValidationError` does not work because the exception has already been initialized with a cause during construction.\r\n\r\nOverall, I think this can be split into a refactoring commit + this commit. I think the combined LOC will be  >100. Not sure if the extra code added and refactoring is worth the benefit: on one hand, having the cause provides better context. On the other hand, the cast function is not that complicated `CAST(value as type)` and the current exception message might be enough for debugging.\r\n\r\nWhat do you think?', 'commenter': 'xwkuang5'}, {'comment': ""Then I'm not sure the current patch is a net win. I guess `UnsupportedOperationException` can be thrown for lots of reasons, and producing `cannotCastToType` can be misleading.\r\n\r\nIt did not expect adding a cause would require that level of refactoring, however, I agree something has to be done with `ExInst` and `ExInstWithCause`.\r\n\r\nFor instance: `ExInst withCause(Throwable)` could be added to `ExInst`.\r\nAn alternative option is probably to remove `ExInstWithCause` altogether."", 'commenter': 'vlsi'}, {'comment': 'I sent a new pull request at https://github.com/apache/calcite/pull/2326 for this. Should I close this pull request?', 'commenter': 'xwkuang5'}]"
2312,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -1212,17 +1212,15 @@ public void _testLikeAndSimilarFails() {
   }
 
   @Test void testCastRegisteredType() {
-    expr(""cast(123 as customBigInt)"")
-        .fails(""class org.apache.calcite.sql.SqlIdentifier: CUSTOMBIGINT"");
+    wholeExpr(""cast(123 as customBigInt)"")
+        .fails(""Cast function does not support casting to type `CUSTOMBIGINT`"");
     expr(""cast(123 as sales.customBigInt)"")","[{'comment': 'Instead of message `Cast function does not support casting to type`, i guess `Cast from {fromType} to {toType} is not supported` is more clear ?', 'commenter': 'danny0405'}, {'comment': 'Thanks for your review Danny. Based on the discussion in CALCITE-4265, I am not planning to move forward with this PR. Instead, I created a simpler PR at https://github.com/apache/calcite/pull/2326. Can you review that one instead? Thanks!', 'commenter': 'xwkuang5'}]"
2352,.travis.yml,"@@ -52,8 +52,8 @@ matrix:
         - GUAVA=31.0.1-jre
 branches:
   only:
-    - master
-    - new-master
+    - main
+    - new-main","[{'comment': ""I think we don't need the `new-main` branch."", 'commenter': 'F21'}]"
2352,appveyor.yml,"@@ -29,8 +29,8 @@ init:
 branches:
   # whitelist
   only:
-    - master
-    - new-master
+    - main
+    - new-main","[{'comment': ""I think we don't need the `new-main` branch here either."", 'commenter': 'F21'}]"
2352,site/community/index.md,"@@ -78,7 +78,7 @@ Need help with Calcite? Try these resources:
   your question.
 * **Browse the code**.
   One of the advantages of open source software is that you can browse the code.
-  The code is available on [github](https://github.com/apache/calcite/tree/master).
+  The code is available on [GitHub](https://github.com/apache/calcite/tree/main).
 
 # Talks","[{'comment': 'Maybe change the `https://github.com/julianhyde/share/blob/master/*` links to `https://github.com/julianhyde/share/blob/main/*` because Julian renamed his default branch to main.', 'commenter': 'F21'}]"
2363,core/src/test/java/org/apache/calcite/test/RelCostTest.java,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.test;
+
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.plan.RelOptPlanner;
+import org.apache.calcite.plan.volcano.VolcanoPlanner;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.RelRoot;
+import org.apache.calcite.rel.logical.LogicalSort;
+import org.apache.calcite.rel.metadata.DefaultRelMetadataProvider;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.util.Util;
+
+import org.junit.jupiter.api.Test;
+
+import static org.hamcrest.CoreMatchers.is;
+import static org.hamcrest.CoreMatchers.notNullValue;
+import static org.hamcrest.MatcherAssert.assertThat;
+
+/**
+ * Unit test for {@link RelOptCost}. See","[{'comment': 'Do we really have to add a new test class? ', 'commenter': 'chunweilei'}, {'comment': 'RelMetadataTest has too many method, a new class may be more clear and readable', 'commenter': 'hqx871'}, {'comment': 'It seems better to put those tests together with the original tests instead of writing a new test class, such as ` RelMetadataTest`.', 'commenter': 'xy2953396112'}, {'comment': 'I agree with @chunweilei , something like `SortCostTest` might work slightly better here, however, I have no strong preference.', 'commenter': 'vlsi'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  // ----------------------------------------------------------------------
+  // Tests for SortCpuCost
+  // ----------------------------------------------------------------------
+","[{'comment': 'Frankly speaking, I am inclined that these markers add little value, and they go out of date quite soon', 'commenter': 'vlsi'}, {'comment': 'I will remove these', 'commenter': 'hqx871'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  // ----------------------------------------------------------------------
+  // Tests for SortCpuCost
+  // ----------------------------------------------------------------------
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  private void checkCpuCost(String sql, double expected) {","[{'comment': 'Thanks for factoring out the verification function. That rocks.', 'commenter': 'vlsi'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  // ----------------------------------------------------------------------
+  // Tests for SortCpuCost
+  // ----------------------------------------------------------------------
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  private void checkCpuCost(String sql, double expected) {
+    RelNode rel = convertSql(sql);
+    assertThat(""query should be sort"", rel instanceof LogicalSort);","[{'comment': 'Please improve assertion style.\r\nThe current assert would fail like `query should be sort, expected true got false` which is not really actionable. Why `expected true`? Why `query should be sort`?\r\n\r\nI suggest the following:\r\n1) Ensure input SQL is a part of the message\r\n2) Prefer `instanceOf(LogicalSort.class)` matcher as it would display the actual input class and the desired one\r\n3) It would be a great plus if you printed the query plan in case of failure. In other words, it is with adding the full plan into the message. Then it would contain both input SQL, and the actual plan which would make CI failure analysis way easier (think of poor developers who would observe the failure after an innocent planner fix)\r\n4) As you might guess it might be expensive to compute the plan always, so JUnit5 assertion with lambdas might help here. On the other hand, three tests won\'t hurt much, so even ""compute plan always"" might be just fine\r\n\r\n\r\n\r\n\r\nPlease ensure the input SQL is a part of the error message.\r\n', 'commenter': 'vlsi'}, {'comment': 'I will remove the rel instanceof LogicalSort assert, as it seams no value here', 'commenter': 'hqx871'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  // ----------------------------------------------------------------------
+  // Tests for SortCpuCost
+  // ----------------------------------------------------------------------
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  private void checkCpuCost(String sql, double expected) {
+    RelNode rel = convertSql(sql);
+    assertThat(""query should be sort"", rel instanceof LogicalSort);
+    final RelMetadataQuery mq = rel.getCluster().getMetadataQuery();
+    RelOptPlanner planner = new VolcanoPlanner();
+    RelOptCost cost = rel.computeSelfCost(planner, mq);
+    assertThat(cost, notNullValue());","[{'comment': 'Please add a clarification message that explains why non-null value expected (like above)', 'commenter': 'vlsi'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  // ----------------------------------------------------------------------
+  // Tests for SortCpuCost
+  // ----------------------------------------------------------------------
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  private void checkCpuCost(String sql, double expected) {
+    RelNode rel = convertSql(sql);
+    assertThat(""query should be sort"", rel instanceof LogicalSort);
+    final RelMetadataQuery mq = rel.getCluster().getMetadataQuery();
+    RelOptPlanner planner = new VolcanoPlanner();
+    RelOptCost cost = rel.computeSelfCost(planner, mq);
+    assertThat(cost, notNullValue());
+    final double result = cost.getCpu();
+    assertThat(result, is(expected));","[{'comment': 'Please add a clarification message that explains why a specific value expected (like above)', 'commenter': 'vlsi'}, {'comment': 'Hi, I learned these notNullValue/is matcher from other test.  I found they will give a message by themselves.  Take the ""is"" matcher for example, when fail, the message like:\r\nExpected: is <1.0>\r\n     but: was <0.0>\r\njava.lang.AssertionError: \r\nExpected: is <1.0>\r\n     but: was <0.0>\r\nI do not find a way to add a clarification message for these matcher', 'commenter': 'hqx871'}, {'comment': 'Suppose I have never seen the test code, and I see the following failure in the CI output:\r\n\r\n```\r\nExpected: not null\r\nbut: was null\r\njava.lang.AssertionError:\r\nExpected: not null\r\nbut: was null\r\n```\r\n\r\nWhat should I do? Why ""expected not null""? Why ""was null""? What exactly was null?\r\n\r\nThe proper assertion failure should look like a good bug report rather than ""go figure out what went wrong"".\r\n\r\nBad assertions and bad test code make maintenance much harder.', 'commenter': 'vlsi'}, {'comment': '>I do not find a way to add a clarification message for these matcher\r\n\r\nPlease use `String reason` parameter: http://hamcrest.org/JavaHamcrest/javadoc/2.1/org/hamcrest/MatcherAssert.html#assertThat-java.lang.String-T-org.hamcrest.Matcher-', 'commenter': 'vlsi'}, {'comment': 'Thanks, I recall that I can use assertEquals(double expected, double actual, Supplier<String> messageSupplier), just as\r\nin previous pr you have told me.', 'commenter': 'hqx871'}]"
2363,core/src/main/java/org/apache/calcite/rel/core/Sort.java,"@@ -124,11 +125,19 @@ public abstract Sort copy(RelTraitSet traitSet, RelNode newInput,
 
   @Override public @Nullable RelOptCost computeSelfCost(RelOptPlanner planner,
       RelMetadataQuery mq) {
+    double rowCount = mq.getRowCount(this);
+    if (collation.getFieldCollations().isEmpty()) {
+      return planner.getCostFactory().makeCost(rowCount, 0, 0);
+    }
+    final int offsetValue = offset == null ? 0 : RexLiteral.intValue(offset);","[{'comment': 'Theoretically, `offset` could not be a `RexLiteral` (e.g. it could be a `RexCall` or a `RexDynamicParam`), which would lead to an `AssertionError` when calling `RexLiteral.intValue`. To be on the safe side, this should be checked before calling this function.', 'commenter': 'rubenada'}, {'comment': 'Thanks, I set offset to be 0 if the it is instance of RexDynamicParam as follow. Am I right ?\r\n     offsetValue = offset == null || offset instanceof RexDynamicParam ? 0 : RexLiteral.intValue(offset);\r\n\r\nWhen offset is a RexCall, the RexLiteral.intValue will compute the final value.\r\n', 'commenter': 'hqx871'}]"
2363,core/src/main/java/org/apache/calcite/rel/core/Sort.java,"@@ -124,11 +125,19 @@ public abstract Sort copy(RelTraitSet traitSet, RelNode newInput,
 
   @Override public @Nullable RelOptCost computeSelfCost(RelOptPlanner planner,
       RelMetadataQuery mq) {
+    double rowCount = mq.getRowCount(this);
+    if (collation.getFieldCollations().isEmpty()) {
+      return planner.getCostFactory().makeCost(rowCount, 0, 0);
+    }
+    final int offsetValue = offset == null ? 0 : RexLiteral.intValue(offset);
+    final double inCount = mq.getRowCount(input);
     // Higher cost if rows are wider discourages pushing a project through a
     // sort.
-    final double rowCount = mq.getRowCount(this);
     final double bytesPerRow = getRowType().getFieldCount() * 4;
-    final double cpu = Util.nLogN(rowCount) * bytesPerRow;
+    // When output count + offset is smaller than input count, we can use heap sort,
+    // otherwise, we can use heap sort, quick sort and so on
+    final double heapSize = Math.min(rowCount + offsetValue, inCount);","[{'comment': ""If I am not mistaken, this change could have some side-effects, e.g.  `EnumerableSort` currently does not override `computeSelfCost`, it uses `Sort`'s one.  `EnumerableSort` implements a nLogn sorting algorithm, so the current `Sort#computeSelfCost` suits better than the new proposed one. I think if we modify the formula here, then we should override `EnumerableSort#computeSelfCost` and apply the old formula there.\r\nHowever, other downstream projects with their own sort operators (which currently rely on the current formula) might be impacted as well, so this could be seen somehow as a breaking change."", 'commenter': 'rubenada'}, {'comment': 'I make a simple query and found the LogicalSort will be implemented to EnumerableLimit and EnumerableSort. The offset and fetch of  EnumerableSort will be both null, so the sort cost is still nLogN.\r\nQuery:\r\nselect * from foodmart.sales_fact_1997 order by cust_id limit 10\r\nPlan:\r\nEnumerableLimit(fetch=[10]): rowcount = 10.0, cumulative cost = {210.0 rows, 3795.1361487904733 cpu, 0.0 io}, id = 35\r\n  EnumerableSort(sort0=[$0], dir0=[ASC]): rowcount = 100.0, cumulative cost = {200.0 rows, 3785.1361487904733 cpu, 0.0 io}, id = 34\r\n    EnumerableTableScan(table=[[foodmart, sales_fact_1997]]): rowcount = 100.0, cumulative cost = {100.0 rows, 101.0 cpu, 0.0 io}, id = 20\r\n\r\nI also checked the EnumerableSort  code, as follow:\r\n\r\n  public EnumerableSort(RelOptCluster cluster, RelTraitSet traitSet,\r\n      RelNode input, RelCollation collation, @Nullable RexNode offset, @Nullable RexNode fetch) {\r\n    super(cluster, traitSet, input, collation, offset, fetch);\r\n    assert getConvention() instanceof EnumerableConvention;\r\n    assert getConvention() == input.getConvention();\r\n    assert fetch == null : ""fetch must be null"";\r\n    assert offset == null : ""offset must be null"";\r\n  }', 'commenter': 'hqx871'}, {'comment': ""Yes, you're right, the cost of EnumerableSort will effectively continue being nLogn"", 'commenter': 'rubenada'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3415,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d);
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost);
+  }
+
+  private void checkCpuCost(String sql, double expected) {
+    RelNode rel = convertSql(sql);
+    RelOptCost cost = computeRelSelfCost(rel);
+    final double result = cost.getCpu();
+    assertEquals(expected, result, () -> ""cpu cost is not as expected <""
+        + expected + "">, but <"" + result + "">, plan as follow:\n""
+        + RelOptUtil.toString(rel, SqlExplainLevel.ALL_ATTRIBUTES));","[{'comment': 'Please provide the output of the failure. Does it look like a good bug report to you?', 'commenter': 'vlsi'}, {'comment': 'hi @vlsi, could you give me an example? I am poor in English.', 'commenter': 'hqx871'}, {'comment': 'You\'ve added `...<""        + expected + "">, but <"" + result + "">...` to the exception message. However, it would make the message complicated with no extra gain.\r\n`assertEquals` would print `expected` vs `actual` on its own, so `message` parameter (which you write in the test code) *must not* include `expected vs actual`.\r\n\r\nOn the other hand, `message` parameter must explain **why** the value is expected like that.\r\n\r\nFor instance: ""sort limit exceeds table size => cost should be dominated by table size"", ""limit is 0, cost must be 0"", and so on.', 'commenter': 'vlsi'}]"
2363,core/src/main/java/org/apache/calcite/rel/core/Sort.java,"@@ -124,11 +126,20 @@ public abstract Sort copy(RelTraitSet traitSet, RelNode newInput,
 
   @Override public @Nullable RelOptCost computeSelfCost(RelOptPlanner planner,
       RelMetadataQuery mq) {
+    double rowCount = mq.getRowCount(this);
+    if (collation.getFieldCollations().isEmpty()) {
+      return planner.getCostFactory().makeCost(rowCount, 0, 0);
+    }
+    int offsetValue = offset == null || offset instanceof RexDynamicParam ? 0
+        : RexLiteral.intValue(offset);","[{'comment': '`RexLiteral.intValue` would do narrowing conversion, so it would yield negative values for values that exceed `Integer.MAX_VALUE`', 'commenter': 'vlsi'}, {'comment': 'I agree. I have try to add a RexLiteral.longValue method, but found there are too many place use RexLiteral.intValue to get offset or fetch value, such as RelMdRowCount/RelMdMinRowCount/RelMdMaxRowCount.', 'commenter': 'hqx871'}, {'comment': ""I have logged https://issues.apache.org/jira/browse/CALCITE-4531 for `intValue` deprecation.\r\nI am afraid `longValue` won't solve the problem since the value might exceed `Long.MAX_VALUE` as well."", 'commenter': 'vlsi'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost, ""offset + fetch smaller than table size ""
+        + ""=> cpu cost should be: input_size * log(offset + fetch) * row_bytes"");
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d, ""no order by clause => cpu cost should be 0"");
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d, ""fetch zero => cpu cost should be 0"");
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost, ""sort limit exceeds table size ""
+        + ""=> cpu cost should be dominated by table size"");
+  }
+
+  private void checkCpuCost(String sql, double expected, String reason) {
+    RelNode rel = convertSql(sql);
+    RelOptCost cost = computeRelSelfCost(rel);
+    final double result = cost.getCpu();
+    assertEquals(expected, result, reason);","[{'comment': 'please add `sql` and the output plan to the `reason`', 'commenter': 'vlsi'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost, ""offset + fetch smaller than table size ""
+        + ""=> cpu cost should be: input_size * log(offset + fetch) * row_bytes"");
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d, ""no order by clause => cpu cost should be 0"");
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d, ""fetch zero => cpu cost should be 0"");
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost, ""sort limit exceeds table size ""
+        + ""=> cpu cost should be dominated by table size"");
+  }
+
+  private void checkCpuCost(String sql, double expected, String reason) {
+    RelNode rel = convertSql(sql);
+    RelOptCost cost = computeRelSelfCost(rel);
+    final double result = cost.getCpu();
+    assertEquals(expected, result, reason);
+  }
+
+  private RelOptCost computeRelSelfCost(RelNode rel) {","[{'comment': '```suggestion\r\n  private static RelOptCost computeRelSelfCost(RelNode rel) {\r\n```', 'commenter': 'vlsi'}]"
2363,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -3412,4 +3414,41 @@ public String colType(RelNode rel, int column) {
     assertThat(columnOrigin.getOriginTable().getRowType().getFieldNames().get(5),
         equalTo(""SAL""));
   }
+
+  @Test void testSortCpuCostOffsetLimit() {
+    final String sql = ""select ename from emp order by ename limit 5 offset 5"";
+    double cpuCost = EMP_SIZE * Math.log(10) * 4;
+    checkCpuCost(sql, cpuCost, ""offset + fetch smaller than table size ""
+        + ""=> cpu cost should be: input_size * log(offset + fetch) * row_bytes"");
+  }
+
+  @Test void testSortCpuCostLimit() {
+    final String sql = ""select ename from emp limit 10"";
+    checkCpuCost(sql, 0d, ""no order by clause => cpu cost should be 0"");
+  }
+
+  @Test void testSortCpuCostLimit0() {
+    final String sql = ""select ename from emp order by ename limit 0"";
+    checkCpuCost(sql, 0d, ""fetch zero => cpu cost should be 0"");
+  }
+
+  @Test void testSortCpuCostLargeLimit() {
+    final String sql = ""select ename from emp order by ename limit 10000"";
+    double cpuCost = EMP_SIZE * Math.log(EMP_SIZE) * 4;
+    checkCpuCost(sql, cpuCost, ""sort limit exceeds table size ""
+        + ""=> cpu cost should be dominated by table size"");
+  }
+
+  private void checkCpuCost(String sql, double expected, String reason) {","[{'comment': '```suggestion\r\n  private static void checkCpuCost(String sql, double expected, String reason) {\r\n```', 'commenter': 'vlsi'}, {'comment': 'This method cannot make to static, becase of the convertSql\r\n```\r\n  private RelNode convertSql(String sql, boolean typeCoercion) {\r\n    final Tester tester = typeCoercion ? this.tester : this.strictTester;\r\n    return convertSql(tester, sql);\r\n  }\r\n```', 'commenter': 'hqx871'}]"
2365,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1550,6 +1552,44 @@ private AggregateOnCalcToAggregateUnifyRule() {
     }
   }
 
+  /** A {@link SubstitutionVisitor.UnifyRule} that matches a
+   * {@link org.apache.calcite.rel.core.Join} to a
+   * {@link org.apache.calcite.rel.core.Join}, provided
+   * that they have the same child. */
+  private static class JoinToJoinUnifyRule extends AbstractUnifyRule {
+    public static final JoinToJoinUnifyRule INSTANCE = new JoinToJoinUnifyRule();
+    private JoinToJoinUnifyRule() {
+      super(any(MutableJoin.class), any(MutableJoin.class), 0);
+    }
+
+    @Override protected UnifyResult apply(UnifyRuleCall call) {
+      MutableJoin query = (MutableJoin) call.query;
+      MutableJoin target = (MutableJoin) call.target;
+
+      // same join type
+      final JoinRelType joinRelType = sameJoinType(query.joinType, target.joinType);
+      if (joinRelType == null) {
+        return null;
+      }","[{'comment': 'Please move the precondition to `matches` method', 'commenter': 'vlsi'}, {'comment': 'thanks for review. If query has different `joinType` with target, the `matches` method can not judge the type of `join`.', 'commenter': 'xy2953396112'}, {'comment': 'How does that impact `matches` method?\r\n', 'commenter': 'vlsi'}, {'comment': 'The matching condition is that they have the same join type.', 'commenter': 'xy2953396112'}, {'comment': 'Please move the condition to `matches` method. I do not understand why you mark this as resolved since the issue is still there.', 'commenter': 'vlsi'}, {'comment': 'Do you mean that the usage of the precondition is same as `RelOptRule`?\r\nThe usage of the two is different here, you can refer `org.apache.calcite.plan.SubstitutionVisitor.JoinOnLeftCalcToJoinUnifyRule`.\r\n\r\n\r\n\r\n\r\n\r\n', 'commenter': 'xy2953396112'}, {'comment': ""Ah, indeed I confused `AbstractUnifyRule` with `RelOptRule`. There's no problem then"", 'commenter': 'vlsi'}]"
2365,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1550,6 +1552,44 @@ private AggregateOnCalcToAggregateUnifyRule() {
     }
   }
 
+  /** A {@link SubstitutionVisitor.UnifyRule} that matches a
+   * {@link org.apache.calcite.rel.core.Join} to a
+   * {@link org.apache.calcite.rel.core.Join}, provided
+   * that they have the same child. */
+  private static class JoinToJoinUnifyRule extends AbstractUnifyRule {
+    public static final JoinToJoinUnifyRule INSTANCE = new JoinToJoinUnifyRule();
+    private JoinToJoinUnifyRule() {
+      super(any(MutableJoin.class), any(MutableJoin.class), 0);
+    }
+
+    @Override protected UnifyResult apply(UnifyRuleCall call) {
+      MutableJoin query = (MutableJoin) call.query;
+      MutableJoin target = (MutableJoin) call.target;
+
+      // same join type
+      final JoinRelType joinRelType = sameJoinType(query.joinType, target.joinType);
+      if (joinRelType == null) {
+        return null;
+      }
+      // same child
+      if (query.getLeft().equals(target.getLeft()) && query.getRight().equals(target.getRight())) {","[{'comment': 'Should this be in `matches`?', 'commenter': 'vlsi'}, {'comment': ""It's not necessary, thx.\r\n\r\n"", 'commenter': 'xy2953396112'}]"
2365,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1550,6 +1552,43 @@ private AggregateOnCalcToAggregateUnifyRule() {
     }
   }
 
+  /** A {@link SubstitutionVisitor.UnifyRule} that matches a
+   * {@link org.apache.calcite.rel.core.Join} to a
+   * {@link org.apache.calcite.rel.core.Join}, provided
+   * that they have the same child. */
+  private static class JoinToJoinUnifyRule extends AbstractUnifyRule {
+    public static final JoinToJoinUnifyRule INSTANCE = new JoinToJoinUnifyRule();
+    private JoinToJoinUnifyRule() {
+      super(operand(MutableJoin.class, query(0)),
+          operand(MutableJoin.class, target(0)), 1);
+    }
+
+    @Override protected UnifyResult apply(UnifyRuleCall call) {
+      MutableJoin query = (MutableJoin) call.query;
+      MutableJoin target = (MutableJoin) call.target;
+
+      // same join type
+      final JoinRelType joinRelType = sameJoinType(query.joinType, target.joinType);
+      if (joinRelType == null) {
+        return null;
+      }
+      List<RexNode> queryCondition = RelOptUtil.conjunctions(query.condition);
+      List<RexNode> targetCondition = RelOptUtil.conjunctions(target.condition);
+      // same join condition
+      if (queryCondition.size() == targetCondition.size()) {
+        Set<String> queryConditionDigest = queryCondition.stream()
+            .map(rex -> rex.toString()).collect(Collectors.toSet());
+        Set<String> targetConditionDigest = targetCondition.stream()
+            .map(rex -> rex.toString()).collect(Collectors.toSet());","[{'comment': 'Please use `RexNode#equals` rather than `toString` (see https://issues.apache.org/jira/browse/CALCITE-3786)', 'commenter': 'vlsi'}, {'comment': 'ok', 'commenter': 'xy2953396112'}]"
2365,core/src/main/java/org/apache/calcite/rel/core/JoinRelType.java,"@@ -25,6 +25,7 @@
   /**
    * Inner join.
    */
+","[{'comment': 'I think that this change is unnecessary. ', 'commenter': 'aigor'}, {'comment': 'thanks', 'commenter': 'xy2953396112'}]"
2365,core/src/test/java/org/apache/calcite/materialize/NormalizationTrimFieldTest.java,"@@ -106,4 +116,38 @@
     final String relOptimizedStr = RelOptUtil.toString(relOptimized.get(0).getKey());
     assertThat(isLinux(optimized).matches(relOptimizedStr), is(true));
   }
+
+  @Test void testJoinToJoinConditionReorder() {
+    final RelBuilder relBuilder = RelBuilder.create(config().build());
+    final RelNode query =
+        relBuilder.scan(""EMP"")
+            .scan(""DEPT"")
+            .join(JoinRelType.INNER,
+                relBuilder.call(SqlStdOperatorTable.EQUALS,
+                    relBuilder.field(2, ""EMP"", ""DEPTNO""),
+                    relBuilder.field(2, ""DEPT"", ""DEPTNO"")),
+                relBuilder.call(SqlStdOperatorTable.EQUALS,
+                    relBuilder.field(2, ""EMP"", ""ENAME""),
+                    relBuilder.field(2, ""DEPT"", ""DNAME""))).project(relBuilder.field(0)).build();
+
+    final RelNode target =
+        relBuilder.scan(""EMP"")
+            .scan(""DEPT"")
+            .join(JoinRelType.INNER,
+                relBuilder.call(SqlStdOperatorTable.EQUALS,
+                    relBuilder.field(2, ""EMP"", ""ENAME""),
+                    relBuilder.field(2, ""DEPT"", ""DNAME"")),
+                relBuilder.call(SqlStdOperatorTable.EQUALS,
+                    relBuilder.field(2, ""EMP"", ""DEPTNO""),
+                    relBuilder.field(2, ""DEPT"", ""DEPTNO""))).project(relBuilder.field(0)).build();
+
+    final RelNode replacement = relBuilder.scan(""mv1"").build();
+    final List<RelNode> relOptimized = new SubstitutionVisitor(target, query).go(replacement);
+
+    final String optimized = """"
+        + ""LogicalTableScan(table=[[mv1]])\n"";
+    final String relOptimizedStr = RelOptUtil.toString(relOptimized.get(0));
+    assertThat(isLinux(optimized).matches(relOptimizedStr), is(true));","[{'comment': 'Please use `reason` message and matcher appropriately so the failure stacktrace explains the nature of the faile', 'commenter': 'vlsi'}, {'comment': 'Just for the reference, `Matcher#matches` is in the list of forbidden signatures to avoid its accidental use :)', 'commenter': 'vlsi'}]"
2365,core/src/main/java/org/apache/calcite/plan/SubstitutionVisitor.java,"@@ -1550,6 +1552,41 @@ private AggregateOnCalcToAggregateUnifyRule() {
     }
   }
 
+  /** A {@link SubstitutionVisitor.UnifyRule} that matches a
+   * {@link org.apache.calcite.rel.core.Join} to a
+   * {@link org.apache.calcite.rel.core.Join}, provided
+   * that they have the same child. */
+  private static class JoinToJoinUnifyRule extends AbstractUnifyRule {
+    public static final JoinToJoinUnifyRule INSTANCE = new JoinToJoinUnifyRule();
+    private JoinToJoinUnifyRule() {
+      super(operand(MutableJoin.class, query(0)),
+          operand(MutableJoin.class, target(0)), 1);
+    }
+
+    @Override protected @Nullable UnifyResult apply(UnifyRuleCall call) {
+      MutableJoin query = (MutableJoin) call.query;
+      MutableJoin target = (MutableJoin) call.target;
+
+      // same join type
+      final JoinRelType joinRelType = sameJoinType(query.joinType, target.joinType);
+      if (joinRelType == null) {
+        return null;
+      }
+      List<RexNode> queryCondition = RelOptUtil.conjunctions(query.condition);
+      List<RexNode> targetCondition = RelOptUtil.conjunctions(target.condition);
+      // same join condition
+      if (queryCondition.size() == targetCondition.size()) {
+        Set<RexNode> queryConditionDigest = queryCondition.stream().collect(Collectors.toSet());
+        Set<RexNode> targetConditionDigest = targetCondition.stream().collect(Collectors.toSet());","[{'comment': 'This looks suspicious.\r\n\r\nDo you think `List<RexNode> queryCondition` can contain duplicate values?\r\nDo you think `List<RexNode> targetCondition` can contain duplicate values?\r\n\r\nJust in case, I have absolutely no clue.\r\n\r\na) If duplicates are possible, then you should not compare lists by size. You need to deduplicate elements, and only then compare sets.\r\n\r\nb) If you think duplicates are not possible, then you do not need to convert the second list to set, and use `set.containsAll(list)`.\r\n\r\nIn any case, it looks like either `if size=size` should be removed or one of the sets should be removed.\r\n\r\nWDYT?', 'commenter': 'vlsi'}, {'comment': '+1 for @vlsi ', 'commenter': 'chunweilei'}]"
2365,core/src/test/java/org/apache/calcite/materialize/NormalizationTrimFieldTest.java,"@@ -106,4 +116,41 @@
     final String relOptimizedStr = RelOptUtil.toString(relOptimized.get(0).getKey());
     assertThat(isLinux(optimized).matches(relOptimizedStr), is(true));
   }
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-4391"">[CALCITE-4391]
+   * The order of join conditions is different,materialized view recognition fails</a>. */
+  @Test void testJoinToJoinConditionReorder() {
+    final RelBuilder relBuilder = RelBuilder.create(config().build());","[{'comment': 'The order of join conditions is different, materialized view recognition fails -> materialized view recognition fails when the order of join conditions is different?', 'commenter': 'chunweilei'}]"
2402,core/src/test/java/org/apache/calcite/test/ExceptionMessageTest.java,"@@ -141,4 +167,29 @@ private void runQuery(String sql) throws SQLException {
           containsString(""Object 'nonexistentTable' not found""));
     }
   }
+
+  @Test void testValidRelNodeQuery() throws SQLException {
+    final RelNode relNode = builder
+        .scan(""test"", ""entries"")
+        .project(builder.field(""name""))
+        .build();
+    runQuery(relNode);
+  }
+
+  @Test void testRelNodeQueryException() throws SQLException {
+    try {
+      final RelNode relNode = builder
+          .scan(""test"", ""entries"")
+          .project(builder.call(SqlStdOperatorTable.ABS, builder.field(""name"")))
+          .build();
+      runQuery(relNode);
+      fail(""Query badEntries should result in an exception"");
+    } catch (RuntimeException e) {
+      assertThat(e.getMessage(),
+          equalTo(""java.sql.SQLException: Error while preparing statement [\n""
+              + ""LogicalProject($f0=[ABS($1)])\n""","[{'comment': 'Hmm, the plan may be helpful but it is not a statement ?', 'commenter': 'danny0405'}, {'comment': 'Statement in Calcite may be  include three types: Sql. RelNode .  Queryable.  This method Called prepareStatement_. My be we listen to others opinion.', 'commenter': 'NobiGo'}, {'comment': 'Actually, I\'m +1 for Danny, maybe change ""statement"" to ""plan"" is better. But the code before is also ""Error while preparing statement""', 'commenter': 'Aaaaaaron'}, {'comment': 'Ok. I will change this to plan. Thanks for all of your advice.', 'commenter': 'NobiGo'}]"
2402,core/src/test/java/org/apache/calcite/test/ExceptionMessageTest.java,"@@ -141,4 +167,29 @@ private void runQuery(String sql) throws SQLException {
           containsString(""Object 'nonexistentTable' not found""));
     }
   }
+
+  @Test void testValidRelNodeQuery() throws SQLException {
+    final RelNode relNode = builder
+        .scan(""test"", ""entries"")
+        .project(builder.field(""name""))
+        .build();
+    runQuery(relNode);
+  }
+
+  @Test void testRelNodeQueryException() throws SQLException {","[{'comment': 'There are test failures in CI (Windows). Please fix the problem with the line endings; check other tests cases comparing plans.', 'commenter': 'zabetak'}, {'comment': 'Yes. I will fix this.', 'commenter': 'NobiGo'}]"
2430,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -1004,6 +1005,13 @@ public boolean supportsGroupByWithCube() {
     return false;
   }
 
+  /**
+   * Returns whether this dialect supports certain type of join in the underlying DBMS.
+   */
+  public boolean isSupportedCertainJoinType(JoinRelType certainJoinType) {","[{'comment': 'Rename to `supportsJoinType` to be uniform with the other methods in this class and the param to be simply `joinType`.', 'commenter': 'zabetak'}]"
2430,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -1004,6 +1005,13 @@ public boolean supportsGroupByWithCube() {
     return false;
   }
 
+  /**
+   * Returns whether this dialect supports certain type of join in the underlying DBMS.","[{'comment': 'Reword: ""Returns whether this dialect support the specified type of join.""', 'commenter': 'zabetak'}]"
2430,core/src/test/java/org/apache/calcite/test/JdbcAdapterTest.java,"@@ -1045,6 +1045,29 @@ private LockWrapper exclusiveCleanDb(Connection c) throws SQLException {
         .planHasSql(""SELECT \""EMPNO\"", \""ENAME\""\nFROM \""SCOTT\"".\""EMP\""\nWHERE \""EMPNO\"" = ?"");
   }
 
+  /**
+   * Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-4619"">[CALCITE-4619]
+   * ""Full join"" generates an incorrect execution plan under mysql</a>
+   */
+  @Test void testSupportedCertainJoinType() {
+    CalciteAssert.model(JdbcTest.SCOTT_MYSQL_DIALECT_MODEL)
+        .query(""select empno, ename, e.deptno, dname\n""
+            + ""from scott.emp e full join scott.dept d\n""
+            + ""on e.deptno = d.deptno"")
+        .explainContains(""PLAN=EnumerableCalc(expr#0..4=[{inputs}], proj#0..2=[{exprs}], "" +
+            ""DNAME=[$t4])\n"" +
+            ""  EnumerableHashJoin(condition=[=($2, $3)], joinType=[full])\n"" +
+            ""    JdbcToEnumerableConverter\n"" +
+            ""      JdbcProject(EMPNO=[$0], ENAME=[$1], DEPTNO=[$7])\n"" +
+            ""        JdbcTableScan(table=[[SCOTT, EMP]])\n"" +
+            ""    JdbcToEnumerableConverter\n"" +
+            ""      JdbcProject(DEPTNO=[$0], DNAME=[$1])\n"" +
+            ""        JdbcTableScan(table=[[SCOTT, DEPT]])"")
+        .enable(CalciteAssert.DB == CalciteAssert.DatabaseInstance.HSQLDB)
+        .runs();
+  }","[{'comment': 'I think it would be better to move the test in `RelToSqlConverterTest`. The class already contains dialect specific tests for MySQL and others and doing so you do not need to add `TestSqlDialectFactoryImpl` class.', 'commenter': 'zabetak'}, {'comment': 'The dialect test in RelToSqlConverterTest does not call the optimizer. Sql.exec method only parses sql into rel and regenerates the sql string according to the configured dialect. I think the joinType test should be placed in `JdbcAdapterTest`, just like the `supportsWindowFunctions`.The test case `testOverNonSupportedDialect` is placed in `JdbcAdapterTest`. WDYT?', 'commenter': 'angelzouxin'}, {'comment': 'You are right `RelToSqlConverterTest` is definitely not the right place. Thinking a bit more, would be sufficient to just change this line:\r\n`.enable(CalciteAssert.DB == CalciteAssert.DatabaseInstance.HSQLDB)`\r\nto\r\n`.enable(CalciteAssert.DB == CalciteAssert.DatabaseInstance.H2 || CalciteAssert.DB == CalciteAssert.DatabaseInstance.MYSQL)`\r\nIt is a bit inconvenient since at the moment we are not running with H2 and MySQL in CI but we can verify that it runs locally by using `calcite.test.db` property. ', 'commenter': 'zabetak'}, {'comment': 'All comments are resolved now. ', 'commenter': 'angelzouxin'}]"
2430,core/src/main/java/org/apache/calcite/sql/dialect/H2SqlDialect.java,"@@ -40,4 +41,8 @@ public H2SqlDialect(Context context) {
   @Override public boolean supportsWindowFunctions() {
     return false;
   }
+
+  @Override public boolean isSupportedCertainJoinType(JoinRelType certainJoinType) {
+    return certainJoinType != JoinRelType.FULL;
+  }","[{'comment': 'Add a test case using H2SqlDialect in `RelToSqlConverterTest`.', 'commenter': 'zabetak'}]"
2439,core/src/test/java/org/apache/calcite/test/SqlToRelTestBase.java,"@@ -585,13 +588,16 @@ protected TesterImpl(DiffRepository diffRepos) {
      * @param clusterFactory Called after a cluster has been created
      */
     protected TesterImpl(DiffRepository diffRepos, boolean enableDecorrelate,
-        boolean enableTrim, boolean enableLateDecorrelate,
+        boolean enableTrim,","[{'comment': 'is this some kind of auto style format ?', 'commenter': 'zinking'}, {'comment': 'Fixed. Keep old format of the parameters.', 'commenter': 'tledkov'}]"
2439,core/src/test/java/org/apache/calcite/test/SqlToRelTestBase.java,"@@ -603,6 +609,7 @@ protected TesterImpl(DiffRepository diffRepos, boolean enableDecorrelate,
       this.plannerFactory = Objects.requireNonNull(plannerFactory, ""plannerFactory"");
       this.conformance = Objects.requireNonNull(conformance, ""conformance"");
       this.contextTransform = Objects.requireNonNull(contextTransform, ""contextTransform"");
+      this.typeFactory = typeFactory;","[{'comment': 'I would create a overloaded version of this constructor so that the below codes remains unchanged', 'commenter': 'zinking'}, {'comment': ""Thanks for the comment. But I don't catch an idea. The methods `with<OptionName>` create new instance of the `TesterImpl`. How we can use old constructor here without specified `typeFactory` and keep the `typeFactory` from current instance? \r\n\r\nDo you suggest use the code like below?\r\n```\r\nnew TesterImpl(diffRepos, enableDecorrelate, enableTrim,\r\n          enableLateDecorrelate, enableTypeCoercion, catalogReaderFactory,\r\n          clusterFactory, plannerFactory, configTransform, conformance,\r\n          contextTransform)\r\n               .withTypeFactory(typeFactory);\r\n```\r\nIt looks ugly for me.\r\n"", 'commenter': 'tledkov'}, {'comment': 'is there a default typeFactory you can pass in at constructor ? I guess most of the places are referring to the same type factory?', 'commenter': 'zinking'}, {'comment': 'What do you propose to make it possible to customize `typeFactory` for the test?\r\n\r\nPlease provide any references to the code where old constructor with default `typeFactory` is applicable.\r\nI see only `SqlToRelTestBase#createTester`. I guess add one argument is easier than add new constructor.\r\n\r\n\r\n', 'commenter': 'tledkov'}, {'comment': 'ok', 'commenter': 'zinking'}]"
2439,core/src/main/java/org/apache/calcite/rel/rules/AggregateExpandDistinctAggregatesRule.java,"@@ -366,12 +370,18 @@ private static RelBuilder convertSingletonDistinct(RelBuilder relBuilder,
         final int arg = bottomGroups.size() + nonDistinctAggCallProcessedSoFar;
         final List<Integer> newArgs = ImmutableList.of(arg);
         if (aggCall.getAggregation().getKind() == SqlKind.COUNT) {
+          RelDataTypeFactory typeFactory = aggregate.getCluster().getTypeFactory();
+          RelDataType sumType = typeFactory.getTypeSystem().deriveSumType(typeFactory,
+              aggCall.getType());
+          needTopCast |= !sumType.equals(aggCall.getType());","[{'comment': 'running new test under debug, i found aggCall.getType() == BIGINT, while sumType == DECIMAL(19, 0) all these representation are identical as i can see, can you explain why we rise needTopCast flag in this case? Additionally i hope we need integration test highliting the bug, ServerTest possibly correct place for it. wdyt ?', 'commenter': 'zstan'}, {'comment': 'Because the transformation rule must do an equivalent transformation. So, the type of the output row must be the same as that of the original node. DECIMAL and BIGINT are different types.', 'commenter': 'tledkov'}]"
2439,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -6769,4 +6771,43 @@ private void checkJoinAssociateRuleWithTopAlwaysTrueCondition(boolean allowAlway
       relFn(relFn).with(hepPlanner).checkUnchanged();
     }
   }
+
+  /**
+   *  Test case for <a href=""https://issues.apache.org/jira/browse/CALCITE-4652"">[CALCITE-4652]
+   *  AggregateExpandDistinctAggregatesRule must cast top aggregates to original type</a>.
+   *
+   *  Checks AggregateExpandDistinctAggregatesRule when return type of the SUM aggregate","[{'comment': 'Add `<p>`. Use one leading space, not two.', 'commenter': 'julianhyde'}]"
2439,core/src/test/java/org/apache/calcite/test/SqlToRelTestBase.java,"@@ -100,6 +102,8 @@
   //~ Static fields/initializers ---------------------------------------------
 
   protected static final String NL = System.getProperty(""line.separator"");
+  protected static final Supplier<RelDataTypeFactory> DFLT_TYPE_FACTORY_SUPPLIER =","[{'comment': ""I don't see any benefit abbreviating 'DEFAULT' to 'DFLT'."", 'commenter': 'julianhyde'}]"
2439,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -6769,4 +6771,43 @@ private void checkJoinAssociateRuleWithTopAlwaysTrueCondition(boolean allowAlway
       relFn(relFn).with(hepPlanner).checkUnchanged();
     }
   }
+
+  /**
+   *  Test case for <a href=""https://issues.apache.org/jira/browse/CALCITE-4652"">[CALCITE-4652]
+   *  AggregateExpandDistinctAggregatesRule must cast top aggregates to original type</a>.
+   *
+   *  Checks AggregateExpandDistinctAggregatesRule when return type of the SUM aggregate
+   *  is changed (expanded) by define custom type factory.
+   */
+  @Test void testDistinctCountWithExpandSumType() {
+    /* Expand SUM return type. */
+    RelDataTypeFactory typeFactory = new SqlTypeFactoryImpl(new RelDataTypeSystemImpl() {","[{'comment': 'Use \'//\' not \'/*\' for comments.\r\n\r\n""Expand SUM return type"" doesn\'t adequately explain what you are doing here. You\'re creating a new type system. Say why.\r\n\r\nRather than creating a typeFactory, I\'d create a type factory supplier. I\'d assign the type system to a variable, to reduce nesting.', 'commenter': 'julianhyde'}]"
2454,core/src/main/java/org/apache/calcite/sql2rel/SqlToRelConverter.java,"@@ -4651,7 +4651,12 @@ public RexNode register(
               currentProjection);
         }
 
-        setRoot(newLeftInput, false);
+        // keep leaves property.
+        if (leaves.remove(root()) != null) {
+          setRoot(newLeftInput, true);
+        } else {
+          setRoot(newLeftInput, false);
+        }","[{'comment': 'What about compacting into this equivalent version?\r\n\r\n```suggestion\r\n        setRoot(newLeftInput, leaves.remove(root()) != null);\r\n```', 'commenter': 'asolimando'}, {'comment': 'Good, Thanks asolimando!', 'commenter': 'hannerwang'}]"
2454,core/src/main/java/org/apache/calcite/sql2rel/SqlToRelConverter.java,"@@ -4651,7 +4651,12 @@ public RexNode register(
               currentProjection);
         }
 
-        setRoot(newLeftInput, false);
+        // keep leaves property.","[{'comment': ""I don't really understand the comment, can you please elaborate more on that? I think a good explanation of what you are trying to do here is very much needed (i.e., why are we replacing the root in this specific case?)."", 'commenter': 'asolimando'}, {'comment': 'Thanks for your suggestions, the setRoot will replace old root rel by new root, but with a fixed false leaf property. If the old root is a leaf rel, the new root should be a leaf rel, otherwise, the LookupContext will search deeper rel tree leaf node, that will cause wrong field offset.', 'commenter': 'hannerwang'}]"
2454,core/src/test/java/org/apache/calcite/test/SqlToRelConverterTest.java,"@@ -3611,6 +3611,20 @@ void checkCorrelatedMapSubQuery(boolean expand) {
         .convertsTo(""${planConverted}"");
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-4683"">[CALCITE-4683]
+   * In-list to join causes field datatypes not matched</a>. */
+  @Test void testInToSemiJoinWithNewProject() {
+    // Before this bug fixed, converting the sql to rel will fail.","[{'comment': ""I'd rather drop this comment here and add the stack trace of the error in the description of the Jira ticket, it will help people understand if they are hitting the same bug as you."", 'commenter': 'asolimando'}, {'comment': 'OK, I will do that.', 'commenter': 'hannerwang'}]"
2480,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -5986,6 +5986,18 @@ private void checkLiteral2(String expression, String expected) {
         .ok(expected);
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-4724"">[CALCITE-4724]
+   * As for ClickHouse do not support values in from clause.
+   */","[{'comment': '1. the test descript should be the same as the CALCITE-4724.\r\n2. the java doc lack of end label about \\</a>', 'commenter': 'NobiGo'}, {'comment': 'Updated . \r\nAnd add two more cases in `testValues()` and `testValuesEmpty()`, please review again. tks', 'commenter': 'Enzo-Liu'}]"
2480,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -5986,6 +5997,18 @@ private void checkLiteral2(String expression, String expected) {
         .ok(expected);
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-4724"">[CALCITE-4724]
+   * ClickHouseSqlDialect `supportsAliasedValues` should return false. </a>
+   */
+  @Test void testAliasedValueForClickHouse() {
+    final String query = ""select 1"";
+    final String expected = ""SELECT 1"";
+    sql(query)
+        .withClickHouse()
+        .ok(expected);","[{'comment': 'some tips:  sql(query).withClickHouse().ok(expected);  may be better.', 'commenter': 'NobiGo'}, {'comment': 'adjusted.', 'commenter': 'Enzo-Liu'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added","[{'comment': 'The children of the RelNodes can be modified by RelNode#replaceInput, so I would prefer to rephrase it. Maybe we just remove this line?', 'commenter': 'thomasrebele'}, {'comment': ""I think we can rephrase it. Although a RelNode's children can be modified, its own properties will not change. I was mainly refering to the immutable properties of a relnode."", 'commenter': 'zuozhiw'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added
+  Map<String, RelNode> allNodes = new HashMap<>();
+
+  public VolcanoRuleMatchVisualizer(VolcanoPlanner volcanoPlanner) {
+    this.volcanoPlanner = volcanoPlanner;
+  }
+
+  public void addRuleMatch(String ruleCallID, Collection<? extends RelNode> matchedRels) {
+
+    // store the current state snapshot
+    // nodes contained in the sets
+    // and inputs of relNodes (and relSubsets)
+    Map<String, String> setLabels = new HashMap<>();
+    Map<String, String> setOriginalRel = new HashMap<>();
+    Map<String, Set<String>> nodesInSet = new HashMap<>();
+    Map<String, Set<String>> nodeInputs = new HashMap<>();
+
+    // newNodes appeared after this ruleCall
+    Set<String> newNodes = new HashSet<>();
+
+    // populate current snapshot, and fill in the allNodes map
+    volcanoPlanner.allSets.forEach(set -> {
+      String setID = ""set-"" + set.id;
+      String setLabel = getSetLabel(set);
+      setLabels.put(setID, setLabel);
+      setOriginalRel.put(setID, set.rel == null ? """" : String.valueOf(set.rel.getId()));
+
+      nodesInSet.put(setID, nodesInSet.getOrDefault(setID, new HashSet<>()));
+
+      Consumer<RelNode> addNode = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodesInSet.get(setID).add(nodeID);
+
+        if (!allNodes.containsKey(nodeID)) {
+          newNodes.add(nodeID);
+          allNodes.put(nodeID, rel);
+        }
+      };
+
+      Consumer<RelNode> addLink = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodeInputs.put(nodeID, new HashSet<>());","[{'comment': 'Assigning the new HashSet to a variable and using it below instead of nodeinputs.get(nodeId) would save a lot of lookups.', 'commenter': 'thomasrebele'}, {'comment': 'agree', 'commenter': 'zuozhiw'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added
+  Map<String, RelNode> allNodes = new HashMap<>();
+
+  public VolcanoRuleMatchVisualizer(VolcanoPlanner volcanoPlanner) {
+    this.volcanoPlanner = volcanoPlanner;
+  }
+
+  public void addRuleMatch(String ruleCallID, Collection<? extends RelNode> matchedRels) {
+
+    // store the current state snapshot
+    // nodes contained in the sets
+    // and inputs of relNodes (and relSubsets)
+    Map<String, String> setLabels = new HashMap<>();
+    Map<String, String> setOriginalRel = new HashMap<>();
+    Map<String, Set<String>> nodesInSet = new HashMap<>();
+    Map<String, Set<String>> nodeInputs = new HashMap<>();
+
+    // newNodes appeared after this ruleCall
+    Set<String> newNodes = new HashSet<>();
+
+    // populate current snapshot, and fill in the allNodes map
+    volcanoPlanner.allSets.forEach(set -> {
+      String setID = ""set-"" + set.id;
+      String setLabel = getSetLabel(set);
+      setLabels.put(setID, setLabel);
+      setOriginalRel.put(setID, set.rel == null ? """" : String.valueOf(set.rel.getId()));
+
+      nodesInSet.put(setID, nodesInSet.getOrDefault(setID, new HashSet<>()));
+
+      Consumer<RelNode> addNode = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodesInSet.get(setID).add(nodeID);
+
+        if (!allNodes.containsKey(nodeID)) {
+          newNodes.add(nodeID);
+          allNodes.put(nodeID, rel);
+        }
+      };
+
+      Consumer<RelNode> addLink = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodeInputs.put(nodeID, new HashSet<>());
+        if (rel instanceof RelSubset) {
+          RelSubset relSubset = (RelSubset) rel;
+          relSubset.getRelList().stream()
+              .filter(input -> input.getTraitSet().equals(relSubset.getTraitSet()))
+              .forEach(input -> nodeInputs.get(nodeID).add(String.valueOf(input.getId())));
+          relSubset.set.subsets.stream()
+              .filter(other -> !other.equals(relSubset))
+              .filter(other -> other.getTraitSet().satisfies(relSubset.getTraitSet()))
+              .forEach(other -> nodeInputs.get(nodeID).add(String.valueOf(other.getId())));
+        } else {
+          rel.getInputs().forEach(input -> nodeInputs.get(nodeID)
+              .add(String.valueOf(input.getId())));
+        }
+      };
+
+      set.rels.forEach(addNode);
+      set.subsets.forEach(addNode);
+      set.rels.forEach(addLink);
+      set.subsets.forEach(addLink);
+    });
+
+    // get the matched nodes of this rule
+    Set<String> matchedNodeIDs = matchedRels.stream()
+        .map(rel -> String.valueOf(rel.getId()))
+        .collect(Collectors.toSet());
+
+    // get importance 0 rels as of right now
+    Set<String> importanceZeroNodes = new HashSet<>();
+    volcanoPlanner.prunedNodes
+        .forEach(rel -> importanceZeroNodes.add(Integer.toString(rel.getId())));
+
+    VisualizerRuleMatchInfo ruleMatchInfo =
+        new VisualizerRuleMatchInfo(setLabels, setOriginalRel, nodesInSet,
+            nodeInputs, matchedNodeIDs, newNodes, importanceZeroNodes);
+
+    ruleMatchSequence.add(ruleCallID);
+    ruleInfoMap.put(ruleCallID, ruleMatchInfo);
+
+    newNodes.forEach(newNode -> nodeAddedInRule.put(newNode, ruleCallID));
+  }
+
+  /**
+   * Add a final plan to the variable.
+   */
+  public void addFinalPlan() {
+    assert !ruleMatchSequence.contains(""FINAL"");
+
+    Set<RelNode> finalPlanNodes = new HashSet<>();
+    Deque<RelSubset> subsetsToVisit = new LinkedList<>();
+    subsetsToVisit.add((RelSubset) volcanoPlanner.getRoot());
+
+    RelSubset subset;
+    while ((subset = subsetsToVisit.poll()) != null) {
+      // add subset itself to the highlight list
+      finalPlanNodes.add(subset);
+      // highlight its best node if it exists
+      RelNode best = subset.getBest();
+      if (best == null) {
+        continue;
+      }
+      finalPlanNodes.add(best);
+      // recursively visit the input relSubsets of the best node
+      best.getInputs().stream().map(rel -> (RelSubset) rel).forEach(subsetsToVisit::add);
+    }
+
+    this.addRuleMatch(""FINAL"", new ArrayList<>(finalPlanNodes));
+  }
+
+  private String getSetLabel(RelSet set) {
+    return ""set-"" + set.id + ""    "";
+  }
+
+  private String getJsonStringResult() {
+    try {
+      Map<String, VisualizerNodeInfo> nodeInfoMap = new HashMap<>();
+      for (String nodeID : allNodes.keySet()) {
+        RelNode relNode = allNodes.get(nodeID);
+        RelNode root = volcanoPlanner.getRoot();
+        if (root == null) {
+          throw new RuntimeException(""volcano planner root is null"");
+        }
+        RelOptCluster cluster = root.getCluster();
+        RelOptCost cost = volcanoPlanner.getCost(relNode, cluster.getMetadataQuery());
+        Double rowCount =
+            relNode.getCluster().getMetadataQuery().getRowCount(relNode);
+
+        VisualizerNodeInfo nodeInfo;
+        if (relNode instanceof RelSubset) {
+          RelSubset relSubset = (RelSubset) relNode;
+          String nodeLabel = ""subset#"" + relSubset.getId() + ""-set#"" + relSubset.set.id + ""-\n""
+              + relSubset.getTraitSet().toString();
+          String relIDs = relSubset.getRelList().stream()
+              .map(i -> ""#"" + i.getId()).collect(joining("", ""));
+          String explanation = ""rels: ["" + relIDs + ""]"";
+          nodeInfo =
+              new VisualizerNodeInfo(nodeLabel, true, explanation, cost, rowCount);
+        } else {
+          InputExcludedRelWriter relWriter = new InputExcludedRelWriter();
+          relNode.explain(relWriter);
+          String inputIDs = relNode.getInputs().stream()
+              .map(i -> ""#"" + i.getId()).collect(joining("", ""));
+          String explanation = relWriter.toString() + "", inputs: ["" + inputIDs + ""]"";
+
+          String nodeLabel = ""#"" + relNode.getId() + ""-"" + relNode.getRelTypeName();
+          nodeInfo = new VisualizerNodeInfo(nodeLabel, false, explanation, cost,
+              rowCount);
+        }
+
+        nodeInfoMap.put(nodeID, nodeInfo);
+      }
+
+      HashMap<String, Object> data = new HashMap<>();
+      data.put(""allNodes"", nodeInfoMap);
+      data.put(""ruleMatchSequence"", ruleMatchSequence);
+      data.put(""ruleMatchInfoMap"", ruleInfoMap);
+      data.put(""nodeAddedInRule"", nodeAddedInRule);
+
+      ObjectMapper objectMapper = new ObjectMapper();
+      return objectMapper.writeValueAsString(data);
+    } catch (JsonProcessingException e) {
+      throw new RuntimeException(e);
+    }
+  }
+
+  /**
+   * Writes the HTML and JS files of the rule match visualization.
+   * <p>
+   * The old files with the same name will be replaced.
+   *
+   * @param outputDirectory directory of the output files
+   * @param suffix          file name suffix, can be null
+   */
+  public void writeToFile(String outputDirectory, String suffix) {
+    // default HTML template is under ""resources""
+    writeToFile(""volcano-viz"", outputDirectory, suffix);
+  }
+
+  public void writeToFile(String templateDirectory, String outputDirectory, String suffix) {
+    try {
+      String templatePath = Paths.get(templateDirectory).resolve(""viz-template.html"").toString();
+      String htmlTemplate = IOUtils.toString(getClass().getResourceAsStream(templatePath),","[{'comment': 'Calling getClass().getResourceAsStream(...) tries to access a wrong path, while getClass().getClassLoader().getResourceAsStream() seems to work.', 'commenter': 'thomasrebele'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added
+  Map<String, RelNode> allNodes = new HashMap<>();
+
+  public VolcanoRuleMatchVisualizer(VolcanoPlanner volcanoPlanner) {
+    this.volcanoPlanner = volcanoPlanner;
+  }
+
+  public void addRuleMatch(String ruleCallID, Collection<? extends RelNode> matchedRels) {
+
+    // store the current state snapshot
+    // nodes contained in the sets
+    // and inputs of relNodes (and relSubsets)
+    Map<String, String> setLabels = new HashMap<>();
+    Map<String, String> setOriginalRel = new HashMap<>();
+    Map<String, Set<String>> nodesInSet = new HashMap<>();
+    Map<String, Set<String>> nodeInputs = new HashMap<>();
+
+    // newNodes appeared after this ruleCall
+    Set<String> newNodes = new HashSet<>();
+
+    // populate current snapshot, and fill in the allNodes map
+    volcanoPlanner.allSets.forEach(set -> {
+      String setID = ""set-"" + set.id;
+      String setLabel = getSetLabel(set);
+      setLabels.put(setID, setLabel);
+      setOriginalRel.put(setID, set.rel == null ? """" : String.valueOf(set.rel.getId()));
+
+      nodesInSet.put(setID, nodesInSet.getOrDefault(setID, new HashSet<>()));
+
+      Consumer<RelNode> addNode = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodesInSet.get(setID).add(nodeID);
+
+        if (!allNodes.containsKey(nodeID)) {
+          newNodes.add(nodeID);
+          allNodes.put(nodeID, rel);
+        }
+      };
+
+      Consumer<RelNode> addLink = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodeInputs.put(nodeID, new HashSet<>());
+        if (rel instanceof RelSubset) {
+          RelSubset relSubset = (RelSubset) rel;
+          relSubset.getRelList().stream()
+              .filter(input -> input.getTraitSet().equals(relSubset.getTraitSet()))
+              .forEach(input -> nodeInputs.get(nodeID).add(String.valueOf(input.getId())));","[{'comment': ""What's the advantage over using `relSubset.getRels().forEach(input -> relInputs.add(String.valueOf(input.getId())));`?"", 'commenter': 'thomasrebele'}, {'comment': 'This was a design tradeoff to make the links in a set less messy. In the environment I was working on, a set contains multiple subsets with related traits (mainly different distributions and collations). So a relNode belongs to many subsets at the same time. \r\n\r\nFor example, suppose there are 2 subsets `S1`, `S2` (`S2` satisfies `S1`) and 2 relnodes `R1`, `R2` (with the same trait as `S2`). \r\n\r\nInstead of creating 4 links for relNodes: `R1 -> S1`, `R1 -> S2`, `R2 -> S1`, `R2 -> S2`,\r\nI decided to create 2 links for relNodes: `R1 -> S2` and `R2 -> S2`, and 1 link for the subsets `S2 -> S1`. So the subset satisfaction relationship is indirectly shown. \r\n\r\nThis way in a set with many subsets/relnodes, the links are much less messy.\r\n\r\n', 'commenter': 'zuozhiw'}, {'comment': ""Thanks for the clarification. It's better to reduce the number of arrows in the graph, so let's keep it as it is."", 'commenter': 'thomasrebele'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added
+  Map<String, RelNode> allNodes = new HashMap<>();
+
+  public VolcanoRuleMatchVisualizer(VolcanoPlanner volcanoPlanner) {
+    this.volcanoPlanner = volcanoPlanner;
+  }
+
+  public void addRuleMatch(String ruleCallID, Collection<? extends RelNode> matchedRels) {
+
+    // store the current state snapshot
+    // nodes contained in the sets
+    // and inputs of relNodes (and relSubsets)
+    Map<String, String> setLabels = new HashMap<>();
+    Map<String, String> setOriginalRel = new HashMap<>();
+    Map<String, Set<String>> nodesInSet = new HashMap<>();
+    Map<String, Set<String>> nodeInputs = new HashMap<>();
+
+    // newNodes appeared after this ruleCall
+    Set<String> newNodes = new HashSet<>();
+
+    // populate current snapshot, and fill in the allNodes map
+    volcanoPlanner.allSets.forEach(set -> {
+      String setID = ""set-"" + set.id;
+      String setLabel = getSetLabel(set);
+      setLabels.put(setID, setLabel);
+      setOriginalRel.put(setID, set.rel == null ? """" : String.valueOf(set.rel.getId()));
+
+      nodesInSet.put(setID, nodesInSet.getOrDefault(setID, new HashSet<>()));
+
+      Consumer<RelNode> addNode = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodesInSet.get(setID).add(nodeID);
+
+        if (!allNodes.containsKey(nodeID)) {
+          newNodes.add(nodeID);
+          allNodes.put(nodeID, rel);
+        }
+      };
+
+      Consumer<RelNode> addLink = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodeInputs.put(nodeID, new HashSet<>());
+        if (rel instanceof RelSubset) {
+          RelSubset relSubset = (RelSubset) rel;
+          relSubset.getRelList().stream()
+              .filter(input -> input.getTraitSet().equals(relSubset.getTraitSet()))
+              .forEach(input -> nodeInputs.get(nodeID).add(String.valueOf(input.getId())));
+          relSubset.set.subsets.stream()
+              .filter(other -> !other.equals(relSubset))
+              .filter(other -> other.getTraitSet().satisfies(relSubset.getTraitSet()))
+              .forEach(other -> nodeInputs.get(nodeID).add(String.valueOf(other.getId())));","[{'comment': ""What's the advantage over using the following?\r\n```\r\nrelSubset.getSubsetsSatisfyingThis()\r\n              .filter(other -> !other.equals(relSubset))\r\n              .forEach(input -> relInputs.add(String.valueOf(input.getId())));\r\n```"", 'commenter': 'thomasrebele'}, {'comment': ""`getSubsetsSatisfyingThis` seems to be a new api that wasn't there when I wrote this code, I agree we should use it"", 'commenter': 'zuozhiw'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added
+  Map<String, RelNode> allNodes = new HashMap<>();
+
+  public VolcanoRuleMatchVisualizer(VolcanoPlanner volcanoPlanner) {
+    this.volcanoPlanner = volcanoPlanner;
+  }
+
+  public void addRuleMatch(String ruleCallID, Collection<? extends RelNode> matchedRels) {
+
+    // store the current state snapshot
+    // nodes contained in the sets
+    // and inputs of relNodes (and relSubsets)
+    Map<String, String> setLabels = new HashMap<>();
+    Map<String, String> setOriginalRel = new HashMap<>();
+    Map<String, Set<String>> nodesInSet = new HashMap<>();
+    Map<String, Set<String>> nodeInputs = new HashMap<>();
+
+    // newNodes appeared after this ruleCall
+    Set<String> newNodes = new HashSet<>();
+
+    // populate current snapshot, and fill in the allNodes map
+    volcanoPlanner.allSets.forEach(set -> {
+      String setID = ""set-"" + set.id;
+      String setLabel = getSetLabel(set);
+      setLabels.put(setID, setLabel);
+      setOriginalRel.put(setID, set.rel == null ? """" : String.valueOf(set.rel.getId()));
+
+      nodesInSet.put(setID, nodesInSet.getOrDefault(setID, new HashSet<>()));
+
+      Consumer<RelNode> addNode = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodesInSet.get(setID).add(nodeID);
+
+        if (!allNodes.containsKey(nodeID)) {
+          newNodes.add(nodeID);
+          allNodes.put(nodeID, rel);
+        }
+      };
+
+      Consumer<RelNode> addLink = rel -> {
+        String nodeID = String.valueOf(rel.getId());
+        nodeInputs.put(nodeID, new HashSet<>());
+        if (rel instanceof RelSubset) {
+          RelSubset relSubset = (RelSubset) rel;
+          relSubset.getRelList().stream()
+              .filter(input -> input.getTraitSet().equals(relSubset.getTraitSet()))
+              .forEach(input -> nodeInputs.get(nodeID).add(String.valueOf(input.getId())));
+          relSubset.set.subsets.stream()
+              .filter(other -> !other.equals(relSubset))
+              .filter(other -> other.getTraitSet().satisfies(relSubset.getTraitSet()))
+              .forEach(other -> nodeInputs.get(nodeID).add(String.valueOf(other.getId())));
+        } else {
+          rel.getInputs().forEach(input -> nodeInputs.get(nodeID)
+              .add(String.valueOf(input.getId())));
+        }
+      };
+
+      set.rels.forEach(addNode);
+      set.subsets.forEach(addNode);
+      set.rels.forEach(addLink);
+      set.subsets.forEach(addLink);
+    });
+
+    // get the matched nodes of this rule
+    Set<String> matchedNodeIDs = matchedRels.stream()
+        .map(rel -> String.valueOf(rel.getId()))
+        .collect(Collectors.toSet());
+
+    // get importance 0 rels as of right now
+    Set<String> importanceZeroNodes = new HashSet<>();","[{'comment': ""Maybe it's better to keep the term `prunedNodes` used by the VolcanoPlanner?"", 'commenter': 'thomasrebele'}, {'comment': 'agree', 'commenter': 'zuozhiw'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();
+ * // writes the output to files
+ * visualizerListener.getVisualizer().writeToFile(outputDirectory, """");
+ * </pre>
+ */
+public class VolcanoRuleMatchVisualizer {
+
+  VolcanoPlanner volcanoPlanner;
+
+  // a sequence of ruleMatch ID to represent the order of rule match
+  List<String> ruleMatchSequence = new ArrayList<>();
+  // map of ruleMatch ID and the info, including the state snapshot at the time of ruleMatch
+  Map<String, VisualizerRuleMatchInfo> ruleInfoMap = new HashMap<>();
+  // map of nodeID to the ruleID it's first added
+  Map<String, String> nodeAddedInRule = new HashMap<>();
+
+  // a map of relNode ID to the actual RelNode object
+  // contains all the relNodes appear during the optimization
+  // all RelNode are immutable in Calcite, therefore only new nodes will be added
+  Map<String, RelNode> allNodes = new HashMap<>();
+
+  public VolcanoRuleMatchVisualizer(VolcanoPlanner volcanoPlanner) {
+    this.volcanoPlanner = volcanoPlanner;
+  }
+
+  public void addRuleMatch(String ruleCallID, Collection<? extends RelNode> matchedRels) {
+
+    // store the current state snapshot
+    // nodes contained in the sets
+    // and inputs of relNodes (and relSubsets)
+    Map<String, String> setLabels = new HashMap<>();
+    Map<String, String> setOriginalRel = new HashMap<>();
+    Map<String, Set<String>> nodesInSet = new HashMap<>();
+    Map<String, Set<String>> nodeInputs = new HashMap<>();","[{'comment': 'Using TreeMaps would make the output more stable (i.e., no reordering when adding new nodes).', 'commenter': 'thomasrebele'}, {'comment': 'agree', 'commenter': 'zuozhiw'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);","[{'comment': 'how about adding the listener when constructing the visualizer?', 'commenter': 'thomasrebele'}, {'comment': 'agree, I saw the changes in your branch and the api is more concise and easy to use.', 'commenter': 'zuozhiw'}]"
2486,core/src/main/java/org/apache/calcite/plan/volcano/VolcanoRuleMatchVisualizer.java,"@@ -0,0 +1,300 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.plan.volcano;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptCost;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.tools.visualizer.InputExcludedRelWriter;
+import org.apache.calcite.tools.visualizer.VisualizerNodeInfo;
+import org.apache.calcite.tools.visualizer.VisualizerRuleMatchInfo;
+
+import org.apache.commons.io.IOUtils;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.google.common.base.Charsets;
+
+import java.io.IOException;
+import java.io.UncheckedIOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.ArrayList;
+import java.util.Collection;
+import java.util.Deque;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.LinkedList;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.function.Consumer;
+import java.util.stream.Collectors;
+
+import static java.util.stream.Collectors.joining;
+
+/**
+ * This is tool to visualize the rule match process of the VolcanoPlanner.
+ *
+ *
+ * <p>To use the visualizer, add a listener before the VolcanoPlanner optimization phase.
+ * Then writes the output to a file after the optimization ends.
+ *
+ * <pre>
+ * // construct the visualizer and attach a listener to VolcanoPlanner
+ * VolcanoRuleMatchVisualizerListener visualizerListener =
+ *   new VolcanoRuleMatchVisualizerListener(volcanoPlanner);
+ * volcanoPlanner.addListener(visualizerListener);
+ *
+ * volcanoPlanner.findBestExpr();
+ *
+ * // after the optimization, adds the final best plan
+ * visualizerListener.getVisualizer().addFinalPlan();","[{'comment': 'we could execute this step automatically when calling writeToFile(...)', 'commenter': 'thomasrebele'}, {'comment': 'agree, makes it easy to use', 'commenter': 'zuozhiw'}]"
2486,core/src/main/resources/volcano-viz/viz-template.html,"@@ -0,0 +1,323 @@
+<!doctype html>
+<html lang=""en"">
+<!--
+{% comment %}
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to you under the Apache License, Version 2.0
+(the ""License""); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+{% endcomment %}
+-->
+<meta charset=""utf-8"">
+<title>Calcite Rule Match Visualization</title>
+
+<script src=""https://d3js.org/d3.v5.min.js"" charset=""utf-8""></script>","[{'comment': 'Maybe we should switch to a more recent version. The latest version of d3 is 7.0.0. I tried v6 and v7 and this breaks only the panning and zooming. Probably not too difficult to fix.', 'commenter': 'thomasrebele'}, {'comment': ""agree, it's been some time since I implemented this code, so the library might be out of date, but one thing to be careful is the compatibility with dagre-d3, which seems to be not actively maintained anymore https://github.com/dagrejs/dagre-d3"", 'commenter': 'zuozhiw'}]"
2486,core/src/main/resources/volcano-viz/viz-template.html,"@@ -0,0 +1,323 @@
+<!doctype html>
+<html lang=""en"">
+<!--
+{% comment %}
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to you under the Apache License, Version 2.0
+(the ""License""); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+{% endcomment %}
+-->
+<meta charset=""utf-8"">
+<title>Calcite Rule Match Visualization</title>
+
+<script src=""https://d3js.org/d3.v5.min.js"" charset=""utf-8""></script>
+<script src=""https://dagrejs.github.io/project/dagre-d3/latest/dagre-d3.min.js""></script>
+<script src=""https://d3js.org/d3-zoom.v1.min.js""></script>
+<script src=""https://unpkg.com/tippy.js@3/dist/tippy.all.min.js""></script>
+<script src=""volcano-viz-data.js""></script>
+
+<style id=""css"">
+    body {
+        height: 100%;
+        margin: 0 0;
+        color: #333;
+        font-weight: 300;
+        font-family: ""Helvetica Neue"", Helvetica, Arial, sans-serf;
+    }
+
+    li a {
+        display: block;
+        /* and you can use padding for additional space if needs, as a clickable area / or other styling */
+        padding: 5px 20px;
+    }
+
+    section {
+        margin-bottom: 3em;
+    }
+
+    section p {
+        text-align: justify;
+    }
+
+    svg {
+        border: 1px solid #ccc;
+        overflow: hidden;
+        margin: 0 auto;
+    }
+
+    pre {
+        border: 1px solid #ccc;
+    }
+
+    .clusters rect {
+        fill: #FFFFE0;
+        stroke: #999;
+        stroke-width: 1.5px;
+    }
+
+    text {
+        font-weight: 300;
+        font-family: ""Helvetica Neue"", Helvetica, Arial, sans-serf;
+        font-size: 2em;
+    }
+
+    .node rect {
+        stroke: #999;
+        fill: #fff;
+        stroke-width: 1.5px;
+    }
+
+    .edgePath path {
+        stroke: #333;
+        stroke-width: 2px;
+    }
+
+    .container {
+        display: flex;
+        align-items: center;
+    }
+
+    .column1 {
+        flex: 0 0 300px;
+    }
+
+    .column2 {
+        flex: 0 0 1000px;
+    }
+
+    .tippy-content {
+        word-break: break-all;
+        word-wrap: break-word;
+    }
+</style>
+
+<div class=""container"">
+    <div class=""column1"">
+        <div style=""width: 100%; text-align: center"">
+            <div id=""current-rule"" style=""display: block""></div>
+            <button id=""prev-button"" style=""width: 80px; height: 40px; display:inline-block"" disabled>prev </button>
+            <button id=""next-button"" style=""width: 80px; height: 40px; display:inline-block"" disabled> next</button>
+        </div>
+        <ul id=""rule-match-list"" style=""width: 300px; height: 600px; overflow: auto"">
+        </ul>
+    </div>
+    <div class=""column2"">
+        <svg id=""svg-canvas"" width=""1200px"" height=""800px""></svg>
+    </div>
+</div>
+
+<script id=""js"">
+
+    var allNodes = data.allNodes;
+    var ruleMatchSequence = data.ruleMatchSequence;
+    var ruleMatchInfoMap = data.ruleMatchInfoMap;
+    var nodeAddedInRule = data.nodeAddedInRule;
+
+    /*
+     * Graph data and D3 JS render related variables
+     */
+
+    // Create the input graph
+    var g = new dagreD3.graphlib.Graph({
+            compound: true
+        })
+        .setGraph({
+            rankdir: 'LR'
+        })
+        .setDefaultEdgeLabel(function () {
+            return {};
+        });
+
+    // Create the renderer
+    var render = new dagreD3.render();
+
+    // Set up an SVG group so that we can translate the final graph.
+    var svg = d3.select(""svg"");
+    var svgGroup = svg.append(""g"");
+
+    // Set up zoom support
+    var svg = d3.select(""svg"")
+        .attr(""width"", ""1200px"")
+        .attr(""height"", ""800px"")
+        .call(d3.zoom().on(""zoom"", function () {
+            svgGroup.attr(""transform"", d3.event.transform)
+        }));
+
+    /*
+     * Global State
+     */
+
+    var currentRuleID = undefined;
+
+    /*
+     * Event Handler functions
+     */
+
+    var setCurrentRule = (ruleMatchID) => {
+        // un-highlight previous entry
+        var prevRuleID = currentRuleID;
+        if (prevRuleID !== undefined) {
+            var prevRuleElement = document.getElementById(prevRuleID);
+            prevRuleElement.style.backgroundColor = ""#FFFFFF"";
+        }
+
+        currentRuleID = ruleMatchID;
+        document.getElementById('current-rule').innerText = currentRuleID;
+
+        var currentRuleElement = document.getElementById(currentRuleID);
+        currentRuleElement.style.backgroundColor = ""#D3D3D3"";
+
+        var ruleIndex = ruleMatchSequence.indexOf(currentRuleID);
+
+        document.getElementById(""prev-button"").disabled = false;
+        document.getElementById(""next-button"").disabled = false;","[{'comment': 'We can set the correct value directly (without using an if).', 'commenter': 'thomasrebele'}, {'comment': 'agree', 'commenter': 'zuozhiw'}]"
2486,core/src/main/resources/volcano-viz/viz-template.html,"@@ -0,0 +1,323 @@
+<!doctype html>
+<html lang=""en"">
+<!--
+{% comment %}
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to you under the Apache License, Version 2.0
+(the ""License""); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+{% endcomment %}
+-->
+<meta charset=""utf-8"">
+<title>Calcite Rule Match Visualization</title>
+
+<script src=""https://d3js.org/d3.v5.min.js"" charset=""utf-8""></script>
+<script src=""https://dagrejs.github.io/project/dagre-d3/latest/dagre-d3.min.js""></script>
+<script src=""https://d3js.org/d3-zoom.v1.min.js""></script>
+<script src=""https://unpkg.com/tippy.js@3/dist/tippy.all.min.js""></script>
+<script src=""volcano-viz-data.js""></script>
+
+<style id=""css"">
+    body {
+        height: 100%;
+        margin: 0 0;
+        color: #333;
+        font-weight: 300;
+        font-family: ""Helvetica Neue"", Helvetica, Arial, sans-serf;
+    }
+
+    li a {
+        display: block;
+        /* and you can use padding for additional space if needs, as a clickable area / or other styling */
+        padding: 5px 20px;
+    }
+
+    section {
+        margin-bottom: 3em;
+    }
+
+    section p {
+        text-align: justify;
+    }
+
+    svg {
+        border: 1px solid #ccc;
+        overflow: hidden;
+        margin: 0 auto;
+    }
+
+    pre {
+        border: 1px solid #ccc;
+    }
+
+    .clusters rect {
+        fill: #FFFFE0;
+        stroke: #999;
+        stroke-width: 1.5px;
+    }
+
+    text {
+        font-weight: 300;
+        font-family: ""Helvetica Neue"", Helvetica, Arial, sans-serf;
+        font-size: 2em;
+    }
+
+    .node rect {
+        stroke: #999;
+        fill: #fff;
+        stroke-width: 1.5px;
+    }
+
+    .edgePath path {
+        stroke: #333;
+        stroke-width: 2px;
+    }
+
+    .container {
+        display: flex;
+        align-items: center;
+    }
+
+    .column1 {
+        flex: 0 0 300px;
+    }
+
+    .column2 {
+        flex: 0 0 1000px;
+    }
+
+    .tippy-content {
+        word-break: break-all;
+        word-wrap: break-word;
+    }
+</style>
+
+<div class=""container"">
+    <div class=""column1"">
+        <div style=""width: 100%; text-align: center"">
+            <div id=""current-rule"" style=""display: block""></div>
+            <button id=""prev-button"" style=""width: 80px; height: 40px; display:inline-block"" disabled>prev </button>
+            <button id=""next-button"" style=""width: 80px; height: 40px; display:inline-block"" disabled> next</button>
+        </div>
+        <ul id=""rule-match-list"" style=""width: 300px; height: 600px; overflow: auto"">
+        </ul>
+    </div>
+    <div class=""column2"">
+        <svg id=""svg-canvas"" width=""1200px"" height=""800px""></svg>
+    </div>
+</div>
+
+<script id=""js"">
+
+    var allNodes = data.allNodes;
+    var ruleMatchSequence = data.ruleMatchSequence;
+    var ruleMatchInfoMap = data.ruleMatchInfoMap;
+    var nodeAddedInRule = data.nodeAddedInRule;
+
+    /*
+     * Graph data and D3 JS render related variables
+     */
+
+    // Create the input graph
+    var g = new dagreD3.graphlib.Graph({
+            compound: true
+        })
+        .setGraph({
+            rankdir: 'LR'
+        })
+        .setDefaultEdgeLabel(function () {
+            return {};
+        });
+
+    // Create the renderer
+    var render = new dagreD3.render();
+
+    // Set up an SVG group so that we can translate the final graph.
+    var svg = d3.select(""svg"");
+    var svgGroup = svg.append(""g"");
+
+    // Set up zoom support
+    var svg = d3.select(""svg"")
+        .attr(""width"", ""1200px"")
+        .attr(""height"", ""800px"")
+        .call(d3.zoom().on(""zoom"", function () {
+            svgGroup.attr(""transform"", d3.event.transform)
+        }));
+
+    /*
+     * Global State
+     */
+
+    var currentRuleID = undefined;
+
+    /*
+     * Event Handler functions
+     */
+
+    var setCurrentRule = (ruleMatchID) => {
+        // un-highlight previous entry
+        var prevRuleID = currentRuleID;
+        if (prevRuleID !== undefined) {
+            var prevRuleElement = document.getElementById(prevRuleID);
+            prevRuleElement.style.backgroundColor = ""#FFFFFF"";
+        }
+
+        currentRuleID = ruleMatchID;
+        document.getElementById('current-rule').innerText = currentRuleID;
+
+        var currentRuleElement = document.getElementById(currentRuleID);
+        currentRuleElement.style.backgroundColor = ""#D3D3D3"";
+
+        var ruleIndex = ruleMatchSequence.indexOf(currentRuleID);
+
+        document.getElementById(""prev-button"").disabled = false;
+        document.getElementById(""next-button"").disabled = false;
+
+        if (ruleIndex === 0) {
+            document.getElementById(""prev-button"").disabled = true;
+        }
+        if (ruleIndex === ruleMatchSequence.length - 1) {
+            document.getElementById(""next-button"").disabled = true;
+        }
+
+        createGraph(ruleMatchID);
+    }
+
+    var createGraph = (ruleMatchID) => {
+        var ruleMatchInfo = ruleMatchInfoMap[ruleMatchID]
+        console.log(ruleMatchInfo);
+
+        // remove previous rendered view and clear graph model
+        d3.select(""svg g"").selectAll(""*"").remove();
+        g.nodes().slice().forEach(nodeID => g.removeNode(nodeID));","[{'comment': 'I think it would be better to update the graph instead of resetting it. We can leave it like this for the moment and change it when we add a functionality that would benefit from keeping the existing nodes.', 'commenter': 'thomasrebele'}, {'comment': ""Agree, but we need to be careful and compare the old nodes with the new nodes. This could be tricky especially when set merge happens: one set is removed and relnodes from this set all go into another set. So re-drawing is eaiser.\r\n\r\nOne more thing on performance. This tool runs slow when the plan is ultra-large. I investigated and the major performance bottleneck is actually doing the **layout** instead of drawing the nodes. I can't recall the exact numbers but over 90% of the time is spent on the layout (`dagre`) for plans with noticable delay in visualization. \r\n\r\nI did an extensive investigation on different layout libraries, but `dagre` remains the best-looking one, so I decided to keep it although it's slow. One sad thing is that none of these layout libraries can calculate layout incrementally. They all have to re-compute the whole thing every time."", 'commenter': 'zuozhiw'}, {'comment': 'Indeed, merging sets would be quite difficult to handle.\r\n\r\nHow big is an ulta-large plan? Maybe we can provide a combo-box to switch between different layout algorithms (e.g., d3-force).', 'commenter': 'thomasrebele'}]"
2486,core/src/main/resources/volcano-viz/viz-template.html,"@@ -0,0 +1,323 @@
+<!doctype html>
+<html lang=""en"">
+<!--
+{% comment %}
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to you under the Apache License, Version 2.0
+(the ""License""); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+{% endcomment %}
+-->
+<meta charset=""utf-8"">
+<title>Calcite Rule Match Visualization</title>
+
+<script src=""https://d3js.org/d3.v5.min.js"" charset=""utf-8""></script>
+<script src=""https://dagrejs.github.io/project/dagre-d3/latest/dagre-d3.min.js""></script>
+<script src=""https://d3js.org/d3-zoom.v1.min.js""></script>
+<script src=""https://unpkg.com/tippy.js@3/dist/tippy.all.min.js""></script>
+<script src=""volcano-viz-data.js""></script>
+
+<style id=""css"">
+    body {
+        height: 100%;
+        margin: 0 0;
+        color: #333;
+        font-weight: 300;
+        font-family: ""Helvetica Neue"", Helvetica, Arial, sans-serf;
+    }
+
+    li a {
+        display: block;
+        /* and you can use padding for additional space if needs, as a clickable area / or other styling */
+        padding: 5px 20px;
+    }
+
+    section {
+        margin-bottom: 3em;
+    }
+
+    section p {
+        text-align: justify;
+    }
+
+    svg {
+        border: 1px solid #ccc;
+        overflow: hidden;
+        margin: 0 auto;
+    }
+
+    pre {
+        border: 1px solid #ccc;
+    }
+
+    .clusters rect {
+        fill: #FFFFE0;
+        stroke: #999;
+        stroke-width: 1.5px;
+    }
+
+    text {
+        font-weight: 300;
+        font-family: ""Helvetica Neue"", Helvetica, Arial, sans-serf;
+        font-size: 2em;
+    }
+
+    .node rect {
+        stroke: #999;
+        fill: #fff;
+        stroke-width: 1.5px;
+    }
+
+    .edgePath path {
+        stroke: #333;
+        stroke-width: 2px;
+    }
+
+    .container {
+        display: flex;
+        align-items: center;
+    }
+
+    .column1 {
+        flex: 0 0 300px;
+    }
+
+    .column2 {
+        flex: 0 0 1000px;
+    }
+
+    .tippy-content {
+        word-break: break-all;
+        word-wrap: break-word;
+    }
+</style>
+
+<div class=""container"">
+    <div class=""column1"">
+        <div style=""width: 100%; text-align: center"">
+            <div id=""current-rule"" style=""display: block""></div>
+            <button id=""prev-button"" style=""width: 80px; height: 40px; display:inline-block"" disabled>prev </button>
+            <button id=""next-button"" style=""width: 80px; height: 40px; display:inline-block"" disabled> next</button>
+        </div>
+        <ul id=""rule-match-list"" style=""width: 300px; height: 600px; overflow: auto"">
+        </ul>
+    </div>
+    <div class=""column2"">
+        <svg id=""svg-canvas"" width=""1200px"" height=""800px""></svg>
+    </div>
+</div>
+
+<script id=""js"">
+
+    var allNodes = data.allNodes;
+    var ruleMatchSequence = data.ruleMatchSequence;
+    var ruleMatchInfoMap = data.ruleMatchInfoMap;
+    var nodeAddedInRule = data.nodeAddedInRule;
+
+    /*
+     * Graph data and D3 JS render related variables
+     */
+
+    // Create the input graph
+    var g = new dagreD3.graphlib.Graph({
+            compound: true
+        })
+        .setGraph({
+            rankdir: 'LR'
+        })
+        .setDefaultEdgeLabel(function () {
+            return {};
+        });
+
+    // Create the renderer
+    var render = new dagreD3.render();
+
+    // Set up an SVG group so that we can translate the final graph.
+    var svg = d3.select(""svg"");
+    var svgGroup = svg.append(""g"");
+
+    // Set up zoom support
+    var svg = d3.select(""svg"")
+        .attr(""width"", ""1200px"")
+        .attr(""height"", ""800px"")
+        .call(d3.zoom().on(""zoom"", function () {
+            svgGroup.attr(""transform"", d3.event.transform)
+        }));
+
+    /*
+     * Global State
+     */
+
+    var currentRuleID = undefined;
+
+    /*
+     * Event Handler functions
+     */
+
+    var setCurrentRule = (ruleMatchID) => {
+        // un-highlight previous entry
+        var prevRuleID = currentRuleID;
+        if (prevRuleID !== undefined) {
+            var prevRuleElement = document.getElementById(prevRuleID);
+            prevRuleElement.style.backgroundColor = ""#FFFFFF"";
+        }
+
+        currentRuleID = ruleMatchID;
+        document.getElementById('current-rule').innerText = currentRuleID;
+
+        var currentRuleElement = document.getElementById(currentRuleID);
+        currentRuleElement.style.backgroundColor = ""#D3D3D3"";
+
+        var ruleIndex = ruleMatchSequence.indexOf(currentRuleID);
+
+        document.getElementById(""prev-button"").disabled = false;
+        document.getElementById(""next-button"").disabled = false;
+
+        if (ruleIndex === 0) {
+            document.getElementById(""prev-button"").disabled = true;
+        }
+        if (ruleIndex === ruleMatchSequence.length - 1) {
+            document.getElementById(""next-button"").disabled = true;
+        }
+
+        createGraph(ruleMatchID);
+    }
+
+    var createGraph = (ruleMatchID) => {
+        var ruleMatchInfo = ruleMatchInfoMap[ruleMatchID]
+        console.log(ruleMatchInfo);
+
+        // remove previous rendered view and clear graph model
+        d3.select(""svg g"").selectAll(""*"").remove();
+        g.nodes().slice().forEach(nodeID => g.removeNode(nodeID));
+
+        // create nodes and sets
+        for (var setID in ruleMatchInfo.nodesInSet) {
+            // add set
+            var setLabel = ruleMatchInfo.setLabels[setID];
+            if (setLabel === null || setLabel === undefined) {
+                setLabel = setID;
+            }
+            g.setNode(setID, {
+                label: setLabel,
+                clusterLabelPos: 'top'
+            });
+            // add nodes and node-set parent relationship
+            var nodes = ruleMatchInfo.nodesInSet[setID];
+
+            nodes.forEach(nodeID => {
+                nodeInfo = allNodes[nodeID];
+                var nodeLabel;
+                if (ruleMatchID === ""FINAL"") {
+                    nodeLabel = nodeInfo.label + ""--"" + nodeInfo.finalCost;
+                } else {
+                    nodeLabel = nodeInfo.label;
+                }
+                var nodeStyle;
+               if (ruleMatchInfo.importanceZeroNodes
+                    && ruleMatchInfo.importanceZeroNodes.includes(nodeID)) {
+                    nodeStyle = ""fill: #D3D3D3""","[{'comment': 'Using a class instead of explicit CSS attributes would allow to change the colors later. The same applies to the other styles set by the js code.', 'commenter': 'thomasrebele'}, {'comment': 'agree', 'commenter': 'zuozhiw'}]"
2486,core/src/main/resources/volcano-viz/volcano-viz-data.js,"@@ -0,0 +1,135 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+// sample generated visualizer data used by the visualizer JavaScript code
+var data = {
+
+	allNodes: {
+		""node1"": {
+			label: ""TableScan-1"", // node label being displayed
+			isSubset: false, // if the node is a RelSubset
+			explanation: ""table=t1"", // additional explanation of properties
+			finalCost: ""100 cpu, 100io"" // final cost (in string) of the node at the end of optimization
+		},
+		""node2"": {
+			label: ""Filter-2"",
+			isSubset: false,
+			explanation: ""condition=c"",
+			finalCost: ""200cpu, 100io""
+		},
+		""node3"": {
+			label: ""TableSink-3"",
+			isSubset: false,
+			explanation: ""table=t2"",
+			finalCost: ""20cpu, 20io""
+		},
+		""node4"": {
+			label: ""IndexTableScan-4"",
+			isSubset: false,
+			explanation: ""table=t1, condition=c"",
+			finalCost: ""10cpu, 10io""
+		},
+	},
+
+	ruleMatchSequence: [
+		""INITIAL"",
+		""IndexTableScanRule#1"",
+		""FINAL""
+	],
+
+	ruleMatchInfoMap: {
+		""INITIAL"": {
+			setLabels: {
+				""set1"": ""set1"",
+				""set2"": ""set2"",
+				""set3"": ""set3"",
+			},
+			setOriginalRel: {
+				""set1"": ""node1"",
+				""set2"": ""node2"",
+				""set3"": ""node3"",
+			},","[{'comment': 'The setLabels and setOriginalRel could be moved to the root level (i.e., to line 47). This requires changing the js code, though.', 'commenter': 'thomasrebele'}, {'comment': ""agree, this can make the json more compact. I can do the JS changes since I'm more familiar."", 'commenter': 'zuozhiw'}]"
2559,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -2657,6 +2664,38 @@ private static RelDataType nullifyType(JavaTypeFactory typeFactory,
     }
   }
 
+  /** Implementor for a array concat. */
+  private static class ArrayConcatImplementor extends AbstractRexCallImplementor {","[{'comment': ""if there is concrete implementation, can we add some sql tests?  \r\n+ doesn't seems mentioned in the spec, but does it interact with filter clause etc."", 'commenter': 'zinking'}, {'comment': 'Could you please a bit elaborate what kind of tests do you mean?\r\ne.g. like that \r\nhttps://github.com/apache/calcite/pull/2559/files#diff-cb3257551f96f6523e9c4464d9359b21b0408ccfb7315955f97a59b45546bc1cR5790-R5799 ?', 'commenter': 'snuyanzin'}, {'comment': 'that was indeed the query test, it was one liner which I missed.', 'commenter': 'zinking'}]"
2559,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -2657,6 +2664,38 @@ private static RelDataType nullifyType(JavaTypeFactory typeFactory,
     }
   }
 
+  /** Implementor for a array concat. */
+  private static class ArrayConcatImplementor extends AbstractRexCallImplementor {
+
+    ArrayConcatImplementor() {
+      super(NullPolicy.STRICT, false);
+    }
+
+    @Override String getVariableName() {
+      return ""array_concat"";
+    }
+
+    @Override Expression implementSafe(RexToLixTranslator translator, RexCall call,
+        List<Expression> argValueList) {
+      final BlockBuilder blockBuilder = translator.getBlockBuilder();
+      final Expression list =
+          blockBuilder.append(""list"", Expressions.new_(ArrayList.class), false);","[{'comment': 'If you try to initialize  ArrayList. Expressions.assign() is more suitable.', 'commenter': 'NobiGo'}, {'comment': 'As far as I know `Expressions.assign()` is good when you have left and right parts. Here we do not have and need to create a new variable. Or ... could you please elaborate your suggestion?', 'commenter': 'snuyanzin'}, {'comment': '+1', 'commenter': 'NobiGo'}]"
2559,site/_docs/reference.md,"@@ -2513,6 +2513,9 @@ semantics.
 | C | Operator syntax                                | Description
 |:- |:-----------------------------------------------|:-----------
 | p | expr :: type                                   | Casts *expr* to *type*
+| b | ARRAY_CONCAT(array [, array ]*)                | Concatenates one or more arrays. If any input argument is `NULL` the function returns `NULL`","[{'comment': 'If any input argument is `NULL` the function returns `NULL`? According test in SqlOperatorBaseTest. The test return value is different. Or did I misunderstand?', 'commenter': 'NobiGo'}, {'comment': 'Not sure what exactly you are referring to... Probably this\r\n```\r\n    tester.checkScalar(\r\n        ""array_concat(array[\'hello\', \'world\'], array[\'!\'], array[cast(null as char)])"",\r\n        ""[hello, world, !, null]"", ""CHAR(5) ARRAY NOT NULL"");\r\n    tester.checkNull(""array_concat(cast(null as integer array), array[1])"");\r\n```\r\n\r\nThe key difference here is that in the first test there are elements `array[\'hello\', \'world\', \'!\']` and `array[null]` while in the second there are `null` and `array[1]`.\r\nSo the tests check that if argument is null then return `null` however if an argument is a collection containing `null` value it should do normal concatenation.\r\n\r\nIn case you are referring to something else please elaborate', 'commenter': 'snuyanzin'}, {'comment': 'Thanks for your reply. +1', 'commenter': 'NobiGo'}]"
2559,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -2657,6 +2664,38 @@ private static RelDataType nullifyType(JavaTypeFactory typeFactory,
     }
   }
 
+  /** Implementor for a array concat. */
+  private static class ArrayConcatImplementor extends AbstractRexCallImplementor {
+
+    ArrayConcatImplementor() {
+      super(NullPolicy.STRICT, false);
+    }
+
+    @Override String getVariableName() {
+      return ""array_concat"";
+    }
+
+    @Override Expression implementSafe(RexToLixTranslator translator, RexCall call,
+        List<Expression> argValueList) {
+      final BlockBuilder blockBuilder = translator.getBlockBuilder();
+      final Expression list =
+          blockBuilder.append(""list"", Expressions.new_(ArrayList.class), false);
+      final Expression nullValue = Expressions.constant(null);","[{'comment': 'nullValue can be replced by ""NULL_EXPR""', 'commenter': 'NobiGo'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/FileRowConverter.java,"@@ -52,13 +53,13 @@
   // row parser configuration
   private final List<FieldDef> fields = new ArrayList<>();
 
-  /** Format for parsing numbers. Not thread-safe, but we assume that only
-   * one thread uses this converter at a time. */
+  /** Format for parsing numbers. Not thread-safe, but we assume that only one thread uses this","[{'comment': 'This and below still look like extraneous formatting.', 'commenter': 'jacques-n'}, {'comment': 'Done. ', 'commenter': 'xwkuang5'}]"
2572,core/src/main/java/org/apache/calcite/sql/type/SqlTypeFactoryImpl.java,"@@ -84,6 +84,10 @@ public SqlTypeFactoryImpl(RelDataTypeSystem typeSystem) {
         || (precision == RelDataType.PRECISION_NOT_SPECIFIED);
     final int maxPrecision = typeSystem.getMaxPrecision(typeName);
     if (maxPrecision >= 0 && precision > maxPrecision) {
+      System.out.println(""WARNING: specified precision ("" + precision","[{'comment': ""You shouldn't add this here. There are several reasons:\r\n\r\n- This path is used by many pieces of code.\r\n- We should never println in core paths to warn someone of something. It could make sense to add a logging invocation here. However, I'm not sure it does. If we thought that made sense, I think you should do it in a separate PR since it is pretty unrelated to this change. If you want to capture and warn that a field in the csv is out of line with what is allowed, you should do that in the csv connector itself, not somewhere in the core module."", 'commenter': 'jacques-n'}, {'comment': 'Removed for now.', 'commenter': 'xwkuang5'}]"
2572,file/src/test/resources/sales-csv/DECIMAL.csv,"@@ -0,0 +1,4 @@
+DEPTNO:int,BUDGET:decimal(18/2)","[{'comment': ""The standard pattern in most sql systems is a comma between scale and precision. It's really weird that you're using a slash. Can you make this a comma?"", 'commenter': 'jacques-n'}, {'comment': 'Done. Added double quote to disambiguate between column separator and the precision and scale separator.', 'commenter': 'xwkuang5'}]"
2572,file/src/test/java/org/apache/calcite/adapter/file/FileAdapterTest.java,"@@ -619,6 +621,72 @@ private String range(int first, int count) {
     return sb.append(')').toString();
   }
 
+  @Test void testDecimalType() {
+    sql(""sales-csv"", ""select BUDGET from sales.\""DECIMAL\"""")
+        .checking(resultSet -> {
+          try {
+            ResultSetMetaData metaData = resultSet.getMetaData();
+            assertEquals(""DECIMAL"", metaData.getColumnTypeName(1));
+            assertEquals(18, metaData.getPrecision(1));
+            assertEquals(2, metaData.getScale(1));
+          } catch (SQLException e) {
+            throw TestUtil.rethrow(e);
+          }
+        })
+        .ok();
+  }
+
+  @Test void testDecimalTypeArithmeticOperations() {","[{'comment': 'Can you also test cases for negative cases and out of space numbers? For example a CSV has 0.0000000000001 or 10000 but the it is declared as DECIMAL(4,1).', 'commenter': 'jacques-n'}, {'comment': 'Done. This has been added in the new CsvEnumeratorTest file as part of testing the parseDecimal method. ', 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -130,30 +129,108 @@ public static RelDataType deduceRowType(JavaTypeFactory typeFactory,
       }
       for (String string : strings) {
         final String name;
-        final CsvFieldType fieldType;
+        final RelDataType fieldType;
         final int colon = string.indexOf(':');
         if (colon >= 0) {
           name = string.substring(0, colon);
           String typeString = string.substring(colon + 1);
-          fieldType = CsvFieldType.of(typeString);
-          if (fieldType == null) {
-            System.out.println(""WARNING: Found unknown type: ""
-                + typeString + "" in file: "" + source.path()
-                + "" for column: "" + name
-                + "". Will assume the type of column is string"");
+          Matcher decimalMatcher = DECIMAL_TYPE_PATTERN.matcher(typeString);
+          if (decimalMatcher.matches()) {
+            int precision = Integer.parseInt(decimalMatcher.group(1));
+            int scale = Integer.parseInt(decimalMatcher.group(2));
+            fieldType = typeFactory.createTypeWithNullability(typeFactory
+                .createSqlType(SqlTypeName.DECIMAL,
+                    precision, scale), true);
+          } else {
+            switch (typeString) {
+            case ""string"":
+              fieldType = typeFactory.createTypeWithNullability(typeFactory
+                      .createSqlType(typeFactory.createJavaType(String.class).getSqlTypeName()),","[{'comment': 'Please just use the SqlTypeName enum directly as opposed to the intermediate step of createJavaType()', 'commenter': 'jacques-n'}, {'comment': 'Done.', 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -130,30 +129,108 @@ public static RelDataType deduceRowType(JavaTypeFactory typeFactory,
       }
       for (String string : strings) {
         final String name;
-        final CsvFieldType fieldType;
+        final RelDataType fieldType;
         final int colon = string.indexOf(':');
         if (colon >= 0) {
           name = string.substring(0, colon);
           String typeString = string.substring(colon + 1);
-          fieldType = CsvFieldType.of(typeString);
-          if (fieldType == null) {
-            System.out.println(""WARNING: Found unknown type: ""
-                + typeString + "" in file: "" + source.path()
-                + "" for column: "" + name
-                + "". Will assume the type of column is string"");
+          Matcher decimalMatcher = DECIMAL_TYPE_PATTERN.matcher(typeString);
+          if (decimalMatcher.matches()) {
+            int precision = Integer.parseInt(decimalMatcher.group(1));
+            int scale = Integer.parseInt(decimalMatcher.group(2));
+            fieldType = typeFactory.createTypeWithNullability(typeFactory
+                .createSqlType(SqlTypeName.DECIMAL,
+                    precision, scale), true);
+          } else {
+            switch (typeString) {
+            case ""string"":
+              fieldType = typeFactory.createTypeWithNullability(typeFactory
+                      .createSqlType(typeFactory.createJavaType(String.class).getSqlTypeName()),
+                  true);
+              break;
+            case ""boolean"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.BOOLEAN.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""byte"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.BYTE.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""char"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.CHAR.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""short"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.SHORT.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""int"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.INT.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""long"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.LONG.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""float"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.FLOAT.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""double"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(Primitive.DOUBLE.getBoxClass()).getSqlTypeName()),
+                  true);
+              break;
+            case ""date"":
+              fieldType = typeFactory.createTypeWithNullability(typeFactory
+                      .createSqlType(typeFactory.createJavaType(java.sql.Date.class)
+                          .getSqlTypeName()),
+                  true);
+              break;
+            case ""time"":
+              fieldType = typeFactory.createTypeWithNullability(typeFactory
+                      .createSqlType(typeFactory.createJavaType(java.sql.Time.class)
+                          .getSqlTypeName()),
+                  true);
+              break;
+            case ""timestamp"":
+              fieldType = typeFactory.createTypeWithNullability(
+                  typeFactory.createSqlType(
+                      typeFactory.createJavaType(java.sql.Timestamp.class).getSqlTypeName()),
+                  true);
+              break;
+            default:
+              System.out.println(""WARNING: Found unknown type: ""","[{'comment': 'I think this should be converted into a logging statement as opposed to a system.out (I know it was here before this change but we should clean this kind of thing up when working on the code.)', 'commenter': 'jacques-n'}, {'comment': 'Done.', 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -130,30 +129,108 @@ public static RelDataType deduceRowType(JavaTypeFactory typeFactory,
       }
       for (String string : strings) {
         final String name;
-        final CsvFieldType fieldType;
+        final RelDataType fieldType;
         final int colon = string.indexOf(':');
         if (colon >= 0) {
           name = string.substring(0, colon);
           String typeString = string.substring(colon + 1);
-          fieldType = CsvFieldType.of(typeString);
-          if (fieldType == null) {
-            System.out.println(""WARNING: Found unknown type: ""
-                + typeString + "" in file: "" + source.path()
-                + "" for column: "" + name
-                + "". Will assume the type of column is string"");
+          Matcher decimalMatcher = DECIMAL_TYPE_PATTERN.matcher(typeString);
+          if (decimalMatcher.matches()) {
+            int precision = Integer.parseInt(decimalMatcher.group(1));
+            int scale = Integer.parseInt(decimalMatcher.group(2));
+            fieldType = typeFactory.createTypeWithNullability(typeFactory
+                .createSqlType(SqlTypeName.DECIMAL,
+                    precision, scale), true);
+          } else {
+            switch (typeString) {
+            case ""string"":
+              fieldType = typeFactory.createTypeWithNullability(typeFactory
+                      .createSqlType(typeFactory.createJavaType(String.class).getSqlTypeName()),
+                  true);
+              break;
+            case ""boolean"":
+              fieldType = typeFactory.createTypeWithNullability(","[{'comment': 'This pattern seems very redundant. It seems like 99% of the time, the pattern is string => sqlTypeName (everything except decimal). Can your refactor to avoid all the repetition?', 'commenter': 'jacques-n'}, {'comment': 'Refactored to a helper method now.', 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -284,6 +361,17 @@ static CSVReader openCsv(Source source) throws IOException {
           return null;
         }
         return Double.parseDouble(string);
+      case DECIMAL:
+        if (string.length() == 0) {
+          return null;
+        }
+        BigDecimal result = new BigDecimal(string);
+        if (result.precision() > fieldType.getPrecision() || result.scale() != fieldType
+            .getScale()) {
+          throw new IllegalArgumentException(","[{'comment': 'Does throwing make sense here? Or should we coerce?', 'commenter': 'jacques-n'}, {'comment': 'Also, best to use string format for this kind of thing as opposed to string concatenation.', 'commenter': 'jacques-n'}, {'comment': ""Done. Based coercion on PostgreSQL's implementation https://www.postgresql.org/docs/13/datatype-numeric.html#DATATYPE-NUMERIC-DECIMAL."", 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -130,30 +137,70 @@ public static RelDataType deduceRowType(JavaTypeFactory typeFactory,
       }
       for (String string : strings) {
         final String name;
-        final CsvFieldType fieldType;
+        final RelDataType fieldType;
         final int colon = string.indexOf(':');
         if (colon >= 0) {
           name = string.substring(0, colon);
           String typeString = string.substring(colon + 1);
-          fieldType = CsvFieldType.of(typeString);
-          if (fieldType == null) {
-            System.out.println(""WARNING: Found unknown type: ""
-                + typeString + "" in file: "" + source.path()
-                + "" for column: "" + name
-                + "". Will assume the type of column is string"");
+          Matcher decimalMatcher = DECIMAL_TYPE_PATTERN.matcher(typeString);
+          if (decimalMatcher.matches()) {
+            int precision = Integer.parseInt(decimalMatcher.group(1));
+            int scale = Integer.parseInt(decimalMatcher.group(2));
+            fieldType = parseDecimalSqlType(typeFactory, precision, scale);
+          } else {
+            switch (typeString) {
+            case ""string"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.VARCHAR);
+              break;
+            case ""boolean"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.BOOLEAN);
+              break;
+            case ""byte"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.TINYINT);
+              break;
+            case ""char"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.CHAR);
+              break;
+            case ""short"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.SMALLINT);
+              break;
+            case ""int"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.INTEGER);
+              break;
+            case ""long"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.BIGINT);
+              break;
+            case ""float"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.REAL);
+              break;
+            case ""double"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.DOUBLE);
+              break;
+            case ""date"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.DATE);
+              break;
+            case ""timestamp"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.TIMESTAMP);
+              break;
+            case ""time"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.TIME);
+              break;
+            default:
+              LOGGER.warn(
+                  String.format(Locale.ROOT,
+                  ""Found unknown type: %s in file: %s for column: %s. Will assume the type of ""","[{'comment': 'when using a logger, you should use the loggers capability for value replacement as opposed to string format.', 'commenter': 'jacques-n'}, {'comment': 'Done.', 'commenter': 'xwkuang5'}, {'comment': ""Usually loggers use {}. Isn't that what should be used (instead of %s?)"", 'commenter': 'jacques-n'}, {'comment': 'Done. ', 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -130,30 +137,70 @@ public static RelDataType deduceRowType(JavaTypeFactory typeFactory,
       }
       for (String string : strings) {
         final String name;
-        final CsvFieldType fieldType;
+        final RelDataType fieldType;
         final int colon = string.indexOf(':');
         if (colon >= 0) {
           name = string.substring(0, colon);
           String typeString = string.substring(colon + 1);
-          fieldType = CsvFieldType.of(typeString);
-          if (fieldType == null) {
-            System.out.println(""WARNING: Found unknown type: ""
-                + typeString + "" in file: "" + source.path()
-                + "" for column: "" + name
-                + "". Will assume the type of column is string"");
+          Matcher decimalMatcher = DECIMAL_TYPE_PATTERN.matcher(typeString);
+          if (decimalMatcher.matches()) {
+            int precision = Integer.parseInt(decimalMatcher.group(1));
+            int scale = Integer.parseInt(decimalMatcher.group(2));
+            fieldType = parseDecimalSqlType(typeFactory, precision, scale);
+          } else {
+            switch (typeString) {
+            case ""string"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.VARCHAR);
+              break;
+            case ""boolean"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.BOOLEAN);
+              break;
+            case ""byte"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.TINYINT);
+              break;
+            case ""char"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.CHAR);
+              break;
+            case ""short"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.SMALLINT);
+              break;
+            case ""int"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.INTEGER);
+              break;
+            case ""long"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.BIGINT);
+              break;
+            case ""float"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.REAL);
+              break;
+            case ""double"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.DOUBLE);
+              break;
+            case ""date"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.DATE);
+              break;
+            case ""timestamp"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.TIMESTAMP);
+              break;
+            case ""time"":
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.TIME);
+              break;
+            default:
+              LOGGER.warn(
+                  String.format(Locale.ROOT,
+                  ""Found unknown type: %s in file: %s for column: %s. Will assume the type of ""
+                      + ""column is string."",
+                  typeString, source.path(), name));
+              fieldType = toNullableRelDataType(typeFactory, SqlTypeName.VARCHAR);","[{'comment': ""Shouldn't you set a max length on this varchar? (same for the one below)"", 'commenter': 'jacques-n'}, {'comment': ""The current code does not set a max on the varchar either. They used the default in the type system https://github.com/apache/calcite/blob/6d51d277b158ff7073f29ada4a96a7a74c0b46fc/core/src/main/java/org/apache/calcite/rel/type/RelDataTypeSystemImpl.java#L62.\r\n\r\nThis is a problem for file adapter since there is no validation for any of the types' precision during enumeration (except for the decimal type being added here). I think this should be addressed in a different PR."", 'commenter': 'xwkuang5'}, {'comment': 'makes sense.', 'commenter': 'jacques-n'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -314,22 +371,55 @@ static CSVReader openCsv(Source source) throws IOException {
         } catch (ParseException e) {
           return null;
         }
-      case STRING:
+      case VARCHAR:
       default:
         return string;
       }
     }
   }
 
+  private static RelDataType parseDecimalSqlType(JavaTypeFactory typeFactory, int precision,
+      int scale) {
+    if (scale < 0) {","[{'comment': 'It seems like you should do some other checks here as well. For example, can precision be negative? What are the requirements for a relationship between precision and scale?', 'commenter': 'jacques-n'}, {'comment': 'Done. The following should be enough:\r\n1. precision > 0: 0 has precision 1 and scale 0\r\n2. scale >= 0\r\n3. precision >= scale\r\n\r\n', 'commenter': 'xwkuang5'}, {'comment': 'Do you want to update these to use Preconditions? I think it has convenience methods to use format strings (although I think it simplifies to %s for everything).', 'commenter': 'jacques-n'}, {'comment': 'Done.', 'commenter': 'xwkuang5'}]"
2572,file/src/main/java/org/apache/calcite/adapter/file/CsvEnumerator.java,"@@ -314,22 +372,56 @@ static CSVReader openCsv(Source source) throws IOException {
         } catch (ParseException e) {
           return null;
         }
-      case STRING:
+      case VARCHAR:
       default:
         return string;
       }
     }
   }
 
+  private static RelDataType parseDecimalSqlType(JavaTypeFactory typeFactory, int precision,
+      int scale) {
+    checkArgument(precision > 0, ""DECIMAL type must have precision > 0. Found %s"", precision);
+    checkArgument(scale >= 0, ""DECIMAL type must have scale >= 0. Found %s"", scale);
+    checkArgument(precision >= scale,
+        ""DECIMAL type must have precision >= scale. Found precision (%s) and scale (%s)."",
+        precision, scale);
+    return typeFactory.createTypeWithNullability(
+        typeFactory.createSqlType(SqlTypeName.DECIMAL, precision, scale), true);
+  }
+
+  @VisibleForTesting
+  protected static BigDecimal parseDecimal(int precision, int scale, String string) {
+    BigDecimal result = new BigDecimal(string);
+    // If the parsed value has more fractional digits than the specified scale, round ties away
+    // from 0.
+    if (result.scale() > scale) {
+      LOGGER.warn(","[{'comment': 'This one is still using wrong pattern %s versus {}', 'commenter': 'jacques-n'}, {'comment': 'Oops, sorry I missed that. Corrected now. ', 'commenter': 'xwkuang5'}]"
2598,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -308,12 +308,20 @@ private static RexNode convertNvl(SqlRexContext cx, SqlCall call) {
         cx.convertExpression(call.getOperandList().get(1));
     final RelDataType type =
         cx.getValidator().getValidatedNodeType(call);
+    // Preserve Operand Nullability
     return rexBuilder.makeCall(type, SqlStdOperatorTable.CASE,
         ImmutableList.of(
             rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL,
                 operand0),
-            rexBuilder.makeCast(type, operand0),
-            rexBuilder.makeCast(type, operand1)));
+            rexBuilder.makeCast(
+                cx.getTypeFactory()
+                    .createTypeWithNullability(type, operand0.getType().isNullable()),
+                operand0),
+            rexBuilder.makeCast(
+                cx.getTypeFactory()
+                    .createTypeWithNullability(type, operand1.getType().isNullable()),
+                operand1)
+        ));
   }","[{'comment': 'Could you add a test case, @jaystarshot ?', 'commenter': 'chunweilei'}, {'comment': '@chunweilei  There is no method to test the Operands of an Operator in the test framework, I think I need to create a new one and/or test it as an integration test.', 'commenter': 'jaystarshot'}]"
2598,core/src/test/java/org/apache/calcite/sql/test/SqlOperatorBaseTest.java,"@@ -7202,6 +7218,41 @@ void assertSubFunReturns(boolean binary, String s, int start,
         ""nvl(CAST(NULL AS VARCHAR(6)), cast(NULL AS VARCHAR(4)))"");
   }
 
+
+  private RelNode transformSqlToRel(String sql) throws Exception {
+    final SchemaPlus rootSchema = Frameworks.createRootSchema(true);
+    final SchemaPlus defSchema = rootSchema.add(""hr"", new HrClusteredSchema());
+    final FrameworkConfig config = Frameworks.newConfigBuilder()
+        .parserConfig(SqlParser.Config.DEFAULT)
+        .defaultSchema(defSchema)
+        .traitDefs(ConventionTraitDef.INSTANCE, RelCollationTraitDef.INSTANCE)
+        .operatorTable(SqlLibraryOperatorTableFactory.INSTANCE
+            .getOperatorTable(SqlLibrary.STANDARD, SqlLibrary.ORACLE))
+        .build();
+    Planner planner = Frameworks.getPlanner(config);
+    SqlNode parse = planner.parse(sql);
+    SqlNode validate = planner.validate(parse);
+    RelRoot planRoot = planner.rel(validate);
+    return planRoot.rel;
+
+  }
+
+  @Test public void testNvlOperands() throws Exception {","[{'comment': ""The testNvlFunc has existed in SqlOperatorTest, If it doesn't have enough tests for you, please perfect it.\r\n\r\nIf this can't suit your need. You can add a SQL type test in .iq file."", 'commenter': 'NobiGo'}, {'comment': '@NobiGo The testNvlFunc tests the function output and not the operands, same with .iq tests. Am I missing something?', 'commenter': 'jaystarshot'}, {'comment': 'You can try to use !plan command in .iq file. Same as https://github.com/apache/calcite/blob/master/core/src/test/resources/sql/agg.iq#L1707 . This can suit your need?', 'commenter': 'NobiGo'}, {'comment': 'Maybe in SqlToRelConverterTest. I think this test case in here is not standard.', 'commenter': 'NobiGo'}, {'comment': 'Thanks @NobiGo. I am new here so when I run the tests in a .iq file I get \r\n`No match found for function signature NVL(<CHARACTER>, <CHARACTER>)` . I guess its because NVl is supported only for Oracle Operator Tables. Is there a way to load it in the .iq tests?', 'commenter': 'jaystarshot'}, {'comment': 'I tried to change org/apache/calcite/prepare/CalcitePrepareImpl.java:721 and added  oracle operators there and the test works fine\r\n```\r\nfinal SqlOperatorTable opTab0 =\r\n    context.config().fun(SqlOperatorTable.class,\r\n        SqlLibraryOperatorTableFactory.INSTANCE\r\n            .getOperatorTable(SqlLibrary.STANDARD, SqlLibrary.ORACLE));\r\n```\r\nBut i think we just want it configured for the Quidem tests and not in general.\r\n ', 'commenter': 'jaystarshot'}, {'comment': 'I noticed the changes in SQL to RelNode So maybe SqlToRelConverterTest(The test result in SqlToRelConverterTest.xml) is more appropriate. Of course, If you think .iq is enough for this, You can try` !use oraclefunc ` expamle as https://github.com/apache/calcite/blob/master/core/src/test/resources/sql/functions.iq#L83 .  ', 'commenter': 'NobiGo'}, {'comment': 'Thanks a lot! Yes I think .iq test is enough as we are able to verify the type of the operand using the plan', 'commenter': 'jaystarshot'}]"
2598,core/src/test/resources/sql/functions.iq,"@@ -179,5 +179,15 @@ SELECT EXISTSNODE(
 
 !ok
 
+# [CALCITE-4875] Preserve Operand Nullability in NVL rewrite
+# Asserting that NVL does not change a Nullable operand to NOT Nullable
+
+!use oraclefunc
+select nvl(""name"", 'undefined') FROM ""hr"".""emps"";
+
+EnumerableCalc(expr#0..4=[{inputs}], expr#5=[IS NOT NULL($t2)], expr#6=[CAST($t2):VARCHAR], expr#7=['undefined':VARCHAR], expr#8=[CASE($t5, $t6, $t7)], EXPR$0=[$t8])
+  EnumerableTableScan(table=[[hr, emps]])
+!plan","[{'comment': 'Can you add extra ` !ok` command to test the output?  Others is good for me.', 'commenter': 'NobiGo'}]"
2598,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -308,12 +308,20 @@ private static RexNode convertNvl(SqlRexContext cx, SqlCall call) {
         cx.convertExpression(call.getOperandList().get(1));
     final RelDataType type =
         cx.getValidator().getValidatedNodeType(call);
+    // Preserve Operand Nullability
     return rexBuilder.makeCall(type, SqlStdOperatorTable.CASE,
         ImmutableList.of(
             rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL,
                 operand0),
-            rexBuilder.makeCast(type, operand0),
-            rexBuilder.makeCast(type, operand1)));
+            rexBuilder.makeCast(
+                cx.getTypeFactory()
+                    .createTypeWithNullability(type, operand0.getType().isNullable()),
+                operand0),
+            rexBuilder.makeCast(
+                cx.getTypeFactory()","[{'comment': 'I agree that operand1 should keep its nullability. But operand0 would be not nullable after rewrite.', 'commenter': 'chunweilei'}, {'comment': '@chunweilei \r\n1) Consider If that operand0 depends on an input reference(which is nullable)\r\n2) If in future that operand pushed down like in [ProjectJoinTransposeRule](https://github.com/apache/calcite/blob/bebe473fab2e242736614659ed6e5d04eeeb8bf5/core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java), there will be an issue as the operand0 and its reference have different nullability.\r\n3) The output of the NVL operation is Not Null but there is no need to change the nullability of the operands as in calcite rules we might push the operands down in some rules causing errors ( operand referenced input type is nullable whereas we forced the operand to be not Null)\r\nAlso I agree that NVL output should be not Nullable but that does not mean that operand0 should be not nullable as operand0 is not the output of the NVL function (its just an operand).\r\n\r\nTLDR: My point is to not force nullability on the input operands by the output of the NVL operation as by definition the function NVL(a, b) only outputs b if a is NULL, so it should handle output Nullability accordingly  however it should not change the nullability of a as a might be a reference field which is indeed nullable.\r\n\r\nDo you think hence it makes sense to let the operand nullability what it was as the output is anyway not nullable?', 'commenter': 'jaystarshot'}, {'comment': '@chunweilei NVL(null, null) is valid sql.', 'commenter': 'jamesstarr'}, {'comment': 'The return type should also be nullable if both inputs are nullable.', 'commenter': 'jamesstarr'}, {'comment': ""`\r\nselect nvl(“name”, “name”) FROM “hr”.“emps”;\r\n`\r\nFor this query the output type was indeed nullable (name col is nullable) so doesn't seem like an issue."", 'commenter': 'jaystarshot'}, {'comment': 'Got it! Thank you for your explanation.', 'commenter': 'chunweilei'}]"
2607,core/src/test/resources/sql/sub-query.iq,"@@ -3306,4 +3306,28 @@ EnumerableCalc(expr#0..7=[{inputs}], expr#8=[7782], expr#9=[CAST($t0):INTEGER NO
   EnumerableTableScan(table=[[scott, EMP]])
 !plan
 
+# [CALCITE-4846] IN-list that includes NULL converted to Values throws exception
+
+select * from ""scott"".emp where empno not in (null, 7782);
++-------+-------+-----+-----+----------+-----+------+--------+
+| EMPNO | ENAME | JOB | MGR | HIREDATE | SAL | COMM | DEPTNO |
++-------+-------+-----+-----+----------+-----+------+--------+
++-------+-------+-----+-----+----------+-----+------+--------+
+(0 rows)
+
+!ok
+
+EnumerableCalc(expr#0..12=[{inputs}], expr#13=[0:BIGINT], expr#14=[=($t8, $t13)], expr#15=[IS NULL($t12)], expr#16=[>=($t9, $t8)], expr#17=[AND($t15, $t16)], expr#18=[OR($t14, $t17)], proj#0..7=[{exprs}], $condition=[$t18])
+  EnumerableMergeJoin(condition=[=($10, $11)], joinType=[left])
+    EnumerableSort(sort0=[$10], dir0=[ASC])
+      EnumerableCalc(expr#0..9=[{inputs}], proj#0..9=[{exprs}], EMPNO0=[$t0])
+        EnumerableNestedLoopJoin(condition=[true], joinType=[inner])
+          EnumerableTableScan(table=[[scott, EMP]])
+          EnumerableAggregate(group=[{}], agg#0=[COUNT()], agg#1=[COUNT($0)])
+            EnumerableValues(tuples=[[{ null }, { 7782 }]])
+    EnumerableSort(sort0=[$0], dir0=[ASC])
+      EnumerableCalc(expr#0=[{inputs}], expr#1=[true], proj#0..1=[{exprs}])
+        EnumerableValues(tuples=[[{ null }, { 7782 }]])","[{'comment': 'The plan looks strange. Why are two joins are present here?\r\n\r\nIf that join duplication is not related to the fix, then I would suggest adding a comment and filing a JIRA ticket.\r\nOtherwise, it looks like a bug.', 'commenter': 'vlsi'}, {'comment': 'If I remembered it correctly, Calcite unnest NOT IN subquery to 2 joins, that is how it deals with NOT IN currently. :(', 'commenter': 'hsyuan'}, {'comment': 'The Join duplication is not related to the fix. When I try to execute:\r\n`select * from ""scott"".emp where (empno, deptno) not in ((7369, 20), (7499, 30));`\r\nThis SQL also has two joins. And return the right answer. So I think this is the right logic. (Unless we find a wrong unit test).', 'commenter': 'NobiGo'}, {'comment': 'When values are non-nullable, then the double join is not really needed. A single anti-join should be enough.\r\nI have filed https://issues.apache.org/jira/browse/CALCITE-4889', 'commenter': 'vlsi'}]"
2607,core/src/test/resources/sql/sub-query.iq,"@@ -3306,4 +3306,28 @@ EnumerableCalc(expr#0..7=[{inputs}], expr#8=[7782], expr#9=[CAST($t0):INTEGER NO
   EnumerableTableScan(table=[[scott, EMP]])
 !plan
 
+# [CALCITE-4846] IN-list that includes NULL converted to Values throws exception
+
+select * from ""scott"".emp where empno not in (null, 7782);","[{'comment': 'just wondering if `(empno, depnto) in ((1,2), (3, null))` work or not. Do you think it is worth adding a test like that?', 'commenter': 'vlsi'}, {'comment': 'Yes. I have added it.', 'commenter': 'NobiGo'}]"
2609,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -1881,6 +1881,31 @@ private void checkHavingAliasSameAsColumn(boolean upperAlias) {
     relFn(relFn).ok(expectedSql);
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-4876"">[CALCITE-4876]
+   * Converting RelNode to SQL with CalciteSqlDialect gets wrong result
+   * while EnumerableIntersect is followed by EnumerableLimit.</a>.","[{'comment': ""Please remove the redundant  '.'  after the EnumerableLimit."", 'commenter': 'NobiGo'}, {'comment': ""OK, I've removed it."", 'commenter': 'ILuffZhe'}]"
2615,core/src/main/java/org/apache/calcite/sql/validate/implicit/TypeCoercionImpl.java,"@@ -104,14 +104,17 @@ public TypeCoercionImpl(RelDataTypeFactory typeFactory, SqlValidator validator)
       updateInferredColumnType(scope1, query, columnIndex, targetType);
       return true;
     case VALUES:
+      boolean coercedValues = true;
       for (SqlNode rowConstructor : ((SqlCall) query).getOperandList()) {
         if (!coerceOperandType(scope, (SqlCall) rowConstructor, columnIndex, targetType)) {
-          return false;
+          coercedValues = false;
         }
       }
-      updateInferredColumnType(
-          requireNonNull(scope, ""scope""), query, columnIndex, targetType);
-      return true;
+      if (coercedValues) {
+        updateInferredColumnType(
+            requireNonNull(scope, ""scope""), query, columnIndex, targetType);","[{'comment': ""What's the difference here ? The original code does the same behavior: `#updateInferredColumnType` only if all the operands are coerced."", 'commenter': 'danny0405'}, {'comment': 'I thought so at first. But many test will be failed, for example:\r\n```\r\n sql(""select 1 from (values(true)) union values (select \'1\' from (values (true)) as tt)"")\r\n        .type(""RecordType(VARCHAR EXPR$0) NOT NULL"");\r\n```\r\n```\r\norg.opentest4j.AssertionFailedError: expected: <RecordType(VARCHAR EXPR$0) NOT NULL> \r\nbut was: <RecordType(VARCHAR NOT NULL EXPR$0) NOT NULL>\r\n```\r\nI think it is only executed when coerced values is true, like the following code\r\n```      \r\n// Update the nested SET operator node type.\r\nif (coerced) {\r\n  updateInferredColumnType(\r\n      requireNonNull(scope, ""scope""), query, columnIndex, targetType);\r\n}\r\n```', 'commenter': 'JiajunBernoulli'}, {'comment': ""> org.opentest4j.AssertionFailedError: expected: <RecordType(VARCHAR EXPR$0) NOT NULL> \r\nbut was: <RecordType(VARCHAR NOT NULL EXPR$0) NOT NULL>\r\n\r\nShouldn't this be the correct behavior ? Two constant literals are type nullable false, and implicit type coercion does not solve nullability in-consistency."", 'commenter': 'danny0405'}, {'comment': 'I modified the expected values of failed unit tests. They should all be not null. Are there any other questions?', 'commenter': 'JiajunBernoulli'}]"
2615,core/src/main/java/org/apache/calcite/sql/validate/implicit/TypeCoercionImpl.java,"@@ -121,8 +124,8 @@ public TypeCoercionImpl(RelDataTypeFactory typeFactory, SqlValidator validator)
       // Set operations are binary for now.
       final SqlCall operand0 = ((SqlCall) query).operand(0);
       final SqlCall operand1 = ((SqlCall) query).operand(1);
-      final boolean coerced = rowTypeCoercion(scope, operand0, columnIndex, targetType)
-          && rowTypeCoercion(scope, operand1, columnIndex, targetType);
+      boolean coerced = rowTypeCoercion(scope, operand0, columnIndex, targetType);","[{'comment': 'Change `&&` directly to `||` ?', 'commenter': 'danny0405'}, {'comment': 'This will not fix the problem. Because when `rowTypeCoercion(scope, operand0, columnIndex, targetType)=true`,  `rowTypeCoercion(scope, operand1, columnIndex, targetType) `will not be run.\r\nI will use `|`, do you agree?\r\n```\r\nfinal boolean coerced = rowTypeCoercion(scope, operand0, columnIndex, targetType)\r\n    | rowTypeCoercion(scope, operand1, columnIndex, targetType);\r\n```', 'commenter': 'JiajunBernoulli'}, {'comment': 'Yeah, you code is correct, we should not add any short-cut logic here.', 'commenter': 'danny0405'}, {'comment': 'done', 'commenter': 'JiajunBernoulli'}]"
2615,core/src/test/java/org/apache/calcite/test/TypeCoercionTest.java,"@@ -894,6 +894,13 @@ public MockCatalogReader init() {
       t2.addColumn(""t2_binary"", binaryType);
       t2.addColumn(""t2_boolean"", booleanType);
       registerTable(t2);
+
+      final MockTable t3 =
+          MockTable.create(this, tSchema, ""T3"", false, 7.0, null);
+      t3.addColumn(""t3_varchar20"", varchar20Type);
+      t3.addColumn(""t3_int"", intType);","[{'comment': ""Why add a new table here ? 't1' and 't2' have all the data types you needed."", 'commenter': 'danny0405'}, {'comment': ""I'm worried that too **many columns** will affect everyone's reading, so I only use **a few columns.** If you think it is more appropriate to use the existing table, I can change it later."", 'commenter': 'JiajunBernoulli'}, {'comment': ""Yeah, i'm sliding to reuse the original tables."", 'commenter': 'danny0405'}, {'comment': 'I deleted `t3` and used `t1`.', 'commenter': 'JiajunBernoulli'}]"
2615,core/src/test/java/org/apache/calcite/test/TypeCoercionConverterTest.java,"@@ -133,4 +162,24 @@
   private void checkPlanEquals(String sql) {
     tester.assertConvertsTo(sql, ""${plan}"");
   }
+
+  private void checkValidateSqlEquals(String sql) {
+    Objects.requireNonNull(sql, ""sql"");
+    final SqlNode sqlQuery;
+    try {
+      sqlQuery = tester.parseQuery(sql);
+    } catch (RuntimeException | Error e) {
+      throw e;
+    } catch (Exception e) {
+      throw TestUtil.rethrow(e);
+    }
+    final RelDataTypeFactory typeFactory = tester.getValidator().getTypeFactory();
+    final Prepare.CatalogReader catalogReader =
+        tester.createCatalogReader(typeFactory);
+    final SqlValidator validator =
+        tester.createValidator(catalogReader, typeFactory);
+
+    final String actual = validator.validate(sqlQuery).toString();","[{'comment': 'Somehow we need some refactoring for this testing infrustructure, for e.g, a `Sql` util, we can do that in another PR.', 'commenter': 'danny0405'}, {'comment': ""I'm interested in it. `checkValidateSqlEquals` function can be abstracted. \r\nDo you think it's more appropriate to put it in the parent class `SqlToRelTestBase` or create an interface `SqlToValidateTestBase`?"", 'commenter': 'JiajunBernoulli'}, {'comment': '@JiajunBernoulli , have you seen https://lists.apache.org/thread/3l9y4fv31kthmpn9pbzqdmfp80yrjphf by @julianhyde ?', 'commenter': 'vlsi'}, {'comment': ""I didn't know before. I will continue to pay attention to it"", 'commenter': 'JiajunBernoulli'}]"
2615,core/src/test/java/org/apache/calcite/test/TypeCoercionConverterTest.java,"@@ -133,4 +172,24 @@
   private void checkPlanEquals(String sql) {
     tester.assertConvertsTo(sql, ""${plan}"");
   }
+
+  private void checkValidateSqlEquals(String sql) {
+    Objects.requireNonNull(sql, ""sql"");
+    final SqlNode sqlQuery;
+    try {
+      sqlQuery = tester.parseQuery(sql);
+    } catch (RuntimeException | Error e) {
+      throw e;
+    } catch (Exception e) {
+      throw TestUtil.rethrow(e);","[{'comment': 'Consider using `catch(Throwable e) { TestUtil.rethrow(e, ""sql="" + sql) }`\r\nThat would be shorter, it would catch all throwables, and it would add the SQL in question', 'commenter': 'vlsi'}, {'comment': 'I have modified it, thank you very much for your advice.', 'commenter': 'JiajunBernoulli'}]"
2615,core/src/main/java/org/apache/calcite/sql/validate/implicit/TypeCoercionImpl.java,"@@ -121,8 +122,9 @@ public TypeCoercionImpl(RelDataTypeFactory typeFactory, SqlValidator validator)
       // Set operations are binary for now.
       final SqlCall operand0 = ((SqlCall) query).operand(0);
       final SqlCall operand1 = ((SqlCall) query).operand(1);
-      final boolean coerced = rowTypeCoercion(scope, operand0, columnIndex, targetType)
-          && rowTypeCoercion(scope, operand1, columnIndex, targetType);
+      @SuppressWarnings(""ShortCircuitBoolean"")
+      boolean coerced = rowTypeCoercion(scope, operand0, columnIndex, targetType)
+          | rowTypeCoercion(scope, operand1, columnIndex, targetType);
       // Update the nested SET operator node type.","[{'comment': 'We should not use `|` in the logical operator.', 'commenter': 'danny0405'}, {'comment': ""I didn't find a more suitable way, just modify the original code."", 'commenter': 'JiajunBernoulli'}]"
2680,core/src/test/java/org/apache/calcite/test/RelMetadataTest.java,"@@ -562,6 +562,17 @@ private void checkTwoColumnOrigin(
         true, metadataConfig);
   }
 
+  @ParameterizedTest
+  @MethodSource(""getArguments"") void testColumnOriginsSnapshot(
+      final MetadataConfig metadataConfig) {
+    checkSingleColumnOrigin(
+        ""select productid from products_temporal ""","[{'comment': 'Please reformat the SQL use line breaking', 'commenter': 'NobiGo'}, {'comment': 'Done', 'commenter': 'lmagic233'}]"
2686,core/src/test/resources/org/apache/calcite/test/RelOptRulesTest.xml,"@@ -9004,6 +9005,38 @@ LogicalProject(EXPR$0=[$1], EXPR$1=[$0])
           LogicalTableScan(table=[[CATALOG, SALES, EMP]])
         LogicalProject(ENAME=[$0])
           LogicalTableScan(table=[[CATALOG, SALES, BONUS]])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name=""testPushProjectPastLeftJoin2"">
+    <Resource name=""sql"">
+      <![CDATA[select coalesce(d.name, b.job, '')
+from emp e
+left join bonus b on e.ename = b.ename
+left join dept d on e.deptno = d.deptno]]>
+    </Resource>
+    <Resource name=""planBefore"">
+      <![CDATA[
+LogicalProject(EXPR$0=[CASE(IS NOT NULL($14), CAST($14):VARCHAR(10) NOT NULL, IS NOT NULL($10), CAST($10):VARCHAR(10) NOT NULL, '':VARCHAR(10))])
+  LogicalJoin(condition=[=($7, $13)], joinType=[left])
+    LogicalJoin(condition=[=($1, $9)], joinType=[left])
+      LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+      LogicalTableScan(table=[[CATALOG, SALES, BONUS]])
+    LogicalTableScan(table=[[CATALOG, SALES, DEPT]])
+]]>
+    </Resource>
+    <Resource name=""planAfter"">
+      <![CDATA[
+LogicalProject(EXPR$0=[CASE(IS NOT NULL($4), CAST($4):VARCHAR(10) NOT NULL, $1, $2, '':VARCHAR(10))])
+  LogicalJoin(condition=[=($0, $3)], joinType=[left])
+    LogicalProject(DEPTNO=[$1], EXPR$0=[IS NOT NULL($3)], EXPR$1=[CAST($3):VARCHAR(10) NOT NULL])","[{'comment': ""@wojustme If the $3 is NULL, then what will happen in `EXPR$1=[CAST($3):VARCHAR(10) NOT NULL])`? Because the EXPR1 will execute any time. right? \r\nBut  the plan bafore, when we confirm $3 is not NULL, we will to calcute `[CAST($3):VARCHAR(10) NOT NULL])`,\r\nSo please try when job include NULL value not just claim this filed can NULL, Plase check the data, I don't know, Just want to confirm."", 'commenter': 'NobiGo'}, {'comment': ""@NobiGo \r\nIt's good question for me. \r\nIn my project, we use calcite as an sql-proxy, and send dialectal sql to various query engine.\r\n`EXPR$1=[CAST($3):VARCHAR(10) NOT NULL])` will be translated to sql fragment of `CAST(job AS VARCHAR)`\r\nSo, I didn't pay attention to this problem. I try to find some codes or docs to explain this question.\r\n\r\nIn calcite's linq4j, `CAST($3):VARCHAR(10) NOT NULL` will be translated to `input_isNull0 ? (String) null : input_value0`\r\n\r\n"", 'commenter': 'wojustme'}, {'comment': ""Hi, Please try validate this SQL result in out.iq and submit the test in this PR? I don't know."", 'commenter': 'NobiGo'}, {'comment': ""Hi @NobiGo \r\nI debug the code`org.apache.calcite.adapter.enumerable.RexImpTable.AbstractRexCallImplementor#genValueStatement`, I found it's really handle it.\r\n`CAST xxx NOT NULL` will be translated to `input_isNull0 ?  null : input_value0`\r\n![image](https://user-images.githubusercontent.com/8967656/150818056-dfe709ca-d0c4-4018-a981-68eb1969d593.png)\r\n\r\n------\r\ncode: https://github.com/wojustme/calcite/commit/d1baa3d0a33dcd3402a6b886f88aa6442774bd5e"", 'commenter': 'wojustme'}]"
2686,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -157,7 +159,24 @@ public ProjectJoinTransposeRule(
   @Value.Immutable(singleton = false)
   public interface Config extends RelRule.Config {
     Config DEFAULT = ImmutableProjectJoinTransposeRule.Config.builder()
-        .withPreserveExprCondition(expr -> !(expr instanceof RexOver))
+        .withPreserveExprCondition(expr -> {
+          // Non push down over's expression by default","[{'comment': ""```suggestion\r\n          // Do not push down over's expression by default\r\n```"", 'commenter': 'libenchao'}, {'comment': 'kindly ping.', 'commenter': 'libenchao'}, {'comment': ""@wojustme Here is one missing comment which hasn't been addressed."", 'commenter': 'libenchao'}, {'comment': '@libenchao Thanks for your reminder, but I check this pr, and I found that I have update this code, screenshot as follows:\r\n![image](https://user-images.githubusercontent.com/8967656/198003453-016b8697-b580-4c8f-8448-46afcd2d10be.png)\r\n', 'commenter': 'wojustme'}, {'comment': ""It's in different line, I'm saying line 163"", 'commenter': 'libenchao'}, {'comment': ""I'm sorry for it.\r\nPlease review it, thanks a lot.\r\n@libenchao "", 'commenter': 'wojustme'}]"
2686,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -157,7 +159,24 @@ public ProjectJoinTransposeRule(
   @Value.Immutable(singleton = false)
   public interface Config extends RelRule.Config {
     Config DEFAULT = ImmutableProjectJoinTransposeRule.Config.builder()
-        .withPreserveExprCondition(expr -> !(expr instanceof RexOver))
+        .withPreserveExprCondition(expr -> {
+          // Non push down over's expression by default
+          if (expr instanceof RexOver) {
+            return false;
+          }
+          final RelDataType relType = expr.getType();
+          if (SqlKind.CAST == expr.getKind()) {
+            final RexCall castCall = (RexCall) expr;
+            final RelDataType operand0Type = castCall.getOperands().get(0).getType();
+            if (relType.getSqlTypeName() == operand0Type.getSqlTypeName()
+                && relType.isNullable() != operand0Type.isNullable()) {","[{'comment': 'casting `not null` to `nullable` could be pushed down?', 'commenter': 'libenchao'}]"
2686,core/src/main/java/org/apache/calcite/rel/rules/ProjectJoinTransposeRule.java,"@@ -157,7 +159,24 @@ public ProjectJoinTransposeRule(
   @Value.Immutable(singleton = false)
   public interface Config extends RelRule.Config {
     Config DEFAULT = ImmutableProjectJoinTransposeRule.Config.builder()
-        .withPreserveExprCondition(expr -> !(expr instanceof RexOver))
+        .withPreserveExprCondition(expr -> {
+          // Do not push down over's expression by default
+          if (expr instanceof RexOver) {
+            return false;
+          }
+          final RelDataType relType = expr.getType();","[{'comment': 'move this into to `if` branch', 'commenter': 'libenchao'}, {'comment': ""Hi @libenchao \r\nI have moved this code into `else` branch, I guess this's your suggestion."", 'commenter': 'wojustme'}, {'comment': ""Sorry that I was not clear enough on this. I mean:\r\n```java\r\n          if (expr instanceof RexOver) {\r\n            return false;\r\n          }\r\n          if (SqlKind.CAST == expr.getKind()) {\r\n            final RelDataType relType = expr.getType();\r\n            final RexCall castCall = (RexCall) expr;\r\n            final RelDataType operand0Type = castCall.getOperands().get(0).getType();\r\n            if (relType.getSqlTypeName() == operand0Type.getSqlTypeName()\r\n                && operand0Type.isNullable() && !relType.isNullable()) {\r\n              // Do not push down not nullable cast's expression with the same type by default\r\n              // eg: CAST($1):VARCHAR(10) NOT NULL, and type of $1 is nullable VARCHAR(10)\r\n              return false;\r\n            }\r\n          }\r\n```"", 'commenter': 'libenchao'}, {'comment': 'Got it, and pr has been updated.\r\nPlease review it.\r\n@libenchao ', 'commenter': 'wojustme'}]"
2692,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -706,4 +707,17 @@ private SqlLibraryOperators() {
   @LibraryOperator(libraries = { POSTGRESQL })
   public static final SqlOperator INFIX_CAST =
       new SqlCastOperator();
+
+  /** Null-safe ""&lt;=&gt;"" equal operator used by MySQL, for example
+   * {@code 1<=>NULL}. */
+  @LibraryOperator(libraries = { MYSQL })
+  public static final SqlOperator NULL_SAFE_EQUAL =","[{'comment': 'I think The NULL_SAFE_EQUAL **is** IS_NOT_DISTINCT_FROM. Not belong to. So\r\n\r\n```\r\npublic static final SqlOperator NULL_SAFE_EQUAL = SqlStdOperatorTable.IS_NOT_DISTINCT_FROM;\r\n```\r\nright ?', 'commenter': 'NobiGo'}, {'comment': ""@NobiGo \r\nYes, you are right.\r\nBut I need change operator's name to '<=>', so, I create an object of 'SqlBinaryOperator' to define Operator of '<=>'.\r\nThanks."", 'commenter': 'wojustme'}, {'comment': ""Why do we need to change the operator's name? If we use the SqlStdOperatorTable.IS_NOT_DISTINCT_FROM directly, Then can support parse and execute. Now only can support parse. If I miss something please let me know. \r\nand Add another parse test cases for `(a, b) <=> (x, y)`"", 'commenter': 'NobiGo'}, {'comment': ""@NobiGo \r\nWhen using SqlStdOperatorTable#IS_NOT_DISTINCT_FROM, '`X` <=> 3' will return '`X` IS NOT DISTINCT FROM 3'.\r\nI think it destroys the user's original input.\r\n\r\nBy the way, I didn't know why we need the test of `(a, b) <=> (x, y)` .\r\nPlease point me, Thanks."", 'commenter': 'wojustme'}, {'comment': ""According to [MySQL '<=>'](https://dev.mysql.com/doc/refman/8.0/en/comparison-operators.html#operator_equal-to) . We should cover it."", 'commenter': 'NobiGo'}, {'comment': ""Please don't force fush commit, until we have a final state. "", 'commenter': 'NobiGo'}, {'comment': ""@NobiGo \r\n\r\nOk, got it.\r\nIn my project, I didn't meet these complex scenes.\r\nI will add some related test cases.\r\nThanks a lot.\r\n\r\nI debug it, I found realizing `(a, b) <=> (x, y)` in current framework of binaryOperatorsTokens is too difficult.\r\n`(a, b) <=> (x, y)` will parse to `ROW(a, b) <=> ROW(x, y)`, is it the correct semantics?\r\nSo, should me define a scalable token to support `(a, b) <=> (x, y)`?\r\n"", 'commenter': 'wojustme'}]"
2692,babel/src/test/java/org/apache/calcite/test/BabelParserTest.java,"@@ -261,6 +261,15 @@ private void checkParseInfixCast(String sqlType) {
     sql(sql).ok(expected);
   }
 
+  /** Tests parsing MySQL-style ""<=>"" equal operator. */
+  @Test void testParseNullSafeEqual()  {
+    String sql = ""SELECT x <=> 3 FROM (VALUES (1, 2)) as tbl(x,y)"";
+    String expected = """"","[{'comment': 'Please reformat the SQL.', 'commenter': 'NobiGo'}, {'comment': 'Got it. I have updated.', 'commenter': 'wojustme'}]"
2692,site/_docs/reference.md,"@@ -2513,6 +2515,7 @@ semantics.
 | C | Operator syntax                                | Description
 |:- |:-----------------------------------------------|:-----------
 | p | expr :: type                                   | Casts *expr* to *type*
+| m | expr1 <=> expr2                                | Whether *expr1* equal to *expr2*, but returns true if both operands are `NULL`, and false if one operand is `NULL` (similar to `IS NOT DISTINCT FROM`)","[{'comment': 'equals to ?', 'commenter': 'NobiGo'}]"
2692,site/_docs/reference.md,"@@ -1203,13 +1203,13 @@ The operator precedence and associativity, highest to lowest.
 | * / % &#124;&#124;                                | left
 | + -                                               | left
 | BETWEEN, IN, LIKE, SIMILAR, OVERLAPS, CONTAINS etc. | -
-| < > = <= >= <> !=                                 | left
+| < > = <= >= <> != <=>                                | left","[{'comment': 'Please trims extra spaces？ The left value has translation.', 'commenter': 'NobiGo'}, {'comment': 'ok, I format it.', 'commenter': 'wojustme'}]"
2698,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTransport.java,"@@ -224,6 +224,16 @@ void closeScroll(Iterable<String> scrollIds) {
       return rawHttp(ElasticsearchJson.Result.class).apply(post);
     };
   }
+  
+  
+
+  @Override
+  protected void finalize() throws Throwable {","[{'comment': ""Finalizers are a java concept that is strongly discouraged for quite some time now. Moreover, they are going to [disappear soon](https://www.youtube.com/watch?v=eDgBnjOid-g) so let's find another way to handle this."", 'commenter': 'zabetak'}, {'comment': '[JEP 421: Deprecate Finalization for Removal](https://openjdk.java.net/jeps/421?continueFlag=abef66f10493295d8376160baf41892b) This address have some way to replace the finalize method and Why we should avoid using it. I hope it can help.', 'commenter': 'NobiGo'}]"
2698,elasticsearch/src/test/java/org/apache/calcite/adapter/elasticsearch/ElasticSearchAdapterTest.java,"@@ -105,7 +105,7 @@ private static Connection createConnection() throws SQLException {
         connection.unwrap(CalciteConnection.class).getRootSchema();
 
     root.add(""elastic"",
-        new ElasticsearchSchema(NODE.restClient(), NODE.mapper(), ZIPS));
+             new ElasticsearchSchema(NODE.clientBuilder(), NODE.mapper(), ZIPS));","[{'comment': 'Please check the indent here, so does somewhere else.', 'commenter': 'ILuffZhe'}]"
2698,elasticsearch/src/test/java/org/apache/calcite/adapter/elasticsearch/EmbeddedElasticsearchPolicy.java,"@@ -192,19 +201,18 @@ ObjectMapper mapper() {
    * Low-level http rest client connected to current embedded elastic search instance.
    * @return http client connected to ES cluster
    */
-  RestClient restClient() {
-    if (client != null) {
-      return client;
+  synchronized RestClientBuilder clientBuilder() {","[{'comment': 'Do we need a synchronized here?', 'commenter': 'ILuffZhe'}]"
2698,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchTransport.java,"@@ -279,22 +276,25 @@ private Response applyInternal(final HttpRequest request)
           request.getRequestLine().getMethod(),
           request.getRequestLine().getUri());
       r.setEntity(entity);
-      final Response response = restClient.performRequest(r);
 
-      final String payload = entity != null && entity.isRepeatable()
-          ? EntityUtils.toString(entity) : ""<empty>"";
+      try (RestClient restClient = clientBuilder.build()) {","[{'comment': ""If I understand this correctly, for each unit test, we will create a new RestClient to request, which is what you mentioned.\r\n\r\n- In my team, we manage the RestClients by Cache(for lifecycle and something else). Since it is actual business related, we might don't make it here\r\n- For unit tests, I'm wandering if there is a suitable way to manage the RestClient in BeforeClass and AfterClass. Just my personal opinion."", 'commenter': 'ILuffZhe'}]"
2698,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -53,6 +60,24 @@
 
   private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchSchemaFactory.class);
 
+  // RestClient objects allocate system resources and are thread safe. Here, we
+  // cache them using a key derived from the hashCode()s of the parameters that
+  // define a RestClient.
+  private static Cache<Integer, RestClient> restClients = CacheBuilder.newBuilder()
+      .maximumSize(1000)","[{'comment': 'Do you ever test the pool size and expireTime in your own project?(No leak problem?) Or, how do you choose them?', 'commenter': 'ILuffZhe'}, {'comment': '@ILuffZhe the choices were just made conservatively (no one will connect to more than 1000 ElasticSearch servers and replacing each RestClient at most hourly will not amount to a great load.  Testing a custom build of Drill based on a custom build of Calcite would be quite lot of effort for us so can I propose that a first PR just aims to stop the resource leaking?  We can then monitor it for an extended period in one of our Drill environments and report back to you with our data if it looks like these parameters need fine tuning.', 'commenter': 'jnturton'}, {'comment': ""Thanks for the clarification. I think this PR is better than the former one(as far as I can remember).\r\nIt's better not to force push before the final decision, so other reviewers can take a look."", 'commenter': 'ILuffZhe'}, {'comment': 'What happens if after one hour the client is removed and closed but there is still an active reference inside the `ElasticsearchSchema`?', 'commenter': 'zabetak'}, {'comment': '@zabetak thank you, that is indeed a mistake.  The ElasticsearchSchema must either be made to either only obtain a rest client from the cache (remove its own reference) or the cache expiry should be set to ""never"" which is the approach in the Cassandra adapter.  Which is preferred?', 'commenter': 'jnturton'}, {'comment': 'Resolved, somewhat.  Clients can still be removed and closed but only if their total number has reached an excessive number, not because of any configured expiry time.  A warning that trouble has begun is logged.  Note that if the clients were not removed and closed and no warning was logged then trouble would nevertheless have begun because the application was heading down the road to getting killed for leaking resources.', 'commenter': 'jnturton'}]"
2698,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -53,6 +60,24 @@
 
   private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchSchemaFactory.class);
 
+  // RestClient objects allocate system resources and are thread safe. Here, we
+  // cache them using a key derived from the hashCode()s of the parameters that
+  // define a RestClient.
+  private static Cache<Integer, RestClient> restClients = CacheBuilder.newBuilder()
+      .maximumSize(1000)
+      .expireAfterAccess(1, TimeUnit.HOURS)
+      .removalListener(new RemovalListener<Integer, RestClient>() {
+        public void onRemoval(RemovalNotification<Integer, RestClient> notice) {","[{'comment': 'Please check the CI.', 'commenter': 'ILuffZhe'}, {'comment': 'Thanks, fixing now...', 'commenter': 'jnturton'}]"
2698,elasticsearch/src/main/java/org/apache/calcite/adapter/elasticsearch/ElasticsearchSchemaFactory.java,"@@ -53,6 +60,24 @@
 
   private static final Logger LOGGER = LoggerFactory.getLogger(ElasticsearchSchemaFactory.class);
 
+  // RestClient objects allocate system resources and are thread safe. Here, we
+  // cache them using a key derived from the hashCode()s of the parameters that
+  // define a RestClient.
+  private static Cache<Integer, RestClient> REST_CLIENTS = CacheBuilder.newBuilder()","[{'comment': 'I’m surprised this isn’t final. ', 'commenter': 'julianhyde'}, {'comment': 'What are the consequences of a key collision?\r\n* if there are no consequences (I.e. a client can serve several servers) maybe we should use a pool or a singleton. \r\n* if the consequences are bad maybe we should not be using a hash key. ', 'commenter': 'julianhyde'}, {'comment': '@julianhyde in the latest push the member is final.  Also, these ES clients are dedicated to a single ES server so the consequences of a hash collision would indeed have been bad.  So the cache is no longer keyed on a hash.', 'commenter': 'jnturton'}]"
2710,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -725,6 +725,11 @@ public boolean supportsAggregateFunction(SqlKind kind) {
     return false;
   }
 
+  /** Returns whether this dialect supports APPROX_COUNT_DISTINCT functions)}. */","[{'comment': 'Please remove the redundant brackets.', 'commenter': 'NobiGo'}, {'comment': 'done', 'commenter': 'JiajunBernoulli'}]"
2710,core/src/main/java/org/apache/calcite/sql/SqlDialectFactoryImpl.java,"@@ -221,6 +221,8 @@
       return VerticaSqlDialect.DEFAULT;
     case SPARK:
       return SparkSqlDialect.DEFAULT;
+    case SNOWFLAKE:","[{'comment': 'Alphabetic order? Looks the SPARK out of position too? ', 'commenter': 'NobiGo'}, {'comment': ""Good advice, I've changed it."", 'commenter': 'JiajunBernoulli'}]"
2710,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -6043,6 +6043,25 @@ private void checkLiteral2(String expression, String expected) {
     sql.ok(expected);
   }
 
+  @Test void testSelectApproxCountDistinct() {
+    final String query = ""select approx_count_distinct(\""product_id\"") from \""product\"""";
+    final String expectedAccurate = ""SELECT COUNT(DISTINCT \""product_id\"")\n""","[{'comment': 'Nitpick: not a native speaker here, but I think that the opposite of ""approximate"" is ""exact"" here', 'commenter': 'asolimando'}, {'comment': ""You're right. I'll pay attention later, but I won't change it this time.\r\n**Accurate** and **Exact** are synonymous, so they do not affect understanding. \r\n"", 'commenter': 'JiajunBernoulli'}, {'comment': 'I changed the word by the way when I rebase.', 'commenter': 'JiajunBernoulli'}]"
2718,core/src/main/java/org/apache/calcite/rel/metadata/MetadataDef.java,"@@ -41,7 +42,10 @@ private MetadataDef(Class<M> metadataClass,
     this.handlerClass = handlerClass;
     this.methods = ImmutableList.copyOf(methods);
     final Method[] handlerMethods = Arrays.stream(handlerClass.getDeclaredMethods())
-        .filter(m -> !m.getName().equals(""getDef"")).toArray(i -> new Method[i]);
+        .filter(m -> !m.getName().equals(""getDef""))","[{'comment': '@jacques-n it seems this filter was originally introduced via CALCITE-4929 (see [4ff5fa8](https://github.com/apache/calcite/commit/4ff5fa89c180ebc30d8fb324c2a50b0e9797b9ca) ), what do you think about the current patch?\r\nAlso, I noticed that in  CALCITE-4929 a similar filter was introduced in [RelMetadataHandlerGeneratorUtil.java](https://github.com/apache/calcite/commit/4ff5fa89c180ebc30d8fb324c2a50b0e9797b9ca#diff-b5bac3d2a905799f710aef8e5fd02dd659dc9e6e2c8e7b05ed0c34022025b8e1) , if we apply this patch, should we apply the change in both files too?', 'commenter': 'rubenada'}, {'comment': ""Yes, we should apply the same logic in both places. I was thinking that we should probably extract this to a utility method as opposed to continue duplication. As part of this, let's also add specific units tests which verify the utility method. You up for that @rpuch? "", 'commenter': 'jacques-n'}, {'comment': ""@jacques-n sure, I'll do it. Thank you guys for your suggestions."", 'commenter': 'rpuch'}, {'comment': 'Done', 'commenter': 'rpuch'}]"
2718,core/src/test/java/org/apache/calcite/rel/metadata/BlankMetadataHandler.java,"@@ -0,0 +1,23 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.metadata;
+
+/**
+ * A blank {@link MetadataHandler} that is used as a base for adding a synthetic method.
+ */
+interface BlankMetadataHandler extends MetadataHandler<TestMetadata> {","[{'comment': 'Can you move the test interfaces into the test class files?', 'commenter': 'jacques-n'}, {'comment': ""Moved `BlankMetadataHandler` into a test class.\r\n\r\n`TestMetadata` and `MetadataHandlerWithStaticMethod` are used by two distinct test classes, so they cannot be 'internalized' without fusing the test classes together. If your suggestion is to still fuse them, please elaborate what test structure you would prefer to see."", 'commenter': 'rpuch'}]"
2718,core/src/main/java/org/apache/calcite/rel/metadata/MetadataHandlerMethods.java,"@@ -0,0 +1,45 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.metadata;
+
+import java.lang.reflect.Method;
+import java.lang.reflect.Modifier;
+import java.util.Arrays;
+
+/**
+ * Utilities useful for obtaining handler methods from a {@link MetadataHandler} class.
+ */
+public class MetadataHandlerMethods {
+  /**
+   * Finds handler methods defined by a {@link MetadataHandler}. Static and synthetic methods
+   * are ignored.
+   *
+   * @param handlerClass the handler class to inspect
+   * @return handler methods
+   */
+  public static Method[] handlerMethods(Class<? extends MetadataHandler<?>> handlerClass) {","[{'comment': 'How about we put this as a static method on MetadataHandler instead of a separate class?', 'commenter': 'jacques-n'}, {'comment': 'Moved the method to `MetadataHandler` class', 'commenter': 'rpuch'}]"
2718,build.gradle.kts,"@@ -893,3 +893,7 @@ allprojects {
         }
     }
 }
+java {
+    sourceCompatibility = JavaVersion.VERSION_17","[{'comment': ""We shouldn't be changing this as part of this patch. (I didn't notice it before.)\r\n\r\nThe rest looks good."", 'commenter': 'jacques-n'}, {'comment': ""Oops, good catch. For some reason, it's already second time when this change was added. First time I noticed and reverted it, second time I didn't. I wonder whether it's added by an IDE (I use IntelliJ IDEA) or by some build script.\r\n\r\nAnyway, I removed the change. Could we please proceed?"", 'commenter': 'rpuch'}]"
2724,core/src/main/java/org/apache/calcite/sql/SqlUtil.java,"@@ -417,24 +418,52 @@ public static void unparseSqlIdentifierSyntax(
     writer.endList(frame);
   }
 
+  private static void unparseSetOpSyntax(","[{'comment': ""It's not obvious what this method does. Can you add brief javadoc."", 'commenter': 'julianhyde'}, {'comment': ""why is the function named `unparseSetOpSyntax`? The `Syntax` seems redundant, in which case it would be `unparseSetOp`. But then I see that it's unparsing a `SqlSelect`, not a set op. So I'm thoroughly confused. "", 'commenter': 'julianhyde'}, {'comment': ""Ok, I've added a doc to explain it."", 'commenter': 'JiajunBernoulli'}, {'comment': 'Sorry, the previous naming was really inappropriate. \r\nI renamed it to `unparseBinaryOperand`(Write parentheses for special operands in it)', 'commenter': 'JiajunBernoulli'}]"
2724,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3301,6 +3301,85 @@ private void checkHavingAliasSameAsColumn(boolean upperAlias) {
     sql(query).ok(expected);
   }
 
+  @Test void testSetOpLimitShouldRetainParentheses() {","[{'comment': ""capitalize 'limit' and other sql keywords"", 'commenter': 'julianhyde'}, {'comment': 'add javadoc referencing jira', 'commenter': 'julianhyde'}, {'comment': 'There are only tests for UNION currently. Add a test for INTERSECT or EXCEPT, or perhaps a combination of set-ops.', 'commenter': 'julianhyde'}, {'comment': ""I changed it, but I'm a little confused about how to choose case. \r\nIn `testUnionWrappedInASelect` and `testAliasOnStarNoExcessQuotes`, sql keywords is lowercase."", 'commenter': 'JiajunBernoulli'}, {'comment': 'Done, and I renamed this function to `testSetOpRetainParentheses`.', 'commenter': 'JiajunBernoulli'}, {'comment': ""There has been a case of UNION and INTERSECT before, I've added a combination of set-ops."", 'commenter': 'JiajunBernoulli'}]"
2724,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3301,6 +3301,85 @@ private void checkHavingAliasSameAsColumn(boolean upperAlias) {
     sql(query).ok(expected);
   }
 
+  @Test void testSetOpLimitShouldRetainParentheses() {
+    // If the subquery parentheses of limit are discarded,
+    // the semantics of parsing will be affected.
+    // Parentheses should be retained, otherwise not required.
+    final String query = ""select \""product_id\"" from \""product\""""
+        + ""union all\n""
+        + ""(select \""product_id\"" from \""product\"" limit 10)""
+        + ""intersect all\n""
+        + ""(select \""product_id\"" from \""product\"")"";
+    final String expected = ""SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""UNION ALL\n""
+        + ""SELECT *\n""
+        + ""FROM ((SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""FETCH NEXT 10 ROWS ONLY)\n""
+        + ""INTERSECT ALL\n""
+        + ""SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\"")"";
+    sql(query).ok(expected);
+
+    // Offset is the same as limit.
+    final String unionOffsetQuery = ""select \""product_id\"" from(\n""
+        + ""(select \""product_id\""  from \""product\"" limit 10)\n""
+        + ""union all\n""
+        + ""(select \""product_id\"" from \""product\"" offset 5)\n""
+        + ""union all\n""
+        + ""(select \""product_id\"" from \""product\"" order by \""product_id\"" limit 5 offset 5))"";
+    final String unionOffsetRes = ""SELECT *\n""
+        + ""FROM (SELECT *\n""
+        + ""FROM ((SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""FETCH NEXT 10 ROWS ONLY)\n""
+        + ""UNION ALL\n""
+        + ""(SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""OFFSET 5 ROWS))\n""
+        + ""UNION ALL\n""
+        + ""(SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""ORDER BY \""product_id\""\n""
+        + ""OFFSET 5 ROWS\n""
+        + ""FETCH NEXT 5 ROWS ONLY)) AS \""t6\"""";
+    sql(unionOffsetQuery).ok(unionOffsetRes);
+  }
+
+  @Test void testSetOpOrderMaybeRetainParentheses() {
+    // Order by without limit/offset will be removed, so parentheses are not required.","[{'comment': 'this test is testing RelToSql, not SqlToRel. So I would remove this case (the first half of this method).', 'commenter': 'julianhyde'}, {'comment': ""Ok, I've deleted this test case."", 'commenter': 'JiajunBernoulli'}]"
2724,core/src/main/java/org/apache/calcite/sql/SqlUtil.java,"@@ -417,24 +418,52 @@ public static void unparseSqlIdentifierSyntax(
     writer.endList(frame);
   }
 
+  private static void unparseSetOpSyntax(
+      SqlNode sqlNode,
+      SqlWriter writer,
+      int leftPrec,
+      int rightPrec) {
+    SqlSelect sqlSelect = (SqlSelect) sqlNode;
+    if (sqlSelect.getOrderList() != null
+        || sqlSelect.getFetch() != null
+        || sqlSelect.getOffset() != null) {
+      final SqlWriter.Frame operandFrame0 = writer.startList(FrameTypeEnum.SETOP, ""("", "")"");
+      sqlSelect.unparse(writer, leftPrec, rightPrec);
+      writer.endList(operandFrame0);
+    } else {
+      sqlSelect.unparse(writer, leftPrec, rightPrec);
+    }
+  }
+
   public static void unparseBinarySyntax(
       SqlOperator operator,
       SqlCall call,
       SqlWriter writer,
       int leftPrec,
       int rightPrec) {
     assert call.operandCount() == 2;
+    boolean isSetOp = operator instanceof SqlSetOperator;
     final SqlWriter.Frame frame =
         writer.startList(
-            (operator instanceof SqlSetOperator)
+            isSetOp
                 ? SqlWriter.FrameTypeEnum.SETOP
                 : SqlWriter.FrameTypeEnum.SIMPLE);
-    call.operand(0).unparse(writer, leftPrec, operator.getLeftPrec());
+    SqlNode operand0 = call.operand(0);
+    if (isSetOp && operand0.getKind() == SqlKind.SELECT) {
+      unparseSetOpSyntax(operand0, writer, leftPrec, operator.getLeftPrec());
+    } else {
+      operand0.unparse(writer, leftPrec, operator.getLeftPrec());
+    }
     final boolean needsSpace = operator.needsSpace();
     writer.setNeedWhitespace(needsSpace);
     writer.sep(operator.getName());
     writer.setNeedWhitespace(needsSpace);
-    call.operand(1).unparse(writer, operator.getRightPrec(), rightPrec);
+    SqlNode operand1 = call.operand(1);","[{'comment': 'Is the logic of the `if` statement below repeated inside the `unparseSetOpSyntax` function?', 'commenter': 'julianhyde'}, {'comment': 'I moved it to `unparseBinaryOperand`.', 'commenter': 'JiajunBernoulli'}]"
2724,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3301,6 +3301,71 @@ private void checkHavingAliasSameAsColumn(boolean upperAlias) {
     sql(query).ok(expected);
   }
 
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5013"">[CALCITE-5013]
+   * Unparse SqlSetOperator should be retained parentheses
+   * when the operand has limit or offset</a>. */
+  @Test void testSetOpRetainParentheses() {
+    // Parentheses will be discarded, because semantics not be affected.
+    final String discardedParenthesesQuery = ""SELECT \""product_id\"" FROM \""product\""""
+        + ""UNION ALL\n""
+        + ""(SELECT \""product_id\"" FROM \""product\"" WHERE \""product_id\"" > 10)\n""
+        + ""INTERSECT ALL\n""
+        + ""(SELECT \""product_id\"" FROM \""product\"" )"";
+    final String discardedParenthesesRes = ""SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""UNION ALL\n""
+        + ""SELECT *\n""
+        + ""FROM (SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\""\n""
+        + ""WHERE \""product_id\"" > 10\n""
+        + ""INTERSECT ALL\n""
+        + ""SELECT \""product_id\""\n""
+        + ""FROM \""foodmart\"".\""product\"")"";
+    sql(discardedParenthesesQuery).ok(discardedParenthesesRes);
+
+    // Parentheses will be retained because subquery has limit or offset.
+    // If parentheses  are discarded the semantics of parsing will be affected.","[{'comment': 'redundant blank space after the parentheses', 'commenter': 'NobiGo'}, {'comment': 'done', 'commenter': 'JiajunBernoulli'}]"
2724,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3301,6 +3301,71 @@ private void checkHavingAliasSameAsColumn(boolean upperAlias) {
     sql(query).ok(expected);
   }
 
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5013"">[CALCITE-5013]
+   * Unparse SqlSetOperator should be retained parentheses
+   * when the operand has limit or offset</a>. */
+  @Test void testSetOpRetainParentheses() {","[{'comment': 'I\'m suspect whether we should remove the parentheses?\r\nIf the SQL is :\r\n```\r\n""SELECT \\""product_id\\"" FROM \\""product\\""""\r\n        + ""UNION ALL\\n""\r\n        + ""(SELECT \\""product_id\\"" FROM \\""product\\"")\\n""\r\n        + ""INTERSECT ALL\\n""\r\n        + ""(SELECT \\""product_id\\"" FROM \\""product\\"" WHERE \\""product_id\\"" > 10)""\r\n```\r\n```\r\nSELECT \\""product_id\\""\r\nFROM \\""foodmart\\"".\\""product\\""\r\nUNION ALL\r\nSELECT *\r\nFROM (SELECT \\""product_id\\""\r\nFROM \\""foodmart\\"".\\""product\\""\r\nINTERSECT ALL\r\nSELECT \\""product_id\\""\r\nFROM \\""foodmart\\"".\\""product\\""\r\nWHERE \\""product_id\\"" > 10)\r\n```\r\n\r\nI think it has become unclear? So maybe we should stay the parentheses?\r\n', 'commenter': 'NobiGo'}, {'comment': 'Do you mean we should retain it when there is a `where` condition? Or we always retain parentheses?', 'commenter': 'JiajunBernoulli'}, {'comment': ""I disagree that we should add parentheses for aesthetics. See my comment in https://issues.apache.org/jira/browse/CALCITE-5013 and let's discuss further there."", 'commenter': 'julianhyde'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {","[{'comment': '```suggestion\r\n    if (fieldCollationIndexes.isEmpty()) {\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/CoreRules.java,"@@ -712,6 +712,10 @@ private CoreRules() {}
   public static final SortProjectTransposeRule SORT_PROJECT_TRANSPOSE =
       SortProjectTransposeRule.Config.DEFAULT.toRule();
 
+  /** Rule that pulles up constant literal under an {@link Sort}. */","[{'comment': 'Nitpick:\r\n```suggestion\r\n  /** Rule that pulls up constant literal under a {@link Sort}. */\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/CoreRules.java,"@@ -712,6 +712,10 @@ private CoreRules() {}
   public static final SortProjectTransposeRule SORT_PROJECT_TRANSPOSE =
       SortProjectTransposeRule.Config.DEFAULT.toRule();
 
+  /** Rule that pulles up constant literal under an {@link Sort}. */
+  public static final SortProjectPullUpConstantsRule SORT_ANY_PULL_UP_CONSTANTS =","[{'comment': 'You use two names here for the same logical entity, `SortProjectPullUpConstantsRule` and `SORT_ANY_PULL_UP_CONSTANTS`, which can generate confusion.\r\n\r\nWhat about `SortPullUpConstantsRule`/`SORT_PULL_UP_CONSTANTS`? Mentioning `project` made me wonder if the project was to be expected as sort\'s input, which is not the case (that\'s why you use `ANY` in the constant name), after looking at the rule I understood it referred to where the constants are ""moved"".\r\n\r\nWhat do you think?\r\n\r\nPS: both of the original names can work for me, as long as we pick one in all places, you can ignore my suggestion if you don\'t like the names\r\n\r\nIn case you change the rule name, don\'t forget to update the Jira title (and the commit message during the final rebase/squash).', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */","[{'comment': ""I think we can drop the comment, what happens it's clear already"", 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.","[{'comment': '```suggestion\r\n    // None of the sort field expressions is constant. Nothing to do.\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.
+    if (map.isEmpty()) {
+      return;
+    }
+
+    // Input of new top constant project.
+    final RelNode newInputRel;
+    if (map.size() == fieldCollationIndexes.size()) {
+      // All field collations are constants.
+      if (sort.offset == null && sort.fetch == null) {
+        // No any offset or fetch in current sort.
+        // Remove current sort.","[{'comment': '```suggestion\r\n        // Neither offset nor fetch in current sort, drop it.\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.
+    if (map.isEmpty()) {
+      return;
+    }
+
+    // Input of new top constant project.
+    final RelNode newInputRel;
+    if (map.size() == fieldCollationIndexes.size()) {
+      // All field collations are constants.
+      if (sort.offset == null && sort.fetch == null) {
+        // No any offset or fetch in current sort.
+        // Remove current sort.
+        newInputRel = input;
+      } else {
+        // Some offset or fetch exist in current sort.
+        newInputRel = sort.copy(sort.getTraitSet(), input, RelCollations.EMPTY);
+      }
+    } else {
+      // All field collations are not all constants.","[{'comment': '```suggestion\r\n      // Some field collations are not constants.\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();","[{'comment': ""What's the rationale for using a `NavigableMap` \\ `TreeMap` over a `HashMap` here?\r\n\r\nBelow you use random access and you never iterate, I think `HashMap` would be a better fit unless I missed something."", 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.
+    if (map.isEmpty()) {
+      return;
+    }
+
+    // Input of new top constant project.
+    final RelNode newInputRel;
+    if (map.size() == fieldCollationIndexes.size()) {
+      // All field collations are constants.
+      if (sort.offset == null && sort.fetch == null) {
+        // No any offset or fetch in current sort.
+        // Remove current sort.
+        newInputRel = input;
+      } else {
+        // Some offset or fetch exist in current sort.
+        newInputRel = sort.copy(sort.getTraitSet(), input, RelCollations.EMPTY);
+      }
+    } else {
+      // All field collations are not all constants.
+      final List<RelFieldCollation> newFieldCollations = new ArrayList<>();
+      for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
+        final int fieldIndex = fieldCollation.getFieldIndex();
+        if (map.containsKey(fieldIndex)) {
+          continue;
+        }
+        newFieldCollations.add(fieldCollation);
+      }
+      final RelCollation newRelCollation = RelCollations.of(newFieldCollations);
+      newInputRel = sort.copy(sort.getTraitSet(), input, newRelCollation);
+    }
+
+    final RelBuilder relBuilder = call.builder();
+    relBuilder.push(newInputRel);
+
+    // Create a projection back again.
+    List<Pair<RexNode, String>> projects = new ArrayList<>();
+    for (RelDataTypeField field : sort.getRowType().getFieldList()) {
+      final int index = field.getIndex();
+      final RexNode constantNode = map.get(index);
+      final RexNode newExpr;
+      if (constantNode == null) {
+        newExpr = rexBuilder.makeInputRef(newInputRel, index);
+      } else {
+        // Re-generate the constant expression in the project.
+        RelDataType originalType =
+            sort.getRowType().getFieldList().get(projects.size()).getType();","[{'comment': ""Extract `sort.getRowType().getFieldList()` into a variable, it's a long expression and you use it already two times here, it will improve readability IMO."", 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.
+    if (map.isEmpty()) {
+      return;
+    }
+
+    // Input of new top constant project.
+    final RelNode newInputRel;
+    if (map.size() == fieldCollationIndexes.size()) {
+      // All field collations are constants.
+      if (sort.offset == null && sort.fetch == null) {
+        // No any offset or fetch in current sort.
+        // Remove current sort.
+        newInputRel = input;
+      } else {
+        // Some offset or fetch exist in current sort.
+        newInputRel = sort.copy(sort.getTraitSet(), input, RelCollations.EMPTY);
+      }
+    } else {
+      // All field collations are not all constants.
+      final List<RelFieldCollation> newFieldCollations = new ArrayList<>();
+      for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
+        final int fieldIndex = fieldCollation.getFieldIndex();
+        if (map.containsKey(fieldIndex)) {
+          continue;
+        }
+        newFieldCollations.add(fieldCollation);
+      }
+      final RelCollation newRelCollation = RelCollations.of(newFieldCollations);
+      newInputRel = sort.copy(sort.getTraitSet(), input, newRelCollation);
+    }
+
+    final RelBuilder relBuilder = call.builder();
+    relBuilder.push(newInputRel);
+
+    // Create a projection back again.
+    List<Pair<RexNode, String>> projects = new ArrayList<>();
+    for (RelDataTypeField field : sort.getRowType().getFieldList()) {
+      final int index = field.getIndex();
+      final RexNode constantNode = map.get(index);
+      final RexNode newExpr;
+      if (constantNode == null) {
+        newExpr = rexBuilder.makeInputRef(newInputRel, index);
+      } else {
+        // Re-generate the constant expression in the project.
+        RelDataType originalType =
+            sort.getRowType().getFieldList().get(projects.size()).getType();
+        if (!originalType.equals(constantNode.getType())) {
+          newExpr = rexBuilder.makeCast(originalType, constantNode, true);
+        } else {
+          newExpr = constantNode;
+        }","[{'comment': 'Having in the `if` clause a negated statement increases the cognitive complexity of the code, we can swap the `then/else` branches and remove the negation:\r\n\r\n```suggestion\r\n        if (originalType.equals(constantNode.getType())) {\r\n          newExpr = constantNode;\r\n        } else {\r\n          newExpr = rexBuilder.makeCast(originalType, constantNode, true);\r\n        }\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.
+    if (map.isEmpty()) {
+      return;
+    }
+
+    // Input of new top constant project.
+    final RelNode newInputRel;
+    if (map.size() == fieldCollationIndexes.size()) {
+      // All field collations are constants.
+      if (sort.offset == null && sort.fetch == null) {
+        // No any offset or fetch in current sort.
+        // Remove current sort.
+        newInputRel = input;
+      } else {
+        // Some offset or fetch exist in current sort.
+        newInputRel = sort.copy(sort.getTraitSet(), input, RelCollations.EMPTY);
+      }
+    } else {
+      // All field collations are not all constants.
+      final List<RelFieldCollation> newFieldCollations = new ArrayList<>();
+      for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
+        final int fieldIndex = fieldCollation.getFieldIndex();
+        if (map.containsKey(fieldIndex)) {
+          continue;
+        }
+        newFieldCollations.add(fieldCollation);
+      }
+      final RelCollation newRelCollation = RelCollations.of(newFieldCollations);
+      newInputRel = sort.copy(sort.getTraitSet(), input, newRelCollation);
+    }
+
+    final RelBuilder relBuilder = call.builder();
+    relBuilder.push(newInputRel);
+
+    // Create a projection back again.
+    List<Pair<RexNode, String>> projects = new ArrayList<>();
+    for (RelDataTypeField field : sort.getRowType().getFieldList()) {
+      final int index = field.getIndex();
+      final RexNode constantNode = map.get(index);
+      final RexNode newExpr;
+      if (constantNode == null) {
+        newExpr = rexBuilder.makeInputRef(newInputRel, index);
+      } else {
+        // Re-generate the constant expression in the project.
+        RelDataType originalType =
+            sort.getRowType().getFieldList().get(projects.size()).getType();
+        if (!originalType.equals(constantNode.getType())) {
+          newExpr = rexBuilder.makeCast(originalType, constantNode, true);
+        } else {
+          newExpr = constantNode;
+        }
+      }
+      projects.add(Pair.of(newExpr, field.getName()));
+    }
+    relBuilder.project(Pair.left(projects), Pair.right(projects)); // inverse","[{'comment': ""Not sure what the comment is saying, if it's important can you elaborate it a bit more?"", 'commenter': 'asolimando'}]"
2740,core/src/main/java/org/apache/calcite/rel/rules/SortProjectPullUpConstantsRule.java,"@@ -0,0 +1,176 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptPredicateList;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelCollation;
+import org.apache.calcite.rel.RelCollations;
+import org.apache.calcite.rel.RelFieldCollation;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Sort;
+import org.apache.calcite.rel.metadata.RelMetadataQuery;
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeField;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexInputRef;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.util.Pair;
+
+import org.immutables.value.Value;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.NavigableMap;
+import java.util.TreeMap;
+import java.util.stream.Collectors;
+
+/**
+ * Planner rule that removes constant keys from an
+ * {@link Sort}.
+ *
+ * <p>Constant fields are deduced using
+ * {@link RelMetadataQuery#getPulledUpPredicates(RelNode)}; the input does not
+ * need to be a {@link org.apache.calcite.rel.core.Project}.
+ *
+ * <p>Since the transformed relational expression has to match the original
+ * relational expression, the constants are placed in a projection above the
+ * reduced sort. If those constants are not used, another rule will remove
+ * them from the project.
+ */
+@Value.Enclosing
+public class SortProjectPullUpConstantsRule
+    extends RelRule<SortProjectPullUpConstantsRule.Config>
+    implements TransformationRule {
+
+  /** Creates an SortProjectPullUpConstantsRule. */
+  protected SortProjectPullUpConstantsRule(Config config) {
+    super(config);
+  }
+
+  //~ Methods ----------------------------------------------------------------
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    final Sort sort = call.rel(0);
+    final RelNode input = call.rel(1);
+
+    final RelCollation collation = sort.getCollation();
+    final List<Integer> fieldCollationIndexes = collation.getFieldCollations()
+        .stream()
+        .map(RelFieldCollation::getFieldIndex)
+        .collect(Collectors.toList());
+    if (fieldCollationIndexes.size() <= 0) {
+      return;
+    }
+
+    final RexBuilder rexBuilder = sort.getCluster().getRexBuilder();
+    final RelMetadataQuery mq = call.getMetadataQuery();
+    final RelOptPredicateList predicates =
+        mq.getPulledUpPredicates(input);
+    if (RelOptPredicateList.isEmpty(predicates)) {
+      return;
+    }
+
+    final NavigableMap<Integer, RexNode> map = new TreeMap<>();
+    for (int fieldCollationIndex : fieldCollationIndexes) {
+      final RexInputRef ref =
+          rexBuilder.makeInputRef(input, fieldCollationIndex);
+      if (predicates.constantMap.containsKey(ref)) {
+        map.put(fieldCollationIndex, predicates.constantMap.get(ref));
+      }
+    }
+
+    // None of the sort field expressions are constant. Nothing to do.
+    if (map.isEmpty()) {
+      return;
+    }
+
+    // Input of new top constant project.
+    final RelNode newInputRel;
+    if (map.size() == fieldCollationIndexes.size()) {
+      // All field collations are constants.
+      if (sort.offset == null && sort.fetch == null) {
+        // No any offset or fetch in current sort.
+        // Remove current sort.
+        newInputRel = input;
+      } else {
+        // Some offset or fetch exist in current sort.
+        newInputRel = sort.copy(sort.getTraitSet(), input, RelCollations.EMPTY);
+      }
+    } else {
+      // All field collations are not all constants.
+      final List<RelFieldCollation> newFieldCollations = new ArrayList<>();
+      for (RelFieldCollation fieldCollation : collation.getFieldCollations()) {
+        final int fieldIndex = fieldCollation.getFieldIndex();
+        if (map.containsKey(fieldIndex)) {
+          continue;
+        }
+        newFieldCollations.add(fieldCollation);
+      }
+      final RelCollation newRelCollation = RelCollations.of(newFieldCollations);
+      newInputRel = sort.copy(sort.getTraitSet(), input, newRelCollation);
+    }
+
+    final RelBuilder relBuilder = call.builder();
+    relBuilder.push(newInputRel);
+
+    // Create a projection back again.
+    List<Pair<RexNode, String>> projects = new ArrayList<>();
+    for (RelDataTypeField field : sort.getRowType().getFieldList()) {
+      final int index = field.getIndex();
+      final RexNode constantNode = map.get(index);
+      final RexNode newExpr;
+      if (constantNode == null) {
+        newExpr = rexBuilder.makeInputRef(newInputRel, index);
+      } else {
+        // Re-generate the constant expression in the project.
+        RelDataType originalType =
+            sort.getRowType().getFieldList().get(projects.size()).getType();
+        if (!originalType.equals(constantNode.getType())) {
+          newExpr = rexBuilder.makeCast(originalType, constantNode, true);
+        } else {
+          newExpr = constantNode;
+        }
+      }
+      projects.add(Pair.of(newExpr, field.getName()));
+    }
+    relBuilder.project(Pair.left(projects), Pair.right(projects)); // inverse
+
+    final RelNode newRelNode = relBuilder.build();
+    call.transformTo(newRelNode);","[{'comment': '```suggestion\r\n    call.transformTo(relBuilder.build());\r\n```', 'commenter': 'asolimando'}]"
2740,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -5530,6 +5530,58 @@ private void checkSemiJoinRuleOnAntiJoin(RelOptRule rule) {
         .checkUnchanged();
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5035"">[CALCITE-5035]
+   * Pull up constant project under sort</a>. */
+  @Test void testSortProjectPullUpConstants1() {","[{'comment': ""You have different test cases for a reason, try to highlight what is the specificity in the name of the test instead of using `1`, `2` etc.\r\n\r\nIt will help debug test failures, but it will also make the life of other people easier to understand if what they are looking for is already handled (tests are documentation too, and their names are a big part of it).\r\n\r\nFor instance, here the focus looks like it's the absence of fetch/limit, maybe we can rename it as `testSortProjectPullUpConstantsNoFetchLimit`?\r\n\r\nThe same comment applies for the other tests."", 'commenter': 'asolimando'}]"
2740,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -5530,6 +5530,58 @@ private void checkSemiJoinRuleOnAntiJoin(RelOptRule rule) {
         .checkUnchanged();
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5035"">[CALCITE-5035]
+   * Pull up constant project under sort</a>. */
+  @Test void testSortProjectPullUpConstants1() {
+    // The constant's count is more than sort's field, and without any fetch or offset
+    final String sql = ""select e.empno, e.ename, e.deptno from sales.emp e\n""","[{'comment': 'Nitpick:\r\n```suggestion\r\n    final String sql = ""select e.empno, e.ename, e.deptno\\n""\r\n        + ""from sales.emp e\\n""\r\n```\r\nIf you accept this change, please be consistent in the other tests.\r\n\r\nPS: I see that in the test, both styles are used, but what I suggest seems preferred for long lines like in your case, up to you :)', 'commenter': 'asolimando'}]"
2740,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -5530,6 +5530,58 @@ private void checkSemiJoinRuleOnAntiJoin(RelOptRule rule) {
         .checkUnchanged();
   }
 
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5035"">[CALCITE-5035]
+   * Pull up constant project under sort</a>. */
+  @Test void testSortProjectPullUpConstants1() {
+    // The constant's count is more than sort's field, and without any fetch or offset
+    final String sql = ""select e.empno, e.ename, e.deptno from sales.emp e\n""
+        + ""where e.deptno = 123\n""
+        + ""order by e.deptno, e.empno"";
+    sql(sql)
+        .withRule(CoreRules.SORT_ANY_PULL_UP_CONSTANTS)
+        .check();
+  }
+
+  /** Test case for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5035"">[CALCITE-5035]
+   * Pull up constant project under sort</a>. */
+  @Test void testSortProjectPullUpConstants2() {
+    // Sort with some fetch and offset","[{'comment': 'You could drop the comment by improving the test name as suggested above.', 'commenter': 'asolimando'}]"
2743,core/src/test/resources/org/apache/calcite/test/RelOptRulesTest.xml,"@@ -6670,6 +6669,48 @@ LogicalProject(DEPTNO=[$7], EXPR$1=[+($7, 1)], EXPR$2=[+($0, $7)])
 LogicalProject(DEPTNO=[10], EXPR$1=[11], EXPR$2=[+($0, 10)])
   LogicalFilter(condition=[=($7, 10)])
     LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name=""testPullConstantIntoProjectWithIsNotDistinctFrom"">
+    <Resource name=""sql"">
+      <![CDATA[select deptno, deptno + 1, empno + deptno
+from sales.emp
+where deptno is not distinct from 10]]>
+    </Resource>
+    <Resource name=""planBefore"">
+      <![CDATA[
+LogicalProject(DEPTNO=[$7], EXPR$1=[+($7, 1)], EXPR$2=[+($0, $7)])
+  LogicalFilter(condition=[OR(AND(IS NULL($7), IS NULL(10)), IS TRUE(=($7, 10)))])
+    LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+]]>
+    </Resource>
+    <Resource name=""planAfter"">
+      <![CDATA[
+LogicalProject(DEPTNO=[10], EXPR$1=[11], EXPR$2=[+($0, 10)])
+  LogicalFilter(condition=[OR(AND(IS NULL($7), IS NULL(10)), IS TRUE(=($7, 10)))])
+    LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+]]>
+    </Resource>
+  </TestCase>
+  <TestCase name=""testPullConstantIntoProjectWithIsNotDistinctFromForNull"">
+    <Resource name=""sql"">
+      <![CDATA[select empno, deptno","[{'comment': 'The SQL is wrong? The plan and the SQL is inconsistent', 'commenter': 'NobiGo'}, {'comment': ""Yes, it's my mistake."", 'commenter': 'wojustme'}]"
2743,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -5582,8 +5603,8 @@ private void checkSemiJoinRuleOnAntiJoin(RelOptRule rule) {
   @Test void testAggregateConstantKeyRule3() {
     final String sql = ""select job\n""
         + ""from sales.emp\n""
-        + ""where sal is null and job = 'Clerk'\n""
-        + ""group by sal, job\n""
+        + ""where mgr is null and job = 'Clerk'\n""","[{'comment': 'I want to know why we need to change the filter condition? ', 'commenter': 'NobiGo'}, {'comment': '@NobiGo Thanks for your reply.\r\nI wanted to submit this pr to solve [ISSUE-5038](https://issues.apache.org/jira/browse/CALCITE-5038) together。\r\nBut, I thought about it for a while, I think I may split the changed codes into two prs to prevent ambiguity.\r\nPlease review [PR-2742](https://github.com/apache/calcite/pull/2742) firstly.\r\n', 'commenter': 'wojustme'}]"
2743,core/src/main/java/org/apache/calcite/rel/metadata/RelMdPredicates.java,"@@ -278,11 +278,18 @@ public RelOptPredicateList getPredicates(Filter filter, RelMetadataQuery mq) {
     final RexBuilder rexBuilder = filter.getCluster().getRexBuilder();
     final RelOptPredicateList inputInfo = mq.getPulledUpPredicates(input);
 
+    // Simplify filter's condition using RexSimplify.","[{'comment': ""Please not use `filter's`"", 'commenter': 'xy2953396112'}, {'comment': 'update it.', 'commenter': 'wojustme'}]"
2774,core/src/main/java/org/apache/calcite/rel/metadata/RelMdRowCount.java,"@@ -147,45 +146,27 @@ public Double getRowCount(Calc rel, RelMetadataQuery mq) {
     if (rowCount == null) {
       return null;
     }
-    if (rel.offset instanceof RexDynamicParam) {
-      return rowCount;
-    }
-    final int offset = rel.offset == null ? 0 : RexLiteral.intValue(rel.offset);
+
+    final int offset = rel.offset instanceof RexLiteral ? RexLiteral.intValue(rel.offset) : 0;
     rowCount = Math.max(rowCount - offset, 0D);
 
-    if (rel.fetch != null) {
-      if (rel.fetch instanceof RexDynamicParam) {
-        return rowCount;
-      }
-      final int limit = RexLiteral.intValue(rel.fetch);
-      if (limit < rowCount) {
-        return (double) limit;
-      }
-    }
-    return rowCount;
+    final double limit =
+        rel.fetch instanceof RexLiteral ? RexLiteral.intValue(rel.fetch) : rowCount;
+    return limit < rowCount ? limit : rowCount;
   }
 
   public @Nullable Double getRowCount(EnumerableLimit rel, RelMetadataQuery mq) {
     Double rowCount = mq.getRowCount(rel.getInput());
     if (rowCount == null) {
       return null;
     }
-    if (rel.offset instanceof RexDynamicParam) {
-      return rowCount;
-    }
-    final int offset = rel.offset == null ? 0 : RexLiteral.intValue(rel.offset);
+
+    final int offset = rel.offset instanceof RexLiteral ? RexLiteral.intValue(rel.offset) : 0;
     rowCount = Math.max(rowCount - offset, 0D);","[{'comment': ""If we don't care about the offset value when it is a dynamic param, the row count value will be wrong? I think the origin logic is good."", 'commenter': 'NobiGo'}, {'comment': 'Yes, I think the row count value will be wrong. \r\nDo you think **14d** is right for the sql?\r\n`select * from emp order by ename limit 1 offset ?`\r\n', 'commenter': 'JiajunBernoulli'}, {'comment': 'The limit number is the max row count that the SQL can return.', 'commenter': 'NobiGo'}]"
2787,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -1776,6 +1776,15 @@ protected static Calendar getCalendarNotTooNear(int timeUnit) {
     f.checkNull("" cast(null as ANY) || cast(null as ANY) "");
     f.checkString(""cast('a' as varchar) || cast('b' as varchar) ""
         + ""|| cast('c' as varchar)"", ""abc"", ""VARCHAR NOT NULL"");
+
+    f.checkScalar(""array[1, 2] || array[2, 3]"", ""[1, 2, 2, 3]"",
+        ""INTEGER NOT NULL ARRAY NOT NULL"");
+    f.checkScalar(""array[1, 2] || array[2, null]"", ""[1, 2, 2, null]"",
+        ""INTEGER ARRAY NOT NULL"");
+    f.checkScalar(""array['hello', 'world'] || array['!'] || ""
+            + ""array[cast(null as char)]"",
+        ""[hello, world, !, null]"", ""CHAR(5) ARRAY NOT NULL"");","[{'comment': 'Could you add a test for `array[] || array[]`?', 'commenter': 'chunweilei'}, {'comment': ""It's impossible because array constructor should have at least one argument"", 'commenter': 'dssysolyatin'}, {'comment': 'Get it!', 'commenter': 'chunweilei'}]"
2787,core/src/main/java/org/apache/calcite/sql/fun/SqlStdOperatorTable.java,"@@ -248,7 +250,7 @@ public class SqlStdOperatorTable extends ReflectiveSqlOperatorTable {
   public static final SqlInternalOperator EXTEND = new SqlExtendOperator();
 
   /**
-   * String concatenation operator, '<code>||</code>'.
+   * String and arrays concatenation operator, '<code>||</code>'.
    *
    * @see SqlLibraryOperators#CONCAT_FUNCTION","[{'comment': 'It would be great if you can specify it only supports `array-to-array concatenation: ARRAY[1,2,3] || ARRAY[4,5,6]`.', 'commenter': 'chunweilei'}, {'comment': 'Fixed', 'commenter': 'dssysolyatin'}]"
2889,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3616,9 +3629,20 @@ private RelDataType validateCommonInputJoinColumn(SqlIdentifier id,
     if (field == null) {
       throw newValidationError(id, RESOURCE.columnNotFound(name));
     }
-    if (nameMatcher.frequency(rowType.getFieldNames(), name) > 1) {
-      throw newValidationError(id,
-          RESOURCE.columnInUsingNotUnique(name));
+    Collection<RelDataType> rowTypes;
+    if (!natural && rowType instanceof RelCrossType) {
+      final RelCrossType crossType = (RelCrossType) rowType;
+      ImmutableList<RelDataType> types = crossType.getTypes();
+      rowTypes = new ArrayList<>(types.size());
+      rowTypes.addAll(types);","[{'comment': 'Nitpick: it is equivalent to the shorter version below.\r\n\r\n```suggestion\r\n      rowTypes = new ArrayList<>(crossType.getTypes());\r\n```', 'commenter': 'asolimando'}]"
2889,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3616,9 +3629,20 @@ private RelDataType validateCommonInputJoinColumn(SqlIdentifier id,
     if (field == null) {
       throw newValidationError(id, RESOURCE.columnNotFound(name));
     }
-    if (nameMatcher.frequency(rowType.getFieldNames(), name) > 1) {
-      throw newValidationError(id,
-          RESOURCE.columnInUsingNotUnique(name));
+    Collection<RelDataType> rowTypes;
+    if (!natural && rowType instanceof RelCrossType) {
+      final RelCrossType crossType = (RelCrossType) rowType;
+      ImmutableList<RelDataType> types = crossType.getTypes();
+      rowTypes = new ArrayList<>(types.size());
+      rowTypes.addAll(types);
+    } else {
+      rowTypes = Collections.singleton(rowType);
+    }
+    for (RelDataType rowType0 : rowTypes) {
+      if (nameMatcher.frequency(rowType0.getFieldNames(), name) > 1) {
+        throw newValidationError(id,
+            RESOURCE.columnInUsingNotUnique(name));","[{'comment': 'Nitpick: the statement is short enough to fit into one line (similarly to what you have done at line 3630 for a similar case):\r\n \r\n```suggestion\r\n        throw newValidationError(id, RESOURCE.columnInUsingNotUnique(name));\r\n```', 'commenter': 'asolimando'}]"
2889,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -6163,7 +6163,7 @@ private ImmutableList<ImmutableBitSet> cube(ImmutableBitSet... sets) {
   /** Test case for
    * <a href=""https://issues.apache.org/jira/browse/CALCITE-5171"">[CALCITE-5171]
    * NATURAL join and USING should fail if join columns are not unique</a>. */
-  @Test void testNaturalJoinDuplicateColumns() {
+  @Test void testJoinDuplicateColumns() {","[{'comment': 'Whenever possible unit tests should check for a single assertion to scope them more clearly and to easily identify the failure ""area"" in CI.\r\n\r\nWhat about splitting this single test into multiple tests with proper naming? (you could possible need less comments if the name is clear enough).', 'commenter': 'asolimando'}, {'comment': 'fixed, thanks !', 'commenter': 'zstan'}]"
2889,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3586,27 +3587,39 @@ private void validateNoAggs(AggFinder aggFinder, SqlNode node,
     }
   }
 
-  /** Validates a column in a USING clause, or an inferred join key in a
-   * NATURAL join. */
+  /** Validates a column in a USING clause, or an inferred join key in a NATURAL join. */
   private void validateCommonJoinColumn(SqlIdentifier id, SqlNode left,
-      SqlNode right, SqlValidatorScope scope) {
+      SqlNode right, SqlValidatorScope scope, boolean natural) {
     if (id.names.size() != 1) {
       throw newValidationError(id, RESOURCE.columnNotFound(id.toString()));
     }
 
-    final RelDataType leftColType = validateCommonInputJoinColumn(id, left, scope);
-    final RelDataType rightColType = validateCommonInputJoinColumn(id, right, scope);
+    final RelDataType leftColType = natural
+        ? checkAndDeriveDataType(id, left)
+        : validateCommonInputJoinColumn(id, left, scope, natural);
+    final RelDataType rightColType = validateCommonInputJoinColumn(id, right, scope, natural);
     if (!SqlTypeUtil.isComparable(leftColType, rightColType)) {
       throw newValidationError(id,
           RESOURCE.naturalOrUsingColumnNotCompatible(id.getSimple(),
               leftColType.toString(), rightColType.toString()));
     }
   }
 
+  private RelDataType checkAndDeriveDataType(SqlIdentifier id, SqlNode node) {
+    Preconditions.checkArgument(id.names.size() == 1);
+    String name = id.names.get(0);
+    SqlNameMatcher nameMatcher = getCatalogReader().nameMatcher();
+    RelDataType rowType = getNamespaceOrThrow(node).getRowType();
+    RelDataType colType = requireNonNull(
+        nameMatcher.field(rowType, name),
+        () -> ""unable to find left field "" + name + "" in "" + rowType).getType();
+    return colType;","[{'comment': 'Nitpick: since modern IDEs allow you to put breakpoints before returning, I generally return immediately without assignment to a temporary variable, but that\'s a matter of taste I guess, I am fine whichever decision you take.\r\n\r\n```suggestion\r\n    return requireNonNull(\r\n        nameMatcher.field(rowType, name),\r\n        () -> ""unable to find left field "" + name + "" in "" + rowType).getType();\r\n```', 'commenter': 'asolimando'}]"
2889,core/src/main/java/org/apache/calcite/rel/type/RelCrossType.java,"@@ -58,6 +58,15 @@ public RelCrossType(
     return false;
   }
 
+  /**
+   * Returns the contained types.
+   *
+   * @return Data types.","[{'comment': ""If you check around, in Calcite it's customary to start with lowercase and omit the full stop at the end for `@return` in Javadoc:\r\n\r\n```suggestion\r\n   * @return data types\r\n```"", 'commenter': 'asolimando'}]"
2889,core/src/main/java/org/apache/calcite/rel/type/RelCrossType.java,"@@ -58,6 +58,15 @@ public RelCrossType(
     return false;
   }
 
+  /**
+   * Returns the contained types.
+   *
+   * @return Data types.
+   */
+  public ImmutableList<RelDataType> getTypes() {","[{'comment': 'Is `ImmutableList<RelDataType>` too specific? How about `List<RelDataType>`?', 'commenter': 'libenchao'}, {'comment': 'good catch, thanks !', 'commenter': 'zstan'}]"
2890,core/src/main/java/org/apache/calcite/prepare/PlannerImpl.java,"@@ -237,6 +237,15 @@ private void ready() {
     return Pair.of(validatedNode, type);
   }
 
+  @Override public RelDataType getParameterRowType() {
+    if (state.ordinal() < State.STATE_4_VALIDATED.ordinal()) {
+      throw new RuntimeException(""Need to call #validate() first"");
+    }","[{'comment': '```suggestion\r\nensure(State.STATE_4_VALIDATED);```', 'commenter': 'jbalint'}, {'comment': '@jbalint \r\n`ensure` works differently. `ensure` checks if planner can move to next state. if ensure is used and user calls getParameterRowType from STATE_5_CONVERTED state, the `getParameterRowType` will throw exception\r\n', 'commenter': 'dssysolyatin'}, {'comment': ""yes - you're right. the javadoc is wrong... :("", 'commenter': 'jbalint'}]"
2913,core/src/main/java/org/apache/calcite/prepare/CalciteCatalogReader.java,"@@ -91,7 +91,10 @@ public class CalciteCatalogReader implements Prepare.CatalogReader {
 
   public CalciteCatalogReader(CalciteSchema rootSchema,
       List<String> defaultSchema, RelDataTypeFactory typeFactory, CalciteConnectionConfig config) {
-    this(rootSchema, SqlNameMatchers.withCaseSensitive(config != null && config.caseSensitive()),
+    this(rootSchema,
+        // TODO: BigQuery has case-insensitive functions","[{'comment': 'https://github.com/apache/calcite/pull/2914 should fix this.', 'commenter': 'tjbanghart'}]"
2913,babel/src/test/resources/sql/big-query.iq,"@@ -16,7 +16,809 @@
 # limitations under the License.
 #
 !use scott-big-query
-!set outputformat csv
+!set outputformat mysql","[{'comment': ""when I merge this I'll factor out the big-query.iq change as a separate commit"", 'commenter': 'julianhyde'}]"
2913,testkit/src/main/java/org/apache/calcite/sql/parser/SqlParserTest.java,"@@ -520,7 +520,9 @@ public class SqlParserTest {
       ""TEMPORARY"",                     ""92"", ""99"",
       ""THEN"",                          ""92"", ""99"", ""2003"", ""2011"", ""2014"", ""c"",
       ""TIME"",                          ""92"", ""99"", ""2003"", ""2011"", ""2014"", ""c"",
+      ""TIME_TRUNC"", // BigQuery","[{'comment': ""I'm surprised there are new keywords. We needed a new keyword for `ILIKE` because it's infix, but these can just be function names."", 'commenter': 'julianhyde'}, {'comment': 'This is me following an example commit too closely.', 'commenter': 'tjbanghart'}]"
2913,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -1604,6 +1604,10 @@ protected static Calendar getCalendarNotTooNear(int timeUnit) {
     f.checkScalar(""{fn TIMESTAMPDIFF(MONTH,""
         + "" TIMESTAMP '2019-09-01 00:00:00',""
         + "" TIMESTAMP '2020-03-01 00:00:00')}"", ""6"", ""INTEGER NOT NULL"");
+    f.checkScalar(""{fn TIMESTAMP_TRUNC(TIMESTAMP '2019-09-20 15:30:00', MONTH) }"",","[{'comment': ""I don't think JDBC syntax is a requirement. You should remove these lines, and revert the changes to `SqlJdbcFunctionCall.java`."", 'commenter': 'julianhyde'}]"
2913,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -4083,6 +4083,55 @@ void subTestIntervalSecondNegative() {
         .fails(""(?s).*Was expecting one of.*"");
   }
 
+  @Test void testTimestampTrunc() {
+    List<String> timeUnits = ImmutableList.<String>builder()
+        .add(""MINUTE"")
+        .add(""HOUR"")
+        .add(""DAY"")
+        .add(""WEEK"")
+        .add(""MONTH"")
+        .add(""QUARTER"")
+        .add(""YEAR"")
+        .add(""ISOYEAR"")
+        .build();
+
+    final SqlOperatorTable opTable = operatorTableFor(SqlLibrary.BIG_QUERY);
+    String test = ""TIMESTAMP_TRUNC(TIMESTAMP '2000-01-01 01:00:00', %s)"";
+
+    for (String unit : timeUnits) {
+      wholeExpr(String.format(Locale.ROOT, test, unit))
+          .fails(""No match found for function signature ""
+              + ""TIMESTAMP_TRUNC\\(<TIMESTAMP>,.*\\)"");
+      expr(String.format(Locale.ROOT, test, unit))
+          .withOperatorTable(opTable)
+          .columnType(""TIMESTAMP(0) NOT NULL"");
+    }
+  }
+
+  @Test void testTimeTrunc() {
+    List<String> timeUnits = ImmutableList.<String>builder()
+        .add(""MILLISECOND"")
+        .add(""SECOND"")
+        .add(""MINUTE"")
+        .add(""HOUR"")
+        .build();
+
+    final SqlOperatorTable opTable = operatorTableFor(SqlLibrary.BIG_QUERY);
+    String test = ""TIME_TRUNC(TIME '15:30:00.00', %s)"";
+
+    for (String unit : timeUnits) {
+      wholeExpr(String.format(Locale.ROOT, test, unit))
+          .fails(""No match found for function signature ""
+              + ""TIME_TRUNC\\(<TIME>,.*\\)"");
+      expr(String.format(Locale.ROOT, test, unit))
+          .withOperatorTable(opTable)
+          .columnType(""TIME(0) NOT NULL"");
+    }
+    // should fail on incompatible time unit
+    expr(""TIME_TRUNC(TIME '15:30:00.00', ^DAY^)"")
+        .fails(""(?s).*Was expecting one of.*"");
+  }
+","[{'comment': ""Are these tests superfluous? between `SqlParserTest` and `SqlOperatorTest` I think you have it covered. I don't think there's any non-trivial validation behavior."", 'commenter': 'julianhyde'}, {'comment': ""These can probably be simplified to run a single time unit but they validate for an error message if the BigQuery operator table is not used. I can add similar check in `SqlOperatorTest` so this file isn't touched."", 'commenter': 'tjbanghart'}]"
2913,site/_docs/reference.md,"@@ -2625,6 +2625,8 @@ semantics.
 | b m o p | SUBSTR(string, position [, substringLength ]) | Returns a portion of *string*, beginning at character *position*, *substringLength* characters long. SUBSTR calculates lengths using characters as defined by the input character set
 | m | STRCMP(string, string)                         | Returns 0 if both of the strings are same and returns -1 when the first argument is smaller than the second and 1 when the second one is smaller than the first one
 | o | TANH(numeric)                                  | Returns the hyperbolic tangent of *numeric*
+| b | TIME_TRUNC(time, timeUnit)                     | Truncates a *time* value to the granularity of *timeUnit*. The *time* value is always rounded to the beginning of timeUnit, which can be one of the following: MILLISECOND, SECOND, MINUTE, HOUR.
+| b | TIMESTAMP_TRUNC(timestamp, timeUnit)           | Truncates a *timestamp* value to the granularity of *timeUnit*. The *timestamp* value is always rounded to the beginning of the *timeUnit*.","[{'comment': 'move down a few lines, to retain alphabetical order', 'commenter': 'julianhyde'}]"
2919,core/src/main/java/org/apache/calcite/util/Util.java,"@@ -1048,6 +1048,19 @@ public static String getStackTrace(Throwable t) {
     return sw.toString();
   }
 
+  /**
+   * Checks a RuntimeException for AccessControlException without importing JDK
+   * classes that are deprecated with the anticipated removal of Java security manager.
+   * Ignores the RuntimeException if it is an AccessControlException otherwise throws.
+   * @param e RuntimeException to check if it is an AccessControlException
+   */
+  @API(since = ""1.33"", status = API.Status.EXPERIMENTAL)
+  public static void ignoreAccessControlException(RuntimeException e) {","[{'comment': 'So I thought about trying to put the whole `try/catch` in here but that got into issues with return values and handling other exceptions. There may be a way to do this with lambdas or functions passed in. I just punted on that and made this a simple method just for checking `AccessControlException`', 'commenter': 'risdenk'}, {'comment': 'Can you re-order the javadoc so that it says what the method does in the first sentence.\r\n\r\nIn the next paragraph explain how it does it.\r\n\r\nPut a blank line before \\@param.', 'commenter': 'julianhyde'}, {'comment': 'Is this issue tied to any particular JDK version? E.g. SecurityManager became deprecated in JDK x.x and is going to be removed in JDK y.y? If so it would be helpful to mention in this comment.', 'commenter': 'julianhyde'}, {'comment': 'Reordered the javadoc and added reference to https://openjdk.org/jeps/411 about JDK 17 deprecated and no JDK marked for removal yet.', 'commenter': 'risdenk'}, {'comment': 'Fixed in ede956c7aecf560ea88c45b48ef7a351f0c8e891', 'commenter': 'risdenk'}]"
2919,core/src/main/java/org/apache/calcite/util/Util.java,"@@ -1048,6 +1048,22 @@ public static String getStackTrace(Throwable t) {
     return sw.toString();
   }
 
+  /**
+   * Ignores the RuntimeException if it is an AccessControlException otherwise throws.
+   *
+   * <p>Checks a RuntimeException for AccessControlException without importing JDK
+   * classes that are deprecated in <a href=""https://openjdk.org/jeps/411"">JDK 17</a>
+   * with the anticipated removal of Java security manager.
+   *
+   * @param e RuntimeException to check if it is an AccessControlException
+   */
+  @API(since = ""1.33"", status = API.Status.EXPERIMENTAL)
+  public static void ignoreAccessControlException(RuntimeException e) {
+    if (!""java.security.AccessControlException"".equals(e.getClass().getName())) {
+      throw e;
+    }
+  }","[{'comment': ""Do we really need this hacky check? `AccessControlException` is a subclass of `SecurityException`. The latter is not deprecated (https://download.java.net/java/early_access/jdk21/docs/api/java.base/java/lang/SecurityException.html) so I assume we can do regular `catch(SecurityException se)` where needed can't we?"", 'commenter': 'zabetak'}, {'comment': 'Seems like a reasonable idea. From https://openjdk.org/jeps/411\r\n\r\n```\r\n...\r\nWe will not deprecate some classes in the java.security package that are related to the Security Manager, for various reasons:\r\n...\r\nSecurityException — A runtime exception thrown by Java APIs when a permission check fails. We may deprecate this API for removal at a later date, but for now the impact of doing so would be too high.\r\n...\r\n```', 'commenter': 'risdenk'}, {'comment': 'Switched to this approach in 88c31c9f29f22754443e2c67b3e9e9e293972fcf', 'commenter': 'risdenk'}]"
2997,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -672,9 +672,11 @@ private static String toSql(RelNode root, SqlDialect dialect,
         + ""FROM \""foodmart\"".\""product\""\n""
         + ""GROUP BY ROLLUP(\""product_class_id\"", \""brand_name\"")\n""
         + ""ORDER BY \""product_class_id\"", \""brand_name\"""";
-    final String expectedMysql = ""SELECT `product_class_id`, `brand_name`\n""
+    final String expectedMysql = ""SELECT *\n""","[{'comment': 'That is probably excessive - if order of grouping fields matches the order of sort fields, we can omit ORDER BY clause (as it was done in the old solution).', 'commenter': 'LeonidChistov'}, {'comment': 'I restored to old solution. Thanks for your review.', 'commenter': 'JiajunBernoulli'}]"
2997,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -868,19 +867,35 @@ public Result visit(Sort e) {
       if (hasTrickyRollup(e, aggregate)) {
         // MySQL 5 does not support standard ""GROUP BY ROLLUP(x, y)"", only
         // the non-standard ""GROUP BY x, y WITH ROLLUP"".
-        // It does not allow ""WITH ROLLUP"" in combination with ""ORDER BY"",
-        // but ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
+        List<Integer> rollupList = Aggregate.Group.getRollup(aggregate.getGroupSets());
+        List<Integer> sortList = e.getCollation()
+            .getFieldCollations()
+            .stream()
+            .map(f -> aggregate.getGroupSet().nth(f.getFieldIndex()))
+            .collect(Collectors.toList());
+        // ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
         // so skip the ORDER BY.
-        final Set<Integer> groupList = new LinkedHashSet<>();
-        for (RelFieldCollation fc : e.collation.getFieldCollations()) {
-          groupList.add(aggregate.getGroupSet().nth(fc.getFieldIndex()));
-        }
-        groupList.addAll(Aggregate.Group.getRollup(aggregate.getGroupSets()));
+        boolean isImplicitlySort = rollupList.subList(0, sortList.size()).equals(sortList);
         final Builder builder =
-            visitAggregate(aggregate, ImmutableList.copyOf(groupList),
+            visitAggregate(aggregate,
+                rollupList,
                 Clause.GROUP_BY, Clause.OFFSET, Clause.FETCH);
-        offsetFetch(e, builder);
-        return builder.result();
+        Result result = builder.result();
+        if (sortList.isEmpty()
+            || isImplicitlySort) {
+          offsetFetch(e, builder);
+          return result;
+        }
+        // It does not allow ""WITH ROLLUP"" in combination with ""ORDER BY"",
+        // so generate the grouped result apply ORDER BY to it.
+        SqlSelect sqlSelect = result.subSelect();
+        SqlNodeList sortExps = exprList(builder.context, e.getSortExps());
+        sqlSelect.setOrderBy(sortExps);
+        SqlNode offset = e.offset == null ? null : builder.context.toSql(null, e.offset);","[{'comment': 'for offset and fetch I think `if` would be clearer than `?`', 'commenter': 'julianhyde'}, {'comment': 'Yes, `if` is clearer.', 'commenter': 'JiajunBernoulli'}]"
2997,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -868,19 +867,35 @@ public Result visit(Sort e) {
       if (hasTrickyRollup(e, aggregate)) {
         // MySQL 5 does not support standard ""GROUP BY ROLLUP(x, y)"", only
         // the non-standard ""GROUP BY x, y WITH ROLLUP"".
-        // It does not allow ""WITH ROLLUP"" in combination with ""ORDER BY"",
-        // but ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
+        List<Integer> rollupList = Aggregate.Group.getRollup(aggregate.getGroupSets());
+        List<Integer> sortList = e.getCollation()
+            .getFieldCollations()
+            .stream()
+            .map(f -> aggregate.getGroupSet().nth(f.getFieldIndex()))
+            .collect(Collectors.toList());
+        // ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
         // so skip the ORDER BY.
-        final Set<Integer> groupList = new LinkedHashSet<>();
-        for (RelFieldCollation fc : e.collation.getFieldCollations()) {
-          groupList.add(aggregate.getGroupSet().nth(fc.getFieldIndex()));
-        }
-        groupList.addAll(Aggregate.Group.getRollup(aggregate.getGroupSets()));
+        boolean isImplicitlySort = rollupList.subList(0, sortList.size()).equals(sortList);
         final Builder builder =
-            visitAggregate(aggregate, ImmutableList.copyOf(groupList),
+            visitAggregate(aggregate,
+                rollupList,","[{'comment': 'put `rollupList` on previous line', 'commenter': 'julianhyde'}, {'comment': 'Ok', 'commenter': 'JiajunBernoulli'}]"
2997,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -868,19 +867,35 @@ public Result visit(Sort e) {
       if (hasTrickyRollup(e, aggregate)) {
         // MySQL 5 does not support standard ""GROUP BY ROLLUP(x, y)"", only
         // the non-standard ""GROUP BY x, y WITH ROLLUP"".
-        // It does not allow ""WITH ROLLUP"" in combination with ""ORDER BY"",
-        // but ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
+        List<Integer> rollupList = Aggregate.Group.getRollup(aggregate.getGroupSets());
+        List<Integer> sortList = e.getCollation()
+            .getFieldCollations()
+            .stream()
+            .map(f -> aggregate.getGroupSet().nth(f.getFieldIndex()))
+            .collect(Collectors.toList());
+        // ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
         // so skip the ORDER BY.
-        final Set<Integer> groupList = new LinkedHashSet<>();
-        for (RelFieldCollation fc : e.collation.getFieldCollations()) {
-          groupList.add(aggregate.getGroupSet().nth(fc.getFieldIndex()));
-        }
-        groupList.addAll(Aggregate.Group.getRollup(aggregate.getGroupSets()));
+        boolean isImplicitlySort = rollupList.subList(0, sortList.size()).equals(sortList);","[{'comment': 'should be `final`', 'commenter': 'julianhyde'}, {'comment': ""I didn't have this consciousness before, thank you for letting me learn."", 'commenter': 'JiajunBernoulli'}]"
2997,core/src/main/java/org/apache/calcite/rel/rel2sql/RelToSqlConverter.java,"@@ -868,19 +867,35 @@ public Result visit(Sort e) {
       if (hasTrickyRollup(e, aggregate)) {
         // MySQL 5 does not support standard ""GROUP BY ROLLUP(x, y)"", only
         // the non-standard ""GROUP BY x, y WITH ROLLUP"".
-        // It does not allow ""WITH ROLLUP"" in combination with ""ORDER BY"",
-        // but ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
+        List<Integer> rollupList = Aggregate.Group.getRollup(aggregate.getGroupSets());
+        List<Integer> sortList = e.getCollation()
+            .getFieldCollations()
+            .stream()
+            .map(f -> aggregate.getGroupSet().nth(f.getFieldIndex()))
+            .collect(Collectors.toList());
+        // ""GROUP BY x, y WITH ROLLUP"" implicitly sorts by x, y,
         // so skip the ORDER BY.
-        final Set<Integer> groupList = new LinkedHashSet<>();
-        for (RelFieldCollation fc : e.collation.getFieldCollations()) {
-          groupList.add(aggregate.getGroupSet().nth(fc.getFieldIndex()));
-        }
-        groupList.addAll(Aggregate.Group.getRollup(aggregate.getGroupSets()));
+        boolean isImplicitlySort = rollupList.subList(0, sortList.size()).equals(sortList);
         final Builder builder =
-            visitAggregate(aggregate, ImmutableList.copyOf(groupList),
+            visitAggregate(aggregate,
+                rollupList,
                 Clause.GROUP_BY, Clause.OFFSET, Clause.FETCH);
-        offsetFetch(e, builder);
-        return builder.result();
+        Result result = builder.result();
+        if (sortList.isEmpty()
+            || isImplicitlySort) {
+          offsetFetch(e, builder);
+          return result;
+        }
+        // It does not allow ""WITH ROLLUP"" in combination with ""ORDER BY"",
+        // so generate the grouped result apply ORDER BY to it.","[{'comment': 'Change ""It"" to ""MySQL""', 'commenter': 'julianhyde'}, {'comment': 'done', 'commenter': 'JiajunBernoulli'}]"
3034,core/src/main/java/org/apache/calcite/sql/dialect/MysqlSqlDialect.java,"@@ -184,6 +185,46 @@ public MysqlSqlDialect(Context context) {
     return super.getCastSpec(type);
   }
 
+  /** {@inheritDoc}
+   *
+   * <p>MySQL format element reference:
+   * <a href=""https://dev.mysql.com/doc/refman/8.0/en/date-and-time-functions.html#function_date-format"">
+   * MySQL Date and Time Functions</a>.
+   */
+  @Override public String getFormatElement(FormatElementEnum fmtElement) {","[{'comment': 'Why does this logic go in MySqlSqlDialect?', 'commenter': 'tanclary'}, {'comment': 'Each dialect might have a different set of elements to represent the same type of datetime unit. \r\n\r\nFor example an abbreviated month name like `Jan` is `%b` in MySQL and `MON` in Snowflake. Each `SqlDialect` will have to override this method to supply the correct string for the element type. I only did MySQL, BigQuery, and Snowflake in the first commit because I wanted to get some feedback before working on each dialect.\r\n\r\nOracle\'s format elements were chosen as the ""base"" set since they map closely to the SQL:2016 standard as described in [CALCITE-2980](https://issues.apache.org/jira/browse/CALCITE-2980).', 'commenter': 'tjbanghart'}, {'comment': 'Makes sense! Looks great.', 'commenter': 'tanclary'}, {'comment': 'As I said previously, the association should be between the FORMAT function (as specified by MySQL) and the format element, not intermediated by the dialect object.', 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql/FormatModel.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql;
+
+import static org.apache.calcite.util.format.FormatElementEnum.D;
+import static org.apache.calcite.util.format.FormatElementEnum.DAY;
+import static org.apache.calcite.util.format.FormatElementEnum.DD;
+import static org.apache.calcite.util.format.FormatElementEnum.DDD;
+import static org.apache.calcite.util.format.FormatElementEnum.DY;
+import static org.apache.calcite.util.format.FormatElementEnum.HH24;
+import static org.apache.calcite.util.format.FormatElementEnum.IW;
+import static org.apache.calcite.util.format.FormatElementEnum.MI;
+import static org.apache.calcite.util.format.FormatElementEnum.MM;
+import static org.apache.calcite.util.format.FormatElementEnum.MON;
+import static org.apache.calcite.util.format.FormatElementEnum.MONTH;
+import static org.apache.calcite.util.format.FormatElementEnum.Q;
+import static org.apache.calcite.util.format.FormatElementEnum.SS;
+import static org.apache.calcite.util.format.FormatElementEnum.TZR;
+import static org.apache.calcite.util.format.FormatElementEnum.WW;
+import static org.apache.calcite.util.format.FormatElementEnum.YYYY;
+
+import org.apache.calcite.sql.fun.SqlLibrary;
+import org.apache.calcite.sql.type.OperandTypes;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.util.format.FormatElementEnum;
+import org.apache.calcite.util.format.FormatModelElement;
+import org.apache.calcite.util.format.FormatModelElementAlias;
+import org.apache.calcite.util.format.FormatModelElementLiteral;
+import org.apache.calcite.util.format.FormatModelUtil;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+
+/** A <a href=""https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlqr/Format-Models.html"">
+ * format model</a> is a character literal that describes the format of {@code DATETIME} or {@code
+ * NUMBER} data stored in a character string.
+ *
+ * <p>{@link #unparse(SqlWriter, SqlCall, int, int)} calls
+ * {@link SqlDialect#getFormatElement(FormatElementEnum)} for known elements and aliases. Consider
+ * overriding this method if a dialect's format elements differs from those in {@link
+ * FormatElementEnum}
+ */
+public class FormatModel extends SqlInternalOperator {
+
+  private List<FormatModelElement> elements;
+  private ImmutableMap<String, FormatModelElement> fmtModelParseMap;
+
+  /**
+   * TODO(CALCITE-2980): This should live elsewhere and be associated with {@link SqlLibrary}
+   * or {@link org.apache.calcite.config.Lex}.
+   */
+  public static final ImmutableMap<String, FormatModelElement> BIG_QUERY_FORMAT_ELEMENT_PARSE_MAP =","[{'comment': 'nit:  I know it\'s everywhere so no need to change it but in general I hake a bit when I see BigQuery since we really want to do ""Google SQL""', 'commenter': 'mkou'}, {'comment': 'For sure, I can open a Jira case to swap `GOOGLE_SQL` or `GSQL` with `BIG_QUERY` references -- would have to a non-breaking change for config settings etc.', 'commenter': 'tjbanghart'}, {'comment': ""As discussed in the review, the world knows only BigQuery SQL so it's simpler to call it BigQuery SQL. I agree that Google SQL is more correct but it's more important to be understood than to be 100% correct."", 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql/dialect/MysqlSqlDialect.java,"@@ -240,6 +281,17 @@ public MysqlSqlDialect(Context context) {
       unparseListAggCall(writer, call, null, leftPrec, rightPrec);
       break;
 
+    case FORMAT_DATE:
+    case FORMAT_TIME:
+    case FORMAT_TIMESTAMP:
+    case FORMAT_DATETIME:
+      writer.print(""DATE_FORMAT("");","[{'comment': 'This feels a bit weird for me but I might miss some context.\r\nShould this live in the definition of FORMAT_DATETIME that DATE_FORMAT is actually an aliases with the operands in different order + different formats elements?', 'commenter': 'mkou'}, {'comment': 'Like all of them should alias to the same canonical form so you can read the canonical form in every language idk if that makes sense', 'commenter': 'mkou'}, {'comment': ""Yeah that's open for discussion -- how to best swap a `FORMAT_TIMESTAMP` Google SQL style function call to any other dialect. Snowflake for example uses `TO_CHAR` or `TO_VARCHAR`. \r\n\r\nMaybe a generic entry in `SqlKind` called `GOOGLE_SQL_DATETIME_FORMAT`?\r\nCould even be more generic like `DATETIME_FORMAT` and then each dialect would know how to unparse."", 'commenter': 'tjbanghart'}, {'comment': 'Or better yet convert these BQ format functions into the standard `CAST(... as FORMAT <str>)` and unparse the `CAST` to `DATE_FORMAT`, `TO_CHAR` accordingly.', 'commenter': 'tjbanghart'}]"
3034,core/src/main/java/org/apache/calcite/sql/dialect/BigQuerySqlDialect.java,"@@ -271,6 +272,50 @@ private static TimeUnit validate(TimeUnit timeUnit) {
     }
   }
 
+  /** {@inheritDoc}
+   *
+   * <p>BigQuery format element reference:
+   * <a href=""https://cloud.google.com/bigquery/docs/reference/standard-sql/format-elements"">
+   * BigQuery Standard SQL Format Elements</a>.
+   */
+  @Override public String getFormatElement(FormatElementEnum fmtElement) {","[{'comment': 'Yes I like this 🌷 ', 'commenter': 'mkou'}, {'comment': 'I agree with @wnob that this `switch` should go, and it should use a map. Probably the map is bi-directional. Probably the map is the parse map, and that parse map can evolve from an ImmutableMap to a larger class.', 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelElement.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Maps;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * A format element in a format string. Knows how to parse and unparse itself.
+ */
+public interface FormatModelElement {","[{'comment': 'Adding examples for each methods would help take out some of the mental load of figuring out exactly the differences. (Easier to read) even though the names are are self suffiscient that would help ', 'commenter': 'mkou'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelUtil.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import com.google.common.collect.ImmutableMap;
+
+import java.util.List;
+import java.util.Stack;
+
+/**
+ * Utility class used to convert format strings into {@link FormatModelElement}s.
+ */
+public class FormatModelUtil {
+
+  private FormatModelUtil() {}
+
+  /**
+   * Parses the {@code fmtString} using element identifiers supplied by {@code fmtModel}.
+   *
+   * TODO(CALCITE-2980): make this configurable for multiple parse maps. Currently this only works
+   * for BigQuery and MySQL style format strings where elements begin with '%'
+   */
+  public static List<FormatModelElement> parse(String fmtString,","[{'comment': 'Not sure if this is a good advice or not but it looks like a good case to just use ReGex and look for the formats defined by each dialect', 'commenter': 'mkou'}, {'comment': 'Took a stab at this in most recent commit.', 'commenter': 'tjbanghart'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelElementAlias.java,"@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import org.checkerframework.checker.nullness.qual.Nullable;
+
+import java.util.Arrays;
+import java.util.List;
+import java.util.Objects;
+import java.util.StringJoiner;
+
+/**
+ * Represents a format element comprised of one or more {@link FormatElementEnum} entries.
+ */
+public class FormatModelElementAlias implements FormatModelElement {","[{'comment': 'what does this `FormatModelElementAlias` actually represent? a collection of `FormatModelElement`s? ', 'commenter': 'olivrlee'}, {'comment': ""Yeah exactly - it maps to one or more FormatModelElementEnum entries.\r\n\r\nFor example in Google SQL `%R` is the same as `HH24:MI`. I'll add more context/examples in the javadoc "", 'commenter': 'tjbanghart'}]"
3034,core/src/main/java/org/apache/calcite/sql/SqlDialect.java,"@@ -1002,6 +1004,18 @@ protected static void unparseOffset(SqlWriter writer, @Nullable SqlNode offset)
     }
   }
 
+  /**","[{'comment': ""There's a complex mapping between format elements and dialects. But I suspect that SqlDialect is not the right place to do it, and functions is closer to the right place.\r\n\r\nHypothetically, someone could be in MySQL dialect and want to enable MySQL's and Postgres's formatting functions. It's a useful hypothetical. SqlDialect is used only for a short part of the query life cycle - when going from AST nodes to SQL text. But functions are around for longer.\r\n\r\nI have in mind a map from strings to format elements that is part of the `SqlLibraryOperators.FORMAT_TIMESTAMP` function, and the same or similar map that is used by `FORMAT_TIME` and `PARSE_TIMESTAMP` functions. Parse functions might have an additional parser, because parsing format strings is not always trivial.\r\n\r\nMaybe the aforementioned 'map' and 'parser' would evolve into slightly larger classes.\r\n\r\nWhen we tackle the different issue for 'how do I translate a MySQL format string to a BigQuery format string?' - or 'how do I translate a call to MySQL_FORMAT_TIMESTAMP to a call to BigQuery_FORMAT_TIMESTAMP' - then those larger classes could be used to drive the proceedings."", 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql/fun/SqlBigQueryFormatDatetimeFunction.java,"@@ -0,0 +1,111 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlFunction;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlOperandTypeChecker;
+import org.apache.calcite.sql.type.SqlTypeFamily;
+import org.apache.calcite.sql.type.SqlTypeName;
+
+import java.util.Locale;
+
+import static org.apache.calcite.sql.type.SqlTypeName.DATE;
+import static org.apache.calcite.sql.type.SqlTypeName.TIME;
+
+/**
+ * <p> The Google BigQuery style datetime formatting functions. This is a generic type representing
+ * one of the following:</p>
+ *
+ * <ul>
+ *   <li>{@code FORMAT_TIME(format_string, time_object)}
+ *   <a href=""https://cloud.google.com/bigquery/docs/reference/standard-sql/time_functions#format_time"">ref</a></li>
+ *   <li>{@code FORMAT_DATE(format_string, date_expr)}
+ *   <a href=""https://cloud.google.com/bigquery/docs/reference/standard-sql/date_functions#format_date"">ref</a></li>
+ *   <li>{@code FORMAT_TIMESTAMP(format_string, timestamp[, time_zone])}
+ *  <a href=""https://cloud.google.com/bigquery/docs/reference/standard-sql/timestamp_functions#format_timestamp"">ref</a></li>
+ *  <li>{@code FORMAT_DATETIME(format_string, timestamp[, time_zone])}
+ *  <a href=""https://cloud.google.com/bigquery/docs/reference/standard-sql/datetime_functions#format_datetime"">ref</a></li>
+ * </ul>
+ */
+public class SqlBigQueryFormatDatetimeFunction extends SqlFunction {","[{'comment': ""Parsing/formatting functions might have enough commonality to warrant a common class - an extension to `SqlBasicFunction` with an extra field, a map from strings to format elements.\r\n\r\nI wouldn't change it now. But come back and refactor if that pattern emerges."", 'commenter': 'julianhyde'}, {'comment': 'However I would make the constructor private now. A public constructor will prevent you from subclassing later. Use a `create` method instead, and add `withXxx` methods to change the value of parameters that are not frequently used. (Same pattern as `SqlBasicFunction`, and a pattern that is a little nearer to functional programming than object-oriented.)', 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelUtil.java,"@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import com.google.common.collect.ImmutableMap;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Utility class used to convert format strings into {@link FormatModelElement}s.
+ */
+public class FormatModelUtil {
+
+  private FormatModelUtil() {}
+
+  /**
+   * Parses the {@code fmtString} using element identifiers supplied by {@code fmtModel}.
+   */
+  public static List<FormatModelElement> parse(String format,
+      ImmutableMap<String, FormatModelElement> fmtModelMap) {
+    List<FormatModelElement> elements = new ArrayList<>();
+    // TODO(CALCITE-2980): make these regex patterns static and tied to a library or dialect.
+    StringBuilder regex = new StringBuilder();
+    for (String key : fmtModelMap.keySet()) {
+      regex.append(""("").append(Pattern.quote(key)).append("")|"");","[{'comment': 'Make sure you get the longest match', 'commenter': 'mkou'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelUtil.java,"@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import com.google.common.collect.ImmutableMap;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * Utility class used to convert format strings into {@link FormatModelElement}s.
+ */
+public class FormatModelUtil {
+
+  private FormatModelUtil() {}
+
+  /**
+   * Parses the {@code fmtString} using element identifiers supplied by {@code fmtModel}.
+   */
+  public static List<FormatModelElement> parse(String format,
+      ImmutableMap<String, FormatModelElement> fmtModelMap) {
+    List<FormatModelElement> elements = new ArrayList<>();
+    // TODO(CALCITE-2980): make these regex patterns static and tied to a library or dialect.
+    StringBuilder regex = new StringBuilder();
+    for (String key : fmtModelMap.keySet()) {
+      regex.append(""("").append(Pattern.quote(key)).append("")|"");
+    }
+    // remove the last '|'
+    regex.setLength(regex.length() - 1);
+    Matcher matcher = Pattern.compile(regex.toString()).matcher(format);
+    int i = 0;
+    while (matcher.find()) {
+      // Add any leading literal text before next element match
+      String literal = format.substring(i, matcher.start());
+      if (!literal.isEmpty()) {
+        elements.add(new FormatModelElementLiteral(literal));","[{'comment': 'For parsing and unparsing, litterals might be in specific separators (`""` for example)', 'commenter': 'mkou'}]"
3034,core/src/main/java/org/apache/calcite/sql/FormatModel.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql;
+
+import org.apache.calcite.sql.fun.SqlLibrary;
+import org.apache.calcite.sql.type.OperandTypes;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.util.format.FormatElementEnum;
+import org.apache.calcite.util.format.FormatModelElement;
+import org.apache.calcite.util.format.FormatModelElementAlias;
+import org.apache.calcite.util.format.FormatModelElementLiteral;
+import org.apache.calcite.util.format.FormatModelUtil;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+import static org.apache.calcite.util.format.FormatElementEnum.D;
+import static org.apache.calcite.util.format.FormatElementEnum.DAY;
+import static org.apache.calcite.util.format.FormatElementEnum.DD;
+import static org.apache.calcite.util.format.FormatElementEnum.DDD;
+import static org.apache.calcite.util.format.FormatElementEnum.DY;
+import static org.apache.calcite.util.format.FormatElementEnum.HH24;
+import static org.apache.calcite.util.format.FormatElementEnum.IW;
+import static org.apache.calcite.util.format.FormatElementEnum.MI;
+import static org.apache.calcite.util.format.FormatElementEnum.MM;
+import static org.apache.calcite.util.format.FormatElementEnum.MON;
+import static org.apache.calcite.util.format.FormatElementEnum.MONTH;
+import static org.apache.calcite.util.format.FormatElementEnum.Q;
+import static org.apache.calcite.util.format.FormatElementEnum.SS;
+import static org.apache.calcite.util.format.FormatElementEnum.TZR;
+import static org.apache.calcite.util.format.FormatElementEnum.WW;
+import static org.apache.calcite.util.format.FormatElementEnum.YYYY;
+
+/** A <a href=""https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlqr/Format-Models.html"">","[{'comment': ""I try not to put a hyperlink in the first sentence of javadoc.\r\n\r\nThe first sentence is special, in that it becomes the public description of the class. It should be simple, like a headline. (In fact, the 'inverted pyramid' model of journalism applies to javadoc.) Go into details (including hyperlinks) in subsequent paragraphs."", 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql/FormatModel.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql;
+
+import org.apache.calcite.sql.fun.SqlLibrary;
+import org.apache.calcite.sql.type.OperandTypes;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.util.format.FormatElementEnum;
+import org.apache.calcite.util.format.FormatModelElement;
+import org.apache.calcite.util.format.FormatModelElementAlias;
+import org.apache.calcite.util.format.FormatModelElementLiteral;
+import org.apache.calcite.util.format.FormatModelUtil;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+import static org.apache.calcite.util.format.FormatElementEnum.D;
+import static org.apache.calcite.util.format.FormatElementEnum.DAY;
+import static org.apache.calcite.util.format.FormatElementEnum.DD;
+import static org.apache.calcite.util.format.FormatElementEnum.DDD;
+import static org.apache.calcite.util.format.FormatElementEnum.DY;
+import static org.apache.calcite.util.format.FormatElementEnum.HH24;
+import static org.apache.calcite.util.format.FormatElementEnum.IW;
+import static org.apache.calcite.util.format.FormatElementEnum.MI;
+import static org.apache.calcite.util.format.FormatElementEnum.MM;
+import static org.apache.calcite.util.format.FormatElementEnum.MON;
+import static org.apache.calcite.util.format.FormatElementEnum.MONTH;
+import static org.apache.calcite.util.format.FormatElementEnum.Q;
+import static org.apache.calcite.util.format.FormatElementEnum.SS;
+import static org.apache.calcite.util.format.FormatElementEnum.TZR;
+import static org.apache.calcite.util.format.FormatElementEnum.WW;
+import static org.apache.calcite.util.format.FormatElementEnum.YYYY;
+
+/** A <a href=""https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlqr/Format-Models.html"">
+ * format model</a> is a character literal that describes the format of {@code DATETIME} or {@code
+ * NUMBER} data stored in a character string.
+ *
+ * <p>{@link #unparse(SqlWriter, SqlCall, int, int)} calls
+ * {@link SqlDialect#getFormatElement(FormatElementEnum)} for known elements and aliases. Consider
+ * overriding this method if a dialect's format elements differs from those in {@link
+ * FormatElementEnum}
+ */
+public class FormatModel extends SqlInternalOperator {
+
+  private final List<FormatModelElement> elements;
+  private final ImmutableMap<String, FormatModelElement> fmtModelParseMap;","[{'comment': ""Field type should be `ImmutableMap<String, FormatModelElement>` rather than `Map<String, FormatModelElement>`. (I absolutely agree that the field value should be an `ImmutableMap`.) It's bad form to include implementation details in the field declaration. So, `TreeSet` bad, `SortedSet` good.\r\n\r\nThis is especially important for public fields and methods. People want to shade guava."", 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql/FormatModel.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql;
+
+import org.apache.calcite.sql.fun.SqlLibrary;
+import org.apache.calcite.sql.type.OperandTypes;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.util.format.FormatElementEnum;
+import org.apache.calcite.util.format.FormatModelElement;
+import org.apache.calcite.util.format.FormatModelElementAlias;
+import org.apache.calcite.util.format.FormatModelElementLiteral;
+import org.apache.calcite.util.format.FormatModelUtil;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+import static org.apache.calcite.util.format.FormatElementEnum.D;
+import static org.apache.calcite.util.format.FormatElementEnum.DAY;
+import static org.apache.calcite.util.format.FormatElementEnum.DD;
+import static org.apache.calcite.util.format.FormatElementEnum.DDD;
+import static org.apache.calcite.util.format.FormatElementEnum.DY;
+import static org.apache.calcite.util.format.FormatElementEnum.HH24;
+import static org.apache.calcite.util.format.FormatElementEnum.IW;
+import static org.apache.calcite.util.format.FormatElementEnum.MI;
+import static org.apache.calcite.util.format.FormatElementEnum.MM;
+import static org.apache.calcite.util.format.FormatElementEnum.MON;
+import static org.apache.calcite.util.format.FormatElementEnum.MONTH;
+import static org.apache.calcite.util.format.FormatElementEnum.Q;
+import static org.apache.calcite.util.format.FormatElementEnum.SS;
+import static org.apache.calcite.util.format.FormatElementEnum.TZR;
+import static org.apache.calcite.util.format.FormatElementEnum.WW;
+import static org.apache.calcite.util.format.FormatElementEnum.YYYY;
+
+/** A <a href=""https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlqr/Format-Models.html"">
+ * format model</a> is a character literal that describes the format of {@code DATETIME} or {@code
+ * NUMBER} data stored in a character string.
+ *
+ * <p>{@link #unparse(SqlWriter, SqlCall, int, int)} calls
+ * {@link SqlDialect#getFormatElement(FormatElementEnum)} for known elements and aliases. Consider
+ * overriding this method if a dialect's format elements differs from those in {@link
+ * FormatElementEnum}
+ */
+public class FormatModel extends SqlInternalOperator {
+
+  private final List<FormatModelElement> elements;
+  private final ImmutableMap<String, FormatModelElement> fmtModelParseMap;
+
+  /**
+   * TODO(CALCITE-2980): This should live elsewhere and be associated with {@link SqlLibrary}
+   * or {@link org.apache.calcite.config.Lex}.
+   */
+  public static final ImmutableMap<String, FormatModelElement> BIG_QUERY_FORMAT_ELEMENT_PARSE_MAP =
+      FormatModelElement.listToMap(
+          new ImmutableList.Builder<FormatModelElement>()
+              .add(FormatModelElementAlias.create(""%A"", DAY))
+              .add(FormatModelElementAlias.create(""%a"", DY))
+              .add(FormatModelElementAlias.create(""%B"", MONTH))
+              .add(FormatModelElementAlias.create(""%b"", MON))
+              .add(FormatModelElementAlias.create(""%d"", DD))
+              .add(FormatModelElementAlias.create(""%H"", HH24))
+              .add(FormatModelElementAlias.create(""%h"", MON))
+              .add(FormatModelElementAlias.create(""%j"", DDD))
+              .add(FormatModelElementAlias.create(""%k"", HH24))
+              .add(FormatModelElementAlias.create(""%M"", MI))
+              .add(FormatModelElementAlias.create(""%m"", MM))
+              .add(FormatModelElementAlias.create(""%Q"", Q))
+              .add(
+                  FormatModelElementAlias.create(""%R"",
+                      Arrays.asList(HH24, new FormatModelElementLiteral("":""), MI),
+                      ""The time in the format %H:%M""))
+              .add(FormatModelElementAlias.create(""%S"", SS))
+              .add(FormatModelElementAlias.create(""%U"", WW))
+              .add(FormatModelElementAlias.create(""%u"", D))
+              .add(FormatModelElementAlias.create(""%V"", IW))
+              .add(FormatModelElementAlias.create(""%W"", WW))
+              .add(FormatModelElementAlias.create(""%Y"", YYYY))
+              .add(FormatModelElementAlias.create(""%Z"", TZR))
+              .build());
+
+
+  public FormatModel(String fmtString, SqlLibrary library) {","[{'comment': ""I think the `library` argument should go. The main association is between FormatModel and function (a subclass of SqlFunction such as SqlLibraryOperators.FORMAT_TIMESTAMP), and no direct association with either  `SqlLibrary` or `SqlDialect`.\r\n\r\nLater, there will be an association between `SqlDialect` and `SqlFunction`, namely, 'in the MySQL dialect, which is the equivalent of the `FORMAT_TIMESTAMP` function' but that can come later."", 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql/FormatModel.java,"@@ -0,0 +1,154 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql;
+
+import org.apache.calcite.sql.fun.SqlLibrary;
+import org.apache.calcite.sql.type.OperandTypes;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlTypeName;
+import org.apache.calcite.sql.type.SqlTypeTransforms;
+import org.apache.calcite.util.format.FormatElementEnum;
+import org.apache.calcite.util.format.FormatModelElement;
+import org.apache.calcite.util.format.FormatModelElementAlias;
+import org.apache.calcite.util.format.FormatModelElementLiteral;
+import org.apache.calcite.util.format.FormatModelUtil;
+
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableMap;
+
+import java.util.Arrays;
+import java.util.List;
+
+import static org.apache.calcite.util.format.FormatElementEnum.D;
+import static org.apache.calcite.util.format.FormatElementEnum.DAY;
+import static org.apache.calcite.util.format.FormatElementEnum.DD;
+import static org.apache.calcite.util.format.FormatElementEnum.DDD;
+import static org.apache.calcite.util.format.FormatElementEnum.DY;
+import static org.apache.calcite.util.format.FormatElementEnum.HH24;
+import static org.apache.calcite.util.format.FormatElementEnum.IW;
+import static org.apache.calcite.util.format.FormatElementEnum.MI;
+import static org.apache.calcite.util.format.FormatElementEnum.MM;
+import static org.apache.calcite.util.format.FormatElementEnum.MON;
+import static org.apache.calcite.util.format.FormatElementEnum.MONTH;
+import static org.apache.calcite.util.format.FormatElementEnum.Q;
+import static org.apache.calcite.util.format.FormatElementEnum.SS;
+import static org.apache.calcite.util.format.FormatElementEnum.TZR;
+import static org.apache.calcite.util.format.FormatElementEnum.WW;
+import static org.apache.calcite.util.format.FormatElementEnum.YYYY;
+
+/** A <a href=""https://docs.oracle.com/en/database/oracle/oracle-database/21/sqlqr/Format-Models.html"">
+ * format model</a> is a character literal that describes the format of {@code DATETIME} or {@code
+ * NUMBER} data stored in a character string.
+ *
+ * <p>{@link #unparse(SqlWriter, SqlCall, int, int)} calls
+ * {@link SqlDialect#getFormatElement(FormatElementEnum)} for known elements and aliases. Consider
+ * overriding this method if a dialect's format elements differs from those in {@link
+ * FormatElementEnum}
+ */
+public class FormatModel extends SqlInternalOperator {","[{'comment': '`FormatModel` should not extend `SqlInternalOperator`. Operators (and functions) should be fixed i.e. stored in public static final fields.\r\n\r\nThere should be a way to convert a string to a `FormatModel`. That should be a property of each function (e.g. FORMAT_TIMESTAMP has one, and CAST has another. It is probably invoked at run time, i.e. the first time the function is called.\r\n', 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -780,6 +784,29 @@ public RexNode convertWindowFunction(
     return cx.getRexBuilder().makeCall(returnType, fun, exprs);
   }
 
+  public RexNode convertFormatDatetimeFunction(
+      SqlRexContext cx,
+      SqlBigQueryFormatDatetimeFunction fun,
+      SqlCall call) {
+    final RexBuilder rexBuilder = cx.getRexBuilder();
+    final List<RexNode> exprs =
+        IntStream.range(0, call.getOperandList().size())
+            .mapToObj(i -> {
+              SqlNode op = call.operand(i);
+              // convert the first char literal arg to a format model
+              if (i == 0 && op.getClass() == SqlCharStringLiteral.class) {","[{'comment': 'I think that creating a `FormatModel` as a new function at compile time is literally premature optimization. It will be difficult to write rules that work on this operator, to serialize the plan as JSON, to convert the plan back to SQL in another dialect, and many other things. Just keep the argument as a string expression.', 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelElement.java,"@@ -0,0 +1,90 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Maps;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * A format element in a format string. Knows how to parse and unparse itself.
+ */
+public interface FormatModelElement {","[{'comment': ""I would rename 'FormatModelElement' to 'FormatElement'. It's shorter, and several subclasses follow this convention already."", 'commenter': 'julianhyde'}]"
3034,core/src/main/java/org/apache/calcite/util/format/FormatModelElement.java,"@@ -0,0 +1,90 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.util.format;
+
+import com.google.common.collect.ImmutableMap;
+import com.google.common.collect.Maps;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * A format element in a format string. Knows how to parse and unparse itself.
+ */
+public interface FormatModelElement {
+  /** TODO(CALCITE-2980): use these methods when implementing format functions. */
+  // String unparseFromDate(java.util.Date date);
+  // String unparseFromInt(Integer date);
+  // String unparseFromLong(Long timestamp);
+
+  /**
+   * Returns the literal value of an element.
+   *
+   * <p>For example, {@code %H} in MySQL represents the hour in 24-hour format (e.g., 00..23). This
+   * method returns the string literal ""%H"".
+   */
+  String getLiteral();
+
+  /**
+   * Returns the {@link FormatElementEnum} token representing the element.
+   *
+   * <p>For example, {@code %H} in MySQL represents the hour in 24-hour format (e.g., 00..23). This
+   * method returns the string ""HH24"" which is the name of the FormatElementEnum {@code HH24}
+   */
+  String getToken();
+
+  /**
+   * Returns the description of an element.
+   *
+   * <p>For example, {@code %H} in MySQL represents the hour in 24-hour format (e.g., 00..23). This
+   * method returns the string ""The hour (24-hour clock) as a decimal number (00-23)"" which is the
+   * description of the FormatElementEnum {@code HH24}
+   */
+  String getDescription();
+
+  /**
+   * Whether this element is a {@link FormatModelElementAlias}. An alias comprises one or
+   * more standard elements declared in {@link FormatElementEnum}.
+   *
+   * <p>For example, {@code %R} in Google SQL represents the hour in 24-hour format (e.g., 00..23)
+   * followed by the minute as a decimal number. This method would return {@code true} as ""%R"" is
+   * an alias for the standard elements {@code HH24} and {@code MI}.
+   */
+  default boolean isAlias() {","[{'comment': ""`isAlias` makes you think that there are only two subtypes but there are 3 or 4 - built in, literal, composite, and maybe other user-defined.\r\n\r\nI would replace both `isAlias` and `getElements` with a method\r\n```\r\ndefault void flatten(Consumer<FormatModelElement> consumer) {\r\n  consumer.accept(this);\r\n}\r\n```\r\nthat is overridden in the composite format element.\r\n\r\nIt's possible that format elements shouldn't have names. The names are just keys by which they are included in a map. So the 'alias' behavior is better described as 'composite'."", 'commenter': 'julianhyde'}]"
3079,core/src/main/codegen/default_config.fmpp,"@@ -84,8 +84,10 @@ parser: {
     ""DATA""
     ""DATABASE""
     ""DATE_TRUNC""
+    ""DATETIME_DIFF""
     ""DATETIME_INTERVAL_CODE""
     ""DATETIME_INTERVAL_PRECISION""
+    ""DATE_DIFF""","[{'comment': 'nit: alphabetically next to DATE_TRUNC, or move DATE_TRUNC down here too (visually _ comes before T to me, but maybe ASCII-wise DATE_ should be after DATET?) ', 'commenter': 'olivrlee'}, {'comment': 'I was also confused about this, on lines 317-321 of this file, _ is given alphabetic precedence over letters, and then letters over _. I agree that visually it comes before. Maybe @julianhyde has thoughts?', 'commenter': 'tanclary'}, {'comment': 'I forget what the rules are. I would defer to UNIX `sort` (using `LC_ALL=C` to override my locale):\r\n\r\n```\r\n$ LC_ALL=C sort<<EOF\r\n    ""DATE_DIFF""\r\n    ""DATETIME_INTERVAL_CODE""\r\n    ""DATETIME_INTERVAL_PRECISION""\r\nEOF\r\n    ""DATETIME_INTERVAL_CODE""\r\n    ""DATETIME_INTERVAL_PRECISION""\r\n    ""DATE_DIFF""\r\n```\r\n', 'commenter': 'julianhyde'}]"
3079,babel/src/test/resources/sql/big-query.iq,"@@ -1798,21 +1811,20 @@ SELECT
 #
 # Returns INT64
 
-!if (false) {
 SELECT
   DATETIME ""2010-07-07 10:20:00"" as first_datetime,
   DATETIME ""2008-12-25 15:30:00"" as second_datetime,
   DATETIME_DIFF(DATETIME ""2010-07-07 10:20:00"",
     DATETIME ""2008-12-25 15:30:00"", DAY) as difference;
-+----------------------------+------------------------+------------------------+
-| first_datetime             | second_datetime        | difference             |
-+----------------------------+------------------------+------------------------+
-| 2010-07-07T10:20:00        | 2008-12-25T15:30:00    | 559                    |
-+----------------------------+------------------------+------------------------+
++---------------------+---------------------+------------+
+| first_datetime      | second_datetime     | difference |
++---------------------+---------------------+------------+
+| 2010-07-07 10:20:00 | 2008-12-25 15:30:00 |        558 |
++---------------------+---------------------+------------+
+(1 row)","[{'comment': 'difference has changed from 559 to 558. which is the correct value?\r\n\r\nAdd a comment to the test justifying the value.', 'commenter': 'julianhyde'}, {'comment': ""I ran this test for timestamp_diff on a fresh branch cut from Calcite main and it also returns 558, although the BigQuery docs have 559 as the answer so it appears unrelated to these changes, I'm looking more into it."", 'commenter': 'tanclary'}, {'comment': 'So after doing some more research, I have realized that BigQuery truncates in every case except for hour. I modified the IF statement to account for this. They even have a test for this in their docs which you can find [here](https://cloud.google.com/bigquery/docs/reference/standard-sql/timestamp_functions#timestamp_diff). It seems odd that HOUR would be the only case where the result is based on the whole number rather than the number of part boundaries, but that seems to be the general rule. ', 'commenter': 'tanclary'}]"
3079,core/src/main/codegen/templates/Parser.jj,"@@ -7313,6 +7361,12 @@ SqlNode JdbcFunctionCall() :
         s = span();
     }
     (
+        LOOKAHEAD(1)
+        call = DateDiffFunctionCall() {
+            name = call.getOperator().getName();
+            args = new SqlNodeList(call.getOperandList(), getPos());
+        }","[{'comment': ""why have you added a call to `DateDiffFunctionCall` but not `DatetimeDiffFunctionCall`?\r\n\r\nwith this omission, I don't understand how the tests could pass."", 'commenter': 'julianhyde'}, {'comment': ""I mistakenly created DatetimeDiffFunctionCall as a SqlNode instead of a SqlCall so it was circumventing this. I'm not entirely sure how it was passing, but I've updated it to be consistent with the other function calls."", 'commenter': 'tanclary'}]"
3079,core/src/main/java/org/apache/calcite/sql/SqlKind.java,"@@ -1215,6 +1218,7 @@ public enum SqlKind {
                   FILTER, WITHIN_GROUP, IGNORE_NULLS, RESPECT_NULLS, SEPARATOR,
                   DESCENDING, CUBE, ROLLUP, GROUPING_SETS, EXTEND, LATERAL,
                   SELECT, JOIN, OTHER_FUNCTION, POSITION, CAST, TRIM, FLOOR, CEIL,
+                  DATE_ADD, TIMESTAMP_ADD, TIMESTAMP_DIFF, EXTRACT, INTERVAL,","[{'comment': 'EXTRACT, INTERVAL and maybe others are now duplicated.', 'commenter': 'julianhyde'}, {'comment': 'This got messed up during rebase, sorry about that.', 'commenter': 'tanclary'}]"
3079,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -933,6 +948,22 @@ private SqlLibraryOperators() {
           ReturnTypes.BIGINT_NULLABLE, OperandTypes.TIMESTAMP,
           SqlFunctionCategory.TIMEDATE);
 
+  /** BigQuery's ""DATETIME_ADD(timestamp, interval) function; Behaves similarly","[{'comment': 'Change `BigQuery\'s ""DATETIME_ADD(timestamp, interval) function` to `The ""DATETIME_ADD(timestamp, interval) function (BigQuery)`. I don\'t want to assume that no other library will ever use it.\r\n\r\nCenter the javadoc in Calcite, not BigQuery. Change ""; Behaves similarly to BigQuery\'s TIMESTAMP_ADD because in Calcite, datetime is a type alias for timestamp."" to "". Like {@code TIMESTAMP_ADD}, returns a Calcite {@code TIMESTAMP} (which BigQuery calls a {@code DATETIME}).""', 'commenter': 'julianhyde'}]"
3079,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -933,6 +948,22 @@ private SqlLibraryOperators() {
           ReturnTypes.BIGINT_NULLABLE, OperandTypes.TIMESTAMP,
           SqlFunctionCategory.TIMEDATE);
 
+  /** BigQuery's ""DATETIME_ADD(timestamp, interval) function; Behaves similarly
+   * to BigQuery's TIMESTAMP_ADD because in Calcite, datetime is a type alias
+   * for timestamp. */
+  @LibraryOperator(libraries = {BIG_QUERY})
+  public static final SqlFunction DATETIME_ADD =
+      TIMESTAMP_ADD2.withName(""DATETIME_ADD"");
+
+  /** BigQuery's ""DATETIME_DIFF(timestamp, timestamp, timeUnit) function; Behaves
+   * similarly to BigQuery's TIMESTAMP_DIFF because in Calcite, datetime is a type
+   * alias for timestamp. Returns the whole number of timeUnit between datetime
+   * and datetime2, with the result being negative if datetime occurs before datetime2. */
+  @LibraryOperator(libraries = {BIG_QUERY})
+  public static final SqlFunction DATETIME_DIFF =","[{'comment': 'As TIMESTAMP_ADD. Also change signature to DATETIME_DIFF(timestamp, timestamp2, timeUnit)"" and fix references to ""datetime"" and ""datetime2"" in the description.', 'commenter': 'julianhyde'}]"
3079,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -2027,13 +2050,38 @@ private static class TimestampDiffConvertlet implements SqlRexConvertlet {
                 qualifier.getParserPosition());
         break;
       }
-      final RelDataType intervalType =
-          cx.getTypeFactory().createTypeWithNullability(
-              cx.getTypeFactory().createSqlIntervalType(qualifier),
-              op1.getType().isNullable() || op2.getType().isNullable());
-      final RexCall rexCall = (RexCall) rexBuilder.makeCall(
-          intervalType, SqlStdOperatorTable.MINUS_DATE,
-          ImmutableList.of(op2, op1));
+
+      RelDataType intervalType;
+      RexCall rexCall;
+      /* This additional logic handles the differing definitions of 'WEEK' between BigQuery","[{'comment': 'Use Java-style comments (`//`) rather than C-style (`/*` ... `*/`)', 'commenter': 'julianhyde'}]"
3079,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -1974,27 +1982,42 @@ private static class TimestampDiffConvertlet implements SqlRexConvertlet {
       SqlIntervalQualifier qualifier;
       final RexNode op1;
       final RexNode op2;
-      if (call.operand(0).getKind() == SqlKind.INTERVAL_QUALIFIER) {
-        qualifier = call.operand(0);
-        op1 = cx.convertExpression(call.operand(1));
-        op2 = cx.convertExpression(call.operand(2));
-      } else {
+      final boolean isBigQuery = !(call.operand(0).getKind() == SqlKind.INTERVAL_QUALIFIER);","[{'comment': ""I don't think the `isBigQuery` variable helps much. You should extend the comment, a few lines previously, about the two variants, and how one only occurs in BigQuery mode.\r\n\r\nYou should also explain why TIMESTAMP_TRUNC calls are necessary."", 'commenter': 'julianhyde'}, {'comment': 'I moved and modified my comments a bit, feel free to let me know if you have other suggestions.', 'commenter': 'tanclary'}]"
3079,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -2027,13 +2050,38 @@ private static class TimestampDiffConvertlet implements SqlRexConvertlet {
                 qualifier.getParserPosition());
         break;
       }
-      final RelDataType intervalType =
-          cx.getTypeFactory().createTypeWithNullability(
-              cx.getTypeFactory().createSqlIntervalType(qualifier),
-              op1.getType().isNullable() || op2.getType().isNullable());
-      final RexCall rexCall = (RexCall) rexBuilder.makeCall(
-          intervalType, SqlStdOperatorTable.MINUS_DATE,
-          ImmutableList.of(op2, op1));
+
+      RelDataType intervalType;
+      RexCall rexCall;
+      /* This additional logic handles the differing definitions of 'WEEK' between BigQuery
+      *  and Calcite. BigQuery considers Sunday as the start of the week, so two dates whose
+      *  day difference is <7 may have a week difference of 1 if they occur on two different","[{'comment': ""Your comments seem to imply that the difference is due to weeks starting on a different day. I don't think that's true. Calcite considers Sunday to be the start of the week too. (Monday the start of an ISOWEEK.)\r\n\r\nI think it's just that this particular function truncates before it subtracts."", 'commenter': 'julianhyde'}, {'comment': 'I will update the comment. What I was trying to say is, Calcite currently computes the number of weeks between two dates by dividing the number of days between them by 7 (and flooring the result). BigQuery however essentially checks how many Sundays are between the two dates, which in certain cases causes a discrepancy.', 'commenter': 'tanclary'}]"
3079,site/_docs/reference.md,"@@ -2649,8 +2653,12 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | DATETIME(date)                                 | Converts *date* to a TIMESTAMP value (at midnight)
 | b | DATETIME(date, timeZone)                       | Converts *date* to a TIMESTAMP value (at midnight), in *timeZone*
 | b | DATETIME(year, month, day, hour, minute, second) | Creates a TIMESTAMP for *year*, *month*, *day*, *hour*, *minute*, *second* (all of type INTEGER)
+| b | DATETIME_ADD(datetime, interval)               | Returns the DATETIME value that occurs *interval* after *datetime*","[{'comment': 's/DATETIME/TIMESTAMP', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/jdbc/Driver.java,"@@ -64,6 +64,15 @@ public Driver() {
     this.prepareFactory = createPrepareFactory();
   }
 
+  private Driver(Function0<CalcitePrepare> prepareFactory) {","[{'comment': 'unify constructors. all constructors except one should call other constructors.', 'commenter': 'julianhyde'}, {'comment': ""I've unified the constructors in my last commit: https://github.com/apache/calcite/pull/3084/commits/5314d5d29e5cd6d271626d7b877125278e8292d4#diff-202586edbf28484a3a4c1498d8f61096e7a12c0a9c813260fb4282b5c19a3e96R63\r\n\r\nBut it doesn't compile due to no explicit assigning of prepareFactory. \r\nDo you have suggestions here?"", 'commenter': 'olivrlee'}, {'comment': ""You're right there's a problem. The problem is that the constructor calls `createPrepareFactory()` - an instance method - before the constructor is complete, and that's a code smell, because it doesn't allow the class to be subclassed cleanly.\r\n\r\nIs there a way to change the design of `Driver` so that it doesn't have that code smell?\r\n\r\nI like the idea of adding `Driver withPrepareFactory(Supplier<CalcitePrepare>)` so that people don't have to subclass Driver. But we have to do so compatibly. "", 'commenter': 'julianhyde'}, {'comment': 'The way that its designed seems to imply some conflicting restraints\r\n- we need `createPrepareFactory()` to be override-able (use cases in JdbcTest.java), thus has to stay an instance method \r\n- we want `prepareFactory` to be `final` \r\n- all constructors except 1 have to call 1 constructor\r\n\r\nIs there a way to satisfy all 3 without conflicts? \r\n\r\n', 'commenter': 'olivrlee'}, {'comment': 'Pushed a change so that `private Driver(prepareFactory)` calls the `public Driver()`', 'commenter': 'olivrlee'}]"
3084,core/src/main/java/org/apache/calcite/jdbc/Driver.java,"@@ -64,6 +64,15 @@ public Driver() {
     this.prepareFactory = createPrepareFactory();
   }
 
+  private Driver(Function0<CalcitePrepare> prepareFactory) {
+    super();
+    this.prepareFactory = prepareFactory;
+  }
+  public Driver withPrepareFactory(Function0<CalcitePrepare> prepareFactory) {","[{'comment': 'add newline and javadoc', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/prepare/CalcitePrepareImpl.java,"@@ -514,14 +514,35 @@ <T> CalciteSignature<T> prepare_(
         throw new AssertionError(""factory returned null planner"");
       }
       try {
+        CalcitePreparingStmt preparingStmt = getPreparingStmt(
+            context, elementType, catalogReader, planner);
         return prepare2_(context, query, elementType, maxRowCount,
-            catalogReader, planner);
+            catalogReader, preparingStmt);
       } catch (RelOptPlanner.CannotPlanException e) {
         exception = e;
       }
     }
     throw exception;
   }
+  protected CalcitePreparingStmt getPreparingStmt(","[{'comment': 'add newline and javadoc', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/prepare/CalcitePrepareImpl.java,"@@ -590,21 +611,8 @@ <T> CalciteSignature<T> prepare2_(
       Type elementType,
       long maxRowCount,
       CalciteCatalogReader catalogReader,
-      RelOptPlanner planner) {
+      CalcitePreparingStmt preparingStmt) {","[{'comment': 'Is CalcitePreparingStmt required? Or could parameter be a superclass?', 'commenter': 'julianhyde'}, {'comment': '`createSqlValidator` is only available in `CalcitePreparingStmt` so it has to be `CalcitePreparingStmt`', 'commenter': 'olivrlee'}]"
3084,core/src/main/java/org/apache/calcite/prepare/CalcitePrepareImpl.java,"@@ -937,8 +944,10 @@ public <R> R perform(CalciteServerStatement statement,
         prepareContext.getRootSchema().plus(), statement);
   }
 
-  /** Holds state for the process of preparing a SQL statement. */
-  static class CalcitePreparingStmt extends Prepare
+  /** Holds state for the process of preparing a SQL statement.
+   *  Overload this class and {@link #createSqlValidator} to supply custom validation logic.
+   * */
+  public static class CalcitePreparingStmt extends Prepare","[{'comment': 'improve javadoc formatting. second sentence should be a new paragraph. use `**/` rather than `* */`.', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/prepare/CalciteSqlValidator.java,"@@ -22,10 +22,12 @@
 import org.apache.calcite.sql.SqlOperatorTable;
 import org.apache.calcite.sql.validate.SqlValidatorImpl;
 
-/** Validator. */
-class CalciteSqlValidator extends SqlValidatorImpl {
+/** Validator.
+ *  Public access-level to allow overriding and custom validation logic.
+ * */","[{'comment': 'Similar comments to previous javadoc. Second sentence should be a paragraph. Also a sentence.', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/jdbc/Driver.java,"@@ -64,6 +64,21 @@ public Driver() {
     this.prepareFactory = createPrepareFactory();
   }
 
+  private Driver(Function0<CalcitePrepare> prepareFactory) {
+    new Driver();","[{'comment': 'This statement is useless. It creates a Driver and throws it away.', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/jdbc/Driver.java,"@@ -64,6 +64,21 @@ public Driver() {
     this.prepareFactory = createPrepareFactory();
   }
 
+  private Driver(Function0<CalcitePrepare> prepareFactory) {
+    new Driver();
+    this.prepareFactory = prepareFactory;
+  }
+
+  /** Allows changing prepareFactory without having to subclass Driver.
+   *
+   * @param prepareFactory {@link org.apache.calcite.jdbc.CalcitePrepare}
+   * @return Driver with the provided prepareFactory
+   */
+  public Driver withPrepareFactory(Function0<CalcitePrepare> prepareFactory) {","[{'comment': 'Use java.util.Supplier rather than Guava Function0', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/prepare/CalcitePrepareImpl.java,"@@ -954,7 +971,7 @@ static class CalcitePreparingStmt extends Prepare
     private int expansionDepth;
     private @Nullable SqlValidator sqlValidator;
 
-    CalcitePreparingStmt(CalcitePrepareImpl prepare,
+    public CalcitePreparingStmt(CalcitePrepareImpl prepare,","[{'comment': 'publlc methods need javadoc', 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/prepare/CalciteSqlValidator.java,"@@ -22,10 +22,13 @@
 import org.apache.calcite.sql.SqlOperatorTable;
 import org.apache.calcite.sql.validate.SqlValidatorImpl;
 
-/** Validator. */
-class CalciteSqlValidator extends SqlValidatorImpl {
+/** Validator.
+ *
+ *  <p>This class has public access-level to allow overriding and custom validation logic.</p>","[{'comment': ""I don't think this paragraph adds much. I'd remove it."", 'commenter': 'julianhyde'}]"
3084,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -771,6 +771,11 @@ private void checkTableFunctionInModel(Class<?> clazz) {
     }
   }
 
+  @Test void testCustomValidator() {
+    final Driver driver = new MockDdlDriver().withPrepareFactory(MockPrepareImpl::new);
+    assertTrue(driver.prepareFactory.apply().getClass() == MockPrepareImpl.class);","[{'comment': 'Use assertThat(...getClass(), is()). Better error message if it fails.', 'commenter': 'julianhyde'}]"
3084,testkit/src/main/java/org/apache/calcite/test/RelOptFixture.java,"@@ -76,8 +76,10 @@
  * <p>A fixture is immutable. If you have two test cases that require a similar
  * set up (for example, the same SQL expression and set of planner rules), it is
  * safe to use the same fixture object as a starting point for both tests.
+ *
+ * <p>The class has public access-level to allow implementing custom fixtures.","[{'comment': ""I don't think this paragraph adds much. I think you should remove it. (It's not even true; the constructor remains package-private because we don't want people subclassing.)"", 'commenter': 'julianhyde'}]"
3084,core/src/main/java/org/apache/calcite/jdbc/Driver.java,"@@ -52,7 +52,7 @@
 public class Driver extends UnregisteredDriver {
   public static final String CONNECT_STRING_PREFIX = ""jdbc:calcite:"";
 
-  final Function0<CalcitePrepare> prepareFactory;
+  public final Function0<CalcitePrepare> prepareFactory;","[{'comment': 'This should remain package-private; but change the type to `Supplier`. Add a method\r\n\r\n```\r\npublic CalcitePrepare createPrepare() {\r\n  return prepareFactory.get();\r\n}\r\n```', 'commenter': 'julianhyde'}]"
3093,core/src/main/java/org/apache/calcite/rex/RexBuilder.java,"@@ -808,6 +904,29 @@ public RexNode makeAbstractCast(
         ImmutableList.of(exp));
   }
 
+  /**
+   * Creates a call to CAST or SAFE_CAST operator.
+   *
+   * @param type Type to cast to
+   * @param exp  Expression being cast
+   * @param kind  Either SqlKind.CAST or SqlKind.SAFE_CAST
+   * @return Call to CAST operator
+   */
+  public RexNode makeAbstractCast(
+      RelDataType type,
+      RexNode exp,
+      SqlKind kind) {
+    assert Arrays.asList(SqlKind.CAST, SqlKind.SAFE_CAST).contains(kind);
+    return kind == SqlKind.SAFE_CAST ? new RexCall(","[{'comment': ""can you re-organize this expression so that it is easier to see what's happening?"", 'commenter': 'julianhyde'}]"
3093,core/src/main/java/org/apache/calcite/rex/RexExecutable.java,"@@ -102,6 +102,38 @@ public void reduce(RexBuilder rexBuilder, List<RexNode> constExps,
     Hook.EXPRESSION_REDUCER.run(Pair.of(code, values));
   }
 
+  /**
+   * Same as {@link #reduce(RexBuilder, List, List)} but with a flag to throw on failure.
+   * <p>Catch the exception to return null for SAFE_ functions.</p>","[{'comment': 'looks like a lot of duplicate code', 'commenter': 'julianhyde'}, {'comment': ""This was because you had a comment saying public methods shouldnt just be changed, but a new one should be written and the old deprecated -- maybe that doesn't apply here? "", 'commenter': 'olivrlee'}, {'comment': ""You can usually move the method body into the new method (with the extra parameter) and have the old (deprecated) method call the new method.\r\n\r\nIf the old method is deprecated you should change all calls to use the new method, and remove its javadoc. Thus the new method's javadoc wouldn't be 'Same as (old method)'."", 'commenter': 'julianhyde'}]"
3093,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -2144,93 +2146,101 @@ private RexNode simplifySearch(RexCall call, RexUnknownAs unknownAs) {
     return call;
   }
 
-  private RexNode simplifyCast(RexCall e) {
+  private RexNode simplifyCast(RexCall e, boolean throwOnFailure) {","[{'comment': ""Does `throwOnFailure` relate to failure of this method - i.e. the effort to simplify - of failure of the cast at run time? You seem to have implemented the former, but I don't think that's what we need."", 'commenter': 'julianhyde'}]"
3093,core/src/main/java/org/apache/calcite/sql/fun/SqlCastFunction.java,"@@ -168,7 +182,7 @@ public SqlCastFunction() {
   }
 
   @Override public SqlSyntax getSyntax() {
-    return SqlSyntax.SPECIAL;
+    return this.kind == SqlKind.CAST ? SqlSyntax.SPECIAL : SqlSyntax.FUNCTION;","[{'comment': ""if SAFE_CAST requires AS, it's not function syntax"", 'commenter': 'julianhyde'}, {'comment': '+1, SAFE_CAST is a special SqlSyntax', 'commenter': 'zoudan'}]"
3093,core/src/main/codegen/templates/Parser.jj,"@@ -6008,6 +6008,18 @@ SqlNode BuiltinFunctionCall() :
         <RPAREN> {
             return SqlStdOperatorTable.CAST.createCall(s.end(this), args);
         }
+    |","[{'comment': 'could you combine with the logic for <CAST>?', 'commenter': 'julianhyde'}]"
3093,linq4j/src/main/java/org/apache/calcite/linq4j/tree/Expressions.java,"@@ -1198,6 +1200,26 @@ public static <T, F extends Function<? extends T>> FunctionExpression<F> lambda(
     return lambda(type, Blocks.toFunctionBlock(body), toList(parameters));
   }
 
+  public static Expression safeExpression(Expression body){","[{'comment': 'Using this `safeExpression` function  I can get it to generate an Expression with the try/catch\r\n```\r\npublic Object[] apply(Object root0) {\r\n  return new Object[] {\r\n      (Integer) new org.apache.calcite.linq4j.function.Function0() {\r\n        public Object apply() {\r\n          try {\r\n            return org.apache.calcite.avatica.util.DateTimeUtils.timeStringToUnixDate(""12:12:11"");\r\n          } catch (Exception e) {\r\n            return null;\r\n          }\r\n        }\r\n      }\r\n    };\r\n}\r\n```\r\n\r\nHowever, in RexExecutable compile line 55 it doesn\'t like the cast to integer / block : `org.codehaus.commons.compiler.CompileException: Line 3, Column 15: Cannot cast ""Reducer$1"" to ""java.lang.Integer""` \r\n\r\nAny suggestions here?', 'commenter': 'olivrlee'}, {'comment': 'The original code without adding a lambda + try/catch block looks like this when running `SAFE_CAST(""a"" AS INT)`\r\n\r\n```\r\npublic Object[] apply(Object root0) {\r\n  return new Object[] {\r\n      Integer.valueOf(org.apache.calcite.runtime.SqlFunctions.toInt(""a""))};\r\n}\r\n```\r\n\r\n', 'commenter': 'olivrlee'}]"
3093,linq4j/src/main/java/org/apache/calcite/linq4j/tree/Expressions.java,"@@ -1164,6 +1164,7 @@ public static <F extends Function<?>> FunctionExpression<F> lambda(
     return new FunctionExpression<>(type, body, toList(parameters));
   }
 
+","[{'comment': 'remove this empty line', 'commenter': 'zoudan'}]"
3093,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3481,6 +3481,7 @@ public static <E> Collection<E> multisetIntersectAll(Collection<E> c1,
     return result;
   }
 
+","[{'comment': 'remove empty line', 'commenter': 'zoudan'}]"
3093,core/src/main/java/org/apache/calcite/sql/SqlKind.java,"@@ -639,6 +639,10 @@ public enum SqlKind {
    */
   CAST,
 
+  /**
+   * The {@code SAFE_CAST} function. */","[{'comment': 'It is better to add description for what is the difference between `SAFE_CAST` and `CAST`', 'commenter': 'zoudan'}, {'comment': ""I'll update the comment. I did describe the function in `SqlLibraryOperators` too"", 'commenter': 'olivrlee'}]"
3093,babel/src/test/resources/sql/big-query.iq,,"[{'comment': 'Shall we add some tests in SqlOperatorTest?', 'commenter': 'zoudan'}]"
3093,core/src/main/java/org/apache/calcite/adapter/enumerable/RexToLixTranslator.java,"@@ -652,8 +714,8 @@ Expression translateCast(
       break;
     case TIMESTAMP_WITH_LOCAL_TIME_ZONE:
       convert =
-          RexImpTable.optimize2(operand,
-              Expressions.call(
+              RexImpTable.optimize2(","[{'comment': 'remove one tab?', 'commenter': 'zoudan'}]"
3093,core/src/main/java/org/apache/calcite/adapter/enumerable/RexToLixTranslator.java,"@@ -267,10 +268,39 @@ Expression translate(RexNode expr, RexImpTable.NullAs nullAs,
     return nullAs.handle(translated);
   }
 
+  /**
+   * Used for safe operators that return null if an exception is thrown.
+   */
+  Expression expressionHandlingSafe(Expression body, boolean safe) {","[{'comment': 'could be private?', 'commenter': 'zoudan'}]"
3093,core/src/main/java/org/apache/calcite/adapter/enumerable/RexToLixTranslator.java,"@@ -267,10 +268,39 @@ Expression translate(RexNode expr, RexImpTable.NullAs nullAs,
     return nullAs.handle(translated);
   }
 
+  /**
+   * Used for safe operators that return null if an exception is thrown.
+   */
+  Expression expressionHandlingSafe(Expression body, boolean safe) {
+    if (safe) {
+      return safeExpression(body);
+    } else {
+      return body;
+    }
+  }
+
+  public static Expression safeExpression(Expression body) {","[{'comment': 'could be private?', 'commenter': 'zoudan'}]"
3093,core/src/main/java/org/apache/calcite/sql/fun/SqlCastFunction.java,"@@ -83,12 +84,25 @@ public class SqlCastFunction extends SqlFunction {
   //~ Constructors -----------------------------------------------------------
 
   public SqlCastFunction() {
-    super(""CAST"",
-        SqlKind.CAST,
+    this(SqlKind.CAST);
+  }
+
+  private SqlCastFunction(SqlKind kind) {","[{'comment': 'How about just keep this constructor and remove `withKind`', 'commenter': 'zoudan'}]"
3099,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -473,6 +474,7 @@ Builder populate() {
       defineMethod(EXP, ""exp"", NullPolicy.STRICT);
       defineMethod(POWER, ""power"", NullPolicy.STRICT);
       defineMethod(LN, ""ln"", NullPolicy.STRICT);
+      defineMethod(LOG, ""log"", NullPolicy.STRICT);","[{'comment': ""Would this be simpler if done with an implementor that translates 'log(x, y)' to 'ln(x) / ln(y)'? Constant reduction could kick in, we could potentially optimize for bases such as e, 2, 10, and we would not need to add to `SqlFunctions`.\r\n\r\nMethod implementor is kind of a hammer."", 'commenter': 'julianhyde'}]"
3099,core/src/main/codegen/default_config.fmpp,"@@ -88,6 +88,8 @@ parser: {
     ""DATETIME_DIFF""
     ""DATETIME_INTERVAL_CODE""
     ""DATETIME_INTERVAL_PRECISION""
+    ""DAYOFWEEK""","[{'comment': 'this has nothing to do with `LOG`?', 'commenter': 'zoudan'}]"
3099,babel/src/test/resources/sql/big-query.iq,"@@ -371,6 +371,30 @@ SELECT EXTRACT(DAY FROM DATE '2013-12-25') AS the_day;
 
 !ok
 
+SELECT
+  EXTRACT(DAYOFWEEK FROM DATE '2008-12-25') as day_of_week,","[{'comment': 'This PR includes some changes which are not release to CALCITE-5565', 'commenter': 'zoudan'}, {'comment': 'Just rebased, was previously dependent on uncommitted changes. Sorry about that!', 'commenter': 'tanclary'}]"
3099,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -3684,6 +3687,43 @@ private static class LogicalNotImplementor extends AbstractRexCallImplementor {
     }
   }
 
+  /**Implementor for the {@code LN, LOG, and LOG10} operators
+   *
+   * <p>Handles all logarithm functions using log rules to determine the
+   * appropriate base (i.e. base e for LN).
+   */
+  private static class LogImplementor extends AbstractRexCallImplementor {
+    LogImplementor() {
+      super(""log"", NullPolicy.STRICT, true);
+    }
+
+    @Override Expression implementSafe(final RexToLixTranslator translator,
+        final RexCall call, final List<Expression> argValueList) {
+      Expression operand0 = argValueList.get(0);
+      Expression operand1;
+
+      switch (call.getOperator().getName()) {
+      case ""LN"":
+        operand1 = Expressions.constant(Math.exp(1));
+        break;
+      case ""LOG"":
+        switch (argValueList.size()) {
+        case 1:
+          operand1 = Expressions.constant(Math.exp(1));
+          break;
+        default:
+          operand1 = argValueList.get(1);
+        }
+        break;
+      case ""LOG10"":
+      default:","[{'comment': 'Throw an unsupported exception may be better for `default` case', 'commenter': 'zoudan'}, {'comment': 'Done.', 'commenter': 'tanclary'}]"
3099,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -3684,6 +3687,43 @@ private static class LogicalNotImplementor extends AbstractRexCallImplementor {
     }
   }
 
+  /**Implementor for the {@code LN, LOG, and LOG10} operators","[{'comment': 'Need space at start of comment. Only the operator names should be monospaced, not “and”. ', 'commenter': 'julianhyde'}, {'comment': 'Done.', 'commenter': 'tanclary'}]"
3113,core/src/main/java/org/apache/calcite/sql/parser/SqlParserUtil.java,"@@ -738,17 +741,7 @@ public static ParsedCollation parseCollation(String in) {
     }
 
     Charset charset = SqlUtil.getCharset(charsetStr);
-    String[] localeParts = localeStr.split(""_"");
-    Locale locale;
-    if (1 == localeParts.length) {
-      locale = new Locale(localeParts[0]);
-    } else if (2 == localeParts.length) {
-      locale = new Locale(localeParts[0], localeParts[1]);
-    } else if (3 == localeParts.length) {
-      locale = new Locale(localeParts[0], localeParts[1], localeParts[2]);
-    } else {
-      throw RESOURCE.illegalLocaleFormat(localeStr).ex();","[{'comment': 'It seems that after these changes we are never going to throw the `illegalLocaleFormat` exception. Are we going to throw another exception? Are we going to fallback silently to something else? \r\n\r\nIf we cannot keep the old behavior then we should document the breaking change in `history.md` file. Also if we never throw `RESOURCE.illegalLocaleFormat` then we maybe we should also drop the respective (dead) code.', 'commenter': 'zabetak'}, {'comment': ""Since this change makes use of IETF BCP 47 language tag string (used by Locale#forLanguageTag) there could be more parts. Fallback is jdk's fallback\r\n\r\nAdded info to `history.md`\r\n\r\nThanks about mentioning `RESOURCE.illegalLocaleFormat`\r\n"", 'commenter': 'snuyanzin'}, {'comment': 'I am not sure if we should use `Locale.forLanguageTag` or `Locale.Builder.setLanguageTag` (https://docs.oracle.com/javase/8/docs/api/java/util/Locale.Builder.html#setLanguageTag-java.lang.String-). Is it safe to just ignore malformed inputs?\r\n\r\nDo all Calcite unit tests run if we use `setLanguageTag`?\r\n\r\nAre we sure that we do not break some SQL standard specification around `COLLATE` clause (etc.) by doing this change?', 'commenter': 'zabetak'}, {'comment': ""Sorry for the delay\r\n>I am not sure if we should use Locale.forLanguageTag or Locale.Builder.setLanguageTag \r\n\r\nJavadoc in jdk19 says to look for `Obtaining Locales` section at https://github.com/openjdk/jdk/commit/526e73498eef5c7608845501ab4ebef0997a5c0d#diff-bae63085ee0310e91011b048b2b59d0986eedf702dee10d7b0ab75c8e20a61eaR728\r\nand then in that section there are 2 ways as mentioned at https://github.com/openjdk/jdk/commit/526e73498eef5c7608845501ab4ebef0997a5c0d#diff-bae63085ee0310e91011b048b2b59d0986eedf702dee10d7b0ab75c8e20a61eaR245\r\n1. `Locale#forLanguageTag` which is used in this PR\r\n2. `Locale#of` which is available only since jdk19 (https://github.com/openjdk/jdk/pull/7947).\r\n\r\n>Do all Calcite unit tests run if we use setLanguageTag?\r\n\r\nI replaced all occurrences of `Locale` constructor (including tests) then yes...\r\nOr do you mean something else?\r\n\r\n >Are we sure that we do not break some SQL standard specification around COLLATE clause (etc.) by doing this change?\r\n \r\n That thing unfortunately I don't know how to check... \r\n \r\n \r\n"", 'commenter': 'snuyanzin'}, {'comment': 'Before the changes in this PR there was somewhat strict control on what formats are allowed/supported when working with locales and an exception was thrown if the requested locale is now invalid.\r\n\r\nNow with the use of `Locale#forLanguageTag` we will never get an error since it appears that we will always fallback to some defaults. \r\n\r\nInstead of using the `Locale#forLanguageTag` we could use the `Locale.Builder.setLanguageTag`, which as far as I understand is not as permissive,  and will thrown an error when the locale is not well formed: https://download.java.net/java/early_access/panama/docs/api/java.base/java/util/Locale.Builder.html#setLanguageTag(java.lang.String)\r\n\r\nIn the context of this PR I was wondering if the `Locale.Builder.setLanguageTag` is a better alternative to `Locale#forLanguageTag`.\r\n\r\nThe latest standard can be found here: https://www.iso.org/standard/76584.html \r\nIt is not free but you may find older versions available online (https://modern-sql.com/standard). The Part 2: Foundations covers the `COLLATE` clause.', 'commenter': 'zabetak'}, {'comment': ""I'm ok with `Locale.Builder.setLanguageTag`\r\nthe only thing we should probably handle is that current behavior: in case of empty `localeString` it returns `Locale.ROOT` while `Locale.Builder.setLanguageTag` fails (also corresponding Calcite tests are failing)\r\n\r\nAlso added actual `localeStr` in exception message since `IllformedLocaleException` throwing by `setLamguageTag` does not contain it"", 'commenter': 'snuyanzin'}, {'comment': 'Instead of throwing a new `AssertionError` I think it is better to restore the `RESOURCE.illegalLocaleFormat`. Other than that the change LGTM.', 'commenter': 'zabetak'}]"
3113,core/src/test/java/org/apache/calcite/util/UtilTest.java,"@@ -914,7 +914,7 @@ private List<Integer> makeConsList(int start, int end) {
     }
     // Example locale names in Locale.toString() javadoc.
     String[] localeNames = {
-        ""en"", ""de_DE"", ""_GB"", ""en_US_WIN"", ""de__POSIX"", ""fr__MAC""
+        ""en"", ""de_DE"", ""fr_CA""","[{'comment': 'The change implies that we no longer support certain patterns when parsing locales so I think we should mention the change in behavior in `history.md`.', 'commenter': 'zabetak'}, {'comment': 'added such note', 'commenter': 'snuyanzin'}]"
3113,core/src/test/java/org/apache/calcite/util/UtilTest.java,"@@ -914,7 +914,7 @@ private List<Integer> makeConsList(int start, int end) {
     }
     // Example locale names in Locale.toString() javadoc.
     String[] localeNames = {
-        ""en"", ""de_DE"", ""_GB"", ""en_US_WIN"", ""de__POSIX"", ""fr__MAC""
+        ""en"", ""de_DE"", ""gb_GB"", ""en_US_WINDOWS"", ""de__POSIX"", ""fr__MACOS""","[{'comment': 'need to extend `en_US_WIN` to `en_US_WINDOWS` since `Locale#forLanguageTag` assumes that variants contain between 4 and 8 symbols', 'commenter': 'snuyanzin'}]"
3113,site/_docs/history.md,"@@ -43,6 +43,10 @@ z.
 #### Breaking Changes
 {: #breaking-1-35-0}
 
+The way of Locale parsing changed within [<a href=""https://issues.apache.org/jira/browse/CALCITE-5567"">CALCITE-5567</a>]
+Now locales are parsed according to IETF BCP 47 language tag string.
+This leads to the fact that some locales not satisfying IETF BCP 47 language tag string.","[{'comment': 'This sentence sounds a bit confusing or unfinished, wdyt?', 'commenter': 'rubenada'}, {'comment': 'yep, thanks for the catch\r\nI changed it ', 'commenter': 'snuyanzin'}]"
3113,core/src/main/java/org/apache/calcite/util/Util.java,"@@ -1717,16 +1719,14 @@ private static void appendPosixTime(StringBuilder buf, int millis) {
    * @return Java locale object
    */
   public static Locale parseLocale(String localeString) {
-    String[] strings = localeString.split(""_"");
-    switch (strings.length) {
-    case 1:
-      return new Locale(strings[0]);
-    case 2:
-      return new Locale(strings[0], strings[1]);
-    case 3:
-      return new Locale(strings[0], strings[1], strings[2]);
-    default:
-      throw new AssertionError(""bad locale string '"" + localeString + ""'"");
+    if (localeString.isEmpty()) {
+      return Locale.ROOT;","[{'comment': 'Is it required to introduce this fallback mechanism to Locale.ROOT?', 'commenter': 'rubenada'}, {'comment': 'if we are using `Locale.Builder.setLanguageTag` as was suggested in other comment https://github.com/apache/calcite/pull/3113/files#r1212934318 then yes.\r\n\r\nThe issue with `Locale.Builder.setLanguageTag` is that it does not allow empty `lcoalStr` and fails.\r\nI mentioned it in same thread, probably should do it here  as well', 'commenter': 'snuyanzin'}]"
3113,core/src/main/java/org/apache/calcite/util/Util.java,"@@ -1717,16 +1719,14 @@ private static void appendPosixTime(StringBuilder buf, int millis) {
    * @return Java locale object
    */
   public static Locale parseLocale(String localeString) {
-    String[] strings = localeString.split(""_"");
-    switch (strings.length) {
-    case 1:
-      return new Locale(strings[0]);
-    case 2:
-      return new Locale(strings[0], strings[1]);
-    case 3:
-      return new Locale(strings[0], strings[1], strings[2]);
-    default:
-      throw new AssertionError(""bad locale string '"" + localeString + ""'"");
+    if (localeString.isEmpty()) {
+      return Locale.ROOT;
+    }
+    try {
+      return new Locale.Builder().setLanguageTag(
+          UNDERSCORE.matcher(localeString).replaceAll(""-"")).build();
+    } catch (IllformedLocaleException e) {
+      throw new AssertionError(""bad locale string '"" + localeString + ""'"", e);","[{'comment': ""A `IllegalStateException` or `IllegalArgumentException` would be more appropriate here but since it was an `AssertionError` before I am also fine leaving it as is.\r\nI don't think an `AssertionError` is appropriate cause we may arrive here by user input."", 'commenter': 'zabetak'}, {'comment': 'makes sense, thanks', 'commenter': 'snuyanzin'}]"
3132,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -892,6 +892,49 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
           OperandTypes.STRING_STRING,
           SqlFunctionCategory.TIMEDATE);
 
+  /**
+   * The ""PARSE_TIME(string, string)"" function (BigQuery); Converts a string representation of time","[{'comment': ""'C' after semicolon should be 'c'\r\n\r\nAlso, I would break the line after ';'; short lines are easier to read and maintain"", 'commenter': 'julianhyde'}]"
3132,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -2650,6 +2651,63 @@ public static String formatTime(DataContext ctx, String fmtString, int time) {
     return internalFormatDatetime(fmtString, internalToTime(time));
   }
 
+  private static String parseDatetimePattern(String fmtString) {
+    StringBuilder sb = new StringBuilder();
+    List<FormatElement> elements = FormatModels.BIG_QUERY.parse(fmtString);
+    elements.forEach(ele -> ele.toPattern(sb));
+    return sb.toString();
+  }
+
+  private static Date interalParseDatetime(String fmtString, String datetime) {
+    return interalParseDatetime(fmtString, datetime, DateTimeUtils.DEFAULT_ZONE);
+  }
+","[{'comment': ""in several function names, 'interal' should be 'internal'"", 'commenter': 'julianhyde'}, {'comment': 'Yikes, thank you!', 'commenter': 'tjbanghart'}]"
3132,core/src/main/java/org/apache/calcite/util/format/FormatElementEnum.java,"@@ -39,188 +39,207 @@
  * @see FormatModels#DEFAULT
  */
 public enum FormatElementEnum implements FormatElement {
-  D(""The weekday (Monday as the first day of the week) as a decimal number (1-7)"") {
-    @Override public String format(Date date) {
+  D(""F"", ""The weekday (Monday as the first day of the week) as a decimal number (1-7)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%d"", calendar.get(Calendar.DAY_OF_WEEK));
+      sb.append(String.format(Locale.ROOT, ""%d"", calendar.get(Calendar.DAY_OF_WEEK)));
     }
   },
-  DAY(""The full weekday name"") {
-    @Override public String format(Date date) {
+  DAY(""EEEE"", ""The full weekday name"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.eeeeFormat.format(date);
+      sb.append(work.eeeeFormat.format(date));
     }
   },
-  DD(""The day of the month as a decimal number (01-31)"") {
-    @Override public String format(Date date) {
+  DD(""dd"", ""The day of the month as a decimal number (01-31)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.DAY_OF_MONTH));
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.DAY_OF_MONTH)));
     }
   },
-  DDD(""The day of the year as a decimal number (001-366)"") {
-    @Override public String format(Date date) {
+  DDD(""D"", ""The day of the year as a decimal number (001-366)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%03d"", calendar.get(Calendar.DAY_OF_YEAR));
+      sb.append(String.format(Locale.ROOT, ""%03d"", calendar.get(Calendar.DAY_OF_YEAR)));
     }
   },
-  DY(""The abbreviated weekday name"") {
-    @Override public String format(Date date) {
+  DY(""EEE"", ""The abbreviated weekday name"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.eeeFormat.format(date);
+      sb.append(work.eeeFormat.format(date));
     }
   },
-  FF1(""Fractional seconds to 1 digit"") {
-    @Override public String format(Date date) {
+  FF1(""S"", ""Fractional seconds to 1 digit"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.sFormat.format(date);
+      sb.append(work.sFormat.format(date));
     }
   },
-  FF2(""Fractional seconds to 2 digits"") {
-    @Override public String format(Date date) {
+  FF2(""SS"", ""Fractional seconds to 2 digits"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.ssFormat.format(date);
+      sb.append(work.ssFormat.format(date));
     }
   },
-  FF3(""Fractional seconds to 3 digits"") {
-    @Override public String format(Date date) {
+  FF3(""SSS"", ""Fractional seconds to 3 digits"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.sssFormat.format(date);
+      sb.append(work.sssFormat.format(date));
     }
   },
-  FF4(""Fractional seconds to 4 digits"") {
-    @Override public String format(Date date) {
+  FF4(""SSSS"", ""Fractional seconds to 4 digits"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.ssssFormat.format(date);
+      sb.append(work.ssssFormat.format(date));
     }
   },
-  FF5(""Fractional seconds to 5 digits"") {
-    @Override public String format(Date date) {
+  FF5(""SSSSS"", ""Fractional seconds to 5 digits"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.sssssFormat.format(date);
+      sb.append(work.sssssFormat.format(date));
     }
   },
-  FF6(""Fractional seconds to 6 digits"") {
-    @Override public String format(Date date) {
+  FF6(""SSSSSS"", ""Fractional seconds to 6 digits"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.ssssssFormat.format(date);
+      sb.append(work.ssssssFormat.format(date));
     }
   },
-  HH12(""The hour (12-hour clock) as a decimal number (01-12)"") {
-    @Override public String format(Date date) {
+  HH12(""h"", ""The hour (12-hour clock) as a decimal number (01-12)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
       int hour = calendar.get(Calendar.HOUR);
-      return String.format(Locale.ROOT, ""%02d"", hour == 0 ? 12 : hour);
+      sb.append(String.format(Locale.ROOT, ""%02d"", hour == 0 ? 12 : hour));
     }
   },
-  HH24(""The hour (24-hour clock) as a decimal number (00-23)"") {
-    @Override public String format(Date date) {
+  HH24(""H"", ""The hour (24-hour clock) as a decimal number (00-23)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.HOUR_OF_DAY));
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.HOUR_OF_DAY)));
     }
   },
-  IW(""The ISO 8601 week number of the year (Monday as the first day of the week) ""
+  // TODO: Ensure ISO 8601 for parsing
+  IW(""w"", ""The ISO 8601 week number of the year (Monday as the first day of the week) ""
       + ""as a decimal number (01-53)"") {
-    @Override public String format(Date date) {
+    @Override public void format(StringBuilder sb, Date date) {
       // TODO: ensure this is isoweek
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
       calendar.setFirstDayOfWeek(Calendar.MONDAY);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.WEEK_OF_YEAR));
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.WEEK_OF_YEAR)));
     }
   },
-  MI(""The minute as a decimal number (00-59)"") {
-    @Override public String format(Date date) {
+  MI(""m"", ""The minute as a decimal number (00-59)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.MINUTE));
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.MINUTE)));
     }
   },
-  MM(""The month as a decimal number (01-12)"") {
-    @Override public String format(Date date) {
+  MM(""MM"", ""The month as a decimal number (01-12)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.MONTH) + 1);
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.MONTH) + 1));
     }
   },
-  MON(""The abbreviated month name"") {
-    @Override public String format(Date date) {
+  MON(""MMM"", ""The abbreviated month name"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.mmmFormat.format(date);
+      sb.append(work.mmmFormat.format(date));
     }
   },
-  MONTH(""The full month name (English)"") {
-    @Override public String format(Date date) {
+  MONTH(""MMMM"", ""The full month name (English)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.mmmmFormat.format(date);
+      sb.append(work.mmmmFormat.format(date));
     }
   },
-  Q(""The quarter as a decimal number (1-4)"") {
-    @Override public String format(Date date) {
+  // PM can represent both AM and PM
+  PM(""a"", ""Meridian indicator without periods"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%d"", (calendar.get(Calendar.MONTH) / 3) + 1);
+      String meridian = calendar.get(Calendar.HOUR_OF_DAY) < 12 ? ""AM"" : ""PM"";
+      sb.append(meridian);
     }
   },
-  SS(""The second as a decimal number (00-60)"") {
-    @Override public String format(Date date) {
+  Q("""", ""The quarter as a decimal number (1-4)"") {
+    // TODO: Allow parsing of quarters.
+    @Override public void toPattern(StringBuilder sb) {
+      throw new UnsupportedOperationException(""Cannot convert 'Q' FormatElement to Java pattern"");
+    }
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.SECOND));
+      sb.append(String.format(Locale.ROOT, ""%d"", (calendar.get(Calendar.MONTH) / 3) + 1));
     }
   },
-  MS(""The millisecond as a decimal number (000-999)"") {
-    @Override public String format(Date date) {
+  MS(""SSS"", ""The millisecond as a decimal number (000-999)"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%03d"", calendar.get(Calendar.MILLISECOND));
+      sb.append(String.format(Locale.ROOT, ""%03d"", calendar.get(Calendar.MILLISECOND)));
     }
   },
-  TZR(""The time zone name"") {
-    @Override public String format(Date date) {
+  SS(""s"", ""The second as a decimal number (00-60)"") {
+    @Override public void format(StringBuilder sb, Date date) {
+      final Calendar calendar = Work.get().calendar;
+      calendar.setTime(date);
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.SECOND)));
+    }
+  },
+  TZR(""z"", ""The time zone name"") {
+    @Override public void format(StringBuilder sb, Date date) {
       // TODO: how to support timezones?
-      return """";
     }
   },
-  WW(""The week number of the year (Sunday as the first day of the week) as a decimal ""
+  WW(""w"", ""The week number of the year (Sunday as the first day of the week) as a decimal ""
       + ""number (00-53)"") {
-    @Override public String format(Date date) {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
       calendar.setFirstDayOfWeek(Calendar.SUNDAY);
-      return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.WEEK_OF_YEAR));
+      sb.append(String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.WEEK_OF_YEAR)));
     }
   },
-  YY(""Last 2 digits of year"") {
-    @Override public String format(Date date) {
+  YY(""yy"", ""Last 2 digits of year"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Work work = Work.get();
-      return work.yyFormat.format(date);
+      sb.append(work.yyFormat.format(date));
     }
   },
-  YYYY(""The year with century as a decimal number"") {
-    @Override public String format(Date date) {
+  YYYY(""yyyy"", ""The year with century as a decimal number"") {
+    @Override public void format(StringBuilder sb, Date date) {
       final Calendar calendar = Work.get().calendar;
       calendar.setTime(date);
-      return String.format(Locale.ROOT, ""%d"", calendar.get(Calendar.YEAR));
+      sb.append(String.format(Locale.ROOT, ""%d"", calendar.get(Calendar.YEAR)));
     }
   };
 
   private final String description;
+  final String javaFmt;","[{'comment': ""Conceivably there might in future be a SQL format element that does not have a corresponding Java format element. Should we just document the fact that, for now, we're ok? Add two `requireNotNull` calls in the constructor."", 'commenter': 'julianhyde'}, {'comment': 'Yes, this will be a problem. `Q` (quarter as a decimal) has no Java equivalent that I am aware of. `toPattern` is overridden for this element to throw an `UnsupportedOperationException`\r\n\r\n```\r\n  Q("""", ""The quarter as a decimal number (1-4)"") {\r\n    // TODO: Allow parsing of quarters.\r\n    @Override public void toPattern(StringBuilder sb) throws UnsupportedOperationException {\r\n      throw new UnsupportedOperationException(""Cannot convert \'Q\' FormatElement to Java pattern"");\r\n    }\r\n...\r\n```\r\n\r\nI updated the javadoc for `toPattern` to reflect this as well. Not ideal but perhaps we can revisit?', 'commenter': 'tjbanghart'}]"
3132,site/_docs/reference.md,"@@ -2716,6 +2716,10 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b m p | MD5(string)                                | Calculates an MD5 128-bit checksum of *string* and returns it as a hex string
 | m | MONTHNAME(date)                                | Returns the name, in the connection's locale, of the month in *datetime*; for example, it returns '二月' for both DATE '2020-02-10' and TIMESTAMP '2020-02-10 10:10:10'
 | o | NVL(value1, value2)                            | Returns *value1* if *value1* is not null, otherwise *value2*
+| b | PARSE_DATE(string1, string2)                   | Uses format specified by *string1* to convert *string2* representation of date to a DATE object
+| b | PARSE_DATETIME(string1, string2)               | Uses format specified by *string1* to convert *string2* representation of datetime to a TIMESTAMP object
+| b | PARSE_TIME(string1, string2)                   | Uses format specified by *string1* to convert *string2* representation of time to a TIME object
+| b | PARSE_TIMESTAMP(string1, string2[, timeZone])  | Uses format specified by *string1* to convert *string2* representation of timestamp to a TIMESTAMP WITH LOCAL TIME ZONE object in *timeZone*","[{'comment': ""change 'DATE object' to 'DATE value' or just 'DATE'\r\n\r\nchange 'string1' to 'format'; makes description more concise"", 'commenter': 'julianhyde'}]"
3134,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -863,6 +863,16 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
           OperandTypes.STRING.or(OperandTypes.BINARY),
           SqlFunctionCategory.STRING);
 
+  /** The ""TO_CHAR(timestamp, format)"" function;
+   * converts {@code timestamp} to string according to the given {@code format}.
+   */
+  @LibraryOperator(libraries = {MYSQL, ORACLE, POSTGRESQL})
+  public static final SqlFunction TO_CHAR =","[{'comment': 'PostgreSQL has 3 different to_char:\r\n`to_char ( timestamp, text ) → text`\r\n`to_char ( interval, text ) → text`\r\n`to_char ( numeric_type, text ) → text`\r\n\r\nYou implemented only it for timestamp type. Can you specify it in jira ticket', 'commenter': 'dssysolyatin'}]"
3134,babel/src/test/resources/sql/postgresql.iq,"@@ -57,3 +57,8 @@ SELECT * FROM sal_emp;
 NAME, PAY_BY_QUARTER, SCHEDULE
 Bill, [10000, 10000, 10000, 10000], [[meeting, lunch], [training, presentation]]
 !ok
+
+select to_char(timestamp '2022-06-03 12:15:48.678', 'YYYY-MM-DD HH24:MI:SS.MS TZ');","[{'comment': 'Can you add more tests for `toChar(DataContext ctx, long timestamp, String pattern)` function in org.apache.calcite.test.SqlFunctionsTest ?', 'commenter': 'dssysolyatin'}]"
3134,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -583,6 +584,7 @@ Builder populate2() {
       defineMethod(TIME, ""time"", NullPolicy.STRICT);
 
       // Datetime formatting methods
+      map.put(TO_CHAR, new ToCharImplementor());","[{'comment': 'Use `defineMethod` instead of `ToChatImplementor`', 'commenter': 'dssysolyatin'}]"
3134,core/src/main/java/org/apache/calcite/util/format/FormatElementEnum.java,"@@ -165,10 +173,17 @@ public enum FormatElementEnum implements FormatElement {
       return String.format(Locale.ROOT, ""%02d"", calendar.get(Calendar.SECOND));
     }
   },
+  MS(""The millisecond as a decimal number (000-999)"") {
+    @Override public String format(Date date) {
+      final Calendar calendar = Work.get().calendar;
+      calendar.setTime(date);
+      return String.format(Locale.ROOT, ""%03d"", calendar.get(Calendar.MILLISECOND));
+    }
+  },
   TZR(""The time zone name"") {
     @Override public String format(Date date) {
       // TODO: how to support timezones?
-      throw new UnsupportedOperationException();
+      return """";","[{'comment': 'why we return empty string for this case', 'commenter': 'zoudan'}, {'comment': ""We do so in order to match PostgreSQL's output when formatting `timestamp`s: https://dbfiddle.uk/VkeR6jUV"", 'commenter': 'tindzk'}]"
3141,core/src/main/java/org/apache/calcite/sql/validate/SqlConformance.java,"@@ -576,4 +576,26 @@ public interface SqlConformance {
    */
   @Experimental
   boolean allowCoercionStringToArray();
+","[{'comment': 'remove a redundant empty line', 'commenter': 'zoudan'}]"
3141,core/src/main/java/org/apache/calcite/sql/validate/SqlConformanceEnum.java,"@@ -439,4 +446,13 @@ public enum SqlConformanceEnum implements SqlConformance {
       return false;
     }
   }
+
+  @Override public boolean allowArrayFunction() {
+    switch (this) {","[{'comment': '`return this == SPARK`', 'commenter': 'zoudan'}, {'comment': ""I'm following the same coding style as the rest of the file.\r\n\r\nhttps://github.com/apache/calcite/blob/8d502cf421441a791db38ff8c87abc47fa45dd74/core/src/main/java/org/apache/calcite/sql/validate/SqlConformanceEnum.java#L441-L448\r\n\r\nif we want to append to the list, the git diff will look better."", 'commenter': 'MasseGuillaume'}]"
3141,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -820,6 +820,22 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
           .withOperandTypeInference(InferTypes.RETURN_TYPE)
           .withKind(SqlKind.CONCAT2);
 
+  private static final SqlReturnTypeInference ARRAY_RETURN_TYPE =","[{'comment': 'these days we use methods rather than lambda constants. see e.g. `transformConvert`.', 'commenter': 'julianhyde'}]"
3141,core/src/main/codegen/templates/Parser.jj,"@@ -4708,14 +4708,40 @@ SqlNode ArrayConstructor() :
 {
     <ARRAY> { s = span(); }
     (
-        LOOKAHEAD(1)
-        <LPAREN>
-        // by sub query ""MULTISET(SELECT * FROM T)""
-        e = OrderedQueryOrExpr(ExprContext.ACCEPT_QUERY)
-        <RPAREN>","[{'comment': ""That's a lot of 'validation' code in the parser. That's a code smell. Move it to the validator.\r\n\r\nMy hunch is that you don't need the `conformance.allowArrayFunction()` at all, anywhere. In the validator you can just look up a function called 'array' in the usual way."", 'commenter': 'julianhyde'}, {'comment': ""Ok, I will remove the conformance. I'm not sure I understand the implementation, do you want to always parse a function call? Then in the `SqlValidator`, when the array function is loaded (via the Spark library) validate that all the arguments are non-query expressions."", 'commenter': 'MasseGuillaume'}]"
3141,core/src/main/java/org/apache/calcite/sql/validate/SqlConformanceEnum.java,"@@ -77,6 +77,10 @@ public enum SqlConformanceEnum implements SqlConformance {
    * consistent with Presto. */
   PRESTO,
 
+  /** Conformance value that instructs Calcite to use SQL semantics
+   * consistent with Spark. */","[{'comment': 'Apache Spark', 'commenter': 'julianhyde'}]"
3141,core/src/test/java/org/apache/calcite/rel/rel2sql/RelToSqlConverterTest.java,"@@ -3684,6 +3684,35 @@ private SqlDialect nonOrdinalDialect() {
     sql(query).withSpark().ok(expected);
   }
 
+  private Sql sqlSpark(String query) {
+    return sql(query)
+      .parserConfig(SqlParser.Config.DEFAULT.withConformance(SqlConformanceEnum.SPARK))
+      .withSpark()
+      .withLibrary(SqlLibrary.SPARK);
+  }
+
+  @Test void testArrayFunction() {
+    sqlSpark(""SELECT ARRAY(1, 2)"")
+      .ok(""SELECT ARRAY(1, 2)\n""
+          + ""FROM (VALUES (0)) t (ZERO)"");
+  }
+
+  @Test void testArrayFunctionNullary() {
+    sqlSpark(""SELECT ARRAY()"")
+      .ok(""SELECT ARRAY()\n""
+          + ""FROM (VALUES (0)) t (ZERO)"");
+  }
+
+  @Test void testArrayQueryInvalid() {  ","[{'comment': 'this should be in SqlPArserTest', 'commenter': 'julianhyde'}]"
3141,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -7584,6 +7584,20 @@ private static void checkArrayConcatAggFuncFails(SqlOperatorFixture t) {
     f.checkFails(""^Array[]^"", ""Require at least 1 argument"", false);
   }
 
+  @Test void testArrayFunctionConstructor() {
+    final SqlOperatorFixture f = fixture();","[{'comment': 'add tests where some or all arguments are null', 'commenter': 'julianhyde'}]"
3141,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -7584,6 +7584,20 @@ private static void checkArrayConcatAggFuncFails(SqlOperatorFixture t) {
     f.checkFails(""^Array[]^"", ""Require at least 1 argument"", false);
   }
 
+  @Test void testArrayFunctionConstructor() {","[{'comment': ""rename test to `testArrayFunction`. it's not a constructor. \r\n\r\nadd javadoc making clear that it's for the function in the Spark library.\r\n\r\ntest what happens when the Spark library is not enabled. (as I said elsewhere, I think you probably don't need the conformance setting.)"", 'commenter': 'julianhyde'}]"
3143,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -3288,6 +3288,57 @@ private void checkSarg(String message, Sarg sarg,
         not(rexBuilder.makeCall(SqlStdOperatorTable.SIMILAR_TO, ref, literal(""%""))));
   }
 
+  @Test void testSimplifyNullCheckInFilter() {","[{'comment': ""Can we split the test into multiple tests?\r\n\r\nUpon failure it should be clear what went wrong, by bundling all in one test it's harder to tell. \r\n\r\nThis said, I understand that it will repeat the first part but I still think it's a price worth paying"", 'commenter': 'asolimando'}, {'comment': 'I can do that, but actually it is not very clear for me, which style to follow. I think that majority of the tests in this file are collected to large methods, and also some of them have an honor to reside in their own method.\r\n\r\nAre there any guidelines in Calcite regarding this?', 'commenter': 'LeonidChistov'}, {'comment': 'AFAIK we don\'t have strong guidelines around this, we mostly act as you did, we look at existing code and we try to adapt to it.\r\n\r\nConcerning the two conflicting styles, I see that older tests (> 5 years ago) are more inclined to put lots of cases inside a single test, newer code seems to be more for ""single case - single test"", which might be a bit more verbose for the ""data preparation"", but makes tests more readable and debuggable IMO.\r\n\r\nI don\'t feel strongly about this but I favour the ""newer"" style. If nobody else chimes in and you prefer the current organization I won\'t object.', 'commenter': 'asolimando'}]"
3143,core/src/test/resources/sql/sub-query.iq,"@@ -1748,7 +1748,7 @@ select sal from ""scott"".emp e
 (0 rows)
 
 !ok
-EnumerableCalc(expr#0..4=[{inputs}], expr#5=[RAND()], expr#6=[CAST($t5):INTEGER NOT NULL], expr#7=[2], expr#8=[MOD($t6, $t7)], expr#9=[3], expr#10=[=($t8, $t9)], expr#11=[IS NOT NULL($t4)], expr#12=[AND($t4, $t11)], expr#13=[OR($t10, $t12)], SAL=[$t1], $condition=[$t13])
+EnumerableCalc(expr#0..4=[{inputs}], expr#5=[RAND()], expr#6=[CAST($t5):INTEGER NOT NULL], expr#7=[2], expr#8=[MOD($t6, $t7)], expr#9=[3], expr#10=[=($t8, $t9)], expr#11=[OR($t10, $t4)], SAL=[$t1], $condition=[$t11])","[{'comment': 'I am OK with `IS NOT NULL($t4)` going away due to `AND($t4, $t11)`\r\n\r\n`$condition=[$t11]` IIUC makes `$t11` in `AND($t4, $t11)` ""redundant"", so I understand that `$t11` goes away and that `$t4` can be placed in the `OR`.\r\n\r\nWhat about `$t12`? I don\'t understand why it\'s being simplified.\r\n\r\nCan you explain a bit the reasoning here, please?', 'commenter': 'asolimando'}, {'comment': 'Since `$t12` is defined as `expr#12=[AND($t4, $t11)]`, and we have just eliminated `expr#11=[IS NOT NULL($t4)]` as redundant (and you agree with that), there is no sense in doing `AND` anymore.\r\n\r\nSo, what happens here AFAICS, is that we had condition `OR($t10, AND($t4, IS NOT NULL($t4)))` and managed to simplify it to `OR($t10, $t4)`.', 'commenter': 'LeonidChistov'}, {'comment': 'Thanks for the clarification, I agree with your analysis', 'commenter': 'asolimando'}]"
3143,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -1793,16 +1761,51 @@ private <C extends Comparable<C>> RexNode simplifyAnd2ForUnknownAsFalse(
         return rexBuilder.makeLiteral(false);
       }
     }
-    // Add the NOT disjunctions back in.
-    for (RexNode notDisjunction : notTerms) {
-      terms.add(not(notDisjunction));
-    }
     // The negated terms: only deterministic expressions
     for (RexNode negatedTerm : negatedTerms) {
       if (termsSet.contains(negatedTerm)) {
         return rexBuilder.makeLiteral(false);
       }
     }
+    // Add the NOT disjunctions back in.","[{'comment': 'Just for my understanding, why you decided to move this part after the for loop above?', 'commenter': 'asolimando'}, {'comment': ""That's probably does not matter a lot, I have just moved it a bit closer to the code where we actually need this.\r\nI rely on having both `terms` and `notTerms` included to `terms` list during calculation of `strongOperands`."", 'commenter': 'LeonidChistov'}]"
3143,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -1793,16 +1761,51 @@ private <C extends Comparable<C>> RexNode simplifyAnd2ForUnknownAsFalse(
         return rexBuilder.makeLiteral(false);
       }
     }
-    // Add the NOT disjunctions back in.
-    for (RexNode notDisjunction : notTerms) {
-      terms.add(not(notDisjunction));
-    }
     // The negated terms: only deterministic expressions
     for (RexNode negatedTerm : negatedTerms) {
       if (termsSet.contains(negatedTerm)) {
         return rexBuilder.makeLiteral(false);
       }
     }
+    // Add the NOT disjunctions back in.
+    for (RexNode notDisjunction : notTerms) {
+      terms.add(not(notDisjunction));
+    }
+    // Find operands that make will let whole expression evaluate to FALSE if set to NULL
+    final Set<RexNode> strongOperands = new HashSet<>();
+    for (RexNode term : terms) {
+      if (!RexUtil.isDeterministic(term)) {
+        continue;
+      }
+      VariableCollector collector = new VariableCollector();
+      term.accept(collector);
+      for (RexInputRef ref : collector.refs) {
+        if (Strong.isNotTrue(term, ImmutableBitSet.of(ref.index))) {
+          strongOperands.add(ref);
+        }
+      }
+      RexUtil.FieldAccessFinder fieldAccessFinder = new RexUtil.FieldAccessFinder();
+      term.accept(fieldAccessFinder);
+      for (RexFieldAccess rexFieldAccess : fieldAccessFinder.getFieldAccessList()) {
+        if (Strong.of(ImmutableSet.of(rexFieldAccess)).isNotTrue(term)) {","[{'comment': 'Nit: I personally prefer to move complex `if` conditions out of the `if` itself, not a big deal to leave it but please double check', 'commenter': 'asolimando'}]"
3143,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -2599,6 +2602,22 @@ default boolean allowedInOr(RelOptPredicateList predicates) {
     }
   }
 
+  /**
+   * Visitor which finds all inputs used by an expressions.
+   */
+  private static class VariableCollector extends RexVisitorImpl<Void> {
+    private final Set<RexInputRef> refs = new LinkedHashSet<>();","[{'comment': 'Just curious, why specifically a `LinkedHashSet` here?', 'commenter': 'asolimando'}, {'comment': ""I have just copied it from other place and didn't reflect enough on reasoning. Can be simplified with HashMap."", 'commenter': 'LeonidChistov'}, {'comment': ""I don't think it will make much of a difference, so it's fine as-is for me"", 'commenter': 'asolimando'}, {'comment': ""I have the same feeling with @asolimando, usually a `LinkedHashSet` would make me wonder what's its purpose to use it instead of a `HashSet`, which will increase the cost of understanding.\r\n\r\nIf we have a reason, we'd better write it into the comment. Else, I would prefer to use the most general one for the above reason. WDYT?"", 'commenter': 'libenchao'}, {'comment': 'Agree, fixed.', 'commenter': 'LeonidChistov'}]"
3143,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -1793,16 +1761,53 @@ private <C extends Comparable<C>> RexNode simplifyAnd2ForUnknownAsFalse(
         return rexBuilder.makeLiteral(false);
       }
     }
-    // Add the NOT disjunctions back in.
-    for (RexNode notDisjunction : notTerms) {
-      terms.add(not(notDisjunction));
-    }
     // The negated terms: only deterministic expressions
     for (RexNode negatedTerm : negatedTerms) {
       if (termsSet.contains(negatedTerm)) {
         return rexBuilder.makeLiteral(false);
       }
     }
+    // Add the NOT disjunctions back in.
+    for (RexNode notDisjunction : notTerms) {
+      terms.add(not(notDisjunction));
+    }
+    // Find operands that make will let whole expression evaluate to FALSE if set to NULL
+    final Set<RexNode> strongOperands = new HashSet<>();
+    for (RexNode term : terms) {
+      if (!RexUtil.isDeterministic(term)) {
+        continue;
+      }
+      final VariableCollector collector = new VariableCollector();
+      term.accept(collector);
+      for (RexInputRef ref : collector.refs) {
+        final boolean strong = Strong.isNotTrue(term, ImmutableBitSet.of(ref.index));
+        if (strong) {
+          strongOperands.add(ref);","[{'comment': 'Since the `strong` variable is only used once, I think there is no need to define a separate variable for it.', 'commenter': 'chunweilei'}, {'comment': ""That was done on my asking to increase readability, if you think it does more harm than good I don't feel strongly about it @chunweilei "", 'commenter': 'asolimando'}, {'comment': '@asolimando @chunweilei \r\n\r\nCould you please suggest how to proceed with this? ', 'commenter': 'LeonidChistov'}, {'comment': ""I am fine with whatever @chunweilei decides, but if he is busy I think we can move forward anyway since it's a rather nitpick subject."", 'commenter': 'asolimando'}, {'comment': 'Got it! Feel free to move forward.', 'commenter': 'chunweilei'}, {'comment': 'Thanks. @asolimando, can we merge the Pull Request then?', 'commenter': 'LeonidChistov'}, {'comment': ""Sure, can you please squash the commits into one having a commit message matching the Jira ticket's title? I will merge by the end of today."", 'commenter': 'asolimando'}]"
3145,slt/src/main/java/org/apache/calcite/slt/executors/JDBCExecutor.java,"@@ -0,0 +1,348 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+package org.apache.calcite.slt.executors;
+
+import org.apache.calcite.slt.*;
+
+import java.security.MessageDigest;
+import java.security.NoSuchAlgorithmException;
+import java.sql.*;
+import java.util.ArrayList;
+import java.util.Comparator;
+import java.util.List;
+import java.util.logging.Logger;
+import javax.annotation.Nullable;
+
+@SuppressWarnings({""SqlDialectInspection"", ""SqlNoDataSourceInspection""})
+public class JDBCExecutor extends SqlSLTTestExecutor {
+  Logger logger = Logger.getLogger(""JDBCExecutor"");
+  public final String dbUrl;
+  @Nullable
+  Connection connection;
+
+  // These could be static final, but then perhaps this would be flagged as a security vulnerability.
+  // There is no security issue because we use a local temporary hsqldb database.
+  String DEFAULT_USER = """";  // no user needed for hsqldb
+  String DEFAULT_PASSWORD = """";  // no password needed for hsqldb
+
+  // In the end everything is decoded as a string
+  static class Row {
+    public final List<String> values;
+
+    Row() {
+      this.values = new ArrayList<>();
+    }
+
+    void add(String v) {
+      this.values.add(v);
+    }
+
+    @Override
+    public String toString() {
+      return String.join(""\n"", this.values);
+    }
+  }
+
+  static class Rows {
+    List<Row> allRows;
+
+    Rows() {
+      this.allRows = new ArrayList<>();
+    }
+
+    void add(Row row) {
+      this.allRows.add(row);
+    }
+
+    @Override
+    public String toString() {
+      return String.join(""\n"", Utilities.map(this.allRows, Row::toString));
+    }
+
+    public int size() {
+      return this.allRows.size();
+    }
+
+    public void sort(SqlTestQueryOutputDescription.SortOrder order) {
+      switch (order) {
+      case NONE:
+        break;
+      case ROW:
+        this.allRows.sort(new RowComparator());
+        break;
+      case VALUE:
+        this.allRows = Utilities.flatMap(this.allRows,
+            r -> Utilities.map(r.values,
+                r0 -> {
+                  Row res = new Row();
+                  res.add(r0);
+                  return res;
+                }));
+        this.allRows.sort(new RowComparator());
+        break;
+      }
+    }
+
+    List<Row> getRows() {
+      return this.allRows;
+    }
+  }
+
+  public JDBCExecutor(String db_url) {
+    this.dbUrl = db_url;
+    this.connection = null;
+  }
+
+  void statement(SLTSqlStatement statement) throws SQLException {
+    logger.info(() -> this.statementsExecuted + "": "" + statement.statement);
+    assert this.connection != null;
+    try (Statement stmt = this.connection.createStatement()) {
+      stmt.execute(statement.statement);
+    } catch (SQLException ex) {
+      logger.severe(""ERROR: "" + ex.getMessage());
+      // Failures during the execution of statements are fatal.
+      // Only failures in queries are handled.
+      throw ex;
+    }
+    this.statementsExecuted++;
+  }
+
+  void query(SqlTestQuery query, TestStatistics statistics) throws SQLException, NoSuchAlgorithmException {
+    assert this.connection != null;
+    if (this.buggyOperations.contains(query.getQuery())) {
+      logger.warning(() -> ""Skipping "" + query.getQuery());
+      return;
+    }
+    try (Statement stmt = this.connection.createStatement()) {
+      ResultSet resultSet = stmt.executeQuery(query.getQuery());
+      this.validate(query, resultSet, query.outputDescription, statistics);
+      resultSet.close();
+    }
+    logger.info(() -> statistics.testsRun() + "": "" + query.getQuery());
+  }
+
+  Row getValue(ResultSet rs, String columnTypes) throws SQLException {
+    Row row = new Row();
+    // Column numbers start from 1
+    for (int i = 1; i <= columnTypes.length(); i++) {
+      char c = columnTypes.charAt(i - 1);
+      switch (c) {
+      case 'R':
+        double d = rs.getDouble(i);
+        if (rs.wasNull())
+          row.add(""NULL"");
+        else
+          row.add(String.format(""%.3f"", d));
+        break;
+      case 'I':
+        try {
+          long integer = rs.getLong(i);
+          if (rs.wasNull())
+            row.add(""NULL"");
+          else
+            row.add(String.format(""%d"", integer));
+        } catch (SQLDataException | NumberFormatException ignore) {
+          // This probably indicates a bug in the query, since
+          // the query expects an integer, but the result cannot
+          // be interpreted as such.
+          // unparsable string: replace with 0
+          row.add(""0"");
+        }
+        break;
+      case 'T':
+        String s = rs.getString(i);
+        if (s == null)
+          row.add(""NULL"");
+        else {
+          StringBuilder result = new StringBuilder();
+          for (int j = 0; j < s.length(); j++) {
+            char sc = s.charAt(j);
+            if (sc < ' ' || sc > '~')
+              sc = '@';
+            result.append(sc);
+          }
+          row.add(result.toString());
+        }
+        break;
+      default:
+        throw new RuntimeException(""Unexpected column type "" + c);
+      }
+    }
+    return row;
+  }
+
+  static class RowComparator implements Comparator<Row> {
+    @Override
+    public int compare(Row o1, Row o2) {
+      if (o1.values.size() != o2.values.size())
+        throw new RuntimeException(""Comparing rows of different lengths"");
+      for (int i = 0; i < o1.values.size(); i++) {
+        int r = o1.values.get(i).compareTo(o2.values.get(i));
+        if (r != 0)
+          return r;
+      }
+      return 0;
+    }
+  }
+
+  @SuppressWarnings(""java:S4790"")  // MD5 checksum
+  void validate(SqlTestQuery query, ResultSet rs,
+      SqlTestQueryOutputDescription description,
+      TestStatistics statistics)
+      throws SQLException, NoSuchAlgorithmException {
+    assert description.columnTypes != null;
+    Rows rows = new Rows();
+    while (rs.next()) {
+      Row row = this.getValue(rs, description.columnTypes);
+      rows.add(row);
+    }
+    if (description.getValueCount() != rows.size() * description.columnTypes.length()) {
+      statistics.addFailure(new TestStatistics.FailedTestDescription(
+          query, ""Expected "" + description.getValueCount() + "" rows, got "" +
+          rows.size() * description.columnTypes.length()));
+      return;
+    }
+    rows.sort(description.getOrder());
+    if (description.getQueryResults() != null) {
+      String r = rows.toString();
+      String q = String.join(""\n"", description.getQueryResults());
+      if (!r.equals(q)) {
+        statistics.addFailure(new TestStatistics.FailedTestDescription(
+            query, ""Output differs: computed\n"" + r + ""\nExpected:\n"" + q));
+        return;
+      }
+    }
+    if (description.hash != null) {
+      // MD5 is considered insecure, but we have no choice because this is
+      // the algorithm used to compute the checksums by SLT.
+      MessageDigest md = MessageDigest.getInstance(""MD5"");
+      String repr = rows + ""\n"";
+      md.update(repr.getBytes());
+      byte[] digest = md.digest();
+      String hash = Utilities.toHex(digest);
+      if (!description.hash.equals(hash)) {
+        statistics.addFailure(new TestStatistics.FailedTestDescription(
+            query, ""Hash of data does not match expected value""));
+        return;
+      }
+    }
+    statistics.incPassed();
+  }
+
+  List<String> getTableList() throws SQLException {
+    List<String> result = new ArrayList<>();
+    assert this.connection != null;
+    DatabaseMetaData md = this.connection.getMetaData();
+    ResultSet rs = md.getTables(null, null, ""%"", new String[]{""TABLE""});
+    while (rs.next()) {
+      String tableName = rs.getString(3);
+      if (tableName.equals(""PUBLIC""))
+        // The catalog table in HSQLDB
+        continue;
+      result.add(tableName);
+    }
+    rs.close();
+    return result;
+  }
+
+  List<String> getViewList() throws SQLException {
+    List<String> result = new ArrayList<>();
+    assert this.connection != null;
+    DatabaseMetaData md = this.connection.getMetaData();
+    ResultSet rs = md.getTables(null, null, ""%"", new String[]{""VIEW""});
+    while (rs.next()) {
+      String tableName = rs.getString(3);
+      result.add(tableName);
+    }
+    rs.close();
+    return result;
+  }
+
+  void dropAllTables() throws SQLException {
+    assert this.connection != null;
+    List<String> tables = this.getTableList();
+    for (String tableName : tables) {
+      String del = ""DROP TABLE ?"";
+      logger.info(del);
+      try (PreparedStatement drop = this.connection.prepareStatement(del)) {
+        drop.setString(1, tableName);
+        drop.execute(del);
+      }
+    }
+  }
+
+  void dropAllViews() throws SQLException {
+    assert this.connection != null;
+    List<String> tables = this.getViewList();
+    for (String tableName : tables) {
+      String del = ""DROP VIEW IF EXISTS ? CASCADE"";
+      logger.info(del);
+      try (PreparedStatement drop = this.connection.prepareStatement(del)) {
+        drop.setString(1, tableName);
+        drop.execute(del);
+      }
+    }
+  }
+
+  public void establishConnection() throws SQLException {
+    this.connection = DriverManager.getConnection(this.dbUrl, DEFAULT_USER, DEFAULT_PASSWORD);","[{'comment': '## A secure password should be used when connecting to a database\n\n<!--SONAR_ISSUE_KEY:AYd7xlZJjm25RUNvuIKp-->Add password protection to this database. <p>See more on <a href=""https://sonarcloud.io/project/issues?id=apache_calcite&issues=AYd7xlZJjm25RUNvuIKp&open=AYd7xlZJjm25RUNvuIKp&pullRequest=3145"">SonarCloud</a></p>\n\n[Show more details](https://github.com/apache/calcite/security/code-scanning/3)', 'commenter': 'github-advanced-security[bot]'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Main.java,"@@ -0,0 +1,208 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *
+ */
+
+package org.apache.calcite.slt;
+
+import com.beust.jcommander.ParameterException;
+
+import org.apache.calcite.slt.executors.SqlSLTTestExecutor;
+import org.apache.calcite.sql.parser.SqlParseException;
+
+import javax.annotation.Nullable;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.URL;
+import java.nio.file.*;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.security.NoSuchAlgorithmException;
+import java.sql.SQLException;
+import java.util.logging.Handler;","[{'comment': 'We are not using java.util.logging in the project; please use SLF4J instead.', 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Main.java,"@@ -0,0 +1,208 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *
+ */
+
+package org.apache.calcite.slt;
+
+import com.beust.jcommander.ParameterException;
+
+import org.apache.calcite.slt.executors.SqlSLTTestExecutor;
+import org.apache.calcite.sql.parser.SqlParseException;
+
+import javax.annotation.Nullable;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.URL;
+import java.nio.file.*;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.security.NoSuchAlgorithmException;
+import java.sql.SQLException;
+import java.util.logging.Handler;
+import java.util.logging.Level;
+import java.util.logging.LogManager;
+import java.util.logging.Logger;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipInputStream;
+
+/**
+ * Execute all SqlLogicTest tests.
+ */
+public class Main {
+  static final String SLT_GIT = ""https://github.com/gregrahn/sqllogictest/archive/refs/heads/master.zip"";
+
+  static class TestLoader extends SimpleFileVisitor<Path> {
+    int errors = 0;
+    final TestStatistics statistics;
+    public final ExecutionOptions options;
+
+    /**
+     * Creates a new class that reads tests from a directory tree and executes them.
+     */
+    TestLoader(ExecutionOptions options) {
+      this.statistics = new TestStatistics(options.stopAtFirstError);
+      this.options = options;
+    }
+
+    @Override
+    public FileVisitResult visitFile(Path file, BasicFileAttributes attrs) {
+      SqlSLTTestExecutor executor;
+      try {
+        executor = this.options.getExecutor();
+      } catch (IOException | SQLException e) {
+        // Can't add exceptions to the overridden method visitFile
+        throw new RuntimeException(e);
+      }
+      String extension = Utilities.getFileExtension(file.toString());
+      if (attrs.isRegularFile() && extension != null && extension.equals(""test"")) {
+        SLTTestFile test = null;
+        try {
+          System.out.println(""Running "" + file);
+          test = new SLTTestFile(file.toString());
+          test.parse();
+        } catch (Exception ex) {
+          System.err.println(""Error while executing test "" + file + "": "" + ex.getMessage());
+          this.errors++;
+        }
+        if (test != null) {
+          try {
+            TestStatistics stats = executor.execute(test, options);
+            this.statistics.add(stats);
+          } catch (SqlParseException | IOException |
+                   SQLException | NoSuchAlgorithmException ex) {
+            // Can't add exceptions to the overridden method visitFile
+            throw new IllegalArgumentException(ex);
+          }
+        }
+      }
+      return FileVisitResult.CONTINUE;
+    }
+  }
+
+  static void abort(ExecutionOptions options, @Nullable String message) {
+    if (message != null)
+      System.err.println(message);
+    options.usage();
+    System.exit(1);
+  }
+
+  @Nullable
+  static File newFile(File destinationDir, ZipEntry zipEntry) throws IOException {
+    String name = zipEntry.getName();
+    name = name.replace(""sqllogictest-master/"", """");
+    if (name.isEmpty())
+      return null;
+    File destFile = new File(destinationDir, name);
+    String destDirPath = destinationDir.getCanonicalPath();
+    String destFilePath = destFile.getCanonicalPath();
+    if (!destFilePath.startsWith(destDirPath + File.separator)) {
+      throw new IOException(""Entry is outside of the target dir: "" + name);
+    }
+    return destFile;
+  }
+
+  public static void install(File directory) throws IOException {
+    File zip = File.createTempFile(""out"", "".zip"", new File("".""));
+    System.out.println(""Downloading SLT from "" + SLT_GIT + "" into "" + zip.getAbsolutePath());","[{'comment': 'Is the use of `System.out` intentional? Is the message targetting a user or it is for logging purposes. If the second then please use a logger instead. Same comment to other places using `System.out` and `System.err`.', 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Main.java,"@@ -0,0 +1,208 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *
+ */
+
+package org.apache.calcite.slt;
+
+import com.beust.jcommander.ParameterException;
+
+import org.apache.calcite.slt.executors.SqlSLTTestExecutor;
+import org.apache.calcite.sql.parser.SqlParseException;
+
+import javax.annotation.Nullable;
+import java.io.File;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.net.URL;
+import java.nio.file.*;
+import java.nio.file.attribute.BasicFileAttributes;
+import java.security.NoSuchAlgorithmException;
+import java.sql.SQLException;
+import java.util.logging.Handler;
+import java.util.logging.Level;
+import java.util.logging.LogManager;
+import java.util.logging.Logger;
+import java.util.zip.ZipEntry;
+import java.util.zip.ZipInputStream;
+
+/**
+ * Execute all SqlLogicTest tests.
+ */
+public class Main {
+  static final String SLT_GIT = ""https://github.com/gregrahn/sqllogictest/archive/refs/heads/master.zip"";","[{'comment': ""Why do we need this? Can it change? What's inside the zip? Is it safe to download and execute? Can a malicious user change the content? \r\n\r\nThe respective repo does not have a license. Is it OK to use it?"", 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/FieldsAreNonnullByDefault.java,"@@ -0,0 +1,43 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *
+ */
+
+package org.apache.calcite.slt;
+
+import java.lang.annotation.Documented;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import javax.annotation.Nonnull;","[{'comment': ""At the moment I think we are using `javax.annotation` only in one place. Let's avoid introducing more if possible:\r\nhttps://github.com/apache/calcite/blob/main/site/develop/index.md#null-safety"", 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/TestStatistics.java,"@@ -0,0 +1,127 @@
+/*
+ * Copyright 2023 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+package org.apache.calcite.slt;
+
+import java.text.DecimalFormat;
+import java.util.ArrayList;
+import java.util.List;
+
+public class TestStatistics {","[{'comment': 'Test prefix usually indicates a class containing tests; please rename.', 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Utilities.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import javax.annotation.Nullable;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.function.Function;
+
+public class Utilities {
+  private Utilities() {}
+
+  /**
+   * Just adds single quotes around a string.  No escaping is performed.
+   */
+  public static String singleQuote(String other) {
+    return ""'"" + other + ""'"";
+  }
+
+  @Nullable
+  public static String getFileExtension(String filename) {
+    int i = filename.lastIndexOf('.');
+    if (i > 0)
+      return filename.substring(i+1);
+    return null;
+  }
+
+  private static final char[] hexCode = ""0123456789abcdef"".toCharArray();
+
+  public static String toHex(byte[] data) {
+    StringBuilder r = new StringBuilder(data.length * 2);
+    for (byte b : data) {
+      r.append(hexCode[(b >> 4) & 0xF]);
+      r.append(hexCode[(b & 0xF)]);
+    }
+    return r.toString();
+  }
+
+  public static <T, S> List<S> map(List<T> data, Function<T, S> function) {
+    List<S> result = new ArrayList<>(data.size());
+    for (T aData : data)
+      result.add(function.apply(aData));
+    return result;
+  }
+
+  public static <T, S> List<S> flatMap(List<T> data, Function<T, List<S>> function) {
+    List<S> result = new ArrayList<>(data.size());
+    for (T aData : data)
+      result.addAll(function.apply(aData));
+    return result;
+  }","[{'comment': 'We have built-in JDK methods for map and flatMap. Do we really need these?', 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Utilities.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import javax.annotation.Nullable;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.function.Function;
+
+public class Utilities {
+  private Utilities() {}
+
+  /**
+   * Just adds single quotes around a string.  No escaping is performed.
+   */
+  public static String singleQuote(String other) {
+    return ""'"" + other + ""'"";
+  }
+
+  @Nullable
+  public static String getFileExtension(String filename) {
+    int i = filename.lastIndexOf('.');
+    if (i > 0)
+      return filename.substring(i+1);
+    return null;
+  }
+
+  private static final char[] hexCode = ""0123456789abcdef"".toCharArray();
+
+  public static String toHex(byte[] data) {
+    StringBuilder r = new StringBuilder(data.length * 2);
+    for (byte b : data) {
+      r.append(hexCode[(b >> 4) & 0xF]);
+      r.append(hexCode[(b & 0xF)]);
+    }
+    return r.toString();
+  }
+
+  public static <T, S> List<S> map(List<T> data, Function<T, S> function) {
+    List<S> result = new ArrayList<>(data.size());
+    for (T aData : data)
+      result.add(function.apply(aData));
+    return result;
+  }
+
+  public static <T, S> List<S> flatMap(List<T> data, Function<T, List<S>> function) {
+    List<S> result = new ArrayList<>(data.size());
+    for (T aData : data)
+      result.addAll(function.apply(aData));
+    return result;
+  }
+
+  public static String getEmptyString() {
+    return """";
+  }","[{'comment': 'More verbose than just having `""""`. Why do we need this?', 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Utilities.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import javax.annotation.Nullable;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.function.Function;
+
+public class Utilities {
+  private Utilities() {}
+
+  /**
+   * Just adds single quotes around a string.  No escaping is performed.
+   */
+  public static String singleQuote(String other) {
+    return ""'"" + other + ""'"";
+  }
+
+  @Nullable
+  public static String getFileExtension(String filename) {
+    int i = filename.lastIndexOf('.');
+    if (i > 0)
+      return filename.substring(i+1);
+    return null;
+  }
+
+  private static final char[] hexCode = ""0123456789abcdef"".toCharArray();
+
+  public static String toHex(byte[] data) {
+    StringBuilder r = new StringBuilder(data.length * 2);
+    for (byte b : data) {
+      r.append(hexCode[(b >> 4) & 0xF]);
+      r.append(hexCode[(b & 0xF)]);
+    }
+    return r.toString();
+  }","[{'comment': ""We probably have this method somewhere in the code base or common deps. Isn't there something in Guava?"", 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/executors/CalciteExecutor.java,"@@ -0,0 +1,129 @@
+/*
+ * Copyright 2023 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+package org.apache.calcite.slt.executors;
+
+import org.apache.calcite.adapter.jdbc.JdbcSchema;
+import org.apache.calcite.jdbc.CalciteConnection;
+import org.apache.calcite.schema.SchemaPlus;
+import org.apache.calcite.slt.*;
+
+import java.io.IOException;
+import java.io.UnsupportedEncodingException;
+import java.security.NoSuchAlgorithmException;
+import java.sql.*;","[{'comment': ""Please avoid wildcard imports. I don't think we use/accept them in the project."", 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/SLTTestFile.java,"@@ -0,0 +1,292 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *
+ */
+
+package org.apache.calcite.slt;
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileReader;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.logging.Logger;
+import javax.annotation.Nullable;
+
+/**
+ * Represents the data from a .test file from the
+ * SqlLogicTest test framework.
+ */
+/*","[{'comment': ""It's confusing to have javadoc and non-javadoc comment coming one after the other. Please combine them together and use proper javadoc annotations to ensure it displays properly."", 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/SLTTestFile.java,"@@ -0,0 +1,292 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ *
+ *
+ */
+
+package org.apache.calcite.slt;
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileReader;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.logging.Logger;
+import javax.annotation.Nullable;
+
+/**
+ * Represents the data from a .test file from the
+ * SqlLogicTest test framework.
+ */
+/*
+ *         The Test file format is described at
+ *         https://www.sqlite.org/sqllogictest/doc/tip/about.wiki.
+ *
+ *         Here is an example:
+ *
+ *         hash-threshold 8
+ *
+ *         statement ok
+ *         CREATE TABLE t1(a INTEGER, b INTEGER, c INTEGER, d INTEGER, e INTEGER)
+ *
+ *         statement ok
+ *         INSERT INTO t1(e,c,b,d,a) VALUES(NULL,102,NULL,101,104)
+ *
+ *         statement ok
+ *         INSERT INTO t1(a,c,d,e,b) VALUES(107,106,108,109,105)
+ *
+ *         query I nosort
+ *         SELECT CASE WHEN c>(SELECT avg(c) FROM t1) THEN a*2 ELSE b*10 END
+ *           FROM t1
+ *          ORDER BY 1
+ *         ----
+ *         30 values hashing to 3c13dee48d9356ae19af2515e05e6b54
+ *
+ */
+public class SLTTestFile {
+  Logger logger = Logger.getLogger(""SLTTestFile"");","[{'comment': ""Aren't loggers always `private static final`? Do we need to create one per instance?"", 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/ExecutionOptions.java,"@@ -0,0 +1,176 @@
+/*
+ * Copyright 2022 VMware, Inc.
+ * SPDX-License-Identifier: MIT
+ * SPDX-License-Identifier: Apache-2.0
+ *
+ * Permission is hereby granted, free of charge, to any person obtaining a copy
+ * of this software and associated documentation files (the ""Software""), to deal
+ * in the Software without restriction, including without limitation the rights
+ * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
+ * copies of the Software, and to permit persons to whom the Software is
+ * furnished to do so, subject to the following conditions:
+ *
+ * The above copyright notice and this permission notice shall be included in all
+ * copies or substantial portions of the Software.
+ *
+ * THE SOFTWARE IS PROVIDED ""AS IS"", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
+ * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
+ * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
+ * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
+ * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
+ * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
+ * SOFTWARE.
+ */
+
+package org.apache.calcite.slt;
+
+import com.beust.jcommander.IParameterValidator;
+import com.beust.jcommander.JCommander;
+import com.beust.jcommander.Parameter;
+import com.beust.jcommander.ParameterException;
+
+import org.apache.calcite.slt.executors.CalciteExecutor;
+
+import org.apache.calcite.slt.executors.JDBCExecutor;
+import org.apache.calcite.slt.executors.NoExecutor;
+
+import org.apache.calcite.slt.executors.SqlSLTTestExecutor;
+
+import java.io.BufferedReader;
+import java.io.File;
+import java.io.FileReader;
+import java.io.IOException;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import javax.annotation.Nullable;
+
+@SuppressWarnings(""CanBeFinal"")
+public class ExecutionOptions {","[{'comment': 'All public classes should have at least some top level javadoc. I think there are even checks for enforcing this.', 'commenter': 'zabetak'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Main1.java,"@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import java.io.IOException;
+import java.io.PrintStream;
+import java.net.URL;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+
+import net.hydromatic.sqllogictest.ExecutionOptions;
+import net.hydromatic.sqllogictest.executors.HsqldbExecutor;
+import net.hydromatic.sqllogictest.executors.NoExecutor;
+import net.hydromatic.sqllogictest.TestLoader;
+
+import org.apache.calcite.slt.executors.CalciteExecutor;
+
+/**
+ * Execute all SqlLogicTest tests.
+ */
+public class Main1 {","[{'comment': ""What's the purpose of this class? I don't see it used anywhere."", 'commenter': 'zabetak'}, {'comment': ""It contains the 'main' entry point.\r\nI am not sure how SLT will be used by Calcite yet, so the plan was to provide an executable that people could run to find bugs. Until the bugs it finds are fixed I don't know exactly how it can be integrated in the test suite."", 'commenter': 'mihaibudiu'}]"
3145,slt/src/main/java/org/apache/calcite/slt/Main1.java,"@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import java.io.IOException;
+import java.io.PrintStream;
+import java.net.URL;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+
+import net.hydromatic.sqllogictest.ExecutionOptions;
+import net.hydromatic.sqllogictest.executors.HsqldbExecutor;
+import net.hydromatic.sqllogictest.executors.NoExecutor;
+import net.hydromatic.sqllogictest.TestLoader;
+
+import org.apache.calcite.slt.executors.CalciteExecutor;
+
+/**
+ * Execute all SqlLogicTest tests.
+ */
+public class Main1 {
+  private Main1() {
+  }
+
+  public static void main(String[] argv) throws IOException {
+    execute(true, System.out, System.err, argv);
+  }
+
+  /** As {@link #main} but does not call {@link System#exit} if {@code exit}
+   * is false. */
+  public static int execute(boolean exit, PrintStream out, PrintStream err,
+      String... argv) throws IOException {
+    ExecutionOptions options = new ExecutionOptions(exit, out, err);
+    options.setBinaryName(""slt"");
+    NoExecutor.register(options);
+    HsqldbExecutor.register(options);
+    CalciteExecutor.register(options);
+    int parse = options.parse(argv);
+    if (parse != 0) {
+      return parse;
+    }
+
+    /*
+    URL r = Thread.currentThread().getContextClassLoader().getResource(""test"");
+    if (r == null) {
+      out.println(""Cannot find resources"");
+      return 1;
+    }
+     */
+    URL r = new URL(""/home/mbudiu/git/sqllogictest/test"");","[{'comment': ""This path to a local directory seems really suspicious. I am not sure what's the purpose of this class but if we really need it we will have to figure a way to make it work without assuming that test files exist in a local directory."", 'commenter': 'zabetak'}, {'comment': ""Sorry, that's a bug left over from testing, the commented-out code should be used instead."", 'commenter': 'mihaibudiu'}]"
3145,slt/README.md,"@@ -0,0 +1,72 @@
+<!--
+{% comment %}
+Licensed to the Apache Software Foundation (ASF) under one or more
+contributor license agreements.  See the NOTICE file distributed with
+this work for additional information regarding copyright ownership.
+The ASF licenses this file to you under the Apache License, Version 2.0
+(the ""License""); you may not use this file except in compliance with
+the License.  You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+{% endcomment %}
+-->
+
+# SQL logic tests","[{'comment': ""We are not going to distribute any `slt` binaries as part of Calcite so we don't need this README."", 'commenter': 'zabetak'}]"
3145,settings.gradle.kts,"@@ -83,7 +83,8 @@ include(
     ""spark"",
     ""splunk"",
     ""testkit"",
-    ""ubenchmark""
+    ""ubenchmark"",
+    ""slt""","[{'comment': ""I agree with Julian that we don't need a new module; putting the tests in plus makes sense."", 'commenter': 'zabetak'}, {'comment': 'I am not sure what ""plus"" is. Should I just move the code into the plus project using the org.apache.calcite.slt package?', 'commenter': 'mihaibudiu'}]"
3145,slt/src/test/java/org/apache/calcite/slt/TestCalcite.java,"@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.PrintStream;
+import java.nio.charset.StandardCharsets;
+
+import org.junit.jupiter.api.Test;
+
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.core.Is.is;
+
+public class TestCalcite {
+  private static final String USAGE = """"","[{'comment': 'Is this used? Do we need this?', 'commenter': 'zabetak'}]"
3145,slt/src/test/java/org/apache/calcite/slt/TestCalcite.java,"@@ -0,0 +1,87 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.calcite.slt;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.PrintStream;
+import java.nio.charset.StandardCharsets;
+
+import org.junit.jupiter.api.Test;
+
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.core.Is.is;
+
+public class TestCalcite {","[{'comment': 'Probably we need to pick a name that reflects that we are running `sql-logic-test`; `TestCalcite` is quite general.', 'commenter': 'zabetak'}, {'comment': 'This class was created only to make sure that this project correctly extends sql-logic-test. \r\nIf we plan to integrate this tool into the Calcite testsuite we have to devise a better name and design for this class.', 'commenter': 'mihaibudiu'}]"
3145,plus/build.gradle.kts,"@@ -25,9 +25,11 @@ dependencies {
     implementation(""com.teradata.tpcds:tpcds"")
     implementation(""io.prestosql.tpch:tpch"")
     implementation(""net.hydromatic:chinook-data-hsqldb"")
+    implementation(""net.hydromatic:sql-logic-test:0.2"")
     implementation(""net.hydromatic:tpcds"")
     implementation(""org.apache.calcite.avatica:avatica-server"")
     implementation(""org.hsqldb:hsqldb"")
+    implementation(""org.reflections:reflections:0.10.2"")","[{'comment': 'Why do we need to declare this? Usually transitive dependencies should be discovered automatically?', 'commenter': 'zabetak'}]"
3145,plus/build.gradle.kts,"@@ -25,9 +25,11 @@ dependencies {
     implementation(""com.teradata.tpcds:tpcds"")
     implementation(""io.prestosql.tpch:tpch"")
     implementation(""net.hydromatic:chinook-data-hsqldb"")
+    implementation(""net.hydromatic:sql-logic-test:0.2"")","[{'comment': 'Should this rather be a `testImplementation` dependency?', 'commenter': 'zabetak'}, {'comment': 'Also probably the version (""0.2"") should not be controlled here. That\'s why we have the gradle.properties file.', 'commenter': 'zabetak'}]"
3145,plus/src/test/java/org/apache/calcite/slt/TestCalcite.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.slt;
+
+import org.apache.calcite.slt.executors.CalciteExecutor;
+
+import net.hydromatic.sqllogictest.OptionsParser;
+
+import org.junit.jupiter.api.Test;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.PrintStream;
+import java.nio.charset.StandardCharsets;
+
+import static org.hamcrest.MatcherAssert.assertThat;
+import static org.hamcrest.core.Is.is;
+
+/**
+ * Tests using sql-logic-test suite.
+ */
+public class TestCalcite {","[{'comment': 'The class should be reworked. \r\n\r\n1. We want to run all sql-logic-test that pass and not only `select1.test`. \r\n2. When there is a regression we want to have a clear way to know which test and which file failed. (optional but useful)\r\n3. We only care about tests using the Calcite executor; anything else is out of context of this pr.', 'commenter': 'zabetak'}, {'comment': 'The main problem is that there are *lots* of failures. Only in these 1000 tests from select1.test there are 153 failures. They are due to a small number of underlying causes. If we run all 5M tests in this call, with this expected failure rate there will be 50K failures, and the output will cause the PrintStreams used in launchSqlLogicTest to run out of memory.\r\n\r\nUntil we implement https://github.com/hydromatic/sql-logic-test/issues/16 we probably cannot run all the tests.\r\n\r\nWhen all the found Calcite bugs are fixed we can modify the test here to assert that there are no failures, but until that happens I am unsure how to use this test. Right now this code is most useful if it outputs a diagnosis for human consumption.', 'commenter': 'mihaibudiu'}]"
3145,plus/src/test/java/org/apache/calcite/slt/executors/CalciteExecutor.java,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.slt.executors;
+
+import org.apache.calcite.adapter.jdbc.JdbcSchema;
+import org.apache.calcite.jdbc.CalciteConnection;
+import org.apache.calcite.schema.SchemaPlus;
+
+import net.hydromatic.sqllogictest.ISqlTestOperation;
+import net.hydromatic.sqllogictest.OptionsParser;
+import net.hydromatic.sqllogictest.SltSqlStatement;
+import net.hydromatic.sqllogictest.SltTestFile;
+import net.hydromatic.sqllogictest.SqlTestQuery;
+import net.hydromatic.sqllogictest.TestStatistics;
+import net.hydromatic.sqllogictest.executors.HsqldbExecutor;
+import net.hydromatic.sqllogictest.executors.JdbcExecutor;
+import net.hydromatic.sqllogictest.executors.SqlSltTestExecutor;
+
+import java.io.IOException;
+import java.security.NoSuchAlgorithmException;
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.util.Set;
+import javax.sql.DataSource;
+
+/**
+ * Executor for SQL logic tests using Calcite's JDBC adapter.
+ */
+public class CalciteExecutor extends SqlSltTestExecutor {","[{'comment': 'I think I left some comments regarding this class in a previous review.', 'commenter': 'zabetak'}, {'comment': ""I looked everywhere and I could not find other comments about this class. I apologize if I didn't address them. "", 'commenter': 'mihaibudiu'}]"
3173,site/_docs/reference.md,"@@ -1835,6 +1835,7 @@ period:
 | Operator syntax | Description
 |:--------------- |:-----------
 | {fn CONVERT(value, type)} | Cast *value* into *type*
+| {fn CONVERT/TRANSLATE(value using transcodingName)} | Alter *value* from one base character set to *transcodingName*","[{'comment': ""Does JDBC syntax (`{fn` ... `}`) allows `USING`? I don't think so.\r\n\r\nSo, move this line to somewhere else in the SQL reference. Probably to the 'Explicit Type Conversion' section. Split into separate lines, one for `CONVERT(value USION transcodingName)`, and one for `TRANSLATE(value USING transcodingName)`\r\n"", 'commenter': 'julianhyde'}, {'comment': 'Move it to `Explicit Type Conversion` section.', 'commenter': 'ILuffZhe'}]"
3173,core/src/main/java/org/apache/calcite/util/BuiltInMethod.java,"@@ -443,6 +443,7 @@ public enum BuiltInMethod {
       String.class, boolean.class),
   REPLACE(SqlFunctions.class, ""replace"", String.class, String.class,
       String.class),
+  TRANSLATE(SqlFunctions.class, ""translateWithCharset"", String.class, String.class),","[{'comment': 'Rename this from TRANSLATE to TRANSLATE_WITH_CHARSET. The enum value should be similar to the function name.', 'commenter': 'julianhyde'}, {'comment': 'Done.', 'commenter': 'ILuffZhe'}]"
3173,core/src/main/java/org/apache/calcite/sql/fun/SqlTranslateFunction.java,"@@ -0,0 +1,108 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.fun;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.sql.SqlCall;
+import org.apache.calcite.sql.SqlCallBinding;
+import org.apache.calcite.sql.SqlFunctionCategory;
+import org.apache.calcite.sql.SqlIdentifier;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlNode;
+import org.apache.calcite.sql.SqlOperandCountRange;
+import org.apache.calcite.sql.SqlUtil;
+import org.apache.calcite.sql.type.ReturnTypes;
+import org.apache.calcite.sql.type.SqlOperandCountRanges;
+import org.apache.calcite.sql.type.SqlTypeUtil;
+import org.apache.calcite.sql.validate.SqlValidator;
+import org.apache.calcite.sql.validate.SqlValidatorScope;
+
+import java.util.List;
+
+import static org.apache.calcite.util.Static.RESOURCE;
+
+/**
+ * Common base for the <code>TRANSLATE</code> function.","[{'comment': ""expand TRANSLATE to TRANSLATE(USING) and CONVERT(USING)\r\n\r\nmention that this is not CONVERT (MSSQL's cast)\r\nand this is not TRANSLATE (SqlTranslate3Function)"", 'commenter': 'julianhyde'}, {'comment': 'Adding doc to make this function clear.', 'commenter': 'ILuffZhe'}]"
3184,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -279,6 +279,11 @@ private StandardConvertletTable() {
             SqlStdOperatorTable.POSITION.createCall(SqlParserPos.ZERO,
                 call.operand(1), call.operand(0))));
 
+    // ""INSTR(string, substring, position, occurrence) is equivalent to","[{'comment': ""We might want to add this comment to the `convertInstr` function since `POSITION` is not referenced in line 284 - we're explicitly registering a `convertInstr` method made for `INSTR`"", 'commenter': 'tjbanghart'}]"
3184,core/src/main/java/org/apache/calcite/sql2rel/StandardConvertletTable.java,"@@ -402,6 +407,32 @@ private static RexNode convertNvl(SqlRexContext cx, SqlCall call) {
                 operand1)));
   }
 
+  /** Converts a call to the INSTR function. */
+  private static RexNode convertInstr(SqlRexContext cx, SqlCall call) {
+    final RexBuilder rexBuilder = cx.getRexBuilder();
+    final List<RexNode> operands =
+        convertOperands(cx, call, SqlOperandTypeChecker.Consistency.NONE);
+    final RelDataType type =
+        cx.getValidator().getValidatedNodeType(call);
+    final List<RexNode> exprs = new ArrayList<>();
+    if (call.operandCount() == 2) {","[{'comment': 'Comments here would also be helpful. It is not clear what each operand is and why their order matters. ', 'commenter': 'tjbanghart'}, {'comment': 'consider a \r\n```\r\nswitch (call.operandCount())\r\ncase 2 \r\ncase 3\r\n...\r\n```', 'commenter': 'olivrlee'}, {'comment': ""added some but might've gone overboard, let me know if it's too verbose"", 'commenter': 'jhugomoore'}]"
3184,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -3677,7 +3677,7 @@ static void checkRlikeFails(SqlOperatorFixture f) {
     f.checkScalarExact(""position('b' in 'abcabc' FROM 3)"", 5);
     f.checkScalarExact(""position('b' in 'abcabc' FROM 5)"", 5);
     f.checkScalarExact(""position('b' in 'abcabc' FROM 6)"", 0);
-    f.checkScalarExact(""position('b' in 'abcabc' FROM -5)"", 0);
+    f.checkScalarExact(""position('b' in 'abcabc' FROM -5)"", 2);","[{'comment': 'Why do we need to change this test? ', 'commenter': 'tjbanghart'}, {'comment': 'These tests were from before a negative position value was accepted as valid input, so it would just return 0.', 'commenter': 'jhugomoore'}]"
3184,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -3686,7 +3686,7 @@ static void checkRlikeFails(SqlOperatorFixture f) {
     f.checkScalarExact(""position(x'bb' in x'aabbccaabbcc' FROM 3)"", 5);
     f.checkScalarExact(""position(x'bb' in x'aabbccaabbcc' FROM 5)"", 5);
     f.checkScalarExact(""position(x'bb' in x'aabbccaabbcc' FROM 6)"", 0);
-    f.checkScalarExact(""position(x'bb' in x'aabbccaabbcc' FROM -5)"", 0);","[{'comment': 'Same here, that seems odd', 'commenter': 'tjbanghart'}, {'comment': 'same reasoning^ also had me confused for a while ', 'commenter': 'jhugomoore'}]"
3184,core/src/main/java/org/apache/calcite/sql/dialect/BigQuerySqlDialect.java,"@@ -150,15 +150,36 @@ public BigQuerySqlDialect(SqlDialect.Context context) {
       final int rightPrec) {
     switch (call.getKind()) {
     case POSITION:
-      final SqlWriter.Frame frame = writer.startFunCall(""STRPOS"");
-      writer.sep("","");
-      call.operand(1).unparse(writer, leftPrec, rightPrec);
-      writer.sep("","");
-      call.operand(0).unparse(writer, leftPrec, rightPrec);
+      if (2 == call.operandCount()) {","[{'comment': 'I think we could simplify the `if` expressions here and elsewhere when checking the `operandCount()`. Consider moving this into a helper function or starting the frame before the `if` blocks and ending the with the `writer.endFunCall(frame)` outside of a block. ', 'commenter': 'tjbanghart'}, {'comment': ""Main reason I couldn't do that was due to wanting to unparse a position() with 2 operands into STRPOS, but 3 or 4 operands into INSTR. I think I'll just unparsing position into INSTR no matter what because it fully encompasses the functionality of STRPOS, let me know if that's an issue"", 'commenter': 'jhugomoore'}]"
3184,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3104,23 +3104,105 @@ public static int position(ByteString seek, ByteString s) {
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function. */
   public static int position(String seek, String s, int from) {
-    final int from0 = from - 1; // 0-based
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      }
+
+      return s.indexOf(seek, from0) + 1;
+    }
+    // Case when from is negative","[{'comment': ""I'd probably add an explicit `else` for this case "", 'commenter': 'olivrlee'}]"
3184,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -1028,4 +1034,6 @@ ExInstWithCause<CalciteException> failedToAccessField(
 
   @BaseMessage(""A table function at most has one input table with row semantics. Table function ''{0}'' has multiple input tables with row semantics"")
   ExInst<SqlValidatorException> multipleRowSemanticsTables(String funcName);
+","[{'comment': 'These can be removed ', 'commenter': 'olivrlee'}]"
3184,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3104,23 +3104,105 @@ public static int position(ByteString seek, ByteString s) {
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function. */
   public static int position(String seek, String s, int from) {
-    final int from0 = from - 1; // 0-based
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      }
+
+      return s.indexOf(seek, from0) + 1;
+    }
+    // Case when from is negative
+    final int rightIndex = from + s.length(); // negative position to positive index
+    if (rightIndex <= 0) {
       return 0;
     }
-
-    return s.indexOf(seek, from0) + 1;
+    return s.substring(0, rightIndex + 1).lastIndexOf(seek) + 1;
   }
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function for byte
    * strings. */
   public static int position(ByteString seek, ByteString s, int from) {
-    final int from0 = from - 1;
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      }
+      return s.indexOf(seek, from0) + 1;
+    }
+    // Case when from is negative
+    final int rightIndex = from + s.length();
+    if (rightIndex <= 0) {
       return 0;
     }
+    int lastIndex = 0;
+    while (lastIndex < rightIndex) {
+      int indexOf = s.substring(lastIndex, rightIndex + 1).indexOf(seek) + 1;
+      if (indexOf == 0) {
+        break;
+      }
+      lastIndex += indexOf;
+    }
+    return lastIndex;
+  }
+
+  /** SQL {@code POSITION(seek, string, from, occurrence)} function. */
+  public static int position(String seek, String s, int from, int occurrence) {
+    if (occurrence == 0) {
+      throw RESOURCE.occurrenceNotZero().ex();
+    }
+    for (int i = 0; i < occurrence; i++) {
+      if (from > 0) {
+        from = position(seek, s, from + (i == 0 ? 0 : 1));
+        if (from == 0) {
+          return 0;
+        }
+      } else {
+        from = position(seek, s, from);
+        if (from == 0) {
+          return 0;
+        }
+        from -= s.length() + 2;
+      }
+    }
+    if (from < 0) {
+      from += s.length() + 2;
+    }
+    return from;
+  }
 
-    return s.indexOf(seek, from0) + 1;
+  /** SQL {@code POSITION(seek, string, from, occurrence)} function for byte
+   * strings. */
+  public static int position(ByteString seek, ByteString s, int from, int occurrence) {
+    if (occurrence == 0) {
+      throw RESOURCE.occurrenceNotZero().ex();
+    }
+    for (int i = 0; i < occurrence; i++) {","[{'comment': 'I think we should rely more heavily on String builtins here. For example rather than making a recursive call to `position` why not just take a substring with the `from` argument and then use a Pattern with grouping sets to count occurrences. \r\n\r\nAlso consider StringUtils: https://commons.apache.org/proper/commons-lang/apidocs/org/apache/commons/lang3/StringUtils.html#countMatches(java.lang.CharSequence,%20java.lang.CharSequence)', 'commenter': 'tjbanghart'}, {'comment': ""^ I didn't think about overlapping patterns. I am not sure if those suggestions will work."", 'commenter': 'tjbanghart'}, {'comment': ""Definitely had a sneaking feeling there's a much more elegant solution than what I implemented, will keep brainstorming."", 'commenter': 'jhugomoore'}, {'comment': ""The call to `position` isn't recursive, thank goodness. \r\n\r\nI'd be inclined to inline the `position` function, and move the `if` outside the `for`. I think you can skip a lot of checks.\r\n\r\nI was wondering how to implement this without calling `String.substring`, but I can't find an easy solution. So let's leave it as is."", 'commenter': 'julianhyde'}]"
3184,core/src/main/java/org/apache/calcite/sql/fun/SqlPositionFunction.java,"@@ -53,12 +57,23 @@ public SqlPositionFunction(String name) {
       int leftPrec,
       int rightPrec) {
     final SqlWriter.Frame frame = writer.startFunCall(getName());
-    call.operand(0).unparse(writer, leftPrec, rightPrec);
-    writer.sep(""IN"");
-    call.operand(1).unparse(writer, leftPrec, rightPrec);
-    if (3 == call.operandCount()) {
-      writer.sep(""FROM"");
+    if (2 == call.operandCount() || 3 == call.operandCount()) {","[{'comment': 'nit: switch the ordering like `call.operandCount() == 2`', 'commenter': 'olivrlee'}]"
3184,core/src/main/java/org/apache/calcite/sql/fun/SqlPositionFunction.java,"@@ -53,12 +57,23 @@ public SqlPositionFunction(String name) {
       int leftPrec,
       int rightPrec) {
     final SqlWriter.Frame frame = writer.startFunCall(getName());
-    call.operand(0).unparse(writer, leftPrec, rightPrec);
-    writer.sep(""IN"");
-    call.operand(1).unparse(writer, leftPrec, rightPrec);
-    if (3 == call.operandCount()) {
-      writer.sep(""FROM"");
+    if (2 == call.operandCount() || 3 == call.operandCount()) {
+      call.operand(0).unparse(writer, leftPrec, rightPrec);
+      writer.sep(""IN"");
+      call.operand(1).unparse(writer, leftPrec, rightPrec);
+      if (3 == call.operandCount()) {
+        writer.sep(""FROM"");
+        call.operand(2).unparse(writer, leftPrec, rightPrec);
+      }
+    }
+    if (4 == call.operandCount()) {
+      call.operand(0).unparse(writer, leftPrec, rightPrec);
+      writer.sep("","");
+      call.operand(1).unparse(writer, leftPrec, rightPrec);
+      writer.sep("","");","[{'comment': 'nit: switch the ordering like `call.operandCount() == 2`', 'commenter': 'olivrlee'}]"
3184,core/src/main/java/org/apache/calcite/sql/fun/SqlPositionFunction.java,"@@ -53,12 +57,23 @@ public SqlPositionFunction(String name) {
       int leftPrec,
       int rightPrec) {
     final SqlWriter.Frame frame = writer.startFunCall(getName());
-    call.operand(0).unparse(writer, leftPrec, rightPrec);
-    writer.sep(""IN"");
-    call.operand(1).unparse(writer, leftPrec, rightPrec);
-    if (3 == call.operandCount()) {
-      writer.sep(""FROM"");
+    if (2 == call.operandCount() || 3 == call.operandCount()) {
+      call.operand(0).unparse(writer, leftPrec, rightPrec);
+      writer.sep(""IN"");
+      call.operand(1).unparse(writer, leftPrec, rightPrec);
+      if (3 == call.operandCount()) {
+        writer.sep(""FROM"");
+        call.operand(2).unparse(writer, leftPrec, rightPrec);
+      }
+    }
+    if (4 == call.operandCount()) {","[{'comment': 'What dialects support this 4 argument position without `IN` and `FROM`?', 'commenter': 'tjbanghart'}, {'comment': ""As far as my understanding, this 4 argument position function doesn't exist outside of calcite. I was basically left with the choice of adding another keyword in the function (would get confusing and doesn't have a clear best identifier), or to just default to comma separated operands (introduces inconsistent syntax in calcite which isn't ideal), wasn't sure the best choice. Let me know if you think I should switch it over."", 'commenter': 'jhugomoore'}]"
3184,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3104,23 +3104,106 @@ public static int position(ByteString seek, ByteString s) {
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function. */
   public static int position(String seek, String s, int from) {
-    final int from0 = from - 1; // 0-based
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      } else {
+        return s.indexOf(seek, from0) + 1;
+      }
+    }
+    // Case when from is negative
+    final int rightIndex = from + s.length(); // negative position to positive index
+    if (rightIndex <= 0) {
       return 0;
     }
-
-    return s.indexOf(seek, from0) + 1;
+    return s.substring(0, rightIndex + 1).lastIndexOf(seek) + 1;
   }
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function for byte
    * strings. */
   public static int position(ByteString seek, ByteString s, int from) {
-    final int from0 = from - 1;
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      } else {
+        return s.indexOf(seek, from0) + 1;
+      }
+    }
+    // Case when from is negative
+    final int rightIndex = from + s.length();
+    if (rightIndex <= 0) {
       return 0;
     }
+    int lastIndex = 0;
+    while (lastIndex < rightIndex) {","[{'comment': 'Is there a method we could add to `ByteString` to allow you to write the same code in this method as for `position(String, String, int)`? (`ByteString` is in Avatica, so we would have to wait a release.)', 'commenter': 'julianhyde'}, {'comment': ""Yes! Java strings have a nice [.lastIndexOf()](https://www.w3schools.com/java/ref_string_lastindexof.asp) function that isn't present in Avatica Bytestrings"", 'commenter': 'jhugomoore'}]"
3184,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3104,23 +3104,106 @@ public static int position(ByteString seek, ByteString s) {
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function. */
   public static int position(String seek, String s, int from) {
-    final int from0 = from - 1; // 0-based
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      } else {
+        return s.indexOf(seek, from0) + 1;
+      }
+    }
+    // Case when from is negative
+    final int rightIndex = from + s.length(); // negative position to positive index
+    if (rightIndex <= 0) {
       return 0;
     }
-
-    return s.indexOf(seek, from0) + 1;
+    return s.substring(0, rightIndex + 1).lastIndexOf(seek) + 1;
   }
 
   /** SQL {@code POSITION(seek IN string FROM integer)} function for byte
    * strings. */
   public static int position(ByteString seek, ByteString s, int from) {
-    final int from0 = from - 1;
-    if (from0 > s.length() || from0 < 0) {
+    if (from == 0) {
+      throw RESOURCE.fromNotZero().ex();
+    }
+    // Case when from is positive
+    if (from > 0) {
+      final int from0 = from - 1; // 0-based
+      if (from0 >= s.length() || from0 < 0) {
+        return 0;
+      } else {
+        return s.indexOf(seek, from0) + 1;
+      }
+    }
+    // Case when from is negative
+    final int rightIndex = from + s.length();
+    if (rightIndex <= 0) {
       return 0;
     }
+    int lastIndex = 0;
+    while (lastIndex < rightIndex) {
+      int indexOf = s.substring(lastIndex, rightIndex + 1).indexOf(seek) + 1;
+      if (indexOf == 0) {
+        break;
+      }
+      lastIndex += indexOf;
+    }
+    return lastIndex;
+  }
 
-    return s.indexOf(seek, from0) + 1;
+  /** SQL {@code POSITION(seek, string, from, occurrence)} function. */
+  public static int position(String seek, String s, int from, int occurrence) {
+    if (occurrence == 0) {
+      throw RESOURCE.occurrenceNotZero().ex();
+    }
+    for (int i = 0; i < occurrence; i++) {","[{'comment': ""`from` is constant and `i` is not. So would it make sense to move the `if` outside the `for`, so that it's only checked once?"", 'commenter': 'julianhyde'}, {'comment': 'Not sure I understand what you mean. From gets updated every time the for loop runs, so we have to check whether to use the logic for from being positive or negative each time. I think checking if from is 0 after assignment is necessary because it will error if we continue running', 'commenter': 'jhugomoore'}]"
3184,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -1054,6 +1055,54 @@ private void thereAndBack(byte[] bytes) {
       // ok
     }
   }
+  @Test void testPosition() {","[{'comment': 'add blankline before', 'commenter': 'julianhyde'}]"
3184,site/_docs/reference.md,"@@ -2693,6 +2693,8 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b o | GREATEST(expr [, expr ]*)                    | Returns the greatest of the expressions
 | b h s | IF(condition, value1, value2)              | Returns *value1* if *condition* is TRUE, *value2* otherwise
 | b | IFNULL(value1, value2)                         | Equivalent to `NVL(value1, value2)`
+| b o | INSTR(string, substring[, from, occurrence]) | Returns the position of substring in string, searching starting at from, and until locating the nth occurrence of substring.","[{'comment': ""s/substring/\\*substring\\*/ etc.\r\n\r\ns/from/from (default 1)/\r\n\r\ns/occurrence/occurrence (default 1)/\r\n\r\nremove '.' at end of line"", 'commenter': 'julianhyde'}]"
3184,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -1054,6 +1055,54 @@ private void thereAndBack(byte[] bytes) {
       // ok
     }
   }
+  @Test void testPosition() {
+    assertThat(3, is(position(""c"", ""abcdec"")));
+    assertThat(3, is(position(""c"", ""abcdec"", 2)));","[{'comment': 'These tests are all backwards! For example, rather than\r\n```\r\nassertThat(3, is(position(""c"", ""abcdec"", 2)));\r\n```\r\nyou should write\r\n```\r\nassertThat(position(""c"", ""abcdec"", 2), is(3)));\r\n```\r\nHere, `position(""c"", ""abcdec"", 2)` is the thing you are testing, and `3` is the expected result. In fact `is(3)` is the assertion about the expected result.\r\n\r\nWhy does it matter? If the test fails - say the position call returns 57 - then the framework should print \'got 57, expected 3\'. Also, the test reads from left-to-right like an English sentence.\r\n\r\nMaybe you\'re familiar with `assertEquals`, and earlier method where you were SUPPOSED to write the arguments backwards. `assertEquals(3, position(""c"", ""abcdec"", 2));` would be the correct way to write this test using `assertEquals`.', 'commenter': 'julianhyde'}]"
3184,core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties,"@@ -336,4 +336,6 @@ InvalidPartitionKeys=Only tables with set semantics may be partitioned. Invalid
 InvalidOrderBy=Only tables with set semantics may be ordered. Invalid ORDER BY clause in the {0,number,#}-th operand of table function ''{1}''
 MultipleRowSemanticsTables=A table function at most has one input table with row semantics. Table function ''{0}'' has multiple input tables with row semantics
 NoOperator=No operator for ''{0}'' with kind: ''{1}'', syntax: ''{2}'' during JSON deserialization
+FromNotZero=Invalid input for position function: from operand value must not be zero","[{'comment': ""s/position/POSITION/\r\n\r\nOther error messages have the function in upper case. It reinforces that it's a function name."", 'commenter': 'julianhyde'}]"
3184,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -1020,6 +1020,12 @@ ExInstWithCause<CalciteException> failedToAccessField(
   @BaseMessage(""No operator for ''{0}'' with kind: ''{1}'', syntax: ''{2}'' during JSON deserialization"")
   ExInst<CalciteException> noOperator(String name, String kind, String syntax);
 
+  @BaseMessage(""Invalid input for position function: from operand value must not be zero"")
+  ExInst<CalciteException> fromNotZero();
+
+  @BaseMessage(""Invalid input for position function: occurrence operand value must not be zero"")","[{'comment': '`occurence` must be positive. Update the message and condition.', 'commenter': 'wnob'}]"
3184,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -1020,6 +1020,12 @@ ExInstWithCause<CalciteException> failedToAccessField(
   @BaseMessage(""No operator for ''{0}'' with kind: ''{1}'', syntax: ''{2}'' during JSON deserialization"")
   ExInst<CalciteException> noOperator(String name, String kind, String syntax);
 
+  @BaseMessage(""Invalid input for position function: from operand value must not be zero"")","[{'comment': 'BQ and Oracle both call this `position`, not `from`. Is there another dialect that calls it `from`?', 'commenter': 'wnob'}]"
3188,core/src/main/codegen/templates/Parser.jj,"@@ -1136,6 +1137,8 @@ SqlNode SqlStmt() :
         stmt = SqlDrop()
     |
 </#if>
+        stmt = SqlTruncateTable()","[{'comment': 'Please implement it in Babel.', 'commenter': 'JiajunBernoulli'}]"
3210,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -593,6 +593,48 @@ private boolean hasFractionalPart(BigDecimal bd) {
         }
       };
 
+  public static final SqlSingleOperandTypeChecker NUMERIC_UNIT_INTERVAL_NUMERIC_LITERAL =","[{'comment': 'add javadoc. also add a blank line after the declaration.', 'commenter': 'julianhyde'}]"
3210,core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties,"@@ -131,6 +131,7 @@ AggregateInWithinGroupIllegal=WITHIN GROUP must not contain aggregate expression
 AggregateInWithinDistinctIllegal=WITHIN DISTINCT must not contain aggregate expression
 AggregateMissingWithinGroupClause=Aggregate expression ''{0}'' must contain a WITHIN GROUP clause
 WithinGroupClauseIllegalInAggregate=Aggregate expression ''{0}'' must not contain a WITHIN GROUP clause
+percentileFunctionsArgumentLimit=Percentile functions may only have 1 or 2 arguments
 AggregateIllegalInOrderBy=Aggregate expression is illegal in ORDER BY clause of non-aggregating SELECT","[{'comment': 's/p/P/', 'commenter': 'julianhyde'}]"
3210,testkit/src/main/java/org/apache/calcite/sql/parser/SqlParserTest.java,"@@ -748,6 +748,50 @@ protected static SortedSet<String> keywords(@Nullable String dialect) {
         .fails(""(?s)Encountered \""\\*\"" at .*"");
   }
 
+  @Test void testPercentileCont() {
+    sql(""select percentile_cont(.5) within group (order by 3) from t"")
+        .ok(""SELECT PERCENTILE_CONT(0.5) WITHIN GROUP (ORDER BY 3)\n""
+  +","[{'comment': ""'+' should be indented"", 'commenter': 'julianhyde'}]"
3210,site/_docs/reference.md,"@@ -2836,6 +2836,8 @@ Dialect-specific aggregate functions.
 | b | LOGICAL_OR(condition)                          | Synonym for `SOME`
 | s | MAX_BY(value, comp)                            | Synonym for `ARG_MAX`
 | s | MIN_BY(value, comp)                            | Synonym for `ARG_MIN`
+| b | PERCENTILE_CONT(value, fraction)               | 2-argument synonym for the standard `PERCENTILE_CONT` that does not use WITHIN GROUP clause and allows for null treatment
+| b | PERCENTILE_DISC(value, fraction)               | 2-argument synonym for the standard `PERCENTILE_DISC` that does not use WITHIN GROUP clause and allows for null treatment","[{'comment': 'does it make sense to add `[ RESPECT NULLS ]` to the syntax?\r\n\r\nis it possible to concisely show the mapping, e.g. that `PERCENTILE_CONT(value, fraction)` is a synonym for `PERCENTILE_CONT(fraction) WITHIN GROUP (ORDER BY value)` (or whatever)', 'commenter': 'julianhyde'}]"
3210,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -6139,27 +6139,35 @@ private SqlNode navigationInDefine(SqlNode node, String alpha) {
     }
 
     if (op.isPercentile()) {","[{'comment': 'This code is now sufficiently complex that a couple of examples would be useful.', 'commenter': 'julianhyde'}]"
3210,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -6540,6 +6540,64 @@ void testGroupExpressionEquivalenceParams() {
         .fails(""'PERCENTILE_DISC' requires precisely one ORDER BY key"");
   }
 
+  @Test void testPercentileFunctionsBigQuery() {
+    final SqlOperatorTable opTable = operatorTableFor(SqlLibrary.BIG_QUERY);","[{'comment': 'the examples over `unnest(array)` are appropriate for `big-query.iq` but are not typical of actual usage. for these tests can you switch to queries that use `emp`. Compute the percentile of sal of each employee within their department and within the whole org.', 'commenter': 'julianhyde'}]"
3210,core/src/main/codegen/templates/Parser.jj,"@@ -4056,6 +4056,59 @@ SqlCall StringAggFunctionCall() :
     }
 }
 
+/**","[{'comment': 'please include some brief example syntax.', 'commenter': 'julianhyde'}]"
3212,core/src/main/java/org/apache/calcite/sql/type/ReturnTypes.java,"@@ -487,6 +487,18 @@ public static SqlCall stripSeparator(SqlCall call) {
         -1);
   };
 
+  /**
+   * Returns the element type of a ARRAY or MULTISET.
+   *
+   * <p>For example, given <code>INTEGER ARRAY or MULTISET ARRAY</code>, returns
+   * <code>INTEGER</code>.
+   */
+  public static final SqlReturnTypeInference TO_COLLECTION_ELEMENT =
+      ARG0.andThen(SqlTypeTransforms.TO_COLLECTION_ELEMENT_TYPE);","[{'comment': 'Will fail with an empty array:\r\nhttps://github.com/apache/calcite/pull/3218#discussion_r1209622163', 'commenter': 'MasseGuillaume'}, {'comment': ""@MasseGuillaume  \r\nit doesn't faill, because array() type is UNKNOWN NOT NULL ARRAY NOT NULL,\r\nso the TO_COLLECTION_ELEMENT will return UNKNOWN NOT NULL "", 'commenter': 'liuyongvs'}]"
3212,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -5336,6 +5336,36 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""array_distinct(null)"");
   }
 
+  /** Tests {@code ARRAY_MAX} function from Spark. */
+  @Test void testArrayMaxFunc() {
+    final SqlOperatorFixture f0 = fixture();
+    f0.setFor(SqlLibraryOperators.ARRAY_MAX);
+    f0.checkFails(""^array_max(array[1, 2])^"",
+        ""No match found for function signature ARRAY_MAX\\(<INTEGER ARRAY>\\)"", false);
+
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.SPARK);
+    f.checkScalar(""array_max(array[1, 2])"", ""2"",","[{'comment': 'minimum case (to check off by one errors, etc):\r\n`f.checkScalar(""array_max(array[1])"", ""1"", ""INTEGER NOT NULL"");`\r\n\r\nempty case:\r\n`f.checkScalar(""array_max(array())"", ""NULL"", ""UNKNOWN"");`', 'commenter': 'MasseGuillaume'}, {'comment': '@MasseGuillaume  thanks, add the test.\r\n\r\nand the type should always nullable, which you can see here \r\n```\r\ncase class ArrayMax(child: Expression)\r\n  extends UnaryExpression with ImplicitCastInputTypes with NullIntolerant {\r\n\r\n  override def nullable: Boolean = true\r\n```\r\n\r\nhttps://github.com/apache/spark/blob/014dd357656106cc8dc0fcfb30cbe067a714916c/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/expressions/collectionOperations.scala#L2126\r\n\r\nso i fixed it in the next commit message with fix review', 'commenter': 'liuyongvs'}]"
3212,core/src/main/java/org/apache/calcite/sql/type/ReturnTypes.java,"@@ -500,7 +515,7 @@ public static SqlCall stripSeparator(SqlCall call) {
    * Returns the element type of a MULTISET.
    */
   public static final SqlReturnTypeInference MULTISET_ELEMENT_NULLABLE =
-      MULTISET.andThen(SqlTypeTransforms.TO_MULTISET_ELEMENT_TYPE);
+      MULTISET.andThen(SqlTypeTransforms.TO_COLLECTION_ELEMENT_TYPE);","[{'comment': 'Do you think SEQ or LIST better than COLLECTION?', 'commenter': 'JiajunBernoulli'}, {'comment': '@JiajunBernoulli i modify the name because it can be use not only multiset type, but also array type', 'commenter': 'liuyongvs'}, {'comment': '`COLLECTION` usually also includes `MAP` and `SET`, does them also work?', 'commenter': 'JiajunBernoulli'}, {'comment': ""@JiajunBernoulli COLLECTION includes array and multiset, both have getComponentType, but doesn't include map type. map type has getKeyType and getValueType"", 'commenter': 'liuyongvs'}]"
3212,core/src/main/java/org/apache/calcite/util/BuiltInMethod.java,"@@ -629,6 +629,8 @@ public enum BuiltInMethod {
   SUBMULTISET_OF(SqlFunctions.class, ""submultisetOf"", Collection.class,
       Collection.class),
   ARRAY_DISTINCT(SqlFunctions.class, ""distinct"", List.class),
+  ARRAY_MAX(SqlFunctions.class, ""max"",  List.class),","[{'comment': 'Oh,  I just realized now that this name is not suitable.\r\n\r\n`MULTISET_UNION_ALL` named as `multisetUnionAll`\r\nARRAY_MAX should be `arrayMax`, not `max`.\r\n\r\nPlease change other function names together `ARRAY_REVERSE`, `ARRAY_REPEAT`, `ARRAY_DISTINCT`.\r\n\r\n', 'commenter': 'JiajunBernoulli'}, {'comment': '@JiajunBernoulli i does that because i refer to array_reverse implmented by snuyanzin, the function also names reverse. so i do it too. i modify all, contains ARRAY_REVERSE', 'commenter': 'liuyongvs'}]"
3212,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3870,7 +3870,7 @@ private static AtomicLong getAtomicLong(String key) {
   }
 
   /** Support the ARRAY_COMPACT function. */
-  public static List compact(List list) {
+  public static List arrayCompact(List list) {","[{'comment': 'why are we going to rename public methods?\r\nthat could impact downstream dependencies', 'commenter': 'snuyanzin'}, {'comment': '@snuyanzin this method merged in the same version, just a few days, do not have released', 'commenter': 'liuyongvs'}, {'comment': 'ok then the naming became more confusing: `arrayCompact` says about array however returns a `List`', 'commenter': 'snuyanzin'}, {'comment': '@snuyanzin just for unify with others, i use removeNulls before, but change it to arrayCompact when reviewed.', 'commenter': 'liuyongvs'}, {'comment': ""I didn't get it\r\n\r\nI see a review comment here https://github.com/apache/calcite/pull/3233#discussion_r1210553037\r\nto use `compact` name and from my point of view this is fine since with such name there is no confusion about `List` and `array`\r\nWhere in review `arrayCompact` has appeared?\r\n"", 'commenter': 'snuyanzin'}, {'comment': '@snuyanzin \r\n""this could also be named compact so it\'s easier to find, removeNulls is also ok"", this is in the comments you refer.\r\noriginally i use removeNulls then changed to compact, and i changed to arrayCompact just because the spark function name is arrayCompact, which others do it too. for search easy.\r\nhttps://github.com/apache/calcite/pull/3212#discussion_r1213835525', 'commenter': 'liuyongvs'}, {'comment': ""my concern is not about search, moreover i don't think search is an issue since you have a comment with sql version\r\nmy concern is about name confusion which I raised in this thread\r\n> ok then the naming became more confusing: `arrayCompact` says about `array` however returns a `List`\r\n"", 'commenter': 'snuyanzin'}, {'comment': ""@snuyanzin i know you meaning. List is just array type's runtime implementation. from my side, the name is ok. if you think it is not good, i can change all of them to revert."", 'commenter': 'liuyongvs'}, {'comment': ""hi @JiajunBernoulli what is your opinion, should it revert? if do don't oppose it, i will revert according to @snuyanzin "", 'commenter': 'liuyongvs'}, {'comment': '```\r\n  ARRAY_MAX(SqlFunctions.class, ""arrayMax"", List.class),\r\n  ARRAY_MIN(SqlFunctions.class, ""arrayMin"", List.class),\r\n```\r\nshould be save.\r\n\r\nOther function name can be revert.', 'commenter': 'JiajunBernoulli'}, {'comment': '@JiajunBernoulli has reverted, thanks for your suggestion @JiajunBernoulli @snuyanzin ', 'commenter': 'liuyongvs'}]"
3212,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3881,13 +3881,41 @@ public static List compact(List list) {
   }
 
   /** Support the ARRAY_DISTINCT function. */
-  public static List distinct(List list) {
+  public static List arrayDistinct(List list) {","[{'comment': 'why are we going to rename public methods?\r\nthat could impact downstream dependencies', 'commenter': 'snuyanzin'}]"
3212,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -3881,13 +3881,41 @@ public static List compact(List list) {
   }
 
   /** Support the ARRAY_DISTINCT function. */
-  public static List distinct(List list) {
+  public static List arrayDistinct(List list) {
     Set result = new LinkedHashSet<>(list);
     return new ArrayList<>(result);
   }
 
+  /** Support the ARRAY_MAX function. */
+  public static @Nullable <T extends Object & Comparable<? super T>> T arrayMax(
+      List<? extends T> list) {
+
+    T max = null;
+    for (int i = 0; i < list.size(); i++) {
+      T item = list.get(i);
+      if (item != null && (max == null || item.compareTo(max) > 0)) {
+        max = item;
+      }
+    }
+    return max;
+  }
+
+  /** Support the ARRAY_MIN function. */
+  public static @Nullable <T extends Object & Comparable<? super T>> T arrayMin(
+      List<? extends T> list) {
+
+    T min = null;
+    for (int i = 0; i < list.size(); i++) {
+      T item = list.get(i);
+      if (item != null && (min == null || item.compareTo(min) < 0)) {
+        min = item;
+      }
+    }
+    return min;
+  }
+
   /** Support the ARRAY_REPEAT function. */
-  public static @Nullable List<Object> repeat(Object element, Object count) {
+  public static @Nullable List<Object> arrayRepeat(Object element, Object count) {","[{'comment': 'why are we going to rename public methods?\r\nthat could impact downstream dependencies', 'commenter': 'snuyanzin'}]"
3212,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -4038,7 +4066,7 @@ public static Collection multisetUnionAll(Collection collection1,
   }
 
   /** Support the ARRAY_REVERSE function. */
-  public static List reverse(List list) {
+  public static List arrayReverse(List list) {","[{'comment': 'why are we going to rename public methods?\r\nthat could impact downstream dependencies', 'commenter': 'snuyanzin'}, {'comment': '1.35 has not been released yet, it will not affect downstream dependencies.\r\n\r\nThe old name is not accurate enough, we should solve this problem before the release version.', 'commenter': 'JiajunBernoulli'}]"
3234,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6111,6 +6111,31 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""truncate(cast(null as double))"");
   }
 
+  @Test void testSafeMultiplyFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.SAFE_MULTIPLY);
+    // Bounds of int64
+    final String max = ""9223372036854775807"";","[{'comment': 'use `Long.MAX_VALUE` may be better', 'commenter': 'zoudan'}, {'comment': 'Great idea.', 'commenter': 'tanclary'}]"
3234,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6111,6 +6111,31 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""truncate(cast(null as double))"");
   }
 
+  @Test void testSafeMultiplyFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.SAFE_MULTIPLY);
+    // Bounds of int64
+    final String max = ""9223372036854775807"";
+    final String min = ""-9223372036854775808"";
+    f0.checkFails(""^safe_multiply(2, 3)^"",
+        ""No match found for function signature SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    // Most tests are to verify correct return type and handling of overflow result
+    f.checkScalar(""safe_multiply(2, 3)"", ""6"", ""INTEGER"");
+    f.checkScalar(""safe_multiply(2, -1)"", ""-2"", ""INTEGER"");
+    f.checkScalar(""safe_multiply(2.5, 3.5)"", ""8.75"", ""DECIMAL(4, 2)"");
+    f.checkScalar(""safe_multiply(cast(2 as float), 3)"", ""6.0"", ""FLOAT"");
+
+    // Test that a result larger than INTEGER but less than overflow will return BIGINT type
+    f.checkScalar(""safe_multiply(1, "" + max + "")"", max, ""BIGINT"");
+    f.checkScalar(""safe_multiply(1, "" + min + "")"", min, ""BIGINT"");
+
+    // Test that overflow/underflow/null operand correctly returns null
+    f.checkNull(""safe_multiply(2, "" + max + "")"");","[{'comment': 'shall we add more test cases for overflow of other types such as safe_multiply(int b0, int b1), which should return null if the result is greater than int max.', 'commenter': 'zoudan'}, {'comment': 'That is a great idea, I think I was misunderstanding the overflow limit. I will update the tests.', 'commenter': 'tanclary'}]"
3234,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1524,6 +1524,19 @@ public static int multiply(int b0, int b1) {
     throw notArithmetic(""*"", b0, b1);
   }
 
+  /** Helper method for safe arithmetic functions that checks if overflow has occurred. */
+  private static boolean isOverflow(BigDecimal b0) {
+    return b0.compareTo(BigDecimal.valueOf(Long.MIN_VALUE)) < 0
+        || b0.compareTo(BigDecimal.valueOf(Long.MAX_VALUE)) > 0;
+  }
+
+  /** SQL {@code SAFE_MULTIPLY(<value0>, <value1>)} function. */
+  public static @Nullable Double safeMultiply(@PolyNull BigDecimal b0,","[{'comment': 'we do not have to use `@PolyNull` here？', 'commenter': 'zoudan'}, {'comment': 'We just have to handle BigDecimal * BigDecimal？May be we should also handle all the combination of input types?', 'commenter': 'zoudan'}, {'comment': 'Yes this is a great idea. ', 'commenter': 'tanclary'}, {'comment': 'Will remove!', 'commenter': 'tanclary'}, {'comment': '@zoudan I think I am going to mirror my commit from [LOG function](https://github.com/apache/calcite/commit/74bc025fbb5af4f43762926e0bec75acf6ac3025). This function has the same operand type // return type relationship so should be okay. [BigQuery docs](https://cloud.google.com/bigquery/docs/reference/standard-sql/mathematical_functions#log)', 'commenter': 'tanclary'}, {'comment': ""Most of the java functions that implement SQL functions do not need to handle null values. So I wouldn't expect to see `@PolyNull` unless there's a good reason."", 'commenter': 'julianhyde'}, {'comment': 'I think we will need to implement `float * float` (32 bit FP), `double * double` (64 bit FP), `long * long` (64 bit integer), etc.\r\n\r\nDetection of overflow is tricky. I would lean on libraries such as `java.math`. They may be able to tap into some of the CPU internals to detect overflow.', 'commenter': 'julianhyde'}, {'comment': ""`Math.multiplyExact' is the kind of thing I was thinking of: https://stackoverflow.com/questions/1657834/how-can-i-check-if-multiplying-two-numbers-in-java-will-cause-an-overflow"", 'commenter': 'julianhyde'}]"
3234,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1515,6 +1515,7 @@ public static int multiply(int b0, int b1) {
       @PolyNull Object b1) {
     if (b0 == null || b1 == null) {
       return castNonNull(null);
+","[{'comment': 'nit: remove blank line', 'commenter': 'jhugomoore'}]"
3234,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1524,6 +1524,139 @@ public static int multiply(int b0, int b1) {
     throw notArithmetic(""*"", b0, b1);
   }
 
+  /** Helper method for safe arithmetic functions that checks if overflow has occurred. */
+  private static boolean isOverflow(BigDecimal ans, BigDecimal min, BigDecimal max) {
+    return ans.compareTo(min) > 0 || ans.compareTo(max) < 0;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer values. */
+  public static @Nullable Integer safeMultiply(int b0, int b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
+    boolean overflow = isOverflow(ans, BigDecimal.valueOf(Integer.MAX_VALUE),
+        BigDecimal.valueOf(Integer.MIN_VALUE));
+    return overflow ? null : ans.intValue();
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer and double values. */
+  public static @Nullable Double safeMultiply(int b0, double b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
+    boolean overflow = isOverflow(ans, BigDecimal.valueOf(Double.MAX_VALUE),
+        BigDecimal.valueOf(-Double.MAX_VALUE));
+    return overflow ? null : ans.doubleValue();
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer and BigDecimal values. */
+  public static @Nullable BigDecimal safeMultiply(int b0, BigDecimal b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), b1);
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
+    return overflow ? null : ans;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer and long values. */
+  public static @Nullable Long safeMultiply(int b0, long b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
+    return overflow ? null : ans.longValue();
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and integer values. */
+  public static @Nullable Double safeMultiply(double b0, int b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
+    boolean overflow = isOverflow(ans, BigDecimal.valueOf(Double.MAX_VALUE),
+        BigDecimal.valueOf(-Double.MAX_VALUE));
+    return overflow ? null : ans.doubleValue();
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double values. */
+  public static @Nullable Double safeMultiply(double b0, double b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
+    boolean overflow = isOverflow(ans, BigDecimal.valueOf(Double.MAX_VALUE),
+        BigDecimal.valueOf(-Double.MAX_VALUE));
+    return overflow ? null : ans.doubleValue();
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and BigDecimal values. */
+  public static @Nullable BigDecimal safeMultiply(double b0, BigDecimal b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), b1);
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
+    return overflow ? null : ans;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and long values. */
+  public static @Nullable Long safeMultiply(double b0, long b1) {
+    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(1));
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
+    return overflow ? null : ans.longValue();
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and integer values. */
+  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, int b1) {
+    BigDecimal ans = multiply(b0, BigDecimal.valueOf(b1));
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
+    return overflow ? null : ans;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and double values. */
+  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, double b1) {
+    BigDecimal ans = multiply(b0, BigDecimal.valueOf(b1));
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
+    return overflow ? null : ans;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal values. */
+  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, BigDecimal b1) {
+    BigDecimal ans = multiply(b0, b1);
+    boolean overflow =
+        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));","[{'comment': 'Why we use `Float` here？', 'commenter': 'zoudan'}, {'comment': ""I'm also surprised that you use  `Float` (rather than `Double`). Each SQL type should use the overflow checking for its corresponding Java data type: SMALLINT = short, INTEGER = int, BIGINT = long, REAL = float, DOUBLE = double. (`TINYINT` is tricky because it is signed whereas `byte` is unsigned.)\r\n\r\nNote that BigQuery `FLOAT64` matches SQL `DOUBLE` and Java `double`.\r\n\r\nI think you should have a version of `safeMultiply` for each java type, e.g. `(short, short)`, `(int, int)`, `(long, long)`, `(float, float)`, `(double, double)`. I don't think you need `BigDecimal`.\r\n\r\nFor `int` and `long` call `Math.multiplyExact` and catch the exception.\r\n\r\nFor `short`, call the `int` version and check whether the result is in range.\r\n\r\nFor `float` and `double` I don't know how you detect overflow. Maybe do ordinary multiplication for now."", 'commenter': 'julianhyde'}, {'comment': ""I agree with both of you, `Double` makes more sense than `Float`. I've changed it."", 'commenter': 'tanclary'}]"
3234,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6114,35 +6114,62 @@ private static void checkIf(SqlOperatorFixture f) {
   @Test void testSafeMultiplyFunc() {
     final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.SAFE_MULTIPLY);
     f0.checkFails(""^safe_multiply(2, 3)^"",
-        ""No match found for function signature SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"",
-        false);
+        ""No match found for function signature ""
+        + ""SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"", false);
     final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
-    // check multiplication with no over/underflow has correct result and result type
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3 as int))"",
-        ""6"", ""INTEGER"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.5 as double))"",
-        ""7.0"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.456 as float))"",
-        ""6.912"", ""FLOAT"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DECIMAL(14, 3)"");
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.5 as double))"",
-        ""7.0"", ""DOUBLE"");
-    // DOUBLE and FLOAT in Calcite maps to BigQuery ""FLOAT64"", so returning DOUBLE is okay here
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.456 as float))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as float), cast(3.456 as float))"",
-        ""6.912"", ""FLOAT"");
-    f.checkScalar(""safe_multiply(cast(2 as float), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(3.4 as decimal(4,3)), cast(3.456 as decimal(4,3)))"",
-        ""11.7504"", ""DECIMAL(8, 6)"");
-    // check overflow returns null
-    f.checkNull(""safe_multiply(cast("" + Integer.MAX_VALUE + "" as int), 3)"");
-    f.checkNull(""safe_multiply(cast("" + Double.MAX_VALUE + "" as double), 3)"");
-    f.checkNull(""safe_multiply(9223372036854775807, 3)"");
+    // Basic test for each of the 9 2-permutations of BIGINT, DECIMAL, and FLOAT
+    f.checkScalar(""safe_multiply(cast(20 as bigint), cast(20 as bigint))"",
+                  ""400"", ""BIGINT"");
+    f.checkScalar(""safe_multiply(cast(20 as bigint), cast(1.2345 as decimal(5,4)))"",
+                  ""24.6900"", ""DECIMAL(19, 4)"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5,4)), cast(20 as bigint))"",
+                  ""24.6900"", ""DECIMAL(19, 4)"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5,4)), ""
+                          + ""cast(2.0 as decimal(2, 1)))"", ""2.46900"",
+                  ""DECIMAL(7, 5)"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(3 as bigint))"",","[{'comment': ""Are you sure? \r\n\r\nSQL's `FLOAT` datatype is more similar to Java `double` than Java `float`.\r\n\r\nIn SQL, 32-bit floating point is called `REAL`."", 'commenter': 'julianhyde'}, {'comment': ""These should have been `Double` that's a mistake on my part, good catch."", 'commenter': 'tanclary'}]"
3234,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6114,35 +6114,62 @@ private static void checkIf(SqlOperatorFixture f) {
   @Test void testSafeMultiplyFunc() {
     final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.SAFE_MULTIPLY);
     f0.checkFails(""^safe_multiply(2, 3)^"",
-        ""No match found for function signature SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"",
-        false);
+        ""No match found for function signature ""
+        + ""SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"", false);
     final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
-    // check multiplication with no over/underflow has correct result and result type
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3 as int))"",
-        ""6"", ""INTEGER"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.5 as double))"",
-        ""7.0"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.456 as float))"",
-        ""6.912"", ""FLOAT"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DECIMAL(14, 3)"");
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.5 as double))"",
-        ""7.0"", ""DOUBLE"");
-    // DOUBLE and FLOAT in Calcite maps to BigQuery ""FLOAT64"", so returning DOUBLE is okay here
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.456 as float))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as float), cast(3.456 as float))"",
-        ""6.912"", ""FLOAT"");
-    f.checkScalar(""safe_multiply(cast(2 as float), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(3.4 as decimal(4,3)), cast(3.456 as decimal(4,3)))"",
-        ""11.7504"", ""DECIMAL(8, 6)"");
-    // check overflow returns null
-    f.checkNull(""safe_multiply(cast("" + Integer.MAX_VALUE + "" as int), 3)"");
-    f.checkNull(""safe_multiply(cast("" + Double.MAX_VALUE + "" as double), 3)"");
-    f.checkNull(""safe_multiply(9223372036854775807, 3)"");
+    // Basic test for each of the 9 2-permutations of BIGINT, DECIMAL, and FLOAT
+    f.checkScalar(""safe_multiply(cast(20 as bigint), cast(20 as bigint))"",
+                  ""400"", ""BIGINT"");
+    f.checkScalar(""safe_multiply(cast(20 as bigint), cast(1.2345 as decimal(5,4)))"",
+                  ""24.6900"", ""DECIMAL(19, 4)"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5,4)), cast(20 as bigint))"",
+                  ""24.6900"", ""DECIMAL(19, 4)"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5,4)), ""
+                          + ""cast(2.0 as decimal(2, 1)))"", ""2.46900"",
+                  ""DECIMAL(7, 5)"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(3 as bigint))"",
+                  ""9.0"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast(3 as bigint), cast(3 as float))"",
+                  ""9.0"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(1.2345 as decimal(5, 4)))"",
+                  ""3.7035"", ""DOUBLE"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5, 4)), cast(3 as float))"",
+                  ""3.7035"", ""DOUBLE"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(3 as float))"",
+                  ""9.0"", ""FLOAT"");
+    // Tests for + and - Infinity 
+    f.checkScalar(""safe_multiply(cast('Infinity' as float), cast(3 as float))"", 
+                  ""Infinity"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast('-Infinity' as float), cast(3 as float))"", 
+                  ""-Infinity"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast('-Infinity' as float), cast('Infinity' as float))"", 
+                  ""-Infinity"", ""FLOAT"");  
+    // Overflow test for each pairing
+    f.checkNull(""safe_multiply(cast(20 as bigint), ""
+                        + ""cast(9223372036854775807 as bigint))"");
+    f.checkNull(""safe_multiply(cast(20 as bigint), ""
+                        + ""cast(-9223372036854775807 as bigint))"");
+    f.checkNull(""safe_multiply(cast(10 as bigint), cast(3.5e75 as DECIMAL(76, 0)))"");
+    f.checkNull(""safe_multiply(cast(10 as bigint), cast(-3.5e75 as DECIMAL(76, 0)))"");
+    f.checkNull(""safe_multiply(cast(3.5e75 as DECIMAL(76, 0)), cast(10 as bigint))"");
+    f.checkNull(""safe_multiply(cast(-3.5e75 as DECIMAL(76, 0)), cast(10 as bigint))"");
+    f.checkNull(""safe_multiply(cast(3.5e75 as DECIMAL(76, 0)), ""
+                        + ""cast(1.5 as DECIMAL(2, 1)))"");
+    f.checkNull(""safe_multiply(cast(-3.5e75 as DECIMAL(76, 0)), ""
+                        + ""cast(1.5 as DECIMAL(2, 1)))"");
+    f.checkNull(""safe_multiply(cast(1.7e308 as float), cast(1.234 as decimal(4, 3)))"");
+    f.checkNull(""safe_multiply(cast(-1.7e308 as float), cast(1.234 as decimal(4, 3)))"");
+    f.checkNull(""safe_multiply(cast(1.234 as decimal(4, 3)), cast(1.7e308 as float))"");
+    f.checkNull(""safe_multiply(cast(1.234 as decimal(4, 3)), cast(-1.7e308 as float))"");
+    f.checkNull(""safe_multiply(cast(1.7e308 as float), cast(3 as bigint))"");
+    f.checkNull(""safe_multiply(cast(-1.7e308 as float), cast(3 as bigint))"");
+    f.checkNull(""safe_multiply(cast(3 as bigint), cast(1.7e308 as float))"");
+    f.checkNull(""safe_multiply(cast(3 as bigint), cast(-1.7e308 as float))"");
+    f.checkNull(""safe_multiply(cast(3 as float), cast(1.7e308 as float))"");
+    f.checkNull(""safe_multiply(cast(3 as float), cast(-1.7e308 as float))"");
+    // Check that null argument retuns null
+    f.checkNull(""safe_multiply(cast(null as float), cast(3 as bigint))"");
+    f.checkNull(""safe_multiply(cast(3 as float), cast(null as bigint))"");
   }","[{'comment': 'add blank line after `}`', 'commenter': 'julianhyde'}]"
3234,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6114,35 +6114,62 @@ private static void checkIf(SqlOperatorFixture f) {
   @Test void testSafeMultiplyFunc() {
     final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.SAFE_MULTIPLY);
     f0.checkFails(""^safe_multiply(2, 3)^"",
-        ""No match found for function signature SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"",
-        false);
+        ""No match found for function signature ""
+        + ""SAFE_MULTIPLY\\(<NUMERIC>, <NUMERIC>\\)"", false);
     final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
-    // check multiplication with no over/underflow has correct result and result type
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3 as int))"",
-        ""6"", ""INTEGER"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.5 as double))"",
-        ""7.0"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.456 as float))"",
-        ""6.912"", ""FLOAT"");
-    f.checkScalar(""safe_multiply(cast(2 as int), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DECIMAL(14, 3)"");
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.5 as double))"",
-        ""7.0"", ""DOUBLE"");
-    // DOUBLE and FLOAT in Calcite maps to BigQuery ""FLOAT64"", so returning DOUBLE is okay here
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.456 as float))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as double), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(2 as float), cast(3.456 as float))"",
-        ""6.912"", ""FLOAT"");
-    f.checkScalar(""safe_multiply(cast(2 as float), cast(3.456 as decimal(4, 3)))"",
-        ""6.912"", ""DOUBLE"");
-    f.checkScalar(""safe_multiply(cast(3.4 as decimal(4,3)), cast(3.456 as decimal(4,3)))"",
-        ""11.7504"", ""DECIMAL(8, 6)"");
-    // check overflow returns null
-    f.checkNull(""safe_multiply(cast("" + Integer.MAX_VALUE + "" as int), 3)"");
-    f.checkNull(""safe_multiply(cast("" + Double.MAX_VALUE + "" as double), 3)"");
-    f.checkNull(""safe_multiply(9223372036854775807, 3)"");
+    // Basic test for each of the 9 2-permutations of BIGINT, DECIMAL, and FLOAT
+    f.checkScalar(""safe_multiply(cast(20 as bigint), cast(20 as bigint))"",
+                  ""400"", ""BIGINT"");
+    f.checkScalar(""safe_multiply(cast(20 as bigint), cast(1.2345 as decimal(5,4)))"",
+                  ""24.6900"", ""DECIMAL(19, 4)"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5,4)), cast(20 as bigint))"",
+                  ""24.6900"", ""DECIMAL(19, 4)"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5,4)), ""
+                          + ""cast(2.0 as decimal(2, 1)))"", ""2.46900"",
+                  ""DECIMAL(7, 5)"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(3 as bigint))"",
+                  ""9.0"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast(3 as bigint), cast(3 as float))"",
+                  ""9.0"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(1.2345 as decimal(5, 4)))"",
+                  ""3.7035"", ""DOUBLE"");
+    f.checkScalar(""safe_multiply(cast(1.2345 as decimal(5, 4)), cast(3 as float))"",
+                  ""3.7035"", ""DOUBLE"");
+    f.checkScalar(""safe_multiply(cast(3 as float), cast(3 as float))"",
+                  ""9.0"", ""FLOAT"");
+    // Tests for + and - Infinity 
+    f.checkScalar(""safe_multiply(cast('Infinity' as float), cast(3 as float))"", 
+                  ""Infinity"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast('-Infinity' as float), cast(3 as float))"", 
+                  ""-Infinity"", ""FLOAT"");
+    f.checkScalar(""safe_multiply(cast('-Infinity' as float), cast('Infinity' as float))"", 
+                  ""-Infinity"", ""FLOAT"");  
+    // Overflow test for each pairing
+    f.checkNull(""safe_multiply(cast(20 as bigint), ""
+                        + ""cast(9223372036854775807 as bigint))"");
+    f.checkNull(""safe_multiply(cast(20 as bigint), ""
+                        + ""cast(-9223372036854775807 as bigint))"");
+    f.checkNull(""safe_multiply(cast(10 as bigint), cast(3.5e75 as DECIMAL(76, 0)))"");
+    f.checkNull(""safe_multiply(cast(10 as bigint), cast(-3.5e75 as DECIMAL(76, 0)))"");
+    f.checkNull(""safe_multiply(cast(3.5e75 as DECIMAL(76, 0)), cast(10 as bigint))"");
+    f.checkNull(""safe_multiply(cast(-3.5e75 as DECIMAL(76, 0)), cast(10 as bigint))"");
+    f.checkNull(""safe_multiply(cast(3.5e75 as DECIMAL(76, 0)), ""
+                        + ""cast(1.5 as DECIMAL(2, 1)))"");
+    f.checkNull(""safe_multiply(cast(-3.5e75 as DECIMAL(76, 0)), ""","[{'comment': 'indent `+ ""cast(1.5 as DECIMAL(2, 1)))"");` only 4 spaces', 'commenter': 'julianhyde'}]"
3234,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1524,136 +1524,89 @@ public static int multiply(int b0, int b1) {
     throw notArithmetic(""*"", b0, b1);
   }
 
-  /** Helper method for safe arithmetic functions that checks if overflow has occurred. */
-  private static boolean isOverflow(BigDecimal ans, BigDecimal min, BigDecimal max) {
-    return ans.compareTo(min) > 0 || ans.compareTo(max) < 0;
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer values. */
-  public static @Nullable Integer safeMultiply(int b0, int b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow = isOverflow(ans, BigDecimal.valueOf(Integer.MAX_VALUE), BigDecimal.valueOf(Integer.MIN_VALUE));
-    return overflow ? null : ans.intValue();
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer and double values. */
-  public static @Nullable Double safeMultiply(int b0, double b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Double.MAX_VALUE), BigDecimal.valueOf(-Double.MAX_VALUE));
-    return overflow ? null : ans.doubleValue();
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer and BigDecimal values. */
-  public static @Nullable BigDecimal safeMultiply(int b0, BigDecimal b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), b1);
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to integer and long values. */
-  public static @Nullable Long safeMultiply(int b0, long b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
-    return overflow ? null : ans.longValue();
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and integer values. */
-  public static @Nullable Double safeMultiply(double b0, int b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Double.MAX_VALUE), BigDecimal.valueOf(-Double.MAX_VALUE));
-    return overflow ? null : ans.doubleValue();
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to double values. */
-  public static @Nullable Double safeMultiply(double b0, double b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Double.MAX_VALUE), BigDecimal.valueOf(-Double.MAX_VALUE));
-    return overflow ? null : ans.doubleValue();
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and BigDecimal values. */
-  public static @Nullable BigDecimal safeMultiply(double b0, BigDecimal b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), b1);
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
-  }
-
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and long values. */
-  public static @Nullable Long safeMultiply(double b0, long b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
-    return overflow ? null : ans.longValue();
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to long values. */
+  public static @Nullable Long safeMultiply(long b0, long b1) {
+    try {
+      return Math.multiplyExact(b0, b1);
+    } catch (ArithmeticException e) {
+      return null;
+    }
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and integer values. */
-  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, int b1) {
-    BigDecimal ans = multiply(b0, BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and BigDecimal values. */
+  public static @Nullable BigDecimal safeMultiply(long b0, BigDecimal b1) {
+    BigDecimal ans = BigDecimal.valueOf(b0).multiply(b1);
+    return decimalOverflow(ans) ? ans : null;
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and double values. */
-  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, double b1) {
-    BigDecimal ans = multiply(b0, BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and long values. */
+  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, long b1) {
+    BigDecimal ans = b0.multiply(BigDecimal.valueOf(b1));
+    return decimalOverflow(ans) ? ans : null;
   }
 
   /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal values. */
   public static @Nullable BigDecimal safeMultiply(BigDecimal b0, BigDecimal b1) {
-    BigDecimal ans = multiply(b0, b1);
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
+    BigDecimal ans = b0.multiply(b1);
+    return decimalOverflow(ans) ? ans : null;
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and long values. */
-  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, long b1) {
-    BigDecimal ans = multiply(b0, BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and long values. */
+  public static @Nullable Double safeMultiply(double b0, long b1) {
+    double ans = b0 * b1;
+    boolean isInfinite = Double.isInfinite(b0);
+    return doubleOverflow(ans) || isInfinite ? ans : null;
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and integer values. */
-  public static @Nullable Long safeMultiply(long b0, int b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
-    return overflow ? null : ans.longValue();
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and double values. */
+  public static @Nullable Double safeMultiply(long b0, double b1) {
+    double ans = b0 * b1;
+    boolean isInfinite = Double.isInfinite(b1);
+    return doubleOverflow(ans) || isInfinite ? ans : null;
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and double values. */
-  public static @Nullable Long safeMultiply(long b0, double b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
-    return overflow ? null : ans.longValue();
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and BigDecimal values. */
+  public static @Nullable Double safeMultiply(double b0, BigDecimal b1) {
+    double ans = b0 * b1.doubleValue();
+    boolean isInfinite = Double.isInfinite(b0);
+    return doubleOverflow(ans) || isInfinite ? ans : null;
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to long values. */
-  public static @Nullable Long safeMultiply(long b0, long b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), BigDecimal.valueOf(b1));
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Long.MAX_VALUE), BigDecimal.valueOf(Long.MIN_VALUE));
-    return overflow ? null : ans.longValue();
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and double values. */
+  public static @Nullable Double safeMultiply(BigDecimal b0, double b1) {
+    double ans = b0.doubleValue() * b1;
+    boolean isInfinite = Double.isInfinite(b1);
+    return doubleOverflow(ans) || isInfinite ? ans : null;
   }
 
-  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and BigDecimal values. */
-  public static @Nullable BigDecimal safeMultiply(long b0, BigDecimal b1) {
-    BigDecimal ans = multiply(BigDecimal.valueOf(b0), b1);
-    boolean overflow =
-        isOverflow(ans, BigDecimal.valueOf(Float.MAX_VALUE), BigDecimal.valueOf(-Float.MAX_VALUE));
-    return overflow ? null : ans;
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double values. */
+  public static @Nullable Double safeMultiply(double b0, double b1) {
+    double ans = b0 * b1;
+    boolean isInfinite = Double.isInfinite(b0) || Double.isInfinite(b1);
+    return doubleOverflow(ans) || isInfinite ? ans : null;
+  }
+
+  /** Helper for the safe arithmetic functions to determine
+   * overflow for a BigDecimal value. According to BigQuery, BigDecimal
+   * overflow occurs if the precision is greater than 76 or the precision
+   * is greater than 38. */","[{'comment': ""The implementation of this function would return true if b.scale is 2 and b.precision is 5. That doesn't seem right."", 'commenter': 'julianhyde'}, {'comment': 'The behavior is correct, the naming is just a bit confusing. I changed it to `safeDouble` and `safeDecimal` which return `TRUE` if there is not overflow and `FALSE` if there is. Let me know if you agree with this.', 'commenter': 'tanclary'}, {'comment': 'Is that sentence correct?\r\n`if the precision is greater than 76 or the precision is greater than 38.`\r\n\r\nShould one of them be scale?', 'commenter': 'olivrlee'}, {'comment': 'Oops, good catch. Fixed now.', 'commenter': 'tanclary'}]"
3234,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -2305,6 +2308,30 @@ private static class LastDayImplementor extends MethodNameImplementor {
     }
   }
 
+  /** Implementor for the {@code SAFE_MULTIPLY} function. */
+  private static class SafeArithmeticImplementor extends MethodNameImplementor {
+    SafeArithmeticImplementor() {
+      super(""safeMultiply"", NullPolicy.STRICT, false);
+    }
+
+    @Override Expression implementSafe(final RexToLixTranslator translator,
+        final RexCall call, final List<Expression> argValueList) {
+      Expression arg0 = toLong(argValueList.get(0), call.operands.get(0));
+      Expression arg1 = toLong(argValueList.get(1), call.operands.get(1));
+      return Expressions.call(SqlFunctions.class, ""safeMultiply"", arg0, arg1);
+    }
+
+    // Because BigQuery treats all int types as aliases for INT64 (Java's LONG)
+    // they can all be converted to LONG to minimize entries in the SqlFunctions class.
+    private Expression toLong(Expression arg, RexNode node) {","[{'comment': 'As we only convert arg to long as when it is int type, but return the origin `arg` for other cases, it would be better to use a more proper method name to describe what this method doas.', 'commenter': 'zoudan'}, {'comment': 'Good point. Changed to `convertType`, let me know if this works for you.', 'commenter': 'tanclary'}]"
3234,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1524,6 +1524,91 @@ public static int multiply(int b0, int b1) {
     throw notArithmetic(""*"", b0, b1);
   }
 
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to long values. */
+  public static @Nullable Long safeMultiply(long b0, long b1) {
+    try {
+      return Math.multiplyExact(b0, b1);
+    } catch (ArithmeticException e) {
+      return null;
+    }
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and BigDecimal values. */
+  public static @Nullable BigDecimal safeMultiply(long b0, BigDecimal b1) {
+    BigDecimal ans = BigDecimal.valueOf(b0).multiply(b1);
+    return safeDecimal(ans) ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and long values. */
+  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, long b1) {
+    BigDecimal ans = b0.multiply(BigDecimal.valueOf(b1));
+    return safeDecimal(ans) ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal values. */
+  public static @Nullable BigDecimal safeMultiply(BigDecimal b0, BigDecimal b1) {
+    BigDecimal ans = b0.multiply(b1);
+    return safeDecimal(ans) ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and long values. */
+  public static @Nullable Double safeMultiply(double b0, long b1) {
+    double ans = b0 * b1;
+    boolean isInfinite = Double.isInfinite(b0);
+    return safeDecimal(ans) || isInfinite ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to long and double values. */
+  public static @Nullable Double safeMultiply(long b0, double b1) {
+    double ans = b0 * b1;
+    boolean isInfinite = Double.isInfinite(b1);
+    return safeDecimal(ans) || isInfinite ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double and BigDecimal values. */
+  public static @Nullable Double safeMultiply(double b0, BigDecimal b1) {
+    double ans = b0 * b1.doubleValue();
+    boolean isInfinite = Double.isInfinite(b0);
+    return safeDecimal(ans) || isInfinite ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to BigDecimal and double values. */
+  public static @Nullable Double safeMultiply(BigDecimal b0, double b1) {
+    double ans = b0.doubleValue() * b1;
+    boolean isInfinite = Double.isInfinite(b1);
+    return safeDecimal(ans) || isInfinite ? ans : null;
+  }
+
+  /** SQL <code>SAFE_MULTIPLY</code> function applied to double values. */
+  public static @Nullable Double safeMultiply(double b0, double b1) {
+    double ans = b0 * b1;
+    boolean isInfinite = Double.isInfinite(b0) || Double.isInfinite(b1);
+    return safeDecimal(ans) || isInfinite ? ans : null;
+  }
+
+  /** Helper for the safe arithmetic functions to determine
+   * overflow for a BigDecimal value. According to BigQuery, BigDecimal
+   * overflow occurs if the precision is greater than 76 or the precision
+   * is greater than 38. */
+  private static boolean safeDecimal(BigDecimal b) {
+    return b.scale() <= 38 && b.precision() <= 76;
+  }
+
+  /** Helper for the safe arithmetic functions to determine
+   * overflow for a double. */
+  private static boolean safeDecimal(double d) {","[{'comment': 'It would be better to use `safeDouble` here?', 'commenter': 'zoudan'}, {'comment': 'Good call. Done.', 'commenter': 'tanclary'}]"
3234,babel/src/test/resources/sql/big-query.iq,"@@ -600,6 +600,44 @@ FROM t;
 !ok
 !}
 
+#####################################################################
+# SAFE_MULTIPLY
+#
+# SAFE_MULTIPLY(value1, value2)
+#
+# Equivalent to the mulitply operator (*), but returns NULL if overflow/underflow occurs.
+SELECT SAFE_MULTIPLY(5, 4) as result;
++--------+
+| result |
++--------+
+|     20 |
++--------+
+(1 row)
+
+!ok
+
+#Overflow occurs if result is greater than 2^63 - 1
+SELECT SAFE_MULTIPLY(9223372036854775807, 2) as overflow_result;
++-----------------+
+| overflow_result |
++-----------------+
+|                 |
++-----------------+
+(1 row)
+
+!ok
+
+#Underflow occurs if result is less than -2^63
+SELECT SAFE_MULTIPLY(-9223372036854775806, 3) as underflow_result;
++------------------+
+| underflow_result |
++------------------+
+|                  |
++------------------+
+(1 row)
+
+!ok
+","[{'comment': 'should we add overflow cases for decimal and double?', 'commenter': 'zoudan'}, {'comment': 'Done.', 'commenter': 'tanclary'}]"
3245,core/src/main/java/org/apache/calcite/sql/dialect/BigQuerySqlDialect.java,"@@ -149,6 +149,16 @@ public BigQuerySqlDialect(SqlDialect.Context context) {
   @Override public void unparseCall(final SqlWriter writer, final SqlCall call, final int leftPrec,
       final int rightPrec) {
     switch (call.getKind()) {
+    case CEIL_BIG_QUERY:
+      final SqlWriter.Frame ceilFrame = writer.startFunCall(""CEIL"");
+      call.operand(0).unparse(writer, leftPrec, rightPrec);
+      writer.endFunCall(ceilFrame);
+      break;
+    case FLOOR_BIG_QUERY:","[{'comment': 'Can the unparse logic be pushed to the operator itself? Otherwise I think each dialect will have to override the `BIG_QUERY` style function calls (e.g. BQ incoming query targeting a Postgres backend).', 'commenter': 'tjbanghart'}]"
3245,core/src/main/java/org/apache/calcite/sql/fun/SqlFloorFunction.java,"@@ -41,22 +45,23 @@
 public class SqlFloorFunction extends SqlMonotonicUnaryFunction {
   //~ Constructors -----------------------------------------------------------
 
-  public SqlFloorFunction(SqlKind kind) {
-    super(kind.name(), kind, ReturnTypes.ARG0_OR_EXACT_NO_SCALE, null,
+  public SqlFloorFunction(SqlKind kind, SqlReturnTypeInference returnTypeInference) {
+    super(kind.name(), kind, returnTypeInference, null,
         OperandTypes.NUMERIC_OR_INTERVAL.or(
             OperandTypes.sequence(""'"" + kind + ""(<DATE> TO <TIME_UNIT>)'\n""
                     + ""'"" + kind + ""(<TIME> TO <TIME_UNIT>)'\n""
                     + ""'"" + kind + ""(<TIMESTAMP> TO <TIME_UNIT>)'"",
                 OperandTypes.DATETIME,
                 OperandTypes.ANY)),
         SqlFunctionCategory.NUMERIC);
-    Preconditions.checkArgument(kind == SqlKind.FLOOR || kind == SqlKind.CEIL);
+    Preconditions.checkArgument(kind == SqlKind.FLOOR || kind == SqlKind.CEIL
+        || kind == SqlKind.FLOOR_BIG_QUERY || kind == SqlKind.CEIL_BIG_QUERY);
   }
 
   //~ Methods ----------------------------------------------------------------
 
   @Override public SqlMonotonicity getMonotonicity(SqlOperatorBinding call) {
-    // Monotonic iff its first argument is, but not strict.
+    // Monotonic if its first argument is, but not strict.","[{'comment': 'Might be intentional for ""if and only if""', 'commenter': 'tjbanghart'}, {'comment': 'Whoops.', 'commenter': 'tanclary'}, {'comment': 'yes it was intentional.\r\n\r\nWhen podcasters say ""If you liked this episode, leave a review on Apple Music"" I\'m always jumping up and down, ""You mean if and only if!""', 'commenter': 'julianhyde'}]"
3245,core/src/main/java/org/apache/calcite/sql/fun/SqlFloorFunction.java,"@@ -41,22 +45,23 @@
 public class SqlFloorFunction extends SqlMonotonicUnaryFunction {
   //~ Constructors -----------------------------------------------------------
 
-  public SqlFloorFunction(SqlKind kind) {
-    super(kind.name(), kind, ReturnTypes.ARG0_OR_EXACT_NO_SCALE, null,
+  public SqlFloorFunction(SqlKind kind, SqlReturnTypeInference returnTypeInference) {
+    super(kind.name(), kind, returnTypeInference, null,
         OperandTypes.NUMERIC_OR_INTERVAL.or(
             OperandTypes.sequence(""'"" + kind + ""(<DATE> TO <TIME_UNIT>)'\n""
                     + ""'"" + kind + ""(<TIME> TO <TIME_UNIT>)'\n""
                     + ""'"" + kind + ""(<TIMESTAMP> TO <TIME_UNIT>)'"",
                 OperandTypes.DATETIME,
                 OperandTypes.ANY)),
         SqlFunctionCategory.NUMERIC);
-    Preconditions.checkArgument(kind == SqlKind.FLOOR || kind == SqlKind.CEIL);
+    Preconditions.checkArgument(kind == SqlKind.FLOOR || kind == SqlKind.CEIL
+        || kind == SqlKind.FLOOR_BIG_QUERY || kind == SqlKind.CEIL_BIG_QUERY);
   }
 
   //~ Methods ----------------------------------------------------------------
 
   @Override public SqlMonotonicity getMonotonicity(SqlOperatorBinding call) {
-    // Monotonic iff its first argument is, but not strict.
+    // Monotonic if its first argument is, but not strict.
     return call.getOperandMonotonicity(0).unstrict();
   }
 ","[{'comment': 'Consider moving the unparsing logic for the BQ style functions here.', 'commenter': 'tjbanghart'}]"
3245,core/src/main/codegen/templates/Parser.jj,"@@ -7335,9 +7336,13 @@ SqlNode StandardFloorCeilOptions(Span s, boolean floorFlag) :
         }
     )?
     <RPAREN> {
-        SqlOperator op = floorFlag
-            ? SqlStdOperatorTable.FLOOR
-            : SqlStdOperatorTable.CEIL;
+        SqlOperator op;
+        boolean isBigQuery = this.conformance.semantics() == SqlLibrary.BIG_QUERY;","[{'comment': 'look at way to make more scaleable', 'commenter': 'tanclary'}, {'comment': 'can you create a function in SqlStdOperatorTable similar to `SqlStdOperatorTable.like(boolean,boolean)`? Its args should be boolean and conformance.', 'commenter': 'julianhyde'}, {'comment': ""What does the boolean argument represent in this case? Whether you want it to be like/unlike the conformance you pass in?\r\n\r\nOr do you mean you pass two conformances in (the one being used and the one you're checking against) and you return `BOOLEAN` (whether they are the same or not)?"", 'commenter': 'tanclary'}]"
3245,core/src/main/java/org/apache/calcite/sql/fun/SqlStdOperatorTable.java,"@@ -1853,12 +1853,14 @@ public class SqlStdOperatorTable extends ReflectiveSqlOperatorTable {
   /**
    * The <code>FLOOR</code> function.
    */
-  public static final SqlFunction FLOOR = new SqlFloorFunction(SqlKind.FLOOR);
+  public static final SqlFunction FLOOR =
+      new SqlFloorFunction(SqlKind.FLOOR, ReturnTypes.ARG0_OR_EXACT_NO_SCALE);","[{'comment': ""I would keep the same constructor, and add methods `withName`, `withReturnTypeInference`. (We have discovered that for functions/operators, subclassing doesn't scale, and adding constructor parameters doesn't scale.)"", 'commenter': 'julianhyde'}]"
3245,site/_docs/reference.md,"@@ -2661,6 +2661,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | s | ARRAY_SIZE(array)                              | Synonym for `CARDINALITY`
 | * | ASINH(numeric)                                 | Returns the inverse hyperbolic sine of *numeric*
 | * | ATANH(numeric)                                 | Returns the inverse hyperbolic tangent of *numeric*
+| b | CEIL(value)                                   | Similar to standard `CEIL(value)` except if *value* is an integer type, the return type is a double","[{'comment': 'add space before `|`', 'commenter': 'julianhyde'}]"
3253,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -2385,16 +2385,24 @@ private static class FloorImplementor extends MethodNameImplementor {
         case MONTH:
         case WEEK:
         case DAY:
+        case DECADE:
+        case CENTURY:
+        case MILLENNIUM:
           final Expression dayOperand0 =
               preFloor ? call(operand0, type, TimeUnit.DAY) : operand0;
           return Expressions.call(floorMethod,
               translator.getLiteral(operand1), dayOperand0);
         default:
+          if (call.op.getName().equals(""DATE_TRUNC"")) {","[{'comment': 'Why this behavior for `DATE_TRUNC` and not other functions? (e.g. `TIMESTAMP_TRUNC`, `DATETIME_TRUNC`)\r\n\r\nIs it possible to add a test for this behavior?\r\n\r\nProbably good to add `SqlKind.DATE_TRUNC`. Switching on function name is not maintainable.\r\n', 'commenter': 'julianhyde'}, {'comment': ""I haven't tested yet the behavior of TIMESTAMP functions.\r\nThis is strictly addressing CALCITE-5761.\r\nIt is possible that the timestamp functions have problems too.\r\nAre you suggesting to add SqlKind.DATE_TRUNC in this PR, or should I file an issue for that?"", 'commenter': 'mihaibudiu'}, {'comment': ""> I haven't tested yet the behavior of TIMESTAMP functions.\r\n\r\nThe other functions seem so closely related, it's strange to not do them.\r\n\r\n> Are you suggesting to add SqlKind.DATE_TRUNC in this PR, or should I file an issue for that?\r\n\r\nYes, add SqlKind.DATE_TRUNC in this PR. Clean up tech debt as you create it. (Not that I'm criticizing you... the DATE_TRUNC function didn't need its own SqlKind previously, so adding one would be over-engineering, but now it does.)"", 'commenter': 'julianhyde'}]"
3253,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -9641,6 +9641,12 @@ void testTimestampDiff(boolean coercionEnabled) {
         ""2015-01-01"", ""DATE NOT NULL"");
     f.checkScalar(""date_trunc(date '2015-02-19', isoyear)"",
         ""2014-12-29"", ""DATE NOT NULL"");
+    f.checkScalar(""date_trunc(date '2015-02-19', decade)"",","[{'comment': 'Add a comment that DECADE rolls down to 0 mod 10, CENTURY and MILLENNIUM roll down to 1 mod 100 and 1 mod 1000. That behavior is surprising to some people.', 'commenter': 'julianhyde'}]"
3257,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -1768,6 +1768,68 @@ private void checkExponentialCnf(int n) {
     checkSimplify(expr, simplified);
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5759"">[CALCITE-5759]
+   * SEARCH operator with special sarg is not fully simplified</a>. */
+  @Test void testSimplifySearchWithSpecialSargIsNotNull() {
+    RexNode intExpression =","[{'comment': 'How about name it `intLiteral`?', 'commenter': 'libenchao'}, {'comment': 'I will refine it.', 'commenter': 'herunkang2018'}]"
3267,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -1604,6 +1604,48 @@ private void checkExponentialCnf(int n) {
         ""true"");
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5780"">[CALCITE-5780]
+   * Always-true OR expressions contain reverse order comparison
+   * should be simplified to TRUE</a>. */
+  @Test void testSimplifyOrTermsWithReverseOrderComparison() {
+    final RelDataType intType = typeFactory.createSqlType(SqlTypeName.INTEGER);
+    final RelDataType rowType = typeFactory.builder()
+        .add(""a"", intType).nullable(true)
+        .build();
+
+    final RexDynamicParam range = rexBuilder.makeDynamicParam(rowType, 0);
+    final RexNode aRef = rexBuilder.makeFieldAccess(range, 0);
+
+    // ""1 > a or 1 <= a or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(gt(literal(1), aRef),
+            le(literal(1), aRef),
+            isNull(aRef)),
+        ""true"");
+
+    // ""1 <= a or 1 > a or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(le(literal(1), aRef),
+            gt(literal(1), aRef),
+            isNull(aRef)),
+        ""true"");
+
+    // ""a is null 1 > a or 1 <= a"" ==> ""true""","[{'comment': 'Should be `""a is null or 1 > a or 1 <= a"" ==> ""true""`', 'commenter': 'NobiGo'}, {'comment': 'I will fix it.', 'commenter': 'herunkang2018'}]"
3267,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -1604,6 +1604,48 @@ private void checkExponentialCnf(int n) {
         ""true"");
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5780"">[CALCITE-5780]
+   * Always-true OR expressions contain reverse order comparison
+   * should be simplified to TRUE</a>. */
+  @Test void testSimplifyOrTermsWithReverseOrderComparison() {
+    final RelDataType intType = typeFactory.createSqlType(SqlTypeName.INTEGER);
+    final RelDataType rowType = typeFactory.builder()","[{'comment': 'According to the code change, Maybe `a is not null` should be covered too.', 'commenter': 'NobiGo'}, {'comment': ""@NobiGo IMO, `a is not null` is not releated to the issue we want to solve here, unlike `a is null`, `1 < a or 1 >= a or a is not null` will return UNKNOWN when a's type is nullable and a's value is null, return TRUE when a'type is not nullable."", 'commenter': 'herunkang2018'}]"
3267,core/src/main/java/org/apache/calcite/plan/RelOptPredicateList.java,"@@ -236,14 +236,18 @@ public boolean isEffectivelyNotNull(RexNode e) {
       }
     }
     if (SqlKind.COMPARISON.contains(e.getKind())) {
-      // A comparison with a (non-null) literal, such as 'ref < 10', is not null if 'ref'
-      // is not null.
+      // A comparison with a (non-null) literal, such as 'ref < 10', or '10 < ref',
+      // is not null if 'ref' is not null.
       List<RexNode> operands = ((RexCall) e).getOperands();
       // We can have just one operand in case e.g. of a RexSubQuery with IN operator.
       if (operands.size() > 1 && operands.get(1) instanceof RexLiteral
           && !((RexLiteral) operands.get(1)).isNull()) {
         return isEffectivelyNotNull(operands.get(0));
       }
+      if (operands.size() > 1 && operands.get(0) instanceof RexLiteral","[{'comment': ""@NobiGo this is to improve the `isEffectivelyNotNull` logic for `10 < ref` when pulled up predicates contain `ref is not null`, then `10 < ref`'s `isEffectivelyNotNull` will be `true`. This is useful to simplify the nested `RexNode`, like `is not true(10 < ref)`, and it will be simplified to `10 >= ref` which is more concise and useful for further simplification in this Jira.\r\n\r\nBesides, another reasonable way is to split this part of code to another Jira, and it will be more clear why make these changes. @NobiGo What do you think?"", 'commenter': 'herunkang2018'}]"
3267,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -1887,11 +1887,10 @@ private static <C extends Comparable<C>> RangeSet<C> residue(RexNode ref,
       case GREATER_THAN:
       case GREATER_THAN_OR_EQUAL:
         final RexCall call = (RexCall) predicate;
-        if (call.operands.get(0).equals(ref)
-            && call.operands.get(1) instanceof RexLiteral) {
-          final RexLiteral literal = (RexLiteral) call.operands.get(1);
-          final C c1 = literal.getValueAs(clazz);
-          assert c1 != null : ""value must not be null in "" + literal;
+        final Comparison comparison = Comparison.of(call);","[{'comment': 'We change here because previous logic only checks `ref > 1`, not `1 < ref`, we use `Comparison` to refine this part of code, and support the reverse order comparison.', 'commenter': 'herunkang2018'}]"
3267,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -1604,6 +1604,68 @@ private void checkExponentialCnf(int n) {
         ""true"");
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5780"">[CALCITE-5780]
+   * Simplify '1 > x OR 1 <= x OR x IS NULL' to TRUE</a>. */
+  @Test void testSimplifyOrTermsWithReverseOrderComparison() {
+    final RelDataType intType = typeFactory.createSqlType(SqlTypeName.INTEGER);
+    final RelDataType rowType = typeFactory.builder()
+        .add(""a"", intType).nullable(true)
+        .build();
+
+    final RexDynamicParam range = rexBuilder.makeDynamicParam(rowType, 0);
+    final RexNode aRef = rexBuilder.makeFieldAccess(range, 0);
+
+    // ""1 > a or 1 <= a or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(gt(literal(1), aRef),
+            le(literal(1), aRef),
+            isNull(aRef)),
+        ""true"");
+
+    // ""1 <= a or 1 > a or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(le(literal(1), aRef),
+            gt(literal(1), aRef),
+            isNull(aRef)),
+        ""true"");
+
+    // ""a is null or 1 > a or 1 <= a"" ==> ""true""
+    checkSimplifyFilter(
+        or(isNull(aRef),
+            gt(literal(1), aRef),
+            le(literal(1), aRef)),
+        ""true"");
+
+    // ""2 > a or 0 < a or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(gt(literal(2), aRef),
+            lt(literal(0), aRef),
+            isNull(aRef)),
+        ""true"");
+
+    // ""1 > a or a >= 1 or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(gt(literal(1), aRef),
+            ge(aRef, literal(1)),
+            isNull(aRef)),
+        ""true"");
+
+    // ""1 <= a or a < 1 or a is null"" ==> ""true""
+    checkSimplifyFilter(
+        or(le(literal(1), aRef),
+            lt(aRef, literal(1)),
+            isNull(aRef)),
+        ""true"");
+
+    // ""a >= 1 or 1 > a or a is null"" ==> ""true""","[{'comment': 'Note that this test case is not effected by this issue, it can be simplified to true before. I add it just for better code coverage.', 'commenter': 'herunkang2018'}]"
3279,core/src/main/java/org/apache/calcite/plan/RelOptPredicateList.java,"@@ -236,14 +236,18 @@ public boolean isEffectivelyNotNull(RexNode e) {
       }
     }
     if (SqlKind.COMPARISON.contains(e.getKind())) {
-      // A comparison with a (non-null) literal, such as 'ref < 10', is not null if 'ref'
-      // is not null.
+      // A comparison with a (non-null) literal, such as 'ref < 10', or '10 < ref',
+      // is not null if 'ref' is not null.
       List<RexNode> operands = ((RexCall) e).getOperands();
       // We can have just one operand in case e.g. of a RexSubQuery with IN operator.
       if (operands.size() > 1 && operands.get(1) instanceof RexLiteral
           && !((RexLiteral) operands.get(1)).isNull()) {
         return isEffectivelyNotNull(operands.get(0));
       }
+      if (operands.size() > 1 && operands.get(0) instanceof RexLiteral
+          && !((RexLiteral) operands.get(0)).isNull()) {
+        return isEffectivelyNotNull(operands.get(1));
+      }","[{'comment': 'I wonder if it would make sense to instead of this:\r\n\r\n* push those `RexLiteral` related stuff as part of `isEffectivelyNotNull` somewhere at the beginning\r\n* replace this block with something like:\r\n```\r\nfor(int i=0;i<operands.size();i++) {\r\n  if(!isEffectivelyNotNull(operands.get(0)) {\r\n    return false;\r\n  }\r\n}\r\nreturn true;\r\n```\r\nso that it will handle `x > y is not true` ; in case `x` and `y` is known to be not null', 'commenter': 'kgyrtkirk'}, {'comment': '@kgyrtkirk Thanks for your advice. The refactor logic is more genaral, to covers more case like `x < y is not true`. I will refactor it soon.', 'commenter': 'herunkang2018'}, {'comment': ""For the first advice, the RexLiteral doesn't need to process seperately, it is covered by L229."", 'commenter': 'herunkang2018'}]"
3279,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2010,6 +2010,20 @@ private void checkExponentialCnf(int n) {
         "">(?0.int0, 0)"");
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5798"">[CALCITE-5798]
+   * '(1 < x) IS NOT TRUE' when x is not nullable should be simplified to '1 >= x'</a>. */
+  @Test void testSimplifyInverseComparisonWithIsNotNullPredicate() {
+    final RexNode ref = input(tInt(true), 0);
+    RelOptPredicateList relOptPredicateList =
+        RelOptPredicateList.of(rexBuilder,
+            ImmutableList.of(isNotNull(ref)));
+    checkSimplifyFilter(
+        isNotTrue(gt(literal(1), ref)),","[{'comment': ""Looks like the test is the opposite. The summary is '(1 < x) IS NOT TRUE-->1>=x' but the test is '(1>x) IS NOT TRUE-->1<=x'. The test result is good. Just I think we should stay the same logic."", 'commenter': 'NobiGo'}, {'comment': '@NobiGo Thanks for review, I will refine it soon.', 'commenter': 'herunkang2018'}]"
3279,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2010,6 +2010,57 @@ private void checkExponentialCnf(int n) {
         "">(?0.int0, 0)"");
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5798"">[CALCITE-5798]
+   * Improve simplification of '(x < y) IS NOT TRUE' and '(x < y) IS TRUE'
+   * when x and y are not nullable</a>. */
+  @Test void testSimplifyWithIsNotNullPredicate() {
+    final RexNode xRef = input(tInt(true), 0);
+    final RexNode yRef = input(tInt(true), 1);
+    RelOptPredicateList relOptPredicateList =
+        RelOptPredicateList.of(rexBuilder,
+            ImmutableList.of(isNotNull(xRef), isNotNull(yRef)));
+
+    // ""(x < y) IS TRUE"" (if x and y are both not nullable) => ""x < y""
+    checkSimplifyWithPredicates(
+        isTrue(lt(xRef, yRef)),
+        relOptPredicateList,
+        RexUnknownAs.UNKNOWN,
+        ""<($0, $1)"");
+
+    // ""(x < y) IS NOT TRUE"" (if x and y are both not nullable) => ""x >= y""
+    checkSimplifyFilter(
+        isNotTrue(lt(xRef, yRef)),
+        relOptPredicateList,
+        "">=($0, $1)"");
+
+    // ""(x < 1) IS TRUE"" (if x is not nullable) => ""x < 1""","[{'comment': 'These two test cases above are not related to this issue, they can be passed before. I add them for better code coverage.', 'commenter': 'herunkang2018'}]"
3296,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2458,6 +2458,63 @@ private SqlOperator getNoDeterministicOperator() {
     checkSimplifyUnchanged(isNull(cast(vVarcharNotNull(), tInt(false))));
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNull3() {
+    // ""(cast A as bigint) IS NULL"" when A is int and A is not null
+    // ==>
+    // ""false""
+    checkSimplify(isNull(cast(vIntNotNull(), tBigInt(false))), ""false"");
+    // ""(cast A as smallint) IS NULL"" when A is int and A is not null
+    // ==>
+    // ""(cast A as smallint) IS NULL""
+    checkSimplifyUnchanged(isNull(cast(vIntNotNull(), tSmallInt(false))));
+  }
+
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNull4() {
+    // ""(cast A as bigint) IS NULL"" when A is int and A is nullable
+    // ==>
+    // ""A IS NULL""
+    checkSimplify(isNull(cast(vInt(), tBigInt(true))), ""IS NULL(?0.int0)"");
+    // ""(cast A as smallint) IS NULL"" when A is int and A is nullable
+    // ==>
+    // ""(cast A as smallint) IS NULL""
+    checkSimplifyUnchanged(isNull(cast(vInt(), tSmallInt(true))));
+  }
+
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNotNull() {
+    // ""(cast A as bigint) IS NOT NULL"" when A is int and A is not null
+    // ==>
+    // ""true""
+    checkSimplify(isNotNull(cast(vIntNotNull(), tBigInt(false))), ""true"");
+    // ""(cast A as smallint) IS NOT NULL"" when A is int and A is not null
+    // ==>
+    // ""(cast A as smallint) IS NOT NULL""
+    checkSimplifyUnchanged(isNotNull(cast(vIntNotNull(), tSmallInt(false))));
+  }
+
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNotNull2() {
+    // ""(cast A as bigint) IS NOT NULL"" when A is int and A is nullable
+    // ==>
+    // ""A IS NOT NULL""
+    checkSimplify(isNotNull(cast(vInt(), tBigInt(true))), ""IS NOT NULL(?0.int0)"");","[{'comment': 'How about `cast(varchar as binary) is not null`?\r\n\r\n> More test between types is better.', 'commenter': 'JiajunBernoulli'}, {'comment': '@JiajunBernoulli I add this test. Now I use RexUtil.isLosslessCast to decide whether remove the cast in this expression. So now this implementation is secure and conservative(Because cast(varchar(8) as varchar(4)) actually can return value in SQL, But this Pr still keeps this cast. Only handle cast(varchar(4) as varchar(8))). About the type change test, we can find it in RexLosslessCastTest.  \r\n', 'commenter': 'NobiGo'}, {'comment': '@NobiGo  Thanks for your detailed explanation.\r\n\r\nI will approve if the CI success.', 'commenter': 'JiajunBernoulli'}]"
3296,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2458,6 +2458,79 @@ private SqlOperator getNoDeterministicOperator() {
     checkSimplifyUnchanged(isNull(cast(vVarcharNotNull(), tInt(false))));
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNull3() {
+    // ""(cast A as bigint) IS NULL"" when A is int and A is not null
+    // ==>
+    // ""false""
+    checkSimplify(isNull(cast(vIntNotNull(), tBigInt(false))), ""false"");
+    // ""(cast A as smallint) IS NULL"" when A is int and A is not null
+    // ==>
+    // ""(cast A as smallint) IS NULL""
+    checkSimplifyUnchanged(isNull(cast(vIntNotNull(), tSmallInt(false))));
+    // ""(cast A as varbinary) IS NULL"" when A is varchar and A is not null
+    // ==>
+    // ""(cast A as varbinary) IS NULL""
+    checkSimplifyUnchanged(isNotNull(cast(vVarcharNotNull(), tVarbinary(false))));
+  }
+
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNull4() {
+    // ""(cast A as bigint) IS NULL"" when A is int and A is nullable
+    // ==>
+    // ""A IS NULL""","[{'comment': 'Why we get `A IS NULL` instead of `true` here?', 'commenter': 'ILuffZhe'}, {'comment': 'Because A is nullable(Possible include NULL value). For example:\r\nWhen A is a 5, the expression value will be false. \r\nIf A is NULL, the expression value will be true.', 'commenter': 'NobiGo'}, {'comment': 'Thanks for your explanation.', 'commenter': 'ILuffZhe'}]"
3296,core/src/test/resources/sql/misc.iq,"@@ -2400,4 +2400,124 @@ TS
 1969-07-21 00:00:00
 !ok
 
+!use scott
+!set outputformat mysql
+
+# [CALCITE-5769] Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'
+
+# Test CAST(e as t) IS NOT NULL when CAST is lossless And e IS NOT NULL
+select cast(deptno as integer) IS NOT NULL from ""scott"".dept;
++--------+
+| EXPR$0 |
++--------+
+| true   |
+| true   |
+| true   |
+| true   |
++--------+
+(4 rows)
+
+!ok
+EnumerableCalc(expr#0..2=[{inputs}], expr#3=[true], EXPR$0=[$t3])
+  EnumerableTableScan(table=[[scott, DEPT]])
+!plan
+
+# Test CAST(e as t) IS NULL when CAST is lossless And e IS NOT NULL
+select cast(deptno as integer) IS NULL from ""scott"".dept;
++--------+
+| EXPR$0 |
++--------+
+| false  |
+| false  |
+| false  |
+| false  |
++--------+
+(4 rows)
+
+!ok
+EnumerableCalc(expr#0..2=[{inputs}], expr#3=[false], EXPR$0=[$t3])
+  EnumerableTableScan(table=[[scott, DEPT]])
+!plan
+
+# Test CAST(e as t) IS NOT NULL when CAST is lossless And e is nullable
+select cast(mgr as integer) IS NOT NULL from ""scott"".emp;
++--------+
+| EXPR$0 |
++--------+
+| false  |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
++--------+
+(14 rows)
+
+!ok
+EnumerableCalc(expr#0..7=[{inputs}], expr#8=[IS NOT NULL($t3)], EXPR$0=[$t8])
+  EnumerableTableScan(table=[[scott, EMP]])
+!plan
+
+# Test CAST(e as t) IS NULL when CAST is lossless And e is nullable
+select cast(mgr as integer) IS NULL from ""scott"".emp;
++--------+
+| EXPR$0 |
++--------+
+| false  |
+| true   |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
++--------+
+(14 rows)
+
+!ok
+EnumerableCalc(expr#0..7=[{inputs}], expr#8=[IS NULL($t3)], EXPR$0=[$t8])
+  EnumerableTableScan(table=[[scott, EMP]])
+!plan
+
+# Test CAST(e as t) IS NULL when CAST is not lossless And e is nullable
+select cast(comm as integer) IS NOT NULL from ""scott"".emp;","[{'comment': ""The test case doesn't fit the description, you want to test `IS NULL` or `IS NOT NULL`?"", 'commenter': 'ILuffZhe'}, {'comment': 'Nice catch. I will fix it.', 'commenter': 'NobiGo'}, {'comment': 'Done.', 'commenter': 'NobiGo'}]"
3296,core/src/test/resources/sql/misc.iq,"@@ -2400,4 +2400,124 @@ TS
 1969-07-21 00:00:00
 !ok
 
+!use scott
+!set outputformat mysql
+
+# [CALCITE-5769] Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'
+
+# Test CAST(e as t) IS NOT NULL when CAST is lossless And e IS NOT NULL
+select cast(deptno as integer) IS NOT NULL from ""scott"".dept;
++--------+
+| EXPR$0 |
++--------+
+| true   |
+| true   |
+| true   |
+| true   |
++--------+
+(4 rows)
+
+!ok
+EnumerableCalc(expr#0..2=[{inputs}], expr#3=[true], EXPR$0=[$t3])
+  EnumerableTableScan(table=[[scott, DEPT]])
+!plan
+
+# Test CAST(e as t) IS NULL when CAST is lossless And e IS NOT NULL
+select cast(deptno as integer) IS NULL from ""scott"".dept;
++--------+
+| EXPR$0 |
++--------+
+| false  |
+| false  |
+| false  |
+| false  |
++--------+
+(4 rows)
+
+!ok
+EnumerableCalc(expr#0..2=[{inputs}], expr#3=[false], EXPR$0=[$t3])
+  EnumerableTableScan(table=[[scott, DEPT]])
+!plan
+
+# Test CAST(e as t) IS NOT NULL when CAST is lossless And e is nullable
+select cast(mgr as integer) IS NOT NULL from ""scott"".emp;
++--------+
+| EXPR$0 |
++--------+
+| false  |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
+| true   |
++--------+
+(14 rows)
+
+!ok
+EnumerableCalc(expr#0..7=[{inputs}], expr#8=[IS NOT NULL($t3)], EXPR$0=[$t8])
+  EnumerableTableScan(table=[[scott, EMP]])
+!plan
+
+# Test CAST(e as t) IS NULL when CAST is lossless And e is nullable
+select cast(mgr as integer) IS NULL from ""scott"".emp;
++--------+
+| EXPR$0 |
++--------+
+| false  |
+| true   |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
+| false  |
++--------+
+(14 rows)
+
+!ok
+EnumerableCalc(expr#0..7=[{inputs}], expr#8=[IS NULL($t3)], EXPR$0=[$t8])
+  EnumerableTableScan(table=[[scott, EMP]])
+!plan
+
+# Test CAST(e as t) IS NULL when CAST is not lossless And e is nullable","[{'comment': ""We won't simplify the CAST that is not lossless, may I ask what's this test for?"", 'commenter': 'ILuffZhe'}, {'comment': 'This tests have two reasons:\r\n1. Compare with other test cases\r\n2. Make sure the code change is right.', 'commenter': 'NobiGo'}]"
3296,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2458,6 +2458,79 @@ private SqlOperator getNoDeterministicOperator() {
     checkSimplifyUnchanged(isNull(cast(vVarcharNotNull(), tInt(false))));
   }
 
+  /** Unit test for","[{'comment': ""I noticed that there are many duplicated java doc for those tests, it would be much better if we propose a suitable way to organize them. But I'm OK with it if remains still."", 'commenter': 'ILuffZhe'}]"
3296,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2458,6 +2458,79 @@ private SqlOperator getNoDeterministicOperator() {
     checkSimplifyUnchanged(isNull(cast(vVarcharNotNull(), tInt(false))));
   }
 
+  /** Unit test for
+   * <a href=""https://issues.apache.org/jira/browse/CALCITE-5769"">[CALCITE-5769]
+   * Optimizing 'CAST(e AS t) IS NOT NULL' to 'e IS NOT NULL'</a>. */
+  @Test void testSimplifyCastIsNull3() {
+    // ""(cast A as bigint) IS NULL"" when A is int and A is not null
+    // ==>
+    // ""false""
+    checkSimplify(isNull(cast(vIntNotNull(), tBigInt(false))), ""false"");","[{'comment': ""I'm a little confused about this `vIntNotNull()`. Per its java doc, it returns a non-nullable int variable, however, in `vParamNotNull()`, whose java doc says this method returns nullable varchar variable."", 'commenter': 'ILuffZhe'}, {'comment': 'Looks like the java doc has some problem. We can fix it in another issue.', 'commenter': 'NobiGo'}]"
3298,site/_docs/reference.md,"@@ -2827,6 +2827,8 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | UNIX_SECONDS(timestamp)                        | Returns the number of seconds since 1970-01-01 00:00:00
 | b | UNIX_DATE(date)                                | Returns the number of days since 1970-01-01
 | o | XMLTRANSFORM(xml, xslt)                        | Applies XSLT transform *xslt* to XML string *xml* and returns the result
+| s | BIT_LENGTH(string)                             | Returns the bit length of *string*
+| s | BIT_LENGTH(binary)                             | Returns the bit length of *binary*","[{'comment': 'move to alphabetical order', 'commenter': 'julianhyde'}, {'comment': '@julianhyde thanks, Julian. fixed.', 'commenter': 'chucheng92'}]"
3299,core/src/test/java/org/apache/calcite/rex/RexProgramBuilderBase.java,"@@ -756,8 +759,8 @@ protected RexNode vParam(String name, RelDataType type) {
    */
   protected RexNode vParam(String name, int arg, RelDataType type) {
     assertArgValue(arg);
-    RelDataType nonNullableType = typeFactory.createTypeWithNullability(type, false);
-    return rexBuilder.makeFieldAccess(getDynamicParam(nonNullableType, name), arg);
+    RelDataType nullableType = typeFactory.createTypeWithNullability(type, true);","[{'comment': 'The logic of the function has also been changed.\r\n\r\nSo I think the commit message is not accurate enough.', 'commenter': 'JiajunBernoulli'}, {'comment': 'How about `Adjust nullableType  and java doc for RexProgramBuilderBase`?', 'commenter': 'JiajunBernoulli'}, {'comment': ""Good point, I'll update the commit info."", 'commenter': 'ILuffZhe'}, {'comment': 'This line code is necessary? Because we have changed the code logic, The Test still passes, So this is an invalid code？', 'commenter': 'NobiGo'}, {'comment': ""I checked `getDynamicParam()` in `vParam`, which creates nullableType internally. So we don't need to change these codes."", 'commenter': 'ILuffZhe'}]"
3303,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6618,6 +6618,34 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""pow(cast(null as integer), 2)"");
   }
 
+  @Test void testIsInfFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_INF);
+    f0.checkFails(""^is_inf(3)^"",
+        ""No match found for function signature IS_INF\\(<NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""is_inf(3)"", false);
+    f.checkBoolean(""is_inf(1.2345)"", false);
+    f.checkBoolean(""is_inf(cast('NaN' as double))"", false);
+    f.checkBoolean(""is_inf(cast('Infinity' as double))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as double))"", true);
+    f.checkNull(""is_inf(cast(null as double))"");
+  }
+
+  @Test void testIsNaNFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_NAN);
+    f0.checkFails(""^is_nan(3)^"",","[{'comment': ""Is this test to test that it's only enabled for BQ? "", 'commenter': 'olivrlee'}, {'comment': 'Yep!', 'commenter': 'tanclary'}]"
3303,site/_docs/reference.md,"@@ -2731,6 +2731,8 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | IFNULL(value1, value2)                         | Equivalent to `NVL(value1, value2)`
 | b o | INSTR(string, substring [, from [, occurrence ] ]) | Returns the position of *substring* in *string*, searching starting at *from* (default 1), and until locating the nth *occurrence* (default 1) of *substring*
 | m | INSTR(string, substring)                       | Equivalent to `POSITION(substring IN string)`
+| b | IS_INF(value)                                  | Returns whether *value* is infinite
+| b | IS_NAN(value)                                  | Returns whether *value* is NaN","[{'comment': 'alphabetically, should be after `ILIKE`', 'commenter': 'julianhyde'}, {'comment': 'Done', 'commenter': 'tanclary'}]"
3303,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6618,6 +6618,34 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""pow(cast(null as integer), 2)"");
   }
 
+  @Test void testIsInfFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_INF);
+    f0.checkFails(""^is_inf(3)^"",
+        ""No match found for function signature IS_INF\\(<NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""is_inf(3)"", false);
+    f.checkBoolean(""is_inf(1.2345)"", false);
+    f.checkBoolean(""is_inf(cast('NaN' as double))"", false);
+    f.checkBoolean(""is_inf(cast('Infinity' as double))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as double))"", true);","[{'comment': ""did we ever test `CAST('Infinity' as DOUBLE)`?\r\n\r\nis this standard SQL behavior?"", 'commenter': 'julianhyde'}, {'comment': 'also check on REAL values (implicit cast of 32-bit float to 64-bit float)', 'commenter': 'julianhyde'}, {'comment': 'Added tests for REAL and Infinity/NaN', 'commenter': 'tanclary'}]"
3303,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -2106,6 +2106,11 @@ public static boolean isInf(double b0) {
     return Double.isInfinite(b0);
   }
 
+  /** SQL <code>IS_INF</code> operator applied to float values. */","[{'comment': 'do the tests pass if you remove the `isInf(float)` and `isNaN(float)` methods? I suspect they will. If so, remove the methods. less is more.', 'commenter': 'julianhyde'}, {'comment': 'Done.', 'commenter': 'tanclary'}, {'comment': 'This was actually not right. The tests fail because if you remove the `float` methods, they use the BigDecimal functions which do not recognize `Infinity` and `NaN`', 'commenter': 'tanclary'}, {'comment': ""Could you add a test case for float value? IMO this may go to the function applied to double value, if we remove the function applied to float value. I am not trying it, so please let me know if I'm wrong."", 'commenter': 'herunkang2018'}, {'comment': 'Done', 'commenter': 'tanclary'}]"
3303,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6618,6 +6618,60 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""pow(cast(null as integer), 2)"");
   }
 
+  @Test void testInfinity() {
+    final SqlOperatorFixture f = fixture();
+    f.checkScalar(""CAST('Infinity' AS DOUBLE)"", ""Infinity"",","[{'comment': 'Would it be better to align the case of keywords, such as keep lower case as other test cases?', 'commenter': 'herunkang2018'}, {'comment': 'Done, let me know if you have other suggestions!', 'commenter': 'tanclary'}]"
3303,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6618,6 +6618,60 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""pow(cast(null as integer), 2)"");
   }
 
+  @Test void testInfinity() {
+    final SqlOperatorFixture f = fixture();
+    f.checkScalar(""cast('Infinity' as double)"", ""Infinity"",
+        ""DOUBLE NOT NULL"");
+    f.checkScalar(""cast('-Infinity' as double)"", ""-Infinity"",
+        ""DOUBLE NOT NULL"");
+    f.checkScalar(""cast('Infinity' as real)"", ""Infinity"",
+        ""REAL NOT NULL"");
+    f.checkScalar(""cast('-Infinity' as real)"", ""-Infinity"",
+        ""REAL NOT NULL"");
+  }
+
+  @Test void testNaN() {
+    final SqlOperatorFixture f = fixture();
+    f.checkScalar(""cast('NaN' as double)"", ""NaN"",
+        ""DOUBLE NOT NULL"");
+    f.checkScalar(""cast('NaN' as real)"", ""NaN"",
+        ""REAL NOT NULL"");
+  }
+
+  @Test void testIsInfFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_INF);
+    f0.checkFails(""^is_inf(3)^"",
+        ""No match found for function signature IS_INF\\(<NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""is_inf(3)"", false);
+    f.checkBoolean(""is_inf(1.2345)"", false);
+    f.checkBoolean(""is_inf(cast('NaN' as double))"", false);
+    f.checkBoolean(""is_inf(cast('NaN' as real))"", false);
+    f.checkBoolean(""is_inf(cast('Infinity' as double))"", true);
+    f.checkBoolean(""is_inf(cast('Infinity' as real))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as double))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as real))"", true);
+    f.checkNull(""is_inf(cast(null as double))"");
+  }
+
+  @Test void testIsNaNFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_NAN);
+    f0.checkFails(""^is_nan(3)^"",
+        ""No match found for function signature IS_NAN\\(<NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""is_nan(3)"", false);
+    f.checkBoolean(""is_nan(1.2345)"", false);","[{'comment': 'Could you add a test case when decimal is Infinity or NaN?', 'commenter': 'herunkang2018'}, {'comment': 'When cast Infinity or NaN to decimal, I find it throws `NumberFormatException: Infinite or NaN`, because BigDecimal does not support Infinity or NaN.\r\nSo currently we are not able to add a test case for these special decimal value.', 'commenter': 'herunkang2018'}]"
3303,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6618,6 +6618,64 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""pow(cast(null as integer), 2)"");
   }
 
+  @Test void testInfinity() {
+    final SqlOperatorFixture f = fixture();
+    f.checkScalar(""cast('Infinity' as double)"", ""Infinity"",
+        ""DOUBLE NOT NULL"");
+    f.checkScalar(""cast('-Infinity' as double)"", ""-Infinity"",
+        ""DOUBLE NOT NULL"");
+    f.checkScalar(""cast('Infinity' as real)"", ""Infinity"",
+        ""REAL NOT NULL"");
+    f.checkScalar(""cast('-Infinity' as real)"", ""-Infinity"",
+        ""REAL NOT NULL"");
+  }
+
+  @Test void testNaN() {
+    final SqlOperatorFixture f = fixture();
+    f.checkScalar(""cast('NaN' as double)"", ""NaN"",
+        ""DOUBLE NOT NULL"");
+    f.checkScalar(""cast('NaN' as real)"", ""NaN"",
+        ""REAL NOT NULL"");
+  }
+
+  @Test void testIsInfFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_INF);
+    f0.checkFails(""^is_inf(3)^"",
+        ""No match found for function signature IS_INF\\(<NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""is_inf(3)"", false);
+    f.checkBoolean(""is_inf(1.2345)"", false);
+    f.checkBoolean(""is_inf(cast('NaN' as double))"", false);
+    f.checkBoolean(""is_inf(cast('NaN' as real))"", false);
+    f.checkBoolean(""is_inf(cast('Infinity' as double))"", true);
+    f.checkBoolean(""is_inf(cast('Infinity' as float))"", true);
+    f.checkBoolean(""is_inf(cast('Infinity' as real))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as double))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as float))"", true);
+    f.checkBoolean(""is_inf(cast('-Infinity' as real))"", true);
+    f.checkNull(""is_inf(cast(null as double))"");
+  }
+
+  @Test void testIsNaNFunc() {
+    final SqlOperatorFixture f0 = fixture().setFor(SqlLibraryOperators.IS_NAN);
+    f0.checkFails(""^is_nan(3)^"",
+        ""No match found for function signature IS_NAN\\(<NUMERIC>\\)"",
+        false);
+    final SqlOperatorFixture f = f0.withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""is_nan(3)"", false);
+    f.checkBoolean(""is_nan(1.2345)"", false);
+    f.checkBoolean(""is_nan(cast('Infinity' as double))"", false);
+    f.checkBoolean(""is_nan(cast('Infinity' as float))"", false);
+    f.checkBoolean(""is_nan(cast('Infinity' as real))"", false);
+    f.checkBoolean(""is_nan(cast('-Infinity' as double))"", false);
+    f.checkBoolean(""is_inf(cast('-Infinity' as float))"", false);","[{'comment': 'Is this a typo(is_inf -> is_nan)?', 'commenter': 'herunkang2018'}, {'comment': 'Yes thanks!', 'commenter': 'tanclary'}]"
3324,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -955,10 +955,38 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
           .withKind(SqlKind.CONCAT_WS_MSSQL);
 
   private static RelDataType arrayReturnType(SqlOperatorBinding opBinding) {
-    RelDataType type =
-        opBinding.getOperandCount() > 0
-            ? ReturnTypes.LEAST_RESTRICTIVE.inferReturnType(opBinding)
-            : opBinding.getTypeFactory().createUnknownType();
+    // only numeric & character types check
+    List<RelDataType> numericTypes = new ArrayList<>();
+    List<RelDataType> characterTypes = new ArrayList<>();
+    List<RelDataType> nullTypes = new ArrayList<>();
+    for (int i = 0; i < opBinding.getOperandCount(); i++) {
+      SqlTypeFamily family = opBinding.getOperandType(i).getSqlTypeName().getFamily();
+      if (family == SqlTypeFamily.NUMERIC) {","[{'comment': 'can this be rewritten as a switch case?', 'commenter': 'tanclary'}]"
3324,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -955,10 +955,38 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
           .withKind(SqlKind.CONCAT_WS_MSSQL);
 
   private static RelDataType arrayReturnType(SqlOperatorBinding opBinding) {
-    RelDataType type =
-        opBinding.getOperandCount() > 0
-            ? ReturnTypes.LEAST_RESTRICTIVE.inferReturnType(opBinding)
-            : opBinding.getTypeFactory().createUnknownType();
+    // only numeric & character types check
+    List<RelDataType> numericTypes = new ArrayList<>();
+    List<RelDataType> characterTypes = new ArrayList<>();
+    List<RelDataType> nullTypes = new ArrayList<>();
+    for (int i = 0; i < opBinding.getOperandCount(); i++) {
+      SqlTypeFamily family = opBinding.getOperandType(i).getSqlTypeName().getFamily();
+      if (family == SqlTypeFamily.NUMERIC) {
+        numericTypes.add(opBinding.getOperandType(i));
+      } else if (family == SqlTypeFamily.CHARACTER) {
+        characterTypes.add(opBinding.getOperandType(i));
+      } else if (family == SqlTypeFamily.NULL) {
+        nullTypes.add(opBinding.getOperandType(i));
+      } else {
+        break;
+      }
+    }
+
+    boolean onlyNumericCharacterTypes = opBinding.getOperandCount() > 0","[{'comment': 'I could be misunderstanding, but if you only care about the size of the lists and not the elements themselves, you could just use boolean flags to keep track of which types have appeared. I think it will simplify the expression below.', 'commenter': 'tanclary'}, {'comment': ""```     \r\nfinal List<RelDataType> types = opBinding.collectOperandTypes();\r\nboolean hasNumeric = false;\r\nboolean hasCharacter = false\r\n types.forEach(type -> {\r\n\t\t\t// null check here maybe\r\n\t\t\tswitch (type.getSqlTypeName().getFamily())  {\r\n\t\t\t case x:\r\n\t\t\t \t\thasNumeric = true;\r\n\t\t\t \t\tbreak;\r\n\t\t\t case y:\r\n\t\t\t \t\thasCharacter = true;\r\n\t\t\t \t\tbreak;\r\n\t\t\t default:\r\n\t\t }\r\n\t\t if hasNumeric || hasCharacter || c {....} ```\r\n you could do something like this maybe? (Excuse the pseudocode it's just an example)"", 'commenter': 'tanclary'}, {'comment': 'Yes. You are right. I have fixed this. PTAL~', 'commenter': 'chucheng92'}]"
3334,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -2256,11 +2256,16 @@ protected void registerNamespace(
       @Nullable String alias,
       SqlValidatorNamespace ns,
       boolean forceNullable) {
-    namespaces.put(requireNonNull(ns.getNode(), () -> ""ns.getNode() for "" + ns), ns);
+    final SqlNode sqlNode = requireNonNull(ns.getNode(), () -> ""ns.getNode() for "" + ns);","[{'comment': ""Consider removing the `sqlNode` variable. After you've called `requireNonNull(ns.getNode())` the validator will no longer complain."", 'commenter': 'julianhyde'}, {'comment': 'Removed `sqlNode`.', 'commenter': 'JiajunBernoulli'}]"
3334,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -5269,6 +5274,20 @@ private static SqlNode getNthExpr(SqlNode query, int ordinal, int sourceCount) {
     SqlInsert insertCallAfterValidate = call.getInsertCall();
     if (insertCallAfterValidate != null) {
       validateInsert(insertCallAfterValidate);
+      // Validate NULL","[{'comment': ""I didn't understand the 'Validate NULL' comment at first. 'Throw if select list contains NULL literal and target is NOT NULL' might be better."", 'commenter': 'julianhyde'}, {'comment': 'Good idea.', 'commenter': 'JiajunBernoulli'}]"
3334,core/src/test/java/org/apache/calcite/test/SqlToRelConverterTest.java,"@@ -3076,16 +3076,14 @@ void checkCorrelatedMapSubQuery(boolean expand) {
     sql(sql).ok();
   }
 
-  @Disabled(""CALCITE-985"")
   @Test void testMerge() {
-    final String sql = ""merge into emp as target\n""
-        + ""using (select * from emp where deptno = 30) as source\n""
-        + ""on target.empno = source.empno\n""
-        + ""when matched then\n""
-        + ""  update set sal = sal + source.sal\n""
-        + ""when not matched then\n""
-        + ""  insert (empno, deptno, sal)\n""
-        + ""  values (source.empno, source.deptno, source.sal)"";
+    final String sql = ""merge into empnullables e ""","[{'comment': 'Can you end each line of SQL with ""\\n"" (and no space). It makes the SQL easier to read inside `SqlToRelConverterTest.xml`.', 'commenter': 'julianhyde'}, {'comment': 'Done', 'commenter': 'JiajunBernoulli'}]"
3338,babel/src/test/resources/sql/big-query.iq,"@@ -3451,5 +3451,60 @@ FROM items;
 
 !ok
 
+#####################################################################
+# REGEXP_CONTAINS(value, regexp)
+#
+# Takes two STRING values. Returns TRUE if value is a partial match
+# for the regular expression, regexp.
+# If the regexp argument is invalid, the function returns an error.
+
+SELECT
+  email,
+  REGEXP_CONTAINS(email, r'@[a-zA-Z0-9-]+\.[a-zA-Z0-9-.]+') AS is_valid
+FROM
+  (SELECT
+    ['foo@example.com', 'bar@example.org', 'www.example.net']
+    AS addresses),
+  UNNEST(addresses) AS email;
+","[{'comment': 'Does it pass with this blank line between the query and the results? We may want to remove it to be consistent with other tests.', 'commenter': 'tanclary'}]"
3338,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -684,6 +685,8 @@ Builder populate2() {
       defineMethod(PARSE_TIME, ""parseTime"", NullPolicy.STRICT);
       defineMethod(PARSE_TIMESTAMP, ""parseTimestamp"", NullPolicy.STRICT);
 
+      defineMethod(REGEXP_CONTAINS, ""regexpContains"", NullPolicy.STRICT);","[{'comment': 'I would move to this around line 545 so it is with the other BigQuery string functions like SPLIT, etc', 'commenter': 'tanclary'}]"
3338,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -1008,6 +1008,9 @@ ExInstWithCause<CalciteException> failedToAccessField(
   @BaseMessage(""Invalid input for REGEXP_REPLACE: ''{0}''"")
   ExInst<CalciteException> invalidInputForRegexpReplace(String value);
 
+  @BaseMessage(""Invalid regex input for REGEXP_CONTAINS: ''{0}''"")
+  ExInst<CalciteException> invalidInputForRegexpContains(String value);","[{'comment': 'nit (up to you): move this above RegexpReplace (especially if you anticipate adding other Regexp Errors to this, might make sense to alphabetize them)', 'commenter': 'tanclary'}]"
3338,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -467,6 +467,16 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
   @LibraryOperator(libraries = {MYSQL, ORACLE})
   public static final SqlFunction REGEXP_REPLACE = new SqlRegexpReplaceFunction();
 
+  /**
+   * The ""REGEXP_CONTAINS(value, regexp)"" function.
+   * Returns TRUE if value is a partial match for the regular expression, regexp.
+   */
+  @LibraryOperator(libraries = { BIG_QUERY })","[{'comment': ""Can remove the spaces around 'BIG_QUERY' "", 'commenter': 'tanclary'}, {'comment': 'Also can you fix the javadoc so that it matches the format of the other ones? There are some good examples starting around line 511', 'commenter': 'tanclary'}]"
3338,site/_docs/reference.md,"@@ -2774,6 +2774,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | PARSE_TIME(format, string)                     | Uses format specified by *format* to convert *string* representation of time to a TIME value
 | b | PARSE_TIMESTAMP(format, string[, timeZone])    | Uses format specified by *format* to convert *string* representation of timestamp to a TIMESTAMP WITH LOCAL TIME ZONE value in *timeZone*
 | b | POW(numeric1, numeric2)                        | Returns *numeric1* raised to the power *numeric2*
+| b | REGEXP_CONTAINS(value, regexp)                 | Returns TRUE if *value* is a partial match for the regular expression, *regexp*.","[{'comment': 'Don\'t need period here. \r\n\r\nnit: Would it be easier to say something like ""Returns whether \\*value\\* is a partial match for the regular expression, \\*regexp\\*? This is up to you', 'commenter': 'tanclary'}]"
3338,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -4438,6 +4438,31 @@ private static void checkIf(SqlOperatorFixture f) {
     f0.forEachLibrary(list(SqlLibrary.MYSQL, SqlLibrary.ORACLE), consumer);
   }
 
+  @Test
+  void testRegexpContainsFunc() {
+    final SqlOperatorFixture f = fixture().setFor(SqlLibraryOperators.REGEXP_CONTAINS)
+        .withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkBoolean(""regexp_contains('abc def ghi', 'abc')"", true);
+    f.checkBoolean(""regexp_contains('abc def ghi', '[a-z]+')"", true);
+    f.checkBoolean(""regexp_contains('foo@bar.com', '@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+')"", true);
+    f.checkBoolean(""regexp_contains('foo@.com', '@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+')"", false);
+    f.checkBoolean(""regexp_contains('5556664422', '^\\d{10}$')"", true);
+    f.checkBoolean(""regexp_contains('11555666442233', '^\\d{10}$')"", false);
+    f.checkBoolean(""regexp_contains('55566644221133', '\\d{10}')"", true);
+    f.checkBoolean(""regexp_contains('55as56664as422', '\\d{10}')"", false);
+
+    f.checkQuery(""select regexp_contains('abc def ghi', 'abc')"");
+    f.checkQuery(""select regexp_contains('foo@bar.com', '@[a-zA-Z0-9-]+\\\\.[a-zA-Z0-9-.]+')"");
+    f.checkQuery(""select regexp_contains('55as56664as422', '\\d{10}')"");
+
+    f.checkFails(""regexp_contains('abc def ghi', '(abc')"",
+        ""Invalid regex input for REGEXP_CONTAINS: '(abc'"", true);
+    f.checkFails(""regexp_contains('abc def ghi', '{3}')"",
+        ""Invalid regex input for REGEXP_CONTAINS: '{3}'"", true);
+    f.checkFails(""regexp_contains('abc def ghi', '[z-a]')"",","[{'comment': 'add a couple more tests for null values ""f.checkNull"" might be useful', 'commenter': 'tanclary'}, {'comment': 'Quick clarification @tanclary , f.checkNull() verifies if we get back a SQL NULL value from the expression right? What should be done in case we are not expecting a NULL return, as in this function always returns a boolean value if the required arguments are passed or an exception for invalid regex.', 'commenter': 'Anthrino'}, {'comment': ""That's right. It's still helpful to add .checkNull() tests to ensure that if either (or both) arguments is null that null is returned. This is useful because not all functions follow that behavior. In this case however, based on a couple of quick queries I ran against BigQuery, if either or both arguments is null the function should return null. Hope this helps."", 'commenter': 'tanclary'}, {'comment': 'In other cases where you are expecting a non-non value you should use .checkBoolean (at least for this function given that the return type is boolean).', 'commenter': 'tanclary'}, {'comment': ""Got it, thanks Tanner! The documentation didn't mention NULL returns so I assumed it returns bools, will run some test queries for additional NULL scenarios."", 'commenter': 'Anthrino'}]"
3338,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -394,6 +394,15 @@ private static int makeRegexpFlags(@Nullable String stringFlags) {
     return flags;
   }
 
+  /** SQL {@code REGEXP_CONTAINS(value, regexp)} function. */
+  public static boolean regexpContains(String value, String regex) {
+    try {
+      return Pattern.compile(regex, Pattern.CASE_INSENSITIVE).matcher(value).matches();
+    } catch (Exception exception) {","[{'comment': ""nit: change this to 'e' to match other caught exception names"", 'commenter': 'tanclary'}, {'comment': ""This is inconsistent though because there is 'e', 'ex', etc"", 'commenter': 'tanclary'}]"
3338,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -467,6 +467,14 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
   @LibraryOperator(libraries = {MYSQL, ORACLE})
   public static final SqlFunction REGEXP_REPLACE = new SqlRegexpReplaceFunction();
 
+  /** The ""REGEXP_CONTAINS(value, regexp)"" function.
+   * Returns TRUE if value is a partial match for the regular expression, regexp. */
+  @LibraryOperator(libraries = {BIG_QUERY})
+  public static final SqlFunction REGEXP_CONTAINS =
+          SqlBasicFunction.create(""REGEXP_CONTAINS"", ReturnTypes.BOOLEAN_NULLABLE,
+          OperandTypes.STRING_STRING,","[{'comment': 'Is the indentation off here? Look at below functions for other examples', 'commenter': 'tanclary'}]"
3338,core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties,"@@ -329,6 +329,7 @@ InvalidInputForJsonKeys=Invalid input for JSON_KEYS: ''{0}''
 InvalidInputForJsonRemove=Invalid input for JSON_REMOVE: document: ''{0}'', jsonpath expressions: ''{1}''
 InvalidInputForJsonStorageSize=Invalid input for JSON_STORAGE_SIZE: ''{0}''
 InvalidInputForRegexpReplace=Invalid input for REGEXP_REPLACE: ''{0}''
+InvalidInputForRegexpContains=Invalid regex input for REGEXP_CONTAINS: ''{0}''","[{'comment': 'Sorry for the nit but maybe contains should go above replace to preserve alphabetic order for the group, it seems like the other sets of functions follow it which is why I suggest it.', 'commenter': 'tanclary'}]"
3338,babel/src/test/resources/sql/big-query.iq,"@@ -3520,5 +3520,71 @@ FROM items;
 
 !ok
 
+#####################################################################","[{'comment': ""Don't put stuff at the end of files. Put it in the best place. (You'll have to figure out how the file is organized - e.g. alphabetical or by topic.)\r\n\r\n(If everyone puts stuff at the end, we get lots of conflicts.)"", 'commenter': 'julianhyde'}, {'comment': 'Thanks for pointing out Julian, moved the tests to appropriate location.', 'commenter': 'Anthrino'}]"
3338,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -1005,6 +1005,9 @@ ExInstWithCause<CalciteException> failedToAccessField(
   @BaseMessage(""Invalid input for JSON_STORAGE_SIZE: ''{0}''"")
   ExInst<CalciteException> invalidInputForJsonStorageSize(String value);
 
+  @BaseMessage(""Invalid regex input for REGEXP_CONTAINS: ''{0}''"")","[{'comment': ""'Invalid regular expression' might be better"", 'commenter': 'julianhyde'}, {'comment': 'Updated error statement as suggested.', 'commenter': 'Anthrino'}]"
3338,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -234,6 +235,34 @@ static <E> List<E> list() {
     assertThat(posixRegex(""abcq"", ""[[:xdigit:]]"", false), is(true));
   }
 
+  @Test void testRegexpContains() {
+    try {
+      regexpContains(""abc def ghi"", ""(abc"");
+      fail(""'regexp_contains' on an invalid regex input '(abc' is not possible"");
+    } catch (CalciteException e) {
+      assertThat(e.getMessage(),
+          is(""Invalid regex input for REGEXP_CONTAINS: 'Unclosed group near index 4\n(abc'""));","[{'comment': 'Break strings after each `\\n`. It makes them easier to read.', 'commenter': 'julianhyde'}, {'comment': ""I'm surprised that this test works. Does `regexpContains` throw a `CalciteException`? Looks like it throws a `RuntimeException`."", 'commenter': 'julianhyde'}, {'comment': ""> Break strings after each `\\n`. It makes them easier to read.\r\n\r\nThanks for the pointer @julianhyde, the \\n is included only as it is part of the exception message returned, I can break the string for legibility but this was easier to match with the returned string.\r\n\r\n\r\n\r\n> I'm surprised that this test works. Does `regexpContains` throw a `CalciteException`? Looks like it throws a `RuntimeException`.\r\n\r\nYes we were returning a `CalciteException` previously, saw your comment on the other file will modify it to a `RuntimeException`."", 'commenter': 'Anthrino'}]"
3338,site/_docs/reference.md,"@@ -2776,6 +2776,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | PARSE_TIMESTAMP(format, string[, timeZone])    | Uses format specified by *format* to convert *string* representation of timestamp to a TIMESTAMP WITH LOCAL TIME ZONE value in *timeZone*
 | h s | PARSE_URL(urlString, partToExtract [, keyToExtract] ) | Returns the specified *partToExtract* from the *urlString*. Valid values for *partToExtract* include HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. *keyToExtract* specifies which query to extract
 | b | POW(numeric1, numeric2)                        | Returns *numeric1* raised to the power *numeric2*
+| b | REGEXP_CONTAINS(value, regexp)                 | Returns TRUE if *value* is a partial match for the regular expression, *regexp*","[{'comment': ""would 'string' be better than 'value'?"", 'commenter': 'julianhyde'}, {'comment': ""I prefer 'Returns whether' to 'Returns TRUE if'. The former is more direct, and the latter doesn't actually say under what conditions the method returns FALSE."", 'commenter': 'julianhyde'}, {'comment': 'Sure @julianhyde, that sounds more clear I just thought it would be best to align it to BQ documentation as they use *value* everywhere.', 'commenter': 'Anthrino'}, {'comment': ""I understand your dilemma. I think it's better to make the Calcite descriptions uniform, even if they come from many different DBs.\r\n\r\nIn `big-query.iq`, feel free to use the doc copy-pasted from BigQuery."", 'commenter': 'julianhyde'}]"
3338,core/src/main/java/org/apache/calcite/runtime/CalciteResource.java,"@@ -1005,6 +1005,9 @@ ExInstWithCause<CalciteException> failedToAccessField(
   @BaseMessage(""Invalid input for JSON_STORAGE_SIZE: ''{0}''"")
   ExInst<CalciteException> invalidInputForJsonStorageSize(String value);
 
+  @BaseMessage(""Invalid regex input for REGEXP_CONTAINS: ''{0}''"")
+  ExInst<CalciteException> invalidInputForRegexpContains(String value);","[{'comment': 'Change `ExInst<CalciteException>` to `ExInst<RuntimeException>` and then I think you will be able to remove the use of `Util.toUnchecked`.\r\n\r\n`CalciteException` is for exceptions detected at prepare time (generally validation) whereas you need a runtime exception.', 'commenter': 'julianhyde'}]"
3338,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -401,6 +402,16 @@ private static int makeRegexpFlags(@Nullable String stringFlags) {
     return flags;
   }
 
+  /** SQL {@code REGEXP_CONTAINS(value, regexp)} function. */","[{'comment': 'Can you briefly document what happens if the regex is invalid.', 'commenter': 'julianhyde'}]"
3338,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -401,6 +402,16 @@ private static int makeRegexpFlags(@Nullable String stringFlags) {
     return flags;
   }
 
+  /** SQL {@code REGEXP_CONTAINS(value, regexp)} function. */
+  public static boolean regexpContains(String value, String regex) {
+    try {
+      Pattern regexp = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);","[{'comment': 'Does this pattern handle Java regular expressions or BigQuery regular expressions?', 'commenter': 'mihaibudiu'}, {'comment': 'Hi @mihaibudiu, this Pattern object is an instance of the java.util.regex library, it has almost complete overlap with BQ regex except for a few negative scenarios as highlighted on this ticket: [CALCITE-5910](https://issues.apache.org/jira/browse/CALCITE-5910)', 'commenter': 'Anthrino'}]"
3339,redis/src/test/java/org/apache/calcite/adapter/redis/RedisCaseBase.java,"@@ -113,7 +113,7 @@ public static int getAvailablePort() {
 
   @AfterAll
   public static void stopRedisContainer() {
-    if (REDIS_CONTAINER != null && REDIS_CONTAINER.isRunning()) {","[{'comment': 'LGTM', 'commenter': 'NobiGo'}]"
3339,redis/src/test/java/org/apache/calcite/adapter/redis/RedisDataCaseBase.java,"@@ -99,8 +99,6 @@ public void makeData() {
 
   @AfterEach
   public void shutDown() {
-    if (null != pool) {","[{'comment': ""I don't think so. When we init the pool throw exception, if, remove the condition, the code will throw NPE. "", 'commenter': 'NobiGo'}, {'comment': '@NobiGo Thanks for reviewing, sorry for my mistake, @AfterEach will still execute if @BeforeEach fails. I have fixed it.', 'commenter': 'chucheng92'}]"
3346,core/src/main/java/org/apache/calcite/sql/SqlNumericLiteral.java,"@@ -117,7 +117,7 @@ public boolean isExact() {
           scaleValue);
     }
 
-    // else we have a a float, real or double.  make them all double for
+    // else we have a float, real or double.  make them all double for","[{'comment': ""From context, this appears to be talking about SQL types. SQL types must be upper-case. SQL's `FLOAT` type is very different to Java's `float` type so it is very important to be precise.\r\n\r\nFix existing documentation if necessary."", 'commenter': 'julianhyde'}]"
3346,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -1925,6 +1925,18 @@ private void checkSemiOrAntiJoinProjectTranspose(JoinRelType type) {
         .check();
   }
 
+  /** Test case for <a href=""https://issues.apache.org/jira/browse/CALCITE-5884"">[CALCITE-5884]
+   * Description of ARRAY_TO_STRING function is incomplete</a>. */","[{'comment': ""can you follow the existing formatting, of a line break after 'test case for'."", 'commenter': 'julianhyde'}, {'comment': 'There were more instances, I fixed all of them in this file.', 'commenter': 'mihaibudiu'}]"
3346,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -1925,6 +1925,18 @@ private void checkSemiOrAntiJoinProjectTranspose(JoinRelType type) {
         .check();
   }
 
+  /** Test case for <a href=""https://issues.apache.org/jira/browse/CALCITE-5884"">[CALCITE-5884]
+   * Description of ARRAY_TO_STRING function is incomplete</a>. */
+  @Test void testArrayToString() {
+    final String sql = ""select array_to_string(array['1','2','3','4',NULL,'6'], ',', NULL)"";
+    sql(sql).withFactory(
+        t -> t.withOperatorTable(","[{'comment': ""add a comment for what the desried outcome is. I guess we don't want to see the expression constant-reduced to NULL?"", 'commenter': 'julianhyde'}]"
3346,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -5471,6 +5471,10 @@ public static String arrayToString(List list, String delimiter) {
 
   /** SQL {@code ARRAY_TO_STRING(array, delimiter, nullText)} function. */
   public static String arrayToString(List list, String delimiter, @Nullable String nullText) {
+    // Note that the SQL function ARRAY_TO_STRING that we implement will return
+    // 'NULL' when the nullText argument is NULL.  However, that is handled by
+    // the nullPolicy of the RexToLixTranslator.  So here a NULL value","[{'comment': 'NIT: redundant spaces (and in above line too)', 'commenter': 'libenchao'}, {'comment': 'I have changed the summary, removed the spaces, and squashed the commits.', 'commenter': 'mihaibudiu'}]"
3363,core/src/main/java/org/apache/calcite/sql/dialect/SparkSqlDialect.java,"@@ -147,9 +147,34 @@ public SparkSqlDialect(SqlDialect.Context context) {
       case TRIM:
         unparseHiveTrim(writer, call, leftPrec, rightPrec);
         break;
+      case POSITION:","[{'comment': ""I noticed `POSITION('a', 'abc')` and `POSITION('a' IN 'abc')` all works in Spark. So we can use \r\n` case POSITION:\r\n    SqlUtil.unparseFunctionSyntax(SqlStdOperatorTable.POSITION, writer, call, false);`. WDYT?"", 'commenter': 'NobiGo'}, {'comment': 'Good suggestion! I replaced it with `SqlUtil.unparseFunctionSyntax`. ', 'commenter': 'macroguo-ghy'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,179 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query
+
+ * <blockquote><pre>{@code
+ *  select a,b from t1
+ *   except
+ *  select a,b from t2
+ *   except
+ *  select a,b from t3
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  select a,b
+ *  from (select a,b,0 as m from t1
+ *  union all
+ *  select a,b,1 as m from t2
+ *  union all
+ *  select a,b,2 as m from t3)
+ *  group by a,b
+ *  having count(*) filter (where m = 0) > 0
+ *   and count(*) filter (where m = 1) = 0
+ *   and count(*) filter (where m = 2) = 0
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index","[{'comment': 'minor comment about format, I would add a blank here.', 'commenter': 'herunkang2018'}]"
3367,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -2699,6 +2699,35 @@ private void checkPushJoinThroughUnionOnRightDoesNotMatchSemiOrAntiJoin(JoinRelT
         .check();
   }
 
+  /** Tests {@link org.apache.calcite.rel.rules.MinusToDistinctRule},","[{'comment': 'Could you add an E2E test case using quidem, to check the final result correct or not?', 'commenter': 'herunkang2018'}, {'comment': '+1, also wondering', 'commenter': 'tanclary'}, {'comment': ""Yes,I'm looking for a single test with the correctness of optimizes rule"", 'commenter': 'LakeShen'}, {'comment': ""> +1, also wondering\r\n\r\n@herunkang2018 @tanclary ,I couldn't find a case where quidem was used to test the correctness of the optimization rules,could you give me a unit test or class to refer to? Thank you very much."", 'commenter': 'LakeShen'}, {'comment': ""I looked through and I also could not find a good example, I don't think that should hold up this PR."", 'commenter': 'tanclary'}, {'comment': '@LakeShen I think we could add the test in [set-op.iq](https://github.com/apache/calcite/blob/2a96512c352bda4a5d9c0c80730f5c115ac363d6/core/src/test/resources/sql/set-op.iq#L157).', 'commenter': 'herunkang2018'}, {'comment': ""In set-op.iq we need to support using this Rule to work. As far as I know It didn't. But  we can try to read \r\n `https://github.com/apache/calcite/blob/main/core/src/test/java/org/apache/calcite/test/JdbcTest.java#L3749C14-L3749C27`. @LakeShen Can we add tests like this?"", 'commenter': 'NobiGo'}, {'comment': ""In set-op.iq we need to support using this Rule to work. As far as I know It didn't. But  we can try to read \r\n `https://github.com/apache/calcite/blob/main/core/src/test/java/org/apache/calcite/test/JdbcTest.java#L3749C14-L3749C27`. @LakeShen Can we add tests like this?"", 'commenter': 'NobiGo'}, {'comment': '@NobiGo @herunkang2018 ,thank you very much for your advice,I will take it later.', 'commenter': 'LakeShen'}, {'comment': ""> In set-op.iq we need to support using this Rule to work. As far as I know It didn't. But we can try to read `https://github.com/apache/calcite/blob/main/core/src/test/java/org/apache/calcite/test/JdbcTest.java#L3749C14-L3749C27`. @LakeShen Can we add tests like this?\r\n\r\nHi @NobiGo ,I have added the test for this rule in JdbcTest,please help me to review again, thank you very much"", 'commenter': 'LakeShen'}, {'comment': ""We are abusing `JdbcTest` but there seems to be no better way at the moment (https://lists.apache.org/thread/r4yhn77m92fodmz8xm6k40sfd130w7hh), and it's definitely better to have a test here than no test at all."", 'commenter': 'asolimando'}]"
3367,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -2699,6 +2699,35 @@ private void checkPushJoinThroughUnionOnRightDoesNotMatchSemiOrAntiJoin(JoinRelT
         .check();
   }
 
+  /** Tests {@link org.apache.calcite.rel.rules.MinusToDistinctRule},
+   * which rewrites an {@link Minus} operator with 3 inputs. */
+  @Test void testMinusToDistinct() {
+    final String sql = ""select EMPNO,ENAME,JOB from emp where deptno = 10\n""
+        + ""except\n""
+        + ""select EMPNO,ENAME,JOB from emp where deptno = 20\n""
+        + ""except\n""
+        + ""select EMPNO,ENAME,JOB from emp where deptno = 30\n"";
+    sql(sql)
+        .withRule(CoreRules.MINUS_MERGE,
+            CoreRules.MINUS_TO_DISTINCT)
+        .check();
+  }
+
+  /** Tests {@link org.apache.calcite.rel.rules.MinusToDistinctRule},
+   *  correctly ignores an {@code EXCEPT ALL}. It can only handle
+   *    * {@code EXCEPT DISTINCT}.*/","[{'comment': 'Is this comment formatted incorrectly? Looks like there is an extra * and could use a space at the end', 'commenter': 'tanclary'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,179 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query
+
+ * <blockquote><pre>{@code
+ *  select a,b from t1
+ *   except
+ *  select a,b from t2
+ *   except
+ *  select a,b from t3
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  select a,b
+ *  from (select a,b,0 as m from t1
+ *  union all
+ *  select a,b,1 as m from t2
+ *  union all
+ *  select a,b,2 as m from t3)
+ *  group by a,b
+ *  having count(*) filter (where m = 0) > 0
+ *   and count(*) filter (where m = 1) = 0
+ *   and count(*) filter (where m = 2) = 0
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch
+    for (int i = 0; i < branchCount; i++) {
+      relBuilder.push(minus.getInput(i));
+      relBuilder.projectPlus(relBuilder.literal(new BigDecimal(i)));
+    }
+
+    // create a union above all the branches
+    relBuilder.union(true, branchCount);
+
+    final RelNode union = relBuilder.peek();
+    final int originalFieldCnt = union.getRowType().getFieldCount() - 1;
+
+    ImmutableList.Builder<RexNode> projects = ImmutableList.builder();
+    // skip the branch index column
+    projects.addAll(Util.first(relBuilder.fields(), originalFieldCnt));
+
+    // On top of the Union, add a Project and add branch cnt number boolean columns
+    // e.g. LogicalProject(EMPNO=[$0], $f1=[=($1, 0)], $f2=[=($1, 1)], $f3=[=($1, 2)])
+    // $f1,$f2,$f3 are the boolean indicate whether it comes from the corresponding branch
+    for (int i = 0; i < branchCount; i++) {
+      projects.add(
+          relBuilder.equals(relBuilder.field(originalFieldCnt),
+              relBuilder.literal(new BigDecimal(i))));
+    }
+
+    relBuilder.project(projects.build());
+
+    // Add the count(*) filter $f1(..) for each branch
+    ImmutableList.Builder<RelBuilder.AggCall> aggCalls = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      aggCalls.add(relBuilder.countStar(null).filter(relBuilder.field(originalFieldCnt + i)));
+    }","[{'comment': 'Is there anyway to combine these `for` loops? I noticed we iterate through the branch count multiple times.', 'commenter': 'tanclary'}, {'comment': '> Is there anyway to combine these `for` loops? I noticed we iterate through the branch count multiple times.\r\n\r\nHi @tanclary ,adding the Count Filter is mainly to calculate the specific value of each branch with group by fields.\r\n![image](https://github.com/apache/calcite/assets/8057451/b1f97cc5-f72b-46aa-875b-dc66a156da6b)\r\n', 'commenter': 'LakeShen'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,180 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query
+
+ * <blockquote><pre>{@code
+ *  select a,b from t1
+ *   except
+ *  select a,b from t2
+ *   except
+ *  select a,b from t3
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code","[{'comment': 'According to the implementation, The rewrite SQL is different from the code annotation（Same meaning), Do we need to keep pace with the implementation？', 'commenter': 'NobiGo'}, {'comment': '> According to the implementation, The rewrite SQL is different from the code annotation（Same meaning), Do we need to keep pace with the implementation？\r\n\r\nHi @NobiGo ,the plan after this rule rewrite is actually the plan for this SQL.\r\n\r\nHow about I put the before and after plan in an example? I think that it maybe make it easier to understand', 'commenter': 'LakeShen'}, {'comment': 'Yes, Looks good.', 'commenter': 'NobiGo'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch
+    for (int i = 0; i < branchCount; i++) {
+      relBuilder.push(minus.getInput(i));
+      relBuilder.projectPlus(relBuilder.literal(new BigDecimal(i)));","[{'comment': ""Nit: since this is a counter for the branch numbers, maybe `BigDecimal` is an overkill?\r\n\r\nEDIT: never mind, it's implemented the same way in `IntersectToDistinctRule` so let's leave it this way"", 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);","[{'comment': ""```suggestion\r\n    final Minus minus = call.rel(0);\r\n```\r\nSince you have marked all other variables as such, it's sending the message that it will mutate if you don't mark it final too."", 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index","[{'comment': 'Nit:\r\n```suggestion\r\n    // For each child branch in minus, add a column which indicates the branch index\r\n```', 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp","[{'comment': 'Nit: missing comma and space after comma\r\n```suggestion\r\n    // e.g., select EMPNO from emp -> select EMPNO, 0 from emp\r\n```', 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch
+    for (int i = 0; i < branchCount; i++) {
+      relBuilder.push(minus.getInput(i));
+      relBuilder.projectPlus(relBuilder.literal(new BigDecimal(i)));
+    }
+
+    // create a union above all the branches
+    relBuilder.union(true, branchCount);
+
+    final RelNode union = relBuilder.peek();
+    final int originalFieldCnt = union.getRowType().getFieldCount() - 1;
+
+    ImmutableList.Builder<RexNode> projects = ImmutableList.builder();
+    // skip the branch index column
+    projects.addAll(Util.first(relBuilder.fields(), originalFieldCnt));
+
+    // On top of the Union, add a Project and add branch cnt number boolean columns","[{'comment': 'Nit:\r\ncheck if this reads better in your opinion\r\n```suggestion\r\n    // On top of the Union, add a Project and add one boolean column per branch counter, where the i-th boolean column is true iff the tuple comes from the i-th branch\r\n```', 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch","[{'comment': '```suggestion\r\n    // 0 indicates that it comes from the first branch (operand) of the minus operator\r\n```', 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch
+    for (int i = 0; i < branchCount; i++) {
+      relBuilder.push(minus.getInput(i));
+      relBuilder.projectPlus(relBuilder.literal(new BigDecimal(i)));
+    }
+
+    // create a union above all the branches
+    relBuilder.union(true, branchCount);
+
+    final RelNode union = relBuilder.peek();
+    final int originalFieldCnt = union.getRowType().getFieldCount() - 1;
+
+    ImmutableList.Builder<RexNode> projects = ImmutableList.builder();
+    // skip the branch index column
+    projects.addAll(Util.first(relBuilder.fields(), originalFieldCnt));
+
+    // On top of the Union, add a Project and add branch cnt number boolean columns
+    //
+    // e.g. LogicalProject(EMPNO=[$0], $f1=[=($1, 0)], $f2=[=($1, 1)], $f3=[=($1, 2)])
+    // $f1,$f2,$f3 are the boolean indicate whether it comes from the corresponding branch
+    for (int i = 0; i < branchCount; i++) {
+      projects.add(
+          relBuilder.equals(relBuilder.field(originalFieldCnt),
+              relBuilder.literal(new BigDecimal(i))));
+    }
+
+    relBuilder.project(projects.build());
+
+    // Add the count(*) filter $f1(..) for each branch
+    ImmutableList.Builder<RelBuilder.AggCall> aggCalls = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      aggCalls.add(relBuilder.countStar(null).filter(relBuilder.field(originalFieldCnt + i)));
+    }
+
+    final ImmutableBitSet groupSet = ImmutableBitSet.range(originalFieldCnt);
+    relBuilder.aggregate(relBuilder.groupKey(groupSet), aggCalls.build());
+
+    ImmutableList.Builder<RexNode> filters = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      SqlOperator operator =
+          i == 0
+              ? SqlStdOperatorTable.GREATER_THAN
+              : SqlStdOperatorTable.EQUALS;
+      filters
+          .add(
+              rexBuilder.makeCall(operator, relBuilder.field(originalFieldCnt + i),
+              relBuilder.literal(new BigDecimal(0))));","[{'comment': 'Nit: I think we are safely within line length limits without so many indentations, check this out:\r\n```suggestion\r\n      SqlOperator operator = i == 0 ? SqlStdOperatorTable.GREATER_THAN : SqlStdOperatorTable.EQUALS;\r\n      filters.add(rexBuilder.makeCall(operator, relBuilder.field(originalFieldCnt + i),\r\n          relBuilder.literal(new BigDecimal(0))));\r\n```', 'commenter': 'asolimando'}]"
3367,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -3773,6 +3774,35 @@ public void checkOrderBy(final boolean desc,
             ""empid=110; name=Theodore"");
   }
 
+  @Test void testExceptToDistinct() {","[{'comment': ""Isn't this test covering `MinusToDistinctRule`? If so, the test name should be `testMinusToDistinct` or similar. Please check."", 'commenter': 'asolimando'}]"
3367,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -3773,6 +3774,35 @@ public void checkOrderBy(final boolean desc,
             ""empid=110; name=Theodore"");
   }
 
+  @Test void testExceptToDistinct() {
+    final String sql = """"
+        + ""select \""empid\"", \""name\"" from \""hr\"".\""emps\"" where \""deptno\""=10\n""
+        + ""except\n""
+        + ""select \""empid\"", \""name\"" from \""hr\"".\""emps\"" where \""empid\"">=150"";
+    CalciteAssert.hr()
+        .query(sql)
+        .withHook(Hook.PLANNER, (Consumer<RelOptPlanner>) planner ->
+            planner.removeRule(ENUMERABLE_MINUS_RULE))","[{'comment': 'Can you elaborate on why you need to exclude this rule in the test?', 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch
+    for (int i = 0; i < branchCount; i++) {
+      relBuilder.push(minus.getInput(i));
+      relBuilder.projectPlus(relBuilder.literal(new BigDecimal(i)));
+    }
+
+    // create a union above all the branches
+    relBuilder.union(true, branchCount);
+
+    final RelNode union = relBuilder.peek();
+    final int originalFieldCnt = union.getRowType().getFieldCount() - 1;
+
+    ImmutableList.Builder<RexNode> projects = ImmutableList.builder();
+    // skip the branch index column
+    projects.addAll(Util.first(relBuilder.fields(), originalFieldCnt));
+
+    // On top of the Union, add a Project and add branch cnt number boolean columns
+    //
+    // e.g. LogicalProject(EMPNO=[$0], $f1=[=($1, 0)], $f2=[=($1, 1)], $f3=[=($1, 2)])
+    // $f1,$f2,$f3 are the boolean indicate whether it comes from the corresponding branch
+    for (int i = 0; i < branchCount; i++) {
+      projects.add(
+          relBuilder.equals(relBuilder.field(originalFieldCnt),
+              relBuilder.literal(new BigDecimal(i))));
+    }
+
+    relBuilder.project(projects.build());
+
+    // Add the count(*) filter $f1(..) for each branch
+    ImmutableList.Builder<RelBuilder.AggCall> aggCalls = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      aggCalls.add(relBuilder.countStar(null).filter(relBuilder.field(originalFieldCnt + i)));
+    }
+
+    final ImmutableBitSet groupSet = ImmutableBitSet.range(originalFieldCnt);
+    relBuilder.aggregate(relBuilder.groupKey(groupSet), aggCalls.build());
+
+    ImmutableList.Builder<RexNode> filters = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      SqlOperator operator =
+          i == 0
+              ? SqlStdOperatorTable.GREATER_THAN
+              : SqlStdOperatorTable.EQUALS;
+      filters
+          .add(
+              rexBuilder.makeCall(operator, relBuilder.field(originalFieldCnt + i),
+              relBuilder.literal(new BigDecimal(0))));
+    }
+
+    relBuilder.filter(filters.build());
+    relBuilder.project(Util.first(relBuilder.fields(), originalFieldCnt));
+    call.transformTo(relBuilder.build());
+  }
+
+  /**
+   * Rule configuration.
+   */
+  @Value.Immutable
+  public interface Config
+      extends RelRule.Config {","[{'comment': 'No need for this newline:\r\n```suggestion\r\n  public interface Config extends RelRule.Config {\r\n```', 'commenter': 'asolimando'}]"
3367,core/src/main/java/org/apache/calcite/rel/rules/MinusToDistinctRule.java,"@@ -0,0 +1,184 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.rel.rules;
+
+import org.apache.calcite.plan.RelOptCluster;
+import org.apache.calcite.plan.RelOptRuleCall;
+import org.apache.calcite.plan.RelRule;
+import org.apache.calcite.rel.RelNode;
+import org.apache.calcite.rel.core.Minus;
+import org.apache.calcite.rel.logical.LogicalMinus;
+import org.apache.calcite.rex.RexBuilder;
+import org.apache.calcite.rex.RexNode;
+import org.apache.calcite.sql.SqlOperator;
+import org.apache.calcite.sql.fun.SqlStdOperatorTable;
+import org.apache.calcite.tools.RelBuilder;
+import org.apache.calcite.tools.RelBuilderFactory;
+import org.apache.calcite.util.ImmutableBitSet;
+import org.apache.calcite.util.Util;
+
+import com.google.common.collect.ImmutableList;
+
+import org.immutables.value.Value;
+
+import java.math.BigDecimal;
+
+/**
+ * Planner rule that translates a distinct
+ * {@link org.apache.calcite.rel.core.Minus}
+ * (<code>all</code> = <code>false</code>)
+ * into a group of operators composed of
+ * {@link org.apache.calcite.rel.core.Union},
+ * {@link org.apache.calcite.rel.core.Aggregate},
+ * {@link org.apache.calcite.rel.core.Filter},etc.
+ *
+ * <p>For example, the query plan
+
+ * <blockquote><pre>{@code
+ *  LogicalMinus(all=[false])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 10)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *    LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *      LogicalFilter(condition=[=($7, 20)])
+ *        LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * <p> will convert to
+ *
+ * <blockquote><pre>{@code
+ *  LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2])
+ *    LogicalFilter(condition=[AND(>($3, 0), =($4, 0))])
+ *      LogicalAggregate(group=[{0, 1, 2}], agg#0=[COUNT() FILTER $3], agg#1=[COUNT() FILTER $4])
+ *        LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[=($3, 0)], $f4=[=($3, 1)])
+ *          LogicalUnion(all=[true])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[0])
+ *              LogicalFilter(condition=[=($7, 10)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ *            LogicalProject(EMPNO=[$0], ENAME=[$1], JOB=[$2], $f3=[1])
+ *              LogicalFilter(condition=[=($7, 20)])
+ *                LogicalTableScan(table=[[CATALOG, SALES, EMP]])
+ * }</pre></blockquote>
+ *
+ * @see CoreRules#MINUS_TO_DISTINCT
+ */
+@Value.Enclosing
+public class MinusToDistinctRule
+    extends RelRule<MinusToDistinctRule.Config>
+    implements TransformationRule {
+
+  protected MinusToDistinctRule(Config config) {
+    super(config);
+  }
+
+  @Deprecated // to be removed before 2.0
+  public MinusToDistinctRule(Class<? extends Minus> minusClass,
+      RelBuilderFactory relBuilderFactory) {
+    this(MinusToDistinctRule.Config.DEFAULT.withRelBuilderFactory(relBuilderFactory)
+        .as(MinusToDistinctRule.Config.class)
+        .withOperandFor(minusClass));
+  }
+
+  @Override public void onMatch(RelOptRuleCall call) {
+    Minus minus = call.rel(0);
+
+    if (minus.all) {
+      // Nothing we can do
+      return;
+    }
+
+    final RelOptCluster cluster = minus.getCluster();
+    final RelBuilder relBuilder = call.builder();
+    final RexBuilder rexBuilder = cluster.getRexBuilder();
+    final int branchCount = minus.getInputs().size();
+
+    // For each child branch in minus,add a column which indicates branch index
+    //
+    // e.g. select EMPNO from emp -> select EMPNO,0 from emp
+    // 0 indicates that it comes from minus the first child branch
+    for (int i = 0; i < branchCount; i++) {
+      relBuilder.push(minus.getInput(i));
+      relBuilder.projectPlus(relBuilder.literal(new BigDecimal(i)));
+    }
+
+    // create a union above all the branches
+    relBuilder.union(true, branchCount);
+
+    final RelNode union = relBuilder.peek();
+    final int originalFieldCnt = union.getRowType().getFieldCount() - 1;
+
+    ImmutableList.Builder<RexNode> projects = ImmutableList.builder();
+    // skip the branch index column
+    projects.addAll(Util.first(relBuilder.fields(), originalFieldCnt));
+
+    // On top of the Union, add a Project and add branch cnt number boolean columns
+    //
+    // e.g. LogicalProject(EMPNO=[$0], $f1=[=($1, 0)], $f2=[=($1, 1)], $f3=[=($1, 2)])
+    // $f1,$f2,$f3 are the boolean indicate whether it comes from the corresponding branch
+    for (int i = 0; i < branchCount; i++) {
+      projects.add(
+          relBuilder.equals(relBuilder.field(originalFieldCnt),
+              relBuilder.literal(new BigDecimal(i))));
+    }
+
+    relBuilder.project(projects.build());
+
+    // Add the count(*) filter $f1(..) for each branch
+    ImmutableList.Builder<RelBuilder.AggCall> aggCalls = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      aggCalls.add(relBuilder.countStar(null).filter(relBuilder.field(originalFieldCnt + i)));
+    }
+
+    final ImmutableBitSet groupSet = ImmutableBitSet.range(originalFieldCnt);
+    relBuilder.aggregate(relBuilder.groupKey(groupSet), aggCalls.build());
+
+    ImmutableList.Builder<RexNode> filters = ImmutableList.builder();
+    for (int i = 0; i < branchCount; i++) {
+      SqlOperator operator =
+          i == 0
+              ? SqlStdOperatorTable.GREATER_THAN
+              : SqlStdOperatorTable.EQUALS;
+      filters
+          .add(
+              rexBuilder.makeCall(operator, relBuilder.field(originalFieldCnt + i),
+              relBuilder.literal(new BigDecimal(0))));
+    }
+
+    relBuilder.filter(filters.build());
+    relBuilder.project(Util.first(relBuilder.fields(), originalFieldCnt));
+    call.transformTo(relBuilder.build());
+  }
+
+  /**
+   * Rule configuration.
+   */
+  @Value.Immutable
+  public interface Config
+      extends RelRule.Config {
+    MinusToDistinctRule.Config DEFAULT = ImmutableMinusToDistinctRule.Config.of()","[{'comment': 'No need for `MinusToDistinctRule.Config`, `Config` alone suffices and makes the code more readable, please fix also below.', 'commenter': 'asolimando'}]"
3367,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -2699,6 +2699,33 @@ private void checkPushJoinThroughUnionOnRightDoesNotMatchSemiOrAntiJoin(JoinRelT
         .check();
   }
 
+  /** Tests {@link org.apache.calcite.rel.rules.MinusToDistinctRule},
+   * which rewrites an {@link Minus} operator with 3 inputs. */
+  @Test void testMinusToDistinct() {
+    final String sql = ""select EMPNO,ENAME,JOB from emp where deptno = 10\n""","[{'comment': 'Nit: can we add a space after commas like in all the other tests? Like `EMPNO, ENAME` etc.?', 'commenter': 'asolimando'}]"
3369,babel/src/test/resources/sql/big-query.iq,"@@ -3657,4 +3915,5 @@ FROM items;
 
 !ok
 
+","[{'comment': 'Did you mean to add this blank line back?', 'commenter': 'tanclary'}, {'comment': ""They popped up with the auto formatting, I'll take it out thanks for pointing out.\r\nDo you know if the IS_NAN ones are valid (taking out the extra space) else I'll remove those too."", 'commenter': 'Anthrino'}, {'comment': 'Those are valid, it should remove blank space at the end of lines. I introduced those. Oops.', 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -355,11 +355,85 @@ public static boolean regexpContains(String value, String regex) {
       Pattern regexp = Pattern.compile(regex);
       return regexp.matcher(value).find();
     } catch (PatternSyntaxException ex) {
-      throw RESOURCE.invalidInputForRegexpContains(ex.getMessage().replace(""\r\n"", "" "")
-          .replace(""\n"", "" "").replace(""\r"", "" "")).ex();
+      throw RESOURCE.invalidRegexInputForRegexpFunctions(ex.getMessage().replace(""\r\n"", "" "")
+              .replace(""\n"", "" "").replace(""\r"", "" ""),","[{'comment': ""We should see if there's a way to avoid having to use all these `.replace()`"", 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -355,11 +355,85 @@ public static boolean regexpContains(String value, String regex) {
       Pattern regexp = Pattern.compile(regex);
       return regexp.matcher(value).find();
     } catch (PatternSyntaxException ex) {
-      throw RESOURCE.invalidInputForRegexpContains(ex.getMessage().replace(""\r\n"", "" "")
-          .replace(""\n"", "" "").replace(""\r"", "" "")).ex();
+      throw RESOURCE.invalidRegexInputForRegexpFunctions(ex.getMessage().replace(""\r\n"", "" "")
+              .replace(""\n"", "" "").replace(""\r"", "" ""),
+          ""REGEXP_CONTAINS"").ex();
     }
   }
 
+  /** SQL {@code REGEXP_EXTRACT(value, regexp[, position[, occurrence]])} function.
+   *  Returns NULL if there is no match, or if position or occurrence are beyond range.
+   *  Returns an exception if regex, position or occurrence are invalid.*/
+  public static @Nullable String regexpExtract(String value, String regex, Integer... params) {","[{'comment': ""is extract just a synonym? you can add it as an alias in `StandardConvertletTable` and then you can refactor/remove a lot this code. You shouldn't need a method for both functions here if they're the same. Let me know if you need more info."", 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -355,11 +355,85 @@ public static boolean regexpContains(String value, String regex) {
       Pattern regexp = Pattern.compile(regex);
       return regexp.matcher(value).find();
     } catch (PatternSyntaxException ex) {
-      throw RESOURCE.invalidInputForRegexpContains(ex.getMessage().replace(""\r\n"", "" "")
-          .replace(""\n"", "" "").replace(""\r"", "" "")).ex();
+      throw RESOURCE.invalidRegexInputForRegexpFunctions(ex.getMessage().replace(""\r\n"", "" "")
+              .replace(""\n"", "" "").replace(""\r"", "" ""),
+          ""REGEXP_CONTAINS"").ex();
     }
   }
 
+  /** SQL {@code REGEXP_EXTRACT(value, regexp[, position[, occurrence]])} function.
+   *  Returns NULL if there is no match, or if position or occurrence are beyond range.
+   *  Returns an exception if regex, position or occurrence are invalid.*/
+  public static @Nullable String regexpExtract(String value, String regex, Integer... params) {
+    return processRegexpExtractOrSubstr(""REGEXP_EXTRACT"", value, regex, params);
+  }
+
+  /** SQL {@code REGEXP_SUBSTR(value, regexp[, position[, occurrence]])} function.
+   *  Returns NULL if there is no match, or if position or occurrence are beyond range.
+   *  Returns an exception if regex, position or occurrence are invalid.*/","[{'comment': 'Add a space here', 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -355,11 +355,85 @@ public static boolean regexpContains(String value, String regex) {
       Pattern regexp = Pattern.compile(regex);
       return regexp.matcher(value).find();
     } catch (PatternSyntaxException ex) {
-      throw RESOURCE.invalidInputForRegexpContains(ex.getMessage().replace(""\r\n"", "" "")
-          .replace(""\n"", "" "").replace(""\r"", "" "")).ex();
+      throw RESOURCE.invalidRegexInputForRegexpFunctions(ex.getMessage().replace(""\r\n"", "" "")
+              .replace(""\n"", "" "").replace(""\r"", "" ""),
+          ""REGEXP_CONTAINS"").ex();
     }
   }
 
+  /** SQL {@code REGEXP_EXTRACT(value, regexp[, position[, occurrence]])} function.
+   *  Returns NULL if there is no match, or if position or occurrence are beyond range.
+   *  Returns an exception if regex, position or occurrence are invalid.*/
+  public static @Nullable String regexpExtract(String value, String regex, Integer... params) {
+    return processRegexpExtractOrSubstr(""REGEXP_EXTRACT"", value, regex, params);
+  }
+
+  /** SQL {@code REGEXP_SUBSTR(value, regexp[, position[, occurrence]])} function.
+   *  Returns NULL if there is no match, or if position or occurrence are beyond range.
+   *  Returns an exception if regex, position or occurrence are invalid.*/
+  public static @Nullable String regexpSubstr(String value, String regex, Integer... params) {
+    return processRegexpExtractOrSubstr(""REGEXP_SUBSTR"", value, regex, params);
+  }
+
+  private static @Nullable String processRegexpExtractOrSubstr(String methodName, String value,","[{'comment': 'once you add one as the alias of the other you can just change this to `regexpExtract` to match other functions', 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -486,6 +483,25 @@ static RelDataType deriveTypeSplit(SqlOperatorBinding operatorBinding,
           OperandTypes.STRING_STRING,
           SqlFunctionCategory.STRING);
 
+  /** The ""REGEXP_EXTRACT(value, regexp[, position[, occurrence]])"" function.
+   * Returns the substring in value that matches the regexp. Returns NULL if there is no match. */
+  @LibraryOperator(libraries = {BIG_QUERY})
+  public static final SqlFunction REGEXP_EXTRACT =
+      SqlBasicFunction.create(""REGEXP_EXTRACT"", ReturnTypes.VARCHAR_NULLABLE,
+          OperandTypes.STRING_STRING_OPTIONAL_INTEGER_OPTIONAL_INTEGER,
+          SqlFunctionCategory.STRING);
+
+  @LibraryOperator(libraries = {MYSQL, ORACLE})
+  public static final SqlFunction REGEXP_REPLACE = new SqlRegexpReplaceFunction();
+
+  /** The ""REGEXP_SUBSTR(value, regexp[, position[, occurrence]])"" function.
+   * Returns the substring in value that matches the regexp. Returns NULL if there is no match. */
+  @LibraryOperator(libraries = {BIG_QUERY})","[{'comment': ""You can just do ` = REGEXP_EXTRACT.withName('REGEXP_SUBSTR')`"", 'commenter': 'tanclary'}]"
3369,site/_docs/reference.md,"@@ -2779,7 +2779,9 @@ BigQuery's type system uses confusingly different names for types and functions:
 | h s | PARSE_URL(urlString, partToExtract [, keyToExtract] ) | Returns the specified *partToExtract* from the *urlString*. Valid values for *partToExtract* include HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. *keyToExtract* specifies which query to extract
 | b | POW(numeric1, numeric2)                        | Returns *numeric1* raised to the power *numeric2*
 | b | REGEXP_CONTAINS(string, regexp)                | Returns whether *string* is a partial match for the *regexp*
+| b | REGEXP_EXTRACT(string, regexp[, position[, occurrence]]) | Returns the substring in *string* that matches the regexp. Returns NULL if there is no match. Use *position* for the start index of search range and *occurrence* for the specific occurence of match in *string*","[{'comment': 'surround with *', 'commenter': 'tanclary'}]"
3369,site/_docs/reference.md,"@@ -2779,7 +2779,9 @@ BigQuery's type system uses confusingly different names for types and functions:
 | h s | PARSE_URL(urlString, partToExtract [, keyToExtract] ) | Returns the specified *partToExtract* from the *urlString*. Valid values for *partToExtract* include HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. *keyToExtract* specifies which query to extract
 | b | POW(numeric1, numeric2)                        | Returns *numeric1* raised to the power *numeric2*
 | b | REGEXP_CONTAINS(string, regexp)                | Returns whether *string* is a partial match for the *regexp*
+| b | REGEXP_EXTRACT(string, regexp[, position[, occurrence]]) | Returns the substring in *string* that matches the regexp. Returns NULL if there is no match. Use *position* for the start index of search range and *occurrence* for the specific occurence of match in *string*
 | m o | REGEXP_REPLACE(string, regexp, rep [, pos [, occurrence [, matchType]]]) | Replaces all substrings of *string* that match *regexp* with *rep* at the starting *pos* in expr (if omitted, the default is 1), *occurrence* means which occurrence of a match to search for (if omitted, the default is 1), *matchType* specifies how to perform matching
+| b | REGEXP_SUBSTR(string, regexp[, position[, occurrence]]) | Synonym for REGEXP_EXTRACT. Returns the substring in *string* that matches the regexp","[{'comment': 'You can drop this part', 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -355,19 +355,88 @@ public static String sha512(ByteString string)  {
   }
 
   /** SQL {@code REGEXP_CONTAINS(value, regexp)} function.
-   * Throws a runtime exception for invalid regular expressions.*/
+   * Throws a runtime exception for invalid regular expressions. */
   public static boolean regexpContains(String value, String regex) {
     try {
       // Uses java.util.regex as a standard for regex processing
       // in Calcite instead of RE2 used by BigQuery/GoogleSQL
       Pattern regexp = Pattern.compile(regex);
       return regexp.matcher(value).find();
     } catch (PatternSyntaxException ex) {
-      throw RESOURCE.invalidInputForRegexpContains(ex.getMessage().replace(""\r\n"", "" "")
-          .replace(""\n"", "" "").replace(""\r"", "" "")).ex();
+      throw RESOURCE.invalidRegexInputForRegexpFunctions(ex.getMessage()
+          .replace(System.lineSeparator(), "" ""), ""REGEXP_CONTAINS"").ex();
     }
   }
 
+  /** SQL {@code REGEXP_EXTRACT(value, regexp)} function.
+   *  Returns NULL if there is no match. Returns an exception if regex is invalid.
+   *  Uses position=1 and occurrence=1 as default values when not specified. */
+  public static @Nullable String regexpExtract(String value, String regex) {
+    return regexpExtract(value, regex, 1, 1);
+  }
+
+  /** SQL {@code REGEXP_EXTRACT(value, regexp, position)} function.
+   *  Returns NULL if there is no match, or if position is beyond range.
+   *  Returns an exception if regex or position is invalid.
+   *  Uses occurrence=1 as default value when not specified. */
+  public static @Nullable String regexpExtract(String value, String regex, int position) {
+    return regexpExtract(value, regex, position, 1);
+  }
+
+  /** SQL {@code REGEXP_EXTRACT(value, regexp, position, occurrence)} function.
+   *  Returns NULL if there is no match, or if position or occurrence are beyond range.
+   *  Returns an exception if regex, position or occurrence are invalid. */
+  public static @Nullable String regexpExtract(String value, String regex, int position,
+      int occurrence) {
+    // Uses java.util.regex as a standard for regex processing
+    // in Calcite instead of RE2 used by BigQuery/GoogleSQL
+    Pattern regexp;
+    String methodName = ""REGEXP_EXTRACT"";
+    try {
+      regexp = Pattern.compile(regex);
+    } catch (PatternSyntaxException ex) {
+      throw RESOURCE.invalidRegexInputForRegexpFunctions(ex.getMessage()
+          .replace(System.lineSeparator(), "" ""), methodName).ex();
+    }
+
+    Matcher matcher = regexp.matcher(value);
+
+    if (position <= 0) {
+      throw RESOURCE.invalidIntegerInputForRegexpFunctions(Integer.toString(position),
+          ""position"", methodName).ex();
+    }
+    if (position > value.length()) {
+      return null;
+    }
+    matcher.region(position - 1, value.length());
+
+    if (occurrence <= 0) {","[{'comment': 'Should we move the checks for `position` and `occurrence` to the top? That way we avoid trying to find the regex or matching it just to find out the arguments are invalid. What do you think?', 'commenter': 'tanclary'}, {'comment': 'On top of that- maybe a good exercise for determining the ordering of the checks could be to run several queries against BQ with multiple errors (i.e. bad position and bad occurrence) and see which error it throws.', 'commenter': 'tanclary'}, {'comment': 'Good point Tanner, technically the matcher is only initialized with the base string and regex at the top, and the pattern matching happens when we call the find() method on line 417, but I also think its better to catch the exceptions first and then initialize it. I had tested the order of errors, will reorganize them to do the exception handling first.', 'commenter': 'Anthrino'}]"
3369,site/_docs/reference.md,"@@ -2783,7 +2783,9 @@ BigQuery's type system uses confusingly different names for types and functions:
 | h s | PARSE_URL(urlString, partToExtract [, keyToExtract] ) | Returns the specified *partToExtract* from the *urlString*. Valid values for *partToExtract* include HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. *keyToExtract* specifies which query to extract
 | b | POW(numeric1, numeric2)                        | Returns *numeric1* raised to the power *numeric2*
 | b | REGEXP_CONTAINS(string, regexp)                | Returns whether *string* is a partial match for the *regexp*
+| b | REGEXP_EXTRACT(string, regexp[, position[, occurrence]]) | Returns the substring in *string* that matches the *regexp*. Returns `NULL` if there is no match. Use *position* for the start index of search range and *occurrence* for the specific occurence of match in *string*","[{'comment': ""Don't think NULL should be quoted based on other usages. \r\n\r\nDo you think you could rewrite to sort of match the `INSTR` description? That might be more simple and is a good example of a function with optional arguments. Let me know what you think."", 'commenter': 'tanclary'}, {'comment': 'Thanks Tanner, but I also saw a couple of instances (MAP_CONCAT, ARRAY_CONCAT) where it was `NULL`, and another few places with returns null in lower case or NULL in upper, what should be the standard here a bit confused.', 'commenter': 'Anthrino'}, {'comment': 'oh interesting. in that case i guess either is fine but it should probably be standardized.', 'commenter': 'tanclary'}]"
3369,site/_docs/reference.md,"@@ -2783,7 +2783,9 @@ BigQuery's type system uses confusingly different names for types and functions:
 | h s | PARSE_URL(urlString, partToExtract [, keyToExtract] ) | Returns the specified *partToExtract* from the *urlString*. Valid values for *partToExtract* include HOST, PATH, QUERY, REF, PROTOCOL, AUTHORITY, FILE, and USERINFO. *keyToExtract* specifies which query to extract
 | b | POW(numeric1, numeric2)                        | Returns *numeric1* raised to the power *numeric2*
 | b | REGEXP_CONTAINS(string, regexp)                | Returns whether *string* is a partial match for the *regexp*
+| b | REGEXP_EXTRACT(string, regexp[, position[, occurrence]]) | Returns the substring in *string* that matches the *regexp*. Returns `NULL` if there is no match. Use *position* for the start index of search range and *occurrence* for the specific occurence of match in *string*
 | m o | REGEXP_REPLACE(string, regexp, rep [, pos [, occurrence [, matchType]]]) | Replaces all substrings of *string* that match *regexp* with *rep* at the starting *pos* in expr (if omitted, the default is 1), *occurrence* means which occurrence of a match to search for (if omitted, the default is 1), *matchType* specifies how to perform matching
+| b | REGEXP_SUBSTR(string, regexp[, position[, occurrence]]) | Synonym for REGEXP_EXTRACT","[{'comment': 'add spaces between the parameter names and `[`', 'commenter': 'tanclary'}]"
3369,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -4568,6 +4568,25 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""regexp_contains(cast(null as varchar), cast(null as varchar))"");
   }
 
+  @Test void testRegexpExtractFunc() {
+    final SqlOperatorFixture f =
+        fixture().setFor(SqlLibraryOperators.REGEXP_EXTRACT).withLibrary(SqlLibrary.BIG_QUERY);
+
+    f.checkString(""regexp_extract('abc def ghi', 'def')"", ""def"", ""VARCHAR NOT NULL"");
+    f.checkString(""regexp_extract('abcadcaecghi', 'a.c', 1, 3)"", ""aec"", ""VARCHAR NOT NULL"");
+    f.checkString(""regexp_extract('abcadcaecghi', 'abc(a.c)')"", ""adc"", ""VARCHAR NOT NULL"");
+    f.checkString(""regexp_extract('55as56664as422', '\\d{3}')"", ""566"", ""VARCHAR NOT NULL"");
+
+    f.checkNull(""regexp_extract('abc def ghi', 'asd')"");
+    f.checkNull(""regexp_extract('abc def ghi', cast(null as varchar))"");","[{'comment': 'Can you add more tests that check the 3rd and 4th args (if they are out of range, null, etc)', 'commenter': 'tanclary'}, {'comment': 'Added those as unit tests in the SqlFunctionsTest and big-query.iq file, i didnt add many here as they seemed redundant at every location should I include some here as well?', 'commenter': 'Anthrino'}, {'comment': 'Good question. I am a bit biased because I write most of my tests in `SqlOperatorTest` when adding a new operator. Might be best to get a second opinion.', 'commenter': 'tanclary'}, {'comment': ""I think it might be best to add some to `SqlOperatorTest` because that seems to serve as the main source of truth for how operators handle their edge cases, I don't necessarily think it's redundant. The operator tests check and showcase that the operator follows the behavior it should, while the function tests show that the actual implementation abides by that behavior as well. What do you think?"", 'commenter': 'tanclary'}, {'comment': 'Sure Tanner, that makes sense we have test cases at each wrapper level so its best to validate at every stage, will add some here.', 'commenter': 'Anthrino'}, {'comment': 'Added additional cases to cover the optional arguments, appreciate the feedback!', 'commenter': 'Anthrino'}]"
3369,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -554,6 +555,7 @@ Builder populate() {
       defineMethod(SPLIT, ""split"", NullPolicy.STRICT);
       defineMethod(PARSE_URL, BuiltInMethod.PARSE_URL.method, NullPolicy.STRICT);
       defineMethod(REGEXP_CONTAINS, ""regexpContains"", NullPolicy.STRICT);
+      defineMethod(REGEXP_EXTRACT, ""regexpExtract"", NullPolicy.STRICT);","[{'comment': 'Julian added a recent commit that makes defining a method using the string name (rather than BuiltInMethod) infeasible. If you rebase on top of upstream/main you should see. If you adjust it to use BuiltInMethod instead then it should work.', 'commenter': 'tanclary'}, {'comment': 'Rebased and aligned! :)', 'commenter': 'Anthrino'}]"
3369,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -260,7 +261,75 @@ static <E> List<E> list() {
     } catch (RuntimeException e) {
       assertThat(
           e.getMessage(), is(""Invalid regular expression for REGEXP_CONTAINS: 'Illegal ""
-              + ""repetition range near "" + ""index 4 {2,1}     ^'""));
+              + ""repetition range near index 4 {2,1}     ^'""));
+    }
+  }
+
+  @Test void testRegexpExtract() {
+","[{'comment': 'nit: Should newline at top of test be removed?', 'commenter': 'tanclary'}]"
3369,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -569,6 +570,8 @@ Builder populate() {
       defineReflective(PARSE_URL, BuiltInMethod.PARSE_URL2.method,
           BuiltInMethod.PARSE_URL3.method);
       defineReflective(REGEXP_CONTAINS, BuiltInMethod.REGEXP_CONTAINS.method);
+      defineReflective(REGEXP_EXTRACT, BuiltInMethod.REGEXP_EXTRACT2.method,","[{'comment': ""Didn't know about this, very cool!"", 'commenter': 'tanclary'}, {'comment': 'New for me too, followed the patterns Julian was using for the other functions.', 'commenter': 'Anthrino'}]"
3369,core/src/test/java/org/apache/calcite/test/SqlFunctionsTest.java,"@@ -254,18 +254,88 @@ static <E> List<E> list() {
       final boolean b = f.regexpContains(""abc def ghi"", ""[z-a]"");
       fail(""expected error, got "" + b);
     } catch (RuntimeException e) {
-      assertThat(e.getMessage(),
-          is(""Invalid regular expression for REGEXP_CONTAINS: 'Illegal ""
-              + ""character range near index"" + "" 3 [z-a]    ^'""));
+      assertThat(
+          e.getMessage(), is(""Invalid regular expression for REGEXP_CONTAINS: 'Illegal ""","[{'comment': 'Is this formatting right?', 'commenter': 'tanclary'}, {'comment': ""It's not throwing any formatting errors, I just removed the extra str concat within the same line as it looked unnecessary"", 'commenter': 'Anthrino'}]"
3373,babel/src/test/resources/sql/big-query.iq,"@@ -3593,5 +3593,61 @@ FROM items;
 
 !ok
 
+#####################################################################
+# CODE_POINTS_TO_BYTES(array<integer>)
+#
+# Takes an array of extended ASCII code points as ARRAY<INT64>
+# and returns BYTES.
+#
+SELECT CODE_POINTS_TO_BYTES(array[65, 66, 67, 68]) as result;
++----------+
+| result   |
++----------+
+| 41424344 |
++----------+
+(1 row)
+
+!ok
+
+SELECT CODE_POINTS_TO_BYTES(array[255, 254, 65, 64]) as result;
++----------+
+| result   |
++----------+
+| fffe4140 |
++----------+
+(1 row)
+
+!ok
 
+SELECT CODE_POINTS_TO_BYTES(null) as result;
++--------+
+| result |
++--------+
+|        |
++--------+
+(1 row)
+
+!ok
+
+SELECT CODE_POINTS_TO_BYTES(array[65, null]) as result;
++--------+
+| result |
++--------+
+|        |
++--------+
+(1 row)
+
+!ok
+
+SELECT CODE_POINTS_TO_BYTES('abc') as result;
+Cannot apply 'CODE_POINTS_TO_BYTES' to arguments of type 'CODE_POINTS_TO_BYTES(<CHAR(3)>)'. Supported form(s): 'CODE_POINTS_TO_BYTES(<ARRAY>)'
+!error
+
+SELECT CODE_POINTS_TO_BYTES(array[-1]) as result;
+Input arguments of CODE_POINTS_TO_BYTES out of range: -1
+!error
+","[{'comment': 'Would you mind moving this to somewhere other than the end of the file? Adding to the end of files can create merge conflict headaches later', 'commenter': 'tanclary'}, {'comment': '+1', 'commenter': 'julianhyde'}]"
3373,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -816,6 +816,33 @@ public static String charFromUtf8(int n) {
     return String.valueOf(Character.toChars(n));
   }
 
+  /**
+   * SQL CODE_POINTS_TO_BYTES function.
+   */
+  public static @Nullable ByteString codePointsToBytes(@Nullable List codePoints) {
+    if (codePoints == null) {
+      return null;
+    }
+    int length = codePoints.size();
+    byte[] bytes = new byte[length];
+    for (int i = 0; i < length; i++) {
+      Object codePoint = codePoints.get(i);","[{'comment': 'Is there a reason to not do `for(Object codePoint : codepoints)`?', 'commenter': 'tanclary'}, {'comment': 'because of `bytes[i] = (byte) cp;`, I need to know the index in the loop for byte array assignment. ', 'commenter': 'macroguo-ghy'}]"
3373,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -816,6 +816,33 @@ public static String charFromUtf8(int n) {
     return String.valueOf(Character.toChars(n));
   }
 
+  /**
+   * SQL CODE_POINTS_TO_BYTES function.
+   */
+  public static @Nullable ByteString codePointsToBytes(@Nullable List codePoints) {
+    if (codePoints == null) {","[{'comment': 'I think you can and should remove the `@Nullable` from `codePoints`. The function should not be called if `codePoints` is null.', 'commenter': 'julianhyde'}, {'comment': 'done.', 'commenter': 'macroguo-ghy'}]"
3373,site/_docs/reference.md,"@@ -2681,6 +2681,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | CEIL(value)                                    | Similar to standard `CEIL(value)` except if *value* is an integer type, the return type is a double
 | m s | CHAR(integer)                                | Returns the character whose ASCII code is *integer* % 256, or null if *integer* &lt; 0
 | b o p | CHR(integer)                               | Returns the character whose UTF-8 code is *integer*
+| b | CODE_POINTS_TO_BYTES(array&lt;integer&gt;)     | Converts an *array&lt;integer&gt;* of extended ASCII code points to bytes, return null if array is null or the element of the array is null","[{'comment': ""I would call the argument `integers`, and describe it 'Converts *integers*, an array of integers between 0 and 255, into a byte string'. `array<integer>` is not how Calcite writes types.\r\n\r\nI would mention that it throws if any element is not between 0 and 255 inclusive; no need to mention that it returns null if `integers` is null."", 'commenter': 'julianhyde'}, {'comment': 'Thanks for your suggestion! I will change the argument name and description.', 'commenter': 'macroguo-ghy'}]"
3373,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -510,6 +510,30 @@ public static SqlOperandTypeChecker variadic(
         }
       };
 
+  public static final SqlSingleOperandTypeChecker ARRAY_OF_INTEGER =
+      new SqlSingleOperandTypeChecker() {
+        @Override public boolean checkSingleOperandType(SqlCallBinding callBinding, SqlNode operand,
+            int iFormalOperand, boolean throwOnFailure) {
+          assert 0 == iFormalOperand;
+          RelDataType type = SqlTypeUtil.deriveType(callBinding, operand);
+          RelDataType componentType =
+              requireNonNull(type.getComponentType(), ""componentType"");
+          if (SqlTypeUtil.isArray(type)
+              && SqlTypeUtil.isIntType(componentType)) {
+            return true;
+          }
+
+          if (throwOnFailure) {
+            throw callBinding.newValidationSignatureError();
+          }
+          return false;
+        }
+
+        @Override public String getAllowedSignatures(SqlOperator op, String opName) {
+          return opName + ""(<INTEGER ARRAY>)"";
+        }
+      };
+","[{'comment': 'Would you like to remove useless blank line?', 'commenter': 'herunkang2018'}, {'comment': 'Done.', 'commenter': 'macroguo-ghy'}]"
3373,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -831,6 +831,30 @@ public static String charFromUtf8(int n) {
     return String.valueOf(Character.toChars(n));
   }
 
+  /**
+   * SQL CODE_POINTS_TO_BYTES function.
+   */
+  public static @Nullable ByteString codePointsToBytes(List codePoints) {
+    int length = codePoints.size();
+    byte[] bytes = new byte[length];
+    for (int i = 0; i < length; i++) {
+      Object codePoint = codePoints.get(i);
+      if (codePoint == null) {
+        return null;
+      }
+      if (codePoint instanceof Number) {
+        long cp = ((Number) codePoint).longValue();
+        if (cp < 0 || cp > 255) {
+          throw new IllegalArgumentException(","[{'comment': 'I would use `CalciteResource` to store the exception string, this is a more uniform approach.', 'commenter': 'herunkang2018'}, {'comment': 'Done.', 'commenter': 'macroguo-ghy'}]"
3373,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -1804,6 +1804,28 @@ void testCastToBoolean(CastType castType, SqlOperatorFixture f) {
         consumer);
   }
 
+  @Test void testCodePointsToBytes() {
+    final SqlOperatorFixture f = fixture()
+        .setFor(SqlLibraryOperators.CODE_POINTS_TO_BYTES, VM_FENNEL, VM_JAVA)
+        .withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkFails(""^code_points_to_bytes('abc')^"",
+        ""Cannot apply 'CODE_POINTS_TO_BYTES' to arguments of type ""
+            + ""'CODE_POINTS_TO_BYTES\\(<CHAR\\(3\\)>\\)'\\. ""
+            + ""Supported form\\(s\\): 'CODE_POINTS_TO_BYTES\\(<ARRAY>\\)'"", false);
+    f.checkFails(""code_points_to_bytes(array[-1])"",
+        ""Input arguments of CODE_POINTS_TO_BYTES out of range: -1"", true);
+    f.checkFails(""code_points_to_bytes(array[2147483648, 1])"",
+        ""Input arguments of CODE_POINTS_TO_BYTES out of range: 2147483648"", true);
+
+    f.checkString(""code_points_to_bytes(array[65,66,67,68])"", ""41424344"", ""VARBINARY NOT NULL"");","[{'comment': 'Minor comment for code format, I would use `array[65, 66, 67, 68]` instead `array[65,66,67,68]` for better code readability.', 'commenter': 'herunkang2018'}, {'comment': 'Done.', 'commenter': 'macroguo-ghy'}]"
3373,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -1804,6 +1804,28 @@ void testCastToBoolean(CastType castType, SqlOperatorFixture f) {
         consumer);
   }
 
+  @Test void testCodePointsToBytes() {
+    final SqlOperatorFixture f = fixture()
+        .setFor(SqlLibraryOperators.CODE_POINTS_TO_BYTES, VM_FENNEL, VM_JAVA)
+        .withLibrary(SqlLibrary.BIG_QUERY);
+    f.checkFails(""^code_points_to_bytes('abc')^"",","[{'comment': ""Would you like to change the `'abc'` to an array literal?"", 'commenter': 'herunkang2018'}, {'comment': 'Good suggestion! I add a new test case for string literals array input.', 'commenter': 'macroguo-ghy'}]"
3373,site/_docs/reference.md,"@@ -2681,6 +2681,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | CEIL(value)                                    | Similar to standard `CEIL(value)` except if *value* is an integer type, the return type is a double
 | m s | CHAR(integer)                                | Returns the character whose ASCII code is *integer* % 256, or null if *integer* &lt; 0
 | b o p | CHR(integer)                               | Returns the character whose UTF-8 code is *integer*
+| b | CODE_POINTS_TO_BYTES(integers)                 | Converts *integers*, an array of integers between 0 and 255 inclusive, throws error if any element is out of range","[{'comment': 'Maybe a small typo, `an array of integers` -> `an array of integer`', 'commenter': 'herunkang2018'}, {'comment': 'I think `an array of integers` is the correct syntax.', 'commenter': 'macroguo-ghy'}]"
3378,babel/src/test/resources/sql/big-query.iq,"@@ -668,6 +668,77 @@ SELECT SAFE_ADD(CAST('NaN' AS DOUBLE), CAST(3 as BIGINT)) as NaN_result;
 (1 row)
 
 !ok
+
+#####################################################################
+# SAFE_DIVIDE
+#
+# SAFE_DIVIDE(value1, value2)","[{'comment': 'Can we have some tests with some expression parameters?\r\n\r\n`SAFE_DIVIDE(1*1, 1-1)`\r\n`SAFE_DIVIDE(1, 1/9223372036854775807)`', 'commenter': 'JiajunBernoulli'}, {'comment': 'Will add these soon, good idea', 'commenter': 'tanclary'}]"
3378,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -7401,6 +7470,87 @@ private static void checkIf(SqlOperatorFixture f) {
     f.checkNull(""safe_multiply(cast(3 as double), cast(null as bigint))"");
   }
 
+  @Test void testSafeSubtractFunc() {","[{'comment': 'JIRA Doc is always popular (not required).', 'commenter': 'JiajunBernoulli'}, {'comment': 'Done', 'commenter': 'tanclary'}]"
3378,babel/src/test/resources/sql/big-query.iq,"@@ -668,6 +668,77 @@ SELECT SAFE_ADD(CAST('NaN' AS DOUBLE), CAST(3 as BIGINT)) as NaN_result;
 (1 row)
 
 !ok
+
+#####################################################################
+# SAFE_DIVIDE","[{'comment': 'It seems that you include both `SAFE_DIVIDE` and `SAFE_SUBTRACT` in this PR?', 'commenter': 'zoudan'}, {'comment': ""Yeah I figured their implementations were similar enough that it might be a bit tedious for reviewers to review two very similar PRs, but I'm happy to split it up if it's easier. What do you think?"", 'commenter': 'tanclary'}, {'comment': 'Two separate PRs look better to me, it would make things more clear.', 'commenter': 'zoudan'}]"
3378,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1859,7 +1983,7 @@ private static boolean safeDouble(double d) {
     // negated MIN and MAX double values, overflow has not occurred. Otherwise,
     // overflow has occurred. Important to note that 'Double.MIN_VALUE' refers to
     // minimum positive value.
-    if (d < Double.MAX_VALUE && d > Double.MIN_VALUE) {
+    if (d < Double.MAX_VALUE && d > Double.MIN_VALUE || d == 0) {","[{'comment': 'Why we have to check `d == 0` here?', 'commenter': 'zoudan'}, {'comment': 'The way I check if a `Double` is ""safe"" or not is by checking whether it falls within the following ranges:\r\n\r\n`Largest Negative Value` < `value` < `Smallest negative value` \r\n\r\nor\r\n\r\n`Smallest positive value` < `value` < `Largest positive value`\r\n\r\nThe exception to this is zero, so I check for that as well.\r\n\r\nLet me know if this makes sense or you think it should be changed.', 'commenter': 'tanclary'}, {'comment': 'Get it. Then how about adjusting it like this: \r\n```\r\nreturn (d < Double.MAX_VALUE && d > Double.MIN_VALUE)\r\n    || (d > -Double.MAX_VALUE && d < -Double.MIN_VALUE)\r\n    || d == 0;\r\n```', 'commenter': 'zoudan'}, {'comment': 'DOne', 'commenter': 'tanclary'}]"
3395,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorUtil.java,"@@ -1309,6 +1311,64 @@ public static boolean isMeasure(SqlNode selectItem) {
     return null;
   }
 
+  /**
+   * When the array element does not equal with the array component type, making explicit casting.
+   *
+   * @param componentType derived array component type
+   * @param opBinding description of call
+   */
+  public static void adjustTypeForArrayConstructor(
+      RelDataType componentType, SqlOperatorBinding opBinding) {
+    if (opBinding instanceof SqlCallBinding) {
+      requireNonNull(componentType, ""array component type"");
+      adjustTypeForMultisetConstructor(
+          componentType, componentType, (SqlCallBinding) opBinding);
+    }
+  }
+
+  /**
+   * When the map key or value does not equal with the map component key type or value type,
+   * making explicit casting.
+   *
+   * @param componentType derived map pair component type
+   * @param opBinding description of call
+   */
+  public static void adjustTypeForMapConstructor(
+      Pair<RelDataType, RelDataType> componentType, SqlOperatorBinding opBinding) {
+    if (opBinding instanceof SqlCallBinding) {
+      requireNonNull(componentType.getKey(), ""map key type"");
+      requireNonNull(componentType.getValue(), ""map value type"");
+      adjustTypeForMultisetConstructor(
+          componentType.getKey(), componentType.getValue(), (SqlCallBinding) opBinding);
+    }
+  }
+
+  private static void adjustTypeForMultisetConstructor(
+      RelDataType evenType, RelDataType oddType, SqlCallBinding sqlCallBinding) {
+    SqlCall call = sqlCallBinding.getCall();
+    List<RelDataType> operandTypes = sqlCallBinding.collectOperandTypes();
+    List<SqlNode> operands = call.getOperandList();
+    RelDataType elementType;
+    for (int i = 0; i < operands.size(); i++) {
+      if (i % 2 == 0) {
+        elementType = evenType;
+      } else {
+        elementType = oddType;
+      }
+      if (operandTypes.get(i).equalsSansFieldNames(elementType)) {","[{'comment': 'can this be rewritten as `if(!operandTypes.get(i)....) { call.setOperand() }`', 'commenter': 'tanclary'}, {'comment': 'yes, good point. fixed. thanks tanner for reviewing.', 'commenter': 'chucheng92'}]"
3395,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorUtil.java,"@@ -1309,6 +1311,64 @@ public static boolean isMeasure(SqlNode selectItem) {
     return null;
   }
 
+  /**
+   * When the array element does not equal with the array component type, making explicit casting.","[{'comment': 'i think you can remove `with` and change making->make', 'commenter': 'tanclary'}, {'comment': 'thanks. fixed.', 'commenter': 'chucheng92'}]"
3395,core/src/test/resources/sql/misc.iq,"@@ -2167,12 +2167,12 @@ select array[1,null,2] as a from (values (1));
 
 values array['a',null,'bcd'],
   array['efgh'];
-+----------------+
-| EXPR$0         |
-+----------------+
-| [a, null, bcd] |
-| [efgh]         |
-+----------------+
++------------------+
+| EXPR$0           |
++------------------+
+| [a  , null, bcd] |","[{'comment': 'Why is there an extra space?', 'commenter': 'JiajunBernoulli'}, {'comment': ""@JiajunBernoulli thanks for reviewing. this is a import change in this PR.\r\n\r\nif we have `array('A', 'AB')`, the derived component type is `char(2)`, the old behavior not cast 'A' to `char(2)` in runtime to match derived component type. The correct behavior let 'A' match the `char(2)`, 'A' cast to `char(2)`, then it will fill with extra spaces by default in calcite.\r\n\r\nThis is calcite and sql standard limitation. Of course, this does look weird, actually calcite has other ways to remove spaces. We can activate `SqlConformanceEnum.PRAGMATIC_2003` to let `shouldConvertRaggedUnionTypesToVarying` be true, it will change array/map char type to varchar type to skip these spaces.\r\n\r\nMore details can be found in javadoc https://github.com/apache/calcite/blob/d9dd3ac8a9f695e111a0a5e77f45b61b90f4b5b6/core/src/main/java/org/apache/calcite/sql/validate/SqlConformance.java#L465C7-L465C7\r\n\r\nI also have added some cases in the PR to show this difference."", 'commenter': 'chucheng92'}, {'comment': '@JiajunBernoulli hi, Jiajun. If you have time, could you help to review it again? thanks', 'commenter': 'chucheng92'}, {'comment': 'Ok, Thank you for your clear explanation.', 'commenter': 'JiajunBernoulli'}]"
3395,core/src/main/java/org/apache/calcite/adapter/enumerable/RexToLixTranslator.java,"@@ -973,6 +973,9 @@ private static Expression scaleIntervalToNumber(
       RelDataType sourceType,
       RelDataType targetType,
       Expression operand) {
+    if (targetType.getSqlTypeName().getFamily() == null) {
+      return operand;
+    }
     switch (requireNonNull(targetType.getSqlTypeName().getFamily(),
         () -> ""SqlTypeFamily for "" + targetType)) {","[{'comment': 'Please rework, and remove code duplication.\r\nExtract `family` into a regular variable, and perform a regular null check. Then `requireNonNull` will not be needed.\r\n\r\nThank you so much for doing so.', 'commenter': 'vlsi'}, {'comment': '@vlsi thanks for reviewing. agree with you. I have fixed it. If you have time, please take a look. thanks', 'commenter': 'chucheng92'}, {'comment': '@vlsi hi, considering [calcite-5960](https://issues.apache.org/jira/browse/CALCITE-5960) has been resolved. Now this PR has nothing to do with it. thanks again.', 'commenter': 'chucheng92'}]"
3395,babel/src/test/resources/sql/big-query.iq,"@@ -1012,9 +1012,9 @@ FROM
 
 SELECT","[{'comment': 'Nit: could we change the commit message to ""Use explicit casting if element type in ARRAY/MAP does not equal derived component type""', 'commenter': 'tanclary'}, {'comment': 'thanks, both updated the Jira name and commit name to this.', 'commenter': 'chucheng92'}]"
3395,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorUtil.java,"@@ -1309,6 +1311,63 @@ public static boolean isMeasure(SqlNode selectItem) {
     return null;
   }
 
+  /**
+   * When the array element does not equal the array component type, make explicit casting.
+   *
+   * @param componentType derived array component type
+   * @param opBinding description of call
+   */
+  public static void adjustTypeForArrayConstructor(
+      RelDataType componentType, SqlOperatorBinding opBinding) {
+    if (opBinding instanceof SqlCallBinding) {
+      requireNonNull(componentType, ""array component type"");
+      adjustTypeForMultisetConstructor(
+          componentType, componentType, (SqlCallBinding) opBinding);
+    }
+  }
+
+  /**
+   * When the map key or value does not equal the map component key type or value type,
+   * make explicit casting.
+   *
+   * @param componentType derived map pair component type
+   * @param opBinding description of call
+   */
+  public static void adjustTypeForMapConstructor(
+      Pair<RelDataType, RelDataType> componentType, SqlOperatorBinding opBinding) {
+    if (opBinding instanceof SqlCallBinding) {
+      requireNonNull(componentType.getKey(), ""map key type"");
+      requireNonNull(componentType.getValue(), ""map value type"");
+      adjustTypeForMultisetConstructor(
+          componentType.getKey(), componentType.getValue(), (SqlCallBinding) opBinding);
+    }
+  }
+
+  private static void adjustTypeForMultisetConstructor(
+      RelDataType evenType, RelDataType oddType, SqlCallBinding sqlCallBinding) {
+    SqlCall call = sqlCallBinding.getCall();
+    List<RelDataType> operandTypes = sqlCallBinding.collectOperandTypes();
+    List<SqlNode> operands = call.getOperandList();
+    RelDataType elementType;
+    for (int i = 0; i < operands.size(); i++) {
+      if (i % 2 == 0) {
+        elementType = evenType;","[{'comment': 'could you explain `even` and `odd` types? I am not sure what that means', 'commenter': 'tanclary'}, {'comment': 'Yes, updated the PR to explain these 2 parameters and gave a example about the usage of this method.', 'commenter': 'chucheng92'}]"
3395,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorUtil.java,"@@ -1309,6 +1311,63 @@ public static boolean isMeasure(SqlNode selectItem) {
     return null;
   }
 
+  /**
+   * When the array element does not equal the array component type, make explicit casting.
+   *
+   * @param componentType derived array component type
+   * @param opBinding description of call
+   */
+  public static void adjustTypeForArrayConstructor(
+      RelDataType componentType, SqlOperatorBinding opBinding) {
+    if (opBinding instanceof SqlCallBinding) {
+      requireNonNull(componentType, ""array component type"");
+      adjustTypeForMultisetConstructor(
+          componentType, componentType, (SqlCallBinding) opBinding);
+    }
+  }
+
+  /**
+   * When the map key or value does not equal the map component key type or value type,
+   * make explicit casting.
+   *
+   * @param componentType derived map pair component type
+   * @param opBinding description of call
+   */
+  public static void adjustTypeForMapConstructor(
+      Pair<RelDataType, RelDataType> componentType, SqlOperatorBinding opBinding) {
+    if (opBinding instanceof SqlCallBinding) {
+      requireNonNull(componentType.getKey(), ""map key type"");
+      requireNonNull(componentType.getValue(), ""map value type"");
+      adjustTypeForMultisetConstructor(
+          componentType.getKey(), componentType.getValue(), (SqlCallBinding) opBinding);
+    }
+  }
+
+  private static void adjustTypeForMultisetConstructor(
+      RelDataType evenType, RelDataType oddType, SqlCallBinding sqlCallBinding) {
+    SqlCall call = sqlCallBinding.getCall();
+    List<RelDataType> operandTypes = sqlCallBinding.collectOperandTypes();
+    List<SqlNode> operands = call.getOperandList();
+    RelDataType elementType;
+    for (int i = 0; i < operands.size(); i++) {
+      if (i % 2 == 0) {
+        elementType = evenType;
+      } else {
+        elementType = oddType;
+      }
+      if (!operandTypes.get(i).equalsSansFieldNames(elementType)) {
+        call.setOperand(i, castTo(operands.get(i), elementType));
+      }
+    }
+  }
+
+  private static SqlNode castTo(SqlNode node, RelDataType type) {","[{'comment': 'Can we javadoc these private methods? It seems that a lot of the actual logic lives within them.', 'commenter': 'tanclary'}, {'comment': 'updated.', 'commenter': 'chucheng92'}]"
3395,core/src/test/java/org/apache/calcite/test/JdbcTest.java,"@@ -8144,10 +8144,9 @@ private void checkGetTimestamp(Connection con) throws SQLException {
    * ClassCastException retrieving from ARRAY that has mixed INTEGER and DECIMAL
    * elements</a>. */
   @Test void testIntAndBigDecimalInArray() {
-    // Result should be ""EXPR$0=[1, 1.1]\n""; [CALCITE-4850] logged.
     CalciteAssert.that()
         .query(""select array[1, 1.1]"")
-        .returns(""EXPR$0=[0E+1, 1.1]\n"");","[{'comment': '@tanclary thanks for patient reviewing! btw, I think we can safely close CALCITE-4850. The result has been corrected.', 'commenter': 'chucheng92'}]"
3416,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -1993,6 +1993,7 @@ private RexNode simplifyOrs(List<RexNode> terms, RexUnknownAs unknownAs) {
     // or 'X IS NOT NULL' if a simplification takes place (because another 'X<>B' is found)
     final Map<RexNode, RexNode> notEqualsComparisonMap = new HashMap<>();
     final RexLiteral trueLiteral = rexBuilder.makeLiteral(true);
+    boolean removeNull = false;","[{'comment': 'I would rather use a flag `hasNullTerm`, and also set it in the `case LITERAL` if the case does not remove it.', 'commenter': 'thomasrebele'}, {'comment': ""I remove this logic because I found `simplifyOrs` method will call `flattenOr` eventually which use a `set` to eliminate duplicates. So we don't need to handle multiple `NULL` literal separately."", 'commenter': 'macroguo-ghy'}]"
3416,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -2060,6 +2060,25 @@ private RexNode simplifyOrs(List<RexNode> terms, RexUnknownAs unknownAs) {
           }
         }
         break;
+      case IS_NOT_TRUE:
+        if (terms.contains(((RexCall) term).getOperands().get(0))) {
+          return trueLiteral;","[{'comment': ""I'm not sure about this; I think safety should still be considered:\r\n```\r\n1/0 or x or (x is not true) \r\n```\r\nI think even if its okay for `x` ; we can't replace it with `true` unless all other parts of the or passes `isSafeExpression` or something similar"", 'commenter': 'kgyrtkirk'}, {'comment': 'Same viewpoint as my other comment.', 'commenter': 'macroguo-ghy'}, {'comment': ""My position on safety is that only CASE has a defined evaluation order. Though we've never really implemented it."", 'commenter': 'julianhyde'}, {'comment': ""Thanks for your explaination, I got your points. \r\nFor the first case `x or not(x)`, I add a new limitation where `x` must be safeExpression.\r\nBut for the second case `a or x or not(x) or b`, I think we can simplify x or not(x) no matter whether `a` and `b` safe or not.\r\nThinking about a simple case: `true or unSafeUdf()`,  calcite will simplify this expression to `true`. And I have tested `select * from t where 1/0 or true` expression in mysql and sparksql, both of them will simpilfy this expression to `true`. And third, in most of programing language(like Java, C++, Python), they always simplify `true or someConditions` to `true` in if clause (A little different, it is Short-circuit OR actully, but we check all items).\r\nSo I think we don't need to care about outside items whether safe or not."", 'commenter': 'macroguo-ghy'}, {'comment': 'I understand your point - and yes that\'s kinda outside the scope of this PR - interesting to know that other systems are discarding them.\r\n\r\n> And third, in most of programing language(like Java, C++, Python),\r\n\r\nI disagree - I think they may not do that; see the following test:\r\n```\r\n    int q=0;\r\n    @Test\r\n    public void asd ( ) {\r\n      RuntimeException e = assertThrows(RuntimeException.class, () ->\r\n      {if(crapMethodWithSideEffects() || crapThrowingException() || true) {\r\n          System.out.println(""yippie"");\r\n        }\r\n      });\r\n      assertEquals(1,q);\r\n    }\r\n    public boolean crapThrowingException() {\r\n      throw new RuntimeException();\r\n    }\r\n    public boolean crapMethodWithSideEffects() {\r\n      q=1;\r\n      return false;\r\n    }\r\n```\r\nyou can try C/C++ I think that will also follow left-to-right in this case; I think the removal of such method may only happen if it could be proved that no sideeffects can occur\r\n\r\nFor the above reasons I have a bad feeling in removing unknown things...', 'commenter': 'kgyrtkirk'}, {'comment': 'Yes, you are correct. In programming languages, the evaluation of `||` follows a left-to-right order. However, in SQL, we need to check all items in the OR condition. So I say it is ""a little different"". \r\nAnd I mentioned a terminology [`Short-circuit OR`](https://chortle.ccsu.edu/java5/Notes/chap40/ch40_8.html), which means if the first condition evaluates to true, the subsequent conditions are not evaluated because the overall result of the OR operation is already determined to be true.\r\nSo I think we are consistent in how programming languages simplify `ORs` :)', 'commenter': 'macroguo-ghy'}]"
3416,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -2060,6 +2060,25 @@ private RexNode simplifyOrs(List<RexNode> terms, RexUnknownAs unknownAs) {
           }
         }
         break;
+      case IS_NOT_TRUE:
+        if (terms.contains(((RexCall) term).getOperands().get(0))) {
+          return trueLiteral;
+        }
+        break;
+      case NOT:
+        RexNode x = ((RexCall) term).getOperands().get(0);
+        if (terms.contains(x)) {
+          if (!x.getType().isNullable()) {
+            return trueLiteral;
+          }
+
+          final RexNode isNotNull =
+              rexBuilder.makeCall(SqlStdOperatorTable.IS_NOT_NULL, x);
+          terms.set(terms.indexOf(x), simplifyIs((RexCall) isNotNull, unknownAs));
+          terms.set(i, rexBuilder.makeNullLiteral(x.getType()));
+          i--;","[{'comment': ""I don't see the reason for this `i--` why its needed?"", 'commenter': 'kgyrtkirk'}, {'comment': 'To simplify `null` literal in next for loop.', 'commenter': 'macroguo-ghy'}]"
3416,core/src/main/java/org/apache/calcite/rex/RexSimplify.java,"@@ -2060,6 +2060,25 @@ private RexNode simplifyOrs(List<RexNode> terms, RexUnknownAs unknownAs) {
           }
         }
         break;
+      case IS_NOT_TRUE:
+        if (terms.contains(((RexCall) term).getOperands().get(0))) {
+          return trueLiteral;
+        }
+        break;
+      case NOT:
+        RexNode x = ((RexCall) term).getOperands().get(0);
+        if (terms.contains(x)) {","[{'comment': 'I think to proceed in both cases `x` must be `isSafeExpression` to remove them', 'commenter': 'kgyrtkirk'}, {'comment': ""@kgyrtkirk Thanks for your review! \r\nAll operands in `OR` operator must be `boolean` type (base on the operand checker), `x` could be `1 / 0 <> 0` but could not be `1 / 0`. So I think wo don't need to care about if `x` safe or not. WDYT?"", 'commenter': 'macroguo-ghy'}, {'comment': ""you've replied to that comment here..that's not great - because I think these are 2 separate issues - but they are somewhat similar.\r\n\r\n`1/0` is not a boolean - my mistake; I just wanted to illustrate the problem quickly\r\n\r\nDon't expect that `1 / 0` will appear as is ... it will be more likely `x / y > 17` which is a boolean; can't be decided at compile time that it will never or always throw exceptions - but still holds the possiblity of an exception because if `y` is `0` it will emit an exception.\r\n\r\nI think the current patch will  remove and simplify unknown udfs away - we don't know for sure that  omitting those calls remove sideeffects or not.\r\n\r\nI think\r\n```\r\nsomeUdf() or someUdf() is not true  ==> true\r\n```\r\nis wrong because it could be a possibly unsafe method - you may not make such transformation; or at least call that method - but I would rather stay on the safe side and not do that either...\r\n\r\nand also\r\n```\r\nsomeUdf() or x or !x ==> true (in case x is not nullable)\r\n```\r\nalmost the same as above - however in this case the unsafe expr is outside\r\n\r\nIn the above cases: what if `someUdf` throws an exception on every invocation? should the query be executed - because we were able to deduce that its return value is irrelevant?\r\n\r\n\r\nCould you please add some illustrative testcases for the above cases?"", 'commenter': 'kgyrtkirk'}, {'comment': ""Thanks for your explaination, I got your points. \r\nFor the first case `x or not(x)`, I add a new limitation where `x` must be safeExpression.\r\nBut for the second case `a or x or not(x) or b`, I think we can simplify `x or not(x)` no matter whether `a` and `b` safe or not.\r\nThinking about a simple case: `true or unSafeUdf()`,  calcite will simplify this expression to `true`. And I have tested `select * from t where 1/0 or true` expression in mysql and sparksql, both of them will simpilfy this expression to `true`. And third, in most of programing language (like Java, C++, Python), they always simplify `true or someConditions` to `true` in if clause (A little different, it is Short-circuit OR actully, but we check all items).\r\nSo I think we don't need to care about outside items whether safe or not."", 'commenter': 'macroguo-ghy'}]"
3416,core/src/test/java/org/apache/calcite/rex/RexProgramTest.java,"@@ -2318,7 +2318,7 @@ trueLiteral, literal(2),
             isTrue(vBool()), literal(1),
             isNotTrue(vBool()), literal(1),
             literal(2)),
-        ""CASE(OR(?0.bool0, IS NOT TRUE(?0.bool0)), 1, 2)"");
+        ""1"");","[{'comment': ':cowboy_hat_face: ', 'commenter': 'kgyrtkirk'}]"
3416,geode/src/test/java/org/apache/calcite/adapter/geode/rel/GeodeAllDataTypesTest.java,"@@ -161,7 +161,7 @@ private CalciteAssert.AssertThat calciteAssert() {
             GeodeAssertions.query(""SELECT stringValue AS stringValue ""
                 + ""FROM /allDataTypesRegion WHERE ""
                 + ""stringValue IN SET('abc', 'def') OR floatValue = 1.5678 ""
-                + ""OR booleanValue <> null""));
+                + ""OR booleanValue = true OR booleanValue = false""));","[{'comment': ""I wonder why this is not getting rewritten - \r\nwhy `booleanValue` isn't considered safe? (it seems like a column to me - isn't it)"", 'commenter': 'kgyrtkirk'}, {'comment': ""In Geodo adapter, all types are represented as JavaType, so all refs will be wrapped with `CAST`.\r\nHowever, `CAST` is not a safe expression as we cannot guarantee the success or failure of the cast in some cases.\r\nFor example:\r\n```sql\r\ncast('2023-03-23' as date) -- success\r\ncast('aaaa' as date) -- fail\r\n```\r\nBoth of these statements attempt to cast a varchar as a date, but the first one is legal while the second one will fail.\r\n\r\nBut I am not familiar with geodo adapters, so I am not very clear why all types are using Java types, I only discovered this during debugging."", 'commenter': 'macroguo-ghy'}]"
3417,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1130,14 +1130,68 @@ public static String charFromUtf8(int n) {
       assert codePoint instanceof Number;
       long cp = ((Number) codePoint).longValue();
       if (cp < 0 || cp > 255) {
-        throw RESOURCE.inputArgumentsOfCodePointsToBytesOutOfRange(cp).ex();
+        throw RESOURCE.inputArgumentsOfFunctionOutOfRange(""CODE_POINTS_TO_BYTES"", cp).ex();","[{'comment': ""Would you mind checking if there are other functions that have a similar error (input out of range?)? I think maybe some of the recently added regex functions have a similar error. It could be a good idea to reduce some redundancy if that's the case."", 'commenter': 'tanclary'}, {'comment': 'I use some keywords like \'out of range\' to search whole project, I find only `atanh` function may throw a out of range exception, I replace old code with `inputArgumentsOfFunctionOutOfRange `. And some other ""out of range exception"" may throw during vaidation phase, I think we don\'t need to change them.', 'commenter': 'macroguo-ghy'}]"
3417,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1130,14 +1130,68 @@ public static String charFromUtf8(int n) {
       assert codePoint instanceof Number;
       long cp = ((Number) codePoint).longValue();
       if (cp < 0 || cp > 255) {
-        throw RESOURCE.inputArgumentsOfCodePointsToBytesOutOfRange(cp).ex();
+        throw RESOURCE.inputArgumentsOfFunctionOutOfRange(""CODE_POINTS_TO_BYTES"", cp).ex();
       }
       bytes[i] = (byte) cp;
     }
 
     return new ByteString(bytes);
   }
 
+  /**
+   * SQL CODE_POINTS_TO_STRING function.
+   */
+  public static @Nullable String codePointsToString(List codePoints) {
+    StringBuilder sb = new StringBuilder();
+    for (Object codePoint: codePoints) {
+      if (codePoint == null) {
+        return null;
+      }
+      assert codePoint instanceof Number;
+      long cp = ((Number) codePoint).longValue();
+      // Each valid code point should fall within the range of [0, 0xD7FF] and [0xE000, 0x10FFFF]
+      if (cp >= 0 && cp <= 0xD7FF || cp >= 0xE000 && cp <= 0x10FFFF) {
+        sb.append(charFromUtf8((int) cp));
+      } else {
+        throw RESOURCE.inputArgumentsOfFunctionOutOfRange(""CODE_POINTS_TO_STRING"", cp).ex();
+      }
+    }
+
+    return sb.toString();
+  }
+
+  /**
+   * SQL TO_CODE_POINTS(string) function.
+   */
+  public static @Nullable List<Integer> toCodePoints(String s) {
+    if (s.length() == 0) {
+      return null;
+    }
+    final ImmutableList.Builder<Integer> builder = new ImmutableList.Builder<>();
+    final int length = s.length();
+    int i = 0;
+    while (i < length) {
+      int cp = s.codePointAt(i);
+      builder.add(cp);
+      i += cp == s.charAt(i) ? 1 : 2;
+    }
+    return builder.build();
+  }
+
+  /**
+   * SQL TO_CODE_POINTS(binary) function.","[{'comment': 'nit: could you check if these javadocs are consistent with other functions that have two signatures (one for strings, one for binary strings)? ', 'commenter': 'tanclary'}, {'comment': 'I replace it with `SQL TO_CODE_POINTS(string) function for binary string.` ', 'commenter': 'macroguo-ghy'}]"
3417,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -1793,6 +1793,22 @@ private static RelDataType deriveTypeMapFromEntries(SqlOperatorBinding opBinding
           OperandTypes.ARRAY_OF_INTEGER,
           SqlFunctionCategory.STRING);
 
+  @LibraryOperator(libraries = {BIG_QUERY})","[{'comment': ""Nit: would you mind adding javadocs here? I know not all of the functions have them but given how many functions we've been adding to Calcite recently I think it would be a good practice to have them well-commented."", 'commenter': 'tanclary'}, {'comment': 'Add some comments for three `code_points` functions.', 'commenter': 'macroguo-ghy'}]"
3417,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -1793,6 +1793,22 @@ private static RelDataType deriveTypeMapFromEntries(SqlOperatorBinding opBinding
           OperandTypes.ARRAY_OF_INTEGER,
           SqlFunctionCategory.STRING);
 
+  @LibraryOperator(libraries = {BIG_QUERY})
+  public static final SqlFunction CODE_POINTS_TO_STRING =
+      SqlBasicFunction.create(""CODE_POINTS_TO_STRING"",
+          ReturnTypes.VARCHAR_NULLABLE,
+          OperandTypes.ARRAY_OF_INTEGER,
+          SqlFunctionCategory.STRING);
+
+  @LibraryOperator(libraries = {BIG_QUERY})
+  public static final SqlFunction TO_CODE_POINTS =
+      SqlBasicFunction.create(""TO_CODE_POINTS"",
+          ReturnTypes.INTEGER","[{'comment': ""Just a question not a comment: I think the answer is yes, but is there a reason you can't use INTEGER_NULLABLE and then transform it to array? is it due to the ordering?"", 'commenter': 'tanclary'}, {'comment': 'The order of transform will affect the return types. \r\n`INTEGER_NULLABLE.andThen(SqlTypeTransforms.TO_ARRAY)` means: an not null array, which element may be null.\r\n`INTEGER.andThen(SqlTypeTransforms.TO_ARRAY).andThen(SqlTypeTransforms.TO_NULLABLE)` means: an array may be null, but its element is not null.\r\n\r\nIn `to_code_points` function, we can not get a result like`[1, NULL, 2, 3]`, the element type of array never be `NULL`, so i use `INTEGER` instead of `INTEGER_NULLABLE`.', 'commenter': 'macroguo-ghy'}, {'comment': 'Ah okay that is what I figured. Thanks for explaining.', 'commenter': 'tanclary'}, {'comment': 'As a follow up, would the `TO_ARRAY_NULLABLE` that could be added here:https://github.com/apache/calcite/pull/3430 be helpful in this case?', 'commenter': 'tanclary'}, {'comment': 'Good suggestion! I add this `SqlTypeTransforms`  as you recommended. But a litter different from #3430, because in #3430, `TO_ARRAY_NULLABLE`  is defined as \r\n`ARG0`\r\n`.andThen(SqlTypeTransforms.TO_ARRAY)`\r\n`.andThen(SqlTypeTransforms.TO_NULLABLE)`, \r\nwhich can not be used in my PR.', 'commenter': 'macroguo-ghy'}]"
3417,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -1130,14 +1130,70 @@ public static String charFromUtf8(int n) {
       assert codePoint instanceof Number;
       long cp = ((Number) codePoint).longValue();
       if (cp < 0 || cp > 255) {
-        throw RESOURCE.inputArgumentsOfCodePointsToBytesOutOfRange(cp).ex();
+        throw RESOURCE.inputArgumentsOfFunctionOutOfRange(
+            ""CODE_POINTS_TO_BYTES"", cp, ""[0, 255]"").ex();
       }
       bytes[i] = (byte) cp;
     }
 
     return new ByteString(bytes);
   }
 
+  /**
+   * SQL CODE_POINTS_TO_STRING function.","[{'comment': 'nit: `CODE_POINTS_TO_STRING(list)` (to match other functions)', 'commenter': 'tanclary'}, {'comment': 'Fixed.', 'commenter': 'macroguo-ghy'}]"
3417,babel/src/test/resources/sql/big-query.iq,"@@ -2029,6 +2029,160 @@ SELECT CODE_POINTS_TO_BYTES(array[2147483648, 1]);
 Input arguments of CODE_POINTS_TO_BYTES out of range: 2147483648
 !error
 
+#####################################################################
+# CODE_POINTS_TO_STRING(array<integer>)
+#
+# Takes an array of Unicode code points as ARRAY<INT64>
+# and returns a STRING.
+#
+SELECT CODE_POINTS_TO_STRING(array[65, 66, 67, 68]) as result;
++--------+
+| result |
++--------+
+| ABCD   |
++--------+
+(1 row)
+
+!ok
+
+SELECT CODE_POINTS_TO_STRING(array[255, 254, 1024, 70000]) as result;
++--------+
+| result |
++--------+
+| ÿþЀ𑅰  |
++--------+
+(1 row)
+
+!ok
+
+SELECT CODE_POINTS_TO_STRING(array[1+2, 3]) as result;
++--------+
+| result |
++--------+
+|      |","[{'comment': 'Why does the spacing look off here, do you know?', 'commenter': 'tanclary'}, {'comment': 'Maybe related to encoding. I copy the ""spaces"" to Sublime Text, the spaces converted to `<0x03><0x03>`', 'commenter': 'macroguo-ghy'}]"
3459,site/_docs/reference.md,"@@ -2769,6 +2769,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | TO_HEX(binary)                                 | Converts *binary* into a hexadecimal varchar
 | b | FROM_HEX(varchar)                              | Converts a hexadecimal-encoded *varchar* into bytes
 | b o | LTRIM(string)                                | Returns *string* with all blanks removed from the start
+| s | MAP(key, value [, key, value]*)                | Returns a map with the given key/value pairs","[{'comment': 'Empty map is a legal functon. Please add `MAP()` to the documentation.', 'commenter': 'macroguo-ghy'}, {'comment': 'yes, good point. I will fix it later.', 'commenter': 'chucheng92'}, {'comment': 'Fixed.', 'commenter': 'chucheng92'}, {'comment': 'Also when referencing the function arguments please surround them with * to remain consistent with other functions', 'commenter': 'tanclary'}, {'comment': 'yes, fixed.', 'commenter': 'chucheng92'}]"
3459,core/src/main/codegen/templates/Parser.jj,"@@ -4886,14 +4886,21 @@ SqlNode MapConstructor() :
 {
     <MAP> { s = span(); }
     (
-        LOOKAHEAD(1)
-        <LPAREN>
-        // by sub query ""MAP (SELECT empno, deptno FROM emp)""
-        e = LeafQueryOrExpr(ExprContext.ACCEPT_QUERY)
-        <RPAREN>
+        (
+            // empty map function call: ""map()""
+            LOOKAHEAD(2)
+            <LPAREN> <RPAREN> { args = SqlNodeList.EMPTY; }
+        |
+            args = ParenthesizedQueryOrCommaList(ExprContext.ACCEPT_ALL)
+        )
         {
-            return SqlStdOperatorTable.MAP_QUERY.createCall(
-                s.end(this), e);
+            if (args.size() == 1 && args.get(0).isA(SqlKind.QUERY)) {
+                // MAP query constructor e.g. ""MAP (SELECT empno, deptno FROM emps)""
+                return SqlStdOperatorTable.MAP_QUERY.createCall(s.end(this), args.get(0));
+            } else {
+                // MAP function e.g. ""MAP(1, 2)"" equivalent to standard ""MAP[1, 2]""
+                return SqlLibraryOperators.MAP.createCall(s.end(this), args.getList());","[{'comment': 'I think we can check if the size of args is an even number.', 'commenter': 'macroguo-ghy'}, {'comment': ""I hope to retain the original parser logic here, because it will be detected later on OperandTypeChecker. And here is similar with spark's array handling and calcite array constructor. pls see: https://github.com/apache/calcite/pull/3141/files\r\n\r\nAnother benefit is that we can use some more human-readable error messages in predefined CalciteResource."", 'commenter': 'chucheng92'}]"
3459,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6604,11 +6605,44 @@ private static void checkIf(SqlOperatorFixture f) {
     // test operands not in same type family.
     f.checkFails(""^map_concat(map[1, null], array[1])^"",
         ""Parameters must be of the same type"", false);
+
+    // 2. check with map function, map(k, v ...)","[{'comment': ""Can you please add some tests with `map()`, like `map_concat(map('foo', 1), map())`, `map_keys(map())` or `cast(map() as MAP<INTEGER, INTEGER>)`.\r\nBecause the type of `map()` is `MAP<UNKNOWN, UNKNOWN>`, I am not sure if unknown component type will cause an error."", 'commenter': 'macroguo-ghy'}, {'comment': 'yes, good point. I will fix it later.', 'commenter': 'chucheng92'}, {'comment': ""updated, but currently calcite not support 'cast(map() as map<string, int>)', so I have added the case in IF block until we support it."", 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -1077,6 +1079,38 @@ private static RelDataType arrayReturnType(SqlOperatorBinding opBinding) {
           SqlLibraryOperators::arrayReturnType,
           OperandTypes.SAME_VARIADIC);
 
+  private static RelDataType mapReturnType(SqlOperatorBinding opBinding) {
+    Pair<@Nullable RelDataType, @Nullable RelDataType> type =
+        getComponentTypes(
+            opBinding.getTypeFactory(), opBinding.collectOperandTypes());
+    return SqlTypeUtil.createMapType(
+        opBinding.getTypeFactory(),
+        requireNonNull(type.left, ""inferred key type""),
+        requireNonNull(type.right, ""inferred value type""),
+        false);
+  }
+
+  private static Pair<@Nullable RelDataType, @Nullable RelDataType> getComponentTypes(
+      RelDataTypeFactory typeFactory,
+      List<RelDataType> argTypes) {
+    // special case, allows empty map
+    if (argTypes.size() == 0) {
+      return Pair.of(typeFactory.createUnknownType(), typeFactory.createUnknownType());","[{'comment': 'There is a subtle difference between `unknown` and `any`, can you please explain why `unknown` is used?', 'commenter': 'macroguo-ghy'}, {'comment': ""because Spark use VOID type when map is empty, the Spark VOID type are equivalent in some degree with calcite UNKNOWN.\r\n\r\nAnd it's similar with current spark ARRAY handling. pls see: https://github.com/apache/calcite/pull/3141/files"", 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/adapter/enumerable/RexImpTable.java,"@@ -873,6 +874,7 @@ Builder populate2() {
       map.put(MAP_VALUE_CONSTRUCTOR, value);
       map.put(ARRAY_VALUE_CONSTRUCTOR, value);
       defineMethod(ARRAY, BuiltInMethod.ARRAYS_AS_LIST.method, NullPolicy.NONE);
+      defineMethod(MAP, BuiltInMethod.MAP_FUNCTION.method, NullPolicy.NONE);","[{'comment': 'should we call it just MAP to be consistent with other functions?', 'commenter': 'tanclary'}, {'comment': 'In fact, there is a MAP object in BuiltInMethod, occupy this name. but yes, if we rename that, we can use MAP. I have updated it. ', 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -5251,6 +5251,17 @@ public static Map mapFromArrays(List keysArray, List valuesArray) {
     return map;
   }
 
+  /** Support the MAP function. */
+  public static Map mapFunction(Object... args) {","[{'comment': 'same comment as above', 'commenter': 'tanclary'}, {'comment': 'fixed.', 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/runtime/SqlFunctions.java,"@@ -5251,6 +5251,17 @@ public static Map mapFromArrays(List keysArray, List valuesArray) {
     return map;
   }
 
+  /** Support the MAP function. */
+  public static Map mapFunction(Object... args) {
+    final Map map = new LinkedHashMap<>();
+    for (int i = 0; i < args.length; i++) {
+      Object key = args[i++];","[{'comment': 'Could be helpful to add a comment explaining the odd elements are keys and the even elements are values.', 'commenter': 'tanclary'}, {'comment': 'yes, updated.', 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/sql/fun/SqlLibraryOperators.java,"@@ -1082,6 +1084,38 @@ private static RelDataType arrayReturnType(SqlOperatorBinding opBinding) {
           SqlLibraryOperators::arrayReturnType,
           OperandTypes.SAME_VARIADIC);
 
+  private static RelDataType mapReturnType(SqlOperatorBinding opBinding) {
+    Pair<@Nullable RelDataType, @Nullable RelDataType> type =
+        getComponentTypes(
+            opBinding.getTypeFactory(), opBinding.collectOperandTypes());
+    return SqlTypeUtil.createMapType(
+        opBinding.getTypeFactory(),
+        requireNonNull(type.left, ""inferred key type""),
+        requireNonNull(type.right, ""inferred value type""),
+        false);
+  }
+
+  private static Pair<@Nullable RelDataType, @Nullable RelDataType> getComponentTypes(
+      RelDataTypeFactory typeFactory,
+      List<RelDataType> argTypes) {
+    // special case, allows empty map
+    if (argTypes.size() == 0) {","[{'comment': 'should we use `isEmpty()` instead?', 'commenter': 'tanclary'}]"
3459,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -568,6 +569,9 @@ public static SqlOperandTypeChecker variadic(
   public static final SqlSingleOperandTypeChecker MAP_FROM_ENTRIES =
       new MapFromEntriesOperandTypeChecker();
 
+  public static final SqlSingleOperandTypeChecker MAP_FUNCTION =","[{'comment': 'same naming comment as above', 'commenter': 'tanclary'}, {'comment': 'fixed.', 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -1221,6 +1225,53 @@ private static class MapFromEntriesOperandTypeChecker
     }
   }
 
+  /**
+   * Operand type-checking strategy for a MAP function, it allows empty map.
+   */
+  private static class MapFunctionOperandTypeChecker
+      extends SameOperandTypeChecker {
+
+    MapFunctionOperandTypeChecker() {
+      super(-1);","[{'comment': 'where does the -1 come from?', 'commenter': 'tanclary'}, {'comment': ""The args of map are non-fixed, so we set to -1 here. then `operandCount`\r\ncan dynamically set according to the number of input args. \r\n\r\nI've added some comments here for better readability."", 'commenter': 'chucheng92'}]"
3459,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -1221,6 +1225,53 @@ private static class MapFromEntriesOperandTypeChecker
     }
   }
 
+  /**
+   * Operand type-checking strategy for a MAP function, it allows empty map.
+   */
+  private static class MapFunctionOperandTypeChecker
+      extends SameOperandTypeChecker {
+
+    MapFunctionOperandTypeChecker() {
+      super(-1);
+    }
+
+    @Override public boolean checkOperandTypes(final SqlCallBinding callBinding,
+        final boolean throwOnFailure) {
+      final List<RelDataType> argTypes =
+          SqlTypeUtil.deriveType(callBinding, callBinding.operands());
+      // allows empty map
+      if (argTypes.size() == 0) {","[{'comment': '`isEmpty()`', 'commenter': 'tanclary'}]"
3459,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -1221,6 +1225,53 @@ private static class MapFromEntriesOperandTypeChecker
     }
   }
 
+  /**
+   * Operand type-checking strategy for a MAP function, it allows empty map.
+   */
+  private static class MapFunctionOperandTypeChecker
+      extends SameOperandTypeChecker {
+
+    MapFunctionOperandTypeChecker() {
+      super(-1);
+    }
+
+    @Override public boolean checkOperandTypes(final SqlCallBinding callBinding,
+        final boolean throwOnFailure) {
+      final List<RelDataType> argTypes =
+          SqlTypeUtil.deriveType(callBinding, callBinding.operands());
+      // allows empty map
+      if (argTypes.size() == 0) {
+        return true;
+      }
+      // the size of map arg types must be even.
+      if (argTypes.size() % 2 > 0) {","[{'comment': 'is the condition more clear if we say `argTypes.size() % 2 != 0`', 'commenter': 'tanclary'}]"
3459,core/src/main/java/org/apache/calcite/sql/type/OperandTypes.java,"@@ -1221,6 +1225,53 @@ private static class MapFromEntriesOperandTypeChecker
     }
   }
 
+  /**
+   * Operand type-checking strategy for a MAP function, it allows empty map.
+   */
+  private static class MapFunctionOperandTypeChecker
+      extends SameOperandTypeChecker {
+
+    MapFunctionOperandTypeChecker() {
+      super(-1);
+    }
+
+    @Override public boolean checkOperandTypes(final SqlCallBinding callBinding,
+        final boolean throwOnFailure) {
+      final List<RelDataType> argTypes =
+          SqlTypeUtil.deriveType(callBinding, callBinding.operands());
+      // allows empty map
+      if (argTypes.size() == 0) {
+        return true;
+      }
+      // the size of map arg types must be even.
+      if (argTypes.size() % 2 > 0) {
+        throw callBinding.newValidationError(RESOURCE.mapRequiresEvenArgCount());
+      }
+      final Pair<@Nullable RelDataType, @Nullable RelDataType> componentType =
+          getComponentTypes(
+              callBinding.getTypeFactory(), argTypes);
+      // check key type & value type
+      if (null == componentType.left || null == componentType.right) {
+        if (throwOnFailure) {
+          throw callBinding.newValidationError(RESOURCE.needSameTypeParameter());
+        }
+        return false;
+      }
+      return true;
+    }
+
+    /**
+     * Extract the key type and value type of arg types.
+     */
+    private static Pair<@Nullable RelDataType, @Nullable RelDataType> getComponentTypes(
+        RelDataTypeFactory typeFactory,
+        List<RelDataType> argTypes) {
+      return Pair.of(
+          typeFactory.leastRestrictive(Util.quotientList(argTypes, 2, 0)),","[{'comment': 'Where are these constants coming from and what do they signify?', 'commenter': 'tanclary'}, {'comment': ""Util.quotientList(argTypes, 2, 0):\r\nThis extracts all elements at even indices from argTypes.\r\nIt represents the types of keys in the map as they are placed at even positions\r\ne.g. 0, 2, 4, etc. details please see Util.quotientList.\r\n\r\nstd MapValueConstructor has same logic. see: https://github.com/apache/calcite/blob/5151168e9a9035595939c2ae0f21a06984229209/core/src/main/java/org/apache/calcite/sql/fun/SqlMapValueConstructor.java#L90\r\n\r\nI've added some comments here for better readability. "", 'commenter': 'chucheng92'}]"
3459,site/_docs/reference.md,"@@ -2769,6 +2769,8 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b | TO_HEX(binary)                                 | Converts *binary* into a hexadecimal varchar
 | b | FROM_HEX(varchar)                              | Converts a hexadecimal-encoded *varchar* into bytes
 | b o | LTRIM(string)                                | Returns *string* with all blanks removed from the start
+| s | MAP()                                          | Returns a empty map","[{'comment': 'nit: an', 'commenter': 'tanclary'}]"
3459,testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java,"@@ -6703,11 +6704,53 @@ private static void checkIf(SqlOperatorFixture f) {
     // test operands not in same type family.
     f.checkFails(""^map_concat(map[1, null], array[1])^"",
         ""Parameters must be of the same type"", false);
+
+    // 2. check with map function, map(k, v ...)
+    final SqlOperatorFixture f1 = fixture()
+        .setFor(SqlLibraryOperators.MAP_CONCAT)
+        .withLibrary(SqlLibrary.SPARK);
+    f1.checkScalar(""map_concat(map('foo', 1), map('bar', 2))"", ""{foo=1, bar=2}"",
+        ""(CHAR(3) NOT NULL, INTEGER NOT NULL) MAP NOT NULL"");
+    f1.checkScalar(""map_concat(map('foo', 1), map('bar', 2), map('foo', 2))"", ""{foo=2, bar=2}"",
+        ""(CHAR(3) NOT NULL, INTEGER NOT NULL) MAP NOT NULL"");
+    f1.checkScalar(""map_concat(map(null, 1), map(null, 2))"", ""{null=2}"",
+        ""(NULL, INTEGER NOT NULL) MAP NOT NULL"");
+    f1.checkScalar(""map_concat(map(1, 2), map(1, null))"", ""{1=null}"",
+        ""(INTEGER NOT NULL, INTEGER) MAP NOT NULL"");
+    // test zero arg, but it should return empty map.
+    f1.checkScalar(""map_concat()"", ""{}"",
+        ""(VARCHAR NOT NULL, VARCHAR NOT NULL) MAP"");
+
+    // test concat with empty map, in fact, spark will return MAP(CHAR, INTEGER), because
+    // it will add a cast 'cast(map() as map<string, int>)' to convert UNKNOWN type,
+    // but currently calcite not support cast to map type.
+    f1.checkScalar(""map_concat(map('foo', 1), map())"", ""{foo=1}"",
+        ""(UNKNOWN NOT NULL, UNKNOWN NOT NULL) MAP NOT NULL"");
+
+    // after calcite supports cast(null as map<string, int>), cast(map() as map<string, int>)
+    // it should add these tests.
+    if (TODO) {","[{'comment': 'instead of `if (TODO)` would it be better to add an enum to the `Bug` class? Here is an example of what I mean: https://github.com/apache/calcite/blob/main/testkit/src/main/java/org/apache/calcite/test/SqlOperatorTest.java#L624\r\n', 'commenter': 'tanclary'}, {'comment': 'I get your point. but I have noticed that CALCITE-5570 has supported cast to map. So these cases can work now. I have removed the IF(TODO).', 'commenter': 'chucheng92'}]"
3480,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableRepeatUnionTest.java,"@@ -45,6 +45,17 @@
  */
 class EnumerableRepeatUnionTest {
 
+  @Test void testGenerateNumbersUsingSql() {
+    CalciteAssert.that()
+        .query(""WITH RECURSIVE delta(n) AS (\n""
+            + ""  VALUES (1)\n""
+            + "" UNION ALL\n""","[{'comment': ""shouldn't UNION ALL actually never converge?\r\nWhy isn't the result collection a multiset that grows infinitely?"", 'commenter': 'mihaibudiu'}, {'comment': '@mihaibudiu the `WHERE n < 10` breaks the ""infinite growth"". We get the same behavior [in e.g. PostgreSQL](http://sqlfiddle.com/#!17/9eecb/111270)', 'commenter': 'rubenada'}, {'comment': 'The `WHERE` breaks the growth in the value of n, but UNION would break the growth in cardinality. \r\nUNION ALL should produce a multiset, so you should get the following values in `delta` in successive iterations: [1], [1, 2], [1, 2, 2, 3], [1, 2, 2, 2, 3, 3, 4] etc in your relation in successive iterations. I understand how this should work with `UNION`, but not with `UNION ALL`. Why is delta a set and not a multiset?\r\n', 'commenter': 'mihaibudiu'}, {'comment': ""@mihaibudiu  Thanks for reviewing the changes. I agree with @rubenada regarding the explanation as to why this use case doesn't run into infinite growth. I believe in general that semantics of UNION / UNION ALL are subtle in Recursive queries. \r\n\r\nHere is an example (again from postgresql) where usage of the union all (http://sqlfiddle.com/#!17/9eecb/111278) will run into infinite loop but usage of union works fine.\r\nThe infinite loop for the above example actually is because of the result set being a multi set when union all is used.\r\n\r\n\r\n"", 'commenter': 'HanumathRao'}, {'comment': 'More info about how RECURSIVE UNION [ALL] works internally can be found here:\r\nhttps://www.postgresql.org/docs/current/queries-with.html#QUERIES-WITH-RECURSIVE\r\nCalcite implementation was heavily inspired by this postgresql description.\r\n', 'commenter': 'rubenada'}]"
3480,core/src/main/java/org/apache/calcite/sql2rel/SqlToRelConverter.java,"@@ -3774,6 +3791,48 @@ protected RelRoot convertQueryRecursive(SqlNode query, boolean top,
     }
   }
 
+  public static boolean hasATableScanWithName(RelNode root, final String recurTableName) {","[{'comment': 'There is a RelOptTableFinder class inside RelBuider which seems to have the same purpose. Currently it is private static, but perhaps it could be moved to another localion (RelOptUtil?) as a public element, and reuse the same code here and in RelBuilder.', 'commenter': 'rubenada'}]"
3480,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableRepeatUnionTest.java,"@@ -70,6 +81,47 @@ class EnumerableRepeatUnionTest {
         .returnsOrdered(""i=1"", ""i=2"", ""i=3"", ""i=4"", ""i=5"", ""i=6"", ""i=7"", ""i=8"", ""i=9"", ""i=10"");
   }
 
+  @Test void testGenerateNumbers2UsingSql() {
+    CalciteAssert.that()
+        .query(""WITH RECURSIVE aux(i) AS (\n""
+            + ""     VALUES (0)""
+            + ""     UNION ""
+            + ""     SELECT MOD((i+1), 10) FROM aux WHERE i < 10""
+            + ""  )""
+            + ""   SELECT * FROM aux\n"")
+        .returnsOrdered(""I=0"", ""I=1"", ""I=2"", ""I=3"", ""I=4"", ""I=5"", ""I=6"", ""I=7"", ""I=8"", ""I=9"");
+  }
+
+  @Test void testGenerateNumbers2UsingSqlCheckPlan() {
+    CalciteAssert.that()
+        .with(CalciteConnectionProperty.LEX, Lex.JAVA)
+        .with(CalciteConnectionProperty.FORCE_DECORRELATE, false)
+        .withSchema(""s"", new ReflectiveSchema(new HierarchySchema()))
+        .withHook(Hook.PLANNER, (Consumer<RelOptPlanner>) planner -> {","[{'comment': 'Do we really need the Hook.PLANNER for this test? It adds/removes join-related rules, but the query does not have any join....', 'commenter': 'rubenada'}]"
3480,core/src/test/java/org/apache/calcite/test/SqlValidatorTest.java,"@@ -5232,6 +5232,39 @@ void testReturnsCorrectRowTypeOnCombinedJoin() {
         + ""select * from emp2"")
         .type(EMP_RECORD_TYPE);
 
+    // simplest with recursive fails
+    sql(""with RECURSIVE emp2 as (select * from ^emp2^)\n""
+        + ""select * from emp2"")
+        .fails(""Object 'EMP2' not found"");
+
+    sql(""with RECURSIVE emp2 as (""
+        + ""select * from emp ""
+        + "" union select * from ^emp2^""
+        + "" union select * from emp2""
+        + "")\n""
+        + ""select * from emp2"")
+        .fails(""Object 'EMP2' not found"");
+
+    // simplest with RECURSIVE working case.
+    sql(""with RECURSIVE emp2 as (select * from emp union select * from emp2)\n""
+        + ""select * from emp2"")
+        .type(EMP_RECORD_TYPE);
+
+    // union all with recursive working case.
+    sql(""with RECURSIVE emp2 as (select * from emp union all select * from emp2)\n""
+        + ""select * from emp2"")
+        .type(EMP_RECORD_TYPE);
+
+    // union all with recursive working case.","[{'comment': 'minor: this comment seems wrong (""working case"" but the test actually checks for a failure)', 'commenter': 'rubenada'}]"
3480,core/src/main/resources/org/apache/calcite/runtime/CalciteResource.properties,"@@ -63,6 +63,8 @@ IncompatibleValueType=Values passed to {0} operator must have compatible types
 IncompatibleTypesInList=Values in expression list must have compatible types
 IncompatibleCharset=Cannot apply {0} to the two different charsets {1} and {2}
 InvalidOrderByPos=ORDER BY is only allowed on top-level SELECT
+RecursiveWithMustHaveUnionSetOp=A recursive query only supports UNION [ALL] operator","[{'comment': 'Would it be possible to have unit tests forcing to have these two error messages?', 'commenter': 'rubenada'}, {'comment': 'These errors are protected by ""Object not found"", currently it is very hard to hit these errors but I thought it is good to protect code path in regards to any future changes with scope etc.\r\n\r\nPlease let me know if you think these are redundant, then I can remove them.', 'commenter': 'HanumathRao'}, {'comment': 'ok, np', 'commenter': 'rubenada'}]"
3480,core/src/main/java/org/apache/calcite/sql/SqlWithItem.java,"@@ -30,13 +30,16 @@
 public class SqlWithItem extends SqlCall {
   public SqlIdentifier name;
   public @Nullable SqlNodeList columnList; // may be null
+  public SqlLiteral recursive;
   public SqlNode query;
 
   public SqlWithItem(SqlParserPos pos, SqlIdentifier name,
-      @Nullable SqlNodeList columnList, SqlNode query) {
+      @Nullable SqlNodeList columnList, SqlNode query,
+      SqlLiteral recursive) {","[{'comment': 'Do we want to keep previous constructor for backward compatibility purposes? Please check other SqlNode classes and check if we are using a deprecation pattern.', 'commenter': 'zabetak'}]"
3480,core/src/test/java/org/apache/calcite/test/RelOptRulesTest.java,"@@ -7487,6 +7487,21 @@ private void checkSemiJoinRuleOnAntiJoin(RelOptRule rule) {
         .checkUnchanged();
   }
 
+  @Test void testRecursiveQuery() {
+    final String sql = ""WITH RECURSIVE aux(i) AS (\n""
+        + ""  VALUES (1)\n""
+        + ""  UNION ALL\n""
+        + ""  SELECT i+1 FROM aux WHERE i < 10\n""
+        + "")\n""
+        + ""SELECT * FROM aux"";
+
+    sql(sql)
+        .withLateDecorrelate(true)
+        .withTrim(true)
+        .withRule() // empty program
+        .checkUnchanged();
+  }
+","[{'comment': 'We are not testing any rules here so the test seems misplaced. Consider removing it.', 'commenter': 'zabetak'}, {'comment': 'This seems like a test that should be added in `SqlToRelConverterTest` class.', 'commenter': 'zabetak'}]"
3480,core/src/test/java/org/apache/calcite/test/enumerable/EnumerableRepeatUnionTest.java,"@@ -45,6 +45,17 @@
  */
 class EnumerableRepeatUnionTest {
 
+  @Test void testGenerateNumbersUsingSql() {","[{'comment': 'The new tests added here are basically testing recursive queries end-to-end. For end-to-end tests it is better to use the .iq files so consider moving the tests in `recursive_queries.iq` and remove them from here unless there is a specific reason to have them here. ', 'commenter': 'zabetak'}]"
3480,site/_docs/algebra.md,"@@ -309,10 +309,6 @@ LogicalRepeatUnion(all=[true])
         LogicalTableScan(table=[[aux]])
 {% endhighlight %}
 
-Note that there is no support for recursive queries in the SQL layer yet
-([CALCITE-129](https://issues.apache.org/jira/browse/CALCITE-129));
-the `WITH RECURSIVE` query above is only for illustrative purposes.
-","[{'comment': 'I think the https://calcite.apache.org/docs/reference.html part of the documentation should be updated as well to reflect the new changes.', 'commenter': 'zabetak'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/WithItemRecursiveNameSpace.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.validate;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.sql.SqlBasicCall;
+import org.apache.calcite.sql.SqlIdentifier;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlNode;
+import org.apache.calcite.sql.SqlNodeList;
+import org.apache.calcite.sql.SqlWith;
+import org.apache.calcite.sql.SqlWithItem;
+import org.apache.calcite.sql.parser.SqlParserPos;
+import org.apache.calcite.util.Pair;
+
+import org.checkerframework.checker.nullness.qual.Nullable;
+
+/** Very similar to {@link WithItemNamespace} but created only for RECURSIVE queries. */
+public class WithItemRecursiveNameSpace extends WithItemNamespace {","[{'comment': 'Should the class be `public`?', 'commenter': 'zabetak'}]"
3480,core/src/main/java/org/apache/calcite/plan/RelOptUtil.java,"@@ -3304,6 +3305,29 @@ public static RelNode createProject(RelNode child, Mappings.TargetMapping mappin
     return createProject(projectFactory, child, Mappings.asListNonNull(mapping.inverse()));
   }
 
+  /** Returns the relational table node for {@code tableName} if it occurs within a
+   * relational expression {@code root} otherwise an empty option is returned. */
+  public static Optional<RelOptTable> findTable(RelNode root, final String tableName) {","[{'comment': ""I don't think we use `Optional` much in the project. I don't have a strong opinion for using it here or not but it seems that all the other methods in this class are simply returning null so for keeping things more consistent I would not add the wrapper."", 'commenter': 'zabetak'}]"
3480,core/src/main/java/org/apache/calcite/sql/SqlWith.java,"@@ -96,6 +96,10 @@ private SqlWithOperator() {
       final SqlWith with = (SqlWith) call;
       final SqlWriter.Frame frame =
           writer.startList(SqlWriter.FrameTypeEnum.WITH, ""WITH"", """");
+      boolean isRecursive = ((SqlWithItem) with.withList.get(0)).recursive.booleanValue();
+      if (isRecursive) {
+        writer.keyword("" RECURSIVE "");","[{'comment': 'We don\'t need to add space, just ` writer.keyword(""RECURSIVE"");`', 'commenter': 'macroguo-ghy'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3099,9 +3100,23 @@ private void registerSetop(
 
     // A setop is in the same scope as its parent.
     scopes.put(call, parentScope);
-    for (SqlNode operand : call.getOperandList()) {
+    @NonNull SqlValidatorScope recursiveScope = parentScope;
+    if (enclosingNode.getKind() == SqlKind.WITH_ITEM) {
+      if (node.getKind() != SqlKind.UNION) {","[{'comment': 'Did you not check if the with item is recursive, was it intentional? \r\nCan you give me a test like \r\n```\r\nwith t as (select 1 union select 2)\r\nselect * from t;\r\n```\r\nAnd I think we should implement this validation logic in `org.apache.calcite.sql.validate.WithItemNamespace#validateImpl` or `org.apache.calcite.sql.validate.SetopNamespace#validateImpl` instead of `registerSetop`. WDYT?', 'commenter': 'macroguo-ghy'}, {'comment': 'The recursive flag is not explicitly checked here because for only recursive queries we pass WITH_ITEM as enclosed node(essentially it is kind of an implicit check). For non recursive queries we pass the original enclosed node which is either WITH or its parent. \r\n\r\n`And I think we should implement this validation logic in org.apache.calcite.sql.validate.WithItemNamespace#validateImpl or org.apache.calcite.sql.validate.SetopNamespace#validateImpl instead of registerSetop. WDYT?`\r\n\r\nAs regards to the validation logic implementation I did go that path but I think code is getting messy. I thought if we can create a WithRecursive* classes for these we could do custom logic for recursive queries alone.', 'commenter': 'HanumathRao'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3099,9 +3100,23 @@ private void registerSetop(
 
     // A setop is in the same scope as its parent.
     scopes.put(call, parentScope);
-    for (SqlNode operand : call.getOperandList()) {
+    @NonNull SqlValidatorScope recursiveScope = parentScope;
+    if (enclosingNode.getKind() == SqlKind.WITH_ITEM) {
+      if (node.getKind() != SqlKind.UNION) {
+        throw newValidationError(node, RESOURCE.recursiveWithMustHaveUnionSetOp());
+      } else if (call.getOperandList().size() > 2) {
+        throw newValidationError(node, RESOURCE.recursiveWithMustHaveTwoChildUnionSetOp());
+      }
+      WithScope scope = (WithScope) scopes.get(enclosingNode);","[{'comment': 'Make variable `final` as much as possiable.', 'commenter': 'macroguo-ghy'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/WithItemRecursiveNameSpace.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.validate;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.sql.SqlBasicCall;
+import org.apache.calcite.sql.SqlIdentifier;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlNode;
+import org.apache.calcite.sql.SqlNodeList;
+import org.apache.calcite.sql.SqlWith;
+import org.apache.calcite.sql.SqlWithItem;
+import org.apache.calcite.sql.parser.SqlParserPos;
+import org.apache.calcite.util.Pair;
+
+import org.checkerframework.checker.nullness.qual.Nullable;
+
+/** Very similar to {@link WithItemNamespace} but created only for RECURSIVE queries. */
+class WithItemRecursiveNameSpace extends WithItemNamespace {
+  private final SqlWithItem withItem;
+  private final SqlWithItemTableRef withItemTableRef;
+  WithItemRecursiveNameSpace(SqlValidatorImpl validator,
+      SqlWithItem withItem,
+      @Nullable SqlNode enclosingNode) {
+    super(validator, withItem, enclosingNode);
+    this.withItem = withItem;
+    this.withItemTableRef = new SqlWithItemTableRef(SqlParserPos.ZERO, withItem);
+  }
+
+  @Override public RelDataType getRowType() {
+    if (rowType == null) {
+      SqlBasicCall call;
+      if (this.withItem.query.getKind() == SqlKind.WITH) {
+        call = (SqlBasicCall) ((SqlWith) this.withItem.query).body;
+      } else {
+        call = (SqlBasicCall) this.withItem.query;
+      }
+      // As this is a recursive query we only should evaluate left child for getting the rowType.
+      RelDataType leftChildType =
+          validator.getNamespaceOrThrow(
+              call.operand(0)).getRowType();
+      SqlNodeList columnList = withItem.columnList;
+      if (columnList == null || columnList.size() == 0) {
+        // This should never happen but added to protect against the NullPointerException.
+        return leftChildType;
+      }
+      final RelDataTypeFactory.Builder builder =
+          validator.getTypeFactory().builder();
+      Pair.forEach(SqlIdentifier.simpleNames(columnList),
+          leftChildType.getFieldList(),
+          (name, field) -> builder.add(name, field.getType()));
+      rowType = builder.build();","[{'comment': ""We don't need to set the `rowtype`. Method `org.apache.calcite.sql.validate.AbstractNamespace#validate` will help us do this."", 'commenter': 'macroguo-ghy'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/WithItemRecursiveNameSpace.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.validate;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.sql.SqlBasicCall;
+import org.apache.calcite.sql.SqlIdentifier;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlNode;
+import org.apache.calcite.sql.SqlNodeList;
+import org.apache.calcite.sql.SqlWith;
+import org.apache.calcite.sql.SqlWithItem;
+import org.apache.calcite.sql.parser.SqlParserPos;
+import org.apache.calcite.util.Pair;
+
+import org.checkerframework.checker.nullness.qual.Nullable;
+
+/** Very similar to {@link WithItemNamespace} but created only for RECURSIVE queries. */
+class WithItemRecursiveNameSpace extends WithItemNamespace {","[{'comment': 'Use `Namespace`.', 'commenter': 'macroguo-ghy'}, {'comment': ""Agreed. (@HanumathRao, note lower-case 's'.)"", 'commenter': 'julianhyde'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/WithItemRecursiveNameSpace.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to you under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.calcite.sql.validate;
+
+import org.apache.calcite.rel.type.RelDataType;
+import org.apache.calcite.rel.type.RelDataTypeFactory;
+import org.apache.calcite.sql.SqlBasicCall;
+import org.apache.calcite.sql.SqlIdentifier;
+import org.apache.calcite.sql.SqlKind;
+import org.apache.calcite.sql.SqlNode;
+import org.apache.calcite.sql.SqlNodeList;
+import org.apache.calcite.sql.SqlWith;
+import org.apache.calcite.sql.SqlWithItem;
+import org.apache.calcite.sql.parser.SqlParserPos;
+import org.apache.calcite.util.Pair;
+
+import org.checkerframework.checker.nullness.qual.Nullable;
+
+/** Very similar to {@link WithItemNamespace} but created only for RECURSIVE queries. */
+class WithItemRecursiveNameSpace extends WithItemNamespace {
+  private final SqlWithItem withItem;
+  private final SqlWithItemTableRef withItemTableRef;
+  WithItemRecursiveNameSpace(SqlValidatorImpl validator,
+      SqlWithItem withItem,
+      @Nullable SqlNode enclosingNode) {
+    super(validator, withItem, enclosingNode);
+    this.withItem = withItem;
+    this.withItemTableRef = new SqlWithItemTableRef(SqlParserPos.ZERO, withItem);
+  }
+
+  @Override public RelDataType getRowType() {
+    if (rowType == null) {
+      SqlBasicCall call;
+      if (this.withItem.query.getKind() == SqlKind.WITH) {
+        call = (SqlBasicCall) ((SqlWith) this.withItem.query).body;
+      } else {
+        call = (SqlBasicCall) this.withItem.query;
+      }
+      // As this is a recursive query we only should evaluate left child for getting the rowType.","[{'comment': 'I am not sure if you check `UNION` operands type. Can you give me a test like\r\n```sql\r\nWITH RECURSIVE cte (n) AS\r\n(\r\n  SELECT 1, 2\r\n  UNION ALL\r\n  SELECT n + 1 FROM cte WHERE n < 5\r\n)\r\nSELECT * FROM cte;\r\n```\r\nThis case is an illegal SQL, it should fail.', 'commenter': 'macroguo-ghy'}]"
3480,core/src/main/java/org/apache/calcite/sql/validate/SqlValidatorImpl.java,"@@ -3126,17 +3141,21 @@ private void registerWith(
     SqlValidatorScope scope = parentScope;
     for (SqlNode withItem_ : with.withList) {
       final SqlWithItem withItem = (SqlWithItem) withItem_;
-      final WithScope withScope = new WithScope(scope, withItem);
+
+      final boolean isRecursiveWith = withItem.recursive.booleanValue();
+      final SqlValidatorScope withScope =","[{'comment': 'What are the benefits of using a nested scope compared to using `WithRecursiveScope` directly', 'commenter': 'macroguo-ghy'}]"
3480,core/src/main/java/org/apache/calcite/sql/SqlWithItem.java,"@@ -30,13 +30,26 @@
 public class SqlWithItem extends SqlCall {
   public SqlIdentifier name;
   public @Nullable SqlNodeList columnList; // may be null
+  public SqlLiteral recursive;","[{'comment': 'Do you have to use the `SqlLiteral` type? I think using `boolean` is simpler.', 'commenter': 'macroguo-ghy'}, {'comment': 'SqlLiteral is better. It contains a position, so you can use it in error messages if necessary.', 'commenter': 'julianhyde'}]"
3480,core/src/main/codegen/templates/Parser.jj,"@@ -3486,14 +3486,16 @@ SqlNodeList WithList() :
 {
     final Span s;
     final List<SqlWithItem> list = new ArrayList<SqlWithItem>();
+    boolean recursive = false;
 }
 {
-    <WITH> { s = span(); }
-    AddWithItem(list) ( <COMMA> AddWithItem(list) )*
+    <WITH> [ <RECURSIVE> { recursive = true; } ]{ s = span(); }","[{'comment': ""I think you'd better add some tests for `WITH RECURSIVE` in `SqlParserTest`."", 'commenter': 'macroguo-ghy'}]"
3528,site/_docs/reference.md,"@@ -2823,7 +2823,7 @@ BigQuery's type system uses confusingly different names for types and functions:
 | b m o p | SOUNDEX(string)                          | Returns the phonetic representation of *string*; throws if *string* is encoded with multi-byte encoding such as UTF-8
 | s | SOUNDEX(string)                                | Returns the phonetic representation of *string*; return original *string* if *string* is encoded with multi-byte encoding such as UTF-8
 | m | SPACE(integer)                                 | Returns a string of *integer* spaces; returns an empty string if *integer* is less than 1
-| b | SPLIT(string [, delimiter ])                   | Returns the string array of *string* split at *delimiter* (if omitted, default is comma)
+| b | SPLIT(string [, delimiter ])                   | Returns the string array of *string* split at *delimiter* (if omitted, default is comma).  If the string is empty it returns an empty vector, otherwise, if the delimiter is empty, it returns a vector containing the original string.","[{'comment': 'Surround the parameter names with * ', 'commenter': 'tanclary'}, {'comment': 'Sorry for the omission. I have squashed the commits optimistically.', 'commenter': 'mihaibudiu'}, {'comment': 'Sorry for the nit but should we remove `it returns a vector containing the original string` in favor of `if the delimiter is empty, returns *string*`?', 'commenter': 'tanclary'}, {'comment': 'I forgot to quote this one. But it always returns a vector.', 'commenter': 'mihaibudiu'}, {'comment': 'Changed to ""array"" instead of ""vector"", that\'s the terminology used everywhere.', 'commenter': 'mihaibudiu'}]"
