Pull,Path,Diff_hunk,Comment
13,long-ride-alerts/DISCUSSION.md,"@@ -21,7 +21,23 @@ under the License.
 
 (Discussion of [Lab: `ProcessFunction` and Timers (Long Ride Alerts)](./))
 
+It would be interesting to test that the solution does not leak state.
 
+A good way to write unit tests for a `KeyedProcessFunction` that check for state retention, etc., is to","[{'comment': '```suggestion\r\nA good way to write unit tests for a `KeyedProcessFunction` to check for state retention, etc., is to\r\n```', 'commenter': 'NicoK'}]"
13,long-ride-alerts/DISCUSSION.md,"@@ -21,7 +21,23 @@ under the License.
 
 (Discussion of [Lab: `ProcessFunction` and Timers (Long Ride Alerts)](./))
 
+It would be interesting to test that the solution does not leak state.
 
+A good way to write unit tests for a `KeyedProcessFunction` that check for state retention, etc., is to
+use the test harnesses described in the
+[documentation on testing](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html#unit-testing-stateful-or-timely-udfs--custom-operators). 
+
+In fact, the reference solutions will leak state in the case where a START event is missing. They also
+leak in the case where the alert is generated, but then the END event does eventually arrive (after `onTimer()`
+has cleared the matching START event).
+
+This could be addressed either by using [state TTL](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/state.html#state-time-to-live-ttl),
+or by using another timer that eventually
+clears any remaining state. There is a tradeoff here, however: once that state has been removed,
+then if the matching events are't actually missing, but are instead very, very late, they will cause erroneous alerts.","[{'comment': '```suggestion\r\nthen if the matching events are not actually missing, but are instead very, very late, they will cause erroneous alerts.\r\n```', 'commenter': 'NicoK'}]"
13,long-ride-alerts/README.md,"@@ -62,13 +62,11 @@ The resulting stream should be printed to standard out.
 <details>
 <summary><strong>Overall approach</strong></summary>
 
-This exercise revolves around using a `ProcessFunction` to manage some keyed state and event time timers, and doing so in a way that works even when the END event for a given `rideId` arrives before the START (which will happen). The challenge is figuring out what state to keep, and when to set and clear that state.
-</details>
-
-<details>
-<summary><strong>Timers and State</strong></summary>
-
-You will want to use event time timers that fire two hours after the incoming events, and in the `onTimer()` method, collect START events to the output only if a matching END event hasn't yet arrived. As for what state to keep, it is enough to remember the ""last"" event for each `rideId`, where ""last"" is based on event time and ride type (START vs END &mdash; yes, there are rides where the START and END have the same timestamp), rather than the order in which the events are processed. The `TaxiRide` class implements `Comparable`; feel free to take advantage of that, and be sure to eventually clear any state you create.","[{'comment': 'Why did you remove the hints on what state to keep?', 'commenter': 'NicoK'}, {'comment': ""That hint was somewhat wrong-headed. I've written a new hint that points (rather strongly) toward the new solution."", 'commenter': 'alpinegizmo'}]"
13,long-ride-alerts/README.md,"@@ -69,6 +69,20 @@ You will want to use event time timers that fire two hours after an incoming STA
 collect START events to the output only if a matching END event hasn't yet arrived.
 </details>
 
+<details>
+<summary><strong>State and timers</strong></summary>
+
+There are many possible solutions for this exercise, but in general it is enough to keep one
+`TaxiRide` in state (one `TaxiRide` for each key, or `rideId`). The approach used in the reference solution is to
+store whichever event arrives first (the START or the END), and if it's a START event,
+create a timer for two hours later. If and when the other event (for the same rideId) arrives,","[{'comment': '```suggestion\r\ncreate a timer for two hours later. If and when the other event (for the same `rideId`) arrives,\r\n```', 'commenter': 'NicoK'}]"
13,long-ride-alerts/README.md,"@@ -69,6 +69,20 @@ You will want to use event time timers that fire two hours after an incoming STA
 collect START events to the output only if a matching END event hasn't yet arrived.
 </details>
 
+<details>
+<summary><strong>State and timers</strong></summary>
+
+There are many possible solutions for this exercise, but in general it is enough to keep one
+`TaxiRide` in state (one `TaxiRide` for each key, or `rideId`). The approach used in the reference solution is to
+store whichever event arrives first (the START or the END), and if it's a START event,
+create a timer for two hours later. If and when the other event (for the same rideId) arrives,
+carefully clean things up.
+
+It's possible to arrange this so that if `onTimer()` is called, you are guaranteed that","[{'comment': '```suggestion\r\nIt is possible to arrange this so that if `onTimer()` is called, you are guaranteed that\r\n```', 'commenter': 'NicoK'}]"
16,ride-cleansing/README.md,"@@ -27,7 +27,7 @@ The `GeoUtils` utility class provides a static method `isInNYC(float lon, float
 
 ### Input Data
 
-This series of exercises is based a stream of `TaxiRide` events, as described in [Using the Taxi Data Streams](../README.md#using-the-taxi-data-streams).
+This series of exercises is based on stream of `TaxiRide` events, as described in [Using the Taxi Data Streams](../README.md#using-the-taxi-data-streams).","[{'comment': '```suggestion\r\nThis exercise is based on a stream of `TaxiRide` events, as described in [Using the Taxi Data Streams](../README.md#using-the-taxi-data-streams).\r\n```', 'commenter': 'alpinegizmo'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ComposedPipeline.java,"@@ -0,0 +1,47 @@
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
+import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
+
+/**
+ * This allows the tests to be run against both the exercises and the solutions.
+ *
+ * <p>If an exercise throws MissingSolutionException, then the solution is tested.
+ */
+public class ComposedPipeline<IN, OUT> implements ExecutablePipeline<IN, OUT> {
+
+    private ExecutablePipeline<IN, OUT> exercise;
+    private ExecutablePipeline<IN, OUT> solution;
+
+    public ComposedPipeline(
+            ExecutablePipeline<IN, OUT> exercise, ExecutablePipeline<IN, OUT> solution) {
+        this.exercise = exercise;
+        this.solution = solution;
+    }
+
+    @Override
+    public void execute(SourceFunction<IN> source, TestSink<OUT> sink) throws Exception {
+
+        sink.reset();
+
+        try {
+            exercise.execute(source, sink);
+        } catch (Exception e) {
+            if (ultimateCauseIsMissingSolution(e)) {
+                solution.execute(source, sink);
+            } else {
+                throw e;
+            }
+        }
+    }
+
+    private boolean ultimateCauseIsMissingSolution(Throwable e) {
+        if (e instanceof MissingSolutionException) {
+            return true;
+        } else if (e.getCause() != null) {
+            return ultimateCauseIsMissingSolution(e.getCause());
+        } else {
+            return false;
+        }","[{'comment': ""I'm not sure how deep these stack traces could be, but wouldn't it be better to iterate through these instead?\r\n```suggestion\r\n        while (e != null) {\r\n            if (e instanceof MissingSolutionException) {\r\n                return true;\r\n            } else {\r\n                e = e.getCause();\r\n            }\r\n        }\r\n        return false;\r\n```"", 'commenter': 'NicoK'}]"
31,common/build.gradle,"@@ -17,6 +17,10 @@ dependencies {
     shadow ""org.apache.flink:flink-runtime_${scalaBinaryVersion}:${flinkVersion}""
 
     testApi ""junit:junit:${junitVersion}""
+    testApi ""org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}:tests""
+    testApi ""org.apache.flink:flink-runtime_${scalaBinaryVersion}:${flinkVersion}:tests""
     testApi ""org.apache.flink:flink-test-utils-junit:${flinkVersion}""
+    testApi ""org.apache.flink:flink-test-utils_${scalaBinaryVersion}:${flinkVersion}""
     testApi 'org.hamcrest:hamcrest-library:1.3'
+    testApi 'org.assertj:assertj-core:3.20.2'","[{'comment': ""Do wee need this dependency? Isn't `org.junit.Assert#assertThat()` doing the same?"", 'commenter': 'NicoK'}, {'comment': ""It's my intention to replace hamcrest with assertj. The motivation is to be able to use assertj's assertions on Collections, such as containsExactlyInAnyOrder.\r\n\r\nI don't believe this is possible with junit (or hamcrest)."", 'commenter': 'alpinegizmo'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ParallelTestSource.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class ParallelTestSource<T> extends RichParallelSourceFunction<T> {
+    protected T[] testStream;
+    TestSourcePartitioner<T> partitioner;
+    private List<T> substream;
+
+    public ParallelTestSource(TestSourcePartitioner<T> partitioner, T... events) {
+        this.partitioner = partitioner;
+        this.testStream = events;
+    }
+
+    public ParallelTestSource(T... events) {
+        this.partitioner = (e -> 0);
+        this.testStream = events;
+    }
+
+    @Override
+    public void open(Configuration parameters) throws Exception {
+
+        int indexOfThisSubtask = getRuntimeContext().getIndexOfThisSubtask();
+        int numberOfParallelSubtasks = getRuntimeContext().getNumberOfParallelSubtasks();
+        substream = new ArrayList<>();
+
+        for (int i = 0; i < testStream.length; i++) {
+            T element = testStream[i];
+            long subtaskToUse = partitioner.partition(element) % numberOfParallelSubtasks;
+
+            if (subtaskToUse == indexOfThisSubtask) {
+                substream.add(element);
+            } else if (subtaskToUse < 0 || subtaskToUse > numberOfParallelSubtasks - 1) {
+                throw new RuntimeException(""Requested subtask is out-of-bounds: "" + subtaskToUse);
+            }
+        }","[{'comment': ""Did you create this `substream` separately for debugging purposes to see which elements are actually contained in a source? Otherwise, we can skip this variable and integrate the logic here into `run()` (but maybe, it's relevant for the source interface change)"", 'commenter': 'NicoK'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ParallelTestSource.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class ParallelTestSource<T> extends RichParallelSourceFunction<T> {
+    protected T[] testStream;
+    TestSourcePartitioner<T> partitioner;
+    private List<T> substream;
+
+    public ParallelTestSource(TestSourcePartitioner<T> partitioner, T... events) {
+        this.partitioner = partitioner;
+        this.testStream = events;
+    }
+
+    public ParallelTestSource(T... events) {
+        this.partitioner = (e -> 0);
+        this.testStream = events;
+    }
+
+    @Override
+    public void open(Configuration parameters) throws Exception {
+
+        int indexOfThisSubtask = getRuntimeContext().getIndexOfThisSubtask();
+        int numberOfParallelSubtasks = getRuntimeContext().getNumberOfParallelSubtasks();
+        substream = new ArrayList<>();
+
+        for (int i = 0; i < testStream.length; i++) {
+            T element = testStream[i];","[{'comment': '```suggestion\r\n        for (T element : testStream) {\r\n```', 'commenter': 'NicoK'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/TestSink.java,"@@ -0,0 +1,26 @@
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+public class TestSink<OUT> implements SinkFunction<OUT> {
+
+    // must be static
+    public static final List VALUES = Collections.synchronizedList(new ArrayList<>());
+
+    @Override
+    public void invoke(OUT value, Context context) {
+        VALUES.add(value);
+    }
+
+    public Iterable<OUT> results() {
+        return VALUES;
+    }
+
+    public void reset() {
+        VALUES.clear();
+    }
+}","[{'comment': 'In the Flink sources, I also found this pattern for test sinks:\r\n```\r\n        stream.addSink(\r\n                new RichSinkFunction<Integer>() {\r\n                    @Override\r\n                    public void open(Configuration parameters) throws Exception {\r\n                        getRuntimeContext()\r\n                                .addAccumulator(""result"", new ListAccumulator<Integer>());\r\n                    }\r\n\r\n                    @Override\r\n                    public void invoke(Integer value, Context context) throws Exception {\r\n                        getRuntimeContext().getAccumulator(""result"").add(value);\r\n                    }\r\n                });\r\n        List<Integer> result = env.execute().getAccumulatorResult(""result"");\r\n```\r\n-> maybe that\'s a cleaner approach to fetching results?\r\n\r\nAnother, probably even better, option: using `org.apache.flink.streaming.util.StreamCollector#collect`. In that case, we wouldn\'t even need our own `SinkFunction`.', 'commenter': 'NicoK'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ParallelTestSource.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class ParallelTestSource<T> extends RichParallelSourceFunction<T> {
+    protected T[] testStream;
+    TestSourcePartitioner<T> partitioner;
+    private List<T> substream;
+
+    public ParallelTestSource(TestSourcePartitioner<T> partitioner, T... events) {
+        this.partitioner = partitioner;
+        this.testStream = events;
+    }
+
+    public ParallelTestSource(T... events) {
+        this.partitioner = (e -> 0);
+        this.testStream = events;
+    }
+
+    @Override
+    public void open(Configuration parameters) throws Exception {
+
+        int indexOfThisSubtask = getRuntimeContext().getIndexOfThisSubtask();
+        int numberOfParallelSubtasks = getRuntimeContext().getNumberOfParallelSubtasks();
+        substream = new ArrayList<>();
+
+        for (int i = 0; i < testStream.length; i++) {
+            T element = testStream[i];
+            long subtaskToUse = partitioner.partition(element) % numberOfParallelSubtasks;
+
+            if (subtaskToUse == indexOfThisSubtask) {
+                substream.add(element);
+            } else if (subtaskToUse < 0 || subtaskToUse > numberOfParallelSubtasks - 1) {","[{'comment': 'I think, `subtaskToUse < 0` is the only thing you need to check here.\r\n```suggestion\r\n            } else if (subtaskToUse < 0) {\r\n```', 'commenter': 'NicoK'}]"
31,long-ride-alerts/README.md,"@@ -62,41 +61,29 @@ The resulting stream should be printed to standard out.
 <details>
 <summary><strong>Overall approach</strong></summary>
 
-This exercise revolves around using a `ProcessFunction` to manage some keyed state and event time timers,
-and doing so in a way that works even when the END event for a given `rideId` arrives before the START (which can happen).
-The challenge is figuring out what state to keep, and when to set and clear that state.
-You will want to use event time timers that fire two hours after an incoming START event, and in the `onTimer()` method,
-collect START events to the output only if a matching END event hasn't yet arrived.
-</details>
-
-<details>
-<summary><strong>State and timers</strong></summary>
-
-There are many possible solutions for this exercise, but in general it is enough to keep one
-`TaxiRide` in state (one `TaxiRide` for each key, or `rideId`). The approach used in the reference solution is to
-store whichever event arrives first (the START or the END), and if it's a START event,
-create a timer for two hours later. If and when the other event (for the same `rideId`) arrives,
-carefully clean things up.
-
-It is possible to arrange this so that if `onTimer()` is called, you are guaranteed that
-an alert (i.e., the ride kept in state) should be emitted. Writing the code this way conveniently
-puts all of the complex business logic together in one place (in the `processElement()` method).
+This exercise revolves around using a `KeyedProcessFunction` to manage some state and event time timers,
+and doing so in a way that works even when the END event for a given `rideId` arrives before the START.
+The challenge is figuring out what state and timers to use, and when to set and clear the state (and timers).
+It is not enough to simply wait for the END event and calculate the duration, as the END event
+may be missing.
 </details>
 
 ## Documentation
 
 - [ProcessFunction](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/process_function.html)
 - [Working with State](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/index.html)
 
+## After you've completed the exercise
+
+Read the [discussion of the reference solutions](DISCUSSION.md).
+
 ## Reference Solutions
 
-Reference solutions are available at GitHub:
+Reference solutions:
 
 - Java API:  [`org.apache.flink.training.solutions.longrides.LongRidesSolution`](src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java)
 - Scala API: [`org.apache.flink.training.solutions.longrides.scala.LongRidesSolution`](src/solution/scala/org/apache/flink/training/solutions/longrides/scala/LongRidesSolution.scala)
 
 -----
 
-[**Lab Discussion: `ProcessFunction` and Timers (Long Ride Alerts)**](DISCUSSION.md)
-","[{'comment': 'Do you actually want to remove the link to the discussion page?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);","[{'comment': ""Although for a production job, we shouldn't set any configuration parameters via code, I'd argue that we may need a special environment for these exercises with well-defined settings. High default parallelism (number of CPUs) in the IDE could, for example, overload the Flink starter with just too much happening in the logs while too low parallelism may hide certain behaviour.\r\n\r\nMaybe something along the lines of https://github.com/ververica/flink-training/blob/d07b181f1fa89137da45a8ffa67ec4cbfaf90cf1/troubleshooting/common/src/main/java/com/ververica/flink/training/common/EnvironmentUtils.java#L44 which enables the web UI on a well-defined port.\r\n\r\nMaybe we could also hide this under a nice builder pattern...\r\n\r\nEither way, that may be a follow-up PR but not sure we should change the parallelism here or rather put this into its own (bigger-scoped) improvements..."", 'commenter': 'NicoK'}, {'comment': ""I dislike the ExerciseBase class, because its existence makes the exercises more complex to understand. I added parallelism to that class when I decided to execute the tests with a parallelism of 1, which I now regret.\r\n\r\nI'm not convinced it's worthwhile to control the parallelism in the exercises -- I don't want to pollute the exercises with inessential details, or things that shouldn't be there in production. I think it's more important to keep the code looking simple than to reduce the logging a bit. There's so much logging on startup anyway.\r\n\r\nAnd I don't really want to include something like createConfiguredEnvironment as used in the troubleshooting exercises in the starter exercises, because it's very scary looking, and it's not possible for a beginner to understand what's going on and whether or not they should have similar code in their own applications.\r\n\r\n"", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);
 
         // start the data generator
-        DataStream<TaxiRide> rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()));
+        DataStream<TaxiRide> rides = env.addSource(source, TypeInformation.of(TaxiRide.class));","[{'comment': ""Not sure why you added this here, but it doesn't seem like we need to provide the type information manually\r\n```suggestion\r\n        DataStream<TaxiRide> rides = env.addSource(source);\r\n```"", 'commenter': 'NicoK'}, {'comment': ""That type information was needed in some intermediate version -- but fortunately, it's no longer useful. "", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);
 
         // start the data generator
-        DataStream<TaxiRide> rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()));
+        DataStream<TaxiRide> rides = env.addSource(source, TypeInformation.of(TaxiRide.class));
 
-        DataStream<TaxiRide> longRides =
-                rides.keyBy((TaxiRide ride) -> ride.rideId).process(new MatchFunction());
+        // the WatermarkStrategy specifies how to extract timestamps and generate watermarks
+        WatermarkStrategy<TaxiRide> watermarkStrategy =
+                WatermarkStrategy.<TaxiRide>forBoundedOutOfOrderness(Duration.ofSeconds(60))
+                        .withTimestampAssigner((ride, timestamp) -> ride.getEventTime());","[{'comment': ""The second parameter here is:\r\n> The current internal timestamp of the element, or a negative value, if no timestamp has been assigned yet.\r\n\r\nI'm not sure (didactically) how to name that one not to be confusing, but `timestamp` sounds misleading ... wdyt?"", 'commenter': 'NicoK'}, {'comment': ""I've changed it to streamRecordTimestamp -- see what you think."", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;","[{'comment': 'This design with an instance of a `SourceFunction` probably needs to be changed when using the new source interface and putting the timestamp assigner into the source.\r\nShould we take that into account now?', 'commenter': 'NicoK'}, {'comment': ""I prefer to wait. Before creating this PR I experimented with schemes for including that, and concluded it's better to wait."", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);
 
         // start the data generator
-        DataStream<TaxiRide> rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()));
+        DataStream<TaxiRide> rides = env.addSource(source, TypeInformation.of(TaxiRide.class));
 
-        DataStream<TaxiRide> longRides =
-                rides.keyBy((TaxiRide ride) -> ride.rideId).process(new MatchFunction());
+        // the WatermarkStrategy specifies how to extract timestamps and generate watermarks
+        WatermarkStrategy<TaxiRide> watermarkStrategy =
+                WatermarkStrategy.<TaxiRide>forBoundedOutOfOrderness(Duration.ofSeconds(60))
+                        .withTimestampAssigner((ride, timestamp) -> ride.getEventTime());
 
-        printOrTest(longRides);
+        // create the pipeline
+        rides.assignTimestampsAndWatermarks(watermarkStrategy)
+                .keyBy((TaxiRide ride) -> ride.rideId)","[{'comment': 'Simpler? Or did you want to make the type explicit?\r\n```suggestion\r\n                .keyBy(ride -> ride.rideId)\r\n```', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/main/scala/org/apache/flink/training/exercises/longrides/scala/LongRidesExercise.scala,"@@ -18,55 +18,83 @@
 
 package org.apache.flink.training.exercises.longrides.scala
 
+import org.apache.flink.api.common.eventtime.{SerializableTimestampAssigner, WatermarkStrategy}","[{'comment': ""Most of the comments for the Java exercise apply 1:1...I'll omit listing them here again"", 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -71,36 +109,53 @@ public void open(Configuration config) {
         }
 
         @Override
-        public void processElement(TaxiRide ride, Context context, Collector<TaxiRide> out)
+        public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
-            TaxiRide previousRideEvent = rideState.value();
 
-            if (previousRideEvent == null) {
+            TaxiRide firstRideEvent = rideState.value();
+
+            if (firstRideEvent == null) {
                 rideState.update(ride);
+
                 if (ride.isStart) {
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
+                } else {
+                    if (rideTooLong(ride)) {
+                        out.collect(ride.rideId);
+                    }
                 }
             } else {
-                if (!ride.isStart) {
-                    // it's an END event, so event saved was the START event and has a timer
-                    // the timer hasn't fired yet, and we can safely kill the timer
-                    context.timerService().deleteEventTimeTimer(getTimerTime(previousRideEvent));
+                if (ride.isStart) {
+                    // There's nothing to do but clear the state (which is done below).
+                } else {
+                    // There may be a timer that hasn't fired yet.
+                    context.timerService().deleteEventTimeTimer(getTimerTime(firstRideEvent));
+
+                    // It could be that the ride has gone on too long, but the timer hasn't fired.","[{'comment': ""```suggestion\r\n                    // It could be that the ride has gone on too long, but the timer hasn't fired yet.\r\n```"", 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/solution/scala/org/apache/flink/training/solutions/longrides/scala/LongRidesSolution.scala,"@@ -18,81 +18,124 @@
 
 package org.apache.flink.training.solutions.longrides.scala
 
-import scala.concurrent.duration._
+import org.apache.flink.api.common.eventtime.{SerializableTimestampAssigner, WatermarkStrategy}
 import org.apache.flink.api.common.state.{ValueState, ValueStateDescriptor}
+import org.apache.flink.configuration.Configuration
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction
+import org.apache.flink.streaming.api.functions.sink.{PrintSinkFunction, SinkFunction}
+import org.apache.flink.streaming.api.functions.source.SourceFunction
 import org.apache.flink.streaming.api.scala.{StreamExecutionEnvironment, _}
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator
-import org.apache.flink.training.exercises.common.utils.ExerciseBase
-import org.apache.flink.training.exercises.common.utils.ExerciseBase._
 import org.apache.flink.util.Collector
 
+import scala.concurrent.duration._
+import java.time.Duration
+
 /**
-  * Scala reference implementation for the ""Long Ride Alerts"" exercise of the Flink training in the docs.
+  * Scala solution for the ""Long Ride Alerts"" exercise.
   *
-  * The goal for this exercise is to emit START events for taxi rides that have not been matched
-  * by an END event during the first 2 hours of the ride.
+  * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+  * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
   *
+  * <p>You should eventually clear any state you create.
   */
 object LongRidesSolution {
 
-  def main(args: Array[String]) {
-
-    // set up the execution environment
-    val env = StreamExecutionEnvironment.getExecutionEnvironment
-    // operate in Event-time
-    env.setParallelism(ExerciseBase.parallelism)
-
-    val rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()))
+  class LongRidesJob(source: SourceFunction[TaxiRide], sink: SinkFunction[Long]) {
+
+    /**
+     * Creates and executes the ride cleansing pipeline.
+     */
+    @throws[Exception]
+    def execute(): Unit = {
+      val env = StreamExecutionEnvironment.getExecutionEnvironment
+
+      // start the data generator
+      val rides = env.addSource(source)
+
+      // the WatermarkStrategy specifies how to extract timestamps and generate watermarks
+      val watermarkStrategy = WatermarkStrategy
+        .forBoundedOutOfOrderness[TaxiRide](Duration.ofSeconds(60))
+        .withTimestampAssigner(new SerializableTimestampAssigner[TaxiRide] {
+          override def extractTimestamp(element: TaxiRide, recordTimestamp: Long): Long =
+            element.getEventTime
+        })
+
+      // create the pipeline
+      rides
+        .assignTimestampsAndWatermarks(watermarkStrategy)
+        .keyBy(_.rideId)
+        .process(new MatchFunction())
+        .addSink(sink)
+
+      // execute the pipeline
+      env.execute(""Long Taxi Rides"")
+    }
 
-    val longRides = rides
-      .keyBy(_.rideId)
-      .process(new MatchFunction())
+  }
 
-    printOrTest(longRides)
+  @throws[Exception]
+  def main (args: Array[String]) {
+    val job = new LongRidesJob(new TaxiRideGenerator, new PrintSinkFunction)
 
-    env.execute(""Long Taxi Rides"")
+    job.execute
   }
 
-  class MatchFunction extends KeyedProcessFunction[Long, TaxiRide, TaxiRide] {
-    lazy val rideState: ValueState[TaxiRide] = getRuntimeContext.getState(
-      new ValueStateDescriptor[TaxiRide](""ride event"", classOf[TaxiRide]))
+  class MatchFunction extends KeyedProcessFunction[Long, TaxiRide, Long] {
+    private var rideState: ValueState[TaxiRide] = _
+
+    override def open(parameters: Configuration): Unit = {
+      rideState = getRuntimeContext.getState(
+        new ValueStateDescriptor[TaxiRide](""ride event"", classOf[TaxiRide]))
+    }
 
     override def processElement(ride: TaxiRide,
-                                context: KeyedProcessFunction[Long, TaxiRide, TaxiRide]#Context,
-                                out: Collector[TaxiRide]): Unit = {
+                                context: KeyedProcessFunction[Long, TaxiRide, Long]#Context,
+                                out: Collector[Long]): Unit = {
 
-      val previousRideEvent = rideState.value()
+      val firstRideEvent = rideState.value()
 
-      if (previousRideEvent == null) {
+      if (firstRideEvent == null) {
         rideState.update(ride)
         if (ride.isStart) {
-          context.timerService().registerEventTimeTimer(getTimerTime(ride))
+          context.timerService.registerEventTimeTimer(getTimerTime(ride))
+        }
+        else if (rideTooLong(ride)) {
+          out.collect(ride.rideId)
         }
-      } else {
-        if (!ride.isStart) {
-          // it's an END event, so event saved was the START event and has a timer
-          // the timer hasn't fired yet, and we can safely kill the timer
-          context.timerService().deleteEventTimeTimer(getTimerTime(previousRideEvent))
+      }
+      else {","[{'comment': 'note sure style-wise, but before this was collapsed into a single line', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesHarnessTest.java,"@@ -0,0 +1,56 @@
+package org.apache.flink.training.exercises.longrides;
+
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.streaming.api.operators.KeyedProcessOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
+import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
+import org.apache.flink.training.solutions.longrides.LongRidesSolution;
+
+import org.junit.Test;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
+
+public class LongRidesHarnessTest {
+
+    @Test
+    public void testLongRideAlertsAsSoonAsPossible() throws Exception {
+        KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> harness = setupHarness();
+
+        TaxiRide startOfLongRide = LongRidesTest.startRide(1, LongRidesTest.BEGINNING);
+        harness.processElement(new StreamRecord<>(startOfLongRide, startOfLongRide.getEventTime()));","[{'comment': 'Do you want to check that there is no output yet after processing this?', 'commenter': 'NicoK'}, {'comment': 'Sure, I think that makes sense.', 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesHarnessTest.java,"@@ -0,0 +1,56 @@
+package org.apache.flink.training.exercises.longrides;
+
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.streaming.api.operators.KeyedProcessOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
+import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
+import org.apache.flink.training.solutions.longrides.LongRidesSolution;
+
+import org.junit.Test;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
+
+public class LongRidesHarnessTest {
+
+    @Test
+    public void testLongRideAlertsAsSoonAsPossible() throws Exception {","[{'comment': ""I think, we'd need a couple of more tests to verify the full behaviour, including:\r\n\r\n- alerting directly if you see the end event first\r\n- not alerting for a start event until the watermark is exactly 2h ahead (even if you see later data or processing time advances beyond 2h)\r\n- not alerting for an end event that is not too long\r\n- alerting if there is no event but the watermark surpasses the 2h\r\n- state cleanup (in the good case - not the leak we leave for the open discussion)\r\n\r\nShould we also verify that things, i.e. the start events, are kept in Flink state after all and not some other local Java store (best-effort by just looking at the number of state entries > 0)?"", 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesHarnessTest.java,"@@ -0,0 +1,56 @@
+package org.apache.flink.training.exercises.longrides;
+
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.streaming.api.operators.KeyedProcessOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
+import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
+import org.apache.flink.training.solutions.longrides.LongRidesSolution;
+
+import org.junit.Test;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
+
+public class LongRidesHarnessTest {
+
+    @Test
+    public void testLongRideAlertsAsSoonAsPossible() throws Exception {
+        KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> harness = setupHarness();
+
+        TaxiRide startOfLongRide = LongRidesTest.startRide(1, LongRidesTest.BEGINNING);
+        harness.processElement(new StreamRecord<>(startOfLongRide, startOfLongRide.getEventTime()));
+
+        Watermark mark2HoursLater =
+                new Watermark(LongRidesTest.BEGINNING.plusSeconds(120 * 60).toEpochMilli());
+        harness.processWatermark(mark2HoursLater);
+
+        // Check that the result is correct
+        ConcurrentLinkedQueue<Object> actualOutput = harness.getOutput();
+        StreamRecord<Long> rideIdAtTimeOfWatermark =
+                new StreamRecord<>(startOfLongRide.rideId, mark2HoursLater.getTimestamp());
+        assertThat(actualOutput).containsExactly(rideIdAtTimeOfWatermark, mark2HoursLater);
+
+        // Check that no state or timers are left behind
+        assertThat(harness.numKeyedStateEntries()).isZero();
+        assertThat(harness.numEventTimeTimers()).isZero();
+    }
+
+    private KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> setupHarness()
+            throws Exception {
+
+        KeyedProcessOperator<Long, TaxiRide, Long> operator =
+                new KeyedProcessOperator<>(new LongRidesSolution.MatchFunction());
+
+        KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> testHarness =
+                new KeyedOneInputStreamOperatorTestHarness<>(
+                        operator, (TaxiRide r) -> r.rideId, BasicTypeInfo.LONG_TYPE_INFO);","[{'comment': '```suggestion\r\n                        operator, (TaxiRide r) -> r.rideId, Types.LONG);\r\n```', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {","[{'comment': 'Is this test more of a UnitTest?\r\n\r\n---\r\n\r\nIn general, the line may be difficult to draw, but how about this:\r\n- an integration test focuses on the whole pipeline (so here: watermarks + keyBy + MatchFunction) and any interplay between these\r\n- a unit test focuses on the logic of the MatchFunction alone\r\n\r\nFor this, we could actually also remove the watermarking code from the exercise and add this to the work to be done (unless you think, it may be too much to ask for a first exercise)', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {","[{'comment': 'Unit test?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {","[{'comment': 'Unit test?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long mark2HoursLater = BEGINNING.plusSeconds(120 * 60).toEpochMilli();
-        TaxiRide rideEnded3HoursLater = endRide(rideStarted, BEGINNING.plusSeconds(180 * 60));
 
-        TestRideSource source =
-                new TestRideSource(rideStarted, mark2HoursLater, rideEnded3HoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void startIsDelayedMoreThanTwoHours() throws Exception {
-        TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide rideEndedAfter1Hour = endRide(rideStarted, BEGINNING.plusSeconds(60 * 60));
-        Long mark2HoursAfterEnd = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+    public void endComesAfter3Hours() throws Exception {","[{'comment': 'Unit test?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long mark2HoursLater = BEGINNING.plusSeconds(120 * 60).toEpochMilli();
-        TaxiRide rideEnded3HoursLater = endRide(rideStarted, BEGINNING.plusSeconds(180 * 60));
 
-        TestRideSource source =
-                new TestRideSource(rideStarted, mark2HoursLater, rideEnded3HoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void startIsDelayedMoreThanTwoHours() throws Exception {
-        TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide rideEndedAfter1Hour = endRide(rideStarted, BEGINNING.plusSeconds(60 * 60));
-        Long mark2HoursAfterEnd = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+    public void endComesAfter3Hours() throws Exception {
+        TaxiRide startOfLongRide = startRide(1, BEGINNING);
+        TaxiRide longRideEndedAfter3Hours = endRide(startOfLongRide, THREE_HOURS_LATER);
 
-        TestRideSource source =
-                new TestRideSource(rideEndedAfter1Hour, mark2HoursAfterEnd, rideStarted);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(
+                        new PartitionByRideId(), startOfLongRide, longRideEndedAfter3Hours);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(startOfLongRide.rideId);
+    }
+
+    @Test
+    public void multipleRides() throws Exception {
+        TaxiRide startOfOneRide = startRide(1, BEGINNING);
+        TaxiRide otherRide = startRide(2, ONE_MINUTE_LATER);
+        TaxiRide oneRideEnded = endRide(startOfOneRide, THREE_HOURS_LATER);
+        TaxiRide otherRideEnded = endRide(otherRide, THREE_HOURS_LATER);","[{'comment': 'Do you want to add a couple of more rides (just 2h, just below 2h, without end,...) to mix things up a bit (more of an ITCase)', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long mark2HoursLater = BEGINNING.plusSeconds(120 * 60).toEpochMilli();
-        TaxiRide rideEnded3HoursLater = endRide(rideStarted, BEGINNING.plusSeconds(180 * 60));
 
-        TestRideSource source =
-                new TestRideSource(rideStarted, mark2HoursLater, rideEnded3HoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void startIsDelayedMoreThanTwoHours() throws Exception {
-        TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide rideEndedAfter1Hour = endRide(rideStarted, BEGINNING.plusSeconds(60 * 60));
-        Long mark2HoursAfterEnd = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+    public void endComesAfter3Hours() throws Exception {
+        TaxiRide startOfLongRide = startRide(1, BEGINNING);
+        TaxiRide longRideEndedAfter3Hours = endRide(startOfLongRide, THREE_HOURS_LATER);
 
-        TestRideSource source =
-                new TestRideSource(rideEndedAfter1Hour, mark2HoursAfterEnd, rideStarted);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(
+                        new PartitionByRideId(), startOfLongRide, longRideEndedAfter3Hours);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(startOfLongRide.rideId);
+    }
+
+    @Test
+    public void multipleRides() throws Exception {
+        TaxiRide startOfOneRide = startRide(1, BEGINNING);
+        TaxiRide otherRide = startRide(2, ONE_MINUTE_LATER);
+        TaxiRide oneRideEnded = endRide(startOfOneRide, THREE_HOURS_LATER);
+        TaxiRide otherRideEnded = endRide(otherRide, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(
+                        new PartitionByRideId(),
+                        startOfOneRide,
+                        otherRide,
+                        oneRideEnded,
+                        otherRideEnded);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results())
+                .containsExactlyInAnyOrder(startOfOneRide.rideId, otherRide.rideId);
     }
 
-    private TaxiRide testRide(long rideId, Boolean isStart, Instant startTime, Instant endTime) {
+    // Arranges for all events for a given rideId to be generated by the same source subtask.
+    private static class PartitionByRideId implements TestSourcePartitioner<TaxiRide> {
+        @Override
+        public long partition(TaxiRide ride) {
+            return ride.rideId;
+        }
+    }","[{'comment': 'Why is this important? Wouldn\'t it be better that things are arbitrarily distributed between source ""partitions""?', 'commenter': 'NicoK'}]"
36,common/src/main/java/org/apache/flink/training/exercises/common/datatypes/TaxiRide.java,"@@ -139,7 +132,7 @@ public int compareTo(@Nullable TaxiRide other) {
         if (other == null) {
             return 1;
         }
-        int compareTimes = Long.compare(this.getEventTime(), other.getEventTime());
+        int compareTimes = Long.compare(this.getEventTimeMillis(), other.getEventTimeMillis());","[{'comment': 'Why not use `java.time.Instant#compareTo`?\r\n```suggestion\r\n        int compareTimes = this.eventTime.compareTo(other.eventTime);\r\n```', 'commenter': 'NicoK'}]"
36,common/src/main/java/org/apache/flink/training/exercises/common/sources/TaxiRideGenerator.java,"@@ -71,7 +71,7 @@ public void run(SourceContext<TaxiRide> ctx) throws Exception {
             java.util.Collections.shuffle(startEvents, new Random(id));
             startEvents
                     .iterator()
-                    .forEachRemaining(r -> ctx.collectWithTimestamp(r, r.getEventTime()));
+                    .forEachRemaining(r -> ctx.collectWithTimestamp(r, r.getEventTimeMillis()));","[{'comment': ""Not for this PR, but didn't you want to remove `collectWithTimestamp` calls?\r\n\r\nIf I see this correctly, only the LongRides exercises and solutions need timestamps and they have appropriate watermark strategies..."", 'commenter': 'NicoK'}]"
36,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -115,31 +115,31 @@ public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
 
             TaxiRide firstRideEvent = rideState.value();
-
             if (firstRideEvent == null) {
+                // whatever event comes first, remember it
                 rideState.update(ride);
 
                 if (ride.isStart) {
+                    // we will use this timer to check for rides that have gone on too long and may
+                    // not yet have an END event (or the END event could be missing)
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
-                } else {
-                    if (rideTooLong(ride)) {
-                        out.collect(ride.rideId);
-                    }
                 }","[{'comment': ""Can you add a section to the discussion on how to deal with missing START events? We could use event-time timers for this as well, e.g. by firing for the END event's timestamp"", 'commenter': 'NicoK'}, {'comment': ""It's not possible to handle missing START events. Those START events are now the only source of knowledge about when the ride started, so it's not possible to know how long the ride was."", 'commenter': 'alpinegizmo'}, {'comment': ""True, you won't know how long a ride was, but you can identify a late START event at least (and maybe put it on a side output for error handling - a best practice in these cases but not sure you want to add this here"", 'commenter': 'NicoK'}, {'comment': ""There's no notion of lateness here. The current solution will wait indefinitely for the START event. If it ever shows up, the ride will then be reported as having been too long. "", 'commenter': 'alpinegizmo'}, {'comment': ""I guess I see what you meant. We could detect missing START events, and indicate that on a side output. Maybe I'll add something to the DISCUSSION about that."", 'commenter': 'alpinegizmo'}, {'comment': 'Exactly, this is what I meant', 'commenter': 'NicoK'}]"
36,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -115,31 +115,31 @@ public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
 
             TaxiRide firstRideEvent = rideState.value();
-
             if (firstRideEvent == null) {
+                // whatever event comes first, remember it
                 rideState.update(ride);
 
                 if (ride.isStart) {
+                    // we will use this timer to check for rides that have gone on too long and may
+                    // not yet have an END event (or the END event could be missing)
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
-                } else {
-                    if (rideTooLong(ride)) {
-                        out.collect(ride.rideId);
-                    }
                 }
             } else {
                 if (ride.isStart) {
-                    // There's nothing to do but clear the state (which is done below).
+                    if (rideTooLong(ride, firstRideEvent)) {
+                        out.collect(ride.rideId);
+                    }
                 } else {
-                    // There may be a timer that hasn't fired yet.
+                    // there is probably a timer that hasn't fired yet","[{'comment': 'There **is** a timer if `firstRideEvent` was a START event...', 'commenter': 'NicoK'}, {'comment': ""I've reworked the comments"", 'commenter': 'alpinegizmo'}]"
36,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -115,31 +115,31 @@ public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
 
             TaxiRide firstRideEvent = rideState.value();
-
             if (firstRideEvent == null) {
+                // whatever event comes first, remember it
                 rideState.update(ride);
 
                 if (ride.isStart) {
+                    // we will use this timer to check for rides that have gone on too long and may
+                    // not yet have an END event (or the END event could be missing)
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
-                } else {
-                    if (rideTooLong(ride)) {
-                        out.collect(ride.rideId);
-                    }
                 }
             } else {
                 if (ride.isStart) {
-                    // There's nothing to do but clear the state (which is done below).
+                    if (rideTooLong(ride, firstRideEvent)) {
+                        out.collect(ride.rideId);
+                    }
                 } else {
-                    // There may be a timer that hasn't fired yet.
+                    // there is probably a timer that hasn't fired yet
                     context.timerService().deleteEventTimeTimer(getTimerTime(firstRideEvent));
 
-                    // It could be that the ride has gone on too long, but the timer hasn't fired
-                    // yet.
-                    if (rideTooLong(ride)) {
+                    // it could be that the ride has gone on too long (and the timer didn't fire)","[{'comment': 'You keep removing ""yet"" here...isn\'t this making clear that the timer would have fired if we hadn\'t removed it above?\r\n```suggestion\r\n                    // it could be that the ride has gone on too long (and the timer didn\'t fire yet)\r\n```', 'commenter': 'NicoK'}, {'comment': 'reworked, as above', 'commenter': 'alpinegizmo'}]"
36,long-ride-alerts/src/solution/scala/org/apache/flink/training/solutions/longrides/scala/LongRidesSolution.scala,"@@ -91,32 +91,38 @@ object LongRidesSolution {
         new ValueStateDescriptor[TaxiRide](""ride event"", classOf[TaxiRide]))
     }
 
+    @throws[Exception]
     override def processElement(ride: TaxiRide,
                                 context: KeyedProcessFunction[Long, TaxiRide, Long]#Context,
                                 out: Collector[Long]): Unit = {
 
-      val firstRideEvent = rideState.value()
+      val firstRideEvent: TaxiRide = rideState.value
 
       if (firstRideEvent == null) {
+        // whatever event comes first, remember it
         rideState.update(ride)
+
         if (ride.isStart) {
+          // we will use this timer to check for rides that have gone on too long and may
+          // not yet have an END event (or the END event could be missing)
           context.timerService.registerEventTimeTimer(getTimerTime(ride))
-        } else if (rideTooLong(ride)) {
-          out.collect(ride.rideId)
         }
       } else {
         if (ride.isStart) {
-          // There's nothing to do but clear the state (which is done below).
+          if (rideTooLong(ride, firstRideEvent)) {
+            out.collect(ride.rideId)
+          }
         } else {
-          // There may be a timer that hasn't fired yet.
+          // there is probably a timer that hasn't fired yet
           context.timerService.deleteEventTimeTimer(getTimerTime(firstRideEvent))
 
-          // It could be that the ride has gone on too long, but the timer hasn't fired yet.
-          if (rideTooLong(ride)) {
+          // it could be that the ride has gone on too long (and the timer didn't fire)","[{'comment': ""```suggestion\r\n          // it could be that the ride has gone on too long (and the timer didn't fire yet)\r\n```"", 'commenter': 'NicoK'}, {'comment': 'fixed', 'commenter': 'alpinegizmo'}]"
36,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesUnitTest.java,"@@ -104,6 +132,15 @@ public void shouldAlertOnWatermark() throws Exception {
         assertThat(harness.numEventTimeTimers()).isZero();
     }
 
+    private Long resultingRideId() {
+        ConcurrentLinkedQueue<Object> results = harness.getOutput();
+        assertThat(results.size())
+                .isEqualTo(1)
+                .withFailMessage(""Expecting test to have exactly one result"");","[{'comment': 'From the Javadoc:\r\n> You must set it before calling the assertion otherwise it is ignored as the failing assertion breaks the chained call by throwing an AssertionError.\r\n\r\n```suggestion\r\n        assertThat(results.size())\r\n                .withFailMessage(""Expecting test to have exactly one result"")\r\n                .isEqualTo(1);\r\n```', 'commenter': 'NicoK'}]"
36,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesUnitTest.java,"@@ -104,6 +132,15 @@ public void shouldAlertOnWatermark() throws Exception {
         assertThat(harness.numEventTimeTimers()).isZero();
     }
 
+    private Long resultingRideId() {
+        ConcurrentLinkedQueue<Object> results = harness.getOutput();
+        assertThat(results.size())
+                .isEqualTo(1)
+                .withFailMessage(""Expecting test to have exactly one result"");
+        StreamRecord<Long> resultingRecord = (StreamRecord<Long>) results.toArray()[0];","[{'comment': 'Converting to array is unnecessary:\r\n```suggestion\r\n        StreamRecord<Long> resultingRecord = (StreamRecord<Long>) results.element();\r\n```', 'commenter': 'NicoK'}]"
36,long-ride-alerts/DISCUSSION.md,"@@ -21,25 +21,30 @@ under the License.
 
 (Discussion of [Lab: `KeyedProcessFunction` and Timers (Long Ride Alerts)](./))
 
-Flaws in the reference solutions:
+### Flaws in the solutions
 
-* The reference solutions leak state in the case where a START event is missing.
-* In the case where the END event eventually arrives, but after the timer
-has fired and has cleared the matching START event, then a duplicate alert is generated.
+*The reference solutions can leak state when an event is missing.*
 
-A good way to write unit tests for a `KeyedProcessFunction` to check for state retention, etc., is to
-use the test harnesses described in the
-[documentation on testing](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html#unit-testing-stateful-or-timely-udfs--custom-operators).
-
-These issues could be addressed by keeping some state longer, and then either
+This could be addressed by either
 using [state TTL](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/state.html#state-time-to-live-ttl),
 or another timer, to eventually clear any lingering state.
 
-But regardless of how long we retain the state, we must eventually clear it, and thereafter we would
+*These solutions also leak state whenever there is a long ride, unless the END event is missing.*","[{'comment': 'That sounds wrong...did you mean this?\r\n```suggestion\r\n*These solutions also leak state whenever there is a long ride and the END event is missing.*\r\n```', 'commenter': 'NicoK'}, {'comment': ""No, that isn't what I meant. I've expanded the DISCUSSION to be clearer."", 'commenter': 'alpinegizmo'}, {'comment': 'The sentence is still misleading as it suggests that you always leak state for every long ride but this is only true if the start event is missing or if the end event is late. Long rides with both events are cleaned up in `processElement`.\r\nThe text should thus go through these (or reflect them somehow):\r\n- start event missing -> end event sits in state (leak!)\r\n- end event missing -> timer fires and clears state (ok)\r\n- end event late -> timer fires, clears state, end event arrives and is stored in state (leak!)', 'commenter': 'NicoK'}]"
40,common/src/main/java/org/apache/flink/training/exercises/common/sources/TaxiFareGenerator.java,"@@ -29,15 +33,25 @@
 public class TaxiFareGenerator implements SourceFunction<TaxiFare> {
 
     private volatile boolean running = true;
+    private Instant limitingTimestamp = Instant.MAX;
+
+    /** Create a bounded TaxiFareGenerator that runs only for the specified duration. */
+    public static TaxiFareGenerator runFor(Duration duration) {
+        TaxiFareGenerator generator = new TaxiFareGenerator();
+        generator.limitingTimestamp = DataGenerator.BEGINNING.plus(duration);
+        return generator;
+    }
 
     @Override
     public void run(SourceContext<TaxiFare> ctx) throws Exception {
 
         long id = 1;
+        Instant latestTimestamp = Instant.MIN;
 
-        while (running) {
+        while (running && (latestTimestamp.compareTo(limitingTimestamp) < 0)) {
             TaxiFare fare = new TaxiFare(id);
             id += 1;
+            latestTimestamp = fare.startTime;
 
             ctx.collect(fare);","[{'comment': 'This will actually put a TaxiFare on the output that has a timestamp later than `limitingTimestamp`. If you want to avoid this (not sure what the guarantees are that you want to provide), you can do something like this instead:\r\n```suggestion\r\n\r\n        while (running) {\r\n            TaxiFare fare = new TaxiFare(id);\r\n            if (fare.startTime.compareTo(limitingTimestamp) >= 0) {\r\n                break;\r\n            }\r\n\r\n            ++id;\r\n            ctx.collect(fare);\r\n```', 'commenter': 'NicoK'}, {'comment': 'Thank you. That is cleaner, and works better in the tests.', 'commenter': 'alpinegizmo'}]"
45,build.gradle,"@@ -87,6 +87,7 @@ subprojects {
         shadow ""org.apache.flink:flink-java:${flinkVersion}""
         shadow ""org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}""
         shadow ""org.apache.flink:flink-streaming-scala_${scalaBinaryVersion}:${flinkVersion}""
+        shadow ""org.apache.flink:flink-runtime-web_${scalaBinaryVersion}:${flinkVersion}""","[{'comment': '```suggestion\r\n        \r\n        // allows using Flink\'s web UI when running in the IDE:\r\n        shadow ""org.apache.flink:flink-runtime-web_${scalaBinaryVersion}:${flinkVersion}""\r\n```', 'commenter': 'NicoK'}]"
46,README_zh.md,"@@ -0,0 +1,274 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# Apache Flink 
+
+
+
+## 
+
+[****](#set-up-your-development-environment)
+
+1. [](#software-requirements)
+1. [ flink-training ](#clone-and-build-the-flink-training-project)
+1. [ flink-training  IDE](#import-the-flink-training-project-into-your-ide)
+
+[**(taxi data stream)**](#using-the-taxi-data-streams)
+
+1. [(taxi ride)](#schema-of-taxi-ride-events)
+1. [(taxi fare)](#schema-of-taxi-fare-events)
+
+[****](#how-to-do-the-lab-exercises)
+
+1. [](#learn-about-the-data)
+2. [ IDE  Flink ](#run-and-debug-flink-programs-in-your-ide)
+3. [](#exercises-tests-and-solutions)
+
+[****](#lab-exercises)
+
+[****](#contributing)
+
+[****](#license)
+
+<a name=""set-up-your-development-environment""></a>
+
+## 
+
+
+
+<a name=""software-requirements""></a>
+
+### 
+
+LinuxOS X  Windows  Flink  Flink 
+
+- Git
+- Java 8  Java 11  JDK (JREJava)
+-  Gradle  Java (/ Scala) IDE
+    -  [IntelliJ](https://www.jetbrains.com/idea/),  [Eclipse](https://www.eclipse.org/downloads/)  [Visual Studio Code](https://code.visualstudio.com/) ( [Java extension pack](https://code.visualstudio.com/docs/java/java-tutorial) ) Java
+    -  Scala,  IntelliJ ( [Scala plugin](https://plugins.jetbrains.com/plugin/1347-scala/) )
+
+> **:information_source: Windows **  shell  UNIX 
+>  Windows  cygwin  WSL Flink (jobs)Windows Flink  webUI IDE
+
+<a name=""clone-and-build-the-flink-training-project""></a>
+
+###  flink-training 
+
+`flink-training` 
+
+> **:information_source: :**  Apache Flink  [apache/flink](https://github.com/apache/flink) 
+> -  Apache Flink  `release-1.10`
+> -  Flink  `master`  `flink:master`
+>
+>  Flink 
+
+ GitHub  `flink-training` 
+
+```bash
+git clone https://github.com/apache/flink-training.git
+cd flink-training
+./gradlew test shadowJar
+```
+
+ Flink ","[{'comment': '```suggestion\r\n Flink \r\n```', 'commenter': 'victorunique'}]"
46,README_zh.md,"@@ -0,0 +1,274 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# Apache Flink 
+
+
+
+## 
+
+[****](#set-up-your-development-environment)
+
+1. [](#software-requirements)
+1. [ flink-training ](#clone-and-build-the-flink-training-project)
+1. [ flink-training  IDE](#import-the-flink-training-project-into-your-ide)
+
+[**(taxi data stream)**](#using-the-taxi-data-streams)
+
+1. [(taxi ride)](#schema-of-taxi-ride-events)
+1. [(taxi fare)](#schema-of-taxi-fare-events)
+
+[****](#how-to-do-the-lab-exercises)
+
+1. [](#learn-about-the-data)
+2. [ IDE  Flink ](#run-and-debug-flink-programs-in-your-ide)
+3. [](#exercises-tests-and-solutions)
+
+[****](#lab-exercises)
+
+[****](#contributing)
+
+[****](#license)
+
+<a name=""set-up-your-development-environment""></a>
+
+## 
+
+
+
+<a name=""software-requirements""></a>
+
+### 
+
+LinuxOS X  Windows  Flink  Flink 
+
+- Git
+- Java 8  Java 11  JDK (JREJava)
+-  Gradle  Java (/ Scala) IDE
+    -  [IntelliJ](https://www.jetbrains.com/idea/),  [Eclipse](https://www.eclipse.org/downloads/)  [Visual Studio Code](https://code.visualstudio.com/) ( [Java extension pack](https://code.visualstudio.com/docs/java/java-tutorial) ) Java
+    -  Scala,  IntelliJ ( [Scala plugin](https://plugins.jetbrains.com/plugin/1347-scala/) )
+
+> **:information_source: Windows **  shell  UNIX 
+>  Windows  cygwin  WSL Flink (jobs)Windows Flink  webUI IDE
+
+<a name=""clone-and-build-the-flink-training-project""></a>
+
+###  flink-training 
+
+`flink-training` 
+
+> **:information_source: :**  Apache Flink  [apache/flink](https://github.com/apache/flink) 
+> -  Apache Flink  `release-1.10`
+> -  Flink  `master`  `flink:master`
+>
+>  Flink 
+
+ GitHub  `flink-training` 
+
+```bash
+git clone https://github.com/apache/flink-training.git
+cd flink-training
+./gradlew test shadowJar
+```
+
+ Flink 
+
+
+
+<details>
+<summary><strong>:cn: :  Maven </strong></summary>
+
+ Maven   [`build.gradle`](build.gradle) 
+
+```groovy
+    repositories {
+        // for access from China, you may need to uncomment this line
+        maven { url 'https://maven.aliyun.com/repository/public/' }
+        mavenCentral()
+        maven {
+            url ""https://repository.apache.org/content/repositories/snapshots/""
+            mavenContent {
+                snapshotsOnly()
+            }
+        }
+    }
+```
+</details>
+
+<details>
+<summary><strong> Scala ()</strong></summary>
+ Scala  Scala  Scala
+ [`gradle.properties`](gradle.properties)  Scala ","[{'comment': '```suggestion\r\n `gradle.properties`  Scala \r\n```', 'commenter': 'victorunique'}]"
46,hourly-tips/README_zh.md,"@@ -0,0 +1,82 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# :  ()
+
+
+
+
+event time
+
+### 
+
+[](../README_zh.md#using-the-taxi-data-streams) `TaxiFare` 
+
+`TaxiFareGenerator` watermark `DataStream<TaxiFare>`
+
+
+### 
+
+ `Tuple3<Long, Long, Float>` 
+`Tuple3<Long, Long, Float>`
+ driverId
+
+
+
+## 
+
+> :information_source:  IDE  flink-training ","[{'comment': '```suggestion\r\n> :information_source:  IDE  flink-training \r\n```', 'commenter': 'victorunique'}]"
46,long-ride-alerts/README_zh.md,"@@ -0,0 +1,93 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# : `ProcessFunction` 
+
+
+
+
+
+ START  END 
+
+END  START 
+
+ END 
+
+
+
+### 
+
+ `DataStream`
+
+### 
+
+ `DataStream<LONG>` `rideId`
+
+
+
+## 
+
+> :information_source:  IDE  flink-training ","[{'comment': '```suggestion\r\n> :information_source:  IDE  flink-training \r\n```', 'commenter': 'victorunique'}]"
46,ride-cleansing/README_zh.md,"@@ -0,0 +1,98 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# : ()
+
+ Flink [](../README_zh.md)
+[](../README_zh.md#how-to-do-the-labs)
+
+"""" `TaxiRide` 
+
+`GeoUtils`  `isInNYC(float lon, float lat)` 
+
+### 
+
+ `TaxiRide` [](../README.md#using-the-taxi-data-streams)
+
+### 
+
+ `DataStream<TaxiRide>` `GeoUtils.isInNYC()` 
+
+
+
+## 
+
+> :information_source:  IDE  flink-training ","[{'comment': '```suggestion\r\n> :information_source:  IDE  flink-training \r\n```', 'commenter': 'victorunique'}]"
46,rides-and-fares/README_zh.md,"@@ -0,0 +1,95 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# : ()
+
+ `TaxiRide`  `TaxiFare` 
+
+ `rideId`
+
+1. `TaxiRide` START 
+1. `TaxiRide` END 
+1.  `TaxiFare` 
+
+ `DataStream<RideAndFare>` `rideId`  `RideAndFare`  
+ `RideAndFare`  `rideId`  `TaxiRide` START  `TaxiFare` 
+
+### 
+
+ `TaxiRideSource`  `TaxiRide`  `TaxiFareSource`  `TaxiFare` 
+ [](../README_zh.md#using-the-taxi-data-streams)
+
+### 
+
+ `RideAndFare`  `rideId`  
+ END  START 
+
+ `new RideAndFare(ride, fare)` 
+
+
+
+## 
+
+> :information_source:  IDE  flink-training ","[{'comment': '```suggestion\r\n> :information_source:  IDE  flink-training \r\n```', 'commenter': 'victorunique'}]"
46,rides-and-fares/README_zh.md,"@@ -0,0 +1,95 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# : ()
+
+ `TaxiRide`  `TaxiFare` 
+
+ `rideId`
+
+1. `TaxiRide` START 
+1. `TaxiRide` END 
+1.  `TaxiFare` 
+
+ `DataStream<RideAndFare>` `rideId`  `RideAndFare`  
+ `RideAndFare`  `rideId`  `TaxiRide` START  `TaxiFare` 
+
+### 
+
+ `TaxiRideSource`  `TaxiRide`  `TaxiFareSource`  `TaxiFare` 
+ [](../README_zh.md#using-the-taxi-data-streams)
+
+### 
+
+ `RideAndFare`  `rideId`  
+ END  START 
+
+ `new RideAndFare(ride, fare)` 
+
+
+
+## 
+
+> :information_source:  IDE  flink-training 
+
+### 
+
+- Java:  [`org.apache.flink.training.exercises.ridesandfares.RidesAndFaresExercise`](src/main/java/org/apache/flink/training/exercises/ridesandfares/RidesAndFaresExercise.java)
+- Scala: [`org.apache.flink.training.exercises.ridesandfares.scala.RidesAndFaresExercise`](src/main/scala/org/apache/flink/training/exercises/ridesandfares/scala/RidesAndFaresExercise.scala)
+
+### 
+
+- Java:  [`org.apache.flink.training.exercises.ridesandfares.RidesAndFaresIntegrationTest`](src/test/java/org/apache/flink/training/exercises/ridesandfares/RidesAndFaresIntegrationTest.java)
+- Scala: [`org.apache.flink.training.exercises.ridesandfares.scala.RidesAndFaresIntegrationTest`](src/test/scala/org/apache/flink/training/exercises/ridesandfares/scala/RidesAndFaresIntegrationTest.scala)
+
+## 
+
+<details>
+<summary><strong></strong></summary>
+
+ `RichCoFlatMap`  rideId ","[{'comment': '```suggestion\r\n `RichCoFlatMap`  rideId \r\n```', 'commenter': 'victorunique'}]"
52,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -97,18 +99,61 @@ public static void main(String[] args) throws Exception {
 
     @VisibleForTesting
     public static class AlertFunction extends KeyedProcessFunction<Long, TaxiRide, Long> {
-
+        private ValueState<TaxiRide> rideState;","[{'comment': 'Since this class implement `Serializable` interface\r\nIt has to be `transient`\r\n` private transient ValueState<TaxiRide> rideState;`\r\nAlso I recommend to specify\r\n`serialVersionUID`\r\nprivate static final long serialVersionUID = 1L;\r\n\r\n', 'commenter': 'pavel-hp'}]"
52,rides-and-fares/src/main/java/org/apache/flink/training/exercises/ridesandfares/RidesAndFaresExercise.java,"@@ -98,20 +100,39 @@ public static void main(String[] args) throws Exception {
 
     public static class EnrichmentFunction
             extends RichCoFlatMapFunction<TaxiRide, TaxiFare, RideAndFare> {
+        private ValueState<TaxiRide> rideState;","[{'comment': 'Since this class implement Serializable interface\r\nIt has to be transient \r\nAlso I recommend to specify\r\nserialVersionUID', 'commenter': 'pavel-hp'}]"
