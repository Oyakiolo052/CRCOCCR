Pull,Path,Diff_hunk,Comment
13,long-ride-alerts/DISCUSSION.md,"@@ -21,7 +21,23 @@ under the License.
 
 (Discussion of [Lab: `ProcessFunction` and Timers (Long Ride Alerts)](./))
 
+It would be interesting to test that the solution does not leak state.
 
+A good way to write unit tests for a `KeyedProcessFunction` that check for state retention, etc., is to","[{'comment': '```suggestion\r\nA good way to write unit tests for a `KeyedProcessFunction` to check for state retention, etc., is to\r\n```', 'commenter': 'NicoK'}]"
13,long-ride-alerts/DISCUSSION.md,"@@ -21,7 +21,23 @@ under the License.
 
 (Discussion of [Lab: `ProcessFunction` and Timers (Long Ride Alerts)](./))
 
+It would be interesting to test that the solution does not leak state.
 
+A good way to write unit tests for a `KeyedProcessFunction` that check for state retention, etc., is to
+use the test harnesses described in the
+[documentation on testing](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html#unit-testing-stateful-or-timely-udfs--custom-operators). 
+
+In fact, the reference solutions will leak state in the case where a START event is missing. They also
+leak in the case where the alert is generated, but then the END event does eventually arrive (after `onTimer()`
+has cleared the matching START event).
+
+This could be addressed either by using [state TTL](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/state.html#state-time-to-live-ttl),
+or by using another timer that eventually
+clears any remaining state. There is a tradeoff here, however: once that state has been removed,
+then if the matching events are't actually missing, but are instead very, very late, they will cause erroneous alerts.","[{'comment': '```suggestion\r\nthen if the matching events are not actually missing, but are instead very, very late, they will cause erroneous alerts.\r\n```', 'commenter': 'NicoK'}]"
13,long-ride-alerts/README.md,"@@ -62,13 +62,11 @@ The resulting stream should be printed to standard out.
 <details>
 <summary><strong>Overall approach</strong></summary>
 
-This exercise revolves around using a `ProcessFunction` to manage some keyed state and event time timers, and doing so in a way that works even when the END event for a given `rideId` arrives before the START (which will happen). The challenge is figuring out what state to keep, and when to set and clear that state.
-</details>
-
-<details>
-<summary><strong>Timers and State</strong></summary>
-
-You will want to use event time timers that fire two hours after the incoming events, and in the `onTimer()` method, collect START events to the output only if a matching END event hasn't yet arrived. As for what state to keep, it is enough to remember the ""last"" event for each `rideId`, where ""last"" is based on event time and ride type (START vs END &mdash; yes, there are rides where the START and END have the same timestamp), rather than the order in which the events are processed. The `TaxiRide` class implements `Comparable`; feel free to take advantage of that, and be sure to eventually clear any state you create.","[{'comment': 'Why did you remove the hints on what state to keep?', 'commenter': 'NicoK'}, {'comment': ""That hint was somewhat wrong-headed. I've written a new hint that points (rather strongly) toward the new solution."", 'commenter': 'alpinegizmo'}]"
13,long-ride-alerts/README.md,"@@ -69,6 +69,20 @@ You will want to use event time timers that fire two hours after an incoming STA
 collect START events to the output only if a matching END event hasn't yet arrived.
 </details>
 
+<details>
+<summary><strong>State and timers</strong></summary>
+
+There are many possible solutions for this exercise, but in general it is enough to keep one
+`TaxiRide` in state (one `TaxiRide` for each key, or `rideId`). The approach used in the reference solution is to
+store whichever event arrives first (the START or the END), and if it's a START event,
+create a timer for two hours later. If and when the other event (for the same rideId) arrives,","[{'comment': '```suggestion\r\ncreate a timer for two hours later. If and when the other event (for the same `rideId`) arrives,\r\n```', 'commenter': 'NicoK'}]"
13,long-ride-alerts/README.md,"@@ -69,6 +69,20 @@ You will want to use event time timers that fire two hours after an incoming STA
 collect START events to the output only if a matching END event hasn't yet arrived.
 </details>
 
+<details>
+<summary><strong>State and timers</strong></summary>
+
+There are many possible solutions for this exercise, but in general it is enough to keep one
+`TaxiRide` in state (one `TaxiRide` for each key, or `rideId`). The approach used in the reference solution is to
+store whichever event arrives first (the START or the END), and if it's a START event,
+create a timer for two hours later. If and when the other event (for the same rideId) arrives,
+carefully clean things up.
+
+It's possible to arrange this so that if `onTimer()` is called, you are guaranteed that","[{'comment': '```suggestion\r\nIt is possible to arrange this so that if `onTimer()` is called, you are guaranteed that\r\n```', 'commenter': 'NicoK'}]"
16,ride-cleansing/README.md,"@@ -27,7 +27,7 @@ The `GeoUtils` utility class provides a static method `isInNYC(float lon, float
 
 ### Input Data
 
-This series of exercises is based a stream of `TaxiRide` events, as described in [Using the Taxi Data Streams](../README.md#using-the-taxi-data-streams).
+This series of exercises is based on stream of `TaxiRide` events, as described in [Using the Taxi Data Streams](../README.md#using-the-taxi-data-streams).","[{'comment': '```suggestion\r\nThis exercise is based on a stream of `TaxiRide` events, as described in [Using the Taxi Data Streams](../README.md#using-the-taxi-data-streams).\r\n```', 'commenter': 'alpinegizmo'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ComposedPipeline.java,"@@ -0,0 +1,47 @@
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
+import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
+
+/**
+ * This allows the tests to be run against both the exercises and the solutions.
+ *
+ * <p>If an exercise throws MissingSolutionException, then the solution is tested.
+ */
+public class ComposedPipeline<IN, OUT> implements ExecutablePipeline<IN, OUT> {
+
+    private ExecutablePipeline<IN, OUT> exercise;
+    private ExecutablePipeline<IN, OUT> solution;
+
+    public ComposedPipeline(
+            ExecutablePipeline<IN, OUT> exercise, ExecutablePipeline<IN, OUT> solution) {
+        this.exercise = exercise;
+        this.solution = solution;
+    }
+
+    @Override
+    public void execute(SourceFunction<IN> source, TestSink<OUT> sink) throws Exception {
+
+        sink.reset();
+
+        try {
+            exercise.execute(source, sink);
+        } catch (Exception e) {
+            if (ultimateCauseIsMissingSolution(e)) {
+                solution.execute(source, sink);
+            } else {
+                throw e;
+            }
+        }
+    }
+
+    private boolean ultimateCauseIsMissingSolution(Throwable e) {
+        if (e instanceof MissingSolutionException) {
+            return true;
+        } else if (e.getCause() != null) {
+            return ultimateCauseIsMissingSolution(e.getCause());
+        } else {
+            return false;
+        }","[{'comment': ""I'm not sure how deep these stack traces could be, but wouldn't it be better to iterate through these instead?\r\n```suggestion\r\n        while (e != null) {\r\n            if (e instanceof MissingSolutionException) {\r\n                return true;\r\n            } else {\r\n                e = e.getCause();\r\n            }\r\n        }\r\n        return false;\r\n```"", 'commenter': 'NicoK'}]"
31,common/build.gradle,"@@ -17,6 +17,10 @@ dependencies {
     shadow ""org.apache.flink:flink-runtime_${scalaBinaryVersion}:${flinkVersion}""
 
     testApi ""junit:junit:${junitVersion}""
+    testApi ""org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}:tests""
+    testApi ""org.apache.flink:flink-runtime_${scalaBinaryVersion}:${flinkVersion}:tests""
     testApi ""org.apache.flink:flink-test-utils-junit:${flinkVersion}""
+    testApi ""org.apache.flink:flink-test-utils_${scalaBinaryVersion}:${flinkVersion}""
     testApi 'org.hamcrest:hamcrest-library:1.3'
+    testApi 'org.assertj:assertj-core:3.20.2'","[{'comment': ""Do wee need this dependency? Isn't `org.junit.Assert#assertThat()` doing the same?"", 'commenter': 'NicoK'}, {'comment': ""It's my intention to replace hamcrest with assertj. The motivation is to be able to use assertj's assertions on Collections, such as containsExactlyInAnyOrder.\r\n\r\nI don't believe this is possible with junit (or hamcrest)."", 'commenter': 'alpinegizmo'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ParallelTestSource.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class ParallelTestSource<T> extends RichParallelSourceFunction<T> {
+    protected T[] testStream;
+    TestSourcePartitioner<T> partitioner;
+    private List<T> substream;
+
+    public ParallelTestSource(TestSourcePartitioner<T> partitioner, T... events) {
+        this.partitioner = partitioner;
+        this.testStream = events;
+    }
+
+    public ParallelTestSource(T... events) {
+        this.partitioner = (e -> 0);
+        this.testStream = events;
+    }
+
+    @Override
+    public void open(Configuration parameters) throws Exception {
+
+        int indexOfThisSubtask = getRuntimeContext().getIndexOfThisSubtask();
+        int numberOfParallelSubtasks = getRuntimeContext().getNumberOfParallelSubtasks();
+        substream = new ArrayList<>();
+
+        for (int i = 0; i < testStream.length; i++) {
+            T element = testStream[i];
+            long subtaskToUse = partitioner.partition(element) % numberOfParallelSubtasks;
+
+            if (subtaskToUse == indexOfThisSubtask) {
+                substream.add(element);
+            } else if (subtaskToUse < 0 || subtaskToUse > numberOfParallelSubtasks - 1) {
+                throw new RuntimeException(""Requested subtask is out-of-bounds: "" + subtaskToUse);
+            }
+        }","[{'comment': ""Did you create this `substream` separately for debugging purposes to see which elements are actually contained in a source? Otherwise, we can skip this variable and integrate the logic here into `run()` (but maybe, it's relevant for the source interface change)"", 'commenter': 'NicoK'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ParallelTestSource.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class ParallelTestSource<T> extends RichParallelSourceFunction<T> {
+    protected T[] testStream;
+    TestSourcePartitioner<T> partitioner;
+    private List<T> substream;
+
+    public ParallelTestSource(TestSourcePartitioner<T> partitioner, T... events) {
+        this.partitioner = partitioner;
+        this.testStream = events;
+    }
+
+    public ParallelTestSource(T... events) {
+        this.partitioner = (e -> 0);
+        this.testStream = events;
+    }
+
+    @Override
+    public void open(Configuration parameters) throws Exception {
+
+        int indexOfThisSubtask = getRuntimeContext().getIndexOfThisSubtask();
+        int numberOfParallelSubtasks = getRuntimeContext().getNumberOfParallelSubtasks();
+        substream = new ArrayList<>();
+
+        for (int i = 0; i < testStream.length; i++) {
+            T element = testStream[i];","[{'comment': '```suggestion\r\n        for (T element : testStream) {\r\n```', 'commenter': 'NicoK'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/TestSink.java,"@@ -0,0 +1,26 @@
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+
+public class TestSink<OUT> implements SinkFunction<OUT> {
+
+    // must be static
+    public static final List VALUES = Collections.synchronizedList(new ArrayList<>());
+
+    @Override
+    public void invoke(OUT value, Context context) {
+        VALUES.add(value);
+    }
+
+    public Iterable<OUT> results() {
+        return VALUES;
+    }
+
+    public void reset() {
+        VALUES.clear();
+    }
+}","[{'comment': 'In the Flink sources, I also found this pattern for test sinks:\r\n```\r\n        stream.addSink(\r\n                new RichSinkFunction<Integer>() {\r\n                    @Override\r\n                    public void open(Configuration parameters) throws Exception {\r\n                        getRuntimeContext()\r\n                                .addAccumulator(""result"", new ListAccumulator<Integer>());\r\n                    }\r\n\r\n                    @Override\r\n                    public void invoke(Integer value, Context context) throws Exception {\r\n                        getRuntimeContext().getAccumulator(""result"").add(value);\r\n                    }\r\n                });\r\n        List<Integer> result = env.execute().getAccumulatorResult(""result"");\r\n```\r\n-> maybe that\'s a cleaner approach to fetching results?\r\n\r\nAnother, probably even better, option: using `org.apache.flink.streaming.util.StreamCollector#collect`. In that case, we wouldn\'t even need our own `SinkFunction`.', 'commenter': 'NicoK'}]"
31,common/src/test/java/org/apache/flink/training/exercises/testing/ParallelTestSource.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.flink.training.exercises.testing;
+
+import org.apache.flink.configuration.Configuration;
+import org.apache.flink.streaming.api.functions.source.RichParallelSourceFunction;
+
+import java.util.ArrayList;
+import java.util.List;
+
+public class ParallelTestSource<T> extends RichParallelSourceFunction<T> {
+    protected T[] testStream;
+    TestSourcePartitioner<T> partitioner;
+    private List<T> substream;
+
+    public ParallelTestSource(TestSourcePartitioner<T> partitioner, T... events) {
+        this.partitioner = partitioner;
+        this.testStream = events;
+    }
+
+    public ParallelTestSource(T... events) {
+        this.partitioner = (e -> 0);
+        this.testStream = events;
+    }
+
+    @Override
+    public void open(Configuration parameters) throws Exception {
+
+        int indexOfThisSubtask = getRuntimeContext().getIndexOfThisSubtask();
+        int numberOfParallelSubtasks = getRuntimeContext().getNumberOfParallelSubtasks();
+        substream = new ArrayList<>();
+
+        for (int i = 0; i < testStream.length; i++) {
+            T element = testStream[i];
+            long subtaskToUse = partitioner.partition(element) % numberOfParallelSubtasks;
+
+            if (subtaskToUse == indexOfThisSubtask) {
+                substream.add(element);
+            } else if (subtaskToUse < 0 || subtaskToUse > numberOfParallelSubtasks - 1) {","[{'comment': 'I think, `subtaskToUse < 0` is the only thing you need to check here.\r\n```suggestion\r\n            } else if (subtaskToUse < 0) {\r\n```', 'commenter': 'NicoK'}]"
31,long-ride-alerts/README.md,"@@ -62,41 +61,29 @@ The resulting stream should be printed to standard out.
 <details>
 <summary><strong>Overall approach</strong></summary>
 
-This exercise revolves around using a `ProcessFunction` to manage some keyed state and event time timers,
-and doing so in a way that works even when the END event for a given `rideId` arrives before the START (which can happen).
-The challenge is figuring out what state to keep, and when to set and clear that state.
-You will want to use event time timers that fire two hours after an incoming START event, and in the `onTimer()` method,
-collect START events to the output only if a matching END event hasn't yet arrived.
-</details>
-
-<details>
-<summary><strong>State and timers</strong></summary>
-
-There are many possible solutions for this exercise, but in general it is enough to keep one
-`TaxiRide` in state (one `TaxiRide` for each key, or `rideId`). The approach used in the reference solution is to
-store whichever event arrives first (the START or the END), and if it's a START event,
-create a timer for two hours later. If and when the other event (for the same `rideId`) arrives,
-carefully clean things up.
-
-It is possible to arrange this so that if `onTimer()` is called, you are guaranteed that
-an alert (i.e., the ride kept in state) should be emitted. Writing the code this way conveniently
-puts all of the complex business logic together in one place (in the `processElement()` method).
+This exercise revolves around using a `KeyedProcessFunction` to manage some state and event time timers,
+and doing so in a way that works even when the END event for a given `rideId` arrives before the START.
+The challenge is figuring out what state and timers to use, and when to set and clear the state (and timers).
+It is not enough to simply wait for the END event and calculate the duration, as the END event
+may be missing.
 </details>
 
 ## Documentation
 
 - [ProcessFunction](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/operators/process_function.html)
 - [Working with State](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/index.html)
 
+## After you've completed the exercise
+
+Read the [discussion of the reference solutions](DISCUSSION.md).
+
 ## Reference Solutions
 
-Reference solutions are available at GitHub:
+Reference solutions:
 
 - Java API:  [`org.apache.flink.training.solutions.longrides.LongRidesSolution`](src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java)
 - Scala API: [`org.apache.flink.training.solutions.longrides.scala.LongRidesSolution`](src/solution/scala/org/apache/flink/training/solutions/longrides/scala/LongRidesSolution.scala)
 
 -----
 
-[**Lab Discussion: `ProcessFunction` and Timers (Long Ride Alerts)**](DISCUSSION.md)
-","[{'comment': 'Do you actually want to remove the link to the discussion page?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);","[{'comment': ""Although for a production job, we shouldn't set any configuration parameters via code, I'd argue that we may need a special environment for these exercises with well-defined settings. High default parallelism (number of CPUs) in the IDE could, for example, overload the Flink starter with just too much happening in the logs while too low parallelism may hide certain behaviour.\r\n\r\nMaybe something along the lines of https://github.com/ververica/flink-training/blob/d07b181f1fa89137da45a8ffa67ec4cbfaf90cf1/troubleshooting/common/src/main/java/com/ververica/flink/training/common/EnvironmentUtils.java#L44 which enables the web UI on a well-defined port.\r\n\r\nMaybe we could also hide this under a nice builder pattern...\r\n\r\nEither way, that may be a follow-up PR but not sure we should change the parallelism here or rather put this into its own (bigger-scoped) improvements..."", 'commenter': 'NicoK'}, {'comment': ""I dislike the ExerciseBase class, because its existence makes the exercises more complex to understand. I added parallelism to that class when I decided to execute the tests with a parallelism of 1, which I now regret.\r\n\r\nI'm not convinced it's worthwhile to control the parallelism in the exercises -- I don't want to pollute the exercises with inessential details, or things that shouldn't be there in production. I think it's more important to keep the code looking simple than to reduce the logging a bit. There's so much logging on startup anyway.\r\n\r\nAnd I don't really want to include something like createConfiguredEnvironment as used in the troubleshooting exercises in the starter exercises, because it's very scary looking, and it's not possible for a beginner to understand what's going on and whether or not they should have similar code in their own applications.\r\n\r\n"", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);
 
         // start the data generator
-        DataStream<TaxiRide> rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()));
+        DataStream<TaxiRide> rides = env.addSource(source, TypeInformation.of(TaxiRide.class));","[{'comment': ""Not sure why you added this here, but it doesn't seem like we need to provide the type information manually\r\n```suggestion\r\n        DataStream<TaxiRide> rides = env.addSource(source);\r\n```"", 'commenter': 'NicoK'}, {'comment': ""That type information was needed in some intermediate version -- but fortunately, it's no longer useful. "", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);
 
         // start the data generator
-        DataStream<TaxiRide> rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()));
+        DataStream<TaxiRide> rides = env.addSource(source, TypeInformation.of(TaxiRide.class));
 
-        DataStream<TaxiRide> longRides =
-                rides.keyBy((TaxiRide ride) -> ride.rideId).process(new MatchFunction());
+        // the WatermarkStrategy specifies how to extract timestamps and generate watermarks
+        WatermarkStrategy<TaxiRide> watermarkStrategy =
+                WatermarkStrategy.<TaxiRide>forBoundedOutOfOrderness(Duration.ofSeconds(60))
+                        .withTimestampAssigner((ride, timestamp) -> ride.getEventTime());","[{'comment': ""The second parameter here is:\r\n> The current internal timestamp of the element, or a negative value, if no timestamp has been assigned yet.\r\n\r\nI'm not sure (didactically) how to name that one not to be confusing, but `timestamp` sounds misleading ... wdyt?"", 'commenter': 'NicoK'}, {'comment': ""I've changed it to streamRecordTimestamp -- see what you think."", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;","[{'comment': 'This design with an instance of a `SourceFunction` probably needs to be changed when using the new source interface and putting the timestamp assigner into the source.\r\nShould we take that into account now?', 'commenter': 'NicoK'}, {'comment': ""I prefer to wait. Before creating this PR I experimented with schemes for including that, and concluded it's better to wait."", 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -18,62 +18,96 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.api.common.eventtime.WatermarkStrategy;
+import org.apache.flink.api.common.typeinfo.TypeInformation;
 import org.apache.flink.configuration.Configuration;
 import org.apache.flink.streaming.api.TimerService;
 import org.apache.flink.streaming.api.datastream.DataStream;
 import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
+import org.apache.flink.streaming.api.functions.sink.PrintSinkFunction;
+import org.apache.flink.streaming.api.functions.sink.SinkFunction;
+import org.apache.flink.streaming.api.functions.source.SourceFunction;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator;
-import org.apache.flink.training.exercises.common.utils.ExerciseBase;
 import org.apache.flink.training.exercises.common.utils.MissingSolutionException;
 import org.apache.flink.util.Collector;
 
+import java.time.Duration;
+
 /**
- * The ""Long Ride Alerts"" exercise of the Flink training in the docs.
+ * The ""Long Ride Alerts"" exercise.
+ *
+ * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+ * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
  *
- * <p>The goal for this exercise is to emit START events for taxi rides that have not been matched
- * by an END event during the first 2 hours of the ride.
+ * <p>You should eventually clear any state you create.
  */
-public class LongRidesExercise extends ExerciseBase {
+public class LongRidesExercise {
+    private SourceFunction<TaxiRide> source;
+    private SinkFunction<Long> sink;
+
+    /** Creates a job using the source and sink provided. */
+    public LongRidesExercise(SourceFunction<TaxiRide> source, SinkFunction<Long> sink) {
+        this.source = source;
+        this.sink = sink;
+    }
 
     /**
-     * Main method.
+     * Creates and executes the long rides pipeline.
      *
-     * @throws Exception which occurs during job execution.
+     * <p>@throws Exception which occurs during job execution.
      */
-    public static void main(String[] args) throws Exception {
+    public void execute() throws Exception {
 
         // set up streaming execution environment
         StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
-        env.setParallelism(ExerciseBase.parallelism);
 
         // start the data generator
-        DataStream<TaxiRide> rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()));
+        DataStream<TaxiRide> rides = env.addSource(source, TypeInformation.of(TaxiRide.class));
 
-        DataStream<TaxiRide> longRides =
-                rides.keyBy((TaxiRide ride) -> ride.rideId).process(new MatchFunction());
+        // the WatermarkStrategy specifies how to extract timestamps and generate watermarks
+        WatermarkStrategy<TaxiRide> watermarkStrategy =
+                WatermarkStrategy.<TaxiRide>forBoundedOutOfOrderness(Duration.ofSeconds(60))
+                        .withTimestampAssigner((ride, timestamp) -> ride.getEventTime());
 
-        printOrTest(longRides);
+        // create the pipeline
+        rides.assignTimestampsAndWatermarks(watermarkStrategy)
+                .keyBy((TaxiRide ride) -> ride.rideId)","[{'comment': 'Simpler? Or did you want to make the type explicit?\r\n```suggestion\r\n                .keyBy(ride -> ride.rideId)\r\n```', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/main/scala/org/apache/flink/training/exercises/longrides/scala/LongRidesExercise.scala,"@@ -18,55 +18,83 @@
 
 package org.apache.flink.training.exercises.longrides.scala
 
+import org.apache.flink.api.common.eventtime.{SerializableTimestampAssigner, WatermarkStrategy}","[{'comment': ""Most of the comments for the Java exercise apply 1:1...I'll omit listing them here again"", 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -71,36 +109,53 @@ public void open(Configuration config) {
         }
 
         @Override
-        public void processElement(TaxiRide ride, Context context, Collector<TaxiRide> out)
+        public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
-            TaxiRide previousRideEvent = rideState.value();
 
-            if (previousRideEvent == null) {
+            TaxiRide firstRideEvent = rideState.value();
+
+            if (firstRideEvent == null) {
                 rideState.update(ride);
+
                 if (ride.isStart) {
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
+                } else {
+                    if (rideTooLong(ride)) {
+                        out.collect(ride.rideId);
+                    }
                 }
             } else {
-                if (!ride.isStart) {
-                    // it's an END event, so event saved was the START event and has a timer
-                    // the timer hasn't fired yet, and we can safely kill the timer
-                    context.timerService().deleteEventTimeTimer(getTimerTime(previousRideEvent));
+                if (ride.isStart) {
+                    // There's nothing to do but clear the state (which is done below).
+                } else {
+                    // There may be a timer that hasn't fired yet.
+                    context.timerService().deleteEventTimeTimer(getTimerTime(firstRideEvent));
+
+                    // It could be that the ride has gone on too long, but the timer hasn't fired.","[{'comment': ""```suggestion\r\n                    // It could be that the ride has gone on too long, but the timer hasn't fired yet.\r\n```"", 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/solution/scala/org/apache/flink/training/solutions/longrides/scala/LongRidesSolution.scala,"@@ -18,81 +18,124 @@
 
 package org.apache.flink.training.solutions.longrides.scala
 
-import scala.concurrent.duration._
+import org.apache.flink.api.common.eventtime.{SerializableTimestampAssigner, WatermarkStrategy}
 import org.apache.flink.api.common.state.{ValueState, ValueStateDescriptor}
+import org.apache.flink.configuration.Configuration
 import org.apache.flink.streaming.api.functions.KeyedProcessFunction
+import org.apache.flink.streaming.api.functions.sink.{PrintSinkFunction, SinkFunction}
+import org.apache.flink.streaming.api.functions.source.SourceFunction
 import org.apache.flink.streaming.api.scala.{StreamExecutionEnvironment, _}
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide
 import org.apache.flink.training.exercises.common.sources.TaxiRideGenerator
-import org.apache.flink.training.exercises.common.utils.ExerciseBase
-import org.apache.flink.training.exercises.common.utils.ExerciseBase._
 import org.apache.flink.util.Collector
 
+import scala.concurrent.duration._
+import java.time.Duration
+
 /**
-  * Scala reference implementation for the ""Long Ride Alerts"" exercise of the Flink training in the docs.
+  * Scala solution for the ""Long Ride Alerts"" exercise.
   *
-  * The goal for this exercise is to emit START events for taxi rides that have not been matched
-  * by an END event during the first 2 hours of the ride.
+  * <p>The goal for this exercise is to emit the rideIds for taxi rides with a duration of more than
+  * two hours. You should assume that TaxiRide events can be lost, but there are no duplicates.
   *
+  * <p>You should eventually clear any state you create.
   */
 object LongRidesSolution {
 
-  def main(args: Array[String]) {
-
-    // set up the execution environment
-    val env = StreamExecutionEnvironment.getExecutionEnvironment
-    // operate in Event-time
-    env.setParallelism(ExerciseBase.parallelism)
-
-    val rides = env.addSource(rideSourceOrTest(new TaxiRideGenerator()))
+  class LongRidesJob(source: SourceFunction[TaxiRide], sink: SinkFunction[Long]) {
+
+    /**
+     * Creates and executes the ride cleansing pipeline.
+     */
+    @throws[Exception]
+    def execute(): Unit = {
+      val env = StreamExecutionEnvironment.getExecutionEnvironment
+
+      // start the data generator
+      val rides = env.addSource(source)
+
+      // the WatermarkStrategy specifies how to extract timestamps and generate watermarks
+      val watermarkStrategy = WatermarkStrategy
+        .forBoundedOutOfOrderness[TaxiRide](Duration.ofSeconds(60))
+        .withTimestampAssigner(new SerializableTimestampAssigner[TaxiRide] {
+          override def extractTimestamp(element: TaxiRide, recordTimestamp: Long): Long =
+            element.getEventTime
+        })
+
+      // create the pipeline
+      rides
+        .assignTimestampsAndWatermarks(watermarkStrategy)
+        .keyBy(_.rideId)
+        .process(new MatchFunction())
+        .addSink(sink)
+
+      // execute the pipeline
+      env.execute(""Long Taxi Rides"")
+    }
 
-    val longRides = rides
-      .keyBy(_.rideId)
-      .process(new MatchFunction())
+  }
 
-    printOrTest(longRides)
+  @throws[Exception]
+  def main (args: Array[String]) {
+    val job = new LongRidesJob(new TaxiRideGenerator, new PrintSinkFunction)
 
-    env.execute(""Long Taxi Rides"")
+    job.execute
   }
 
-  class MatchFunction extends KeyedProcessFunction[Long, TaxiRide, TaxiRide] {
-    lazy val rideState: ValueState[TaxiRide] = getRuntimeContext.getState(
-      new ValueStateDescriptor[TaxiRide](""ride event"", classOf[TaxiRide]))
+  class MatchFunction extends KeyedProcessFunction[Long, TaxiRide, Long] {
+    private var rideState: ValueState[TaxiRide] = _
+
+    override def open(parameters: Configuration): Unit = {
+      rideState = getRuntimeContext.getState(
+        new ValueStateDescriptor[TaxiRide](""ride event"", classOf[TaxiRide]))
+    }
 
     override def processElement(ride: TaxiRide,
-                                context: KeyedProcessFunction[Long, TaxiRide, TaxiRide]#Context,
-                                out: Collector[TaxiRide]): Unit = {
+                                context: KeyedProcessFunction[Long, TaxiRide, Long]#Context,
+                                out: Collector[Long]): Unit = {
 
-      val previousRideEvent = rideState.value()
+      val firstRideEvent = rideState.value()
 
-      if (previousRideEvent == null) {
+      if (firstRideEvent == null) {
         rideState.update(ride)
         if (ride.isStart) {
-          context.timerService().registerEventTimeTimer(getTimerTime(ride))
+          context.timerService.registerEventTimeTimer(getTimerTime(ride))
+        }
+        else if (rideTooLong(ride)) {
+          out.collect(ride.rideId)
         }
-      } else {
-        if (!ride.isStart) {
-          // it's an END event, so event saved was the START event and has a timer
-          // the timer hasn't fired yet, and we can safely kill the timer
-          context.timerService().deleteEventTimeTimer(getTimerTime(previousRideEvent))
+      }
+      else {","[{'comment': 'note sure style-wise, but before this was collapsed into a single line', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesHarnessTest.java,"@@ -0,0 +1,56 @@
+package org.apache.flink.training.exercises.longrides;
+
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.streaming.api.operators.KeyedProcessOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
+import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
+import org.apache.flink.training.solutions.longrides.LongRidesSolution;
+
+import org.junit.Test;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
+
+public class LongRidesHarnessTest {
+
+    @Test
+    public void testLongRideAlertsAsSoonAsPossible() throws Exception {
+        KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> harness = setupHarness();
+
+        TaxiRide startOfLongRide = LongRidesTest.startRide(1, LongRidesTest.BEGINNING);
+        harness.processElement(new StreamRecord<>(startOfLongRide, startOfLongRide.getEventTime()));","[{'comment': 'Do you want to check that there is no output yet after processing this?', 'commenter': 'NicoK'}, {'comment': 'Sure, I think that makes sense.', 'commenter': 'alpinegizmo'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesHarnessTest.java,"@@ -0,0 +1,56 @@
+package org.apache.flink.training.exercises.longrides;
+
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.streaming.api.operators.KeyedProcessOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
+import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
+import org.apache.flink.training.solutions.longrides.LongRidesSolution;
+
+import org.junit.Test;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
+
+public class LongRidesHarnessTest {
+
+    @Test
+    public void testLongRideAlertsAsSoonAsPossible() throws Exception {","[{'comment': ""I think, we'd need a couple of more tests to verify the full behaviour, including:\r\n\r\n- alerting directly if you see the end event first\r\n- not alerting for a start event until the watermark is exactly 2h ahead (even if you see later data or processing time advances beyond 2h)\r\n- not alerting for an end event that is not too long\r\n- alerting if there is no event but the watermark surpasses the 2h\r\n- state cleanup (in the good case - not the leak we leave for the open discussion)\r\n\r\nShould we also verify that things, i.e. the start events, are kept in Flink state after all and not some other local Java store (best-effort by just looking at the number of state entries > 0)?"", 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesHarnessTest.java,"@@ -0,0 +1,56 @@
+package org.apache.flink.training.exercises.longrides;
+
+import org.apache.flink.api.common.typeinfo.BasicTypeInfo;
+import org.apache.flink.streaming.api.operators.KeyedProcessOperator;
+import org.apache.flink.streaming.api.watermark.Watermark;
+import org.apache.flink.streaming.runtime.streamrecord.StreamRecord;
+import org.apache.flink.streaming.util.KeyedOneInputStreamOperatorTestHarness;
+import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
+import org.apache.flink.training.solutions.longrides.LongRidesSolution;
+
+import org.junit.Test;
+
+import java.util.concurrent.ConcurrentLinkedQueue;
+
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
+
+public class LongRidesHarnessTest {
+
+    @Test
+    public void testLongRideAlertsAsSoonAsPossible() throws Exception {
+        KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> harness = setupHarness();
+
+        TaxiRide startOfLongRide = LongRidesTest.startRide(1, LongRidesTest.BEGINNING);
+        harness.processElement(new StreamRecord<>(startOfLongRide, startOfLongRide.getEventTime()));
+
+        Watermark mark2HoursLater =
+                new Watermark(LongRidesTest.BEGINNING.plusSeconds(120 * 60).toEpochMilli());
+        harness.processWatermark(mark2HoursLater);
+
+        // Check that the result is correct
+        ConcurrentLinkedQueue<Object> actualOutput = harness.getOutput();
+        StreamRecord<Long> rideIdAtTimeOfWatermark =
+                new StreamRecord<>(startOfLongRide.rideId, mark2HoursLater.getTimestamp());
+        assertThat(actualOutput).containsExactly(rideIdAtTimeOfWatermark, mark2HoursLater);
+
+        // Check that no state or timers are left behind
+        assertThat(harness.numKeyedStateEntries()).isZero();
+        assertThat(harness.numEventTimeTimers()).isZero();
+    }
+
+    private KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> setupHarness()
+            throws Exception {
+
+        KeyedProcessOperator<Long, TaxiRide, Long> operator =
+                new KeyedProcessOperator<>(new LongRidesSolution.MatchFunction());
+
+        KeyedOneInputStreamOperatorTestHarness<Long, TaxiRide, Long> testHarness =
+                new KeyedOneInputStreamOperatorTestHarness<>(
+                        operator, (TaxiRide r) -> r.rideId, BasicTypeInfo.LONG_TYPE_INFO);","[{'comment': '```suggestion\r\n                        operator, (TaxiRide r) -> r.rideId, Types.LONG);\r\n```', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {","[{'comment': 'Is this test more of a UnitTest?\r\n\r\n---\r\n\r\nIn general, the line may be difficult to draw, but how about this:\r\n- an integration test focuses on the whole pipeline (so here: watermarks + keyBy + MatchFunction) and any interplay between these\r\n- a unit test focuses on the logic of the MatchFunction alone\r\n\r\nFor this, we could actually also remove the watermarking code from the exercise and add this to the work to be done (unless you think, it may be too much to ask for a first exercise)', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {","[{'comment': 'Unit test?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {","[{'comment': 'Unit test?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long mark2HoursLater = BEGINNING.plusSeconds(120 * 60).toEpochMilli();
-        TaxiRide rideEnded3HoursLater = endRide(rideStarted, BEGINNING.plusSeconds(180 * 60));
 
-        TestRideSource source =
-                new TestRideSource(rideStarted, mark2HoursLater, rideEnded3HoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void startIsDelayedMoreThanTwoHours() throws Exception {
-        TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide rideEndedAfter1Hour = endRide(rideStarted, BEGINNING.plusSeconds(60 * 60));
-        Long mark2HoursAfterEnd = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+    public void endComesAfter3Hours() throws Exception {","[{'comment': 'Unit test?', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long mark2HoursLater = BEGINNING.plusSeconds(120 * 60).toEpochMilli();
-        TaxiRide rideEnded3HoursLater = endRide(rideStarted, BEGINNING.plusSeconds(180 * 60));
 
-        TestRideSource source =
-                new TestRideSource(rideStarted, mark2HoursLater, rideEnded3HoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void startIsDelayedMoreThanTwoHours() throws Exception {
-        TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide rideEndedAfter1Hour = endRide(rideStarted, BEGINNING.plusSeconds(60 * 60));
-        Long mark2HoursAfterEnd = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+    public void endComesAfter3Hours() throws Exception {
+        TaxiRide startOfLongRide = startRide(1, BEGINNING);
+        TaxiRide longRideEndedAfter3Hours = endRide(startOfLongRide, THREE_HOURS_LATER);
 
-        TestRideSource source =
-                new TestRideSource(rideEndedAfter1Hour, mark2HoursAfterEnd, rideStarted);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(
+                        new PartitionByRideId(), startOfLongRide, longRideEndedAfter3Hours);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(startOfLongRide.rideId);
+    }
+
+    @Test
+    public void multipleRides() throws Exception {
+        TaxiRide startOfOneRide = startRide(1, BEGINNING);
+        TaxiRide otherRide = startRide(2, ONE_MINUTE_LATER);
+        TaxiRide oneRideEnded = endRide(startOfOneRide, THREE_HOURS_LATER);
+        TaxiRide otherRideEnded = endRide(otherRide, THREE_HOURS_LATER);","[{'comment': 'Do you want to add a couple of more rides (just 2h, just below 2h, without end,...) to mix things up a bit (more of an ITCase)', 'commenter': 'NicoK'}]"
31,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesTest.java,"@@ -18,89 +18,150 @@
 
 package org.apache.flink.training.exercises.longrides;
 
+import org.apache.flink.runtime.testutils.MiniClusterResourceConfiguration;
+import org.apache.flink.test.util.MiniClusterWithClientResource;
 import org.apache.flink.training.exercises.common.datatypes.TaxiRide;
-import org.apache.flink.training.exercises.testing.TaxiRideTestBase;
+import org.apache.flink.training.exercises.testing.ComposedPipeline;
+import org.apache.flink.training.exercises.testing.ExecutablePipeline;
+import org.apache.flink.training.exercises.testing.ParallelTestSource;
+import org.apache.flink.training.exercises.testing.TestSink;
+import org.apache.flink.training.exercises.testing.TestSourcePartitioner;
 import org.apache.flink.training.solutions.longrides.LongRidesSolution;
 
+import org.junit.ClassRule;
 import org.junit.Test;
 
 import java.time.Instant;
-import java.util.Collections;
-import java.util.List;
 
-import static org.junit.Assert.assertEquals;
+import static org.assertj.core.api.AssertionsForInterfaceTypes.assertThat;
 
-public class LongRidesTest extends TaxiRideTestBase<TaxiRide> {
+public class LongRidesTest {
 
-    static final Testable JAVA_EXERCISE = () -> LongRidesExercise.main(new String[] {});
+    private static final int PARALLELISM = 2;
 
-    private static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    /** This isn't necessary, but speeds up the tests. */
+    @ClassRule
+    public static MiniClusterWithClientResource flinkCluster =
+            new MiniClusterWithClientResource(
+                    new MiniClusterResourceConfiguration.Builder()
+                            .setNumberSlotsPerTaskManager(PARALLELISM)
+                            .setNumberTaskManagers(1)
+                            .build());
+
+    public static final Instant BEGINNING = Instant.parse(""2020-01-01T12:00:00.00Z"");
+    public static final Instant ONE_MINUTE_LATER = BEGINNING.plusSeconds(60);
+    public static final Instant THREE_HOURS_LATER = BEGINNING.plusSeconds(180 * 60);
 
     @Test
     public void shortRide() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
+
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(rideStarted, endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted, endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void outOfOrder() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater, rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, rideStarted, markOneMinLater);
-        assert (results(source).isEmpty());
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
     public void noStartShort() throws Exception {
-        Instant oneMinLater = BEGINNING.plusSeconds(60);
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide endedOneMinLater = endRide(rideStarted, oneMinLater);
-        Long markOneMinLater = oneMinLater.toEpochMilli();
+        TaxiRide endedOneMinLater = endRide(rideStarted, ONE_MINUTE_LATER);
 
-        TestRideSource source = new TestRideSource(endedOneMinLater, markOneMinLater);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedOneMinLater);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).isEmpty();
     }
 
     @Test
-    public void noEnd() throws Exception {
+    public void noStartLong() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long markThreeHoursLater = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+        TaxiRide endedThreeHoursLater = endRide(rideStarted, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), endedThreeHoursLater);
+        TestSink<Long> sink = new TestSink<Long>();
 
-        TestRideSource source = new TestRideSource(rideStarted, markThreeHoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void longRide() throws Exception {
+    public void endIsMissing() throws Exception {
         TaxiRide rideStarted = startRide(1, BEGINNING);
-        Long mark2HoursLater = BEGINNING.plusSeconds(120 * 60).toEpochMilli();
-        TaxiRide rideEnded3HoursLater = endRide(rideStarted, BEGINNING.plusSeconds(180 * 60));
 
-        TestRideSource source =
-                new TestRideSource(rideStarted, mark2HoursLater, rideEnded3HoursLater);
-        assertEquals(Collections.singletonList(rideStarted), results(source));
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(new PartitionByRideId(), rideStarted);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(rideStarted.rideId);
     }
 
     @Test
-    public void startIsDelayedMoreThanTwoHours() throws Exception {
-        TaxiRide rideStarted = startRide(1, BEGINNING);
-        TaxiRide rideEndedAfter1Hour = endRide(rideStarted, BEGINNING.plusSeconds(60 * 60));
-        Long mark2HoursAfterEnd = BEGINNING.plusSeconds(180 * 60).toEpochMilli();
+    public void endComesAfter3Hours() throws Exception {
+        TaxiRide startOfLongRide = startRide(1, BEGINNING);
+        TaxiRide longRideEndedAfter3Hours = endRide(startOfLongRide, THREE_HOURS_LATER);
 
-        TestRideSource source =
-                new TestRideSource(rideEndedAfter1Hour, mark2HoursAfterEnd, rideStarted);
-        assert (results(source).isEmpty());
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(
+                        new PartitionByRideId(), startOfLongRide, longRideEndedAfter3Hours);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results()).containsExactly(startOfLongRide.rideId);
+    }
+
+    @Test
+    public void multipleRides() throws Exception {
+        TaxiRide startOfOneRide = startRide(1, BEGINNING);
+        TaxiRide otherRide = startRide(2, ONE_MINUTE_LATER);
+        TaxiRide oneRideEnded = endRide(startOfOneRide, THREE_HOURS_LATER);
+        TaxiRide otherRideEnded = endRide(otherRide, THREE_HOURS_LATER);
+
+        ParallelTestSource<TaxiRide> source =
+                new ParallelTestSource<>(
+                        new PartitionByRideId(),
+                        startOfOneRide,
+                        otherRide,
+                        oneRideEnded,
+                        otherRideEnded);
+        TestSink<Long> sink = new TestSink<Long>();
+
+        longRidesPipeline().execute(source, sink);
+        assertThat(sink.results())
+                .containsExactlyInAnyOrder(startOfOneRide.rideId, otherRide.rideId);
     }
 
-    private TaxiRide testRide(long rideId, Boolean isStart, Instant startTime, Instant endTime) {
+    // Arranges for all events for a given rideId to be generated by the same source subtask.
+    private static class PartitionByRideId implements TestSourcePartitioner<TaxiRide> {
+        @Override
+        public long partition(TaxiRide ride) {
+            return ride.rideId;
+        }
+    }","[{'comment': 'Why is this important? Wouldn\'t it be better that things are arbitrarily distributed between source ""partitions""?', 'commenter': 'NicoK'}]"
36,common/src/main/java/org/apache/flink/training/exercises/common/datatypes/TaxiRide.java,"@@ -139,7 +132,7 @@ public int compareTo(@Nullable TaxiRide other) {
         if (other == null) {
             return 1;
         }
-        int compareTimes = Long.compare(this.getEventTime(), other.getEventTime());
+        int compareTimes = Long.compare(this.getEventTimeMillis(), other.getEventTimeMillis());","[{'comment': 'Why not use `java.time.Instant#compareTo`?\r\n```suggestion\r\n        int compareTimes = this.eventTime.compareTo(other.eventTime);\r\n```', 'commenter': 'NicoK'}]"
36,common/src/main/java/org/apache/flink/training/exercises/common/sources/TaxiRideGenerator.java,"@@ -71,7 +71,7 @@ public void run(SourceContext<TaxiRide> ctx) throws Exception {
             java.util.Collections.shuffle(startEvents, new Random(id));
             startEvents
                     .iterator()
-                    .forEachRemaining(r -> ctx.collectWithTimestamp(r, r.getEventTime()));
+                    .forEachRemaining(r -> ctx.collectWithTimestamp(r, r.getEventTimeMillis()));","[{'comment': ""Not for this PR, but didn't you want to remove `collectWithTimestamp` calls?\r\n\r\nIf I see this correctly, only the LongRides exercises and solutions need timestamps and they have appropriate watermark strategies..."", 'commenter': 'NicoK'}]"
36,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -115,31 +115,31 @@ public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
 
             TaxiRide firstRideEvent = rideState.value();
-
             if (firstRideEvent == null) {
+                // whatever event comes first, remember it
                 rideState.update(ride);
 
                 if (ride.isStart) {
+                    // we will use this timer to check for rides that have gone on too long and may
+                    // not yet have an END event (or the END event could be missing)
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
-                } else {
-                    if (rideTooLong(ride)) {
-                        out.collect(ride.rideId);
-                    }
                 }","[{'comment': ""Can you add a section to the discussion on how to deal with missing START events? We could use event-time timers for this as well, e.g. by firing for the END event's timestamp"", 'commenter': 'NicoK'}, {'comment': ""It's not possible to handle missing START events. Those START events are now the only source of knowledge about when the ride started, so it's not possible to know how long the ride was."", 'commenter': 'alpinegizmo'}, {'comment': ""True, you won't know how long a ride was, but you can identify a late START event at least (and maybe put it on a side output for error handling - a best practice in these cases but not sure you want to add this here"", 'commenter': 'NicoK'}, {'comment': ""There's no notion of lateness here. The current solution will wait indefinitely for the START event. If it ever shows up, the ride will then be reported as having been too long. "", 'commenter': 'alpinegizmo'}, {'comment': ""I guess I see what you meant. We could detect missing START events, and indicate that on a side output. Maybe I'll add something to the DISCUSSION about that."", 'commenter': 'alpinegizmo'}, {'comment': 'Exactly, this is what I meant', 'commenter': 'NicoK'}]"
36,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -115,31 +115,31 @@ public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
 
             TaxiRide firstRideEvent = rideState.value();
-
             if (firstRideEvent == null) {
+                // whatever event comes first, remember it
                 rideState.update(ride);
 
                 if (ride.isStart) {
+                    // we will use this timer to check for rides that have gone on too long and may
+                    // not yet have an END event (or the END event could be missing)
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
-                } else {
-                    if (rideTooLong(ride)) {
-                        out.collect(ride.rideId);
-                    }
                 }
             } else {
                 if (ride.isStart) {
-                    // There's nothing to do but clear the state (which is done below).
+                    if (rideTooLong(ride, firstRideEvent)) {
+                        out.collect(ride.rideId);
+                    }
                 } else {
-                    // There may be a timer that hasn't fired yet.
+                    // there is probably a timer that hasn't fired yet","[{'comment': 'There **is** a timer if `firstRideEvent` was a START event...', 'commenter': 'NicoK'}, {'comment': ""I've reworked the comments"", 'commenter': 'alpinegizmo'}]"
36,long-ride-alerts/src/solution/java/org/apache/flink/training/solutions/longrides/LongRidesSolution.java,"@@ -115,31 +115,31 @@ public void processElement(TaxiRide ride, Context context, Collector<Long> out)
                 throws Exception {
 
             TaxiRide firstRideEvent = rideState.value();
-
             if (firstRideEvent == null) {
+                // whatever event comes first, remember it
                 rideState.update(ride);
 
                 if (ride.isStart) {
+                    // we will use this timer to check for rides that have gone on too long and may
+                    // not yet have an END event (or the END event could be missing)
                     context.timerService().registerEventTimeTimer(getTimerTime(ride));
-                } else {
-                    if (rideTooLong(ride)) {
-                        out.collect(ride.rideId);
-                    }
                 }
             } else {
                 if (ride.isStart) {
-                    // There's nothing to do but clear the state (which is done below).
+                    if (rideTooLong(ride, firstRideEvent)) {
+                        out.collect(ride.rideId);
+                    }
                 } else {
-                    // There may be a timer that hasn't fired yet.
+                    // there is probably a timer that hasn't fired yet
                     context.timerService().deleteEventTimeTimer(getTimerTime(firstRideEvent));
 
-                    // It could be that the ride has gone on too long, but the timer hasn't fired
-                    // yet.
-                    if (rideTooLong(ride)) {
+                    // it could be that the ride has gone on too long (and the timer didn't fire)","[{'comment': 'You keep removing ""yet"" here...isn\'t this making clear that the timer would have fired if we hadn\'t removed it above?\r\n```suggestion\r\n                    // it could be that the ride has gone on too long (and the timer didn\'t fire yet)\r\n```', 'commenter': 'NicoK'}, {'comment': 'reworked, as above', 'commenter': 'alpinegizmo'}]"
36,long-ride-alerts/src/solution/scala/org/apache/flink/training/solutions/longrides/scala/LongRidesSolution.scala,"@@ -91,32 +91,38 @@ object LongRidesSolution {
         new ValueStateDescriptor[TaxiRide](""ride event"", classOf[TaxiRide]))
     }
 
+    @throws[Exception]
     override def processElement(ride: TaxiRide,
                                 context: KeyedProcessFunction[Long, TaxiRide, Long]#Context,
                                 out: Collector[Long]): Unit = {
 
-      val firstRideEvent = rideState.value()
+      val firstRideEvent: TaxiRide = rideState.value
 
       if (firstRideEvent == null) {
+        // whatever event comes first, remember it
         rideState.update(ride)
+
         if (ride.isStart) {
+          // we will use this timer to check for rides that have gone on too long and may
+          // not yet have an END event (or the END event could be missing)
           context.timerService.registerEventTimeTimer(getTimerTime(ride))
-        } else if (rideTooLong(ride)) {
-          out.collect(ride.rideId)
         }
       } else {
         if (ride.isStart) {
-          // There's nothing to do but clear the state (which is done below).
+          if (rideTooLong(ride, firstRideEvent)) {
+            out.collect(ride.rideId)
+          }
         } else {
-          // There may be a timer that hasn't fired yet.
+          // there is probably a timer that hasn't fired yet
           context.timerService.deleteEventTimeTimer(getTimerTime(firstRideEvent))
 
-          // It could be that the ride has gone on too long, but the timer hasn't fired yet.
-          if (rideTooLong(ride)) {
+          // it could be that the ride has gone on too long (and the timer didn't fire)","[{'comment': ""```suggestion\r\n          // it could be that the ride has gone on too long (and the timer didn't fire yet)\r\n```"", 'commenter': 'NicoK'}, {'comment': 'fixed', 'commenter': 'alpinegizmo'}]"
36,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesUnitTest.java,"@@ -104,6 +132,15 @@ public void shouldAlertOnWatermark() throws Exception {
         assertThat(harness.numEventTimeTimers()).isZero();
     }
 
+    private Long resultingRideId() {
+        ConcurrentLinkedQueue<Object> results = harness.getOutput();
+        assertThat(results.size())
+                .isEqualTo(1)
+                .withFailMessage(""Expecting test to have exactly one result"");","[{'comment': 'From the Javadoc:\r\n> You must set it before calling the assertion otherwise it is ignored as the failing assertion breaks the chained call by throwing an AssertionError.\r\n\r\n```suggestion\r\n        assertThat(results.size())\r\n                .withFailMessage(""Expecting test to have exactly one result"")\r\n                .isEqualTo(1);\r\n```', 'commenter': 'NicoK'}]"
36,long-ride-alerts/src/test/java/org/apache/flink/training/exercises/longrides/LongRidesUnitTest.java,"@@ -104,6 +132,15 @@ public void shouldAlertOnWatermark() throws Exception {
         assertThat(harness.numEventTimeTimers()).isZero();
     }
 
+    private Long resultingRideId() {
+        ConcurrentLinkedQueue<Object> results = harness.getOutput();
+        assertThat(results.size())
+                .isEqualTo(1)
+                .withFailMessage(""Expecting test to have exactly one result"");
+        StreamRecord<Long> resultingRecord = (StreamRecord<Long>) results.toArray()[0];","[{'comment': 'Converting to array is unnecessary:\r\n```suggestion\r\n        StreamRecord<Long> resultingRecord = (StreamRecord<Long>) results.element();\r\n```', 'commenter': 'NicoK'}]"
36,long-ride-alerts/DISCUSSION.md,"@@ -21,25 +21,30 @@ under the License.
 
 (Discussion of [Lab: `KeyedProcessFunction` and Timers (Long Ride Alerts)](./))
 
-Flaws in the reference solutions:
+### Flaws in the solutions
 
-* The reference solutions leak state in the case where a START event is missing.
-* In the case where the END event eventually arrives, but after the timer
-has fired and has cleared the matching START event, then a duplicate alert is generated.
+*The reference solutions can leak state when an event is missing.*
 
-A good way to write unit tests for a `KeyedProcessFunction` to check for state retention, etc., is to
-use the test harnesses described in the
-[documentation on testing](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/testing.html#unit-testing-stateful-or-timely-udfs--custom-operators).
-
-These issues could be addressed by keeping some state longer, and then either
+This could be addressed by either
 using [state TTL](https://ci.apache.org/projects/flink/flink-docs-stable/dev/stream/state/state.html#state-time-to-live-ttl),
 or another timer, to eventually clear any lingering state.
 
-But regardless of how long we retain the state, we must eventually clear it, and thereafter we would
+*These solutions also leak state whenever there is a long ride, unless the END event is missing.*","[{'comment': 'That sounds wrong...did you mean this?\r\n```suggestion\r\n*These solutions also leak state whenever there is a long ride and the END event is missing.*\r\n```', 'commenter': 'NicoK'}, {'comment': ""No, that isn't what I meant. I've expanded the DISCUSSION to be clearer."", 'commenter': 'alpinegizmo'}, {'comment': 'The sentence is still misleading as it suggests that you always leak state for every long ride but this is only true if the start event is missing or if the end event is late. Long rides with both events are cleaned up in `processElement`.\r\nThe text should thus go through these (or reflect them somehow):\r\n- start event missing -> end event sits in state (leak!)\r\n- end event missing -> timer fires and clears state (ok)\r\n- end event late -> timer fires, clears state, end event arrives and is stored in state (leak!)', 'commenter': 'NicoK'}]"
40,common/src/main/java/org/apache/flink/training/exercises/common/sources/TaxiFareGenerator.java,"@@ -29,15 +33,25 @@
 public class TaxiFareGenerator implements SourceFunction<TaxiFare> {
 
     private volatile boolean running = true;
+    private Instant limitingTimestamp = Instant.MAX;
+
+    /** Create a bounded TaxiFareGenerator that runs only for the specified duration. */
+    public static TaxiFareGenerator runFor(Duration duration) {
+        TaxiFareGenerator generator = new TaxiFareGenerator();
+        generator.limitingTimestamp = DataGenerator.BEGINNING.plus(duration);
+        return generator;
+    }
 
     @Override
     public void run(SourceContext<TaxiFare> ctx) throws Exception {
 
         long id = 1;
+        Instant latestTimestamp = Instant.MIN;
 
-        while (running) {
+        while (running && (latestTimestamp.compareTo(limitingTimestamp) < 0)) {
             TaxiFare fare = new TaxiFare(id);
             id += 1;
+            latestTimestamp = fare.startTime;
 
             ctx.collect(fare);","[{'comment': 'This will actually put a TaxiFare on the output that has a timestamp later than `limitingTimestamp`. If you want to avoid this (not sure what the guarantees are that you want to provide), you can do something like this instead:\r\n```suggestion\r\n\r\n        while (running) {\r\n            TaxiFare fare = new TaxiFare(id);\r\n            if (fare.startTime.compareTo(limitingTimestamp) >= 0) {\r\n                break;\r\n            }\r\n\r\n            ++id;\r\n            ctx.collect(fare);\r\n```', 'commenter': 'NicoK'}, {'comment': 'Thank you. That is cleaner, and works better in the tests.', 'commenter': 'alpinegizmo'}]"
45,build.gradle,"@@ -87,6 +87,7 @@ subprojects {
         shadow ""org.apache.flink:flink-java:${flinkVersion}""
         shadow ""org.apache.flink:flink-streaming-java_${scalaBinaryVersion}:${flinkVersion}""
         shadow ""org.apache.flink:flink-streaming-scala_${scalaBinaryVersion}:${flinkVersion}""
+        shadow ""org.apache.flink:flink-runtime-web_${scalaBinaryVersion}:${flinkVersion}""","[{'comment': '```suggestion\r\n        \r\n        // allows using Flink\'s web UI when running in the IDE:\r\n        shadow ""org.apache.flink:flink-runtime-web_${scalaBinaryVersion}:${flinkVersion}""\r\n```', 'commenter': 'NicoK'}]"
46,README_zh.md,"@@ -0,0 +1,274 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# Apache Flink 实践练习
+
+与文档中实践练习内容相关的练习。
+
+## 目录
+
+[**设置开发环境**](#set-up-your-development-environment)
+
+1. [软件要求](#software-requirements)
+1. [克隆并构建 flink-training 项目](#clone-and-build-the-flink-training-project)
+1. [将 flink-training 项目导入 IDE](#import-the-flink-training-project-into-your-ide)
+
+[**使用出租车数据流(taxi data stream)**](#using-the-taxi-data-streams)
+
+1. [出租车车程(taxi ride)事件结构](#schema-of-taxi-ride-events)
+1. [出租车费用(taxi fare)事件结构](#schema-of-taxi-fare-events)
+
+[**如何做练习**](#how-to-do-the-lab-exercises)
+
+1. [了解数据](#learn-about-the-data)
+2. [在 IDE 中运行和调试 Flink 程序](#run-and-debug-flink-programs-in-your-ide)
+3. [练习、测试及解决方案](#exercises-tests-and-solutions)
+
+[**练习**](#lab-exercises)
+
+[**提交贡献**](#contributing)
+
+[**许可证**](#license)
+
+<a name=""set-up-your-development-environment""></a>
+
+## 设置开发环境
+
+你需要设置便于进行开发、调试并运行实践练习的示例和解决方案的环境。
+
+<a name=""software-requirements""></a>
+
+### 软件要求
+
+Linux、OS X 和 Windows 均可作为 Flink 程序和本地执行的开发环境。 Flink 开发设置需要以下软件，它们应该安装在系统上：
+
+- Git
+- Java 8 或者 Java 11 版本的 JDK (JRE不满足要求；目前不支持其他版本的Java)
+- 支持 Gradle 的 Java (及/或 Scala) 开发IDE
+    - 推荐使用 [IntelliJ](https://www.jetbrains.com/idea/), 但 [Eclipse](https://www.eclipse.org/downloads/) 或 [Visual Studio Code](https://code.visualstudio.com/) (安装 [Java extension pack](https://code.visualstudio.com/docs/java/java-tutorial) 插件) 也可以用于Java环境
+    - 为了使用 Scala, 需要使用 IntelliJ (及其 [Scala plugin](https://plugins.jetbrains.com/plugin/1347-scala/) 插件)
+
+> **:information_source: Windows 用户须知：** 实践说明中提供的 shell 命令示例适用于 UNIX 环境。
+> 您可能会发现值得在 Windows 环境中设置 cygwin 或 WSL。对于开发 Flink 作业(jobs)，Windows工作的相当好：可以在单机上运行 Flink 集群、提交作业、运行 webUI 并在IDE中执行作业。
+
+<a name=""clone-and-build-the-flink-training-project""></a>
+
+### 克隆并构建 flink-training 项目
+
+`flink-training` 仓库包含编程练习的习题、测试和参考解决方案。
+
+> **:information_source: 仓库格局:** 本仓库有几个分支，分别指向不同的 Apache Flink 版本，类似于 [apache/flink](https://github.com/apache/flink) 仓库：
+> - 每个 Apache Flink 次要版本的发布分支，例如 `release-1.10`，和
+> - 一个指向当前 Flink 版本的 `master` 分支（不是 `flink:master`！）
+>
+> 如果想在当前 Flink 版本以外的版本上工作，请务必签出相应的分支。
+
+从 GitHub 克隆出 `flink-training` 仓库，导航到本地项目仓库并构建它：
+
+```bash
+git clone https://github.com/apache/flink-training.git
+cd flink-training
+./gradlew test shadowJar
+```
+
+如果是第一次构建，将会下载此 Flink 练习项目的所有依赖项。这通常需要几分钟事件，但具体取决于互联网连接速度。","[{'comment': '```suggestion\r\n如果是第一次构建，将会下载此 Flink 练习项目的所有依赖项。这通常需要几分钟时间，但具体取决于互联网连接速度。\r\n```', 'commenter': 'victorunique'}]"
46,README_zh.md,"@@ -0,0 +1,274 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# Apache Flink 实践练习
+
+与文档中实践练习内容相关的练习。
+
+## 目录
+
+[**设置开发环境**](#set-up-your-development-environment)
+
+1. [软件要求](#software-requirements)
+1. [克隆并构建 flink-training 项目](#clone-and-build-the-flink-training-project)
+1. [将 flink-training 项目导入 IDE](#import-the-flink-training-project-into-your-ide)
+
+[**使用出租车数据流(taxi data stream)**](#using-the-taxi-data-streams)
+
+1. [出租车车程(taxi ride)事件结构](#schema-of-taxi-ride-events)
+1. [出租车费用(taxi fare)事件结构](#schema-of-taxi-fare-events)
+
+[**如何做练习**](#how-to-do-the-lab-exercises)
+
+1. [了解数据](#learn-about-the-data)
+2. [在 IDE 中运行和调试 Flink 程序](#run-and-debug-flink-programs-in-your-ide)
+3. [练习、测试及解决方案](#exercises-tests-and-solutions)
+
+[**练习**](#lab-exercises)
+
+[**提交贡献**](#contributing)
+
+[**许可证**](#license)
+
+<a name=""set-up-your-development-environment""></a>
+
+## 设置开发环境
+
+你需要设置便于进行开发、调试并运行实践练习的示例和解决方案的环境。
+
+<a name=""software-requirements""></a>
+
+### 软件要求
+
+Linux、OS X 和 Windows 均可作为 Flink 程序和本地执行的开发环境。 Flink 开发设置需要以下软件，它们应该安装在系统上：
+
+- Git
+- Java 8 或者 Java 11 版本的 JDK (JRE不满足要求；目前不支持其他版本的Java)
+- 支持 Gradle 的 Java (及/或 Scala) 开发IDE
+    - 推荐使用 [IntelliJ](https://www.jetbrains.com/idea/), 但 [Eclipse](https://www.eclipse.org/downloads/) 或 [Visual Studio Code](https://code.visualstudio.com/) (安装 [Java extension pack](https://code.visualstudio.com/docs/java/java-tutorial) 插件) 也可以用于Java环境
+    - 为了使用 Scala, 需要使用 IntelliJ (及其 [Scala plugin](https://plugins.jetbrains.com/plugin/1347-scala/) 插件)
+
+> **:information_source: Windows 用户须知：** 实践说明中提供的 shell 命令示例适用于 UNIX 环境。
+> 您可能会发现值得在 Windows 环境中设置 cygwin 或 WSL。对于开发 Flink 作业(jobs)，Windows工作的相当好：可以在单机上运行 Flink 集群、提交作业、运行 webUI 并在IDE中执行作业。
+
+<a name=""clone-and-build-the-flink-training-project""></a>
+
+### 克隆并构建 flink-training 项目
+
+`flink-training` 仓库包含编程练习的习题、测试和参考解决方案。
+
+> **:information_source: 仓库格局:** 本仓库有几个分支，分别指向不同的 Apache Flink 版本，类似于 [apache/flink](https://github.com/apache/flink) 仓库：
+> - 每个 Apache Flink 次要版本的发布分支，例如 `release-1.10`，和
+> - 一个指向当前 Flink 版本的 `master` 分支（不是 `flink:master`！）
+>
+> 如果想在当前 Flink 版本以外的版本上工作，请务必签出相应的分支。
+
+从 GitHub 克隆出 `flink-training` 仓库，导航到本地项目仓库并构建它：
+
+```bash
+git clone https://github.com/apache/flink-training.git
+cd flink-training
+./gradlew test shadowJar
+```
+
+如果是第一次构建，将会下载此 Flink 练习项目的所有依赖项。这通常需要几分钟事件，但具体取决于互联网连接速度。
+
+如果所有测试都通过并且构建成功，这说明你的实践练习已经开了一个好头。
+
+<details>
+<summary><strong>:cn: 中国用户: 点击这里了解如何使用本地 Maven 镜像。</strong></summary>
+
+如果你在中国，我们建议将 Maven 存储库配置为使用镜像。 可以通过在 [`build.gradle`](build.gradle) 文件中取消注释此部分来做到这一点：
+
+```groovy
+    repositories {
+        // for access from China, you may need to uncomment this line
+        maven { url 'https://maven.aliyun.com/repository/public/' }
+        mavenCentral()
+        maven {
+            url ""https://repository.apache.org/content/repositories/snapshots/""
+            mavenContent {
+                snapshotsOnly()
+            }
+        }
+    }
+```
+</details>
+
+<details>
+<summary><strong>启用 Scala (可选)</strong></summary>
+这个项目中的练习也可以使用 Scala ，但由于非 Scala 用户报告的一些问题，我们决定默认禁用 Scala。
+可以通过以下的方法修改 [`gradle.properties`](gradle.properties) 文件以重新启用所有 Scala 练习和解决方案：","[{'comment': '```suggestion\r\n可以通过以下的方法修改 `gradle.properties` 文件以重新启用所有 Scala 练习和解决方案：\r\n```', 'commenter': 'victorunique'}]"
46,hourly-tips/README_zh.md,"@@ -0,0 +1,82 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# 练习: 窗口分析 (每小时小费)
+
+“每小时小费”练习的任务是确定每小时赚取最多小费的司机。
+最简单的方法是通过两个步骤来解决这个问题：首先使用一个小时长的窗口来计算每个司机在一小时内的总小费，然后从该窗口结果流中找到每小时总小费最多的司机。
+
+请注意，该程序应使用事件时间（event time）。
+
+### 输入数据
+
+本练习的输入数据是由[出租车车费流生成器](../README_zh.md#using-the-taxi-data-streams)生成的 `TaxiFare` 事件流。
+
+`TaxiFareGenerator` 用时间戳和水位线（watermark）注解生成的 `DataStream<TaxiFare>`。
+因此，无需提供自定义的时间戳和水印分配器即可正确使用事件时间。
+
+### 期望输出
+
+所希望的结果是每小时产生一个 `Tuple3<Long, Long, Float>` 记录的数据流。
+这个记录（`Tuple3<Long, Long, Float>`）应包含该小时结束时的时间戳（对应三元组的第一个元素）、
+该小时内获得小费最多的司机的 driverId（对应三元组的第二个元素）以及他的实际小费总数（对应三元组的第三个元素））。
+
+结果流应打印到标准输出。
+
+## 入门指南
+
+> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是实用本节中源文件的链接。","[{'comment': '```suggestion\r\n> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是使用本节中源文件的链接。\r\n```', 'commenter': 'victorunique'}]"
46,long-ride-alerts/README_zh.md,"@@ -0,0 +1,93 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# 练习: `ProcessFunction` 及定时器（长车程警报）
+
+“长车程警报”练习的目标是对于持续超过两个小时的出租车车程发出警报。
+
+这应该使用数据流中提供的事件时间时间戳和水位线来完成。
+
+流是无序的，并且可能会在其 START 事件之前处理车程的 END 事件。
+
+END 事件可能会丢失，但你可以假设没有重复的事件，也没有丢失的 START 事件。
+
+仅仅等待 END 事件并计算持续时间是不够的，因为我们希望尽快收到关于长车程的警报。
+
+最终应该清除创建的任何状态。
+
+### 输入数据
+
+输入数据是出租车乘车事件的 `DataStream`。
+
+### 期望输出
+
+所希望的结果应该是一个 `DataStream<LONG>`，其中包含持续时间超过两小时的车程的 `rideId`。
+
+结果流应打印到标准输出。
+
+## 入门指南
+
+> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是实用本节中源文件的链接。","[{'comment': '```suggestion\r\n> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是使用本节中源文件的链接。\r\n```', 'commenter': 'victorunique'}]"
46,ride-cleansing/README_zh.md,"@@ -0,0 +1,98 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# 练习: 过滤流(车程清理)
+
+如果尚未设置 Flink 开发环境，请参阅[指南](../README_zh.md)。
+有关练习的总体介绍，请参阅[如何做练习](../README_zh.md#how-to-do-the-labs)。
+
+""出租车车程清理""练习的任务是通过删除在纽约市以外开始或结束的车程来清理一系列的 `TaxiRide` 事件。
+
+`GeoUtils` 实用程序类提供了一个静态方法 `isInNYC(float lon, float lat)` 来检查某个位置是否在纽约市区域内。
+
+### 输入数据
+
+此练习基于 `TaxiRide` 事件流，如[使用出租车数据流](../README.md#using-the-taxi-data-streams)中所述。
+
+### 期望输出
+
+练习的结果应该是一个 `DataStream<TaxiRide>`，它只包含在 `GeoUtils.isInNYC()` 定义的纽约市地区开始和结束的出租车车程事件。
+
+结果流应打印到标准输出。
+
+## 入门指南
+
+> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是实用本节中源文件的链接。","[{'comment': '```suggestion\r\n> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是使用本节中源文件的链接。\r\n```', 'commenter': 'victorunique'}]"
46,rides-and-fares/README_zh.md,"@@ -0,0 +1,95 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# 练习: 有状态的增强(车程及车费)
+
+本练习的目标是将每次车程的 `TaxiRide` 和 `TaxiFare` 记录连接在一起。
+
+对于每个不同的 `rideId`，恰好有三个事件：
+
+1. `TaxiRide` START 事件
+1. `TaxiRide` END 事件
+1. 一个 `TaxiFare` 事件（其时间戳恰好与开始时间匹配）
+
+最终的结果应该是 `DataStream<RideAndFare>`，每个不同的 `rideId` 都产生一个 `RideAndFare` 记录。 
+每个 `RideAndFare` 都应该将某个 `rideId` 的 `TaxiRide` START 事件与其匹配的 `TaxiFare` 配对。
+
+### 输入数据
+
+在练习中，你将使用两个数据流，一个使用由 `TaxiRideSource` 生成的 `TaxiRide` 事件，另一个使用由 `TaxiFareSource` 生成的 `TaxiFare` 事件。
+有关如何使用这些流生成器的信息，请参阅 [使用出租车数据流](../README_zh.md#using-the-taxi-data-streams)。
+
+### 期望输出
+
+所希望的结果是一个 `RideAndFare` 记录的数据流，每个不同的 `rideId` 都有一条这样的记录。 
+本练习设置为忽略 END 事件，你应该连接每次乘车的 START 事件及其相应的车费事件。
+
+一旦具有了相互关联的车程和车费事件，你可以使用 `new RideAndFare(ride, fare)` 方法为输出流创建所需的对象。
+
+流将会被打印到标准输出。
+
+## 入门指南
+
+> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是实用本节中源文件的链接。","[{'comment': '```suggestion\r\n> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是使用本节中源文件的链接。\r\n```', 'commenter': 'victorunique'}]"
46,rides-and-fares/README_zh.md,"@@ -0,0 +1,95 @@
+<!--
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+  http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing,
+software distributed under the License is distributed on an
+""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+KIND, either express or implied.  See the License for the
+specific language governing permissions and limitations
+under the License.
+-->
+
+# 练习: 有状态的增强(车程及车费)
+
+本练习的目标是将每次车程的 `TaxiRide` 和 `TaxiFare` 记录连接在一起。
+
+对于每个不同的 `rideId`，恰好有三个事件：
+
+1. `TaxiRide` START 事件
+1. `TaxiRide` END 事件
+1. 一个 `TaxiFare` 事件（其时间戳恰好与开始时间匹配）
+
+最终的结果应该是 `DataStream<RideAndFare>`，每个不同的 `rideId` 都产生一个 `RideAndFare` 记录。 
+每个 `RideAndFare` 都应该将某个 `rideId` 的 `TaxiRide` START 事件与其匹配的 `TaxiFare` 配对。
+
+### 输入数据
+
+在练习中，你将使用两个数据流，一个使用由 `TaxiRideSource` 生成的 `TaxiRide` 事件，另一个使用由 `TaxiFareSource` 生成的 `TaxiFare` 事件。
+有关如何使用这些流生成器的信息，请参阅 [使用出租车数据流](../README_zh.md#using-the-taxi-data-streams)。
+
+### 期望输出
+
+所希望的结果是一个 `RideAndFare` 记录的数据流，每个不同的 `rideId` 都有一条这样的记录。 
+本练习设置为忽略 END 事件，你应该连接每次乘车的 START 事件及其相应的车费事件。
+
+一旦具有了相互关联的车程和车费事件，你可以使用 `new RideAndFare(ride, fare)` 方法为输出流创建所需的对象。
+
+流将会被打印到标准输出。
+
+## 入门指南
+
+> :information_source: 最好在 IDE 的 flink-training 项目中找到这些类，而不是实用本节中源文件的链接。
+
+### 练习相关类
+
+- Java:  [`org.apache.flink.training.exercises.ridesandfares.RidesAndFaresExercise`](src/main/java/org/apache/flink/training/exercises/ridesandfares/RidesAndFaresExercise.java)
+- Scala: [`org.apache.flink.training.exercises.ridesandfares.scala.RidesAndFaresExercise`](src/main/scala/org/apache/flink/training/exercises/ridesandfares/scala/RidesAndFaresExercise.scala)
+
+### 集成测试
+
+- Java:  [`org.apache.flink.training.exercises.ridesandfares.RidesAndFaresIntegrationTest`](src/test/java/org/apache/flink/training/exercises/ridesandfares/RidesAndFaresIntegrationTest.java)
+- Scala: [`org.apache.flink.training.exercises.ridesandfares.scala.RidesAndFaresIntegrationTest`](src/test/scala/org/apache/flink/training/exercises/ridesandfares/scala/RidesAndFaresIntegrationTest.scala)
+
+## 实现提示
+
+<details>
+<summary><strong>程序结构</strong></summary>
+
+可以使用 `RichCoFlatMap` 来实现连接操作。请注意，你无法控制每个 rideId 的车程和车费记录的到达顺序，因此需要存储一个事件，直到与其匹配事件到达。","[{'comment': '```suggestion\r\n可以使用 `RichCoFlatMap` 来实现连接操作。请注意，你无法控制每个 rideId 的车程和车费记录的到达顺序，因此需要存储其中一个事件，直到与其匹配的另一事件到达。\r\n```', 'commenter': 'victorunique'}]"
52,long-ride-alerts/src/main/java/org/apache/flink/training/exercises/longrides/LongRidesExercise.java,"@@ -97,18 +99,61 @@ public static void main(String[] args) throws Exception {
 
     @VisibleForTesting
     public static class AlertFunction extends KeyedProcessFunction<Long, TaxiRide, Long> {
-
+        private ValueState<TaxiRide> rideState;","[{'comment': 'Since this class implement `Serializable` interface\r\nIt has to be `transient`\r\n` private transient ValueState<TaxiRide> rideState;`\r\nAlso I recommend to specify\r\n`serialVersionUID`\r\nprivate static final long serialVersionUID = 1L;\r\n\r\n', 'commenter': 'pavel-hp'}]"
52,rides-and-fares/src/main/java/org/apache/flink/training/exercises/ridesandfares/RidesAndFaresExercise.java,"@@ -98,20 +100,39 @@ public static void main(String[] args) throws Exception {
 
     public static class EnrichmentFunction
             extends RichCoFlatMapFunction<TaxiRide, TaxiFare, RideAndFare> {
+        private ValueState<TaxiRide> rideState;","[{'comment': 'Since this class implement Serializable interface\r\nIt has to be transient \r\nAlso I recommend to specify\r\nserialVersionUID', 'commenter': 'pavel-hp'}]"
