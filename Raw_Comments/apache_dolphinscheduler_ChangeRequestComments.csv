Pull,Path,Diff_hunk,Comment
1018,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -817,7 +817,7 @@ public void exportProcessDefinitionById(User loginUser, String projectName, Inte
         ProcessDefinition processDefinition = processDefineMapper.selectById(defineId);
         if (processDefinition == null) {
             logger.info(""process define not exists"");
-            putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processDefinition.getId());
+            putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST);","[{'comment': 'Here, you can not omit the third parameter for putMsg (since the PROCESS_DEFINE_NOT_EXIST need an additional parameter to replace {0}\r\n\r\nHere you need to change to\r\n\r\nputMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, defineId);', 'commenter': 'Baoqi'}, {'comment': 'done', 'commenter': 'khadgarmage'}]"
1021,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/zk/AbstractZKClient.java,"@@ -1,4 +1,4 @@
-/*
+	/*","[{'comment': ""Here don't need extra spaces (要不这个还是去掉吧, 要不以后代码显得不专业)"", 'commenter': 'Baoqi'}, {'comment': '额，我再check下，我明明是删了~~', 'commenter': 'khadgarmage'}]"
1021,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/sql/SqlTask.java,"@@ -355,9 +355,8 @@ private PreparedStatement prepareStatementAndBind(Connection connection, SqlBind
         }
         Map<Integer, Property> params = sqlBinds.getParamsMap();
         if(params != null){
-            for(Integer key : params.keySet()){
-                Property prop = params.get(key);
-                ParameterUtils.setInParameter(key,stmt,prop.getType(),prop.getValue());
+            for(Map.Entry<Integer, Property> entry: sqlBinds.getParamsMap().entrySet()) {","[{'comment': '""sqlBinds.getParamsMap()"" can be replaced with  ""params.entrySet()"" \r\n\r\nsince there is alreay a  params.\r\n', 'commenter': 'Baoqi'}, {'comment': 'ok', 'commenter': 'khadgarmage'}]"
1021,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/sql/SqlTask.java,"@@ -355,9 +355,8 @@ private PreparedStatement prepareStatementAndBind(Connection connection, SqlBind
         }
         Map<Integer, Property> params = sqlBinds.getParamsMap();
         if(params != null){
-            for(Integer key : params.keySet()){
-                Property prop = params.get(key);
-                ParameterUtils.setInParameter(key,stmt,prop.getType(),prop.getValue());
+            for(Map.Entry<Integer, Property> entry: sqlBinds.getParamsMap().entrySet()) {
+                ParameterUtils.setInParameter(entry.getKey(),stmt,entry.getValue().getType(),entry.getValue().getValue());","[{'comment': 'To make it easier to read, Here, I would sugguest to change to:\r\n\r\nProperty prop = entry.getValue();\r\nParameterUtils.setInParameter(entry.getKey(), stmt, prop.getType(), prop.getValue());\r\n\r\n', 'commenter': 'Baoqi'}, {'comment': 'ok, i will modify it, thanks.', 'commenter': 'khadgarmage'}]"
1035,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/sql/SqlTask.java,"@@ -355,10 +355,9 @@ private PreparedStatement prepareStatementAndBind(Connection connection, SqlBind
         }
         Map<Integer, Property> params = sqlBinds.getParamsMap();
         if(params != null){
-            for(Integer key : params.keySet()){
-                Property prop = params.get(key);
-                ParameterUtils.setInParameter(key,stmt,prop.getType(),prop.getValue());
-            }
+            for(Map.Entry<Integer, Property> entry: params.entrySet()) {
+                Property prop = entry.getValue();
+                ParameterUtils.setInParameter(entry.getKey(),stmt,prop.getType(),prop.getValue());","[{'comment': 'Here,  you delete an extra  }    So, it can not compile\r\n\r\n(你是不是多删除了一个 }   这样会编译不过, 最好先编译一下再提交)', 'commenter': 'Baoqi'}, {'comment': '这个我编译了，可能后来我又手工删了，没编译，sorry', 'commenter': 'khadgarmage'}]"
1494,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/worker/task/spark/SparkTaskTest.java,"@@ -0,0 +1,138 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.server.worker.task.spark;
+
+import org.apache.commons.lang3.StringUtils;
+import org.apache.dolphinscheduler.common.enums.SparkVersion;
+import org.apache.dolphinscheduler.common.process.Property;
+import org.apache.dolphinscheduler.common.task.spark.SparkParameters;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.server.utils.ParamUtils;
+import org.apache.dolphinscheduler.server.utils.SparkArgsUtils;
+import org.apache.dolphinscheduler.server.worker.task.TaskProps;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+
+public class SparkTaskTest {
+
+    private static final Logger logger = LoggerFactory.getLogger(SparkTaskTest.class);
+
+    /**
+     * spark1 command
+     */
+    private static final String SPARK1_COMMAND = ""${SPARK_HOME1}/bin/spark-submit"";
+
+    /**
+     * spark2 command
+     */
+    private static final String SPARK2_COMMAND = ""${SPARK_HOME2}/bin/spark-submit"";
+
+    @Test
+    public void testSparkTaskInit() {
+
+        TaskProps taskProps = new TaskProps();","[{'comment': 'ut has no assert check?', 'commenter': 'khadgarmage'}, {'comment': 'i will add assert check for this', 'commenter': 'Eights-Li'}]"
1517,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/QueueService.java,"@@ -240,21 +252,35 @@ public Result verifyQueue(String queue, String queueName) {
      * check queue exist
      * if exists return true，not exists return false
      * check queue exist
+     *
      * @param queue queue
      * @return true if the queue not exists, otherwise return false
      */
     private boolean checkQueueExist(String queue) {
-        return queueMapper.queryAllQueueList(queue, null).size()>0 ? true : false;
+        return queueMapper.queryAllQueueList(queue, null).size() > 0;
     }
 
     /**
      * check queue name exist
      * if exists return true，not exists return false
+     *
      * @param queueName queue name
      * @return true if the queue name not exists, otherwise return false
      */
     private boolean checkQueueNameExist(String queueName) {
-        return queueMapper.queryAllQueueList(null ,queueName).size() > 0 ? true : false;
+        return queueMapper.queryAllQueueList(null, queueName).size() > 0;
+    }
+
+    /**
+     * check old queue name using by any user
+     * if need to update user
+     *
+     * @param queueOld old queue name
+     * @param queueNew new queue name
+     * @return true if need to update user
+     */
+    private boolean checkUserRelatedQueue(String queueOld, String queueNew) {","[{'comment': 'oldQueue， newQueue', 'commenter': 'Technoboy-'}, {'comment': 'method name is not readable.     checkIfQueueIsInUsing is prefered ', 'commenter': 'Technoboy-'}]"
1517,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/mapper/UserMapper.java,"@@ -95,4 +95,18 @@
      */
     User queryUserByToken(@Param(""token"") String token);
 
+    /**
+     * query user by queue name
+     * @param queueName queue name
+     * @return user list
+     */
+    List<User> queryUserListByQueue(@Param(""queueName"") String queueName);
+
+    /**
+     * update user with old queue
+     * @param queueOld old queue name
+     * @param queueNew new queue name
+     * @return update rows
+     */
+    Integer updateUserQueue(@Param(""queueOld"") String queueOld, @Param(""queueNew"") String queueNew);","[{'comment': 'oldQueue, newQueue', 'commenter': 'Technoboy-'}, {'comment': 'Method and param name have been modified, please review. thanks~ ', 'commenter': 'Eights-Li'}]"
1568,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/log/SensitiveDataConverter.java,"@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.server.worker.log;
+
+
+import ch.qos.logback.classic.pattern.MessageConverter;
+import ch.qos.logback.classic.spi.ILoggingEvent;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.lang3.StringUtils;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.server.utils.SensitiveLogUtil;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * sensitive data log converter
+ */
+@Slf4j
+public class SensitiveDataConverter extends MessageConverter {
+
+
+    @Override
+    public String convert(ILoggingEvent event) {
+
+        // get original log
+        String requestLogMsg = event.getFormattedMessage();
+
+        // desensitization log
+        return convertMsg(requestLogMsg);
+    }
+
+    /**
+     * deal with sensitive log
+     *
+     * @param oriLogMsg original log
+     */
+    private String convertMsg(final String oriLogMsg) {
+
+        String tempLogMsg = oriLogMsg;
+
+        if (StringUtils.isNotEmpty(tempLogMsg)) {
+            tempLogMsg = passwordHandler(tempLogMsg);
+        }
+        return tempLogMsg;
+    }
+
+    /**
+     * password regex
+     *
+     * @param logMsg original log
+     */
+    private String passwordHandler(String logMsg) {
+
+        Pattern pattern = Pattern.compile(Constants.DATASOURCE_PASSWORD_REGEX);","[{'comment': 'put this line as private object', 'commenter': 'Technoboy-'}, {'comment': 'thx, i will fix it.', 'commenter': 'Eights-Li'}]"
1568,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/log/SensitiveDataConverter.java,"@@ -0,0 +1,89 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.server.worker.log;
+
+
+import ch.qos.logback.classic.pattern.MessageConverter;
+import ch.qos.logback.classic.spi.ILoggingEvent;
+import lombok.extern.slf4j.Slf4j;
+import org.apache.commons.lang3.StringUtils;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.server.utils.SensitiveLogUtil;
+
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * sensitive data log converter
+ */
+@Slf4j
+public class SensitiveDataConverter extends MessageConverter {
+
+
+    @Override
+    public String convert(ILoggingEvent event) {
+
+        // get original log
+        String requestLogMsg = event.getFormattedMessage();
+
+        // desensitization log
+        return convertMsg(requestLogMsg);
+    }
+
+    /**
+     * deal with sensitive log
+     *
+     * @param oriLogMsg original log
+     */
+    private String convertMsg(final String oriLogMsg) {
+
+        String tempLogMsg = oriLogMsg;
+
+        if (StringUtils.isNotEmpty(tempLogMsg)) {
+            tempLogMsg = passwordHandler(tempLogMsg);
+        }
+        return tempLogMsg;
+    }
+
+    /**
+     * password regex
+     *
+     * @param logMsg original log
+     */
+    private String passwordHandler(String logMsg) {
+
+        Pattern pattern = Pattern.compile(Constants.DATASOURCE_PASSWORD_REGEX);
+
+        Matcher matcher = pattern.matcher(logMsg);
+
+        StringBuffer sb = new StringBuffer();","[{'comment': 'StringBuffer sb = new StringBuffer(logMsg.length);', 'commenter': 'Technoboy-'}]"
1684,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ResourcesService.java,"@@ -234,6 +234,12 @@ public Result updateResource(User loginUser,
             }
         }
 
+        // query tenant by user id
+        String tenantCode = getTenantCode(resource.getUserId(),result);
+        if (StringUtils.isEmpty(tenantCode)){","[{'comment': 'Is necessary to putMsg and log error?', 'commenter': 'khadgarmage'}, {'comment': 'add error log in getTenantCode method\r\n', 'commenter': 'samz406'}]"
1684,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ResourcesService.java,"@@ -522,8 +529,11 @@ public Result readResource(int resourceId, int skipLineNum, int limit) {
             }
         }
 
-        User user = userMapper.queryDetailsById(resource.getUserId());
-        String tenantCode = tenantMapper.queryById(user.getTenantId()).getTenantCode();
+        String tenantCode = getTenantCode(resource.getUserId(),result);
+        if (StringUtils.isEmpty(tenantCode)){
+            return  result;","[{'comment': 'Is necessary to putMsg and log error?', 'commenter': 'khadgarmage'}, {'comment': 'add error log in getTenantCode method\r\n\r\n', 'commenter': 'samz406'}]"
1684,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ResourcesService.java,"@@ -644,18 +654,20 @@ public Result updateResourceContent(int resourceId, String content) {
         if (StringUtils.isNotEmpty(resourceViewSuffixs)) {
             List<String> strList = Arrays.asList(resourceViewSuffixs.split("",""));
             if (!strList.contains(nameSuffix)) {
-                logger.error(""resouce suffix {} not support updateProcessInstance,  resource id {}"", nameSuffix, resourceId);
+                logger.error(""resource suffix {} not support updateProcessInstance,  resource id {}"", nameSuffix, resourceId);
                 putMsg(result, Status.RESOURCE_SUFFIX_NOT_SUPPORT_VIEW);
                 return result;
             }
         }
 
+        String tenantCode = getTenantCode(resource.getUserId(),result);
+        if (StringUtils.isEmpty(tenantCode)){","[{'comment': 'Is necessary to putMsg and log error?', 'commenter': 'khadgarmage'}, {'comment': 'Since a tenant is required to upload a resource, the resource and tenant are associated through the user. If the user on resouce is illegal. Then the tenant cannot be obtained, and the null pointer exception will be thrown when the tenantCode is obtained.\r\n\r\n由于上传resource需要tenant，resource和tenant是通过用户关联，如果resource上的用户是非法的。那么就获取不到tenant了， 获取tenantCode也就会抛空指针异常', 'commenter': 'samz406'}, {'comment': 'add error log  in getTenantCode method', 'commenter': 'samz406'}]"
1910,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/shell/AbstractShell.java,"@@ -281,7 +283,7 @@ public void run() {
         //Process has not terminated.
         //So check if it has completed 
         //if not just destroy it.
-        if (p != null && !shell.completed.get()) {
+        if (!shell.completed.get()) {
           shell.setTimedOut();","[{'comment': 'If  runCommand is not called, process may  be null , use ` !(p  instanceof Process) ` to check it.', 'commenter': 'Jave-Chen'}, {'comment': 'process vaiable will be assigned before ShellTimeoutTimerTask, so no need to check', 'commenter': 'gabrywu'}]"
1963,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -922,7 +922,11 @@ public void importSubProcess(User loginUser, Project targetProject, JSONArray js
                 }
 
                 // check extra params
-                CheckUtils.checkOtherParams(taskNode.getExtras());
+                if(taskNode.getExtras() !=null && !CheckUtils.checkOtherParams(taskNode.getExtras())){","[{'comment': 'checkOtherParams has checked null', 'commenter': 'Technoboy-'}, {'comment': 'I think null is valid params', 'commenter': 'gabrywu'}, {'comment': 'CheckUtils.checkOtherParams optimized, review please', 'commenter': 'gabrywu'}]"
1970,ambari_plugin/common-services/DOLPHIN/1.2.1/package/scripts/status_params.py,"@@ -0,0 +1,13 @@
+#!/usr/bin/env python
+# -*- coding: utf-8 -*-
+
+""""""
+Redis service params
+","[{'comment': 'license description needed', 'commenter': 'Jave-Chen'}]"
1970,ambari_plugin/common-services/DOLPHIN/1.2.1/configuration/dolphin-env.xml,"@@ -0,0 +1,114 @@
+<configuration>
+	<property>
+		<name>dolphin.database.type</name>
+		<value>mysql</value>
+		<description>Dolphin Scheduler DataBase Type Which Is Select</description>
+		<display-name>Dolphin Database Type</display-name>
+		<value-attributes>
+			<type>value-list</type>
+			<entries>
+				<entry>
+					<value>mysql</value>
+					<label>Mysql</label>
+				</entry>
+				<entry>
+					<value>postgresql</value>
+					<label>Postgresql</label>
+				</entry>
+			</entries>
+			<selection-cardinality>1</selection-cardinality>
+		</value-attributes>
+		<on-ambari-upgrade add=""true""/>
+	</property>
+
+	<property>
+		<name>dolphin.database.host</name>
+		<value>ark1</value>","[{'comment': 'if dolphin.database.host is must be config , it is recommended to set this parameter as required instead of giving an unavailable default value.The same goes for other parameters.', 'commenter': 'EricJoy2048'}]"
1970,ambari_plugin/common-services/DOLPHIN/1.2.1/metainfo.xml,"@@ -0,0 +1,121 @@
+<?xml version=""1.0""?>
+<metainfo>
+    <schemaVersion>2.0</schemaVersion>
+    <services>
+        <service>
+            <name>DOLPHIN</name>
+            <displayName>Dolphin Scheduler</displayName>
+            <comment>分布式易扩展的可视化DAG工作流任务调度系统</comment>
+            <version>1.2.1</version>
+            <components>
+                <component>
+                    <name>DOLPHIN_MASTER</name>
+                    <displayName>DS Master</displayName>
+                    <category>MASTER</category>
+                    <cardinality>1-2</cardinality>","[{'comment': 'DOLPHIN_MASTER`s cardinality is 1-2 ?', 'commenter': 'EricJoy2048'}, {'comment': 'yeah!  The master component supports multiple installations', 'commenter': 'zhangchunyang1024'}]"
1970,ambari_plugin/common-services/DOLPHIN/1.2.1/package/alerts/alert_dolphin_scheduler_status.py,"@@ -0,0 +1,138 @@
+# coding=utf8
+#!/usr/bin/env python
+
+""""""
+Licensed to the Apache Software Foundation (ASF) under one
+or more contributor license agreements.  See the NOTICE file
+distributed with this work for additional information
+regarding copyright ownership.  The ASF licenses this file
+to you under the Apache License, Version 2.0 (the
+""License""); you may not use this file except in compliance
+with the License.  You may obtain a copy of the License at
+
+    http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+distributed under the License is distributed on an ""AS IS"" BASIS,
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+See the License for the specific language governing permissions and
+limitations under the License.
+""""""
+import urllib2
+import urllib
+import os
+import logging
+import ambari_simplejson as json
+import time
+from resource_management.libraries.script.script import Script
+import telnetlib 
+import sys
+reload(sys)
+sys.setdefaultencoding('utf-8')
+
+logger = logging.getLogger('ambari_alerts')
+
+config = Script.get_config()
+
+
+def get_tokens():
+    """"""
+    Returns a tuple of tokens in the format {{site/property}} that will be used
+    to build the dictionary passed into execute
+    
+    :rtype tuple
+    """"""
+
+def get_info(url, connection_timeout):
+    response = None
+    
+    try:
+        response = urllib2.urlopen(url, timeout=connection_timeout)
+        json_data = response.read()
+        return json_data
+    finally:
+        if response is not None:
+            try:
+                response.close()
+            except:
+                pass
+
+
+def execute(configurations={}, parameters={}, host_name=None):
+    """"""
+    Returns a tuple containing the result code and a pre-formatted result label
+    
+    Keyword arguments:
+    configurations : a mapping of configuration key to value
+    parameters : a mapping of script parameter key to value
+    host_name : the name of this host where the alert is running
+    
+    :type configurations dict
+    :type parameters dict
+    :type host_name str
+    """"""
+    
+    alert_name = parameters['alertName']
+
+    dolphin_pidfile_dir = ""/opt/soft/run/dolphinscheduler""
+
+    pid = ""0""
+    
+    
+    from resource_management.core import sudo
+
+    is_running = True
+    pid_file_path = """"
+    if alert_name == 'DOLPHIN_MASTER':
+        pid_file_path = dolphin_pidfile_dir + ""/master-server.pid""
+    elif alert_name == 'DOLPHIN_WORKER':
+        pid_file_path = dolphin_pidfile_dir + ""/worker-server.pid""
+    elif alert_name == 'DOLPHIN_ALERT':
+        pid_file_path = dolphin_pidfile_dir + ""/alert-server.pid""
+        
+    if not pid_file_path or not os.path.isfile(pid_file_path):
+        is_running = False
+        
+    try:
+        pid = int(sudo.read_file(pid_file_path))
+    except:
+        is_running = False
+
+    try:
+        # Kill will not actually kill the process
+        # From the doc:
+        # If sig is 0, then no signal is sent, but error checking is still
+        # performed; this can be used to check for the existence of a
+        # process ID or process group ID.
+        sudo.kill(pid, 0)
+    except OSError:
+        is_running = False
+    
+    if not is_running:
+        result_code = ""CRITICAL""
+        label_content = {
+            ""serviceName"": ""DOLPHIN_SCHEDULER"",
+            ""show_type"": ""text"",
+            ""alert_message"": [","[{'comment': ""Native ambari can't recognize such alarm json, so you need to modify the alarm information a bit easier"", 'commenter': 'EricJoy2048'}]"
1970,ambari_plugin/common-services/DOLPHIN/1.2.1/package/scripts/dolphin_alert_service.py,"@@ -0,0 +1,44 @@
+# -*- coding: utf-8 -*-
+
+import time
+from resource_management import *
+
+from dolphin_env import dolphin_env
+
+
+class DolphinAlertService(Script):
+    def install(self, env):
+        import params
+        env.set_params(params)
+        self.install_packages(env)
+        Execute(('chmod', '-R', '777', params.dolphin_home), user=params.dolphin_user, sudo=True)
+
+    def configure(self, env):
+        import params
+        params.pika_slave = True
+        env.set_params(params)
+
+        dolphin_env()
+
+    def start(self, env):
+        import params
+        env.set_params(params)
+        self.configure(env)
+        start_cmd = format(""sh "" + params.dolphin_bin_dir + ""/dolphinscheduler-daemon.sh start alert-server"")
+        Execute(start_cmd, user=params.dolphin_user)","[{'comment': 'Have you tested what happens if the service is already started at this time and then click Start? Do you need to add the not_if parameter.', 'commenter': 'EricJoy2048'}]"
1970,ambari_plugin/common-services/DOLPHIN/1.2.1/package/scripts/dolphin_worker_service.py,"@@ -0,0 +1,44 @@
+# -*- coding: utf-8 -*-
+","[{'comment': 'License is need', 'commenter': 'EricJoy2048'}]"
1978,dockerfile/Dockerfile,"@@ -1,136 +1,74 @@
-#","[{'comment': 'Why delete license announcement?', 'commenter': 'khadgarmage'}, {'comment': 'I have forgot it, because this dockerfile is new.', 'commenter': 'liwenhe1993'}]"
1978,dockerfile/Dockerfile,"@@ -1,136 +1,74 @@
-#
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the ""License""); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
+FROM nginx:alpine
 
-FROM ubuntu:18.04
+ARG VERSION
 
-ENV LANG=C.UTF-8
-ENV DEBIAN_FRONTEND=noninteractive
+ENV TZ Asia/Shanghai
+ENV LANG C.UTF-8
+ENV DEBIAN_FRONTEND noninteractive
 
-ARG version
-ARG tar_version
+#1. using aliyun mirror, and install dos2unix shadow bash openrc python sudo vim wget iputils net-tools ssh pip kazoo
+RUN sed -i ""s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g"" /etc/apk/repositories && \","[{'comment': 'Can Alibaba Cloud Mirror make download quickly abroad?', 'commenter': 'khadgarmage'}, {'comment': 'I will remove it ', 'commenter': 'liwenhe1993'}]"
1978,dockerfile/Dockerfile,"@@ -1,136 +1,74 @@
-#
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the ""License""); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
-#
-#     http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
-#
+FROM nginx:alpine
 
-FROM ubuntu:18.04
+ARG VERSION
 
-ENV LANG=C.UTF-8
-ENV DEBIAN_FRONTEND=noninteractive
+ENV TZ Asia/Shanghai
+ENV LANG C.UTF-8
+ENV DEBIAN_FRONTEND noninteractive
 
-ARG version
-ARG tar_version
+#1. using aliyun mirror, and install dos2unix shadow bash openrc python sudo vim wget iputils net-tools ssh pip kazoo
+RUN sed -i ""s/dl-cdn.alpinelinux.org/mirrors.aliyun.com/g"" /etc/apk/repositories && \
+    apk update && \
+    apk add dos2unix shadow bash openrc python sudo vim wget iputils net-tools openssh-server py2-pip && \
+    apk add --update procps && \
+    openrc boot && \
+    pip install kazoo
 
-#1,install jdk
-
-RUN apt-get update \
-    && apt-get -y install openjdk-8-jdk \
-    && rm -rf /var/lib/apt/lists/*
-
-ENV JAVA_HOME /usr/lib/jvm/java-8-openjdk-amd64
+#2. install jdk
+RUN apk add openjdk8
+ENV JAVA_HOME /usr/lib/jvm/java-1.8-openjdk
 ENV PATH $JAVA_HOME/bin:$PATH
 
-
-#install wget
-RUN apt-get update && \
-        apt-get -y install wget
-#2,install ZK
-
+#3. install zk
 RUN cd /opt && \
-    wget https://www-us.apache.org/dist/zookeeper/zookeeper-3.4.14/zookeeper-3.4.14.tar.gz  && \
-    tar -zxvf zookeeper-3.4.14.tar.gz  && \
-    mv zookeeper-3.4.14 zookeeper && \
-    rm -rf ./zookeeper-*tar.gz && \
+    wget https://downloads.apache.org/zookeeper/zookeeper-3.5.7/apache-zookeeper-3.5.7-bin.tar.gz && \
+    tar -zxvf apache-zookeeper-3.5.7-bin.tar.gz && \
+    mv apache-zookeeper-3.5.7-bin zookeeper && \
     mkdir -p /tmp/zookeeper && \
+    rm -rf ./zookeeper-*tar.gz && \
     rm -rf /opt/zookeeper/conf/zoo_sample.cfg
-
-ADD ./dockerfile/conf/zookeeper/zoo.cfg /opt/zookeeper/conf
-ENV ZK_HOME=/opt/zookeeper
-ENV PATH $PATH:$ZK_HOME/bin
-
-#3,install maven
-RUN cd /opt && \
-    wget http://apache-mirror.rbc.ru/pub/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz && \
-    tar -zxvf apache-maven-3.3.9-bin.tar.gz && \
-    mv apache-maven-3.3.9 maven && \
-    rm -rf ./apache-maven-*tar.gz && \
-    rm -rf /opt/maven/conf/settings.xml
-ADD ./dockerfile/conf/maven/settings.xml /opt/maven/conf
-ENV MAVEN_HOME=/opt/maven
-ENV PATH $PATH:$MAVEN_HOME/bin
-
-#4,install node
-RUN cd /opt && \
-    wget https://nodejs.org/download/release/v8.9.4/node-v8.9.4-linux-x64.tar.gz && \
-    tar -zxvf node-v8.9.4-linux-x64.tar.gz && \
-    mv node-v8.9.4-linux-x64 node && \
-    rm -rf ./node-v8.9.4-*tar.gz
-ENV NODE_HOME=/opt/node
-ENV PATH $PATH:$NODE_HOME/bin
-
-#5,install postgresql
-RUN apt-get update && \
-    apt-get install -y postgresql postgresql-contrib sudo && \
-    sed -i 's/localhost/*/g' /etc/postgresql/10/main/postgresql.conf
-
-#6,install nginx
-RUN apt-get update && \
-  apt-get install -y nginx && \
-  rm -rf /var/lib/apt/lists/* && \
-  echo ""\ndaemon off;"" >> /etc/nginx/nginx.conf && \
-  chown -R www-data:www-data /var/lib/nginx
-
-#7,install sudo,python,vim,ping and ssh command
-RUN apt-get update && \
-  apt-get -y install sudo && \
-  apt-get -y install python && \
-  apt-get -y install vim && \
-  apt-get -y install iputils-ping && \
-  apt-get -y install net-tools && \
-  apt-get -y install openssh-server && \
-  apt-get -y install python-pip && \
-  pip install kazoo
-
-#8,add dolphinscheduler source code to /opt/dolphinscheduler_source
-ADD . /opt/dolphinscheduler_source
-
-
-#9,backend compilation
-RUN cd /opt/dolphinscheduler_source && \
-    mvn clean package -Prelease -Dmaven.test.skip=true
-
-#10,frontend compilation
-RUN chmod -R 777 /opt/dolphinscheduler_source/dolphinscheduler-ui && \
-    cd /opt/dolphinscheduler_source/dolphinscheduler-ui && \
-    rm -rf /opt/dolphinscheduler_source/dolphinscheduler-ui/node_modules && \
-    npm install node-sass --unsafe-perm && \
-    npm install && \
-    npm run build
-
-#11,modify dolphinscheduler configuration file
-#backend configuration
-RUN tar -zxvf /opt/dolphinscheduler_source/dolphinscheduler-dist/dolphinscheduler-backend/target/apache-dolphinscheduler-incubating-${tar_version}-dolphinscheduler-backend-bin.tar.gz -C /opt && \
-    mv /opt/apache-dolphinscheduler-incubating-${tar_version}-dolphinscheduler-backend-bin /opt/dolphinscheduler && \
-    rm -rf /opt/dolphinscheduler/conf
-
-ADD ./dockerfile/conf/dolphinscheduler/conf /opt/dolphinscheduler/conf
-#frontend nginx configuration
-ADD ./dockerfile/conf/nginx/dolphinscheduler.conf /etc/nginx/conf.d
-
-#12,open port
-EXPOSE 2181 2888 3888 3306 80 12345 8888
-
-COPY ./dockerfile/startup.sh /root/startup.sh
-#13,modify permissions and set soft links
-RUN chmod +x /root/startup.sh && \
-  chmod +x /opt/dolphinscheduler/script/create-dolphinscheduler.sh && \
-  chmod +x /opt/zookeeper/bin/zkServer.sh && \
-  chmod +x /opt/dolphinscheduler/bin/dolphinscheduler-daemon.sh && \
-  rm -rf /bin/sh && \
-  ln -s /bin/bash /bin/sh && \
-  mkdir -p /tmp/xls
-
+ADD ./conf/zookeeper/zoo.cfg /opt/zookeeper/conf
+ENV ZK_HOME /opt/zookeeper
+ENV PATH $ZK_HOME/bin:$PATH
+
+#4. install pg
+RUN apk add postgresql postgresql-contrib
+
+#5. add dolphinscheduler
+ADD ./apache-dolphinscheduler-incubating-${VERSION}-SNAPSHOT-dolphinscheduler-bin.tar.gz /opt/
+RUN mv /opt/apache-dolphinscheduler-incubating-${VERSION}-SNAPSHOT-dolphinscheduler-bin/ /opt/dolphinscheduler/
+ENV DOLPHINSCHEDULER_HOME /opt/dolphinscheduler
+
+#6. modify nginx
+RUN echo ""daemon off;"" >> /etc/nginx/nginx.conf && \
+    rm -rf /etc/nginx/conf.d/*
+ADD ./conf/nginx/dolphinscheduler.conf /etc/nginx/conf.d
+
+#7. add configuration and modify permissions and set soft links
+ADD ./startup-init-conf.sh /root/startup-init-conf.sh
+ADD ./startup.sh /root/startup.sh
+ADD ./conf/dolphinscheduler/*.tpl /opt/dolphinscheduler/conf/
+ADD ./conf/dolphinscheduler/env/dolphinscheduler_env /opt/dolphinscheduler/conf/env/
+RUN chmod +x /root/startup-init-conf.sh && \
+    chmod +x /root/startup.sh && \
+    chmod +x /opt/dolphinscheduler/conf/env/dolphinscheduler_env && \
+    chmod +x /opt/dolphinscheduler/script/*.sh && \
+    chmod +x /opt/dolphinscheduler/bin/*.sh && \
+    chmod +x /opt/zookeeper/bin/*.sh && \
+    dos2unix /root/startup-init-conf.sh && \","[{'comment': 'Why dos2unix, not sh?', 'commenter': 'khadgarmage'}, {'comment': ""Because bash script with Windows line-ending `CRLF` won't work on Linux.\r\n\r\nUNIX and UNIX-like operating systems (including Mac OS X) represent line endings as `LF` alone.\r\n\r\nConverting line-ending using `dos2unix`."", 'commenter': 'liwenhe1993'}]"
1978,dockerfile/hooks/build,"@@ -15,10 +15,21 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
 echo ""------ dolphinscheduler start - build -------""
 printenv
 
-docker build --build-arg version=$version --build-arg tar_version=$tar_version  -t $DOCKER_REPO:$version .
+echo -e ""Current Directory is $(pwd)\n""
+
+# maven package(Project Directory)
+echo -e ""mvn clean compile package -Prelease""
+mvn clean compile package -Prelease
+
+# mv dolphinscheduler-bin.tar.gz file to dockerfile directory
+echo -e ""mv $(pwd)/dolphinscheduler-dist/target/apache-dolphinscheduler-incubating-${VERSION}-SNAPSHOT-dolphinscheduler-bin.tar.gz $(pwd)/dockerfile/\n""","[{'comment': 'It is better to build image based on the current branch code, both CI and release can be used, rather than build based on the package', 'commenter': 'khadgarmage'}, {'comment': '`User` can use it, and `CI` can also use it.', 'commenter': 'liwenhe1993'}]"
2023,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/process/ProcessBuilderForWin32.java,"@@ -0,0 +1,1065 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.common.utils.process;
+
+import java.io.File;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * This class is used to create operating system processes.
+ *
+ * <p>Each {@code ProcessBuilderForWindows} instance manages a collection
+ * of process attributes.  The {@link #start()} method creates a new
+ * {@link Process} instance with those attributes.  The {@link
+ * #start()} method can be invoked repeatedly from the same instance
+ * to create new subprocesses with identical or related attributes.
+ *
+ * <p>Each process builder manages these process attributes:
+ *
+ * <ul>
+ *
+ * <li>a <i>command</i>, a list of strings which signifies the
+ * external program file to be invoked and its arguments, if any.
+ * Which string lists represent a valid operating system command is
+ * system-dependent.  For example, it is common for each conceptual
+ * argument to be an element in this list, but there are operating
+ * systems where programs are expected to tokenize command line
+ * strings themselves - on such a system a Java implementation might
+ * require commands to contain exactly two elements.
+ *
+ * <li>an <i>environment</i>, which is a system-dependent mapping from
+ * <i>variables</i> to <i>values</i>.  The initial value is a copy of
+ * the environment of the current process (see {@link System#getenv()}).
+ *
+ * <li>a <i>working directory</i>.  The default value is the current
+ * working directory of the current process, usually the directory
+ * named by the system property {@code user.dir}.
+ *
+ * <li><a name=""redirect-input"">a source of <i>standard input</i></a>.
+ * By default, the subprocess reads input from a pipe.  Java code
+ * can access this pipe via the output stream returned by
+ * {@link Process#getOutputStream()}.  However, standard input may
+ * be redirected to another source using
+ * {@link #redirectInput(ProcessBuilderForWin32.Redirect) redirectInput}.
+ * In this case, {@link Process#getOutputStream()} will return a
+ * <i>null output stream</i>, for which:
+ *
+ * <ul>
+ * <li>the {@link OutputStream#write(int) write} methods always
+ * throw {@code IOException}
+ * <li>the {@link OutputStream#close() close} method does nothing
+ * </ul>
+ *
+ * <li><a name=""redirect-output"">a destination for <i>standard output</i>
+ * and <i>standard error</i></a>.  By default, the subprocess writes standard
+ * output and standard error to pipes.  Java code can access these pipes
+ * via the input streams returned by {@link Process#getInputStream()} and
+ * {@link Process#getErrorStream()}.  However, standard output and
+ * standard error may be redirected to other destinations using
+ * {@link #redirectOutput(ProcessBuilderForWin32.Redirect) redirectOutput} and
+ * {@link #redirectError(ProcessBuilderForWin32.Redirect) redirectError}.
+ * In this case, {@link Process#getInputStream()} and/or
+ * {@link Process#getErrorStream()} will return a <i>null input
+ * stream</i>, for which:
+ *
+ * <ul>
+ * <li>the {@link InputStream#read() read} methods always return
+ * {@code -1}
+ * <li>the {@link InputStream#available() available} method always returns
+ * {@code 0}
+ * <li>the {@link InputStream#close() close} method does nothing
+ * </ul>
+ *
+ * <li>a <i>redirectErrorStream</i> property.  Initially, this property
+ * is {@code false}, meaning that the standard output and error
+ * output of a subprocess are sent to two separate streams, which can
+ * be accessed using the {@link Process#getInputStream()} and {@link
+ * Process#getErrorStream()} methods.
+ *
+ * <p>If the value is set to {@code true}, then:
+ *
+ * <ul>
+ * <li>standard error is merged with the standard output and always sent
+ * to the same destination (this makes it easier to correlate error
+ * messages with the corresponding output)
+ * <li>the common destination of standard error and standard output can be
+ * redirected using
+ * {@link #redirectOutput(ProcessBuilderForWin32.Redirect) redirectOutput}
+ * <li>any redirection set by the
+ * {@link #redirectError(ProcessBuilderForWin32.Redirect) redirectError}
+ * method is ignored when creating a subprocess
+ * <li>the stream returned from {@link Process#getErrorStream()} will
+ * always be a <a href=""#redirect-output"">null input stream</a>
+ * </ul>
+ *
+ * </ul>
+ *
+ * <p>Modifying a process builder's attributes will affect processes
+ * subsequently started by that object's {@link #start()} method, but
+ * will never affect previously started processes or the Java process
+ * itself.
+ *
+ * <p>Most error checking is performed by the {@link #start()} method.
+ * It is possible to modify the state of an object so that {@link
+ * #start()} will fail.  For example, setting the command attribute to
+ * an empty list will not throw an exception unless {@link #start()}
+ * is invoked.
+ *
+ * <p><strong>Note that this class is not synchronized.</strong>
+ * If multiple threads access a {@code ProcessBuilderForWindows} instance
+ * concurrently, and at least one of the threads modifies one of the
+ * attributes structurally, it <i>must</i> be synchronized externally.
+ *
+ * <p>Starting a new process which uses the default working directory
+ * and environment is easy:
+ *
+ * <pre> {@code
+ * Process p = new ProcessBuilderForWindows(""myCommand"", ""myArg"").start();
+ * }</pre>
+ *
+ * <p>Here is an example that starts a process with a modified working
+ * directory and environment, and redirects standard output and error
+ * to be appended to a log file:
+ *
+ * <pre> {@code
+ * ProcessBuilderForWindows pb =
+ *   new ProcessBuilderForWindows(""myCommand"", ""myArg1"", ""myArg2"");
+ * Map<String, String> env = pb.environment();
+ * env.put(""VAR1"", ""myValue"");
+ * env.remove(""OTHERVAR"");
+ * env.put(""VAR2"", env.get(""VAR1"") + ""suffix"");
+ * pb.directory(new File(""myDir""));
+ * File log = new File(""log"");
+ * pb.redirectErrorStream(true);
+ * pb.redirectOutput(Redirect.appendTo(log));
+ * Process p = pb.start();
+ * assert pb.redirectInput() == Redirect.PIPE;
+ * assert pb.redirectOutput().file() == log;
+ * assert p.getInputStream().read() == -1;
+ * }</pre>
+ *
+ * <p>To start a process with an explicit set of environment
+ * variables, first call {@link Map#clear() Map.clear()}
+ * before adding environment variables.
+ *
+ * @author Martin Buchholz
+ * @since 1.5
+ */
+
+public class ProcessBuilderForWin32 {","[{'comment': ""@dailidong what's the different between this class and the internal class? I would prefer remove all duplicated document, emphasize the difference and link to ProcessBuilder's build if there is nothing changed. Also at the beginning of the class document, it is possibly required that we mention it is copied from openjdk with modification, which will help reduce legal risk."", 'commenter': 'tisonkun'}]"
2023,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/process/ProcessEnvironmentForWin32.java,"@@ -0,0 +1,286 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.common.utils.process;
+
+import com.sun.jna.platform.win32.Kernel32Util;
+
+import java.util.*;
+
+final class ProcessEnvironmentForWin32 extends HashMap<String,String> {","[{'comment': 'ditto', 'commenter': 'tisonkun'}]"
2023,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/process/ProcessImplForWin32.java,"@@ -0,0 +1,752 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.common.utils.process;
+
+import com.sun.jna.Pointer;
+import com.sun.jna.platform.win32.*;
+import com.sun.jna.ptr.IntByReference;
+import sun.security.action.GetPropertyAction;
+
+import java.io.*;
+import java.security.AccessController;
+import java.security.PrivilegedAction;
+import java.util.ArrayList;
+import java.util.Locale;
+import java.util.concurrent.TimeUnit;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import static com.sun.jna.platform.win32.WinBase.STILL_ACTIVE;
+
+public class ProcessImplForWin32 extends Process {","[{'comment': 'ditto', 'commenter': 'tisonkun'}]"
2027,e2e/src/test/java/org/apache/dolphinscheduler/data/project/CreatWorkflowData.java,"@@ -29,8 +29,18 @@
     //input shell script
     public static final String SHELL_SCRIPT = ""echo 1111111"";
 
-    public static final String WORKFLOW_TITLE = ""创建流程定义 - DolphinScheduler"";
+    //input custom parameters
+    public static final String INPUT_CUSTOM_PARAMETERS = ""selenium_parameter"";
+
+    //input custom parameters value
+    public static final String INPUT_CUSTOM_PARAMETERS_VALUE = ""selenium_parameter_123"";
 
+    //input add custom parameters
+    public static final String INPUT_ADD_CUSTOM_PARAMETERS = ""selenium_parameter_delete"";
 
+    //input add custom parameters value
+    public static final String INPUT_ADD_CUSTOM_PARAMETERS_VALUE = ""selenium_parameter_delete_456"";
 
+    //create workflow title
+    public static final String WORKFLOW_TITLE = ""创建流程定义 - DolphinScheduler"";","[{'comment': 'Pls change to english content', 'commenter': 'khadgarmage'}]"
2035,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java,"@@ -391,8 +391,8 @@ public Result verifyDataSourceName(@ApiIgnore @RequestAttribute(value = Constant
         try {
             return dataSourceService.verifyDataSourceName(loginUser, name);
         } catch (Exception e) {
-            logger.error(VERFIY_DATASOURCE_NAME_FAILURE.getMsg(),e);
-            return error(VERFIY_DATASOURCE_NAME_FAILURE.getCode(), VERFIY_DATASOURCE_NAME_FAILURE.getMsg());
+            logger.error(VERIFY_DATASOURCE_NAME_FAILURE.getMsg(),e);","[{'comment': 'Space after comma, ie `logger.error(VERIFY_DATASOURCE_NAME_FAILURE.getMsg(), e);`', 'commenter': 'Jave-Chen'}]"
2035,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -16,251 +16,259 @@
  */
 package org.apache.dolphinscheduler.api.enums;
 
+import org.springframework.context.i18n.LocaleContextHolder;
+
+import java.util.Locale;
+
 /**
  *  status enum
  */
 public enum Status {
 
-    SUCCESS(0, ""success""),
+    SUCCESS(0, ""success"", ""成功""),
 
-    REQUEST_PARAMS_NOT_VALID_ERROR(10001, ""request parameter {0} is not valid""),
-    TASK_TIMEOUT_PARAMS_ERROR(10002, ""task timeout parameter is not valid""),
-    USER_NAME_EXIST(10003, ""user name already exists""),
-    USER_NAME_NULL(10004,""user name is null""),
-    HDFS_OPERATION_ERROR(10006, ""hdfs operation error""),
-    TASK_INSTANCE_NOT_FOUND(10008, ""task instance not found""),
-    TENANT_NAME_EXIST(10009, ""tenant code already exists""),
-    USER_NOT_EXIST(10010, ""user {0} not exists""),
-    ALERT_GROUP_NOT_EXIST(10011, ""alarm group not found""),
-    ALERT_GROUP_EXIST(10012, ""alarm group already exists""),
-    USER_NAME_PASSWD_ERROR(10013,""user name or password error""),
-    LOGIN_SESSION_FAILED(10014,""create session failed!""),
-    DATASOURCE_EXIST(10015, ""data source name already exists""),
-    DATASOURCE_CONNECT_FAILED(10016, ""data source connection failed""),
-    TENANT_NOT_EXIST(10017, ""tenant not exists""),
-    PROJECT_NOT_FOUNT(10018, ""project {0} not found ""),
-    PROJECT_ALREADY_EXISTS(10019, ""project {0} already exists""),
-    TASK_INSTANCE_NOT_EXISTS(10020, ""task instance {0} does not exist""),
-    TASK_INSTANCE_NOT_SUB_WORKFLOW_INSTANCE(10021, ""task instance {0} is not sub process instance""),
-    SCHEDULE_CRON_NOT_EXISTS(10022, ""scheduler crontab {0} does not exist""),
-    SCHEDULE_CRON_ONLINE_FORBID_UPDATE(10023, ""online status does not allow updateProcessInstance operations""),
-    SCHEDULE_CRON_CHECK_FAILED(10024, ""scheduler crontab expression validation failure: {0}""),
-    MASTER_NOT_EXISTS(10025, ""master does not exist""),
-    SCHEDULE_STATUS_UNKNOWN(10026, ""unknown command: {0}""),
-    CREATE_ALERT_GROUP_ERROR(10027,""create alert group error""),
-    QUERY_ALL_ALERTGROUP_ERROR(10028,""query all alertgroup error""),
-    LIST_PAGING_ALERT_GROUP_ERROR(10029,""list paging alert group error""),
-    UPDATE_ALERT_GROUP_ERROR(10030,""updateProcessInstance alert group error""),
-    DELETE_ALERT_GROUP_ERROR(10031,""delete alert group error""),
-    ALERT_GROUP_GRANT_USER_ERROR(10032,""alert group grant user error""),
-    CREATE_DATASOURCE_ERROR(10033,""create datasource error""),
-    UPDATE_DATASOURCE_ERROR(10034,""updateProcessInstance datasource error""),
-    QUERY_DATASOURCE_ERROR(10035,""query datasource error""),
-    CONNECT_DATASOURCE_FAILURE(10036,""connect datasource failure""),
-    CONNECTION_TEST_FAILURE(10037,""connection test failure""),
-    DELETE_DATA_SOURCE_FAILURE(10038,""delete data source failure""),
-    VERFIY_DATASOURCE_NAME_FAILURE(10039,""verfiy datasource name failure""),
-    UNAUTHORIZED_DATASOURCE(10040,""unauthorized datasource""),
-    AUTHORIZED_DATA_SOURCE(10041,""authorized data source""),
-    LOGIN_SUCCESS(10042,""login success""),
-    USER_LOGIN_FAILURE(10043,""user login failure""),
-    LIST_WORKERS_ERROR(10044,""list workers error""),
-    LIST_MASTERS_ERROR(10045,""list masters error""),
-    UPDATE_PROJECT_ERROR(10046,""updateProcessInstance project error""),
-    QUERY_PROJECT_DETAILS_BY_ID_ERROR(10047,""query project details by id error""),
-    CREATE_PROJECT_ERROR(10048,""create project error""),
-    LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR(10049,""login user query project list paging error""),
-    DELETE_PROJECT_ERROR(10050,""delete project error""),
-    QUERY_UNAUTHORIZED_PROJECT_ERROR(10051,""query unauthorized project error""),
-    QUERY_AUTHORIZED_PROJECT(10052,""query authorized project""),
-    QUERY_QUEUE_LIST_ERROR(10053,""query queue list error""),
-    CREATE_RESOURCE_ERROR(10054,""create resource error""),
-    UPDATE_RESOURCE_ERROR(10055,""updateProcessInstance resource error""),
-    QUERY_RESOURCES_LIST_ERROR(10056,""query resources list error""),
-    QUERY_RESOURCES_LIST_PAGING(10057,""query resources list paging""),
-    DELETE_RESOURCE_ERROR(10058,""delete resource error""),
-    VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR(10059,""verify resource by name and type error""),
-    VIEW_RESOURCE_FILE_ON_LINE_ERROR(10060,""view resource file online error""),
-    CREATE_RESOURCE_FILE_ON_LINE_ERROR(10061,""create resource file online error""),
-    RESOURCE_FILE_IS_EMPTY(10062,""resource file is empty""),
-    EDIT_RESOURCE_FILE_ON_LINE_ERROR(10063,""edit resource file online error""),
-    DOWNLOAD_RESOURCE_FILE_ERROR(10064,""download resource file error""),
-    CREATE_UDF_FUNCTION_ERROR(10065 ,""create udf function error""),
-    VIEW_UDF_FUNCTION_ERROR( 10066,""view udf function error""),
-    UPDATE_UDF_FUNCTION_ERROR(10067,""updateProcessInstance udf function error""),
-    QUERY_UDF_FUNCTION_LIST_PAGING_ERROR( 10068,""query udf function list paging error""),
-    QUERY_DATASOURCE_BY_TYPE_ERROR( 10069,""query datasource by type error""),
-    VERIFY_UDF_FUNCTION_NAME_ERROR( 10070,""verify udf function name error""),
-    DELETE_UDF_FUNCTION_ERROR( 10071,""delete udf function error""),
-    AUTHORIZED_FILE_RESOURCE_ERROR( 10072,""authorized file resource error""),
-    UNAUTHORIZED_FILE_RESOURCE_ERROR( 10073,""unauthorized file resource error""),
-    UNAUTHORIZED_UDF_FUNCTION_ERROR( 10074,""unauthorized udf function error""),
-    AUTHORIZED_UDF_FUNCTION_ERROR(10075,""authorized udf function error""),
-    CREATE_SCHEDULE_ERROR(10076,""create schedule error""),
-    UPDATE_SCHEDULE_ERROR(10077,""updateProcessInstance schedule error""),
-    PUBLISH_SCHEDULE_ONLINE_ERROR(10078,""publish schedule online error""),
-    OFFLINE_SCHEDULE_ERROR(10079,""offline schedule error""),
-    QUERY_SCHEDULE_LIST_PAGING_ERROR(10080,""query schedule list paging error""),
-    QUERY_SCHEDULE_LIST_ERROR(10081,""query schedule list error""),
-    QUERY_TASK_LIST_PAGING_ERROR(10082,""query task list paging error""),
-    QUERY_TASK_RECORD_LIST_PAGING_ERROR(10083,""query task record list paging error""),
-    CREATE_TENANT_ERROR(10084,""create tenant error""),
-    QUERY_TENANT_LIST_PAGING_ERROR(10085,""query tenant list paging error""),
-    QUERY_TENANT_LIST_ERROR(10086,""query tenant list error""),
-    UPDATE_TENANT_ERROR(10087,""updateProcessInstance tenant error""),
-    DELETE_TENANT_BY_ID_ERROR(10088,""delete tenant by id error""),
-    VERIFY_TENANT_CODE_ERROR(10089,""verify tenant code error""),
-    CREATE_USER_ERROR(10090,""create user error""),
-    QUERY_USER_LIST_PAGING_ERROR(10091,""query user list paging error""),
-    UPDATE_USER_ERROR(10092,""updateProcessInstance user error""),
-    DELETE_USER_BY_ID_ERROR(10093,""delete user by id error""),
-    GRANT_PROJECT_ERROR(10094,""grant project error""),
-    GRANT_RESOURCE_ERROR(10095,""grant resource error""),
-    GRANT_UDF_FUNCTION_ERROR(10096,""grant udf function error""),
-    GRANT_DATASOURCE_ERROR(10097,""grant datasource error""),
-    GET_USER_INFO_ERROR(10098,""get user info error""),
-    USER_LIST_ERROR(10099,""user list error""),
-    VERIFY_USERNAME_ERROR(10100,""verify username error""),
-    UNAUTHORIZED_USER_ERROR(10101,""unauthorized user error""),
-    AUTHORIZED_USER_ERROR(10102,""authorized user error""),
-    QUERY_TASK_INSTANCE_LOG_ERROR(10103,""view task instance log error""),
-    DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR(10104,""download task instance log file error""),
-    CREATE_PROCESS_DEFINITION(10105,""create process definition""),
-    VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR(10106,""verify process definition name unique error""),
-    UPDATE_PROCESS_DEFINITION_ERROR(10107,""updateProcessInstance process definition error""),
-    RELEASE_PROCESS_DEFINITION_ERROR(10108,""release process definition error""),
-    QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR(10109,""query datail of process definition error""),
-    QUERY_PROCCESS_DEFINITION_LIST(10110,""query proccess definition list""),
-    ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR(10111,""encapsulation treeview structure error""),
-    GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR(10112,""get tasks list by process definition id error""),
-    QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR(10113,""query process instance list paging error""),
-    QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR(10114,""query task list by process instance id error""),
-    UPDATE_PROCESS_INSTANCE_ERROR(10115,""updateProcessInstance process instance error""),
-    QUERY_PROCESS_INSTANCE_BY_ID_ERROR(10116,""query process instance by id error""),
-    DELETE_PROCESS_INSTANCE_BY_ID_ERROR(10117,""delete process instance by id error""),
-    QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR(10118,""query sub process instance detail info by task id error""),
-    QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR(10119,""query parent process instance detail info by sub process instance id error""),
-    QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR(10120,""query process instance all variables error""),
-    ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR(10121,""encapsulation process instance gantt structure error""),
-    QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR(10122,""query proccess definition list paging error""),
-    SIGN_OUT_ERROR(10123,""sign out error""),
-    TENANT_CODE_HAS_ALREADY_EXISTS(10124,""tenant code has already exists""),
-    IP_IS_EMPTY(10125,""ip is empty""),
-    SCHEDULE_CRON_REALEASE_NEED_NOT_CHANGE(10126, ""schedule release is already {0}""),
-    CREATE_QUEUE_ERROR(10127, ""create queue error""),
-    QUEUE_NOT_EXIST(10128, ""queue {0} not exists""),
-    QUEUE_VALUE_EXIST(10129, ""queue value {0} already exists""),
-    QUEUE_NAME_EXIST(10130, ""queue name {0} already exists""),
-    UPDATE_QUEUE_ERROR(10131, ""update queue error""),
-    NEED_NOT_UPDATE_QUEUE(10132, ""no content changes, no updates are required""),
-    VERIFY_QUEUE_ERROR(10133,""verify queue error""),
-    NAME_NULL(10134,""name must be not null""),
-    NAME_EXIST(10135, ""name {0} already exists""),
-    SAVE_ERROR(10136, ""save error""),
-    DELETE_PROJECT_ERROR_DEFINES_NOT_NULL(10137, ""please delete the process definitions in project first!""),
-    BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR(10117,""batch delete process instance by ids {0} error""),
-    PREVIEW_SCHEDULE_ERROR(10139,""preview schedule error""),
-    PARSE_TO_CRON_EXPRESSION_ERROR(10140,""parse cron to cron expression error""),
-    SCHEDULE_START_TIME_END_TIME_SAME(10141,""The start time must not be the same as the end""),
-    DELETE_TENANT_BY_ID_FAIL(100142,""delete tenant by id fail, for there are {0} process instances in executing using it""),
-    DELETE_TENANT_BY_ID_FAIL_DEFINES(100143,""delete tenant by id fail, for there are {0} process definitions using it""),
-    DELETE_TENANT_BY_ID_FAIL_USERS(100144,""delete tenant by id fail, for there are {0} users using it""),
+    REQUEST_PARAMS_NOT_VALID_ERROR(10001, ""request parameter {0} is not valid"", ""请求参数[{0}]无效""),
+    TASK_TIMEOUT_PARAMS_ERROR(10002, ""task timeout parameter is not valid"", ""任务超时参数无效""),
+    USER_NAME_EXIST(10003, ""user name already exists"", ""用户名已存在""),
+    USER_NAME_NULL(10004,""user name is null"", ""用户名不能为空""),
+    HDFS_OPERATION_ERROR(10006, ""hdfs operation error"", ""hdfs操作错误""),
+    TASK_INSTANCE_NOT_FOUND(10008, ""task instance not found"", ""任务实例不存在""),
+    TENANT_NAME_EXIST(10009, ""tenant code already exists"", ""租户编码不能为空""),
+    USER_NOT_EXIST(10010, ""user {0} not exists"", ""用户[{0}]不存在""),
+    ALERT_GROUP_NOT_EXIST(10011, ""alarm group not found"", ""告警组不存在""),
+    ALERT_GROUP_EXIST(10012, ""alarm group already exists"", ""告警组名称已存在""),
+    USER_NAME_PASSWD_ERROR(10013,""user name or password error"", ""用户名或密码错误""),
+    LOGIN_SESSION_FAILED(10014,""create session failed!"", ""创建session失败""),
+    DATASOURCE_EXIST(10015, ""data source name already exists"", ""数据源名称已存在""),
+    DATASOURCE_CONNECT_FAILED(10016, ""data source connection failed"", ""建立数据源连接失败""),
+    TENANT_NOT_EXIST(10017, ""tenant not exists"", ""租户不存在""),
+    PROJECT_NOT_FOUNT(10018, ""project {0} not found "", ""项目[{0}]不存在""),
+    PROJECT_ALREADY_EXISTS(10019, ""project {0} already exists"", ""项目名称[{0}]已存在""),
+    TASK_INSTANCE_NOT_EXISTS(10020, ""task instance {0} does not exist"", ""任务实例[{0}]不存在""),
+    TASK_INSTANCE_NOT_SUB_WORKFLOW_INSTANCE(10021, ""task instance {0} is not sub process instance"", ""任务实例[{0}]不是子流程实例""),
+    SCHEDULE_CRON_NOT_EXISTS(10022, ""scheduler crontab {0} does not exist"", ""调度配置定时表达式[{0}]不存在""),
+    SCHEDULE_CRON_ONLINE_FORBID_UPDATE(10023, ""online status does not allow update operations"", ""调度配置上线状态不允许修改""),
+    SCHEDULE_CRON_CHECK_FAILED(10024, ""scheduler crontab expression validation failure: {0}"", ""调度配置定时表达式验证失败: {0}""),
+    MASTER_NOT_EXISTS(10025, ""master does not exist"", ""无可用master节点""),
+    SCHEDULE_STATUS_UNKNOWN(10026, ""unknown status: {0}"", ""未知状态: {0}""),
+    CREATE_ALERT_GROUP_ERROR(10027,""create alert group error"", ""创建告警组错误""),
+    QUERY_ALL_ALERTGROUP_ERROR(10028,""query all alertgroup error"", ""查询告警组错误""),
+    LIST_PAGING_ALERT_GROUP_ERROR(10029,""list paging alert group error"", ""分页查询告警组错误""),
+    UPDATE_ALERT_GROUP_ERROR(10030,""update alert group error"", ""更新告警组错误""),
+    DELETE_ALERT_GROUP_ERROR(10031,""delete alert group error"", ""删除告警组错误""),
+    ALERT_GROUP_GRANT_USER_ERROR(10032,""alert group grant user error"", ""告警组授权用户错误""),
+    CREATE_DATASOURCE_ERROR(10033,""create datasource error"", ""创建数据源错误""),
+    UPDATE_DATASOURCE_ERROR(10034,""update datasource error"", ""更新数据源错误""),
+    QUERY_DATASOURCE_ERROR(10035,""query datasource error"", ""查询数据源错误""),
+    CONNECT_DATASOURCE_FAILURE(10036,""connect datasource failure"", ""建立数据源连接失败""),
+    CONNECTION_TEST_FAILURE(10037,""connection test failure"", ""测试数据源连接失败""),
+    DELETE_DATA_SOURCE_FAILURE(10038,""delete data source failure"", ""删除数据源失败""),
+    VERIFY_DATASOURCE_NAME_FAILURE(10039,""verify datasource name failure"", ""验证数据源名称失败""),
+    UNAUTHORIZED_DATASOURCE(10040,""unauthorized datasource"", ""未经授权的数据源""),
+    AUTHORIZED_DATA_SOURCE(10041,""authorized data source"", ""授权数据源失败""),
+    LOGIN_SUCCESS(10042,""login success"", ""登录成功""),
+    USER_LOGIN_FAILURE(10043,""user login failure"", ""用户登录失败""),
+    LIST_WORKERS_ERROR(10044,""list workers error"", ""查询worker列表错误""),
+    LIST_MASTERS_ERROR(10045,""list masters error"", ""查询master列表错误""),
+    UPDATE_PROJECT_ERROR(10046,""update project error"", ""更新项目信息错误""),
+    QUERY_PROJECT_DETAILS_BY_ID_ERROR(10047,""query project details by id error"", ""查询项目详细信息错误""),
+    CREATE_PROJECT_ERROR(10048,""create project error"", ""创建项目错误""),
+    LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR(10049,""login user query project list paging error"", ""分页查询项目列表错误""),
+    DELETE_PROJECT_ERROR(10050,""delete project error"", ""删除项目错误""),
+    QUERY_UNAUTHORIZED_PROJECT_ERROR(10051,""query unauthorized project error"", ""查询未授权项目错误""),
+    QUERY_AUTHORIZED_PROJECT(10052,""query authorized project"", ""查询授权项目错误""),
+    QUERY_QUEUE_LIST_ERROR(10053,""query queue list error"", ""查询队列列表错误""),
+    CREATE_RESOURCE_ERROR(10054,""create resource error"", ""创建资源错误""),
+    UPDATE_RESOURCE_ERROR(10055,""update resource error"", ""更新资源错误""),
+    QUERY_RESOURCES_LIST_ERROR(10056,""query resources list error"", ""查询资源列表错误""),
+    QUERY_RESOURCES_LIST_PAGING(10057,""query resources list paging"", ""分页查询资源列表错误""),
+    DELETE_RESOURCE_ERROR(10058,""delete resource error"", ""删除资源错误""),
+    VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR(10059,""verify resource by name and type error"", ""资源名称或类型验证错误""),
+    VIEW_RESOURCE_FILE_ON_LINE_ERROR(10060,""view resource file online error"", ""查看资源文件错误""),
+    CREATE_RESOURCE_FILE_ON_LINE_ERROR(10061,""create resource file online error"", ""创建资源文件错误""),
+    RESOURCE_FILE_IS_EMPTY(10062,""resource file is empty"", ""资源文件内容不能为空""),
+    EDIT_RESOURCE_FILE_ON_LINE_ERROR(10063,""edit resource file online error"", ""更新资源文件错误""),
+    DOWNLOAD_RESOURCE_FILE_ERROR(10064,""download resource file error"", ""下载资源文件错误""),
+    CREATE_UDF_FUNCTION_ERROR(10065 ,""create udf function error"", ""创建UDF函数错误""),
+    VIEW_UDF_FUNCTION_ERROR( 10066,""view udf function error"", ""查询UDF函数错误""),
+    UPDATE_UDF_FUNCTION_ERROR(10067,""update udf function error"", ""更新UDF函数错误""),
+    QUERY_UDF_FUNCTION_LIST_PAGING_ERROR( 10068,""query udf function list paging error"", ""分页查询UDF函数列表错误""),
+    QUERY_DATASOURCE_BY_TYPE_ERROR( 10069,""query datasource by type error"", ""查询数据源信息错误""),
+    VERIFY_UDF_FUNCTION_NAME_ERROR( 10070,""verify udf function name error"", ""UDF函数名称验证错误""),
+    DELETE_UDF_FUNCTION_ERROR( 10071,""delete udf function error"", ""删除UDF函数错误""),
+    AUTHORIZED_FILE_RESOURCE_ERROR( 10072,""authorized file resource error"", ""授权资源文件错误""),
+    UNAUTHORIZED_FILE_RESOURCE_ERROR( 10073,""unauthorized file resource error"", ""查询未授权资源错误""),
+    UNAUTHORIZED_UDF_FUNCTION_ERROR( 10074,""unauthorized udf function error"", ""查询未授权UDF函数错误""),
+    AUTHORIZED_UDF_FUNCTION_ERROR(10075,""authorized udf function error"", ""授权UDF函数错误""),
+    CREATE_SCHEDULE_ERROR(10076,""create schedule error"", ""创建调度配置错误""),
+    UPDATE_SCHEDULE_ERROR(10077,""update schedule error"", ""更新调度配置错误""),
+    PUBLISH_SCHEDULE_ONLINE_ERROR(10078,""publish schedule online error"", ""上线调度配置错误""),
+    OFFLINE_SCHEDULE_ERROR(10079,""offline schedule error"", ""下线调度配置错误""),
+    QUERY_SCHEDULE_LIST_PAGING_ERROR(10080,""query schedule list paging error"", ""分页查询调度配置列表错误""),
+    QUERY_SCHEDULE_LIST_ERROR(10081,""query schedule list error"", ""查询调度配置列表错误""),
+    QUERY_TASK_LIST_PAGING_ERROR(10082,""query task list paging error"", ""分页查询任务列表错误""),
+    QUERY_TASK_RECORD_LIST_PAGING_ERROR(10083,""query task record list paging error"", ""分页查询任务记录错误""),
+    CREATE_TENANT_ERROR(10084,""create tenant error"", ""创建租户错误""),
+    QUERY_TENANT_LIST_PAGING_ERROR(10085,""query tenant list paging error"", ""分页查询租户列表错误""),
+    QUERY_TENANT_LIST_ERROR(10086,""query tenant list error"", ""查询租户列表错误""),
+    UPDATE_TENANT_ERROR(10087,""update tenant error"", ""更新租户错误""),
+    DELETE_TENANT_BY_ID_ERROR(10088,""delete tenant by id error"", ""删除租户错误""),
+    VERIFY_TENANT_CODE_ERROR(10089,""verify tenant code error"", ""租户编码验证错误""),
+    CREATE_USER_ERROR(10090,""create user error"", ""创建用户错误""),
+    QUERY_USER_LIST_PAGING_ERROR(10091,""query user list paging error"", ""分页查询用户列表错误""),
+    UPDATE_USER_ERROR(10092,""update user error"", ""更新用户错误""),
+    DELETE_USER_BY_ID_ERROR(10093,""delete user by id error"", ""删除用户错误""),
+    GRANT_PROJECT_ERROR(10094,""grant project error"", ""授权项目错误""),
+    GRANT_RESOURCE_ERROR(10095,""grant resource error"", ""授权资源错误""),
+    GRANT_UDF_FUNCTION_ERROR(10096,""grant udf function error"", ""授权UDF函数错误""),
+    GRANT_DATASOURCE_ERROR(10097,""grant datasource error"", ""授权数据源错误""),
+    GET_USER_INFO_ERROR(10098,""get user info error"", ""获取用户信息错误""),
+    USER_LIST_ERROR(10099,""user list error"", ""查询用户列表错误""),
+    VERIFY_USERNAME_ERROR(10100,""verify username error"", ""用户名验证错误""),
+    UNAUTHORIZED_USER_ERROR(10101,""unauthorized user error"", ""查询未授权用户错误""),
+    AUTHORIZED_USER_ERROR(10102,""authorized user error"", ""查询授权用户错误""),
+    QUERY_TASK_INSTANCE_LOG_ERROR(10103,""view task instance log error"", ""查询任务实例日志错误""),
+    DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR(10104,""download task instance log file error"", ""下载任务日志文件错误""),
+    CREATE_PROCESS_DEFINITION(10105,""create process definition"", ""创建工作流错误""),
+    VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR(10106,""verify process definition name unique error"", ""工作流名称已存在""),
+    UPDATE_PROCESS_DEFINITION_ERROR(10107,""update process definition error"", ""更新工作流定义错误""),
+    RELEASE_PROCESS_DEFINITION_ERROR(10108,""release process definition error"", ""上下线工作流错误""),","[{'comment': '上线工作流错误', 'commenter': 'Technoboy-'}]"
2035,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -16,251 +16,259 @@
  */
 package org.apache.dolphinscheduler.api.enums;
 
+import org.springframework.context.i18n.LocaleContextHolder;
+
+import java.util.Locale;
+
 /**
  *  status enum
  */
 public enum Status {
 
-    SUCCESS(0, ""success""),
+    SUCCESS(0, ""success"", ""成功""),
 
-    REQUEST_PARAMS_NOT_VALID_ERROR(10001, ""request parameter {0} is not valid""),
-    TASK_TIMEOUT_PARAMS_ERROR(10002, ""task timeout parameter is not valid""),
-    USER_NAME_EXIST(10003, ""user name already exists""),
-    USER_NAME_NULL(10004,""user name is null""),
-    HDFS_OPERATION_ERROR(10006, ""hdfs operation error""),
-    TASK_INSTANCE_NOT_FOUND(10008, ""task instance not found""),
-    TENANT_NAME_EXIST(10009, ""tenant code already exists""),
-    USER_NOT_EXIST(10010, ""user {0} not exists""),
-    ALERT_GROUP_NOT_EXIST(10011, ""alarm group not found""),
-    ALERT_GROUP_EXIST(10012, ""alarm group already exists""),
-    USER_NAME_PASSWD_ERROR(10013,""user name or password error""),
-    LOGIN_SESSION_FAILED(10014,""create session failed!""),
-    DATASOURCE_EXIST(10015, ""data source name already exists""),
-    DATASOURCE_CONNECT_FAILED(10016, ""data source connection failed""),
-    TENANT_NOT_EXIST(10017, ""tenant not exists""),
-    PROJECT_NOT_FOUNT(10018, ""project {0} not found ""),
-    PROJECT_ALREADY_EXISTS(10019, ""project {0} already exists""),
-    TASK_INSTANCE_NOT_EXISTS(10020, ""task instance {0} does not exist""),
-    TASK_INSTANCE_NOT_SUB_WORKFLOW_INSTANCE(10021, ""task instance {0} is not sub process instance""),
-    SCHEDULE_CRON_NOT_EXISTS(10022, ""scheduler crontab {0} does not exist""),
-    SCHEDULE_CRON_ONLINE_FORBID_UPDATE(10023, ""online status does not allow updateProcessInstance operations""),
-    SCHEDULE_CRON_CHECK_FAILED(10024, ""scheduler crontab expression validation failure: {0}""),
-    MASTER_NOT_EXISTS(10025, ""master does not exist""),
-    SCHEDULE_STATUS_UNKNOWN(10026, ""unknown command: {0}""),
-    CREATE_ALERT_GROUP_ERROR(10027,""create alert group error""),
-    QUERY_ALL_ALERTGROUP_ERROR(10028,""query all alertgroup error""),
-    LIST_PAGING_ALERT_GROUP_ERROR(10029,""list paging alert group error""),
-    UPDATE_ALERT_GROUP_ERROR(10030,""updateProcessInstance alert group error""),
-    DELETE_ALERT_GROUP_ERROR(10031,""delete alert group error""),
-    ALERT_GROUP_GRANT_USER_ERROR(10032,""alert group grant user error""),
-    CREATE_DATASOURCE_ERROR(10033,""create datasource error""),
-    UPDATE_DATASOURCE_ERROR(10034,""updateProcessInstance datasource error""),
-    QUERY_DATASOURCE_ERROR(10035,""query datasource error""),
-    CONNECT_DATASOURCE_FAILURE(10036,""connect datasource failure""),
-    CONNECTION_TEST_FAILURE(10037,""connection test failure""),
-    DELETE_DATA_SOURCE_FAILURE(10038,""delete data source failure""),
-    VERFIY_DATASOURCE_NAME_FAILURE(10039,""verfiy datasource name failure""),
-    UNAUTHORIZED_DATASOURCE(10040,""unauthorized datasource""),
-    AUTHORIZED_DATA_SOURCE(10041,""authorized data source""),
-    LOGIN_SUCCESS(10042,""login success""),
-    USER_LOGIN_FAILURE(10043,""user login failure""),
-    LIST_WORKERS_ERROR(10044,""list workers error""),
-    LIST_MASTERS_ERROR(10045,""list masters error""),
-    UPDATE_PROJECT_ERROR(10046,""updateProcessInstance project error""),
-    QUERY_PROJECT_DETAILS_BY_ID_ERROR(10047,""query project details by id error""),
-    CREATE_PROJECT_ERROR(10048,""create project error""),
-    LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR(10049,""login user query project list paging error""),
-    DELETE_PROJECT_ERROR(10050,""delete project error""),
-    QUERY_UNAUTHORIZED_PROJECT_ERROR(10051,""query unauthorized project error""),
-    QUERY_AUTHORIZED_PROJECT(10052,""query authorized project""),
-    QUERY_QUEUE_LIST_ERROR(10053,""query queue list error""),
-    CREATE_RESOURCE_ERROR(10054,""create resource error""),
-    UPDATE_RESOURCE_ERROR(10055,""updateProcessInstance resource error""),
-    QUERY_RESOURCES_LIST_ERROR(10056,""query resources list error""),
-    QUERY_RESOURCES_LIST_PAGING(10057,""query resources list paging""),
-    DELETE_RESOURCE_ERROR(10058,""delete resource error""),
-    VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR(10059,""verify resource by name and type error""),
-    VIEW_RESOURCE_FILE_ON_LINE_ERROR(10060,""view resource file online error""),
-    CREATE_RESOURCE_FILE_ON_LINE_ERROR(10061,""create resource file online error""),
-    RESOURCE_FILE_IS_EMPTY(10062,""resource file is empty""),
-    EDIT_RESOURCE_FILE_ON_LINE_ERROR(10063,""edit resource file online error""),
-    DOWNLOAD_RESOURCE_FILE_ERROR(10064,""download resource file error""),
-    CREATE_UDF_FUNCTION_ERROR(10065 ,""create udf function error""),
-    VIEW_UDF_FUNCTION_ERROR( 10066,""view udf function error""),
-    UPDATE_UDF_FUNCTION_ERROR(10067,""updateProcessInstance udf function error""),
-    QUERY_UDF_FUNCTION_LIST_PAGING_ERROR( 10068,""query udf function list paging error""),
-    QUERY_DATASOURCE_BY_TYPE_ERROR( 10069,""query datasource by type error""),
-    VERIFY_UDF_FUNCTION_NAME_ERROR( 10070,""verify udf function name error""),
-    DELETE_UDF_FUNCTION_ERROR( 10071,""delete udf function error""),
-    AUTHORIZED_FILE_RESOURCE_ERROR( 10072,""authorized file resource error""),
-    UNAUTHORIZED_FILE_RESOURCE_ERROR( 10073,""unauthorized file resource error""),
-    UNAUTHORIZED_UDF_FUNCTION_ERROR( 10074,""unauthorized udf function error""),
-    AUTHORIZED_UDF_FUNCTION_ERROR(10075,""authorized udf function error""),
-    CREATE_SCHEDULE_ERROR(10076,""create schedule error""),
-    UPDATE_SCHEDULE_ERROR(10077,""updateProcessInstance schedule error""),
-    PUBLISH_SCHEDULE_ONLINE_ERROR(10078,""publish schedule online error""),
-    OFFLINE_SCHEDULE_ERROR(10079,""offline schedule error""),
-    QUERY_SCHEDULE_LIST_PAGING_ERROR(10080,""query schedule list paging error""),
-    QUERY_SCHEDULE_LIST_ERROR(10081,""query schedule list error""),
-    QUERY_TASK_LIST_PAGING_ERROR(10082,""query task list paging error""),
-    QUERY_TASK_RECORD_LIST_PAGING_ERROR(10083,""query task record list paging error""),
-    CREATE_TENANT_ERROR(10084,""create tenant error""),
-    QUERY_TENANT_LIST_PAGING_ERROR(10085,""query tenant list paging error""),
-    QUERY_TENANT_LIST_ERROR(10086,""query tenant list error""),
-    UPDATE_TENANT_ERROR(10087,""updateProcessInstance tenant error""),
-    DELETE_TENANT_BY_ID_ERROR(10088,""delete tenant by id error""),
-    VERIFY_TENANT_CODE_ERROR(10089,""verify tenant code error""),
-    CREATE_USER_ERROR(10090,""create user error""),
-    QUERY_USER_LIST_PAGING_ERROR(10091,""query user list paging error""),
-    UPDATE_USER_ERROR(10092,""updateProcessInstance user error""),
-    DELETE_USER_BY_ID_ERROR(10093,""delete user by id error""),
-    GRANT_PROJECT_ERROR(10094,""grant project error""),
-    GRANT_RESOURCE_ERROR(10095,""grant resource error""),
-    GRANT_UDF_FUNCTION_ERROR(10096,""grant udf function error""),
-    GRANT_DATASOURCE_ERROR(10097,""grant datasource error""),
-    GET_USER_INFO_ERROR(10098,""get user info error""),
-    USER_LIST_ERROR(10099,""user list error""),
-    VERIFY_USERNAME_ERROR(10100,""verify username error""),
-    UNAUTHORIZED_USER_ERROR(10101,""unauthorized user error""),
-    AUTHORIZED_USER_ERROR(10102,""authorized user error""),
-    QUERY_TASK_INSTANCE_LOG_ERROR(10103,""view task instance log error""),
-    DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR(10104,""download task instance log file error""),
-    CREATE_PROCESS_DEFINITION(10105,""create process definition""),
-    VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR(10106,""verify process definition name unique error""),
-    UPDATE_PROCESS_DEFINITION_ERROR(10107,""updateProcessInstance process definition error""),
-    RELEASE_PROCESS_DEFINITION_ERROR(10108,""release process definition error""),
-    QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR(10109,""query datail of process definition error""),
-    QUERY_PROCCESS_DEFINITION_LIST(10110,""query proccess definition list""),
-    ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR(10111,""encapsulation treeview structure error""),
-    GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR(10112,""get tasks list by process definition id error""),
-    QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR(10113,""query process instance list paging error""),
-    QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR(10114,""query task list by process instance id error""),
-    UPDATE_PROCESS_INSTANCE_ERROR(10115,""updateProcessInstance process instance error""),
-    QUERY_PROCESS_INSTANCE_BY_ID_ERROR(10116,""query process instance by id error""),
-    DELETE_PROCESS_INSTANCE_BY_ID_ERROR(10117,""delete process instance by id error""),
-    QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR(10118,""query sub process instance detail info by task id error""),
-    QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR(10119,""query parent process instance detail info by sub process instance id error""),
-    QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR(10120,""query process instance all variables error""),
-    ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR(10121,""encapsulation process instance gantt structure error""),
-    QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR(10122,""query proccess definition list paging error""),
-    SIGN_OUT_ERROR(10123,""sign out error""),
-    TENANT_CODE_HAS_ALREADY_EXISTS(10124,""tenant code has already exists""),
-    IP_IS_EMPTY(10125,""ip is empty""),
-    SCHEDULE_CRON_REALEASE_NEED_NOT_CHANGE(10126, ""schedule release is already {0}""),
-    CREATE_QUEUE_ERROR(10127, ""create queue error""),
-    QUEUE_NOT_EXIST(10128, ""queue {0} not exists""),
-    QUEUE_VALUE_EXIST(10129, ""queue value {0} already exists""),
-    QUEUE_NAME_EXIST(10130, ""queue name {0} already exists""),
-    UPDATE_QUEUE_ERROR(10131, ""update queue error""),
-    NEED_NOT_UPDATE_QUEUE(10132, ""no content changes, no updates are required""),
-    VERIFY_QUEUE_ERROR(10133,""verify queue error""),
-    NAME_NULL(10134,""name must be not null""),
-    NAME_EXIST(10135, ""name {0} already exists""),
-    SAVE_ERROR(10136, ""save error""),
-    DELETE_PROJECT_ERROR_DEFINES_NOT_NULL(10137, ""please delete the process definitions in project first!""),
-    BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR(10117,""batch delete process instance by ids {0} error""),
-    PREVIEW_SCHEDULE_ERROR(10139,""preview schedule error""),
-    PARSE_TO_CRON_EXPRESSION_ERROR(10140,""parse cron to cron expression error""),
-    SCHEDULE_START_TIME_END_TIME_SAME(10141,""The start time must not be the same as the end""),
-    DELETE_TENANT_BY_ID_FAIL(100142,""delete tenant by id fail, for there are {0} process instances in executing using it""),
-    DELETE_TENANT_BY_ID_FAIL_DEFINES(100143,""delete tenant by id fail, for there are {0} process definitions using it""),
-    DELETE_TENANT_BY_ID_FAIL_USERS(100144,""delete tenant by id fail, for there are {0} users using it""),
+    REQUEST_PARAMS_NOT_VALID_ERROR(10001, ""request parameter {0} is not valid"", ""请求参数[{0}]无效""),
+    TASK_TIMEOUT_PARAMS_ERROR(10002, ""task timeout parameter is not valid"", ""任务超时参数无效""),
+    USER_NAME_EXIST(10003, ""user name already exists"", ""用户名已存在""),
+    USER_NAME_NULL(10004,""user name is null"", ""用户名不能为空""),
+    HDFS_OPERATION_ERROR(10006, ""hdfs operation error"", ""hdfs操作错误""),
+    TASK_INSTANCE_NOT_FOUND(10008, ""task instance not found"", ""任务实例不存在""),
+    TENANT_NAME_EXIST(10009, ""tenant code already exists"", ""租户编码不能为空""),
+    USER_NOT_EXIST(10010, ""user {0} not exists"", ""用户[{0}]不存在""),
+    ALERT_GROUP_NOT_EXIST(10011, ""alarm group not found"", ""告警组不存在""),
+    ALERT_GROUP_EXIST(10012, ""alarm group already exists"", ""告警组名称已存在""),
+    USER_NAME_PASSWD_ERROR(10013,""user name or password error"", ""用户名或密码错误""),
+    LOGIN_SESSION_FAILED(10014,""create session failed!"", ""创建session失败""),
+    DATASOURCE_EXIST(10015, ""data source name already exists"", ""数据源名称已存在""),
+    DATASOURCE_CONNECT_FAILED(10016, ""data source connection failed"", ""建立数据源连接失败""),
+    TENANT_NOT_EXIST(10017, ""tenant not exists"", ""租户不存在""),
+    PROJECT_NOT_FOUNT(10018, ""project {0} not found "", ""项目[{0}]不存在""),
+    PROJECT_ALREADY_EXISTS(10019, ""project {0} already exists"", ""项目名称[{0}]已存在""),
+    TASK_INSTANCE_NOT_EXISTS(10020, ""task instance {0} does not exist"", ""任务实例[{0}]不存在""),
+    TASK_INSTANCE_NOT_SUB_WORKFLOW_INSTANCE(10021, ""task instance {0} is not sub process instance"", ""任务实例[{0}]不是子流程实例""),
+    SCHEDULE_CRON_NOT_EXISTS(10022, ""scheduler crontab {0} does not exist"", ""调度配置定时表达式[{0}]不存在""),
+    SCHEDULE_CRON_ONLINE_FORBID_UPDATE(10023, ""online status does not allow update operations"", ""调度配置上线状态不允许修改""),
+    SCHEDULE_CRON_CHECK_FAILED(10024, ""scheduler crontab expression validation failure: {0}"", ""调度配置定时表达式验证失败: {0}""),
+    MASTER_NOT_EXISTS(10025, ""master does not exist"", ""无可用master节点""),
+    SCHEDULE_STATUS_UNKNOWN(10026, ""unknown status: {0}"", ""未知状态: {0}""),
+    CREATE_ALERT_GROUP_ERROR(10027,""create alert group error"", ""创建告警组错误""),
+    QUERY_ALL_ALERTGROUP_ERROR(10028,""query all alertgroup error"", ""查询告警组错误""),
+    LIST_PAGING_ALERT_GROUP_ERROR(10029,""list paging alert group error"", ""分页查询告警组错误""),
+    UPDATE_ALERT_GROUP_ERROR(10030,""update alert group error"", ""更新告警组错误""),
+    DELETE_ALERT_GROUP_ERROR(10031,""delete alert group error"", ""删除告警组错误""),
+    ALERT_GROUP_GRANT_USER_ERROR(10032,""alert group grant user error"", ""告警组授权用户错误""),
+    CREATE_DATASOURCE_ERROR(10033,""create datasource error"", ""创建数据源错误""),
+    UPDATE_DATASOURCE_ERROR(10034,""update datasource error"", ""更新数据源错误""),
+    QUERY_DATASOURCE_ERROR(10035,""query datasource error"", ""查询数据源错误""),
+    CONNECT_DATASOURCE_FAILURE(10036,""connect datasource failure"", ""建立数据源连接失败""),
+    CONNECTION_TEST_FAILURE(10037,""connection test failure"", ""测试数据源连接失败""),
+    DELETE_DATA_SOURCE_FAILURE(10038,""delete data source failure"", ""删除数据源失败""),
+    VERIFY_DATASOURCE_NAME_FAILURE(10039,""verify datasource name failure"", ""验证数据源名称失败""),
+    UNAUTHORIZED_DATASOURCE(10040,""unauthorized datasource"", ""未经授权的数据源""),
+    AUTHORIZED_DATA_SOURCE(10041,""authorized data source"", ""授权数据源失败""),
+    LOGIN_SUCCESS(10042,""login success"", ""登录成功""),
+    USER_LOGIN_FAILURE(10043,""user login failure"", ""用户登录失败""),
+    LIST_WORKERS_ERROR(10044,""list workers error"", ""查询worker列表错误""),
+    LIST_MASTERS_ERROR(10045,""list masters error"", ""查询master列表错误""),
+    UPDATE_PROJECT_ERROR(10046,""update project error"", ""更新项目信息错误""),
+    QUERY_PROJECT_DETAILS_BY_ID_ERROR(10047,""query project details by id error"", ""查询项目详细信息错误""),
+    CREATE_PROJECT_ERROR(10048,""create project error"", ""创建项目错误""),
+    LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR(10049,""login user query project list paging error"", ""分页查询项目列表错误""),
+    DELETE_PROJECT_ERROR(10050,""delete project error"", ""删除项目错误""),
+    QUERY_UNAUTHORIZED_PROJECT_ERROR(10051,""query unauthorized project error"", ""查询未授权项目错误""),
+    QUERY_AUTHORIZED_PROJECT(10052,""query authorized project"", ""查询授权项目错误""),
+    QUERY_QUEUE_LIST_ERROR(10053,""query queue list error"", ""查询队列列表错误""),
+    CREATE_RESOURCE_ERROR(10054,""create resource error"", ""创建资源错误""),
+    UPDATE_RESOURCE_ERROR(10055,""update resource error"", ""更新资源错误""),
+    QUERY_RESOURCES_LIST_ERROR(10056,""query resources list error"", ""查询资源列表错误""),
+    QUERY_RESOURCES_LIST_PAGING(10057,""query resources list paging"", ""分页查询资源列表错误""),
+    DELETE_RESOURCE_ERROR(10058,""delete resource error"", ""删除资源错误""),
+    VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR(10059,""verify resource by name and type error"", ""资源名称或类型验证错误""),
+    VIEW_RESOURCE_FILE_ON_LINE_ERROR(10060,""view resource file online error"", ""查看资源文件错误""),
+    CREATE_RESOURCE_FILE_ON_LINE_ERROR(10061,""create resource file online error"", ""创建资源文件错误""),
+    RESOURCE_FILE_IS_EMPTY(10062,""resource file is empty"", ""资源文件内容不能为空""),
+    EDIT_RESOURCE_FILE_ON_LINE_ERROR(10063,""edit resource file online error"", ""更新资源文件错误""),
+    DOWNLOAD_RESOURCE_FILE_ERROR(10064,""download resource file error"", ""下载资源文件错误""),
+    CREATE_UDF_FUNCTION_ERROR(10065 ,""create udf function error"", ""创建UDF函数错误""),
+    VIEW_UDF_FUNCTION_ERROR( 10066,""view udf function error"", ""查询UDF函数错误""),
+    UPDATE_UDF_FUNCTION_ERROR(10067,""update udf function error"", ""更新UDF函数错误""),
+    QUERY_UDF_FUNCTION_LIST_PAGING_ERROR( 10068,""query udf function list paging error"", ""分页查询UDF函数列表错误""),
+    QUERY_DATASOURCE_BY_TYPE_ERROR( 10069,""query datasource by type error"", ""查询数据源信息错误""),
+    VERIFY_UDF_FUNCTION_NAME_ERROR( 10070,""verify udf function name error"", ""UDF函数名称验证错误""),
+    DELETE_UDF_FUNCTION_ERROR( 10071,""delete udf function error"", ""删除UDF函数错误""),
+    AUTHORIZED_FILE_RESOURCE_ERROR( 10072,""authorized file resource error"", ""授权资源文件错误""),
+    UNAUTHORIZED_FILE_RESOURCE_ERROR( 10073,""unauthorized file resource error"", ""查询未授权资源错误""),
+    UNAUTHORIZED_UDF_FUNCTION_ERROR( 10074,""unauthorized udf function error"", ""查询未授权UDF函数错误""),
+    AUTHORIZED_UDF_FUNCTION_ERROR(10075,""authorized udf function error"", ""授权UDF函数错误""),
+    CREATE_SCHEDULE_ERROR(10076,""create schedule error"", ""创建调度配置错误""),
+    UPDATE_SCHEDULE_ERROR(10077,""update schedule error"", ""更新调度配置错误""),
+    PUBLISH_SCHEDULE_ONLINE_ERROR(10078,""publish schedule online error"", ""上线调度配置错误""),
+    OFFLINE_SCHEDULE_ERROR(10079,""offline schedule error"", ""下线调度配置错误""),
+    QUERY_SCHEDULE_LIST_PAGING_ERROR(10080,""query schedule list paging error"", ""分页查询调度配置列表错误""),
+    QUERY_SCHEDULE_LIST_ERROR(10081,""query schedule list error"", ""查询调度配置列表错误""),
+    QUERY_TASK_LIST_PAGING_ERROR(10082,""query task list paging error"", ""分页查询任务列表错误""),
+    QUERY_TASK_RECORD_LIST_PAGING_ERROR(10083,""query task record list paging error"", ""分页查询任务记录错误""),
+    CREATE_TENANT_ERROR(10084,""create tenant error"", ""创建租户错误""),
+    QUERY_TENANT_LIST_PAGING_ERROR(10085,""query tenant list paging error"", ""分页查询租户列表错误""),
+    QUERY_TENANT_LIST_ERROR(10086,""query tenant list error"", ""查询租户列表错误""),
+    UPDATE_TENANT_ERROR(10087,""update tenant error"", ""更新租户错误""),
+    DELETE_TENANT_BY_ID_ERROR(10088,""delete tenant by id error"", ""删除租户错误""),
+    VERIFY_TENANT_CODE_ERROR(10089,""verify tenant code error"", ""租户编码验证错误""),
+    CREATE_USER_ERROR(10090,""create user error"", ""创建用户错误""),
+    QUERY_USER_LIST_PAGING_ERROR(10091,""query user list paging error"", ""分页查询用户列表错误""),
+    UPDATE_USER_ERROR(10092,""update user error"", ""更新用户错误""),
+    DELETE_USER_BY_ID_ERROR(10093,""delete user by id error"", ""删除用户错误""),
+    GRANT_PROJECT_ERROR(10094,""grant project error"", ""授权项目错误""),
+    GRANT_RESOURCE_ERROR(10095,""grant resource error"", ""授权资源错误""),
+    GRANT_UDF_FUNCTION_ERROR(10096,""grant udf function error"", ""授权UDF函数错误""),
+    GRANT_DATASOURCE_ERROR(10097,""grant datasource error"", ""授权数据源错误""),
+    GET_USER_INFO_ERROR(10098,""get user info error"", ""获取用户信息错误""),
+    USER_LIST_ERROR(10099,""user list error"", ""查询用户列表错误""),
+    VERIFY_USERNAME_ERROR(10100,""verify username error"", ""用户名验证错误""),
+    UNAUTHORIZED_USER_ERROR(10101,""unauthorized user error"", ""查询未授权用户错误""),
+    AUTHORIZED_USER_ERROR(10102,""authorized user error"", ""查询授权用户错误""),
+    QUERY_TASK_INSTANCE_LOG_ERROR(10103,""view task instance log error"", ""查询任务实例日志错误""),
+    DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR(10104,""download task instance log file error"", ""下载任务日志文件错误""),
+    CREATE_PROCESS_DEFINITION(10105,""create process definition"", ""创建工作流错误""),
+    VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR(10106,""verify process definition name unique error"", ""工作流名称已存在""),
+    UPDATE_PROCESS_DEFINITION_ERROR(10107,""update process definition error"", ""更新工作流定义错误""),
+    RELEASE_PROCESS_DEFINITION_ERROR(10108,""release process definition error"", ""上下线工作流错误""),
+    QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR(10109,""query datail of process definition error"", ""查询工作流详细信息错误""),
+    QUERY_PROCCESS_DEFINITION_LIST(10110,""query proccess definition list"", ""查询工作流列表错误""),
+    ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR(10111,""encapsulation treeview structure error"", ""查询工作流树形图数据错误""),
+    GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR(10112,""get tasks list by process definition id error"", ""查询工作流定义节点信息错误""),
+    QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR(10113,""query process instance list paging error"", ""分页查询工作流实例列表错误""),
+    QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR(10114,""query task list by process instance id error"", ""查询任务实例列表错误""),
+    UPDATE_PROCESS_INSTANCE_ERROR(10115,""update process instance error"", ""更新工作流实例错误""),
+    QUERY_PROCESS_INSTANCE_BY_ID_ERROR(10116,""query process instance by id error"", ""查询工作流实例错误""),
+    DELETE_PROCESS_INSTANCE_BY_ID_ERROR(10117,""delete process instance by id error"", ""删除工作流实例错误""),
+    QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR(10118,""query sub process instance detail info by task id error"", ""查询子流程任务实例错误""),
+    QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR(10119,""query parent process instance detail info by sub process instance id error"", ""查询子流程该工作流实例错误""),
+    QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR(10120,""query process instance all variables error"", ""查询工作流自定义变量信息错误""),
+    ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR(10121,""encapsulation process instance gantt structure error"", ""查询工作流实例甘特图数据错误""),
+    QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR(10122,""query proccess definition list paging error"", ""分页查询工作流定义列表错误""),
+    SIGN_OUT_ERROR(10123,""sign out error"", ""退出错误""),
+    TENANT_CODE_HAS_ALREADY_EXISTS(10124,""tenant code has already exists"", ""租户编码已存在""),
+    IP_IS_EMPTY(10125,""ip is empty"", ""IP地址不能为空""),
+    SCHEDULE_CRON_REALEASE_NEED_NOT_CHANGE(10126, ""schedule release is already {0}"", ""调度配置上下线错误[{0}]""),","[{'comment': '调度配置上线错误', 'commenter': 'Technoboy-'}]"
2035,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -16,251 +16,259 @@
  */
 package org.apache.dolphinscheduler.api.enums;
 
+import org.springframework.context.i18n.LocaleContextHolder;
+
+import java.util.Locale;
+
 /**
  *  status enum
  */
 public enum Status {
 
-    SUCCESS(0, ""success""),
+    SUCCESS(0, ""success"", ""成功""),
 
-    REQUEST_PARAMS_NOT_VALID_ERROR(10001, ""request parameter {0} is not valid""),
-    TASK_TIMEOUT_PARAMS_ERROR(10002, ""task timeout parameter is not valid""),
-    USER_NAME_EXIST(10003, ""user name already exists""),
-    USER_NAME_NULL(10004,""user name is null""),
-    HDFS_OPERATION_ERROR(10006, ""hdfs operation error""),
-    TASK_INSTANCE_NOT_FOUND(10008, ""task instance not found""),
-    TENANT_NAME_EXIST(10009, ""tenant code already exists""),
-    USER_NOT_EXIST(10010, ""user {0} not exists""),
-    ALERT_GROUP_NOT_EXIST(10011, ""alarm group not found""),
-    ALERT_GROUP_EXIST(10012, ""alarm group already exists""),
-    USER_NAME_PASSWD_ERROR(10013,""user name or password error""),
-    LOGIN_SESSION_FAILED(10014,""create session failed!""),
-    DATASOURCE_EXIST(10015, ""data source name already exists""),
-    DATASOURCE_CONNECT_FAILED(10016, ""data source connection failed""),
-    TENANT_NOT_EXIST(10017, ""tenant not exists""),
-    PROJECT_NOT_FOUNT(10018, ""project {0} not found ""),
-    PROJECT_ALREADY_EXISTS(10019, ""project {0} already exists""),
-    TASK_INSTANCE_NOT_EXISTS(10020, ""task instance {0} does not exist""),
-    TASK_INSTANCE_NOT_SUB_WORKFLOW_INSTANCE(10021, ""task instance {0} is not sub process instance""),
-    SCHEDULE_CRON_NOT_EXISTS(10022, ""scheduler crontab {0} does not exist""),
-    SCHEDULE_CRON_ONLINE_FORBID_UPDATE(10023, ""online status does not allow updateProcessInstance operations""),
-    SCHEDULE_CRON_CHECK_FAILED(10024, ""scheduler crontab expression validation failure: {0}""),
-    MASTER_NOT_EXISTS(10025, ""master does not exist""),
-    SCHEDULE_STATUS_UNKNOWN(10026, ""unknown command: {0}""),
-    CREATE_ALERT_GROUP_ERROR(10027,""create alert group error""),
-    QUERY_ALL_ALERTGROUP_ERROR(10028,""query all alertgroup error""),
-    LIST_PAGING_ALERT_GROUP_ERROR(10029,""list paging alert group error""),
-    UPDATE_ALERT_GROUP_ERROR(10030,""updateProcessInstance alert group error""),
-    DELETE_ALERT_GROUP_ERROR(10031,""delete alert group error""),
-    ALERT_GROUP_GRANT_USER_ERROR(10032,""alert group grant user error""),
-    CREATE_DATASOURCE_ERROR(10033,""create datasource error""),
-    UPDATE_DATASOURCE_ERROR(10034,""updateProcessInstance datasource error""),
-    QUERY_DATASOURCE_ERROR(10035,""query datasource error""),
-    CONNECT_DATASOURCE_FAILURE(10036,""connect datasource failure""),
-    CONNECTION_TEST_FAILURE(10037,""connection test failure""),
-    DELETE_DATA_SOURCE_FAILURE(10038,""delete data source failure""),
-    VERFIY_DATASOURCE_NAME_FAILURE(10039,""verfiy datasource name failure""),
-    UNAUTHORIZED_DATASOURCE(10040,""unauthorized datasource""),
-    AUTHORIZED_DATA_SOURCE(10041,""authorized data source""),
-    LOGIN_SUCCESS(10042,""login success""),
-    USER_LOGIN_FAILURE(10043,""user login failure""),
-    LIST_WORKERS_ERROR(10044,""list workers error""),
-    LIST_MASTERS_ERROR(10045,""list masters error""),
-    UPDATE_PROJECT_ERROR(10046,""updateProcessInstance project error""),
-    QUERY_PROJECT_DETAILS_BY_ID_ERROR(10047,""query project details by id error""),
-    CREATE_PROJECT_ERROR(10048,""create project error""),
-    LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR(10049,""login user query project list paging error""),
-    DELETE_PROJECT_ERROR(10050,""delete project error""),
-    QUERY_UNAUTHORIZED_PROJECT_ERROR(10051,""query unauthorized project error""),
-    QUERY_AUTHORIZED_PROJECT(10052,""query authorized project""),
-    QUERY_QUEUE_LIST_ERROR(10053,""query queue list error""),
-    CREATE_RESOURCE_ERROR(10054,""create resource error""),
-    UPDATE_RESOURCE_ERROR(10055,""updateProcessInstance resource error""),
-    QUERY_RESOURCES_LIST_ERROR(10056,""query resources list error""),
-    QUERY_RESOURCES_LIST_PAGING(10057,""query resources list paging""),
-    DELETE_RESOURCE_ERROR(10058,""delete resource error""),
-    VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR(10059,""verify resource by name and type error""),
-    VIEW_RESOURCE_FILE_ON_LINE_ERROR(10060,""view resource file online error""),
-    CREATE_RESOURCE_FILE_ON_LINE_ERROR(10061,""create resource file online error""),
-    RESOURCE_FILE_IS_EMPTY(10062,""resource file is empty""),
-    EDIT_RESOURCE_FILE_ON_LINE_ERROR(10063,""edit resource file online error""),
-    DOWNLOAD_RESOURCE_FILE_ERROR(10064,""download resource file error""),
-    CREATE_UDF_FUNCTION_ERROR(10065 ,""create udf function error""),
-    VIEW_UDF_FUNCTION_ERROR( 10066,""view udf function error""),
-    UPDATE_UDF_FUNCTION_ERROR(10067,""updateProcessInstance udf function error""),
-    QUERY_UDF_FUNCTION_LIST_PAGING_ERROR( 10068,""query udf function list paging error""),
-    QUERY_DATASOURCE_BY_TYPE_ERROR( 10069,""query datasource by type error""),
-    VERIFY_UDF_FUNCTION_NAME_ERROR( 10070,""verify udf function name error""),
-    DELETE_UDF_FUNCTION_ERROR( 10071,""delete udf function error""),
-    AUTHORIZED_FILE_RESOURCE_ERROR( 10072,""authorized file resource error""),
-    UNAUTHORIZED_FILE_RESOURCE_ERROR( 10073,""unauthorized file resource error""),
-    UNAUTHORIZED_UDF_FUNCTION_ERROR( 10074,""unauthorized udf function error""),
-    AUTHORIZED_UDF_FUNCTION_ERROR(10075,""authorized udf function error""),
-    CREATE_SCHEDULE_ERROR(10076,""create schedule error""),
-    UPDATE_SCHEDULE_ERROR(10077,""updateProcessInstance schedule error""),
-    PUBLISH_SCHEDULE_ONLINE_ERROR(10078,""publish schedule online error""),
-    OFFLINE_SCHEDULE_ERROR(10079,""offline schedule error""),
-    QUERY_SCHEDULE_LIST_PAGING_ERROR(10080,""query schedule list paging error""),
-    QUERY_SCHEDULE_LIST_ERROR(10081,""query schedule list error""),
-    QUERY_TASK_LIST_PAGING_ERROR(10082,""query task list paging error""),
-    QUERY_TASK_RECORD_LIST_PAGING_ERROR(10083,""query task record list paging error""),
-    CREATE_TENANT_ERROR(10084,""create tenant error""),
-    QUERY_TENANT_LIST_PAGING_ERROR(10085,""query tenant list paging error""),
-    QUERY_TENANT_LIST_ERROR(10086,""query tenant list error""),
-    UPDATE_TENANT_ERROR(10087,""updateProcessInstance tenant error""),
-    DELETE_TENANT_BY_ID_ERROR(10088,""delete tenant by id error""),
-    VERIFY_TENANT_CODE_ERROR(10089,""verify tenant code error""),
-    CREATE_USER_ERROR(10090,""create user error""),
-    QUERY_USER_LIST_PAGING_ERROR(10091,""query user list paging error""),
-    UPDATE_USER_ERROR(10092,""updateProcessInstance user error""),
-    DELETE_USER_BY_ID_ERROR(10093,""delete user by id error""),
-    GRANT_PROJECT_ERROR(10094,""grant project error""),
-    GRANT_RESOURCE_ERROR(10095,""grant resource error""),
-    GRANT_UDF_FUNCTION_ERROR(10096,""grant udf function error""),
-    GRANT_DATASOURCE_ERROR(10097,""grant datasource error""),
-    GET_USER_INFO_ERROR(10098,""get user info error""),
-    USER_LIST_ERROR(10099,""user list error""),
-    VERIFY_USERNAME_ERROR(10100,""verify username error""),
-    UNAUTHORIZED_USER_ERROR(10101,""unauthorized user error""),
-    AUTHORIZED_USER_ERROR(10102,""authorized user error""),
-    QUERY_TASK_INSTANCE_LOG_ERROR(10103,""view task instance log error""),
-    DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR(10104,""download task instance log file error""),
-    CREATE_PROCESS_DEFINITION(10105,""create process definition""),
-    VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR(10106,""verify process definition name unique error""),
-    UPDATE_PROCESS_DEFINITION_ERROR(10107,""updateProcessInstance process definition error""),
-    RELEASE_PROCESS_DEFINITION_ERROR(10108,""release process definition error""),
-    QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR(10109,""query datail of process definition error""),
-    QUERY_PROCCESS_DEFINITION_LIST(10110,""query proccess definition list""),
-    ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR(10111,""encapsulation treeview structure error""),
-    GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR(10112,""get tasks list by process definition id error""),
-    QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR(10113,""query process instance list paging error""),
-    QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR(10114,""query task list by process instance id error""),
-    UPDATE_PROCESS_INSTANCE_ERROR(10115,""updateProcessInstance process instance error""),
-    QUERY_PROCESS_INSTANCE_BY_ID_ERROR(10116,""query process instance by id error""),
-    DELETE_PROCESS_INSTANCE_BY_ID_ERROR(10117,""delete process instance by id error""),
-    QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR(10118,""query sub process instance detail info by task id error""),
-    QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR(10119,""query parent process instance detail info by sub process instance id error""),
-    QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR(10120,""query process instance all variables error""),
-    ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR(10121,""encapsulation process instance gantt structure error""),
-    QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR(10122,""query proccess definition list paging error""),
-    SIGN_OUT_ERROR(10123,""sign out error""),
-    TENANT_CODE_HAS_ALREADY_EXISTS(10124,""tenant code has already exists""),
-    IP_IS_EMPTY(10125,""ip is empty""),
-    SCHEDULE_CRON_REALEASE_NEED_NOT_CHANGE(10126, ""schedule release is already {0}""),
-    CREATE_QUEUE_ERROR(10127, ""create queue error""),
-    QUEUE_NOT_EXIST(10128, ""queue {0} not exists""),
-    QUEUE_VALUE_EXIST(10129, ""queue value {0} already exists""),
-    QUEUE_NAME_EXIST(10130, ""queue name {0} already exists""),
-    UPDATE_QUEUE_ERROR(10131, ""update queue error""),
-    NEED_NOT_UPDATE_QUEUE(10132, ""no content changes, no updates are required""),
-    VERIFY_QUEUE_ERROR(10133,""verify queue error""),
-    NAME_NULL(10134,""name must be not null""),
-    NAME_EXIST(10135, ""name {0} already exists""),
-    SAVE_ERROR(10136, ""save error""),
-    DELETE_PROJECT_ERROR_DEFINES_NOT_NULL(10137, ""please delete the process definitions in project first!""),
-    BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR(10117,""batch delete process instance by ids {0} error""),
-    PREVIEW_SCHEDULE_ERROR(10139,""preview schedule error""),
-    PARSE_TO_CRON_EXPRESSION_ERROR(10140,""parse cron to cron expression error""),
-    SCHEDULE_START_TIME_END_TIME_SAME(10141,""The start time must not be the same as the end""),
-    DELETE_TENANT_BY_ID_FAIL(100142,""delete tenant by id fail, for there are {0} process instances in executing using it""),
-    DELETE_TENANT_BY_ID_FAIL_DEFINES(100143,""delete tenant by id fail, for there are {0} process definitions using it""),
-    DELETE_TENANT_BY_ID_FAIL_USERS(100144,""delete tenant by id fail, for there are {0} users using it""),
+    REQUEST_PARAMS_NOT_VALID_ERROR(10001, ""request parameter {0} is not valid"", ""请求参数[{0}]无效""),
+    TASK_TIMEOUT_PARAMS_ERROR(10002, ""task timeout parameter is not valid"", ""任务超时参数无效""),
+    USER_NAME_EXIST(10003, ""user name already exists"", ""用户名已存在""),
+    USER_NAME_NULL(10004,""user name is null"", ""用户名不能为空""),
+    HDFS_OPERATION_ERROR(10006, ""hdfs operation error"", ""hdfs操作错误""),
+    TASK_INSTANCE_NOT_FOUND(10008, ""task instance not found"", ""任务实例不存在""),
+    TENANT_NAME_EXIST(10009, ""tenant code already exists"", ""租户编码不能为空""),
+    USER_NOT_EXIST(10010, ""user {0} not exists"", ""用户[{0}]不存在""),
+    ALERT_GROUP_NOT_EXIST(10011, ""alarm group not found"", ""告警组不存在""),
+    ALERT_GROUP_EXIST(10012, ""alarm group already exists"", ""告警组名称已存在""),
+    USER_NAME_PASSWD_ERROR(10013,""user name or password error"", ""用户名或密码错误""),
+    LOGIN_SESSION_FAILED(10014,""create session failed!"", ""创建session失败""),
+    DATASOURCE_EXIST(10015, ""data source name already exists"", ""数据源名称已存在""),
+    DATASOURCE_CONNECT_FAILED(10016, ""data source connection failed"", ""建立数据源连接失败""),
+    TENANT_NOT_EXIST(10017, ""tenant not exists"", ""租户不存在""),
+    PROJECT_NOT_FOUNT(10018, ""project {0} not found "", ""项目[{0}]不存在""),
+    PROJECT_ALREADY_EXISTS(10019, ""project {0} already exists"", ""项目名称[{0}]已存在""),
+    TASK_INSTANCE_NOT_EXISTS(10020, ""task instance {0} does not exist"", ""任务实例[{0}]不存在""),
+    TASK_INSTANCE_NOT_SUB_WORKFLOW_INSTANCE(10021, ""task instance {0} is not sub process instance"", ""任务实例[{0}]不是子流程实例""),
+    SCHEDULE_CRON_NOT_EXISTS(10022, ""scheduler crontab {0} does not exist"", ""调度配置定时表达式[{0}]不存在""),
+    SCHEDULE_CRON_ONLINE_FORBID_UPDATE(10023, ""online status does not allow update operations"", ""调度配置上线状态不允许修改""),
+    SCHEDULE_CRON_CHECK_FAILED(10024, ""scheduler crontab expression validation failure: {0}"", ""调度配置定时表达式验证失败: {0}""),
+    MASTER_NOT_EXISTS(10025, ""master does not exist"", ""无可用master节点""),
+    SCHEDULE_STATUS_UNKNOWN(10026, ""unknown status: {0}"", ""未知状态: {0}""),
+    CREATE_ALERT_GROUP_ERROR(10027,""create alert group error"", ""创建告警组错误""),
+    QUERY_ALL_ALERTGROUP_ERROR(10028,""query all alertgroup error"", ""查询告警组错误""),
+    LIST_PAGING_ALERT_GROUP_ERROR(10029,""list paging alert group error"", ""分页查询告警组错误""),
+    UPDATE_ALERT_GROUP_ERROR(10030,""update alert group error"", ""更新告警组错误""),
+    DELETE_ALERT_GROUP_ERROR(10031,""delete alert group error"", ""删除告警组错误""),
+    ALERT_GROUP_GRANT_USER_ERROR(10032,""alert group grant user error"", ""告警组授权用户错误""),
+    CREATE_DATASOURCE_ERROR(10033,""create datasource error"", ""创建数据源错误""),
+    UPDATE_DATASOURCE_ERROR(10034,""update datasource error"", ""更新数据源错误""),
+    QUERY_DATASOURCE_ERROR(10035,""query datasource error"", ""查询数据源错误""),
+    CONNECT_DATASOURCE_FAILURE(10036,""connect datasource failure"", ""建立数据源连接失败""),
+    CONNECTION_TEST_FAILURE(10037,""connection test failure"", ""测试数据源连接失败""),
+    DELETE_DATA_SOURCE_FAILURE(10038,""delete data source failure"", ""删除数据源失败""),
+    VERIFY_DATASOURCE_NAME_FAILURE(10039,""verify datasource name failure"", ""验证数据源名称失败""),
+    UNAUTHORIZED_DATASOURCE(10040,""unauthorized datasource"", ""未经授权的数据源""),
+    AUTHORIZED_DATA_SOURCE(10041,""authorized data source"", ""授权数据源失败""),
+    LOGIN_SUCCESS(10042,""login success"", ""登录成功""),
+    USER_LOGIN_FAILURE(10043,""user login failure"", ""用户登录失败""),
+    LIST_WORKERS_ERROR(10044,""list workers error"", ""查询worker列表错误""),
+    LIST_MASTERS_ERROR(10045,""list masters error"", ""查询master列表错误""),
+    UPDATE_PROJECT_ERROR(10046,""update project error"", ""更新项目信息错误""),
+    QUERY_PROJECT_DETAILS_BY_ID_ERROR(10047,""query project details by id error"", ""查询项目详细信息错误""),
+    CREATE_PROJECT_ERROR(10048,""create project error"", ""创建项目错误""),
+    LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR(10049,""login user query project list paging error"", ""分页查询项目列表错误""),
+    DELETE_PROJECT_ERROR(10050,""delete project error"", ""删除项目错误""),
+    QUERY_UNAUTHORIZED_PROJECT_ERROR(10051,""query unauthorized project error"", ""查询未授权项目错误""),
+    QUERY_AUTHORIZED_PROJECT(10052,""query authorized project"", ""查询授权项目错误""),
+    QUERY_QUEUE_LIST_ERROR(10053,""query queue list error"", ""查询队列列表错误""),
+    CREATE_RESOURCE_ERROR(10054,""create resource error"", ""创建资源错误""),
+    UPDATE_RESOURCE_ERROR(10055,""update resource error"", ""更新资源错误""),
+    QUERY_RESOURCES_LIST_ERROR(10056,""query resources list error"", ""查询资源列表错误""),
+    QUERY_RESOURCES_LIST_PAGING(10057,""query resources list paging"", ""分页查询资源列表错误""),
+    DELETE_RESOURCE_ERROR(10058,""delete resource error"", ""删除资源错误""),
+    VERIFY_RESOURCE_BY_NAME_AND_TYPE_ERROR(10059,""verify resource by name and type error"", ""资源名称或类型验证错误""),
+    VIEW_RESOURCE_FILE_ON_LINE_ERROR(10060,""view resource file online error"", ""查看资源文件错误""),
+    CREATE_RESOURCE_FILE_ON_LINE_ERROR(10061,""create resource file online error"", ""创建资源文件错误""),
+    RESOURCE_FILE_IS_EMPTY(10062,""resource file is empty"", ""资源文件内容不能为空""),
+    EDIT_RESOURCE_FILE_ON_LINE_ERROR(10063,""edit resource file online error"", ""更新资源文件错误""),
+    DOWNLOAD_RESOURCE_FILE_ERROR(10064,""download resource file error"", ""下载资源文件错误""),
+    CREATE_UDF_FUNCTION_ERROR(10065 ,""create udf function error"", ""创建UDF函数错误""),
+    VIEW_UDF_FUNCTION_ERROR( 10066,""view udf function error"", ""查询UDF函数错误""),
+    UPDATE_UDF_FUNCTION_ERROR(10067,""update udf function error"", ""更新UDF函数错误""),
+    QUERY_UDF_FUNCTION_LIST_PAGING_ERROR( 10068,""query udf function list paging error"", ""分页查询UDF函数列表错误""),
+    QUERY_DATASOURCE_BY_TYPE_ERROR( 10069,""query datasource by type error"", ""查询数据源信息错误""),
+    VERIFY_UDF_FUNCTION_NAME_ERROR( 10070,""verify udf function name error"", ""UDF函数名称验证错误""),
+    DELETE_UDF_FUNCTION_ERROR( 10071,""delete udf function error"", ""删除UDF函数错误""),
+    AUTHORIZED_FILE_RESOURCE_ERROR( 10072,""authorized file resource error"", ""授权资源文件错误""),
+    UNAUTHORIZED_FILE_RESOURCE_ERROR( 10073,""unauthorized file resource error"", ""查询未授权资源错误""),
+    UNAUTHORIZED_UDF_FUNCTION_ERROR( 10074,""unauthorized udf function error"", ""查询未授权UDF函数错误""),
+    AUTHORIZED_UDF_FUNCTION_ERROR(10075,""authorized udf function error"", ""授权UDF函数错误""),
+    CREATE_SCHEDULE_ERROR(10076,""create schedule error"", ""创建调度配置错误""),
+    UPDATE_SCHEDULE_ERROR(10077,""update schedule error"", ""更新调度配置错误""),
+    PUBLISH_SCHEDULE_ONLINE_ERROR(10078,""publish schedule online error"", ""上线调度配置错误""),
+    OFFLINE_SCHEDULE_ERROR(10079,""offline schedule error"", ""下线调度配置错误""),
+    QUERY_SCHEDULE_LIST_PAGING_ERROR(10080,""query schedule list paging error"", ""分页查询调度配置列表错误""),
+    QUERY_SCHEDULE_LIST_ERROR(10081,""query schedule list error"", ""查询调度配置列表错误""),
+    QUERY_TASK_LIST_PAGING_ERROR(10082,""query task list paging error"", ""分页查询任务列表错误""),
+    QUERY_TASK_RECORD_LIST_PAGING_ERROR(10083,""query task record list paging error"", ""分页查询任务记录错误""),
+    CREATE_TENANT_ERROR(10084,""create tenant error"", ""创建租户错误""),
+    QUERY_TENANT_LIST_PAGING_ERROR(10085,""query tenant list paging error"", ""分页查询租户列表错误""),
+    QUERY_TENANT_LIST_ERROR(10086,""query tenant list error"", ""查询租户列表错误""),
+    UPDATE_TENANT_ERROR(10087,""update tenant error"", ""更新租户错误""),
+    DELETE_TENANT_BY_ID_ERROR(10088,""delete tenant by id error"", ""删除租户错误""),
+    VERIFY_TENANT_CODE_ERROR(10089,""verify tenant code error"", ""租户编码验证错误""),
+    CREATE_USER_ERROR(10090,""create user error"", ""创建用户错误""),
+    QUERY_USER_LIST_PAGING_ERROR(10091,""query user list paging error"", ""分页查询用户列表错误""),
+    UPDATE_USER_ERROR(10092,""update user error"", ""更新用户错误""),
+    DELETE_USER_BY_ID_ERROR(10093,""delete user by id error"", ""删除用户错误""),
+    GRANT_PROJECT_ERROR(10094,""grant project error"", ""授权项目错误""),
+    GRANT_RESOURCE_ERROR(10095,""grant resource error"", ""授权资源错误""),
+    GRANT_UDF_FUNCTION_ERROR(10096,""grant udf function error"", ""授权UDF函数错误""),
+    GRANT_DATASOURCE_ERROR(10097,""grant datasource error"", ""授权数据源错误""),
+    GET_USER_INFO_ERROR(10098,""get user info error"", ""获取用户信息错误""),
+    USER_LIST_ERROR(10099,""user list error"", ""查询用户列表错误""),
+    VERIFY_USERNAME_ERROR(10100,""verify username error"", ""用户名验证错误""),
+    UNAUTHORIZED_USER_ERROR(10101,""unauthorized user error"", ""查询未授权用户错误""),
+    AUTHORIZED_USER_ERROR(10102,""authorized user error"", ""查询授权用户错误""),
+    QUERY_TASK_INSTANCE_LOG_ERROR(10103,""view task instance log error"", ""查询任务实例日志错误""),
+    DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR(10104,""download task instance log file error"", ""下载任务日志文件错误""),
+    CREATE_PROCESS_DEFINITION(10105,""create process definition"", ""创建工作流错误""),
+    VERIFY_PROCESS_DEFINITION_NAME_UNIQUE_ERROR(10106,""verify process definition name unique error"", ""工作流名称已存在""),
+    UPDATE_PROCESS_DEFINITION_ERROR(10107,""update process definition error"", ""更新工作流定义错误""),
+    RELEASE_PROCESS_DEFINITION_ERROR(10108,""release process definition error"", ""上下线工作流错误""),
+    QUERY_DATAIL_OF_PROCESS_DEFINITION_ERROR(10109,""query datail of process definition error"", ""查询工作流详细信息错误""),
+    QUERY_PROCCESS_DEFINITION_LIST(10110,""query proccess definition list"", ""查询工作流列表错误""),
+    ENCAPSULATION_TREEVIEW_STRUCTURE_ERROR(10111,""encapsulation treeview structure error"", ""查询工作流树形图数据错误""),
+    GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR(10112,""get tasks list by process definition id error"", ""查询工作流定义节点信息错误""),
+    QUERY_PROCESS_INSTANCE_LIST_PAGING_ERROR(10113,""query process instance list paging error"", ""分页查询工作流实例列表错误""),
+    QUERY_TASK_LIST_BY_PROCESS_INSTANCE_ID_ERROR(10114,""query task list by process instance id error"", ""查询任务实例列表错误""),
+    UPDATE_PROCESS_INSTANCE_ERROR(10115,""update process instance error"", ""更新工作流实例错误""),
+    QUERY_PROCESS_INSTANCE_BY_ID_ERROR(10116,""query process instance by id error"", ""查询工作流实例错误""),
+    DELETE_PROCESS_INSTANCE_BY_ID_ERROR(10117,""delete process instance by id error"", ""删除工作流实例错误""),
+    QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR(10118,""query sub process instance detail info by task id error"", ""查询子流程任务实例错误""),
+    QUERY_PARENT_PROCESS_INSTANCE_DETAIL_INFO_BY_SUB_PROCESS_INSTANCE_ID_ERROR(10119,""query parent process instance detail info by sub process instance id error"", ""查询子流程该工作流实例错误""),
+    QUERY_PROCESS_INSTANCE_ALL_VARIABLES_ERROR(10120,""query process instance all variables error"", ""查询工作流自定义变量信息错误""),
+    ENCAPSULATION_PROCESS_INSTANCE_GANTT_STRUCTURE_ERROR(10121,""encapsulation process instance gantt structure error"", ""查询工作流实例甘特图数据错误""),
+    QUERY_PROCCESS_DEFINITION_LIST_PAGING_ERROR(10122,""query proccess definition list paging error"", ""分页查询工作流定义列表错误""),
+    SIGN_OUT_ERROR(10123,""sign out error"", ""退出错误""),
+    TENANT_CODE_HAS_ALREADY_EXISTS(10124,""tenant code has already exists"", ""租户编码已存在""),
+    IP_IS_EMPTY(10125,""ip is empty"", ""IP地址不能为空""),
+    SCHEDULE_CRON_REALEASE_NEED_NOT_CHANGE(10126, ""schedule release is already {0}"", ""调度配置上下线错误[{0}]""),
+    CREATE_QUEUE_ERROR(10127, ""create queue error"", ""创建队列错误""),
+    QUEUE_NOT_EXIST(10128, ""queue {0} not exists"", ""队列ID[{0}]不存在""),
+    QUEUE_VALUE_EXIST(10129, ""queue value {0} already exists"", ""队列值[{0}]已存在""),
+    QUEUE_NAME_EXIST(10130, ""queue name {0} already exists"", ""队列名称[{0}]已存在""),
+    UPDATE_QUEUE_ERROR(10131, ""update queue error"", ""更新队列信息错误""),
+    NEED_NOT_UPDATE_QUEUE(10132, ""no content changes, no updates are required"", ""数据未变更，不需要更新队列信息""),
+    VERIFY_QUEUE_ERROR(10133,""verify queue error"", ""验证队列信息错误""),
+    NAME_NULL(10134,""name must be not null"", ""名称不能为空""),
+    NAME_EXIST(10135, ""name {0} already exists"", ""名称[{0}]已存在""),
+    SAVE_ERROR(10136, ""save error"", ""保存错误""),
+    DELETE_PROJECT_ERROR_DEFINES_NOT_NULL(10137, ""please delete the process definitions in project first!"", ""请先删除全部工作流定义""),
+    BATCH_DELETE_PROCESS_INSTANCE_BY_IDS_ERROR(10117,""batch delete process instance by ids {0} error"", ""批量删除工作流实例错误""),
+    PREVIEW_SCHEDULE_ERROR(10139,""preview schedule error"", ""预览调度配置错误""),
+    PARSE_TO_CRON_EXPRESSION_ERROR(10140,""parse cron to cron expression error"", ""解析调度表达式错误""),
+    SCHEDULE_START_TIME_END_TIME_SAME(10141,""The start time must not be the same as the end"", ""开始时间不能和结束时间一样""),
+    DELETE_TENANT_BY_ID_FAIL(100142,""delete tenant by id fail, for there are {0} process instances in executing using it"", ""删除租户失败，有[{0}]个运行中的工作流实例正在使用""),
+    DELETE_TENANT_BY_ID_FAIL_DEFINES(100143,""delete tenant by id fail, for there are {0} process definitions using it"", ""删除租户失败，有[{0}]个工作流定义正在使用""),
+    DELETE_TENANT_BY_ID_FAIL_USERS(100144,""delete tenant by id fail, for there are {0} users using it"", ""删除租户失败，有[{0}]个用户正在使用""),
 
-    DELETE_WORKER_GROUP_BY_ID_FAIL(100145,""delete worker group by id fail, for there are {0} process instances in executing using it""),
+    DELETE_WORKER_GROUP_BY_ID_FAIL(100145,""delete worker group by id fail, for there are {0} process instances in executing using it"", ""删除Worker分组失败，有[{0}]个运行中的工作流实例正在使用""),
 
-    QUERY_WORKER_GROUP_FAIL(100146,""query worker group fail ""),
-    DELETE_WORKER_GROUP_FAIL(100147,""delete worker group fail ""),
+    QUERY_WORKER_GROUP_FAIL(100146,""query worker group fail "", ""查询worker分组失败""),
+    DELETE_WORKER_GROUP_FAIL(100147,""delete worker group fail "", ""删除worker分组失败""),
 
 
-    UDF_FUNCTION_NOT_EXIST(20001, ""UDF function not found""),
-    UDF_FUNCTION_EXISTS(20002, ""UDF function already exists""),
-    RESOURCE_NOT_EXIST(20004, ""resource not exist""),
-    RESOURCE_EXIST(20005, ""resource already exists""),
-    RESOURCE_SUFFIX_NOT_SUPPORT_VIEW(20006, ""resource suffix do not support online viewing""),
-    RESOURCE_SIZE_EXCEED_LIMIT(20007, ""upload resource file size exceeds limit""),
-    RESOURCE_SUFFIX_FORBID_CHANGE(20008, ""resource suffix not allowed to be modified""),
-    UDF_RESOURCE_SUFFIX_NOT_JAR(20009, ""UDF resource suffix name must be jar""),
-    HDFS_COPY_FAIL(20009, ""hdfs copy {0} -> {1} fail""),
-    RESOURCE_FILE_EXIST(20010, ""resource file {0} already exists in hdfs,please delete it or change name!""),
-    RESOURCE_FILE_NOT_EXIST(20011, ""resource file {0} not exists in hdfs!""),
+    UDF_FUNCTION_NOT_EXIST(20001, ""UDF function not found"", ""UDF函数不存在""),
+    UDF_FUNCTION_EXISTS(20002, ""UDF function already exists"", ""UDF函数已存在""),
+    RESOURCE_NOT_EXIST(20004, ""resource not exist"", ""资源不存在""),
+    RESOURCE_EXIST(20005, ""resource already exists"", ""资源已存在""),
+    RESOURCE_SUFFIX_NOT_SUPPORT_VIEW(20006, ""resource suffix do not support online viewing"", ""资源文件后缀不支持查看""),
+    RESOURCE_SIZE_EXCEED_LIMIT(20007, ""upload resource file size exceeds limit"", ""上传资源文件大小超过限制""),
+    RESOURCE_SUFFIX_FORBID_CHANGE(20008, ""resource suffix not allowed to be modified"", ""资源文件后缀不支持修改""),
+    UDF_RESOURCE_SUFFIX_NOT_JAR(20009, ""UDF resource suffix name must be jar"", ""UDF资源文件后缀名只支持[jar]""),
+    HDFS_COPY_FAIL(20009, ""hdfs copy {0} -> {1} fail"", ""hdfs复制失败：[{0}] -> [{1}]""),
+    RESOURCE_FILE_EXIST(20010, ""resource file {0} already exists in hdfs,please delete it or change name!"", ""资源文件[{0}]在hdfs中已存在，请删除或修改资源名""),
+    RESOURCE_FILE_NOT_EXIST(20011, ""resource file {0} not exists in hdfs!"", ""资源文件[{0}]在hdfs中不存在""),
 
 
 
-    USER_NO_OPERATION_PERM(30001, ""user has no operation privilege""),
-    USER_NO_OPERATION_PROJECT_PERM(30002, ""user {0} is not has project {1} permission""),
+    USER_NO_OPERATION_PERM(30001, ""user has no operation privilege"", ""当前用户没有操作权限""),
+    USER_NO_OPERATION_PROJECT_PERM(30002, ""user {0} is not has project {1} permission"", ""当前用户[{0}]没有[{1}]项目的操作权限""),
 
 
-    PROCESS_INSTANCE_NOT_EXIST(50001, ""process instance {0} does not exist""),
-    PROCESS_INSTANCE_EXIST(50002, ""process instance {0} already exists""),
-    PROCESS_DEFINE_NOT_EXIST(50003, ""process definition {0} does not exist""),
-    PROCESS_DEFINE_NOT_RELEASE(50004, ""process definition {0} not on line""),
-    PROCESS_INSTANCE_ALREADY_CHANGED(50005, ""the status of process instance {0} is already {1}""),
-    PROCESS_INSTANCE_STATE_OPERATION_ERROR(50006, ""the status of process instance {0} is {1},Cannot perform {2} operation""),
-    SUB_PROCESS_INSTANCE_NOT_EXIST(50007, ""the task belong to process instance does not exist""),
-    PROCESS_DEFINE_NOT_ALLOWED_EDIT(50008, ""process definition {0} does not allow edit""),
-    PROCESS_INSTANCE_EXECUTING_COMMAND(50009, ""process instance {0} is executing the command, please wait ...""),
-    PROCESS_INSTANCE_NOT_SUB_PROCESS_INSTANCE(50010, ""process instance {0} is not sub process instance""),
-    TASK_INSTANCE_STATE_COUNT_ERROR(50011,""task instance state count error""),
-    COUNT_PROCESS_INSTANCE_STATE_ERROR(50012,""count process instance state error""),
-    COUNT_PROCESS_DEFINITION_USER_ERROR(50013,""count process definition user error""),
-    START_PROCESS_INSTANCE_ERROR(50014,""start process instance error""),
-    EXECUTE_PROCESS_INSTANCE_ERROR(50015,""execute process instance error""),
-    CHECK_PROCESS_DEFINITION_ERROR(50016,""check process definition error""),
-    QUERY_RECIPIENTS_AND_COPYERS_BY_PROCESS_DEFINITION_ERROR(50017,""query recipients and copyers by process definition error""),
-    DATA_IS_NOT_VALID(50017,""data %s not valid""),
-    DATA_IS_NULL(50018,""data %s is null""),
-    PROCESS_NODE_HAS_CYCLE(50019,""process node has cycle""),
-    PROCESS_NODE_S_PARAMETER_INVALID(50020,""process node %s parameter invalid""),
-    PROCESS_DEFINE_STATE_ONLINE(50021, ""process definition {0} is already on line""),
-    DELETE_PROCESS_DEFINE_BY_ID_ERROR(50022,""delete process definition by id error""),
-    SCHEDULE_CRON_STATE_ONLINE(50023,""the status of schedule {0} is already on line""),
-    DELETE_SCHEDULE_CRON_BY_ID_ERROR(50024,""delete schedule by id error""),
-    BATCH_DELETE_PROCESS_DEFINE_ERROR(50025,""batch delete process definition error""),
-    BATCH_DELETE_PROCESS_DEFINE_BY_IDS_ERROR(50026,""batch delete process definition by ids {0} error""),
-    TENANT_NOT_SUITABLE(50027,""there is not any tenant suitable, please choose a tenant available.""),
-    EXPORT_PROCESS_DEFINE_BY_ID_ERROR(50028,""export process definition by id error""),
-    IMPORT_PROCESS_DEFINE_ERROR(50029,""import process definition error""),
+    PROCESS_INSTANCE_NOT_EXIST(50001, ""process instance {0} does not exist"", ""工作流实例[{0}]不存在""),
+    PROCESS_INSTANCE_EXIST(50002, ""process instance {0} already exists"", ""工作流实例[{0}]已存在""),
+    PROCESS_DEFINE_NOT_EXIST(50003, ""process definition {0} does not exist"", ""工作流定义[{0}]不存在""),
+    PROCESS_DEFINE_NOT_RELEASE(50004, ""process definition {0} not on line"", ""工作流定义[{0}]不是上线状态""),
+    PROCESS_INSTANCE_ALREADY_CHANGED(50005, ""the status of process instance {0} is already {1}"", ""工作流实例[{0}]的状态已经是[{1}]""),
+    PROCESS_INSTANCE_STATE_OPERATION_ERROR(50006, ""the status of process instance {0} is {1},Cannot perform {2} operation"", ""工作流实例[{0}]的状态是[{1}]，无法执行[{2}]操作""),
+    SUB_PROCESS_INSTANCE_NOT_EXIST(50007, ""the task belong to process instance does not exist"", ""子工作流实例不存在""),
+    PROCESS_DEFINE_NOT_ALLOWED_EDIT(50008, ""process definition {0} does not allow edit"", ""工作流定义[{0}]不允许修改""),
+    PROCESS_INSTANCE_EXECUTING_COMMAND(50009, ""process instance {0} is executing the command, please wait ..."", ""工作流实例[{0}]正在执行命令，请稍等...""),
+    PROCESS_INSTANCE_NOT_SUB_PROCESS_INSTANCE(50010, ""process instance {0} is not sub process instance"", ""工作流实例[{0}]不是子工作流实例""),
+    TASK_INSTANCE_STATE_COUNT_ERROR(50011,""task instance state count error"", ""查询各状态任务实例数错误""),
+    COUNT_PROCESS_INSTANCE_STATE_ERROR(50012,""count process instance state error"", ""查询各状态流程实例数错误""),
+    COUNT_PROCESS_DEFINITION_USER_ERROR(50013,""count process definition user error"", ""查询各用户流程定义数错误""),
+    START_PROCESS_INSTANCE_ERROR(50014,""start process instance error"", ""运行工作流实例错误""),
+    EXECUTE_PROCESS_INSTANCE_ERROR(50015,""execute process instance error"", ""操作工作流实例错误""),
+    CHECK_PROCESS_DEFINITION_ERROR(50016,""check process definition error"", ""检查工作流实例错误""),
+    QUERY_RECIPIENTS_AND_COPYERS_BY_PROCESS_DEFINITION_ERROR(50017,""query recipients and copyers by process definition error"", ""查询收件人和抄送人错误""),
+    DATA_IS_NOT_VALID(50017,""data %s not valid"", ""数据[%s]无效""),
+    DATA_IS_NULL(50018,""data %s is null"", ""数据[%s]不能为空""),
+    PROCESS_NODE_HAS_CYCLE(50019,""process node has cycle"", ""流程节点间存在循环依赖""),
+    PROCESS_NODE_S_PARAMETER_INVALID(50020,""process node %s parameter invalid"", ""流程节点[%s]参数无效""),
+    PROCESS_DEFINE_STATE_ONLINE(50021, ""process definition {0} is already on line"", ""工作流定义[{0}]已上线""),
+    DELETE_PROCESS_DEFINE_BY_ID_ERROR(50022,""delete process definition by id error"", ""删除工作流定义错误""),
+    SCHEDULE_CRON_STATE_ONLINE(50023,""the status of schedule {0} is already on line"", ""调度配置[{0}]已上线""),
+    DELETE_SCHEDULE_CRON_BY_ID_ERROR(50024,""delete schedule by id error"", ""删除调度配置错误""),
+    BATCH_DELETE_PROCESS_DEFINE_ERROR(50025,""batch delete process definition error"", ""批量删除工作流定义错误""),
+    BATCH_DELETE_PROCESS_DEFINE_BY_IDS_ERROR(50026,""batch delete process definition by ids {0} error"", ""批量删除工作流定义[{0}]错误""),
+    TENANT_NOT_SUITABLE(50027,""there is not any tenant suitable, please choose a tenant available."", ""没有合适的租户，请选择可用的租户""),
+    EXPORT_PROCESS_DEFINE_BY_ID_ERROR(50028,""export process definition by id error"", ""导出工作流定义错误""),
+    IMPORT_PROCESS_DEFINE_ERROR(50029,""import process definition error"", ""导入工作流定义错误""),
 
-    HDFS_NOT_STARTUP(60001,""hdfs not startup""),
-    HDFS_TERANT_RESOURCES_FILE_EXISTS(60002,""resource file exists,please delete resource first""),
-    HDFS_TERANT_UDFS_FILE_EXISTS(60003,""udf file exists,please delete resource first""),
+    HDFS_NOT_STARTUP(60001,""hdfs not startup"", ""hdfs未启用""),
 
     /**
      * for monitor
      */
-    QUERY_DATABASE_STATE_ERROR(70001,""query database state error""),
-    QUERY_ZOOKEEPER_STATE_ERROR(70002,""query zookeeper state error""),
+    QUERY_DATABASE_STATE_ERROR(70001,""query database state error"", ""查询数据库状态错误""),
+    QUERY_ZOOKEEPER_STATE_ERROR(70002,""query zookeeper state error"", ""查询zookeeper状态错误""),
 
 
 
-    CREATE_ACCESS_TOKEN_ERROR(70010,""create access token error""),
-    GENERATE_TOKEN_ERROR(70011,""generate token error""),
-    QUERY_ACCESSTOKEN_LIST_PAGING_ERROR(70012,""query access token list paging error""),
-    UPDATE_ACCESS_TOKEN_ERROR(70013,""update access token error""),
-    DELETE_ACCESS_TOKEN_ERROR(70014,""delete access token error""),
-    ACCESS_TOKEN_NOT_EXIST(70015, ""access token not exist""),
+    CREATE_ACCESS_TOKEN_ERROR(70010,""create access token error"", ""创建访问token错误""),
+    GENERATE_TOKEN_ERROR(70011,""generate token error"", ""生成token错误""),
+    QUERY_ACCESSTOKEN_LIST_PAGING_ERROR(70012,""query access token list paging error"", ""分页查询访问token列表错误""),
+    UPDATE_ACCESS_TOKEN_ERROR(70013,""update access token error"", ""更新访问token错误""),
+    DELETE_ACCESS_TOKEN_ERROR(70014,""delete access token error"", ""删除访问token错误""),
+    ACCESS_TOKEN_NOT_EXIST(70015, ""access token not exist"", ""访问token不存在""),
 
 
-    COMMAND_STATE_COUNT_ERROR(80001,""task instance state count error""),
+    COMMAND_STATE_COUNT_ERROR(80001,""task instance state count error"", ""查询各状态任务实例数错误""),
 
-    QUEUE_COUNT_ERROR(90001,""queue count error""),
+    QUEUE_COUNT_ERROR(90001,""queue count error"", ""查询数据错误""),","[{'comment': '队列', 'commenter': 'Technoboy-'}]"
2113,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/process/ProcessImplForWin32.java,"@@ -33,8 +34,17 @@
 import static com.sun.jna.platform.win32.WinBase.STILL_ACTIVE;
 
 public class ProcessImplForWin32 extends Process {
-    private static final sun.misc.JavaIOFileDescriptorAccess fdAccess
-            = sun.misc.SharedSecrets.getJavaIOFileDescriptorAccess();
+
+    private static final Field FD_ACCESS;
+
+    static{
+        try {
+            FD_ACCESS = FileDescriptor.class.getDeclaredField(""fd"");
+            FD_ACCESS.setAccessible(true);
+        } catch (NoSuchFieldException e) {
+            throw new RuntimeException(e);","[{'comment': ""I'm unfamiliar with exception strategy in DolphinScheduler so it would be better our committers can check whether the exception thrown obeys conventions."", 'commenter': 'tisonkun'}]"
2113,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/process/ProcessImplForWin32.java,"@@ -46,6 +56,22 @@
 
     private static final WinNT.HANDLE JAVA_INVALID_HANDLE_VALUE = new WinNT.HANDLE(Pointer.createConstant(-1));
 
+    private static void setFd(FileDescriptor obj, long fd) {
+        try {
+            FD_ACCESS.set(obj, fd);
+        } catch (IllegalAccessException e) {
+            throw new RuntimeException(e);","[{'comment': 'ditto', 'commenter': 'tisonkun'}]"
2113,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/process/ProcessImplForWin32.java,"@@ -46,6 +56,22 @@
 
     private static final WinNT.HANDLE JAVA_INVALID_HANDLE_VALUE = new WinNT.HANDLE(Pointer.createConstant(-1));
 
+    private static void setFd(FileDescriptor obj, long fd) {
+        try {
+            FD_ACCESS.set(obj, fd);
+        } catch (IllegalAccessException e) {
+            throw new RuntimeException(e);
+        }
+    }
+
+    private static long getFd(FileDescriptor obj) {
+        try {
+            return (Long) FD_ACCESS.get(obj);
+        } catch (IllegalAccessException e) {
+            throw new RuntimeException(e);","[{'comment': 'ditto', 'commenter': 'tisonkun'}]"
2114,dolphinscheduler-service/src/test/java/org/apache/dolphinscheduler/service/process/ProcessServiceTest.java,"@@ -0,0 +1,60 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.service.process;
+
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.junit.Assert;
+import org.junit.Test;
+import org.mockito.Mockito;
+import org.powermock.api.mockito.PowerMockito;
+
+/**
+ * ProcessService Tester
+ */
+public class ProcessServiceTest {","[{'comment': 'Add the test file to the pom file to ensure that the ut will be executed', 'commenter': 'CalvinKirs'}]"
2172,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/sql/SqlTask.java,"@@ -236,6 +236,9 @@ private SqlBinds getSqlAndSqlParamsMap(String sql) {
             sqlParameters.setTitle(title);
         }
 
+        //new add,手动执行，手动补数，自动调度，历史重跑调度日期替换$[yyyy-MM-dd]","[{'comment': 'English is needed', 'commenter': 'davidzollo'}]"
2172,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ParameterUtils.java,"@@ -78,6 +78,68 @@ public static String convertParameterPlaceholders(String parameterString, Map<St
     return parameterString;
   }
 
+  /**
+   * new
+   * 新增方法替换调度时间","[{'comment': 'English is needed', 'commenter': 'davidzollo'}]"
2245,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/UserAlertGroupService.java,"@@ -0,0 +1,24 @@
+package org.apache.dolphinscheduler.api.service;","[{'comment': 'need add license', 'commenter': 'Jave-Chen'}]"
2245,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/UserAlertGroupServiceTest.java,"@@ -0,0 +1,39 @@
+package org.apache.dolphinscheduler.api.service;","[{'comment': 'need add license', 'commenter': 'Jave-Chen'}]"
2245,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/UserAlertGroupService.java,"@@ -0,0 +1,24 @@
+package org.apache.dolphinscheduler.api.service;
+
+import com.baomidou.mybatisplus.extension.service.impl.ServiceImpl;
+import org.apache.dolphinscheduler.dao.entity.UserAlertGroup;
+import org.apache.dolphinscheduler.dao.mapper.UserAlertGroupMapper;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+/**
+ * Created on 2020/3/19.
+ *
+ * @author flowkr90@gmail.com","[{'comment': 'author needs removed', 'commenter': 'Jave-Chen'}]"
2245,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/UserAlertGroupServiceTest.java,"@@ -0,0 +1,39 @@
+package org.apache.dolphinscheduler.api.service;
+
+import org.apache.dolphinscheduler.dao.mapper.UserAlertGroupMapper;
+import static org.junit.Assert.assertEquals;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.ArgumentCaptor;
+import org.mockito.InjectMocks;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+
+/**
+ * Created on 2020/3/19.
+ *
+ * @author flowkr90gmail.com","[{'comment': 'author needs removed', 'commenter': 'Jave-Chen'}]"
2677,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/CommandType.java,"@@ -66,11 +69,26 @@ public String getDescp() {
         return descp;
     }
 
-    public static CommandType of(Integer status){
-        for(CommandType cmdType : values()){
-            if(cmdType.getCode() == status){
-                return cmdType;
-            }
+    private static final Map<Integer, CommandType> COMMAND_TYPE_MAP = new HashMap<>();
+
+    static {
+        COMMAND_TYPE_MAP.put(0, START_PROCESS);
+        COMMAND_TYPE_MAP.put(1, START_CURRENT_TASK_PROCESS);
+        COMMAND_TYPE_MAP.put(2, RECOVER_TOLERANCE_FAULT_PROCESS);
+        COMMAND_TYPE_MAP.put(3, RECOVER_SUSPENDED_PROCESS);
+        COMMAND_TYPE_MAP.put(4, START_FAILURE_TASK_PROCESS);
+        COMMAND_TYPE_MAP.put(5, COMPLEMENT_DATA);
+        COMMAND_TYPE_MAP.put(6, SCHEDULER);
+        COMMAND_TYPE_MAP.put(7, REPEAT_RUNNING);
+        COMMAND_TYPE_MAP.put(8, PAUSE);
+        COMMAND_TYPE_MAP.put(9, STOP);
+        COMMAND_TYPE_MAP.put(10, RECOVER_WAITTING_THREAD);","[{'comment': 'do you have better idea? I think the map key will be easy to make wrong with the enum self ,  actually , it write twice now, these number  will be easy to wrong', 'commenter': 'davidzollo'}, {'comment': '> do you have better idea? I think the map key will be easy to make wrong with the enum self , actually , it write twice now, these number will be easy to wrong\r\n\r\nI have completed the change, please review', 'commenter': 'CalvinKirs'}]"
2872,dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/template/impl/DefaultHTMLTemplate.java,"@@ -116,9 +116,9 @@ private String getTextTypeMessage(String content,boolean showAll){
             }
 
             StringBuilder contents = new StringBuilder(100);
-            for (String str : list){
+            for (Object obj : list){","[{'comment': ""the type of 'list' variable is List<String> , why replace String with Object "", 'commenter': 'gabrywu'}, {'comment': 'JSONUtils.toList will return List< LinkedHashMap > and will Cause exception : LinkedHashMap cannot be cast to String', 'commenter': 'simon824'}]"
2872,dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java,"@@ -99,9 +99,7 @@ public static String getToken() throws IOException {
                 response.close();
             }
 
-            Map<String, Object> map = JSON.parseObject(resp,
-                    new TypeToken<Map<String, Object>>() {
-                    }.getType());
+            Map<String, Object> map = JSONUtils.parseObject(resp, Map.class);","[{'comment': 'parseObject is hard to understand ,suggest add parseMap method ,refer to the following code \r\n`TypeReference<HashMap<String, String>> typeRef \r\n  = new TypeReference<HashMap<String, String>>() {};\r\nMap<String, String> map = mapper.readValue(jsonInput, typeRef);`', 'commenter': 'gabrywu'}, {'comment': 'ok，I will fix all similar problems', 'commenter': 'simon824'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/resources/ResourceComponent.java,"@@ -1,7 +1,7 @@
 package org.apache.dolphinscheduler.api.dto.resources;
 
-import com.alibaba.fastjson.annotation.JSONField;
 import com.alibaba.fastjson.annotation.JSONType;
+import com.alibaba.fastjson.annotation.JSONField;","[{'comment': 'why still using the fastjson annotation?', 'commenter': 'gabrywu'}, {'comment': 'sorry，I missed it \r\ni will fix it later', 'commenter': 'simon824'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/DataSourceService.java,"@@ -161,15 +159,15 @@
             return result;
         }
         //check password，if the password is not updated, set to the old password.
-        JSONObject paramObject = JSON.parseObject(parameter);
-        String password = paramObject.getString(Constants.PASSWORD);
+        ObjectNode paramObject = JSONUtils.parseObject(parameter);
+        String password = paramObject.path(Constants.PASSWORD).asText();
         if (StringUtils.isBlank(password)) {
             String oldConnectionParams = dataSource.getConnectionParams();
-            JSONObject oldParams = JSON.parseObject(oldConnectionParams);
-            paramObject.put(Constants.PASSWORD, oldParams.getString(Constants.PASSWORD));
+            ObjectNode oldParams = JSONUtils.parseObject(oldConnectionParams);
+            paramObject.put(Constants.PASSWORD, oldParams.path(Constants.PASSWORD).asText());
         }
         // connectionParams json
-        String connectionParams = paramObject.toJSONString();
+        String connectionParams = JSONUtils.toJsonString(paramObject);","[{'comment': 'paramObject is ObjectNode ,why not use toString directly ?', 'commenter': 'gabrywu'}, {'comment': 'ok，I will fix all similar problems', 'commenter': 'simon824'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/DataSourceService.java,"@@ -315,9 +313,9 @@ private void handlePasswd(List<DataSource> dataSourceList) {
         for (DataSource dataSource : dataSourceList) {
 
             String connectionParams  = dataSource.getConnectionParams();
-            JSONObject  object = JSON.parseObject(connectionParams);
+            ObjectNode  object = JSONUtils.parseObject(connectionParams);
             object.put(Constants.PASSWORD, Constants.XXXXXX);
-            dataSource.setConnectionParams(JSONUtils.toJson(object));
+            dataSource.setConnectionParams(JSONUtils.toJsonString(object));","[{'comment': 'object is ObjectNode ,why not use toString directly ?', 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/DataSourceService.java,"@@ -526,8 +524,7 @@ public String buildParameter(String name, String desc, DbType type, String host,
             parameterMap.put(Constants.PRINCIPAL,principal);
         }
         if (other != null && !"""".equals(other)) {
-            LinkedHashMap<String, String> map = JSON.parseObject(other, new TypeReference<LinkedHashMap<String, String>>() {
-            });
+            LinkedHashMap<String, String> map = JSONUtils.parseObject(other, LinkedHashMap.class);","[{'comment': ""suggest use TypeReference to parse 'other' variable\r\n`TypeReference<HashMap<String, String>> typeRef \r\n  = new TypeReference<HashMap<String, String>>() {};\r\nMap<String, String> map = mapper.readValue(jsonInput, typeRef);`"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -636,7 +636,7 @@ private void downloadProcessDefinitionFile(HttpServletResponse response, List<Pr
         try {
             out = response.getOutputStream();
             buff = new BufferedOutputStream(out);
-            buff.write(JSON.toJSONString(processDefinitionList).getBytes(StandardCharsets.UTF_8));
+            buff.write(JSONUtils.toJsonString(processDefinitionList).getBytes(StandardCharsets.UTF_8));","[{'comment': ""It's better add test code into JSONUtils.toJsonString to cover the List<ProcessMeta> parameter"", 'commenter': 'gabrywu'}, {'comment': 'ok', 'commenter': 'simon824'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -756,8 +756,13 @@ private boolean checkTaskHasSubProcess(String taskType) {
     public Map<String, Object> importProcessDefinition(User loginUser, MultipartFile file, String currentProjectName) {
         Map<String, Object> result = new HashMap<>(5);
         String processMetaJson = FileUtils.file2String(file);
-        List<ProcessMeta> processMetaList = JSON.parseArray(processMetaJson, ProcessMeta.class);
+        List<ProcessMeta> processMetaList = new ArrayList<>();
 
+        try {
+            processMetaList = JSONUtils.getMapper().readValue(processMetaJson, new TypeReference<List<ProcessMeta>>() {});","[{'comment': 'why not use JSONUtils.toList', 'commenter': 'gabrywu'}, {'comment': 'toList will return List< LinkedHashMap > and will Cause  exception :\r\n "" Could not write JSON: java.util.LinkedHashMap cannot be cast to org.apache.dolphinscheduler.common.process.Property""', 'commenter': 'simon824'}]"
2872,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/JSONUtils.java,"@@ -50,23 +50,42 @@ private JSONUtils() {
         objectMapper.configure(DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true).setTimeZone(TimeZone.getDefault());
     }
 
+    public static ObjectMapper getMapper() {","[{'comment': 'getMapper,createArrayNode,createObjectNode better private ,we should not use ObjectMapper directly', 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -551,7 +562,13 @@ private void addDependResultForTaskList(List<TaskInstance> taskInstanceList) thr
             String localParams = map.get(LOCAL_PARAMS);
             if (localParams != null && !localParams.isEmpty()) {
                 localParams = ParameterUtils.convertParameterPlaceholders(localParams, timeParams);
-                List<Property> localParamsList = JSON.parseArray(localParams, Property.class);
+                List<Property> localParamsList = new ArrayList<>();
+                try {
+                    localParamsList = JSONUtils.getMapper().readValue(localParams, new TypeReference<List<Property>>() {});","[{'comment': ""don't use getMapper directly , abstract one method to deserialize List<?>"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HadoopUtils.java,"@@ -408,9 +406,8 @@ public boolean isYarnEnabled() {
      *
      * @param applicationId application id
      * @return the return may be null or there may be other parse exceptions
-     * @throws JSONException json exception
      */
-    public ExecutionStatus getApplicationStatus(String applicationId) throws JSONException {
+    public ExecutionStatus getApplicationStatus(String applicationId)  {","[{'comment': ""why remove the 'throws JSONException', I think it's better not remove"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HadoopUtils.java,"@@ -421,15 +418,15 @@ public ExecutionStatus getApplicationStatus(String applicationId) throws JSONExc
 
         String responseContent = HttpUtils.get(applicationUrl);
         if (responseContent != null) {
-            JSONObject jsonObject = JSON.parseObject(responseContent);
-            result = jsonObject.getJSONObject(""app"").getString(""finalStatus"");
+            ObjectNode jsonObject = JSONUtils.parseObject(responseContent);
+            result = jsonObject.path(""app"").path(""finalStatus"").asText();
         } else {
             //may be in job history
             String jobHistoryUrl = getJobHistoryUrl(applicationId);
             logger.info(""jobHistoryUrl={}"", jobHistoryUrl);
             responseContent = HttpUtils.get(jobHistoryUrl);
-            JSONObject jsonObject = JSONObject.parseObject(responseContent);
-            result = jsonObject.getJSONObject(""job"").getString(""state"");
+            ObjectNode jsonObject = JSONUtils.parseObject(responseContent);
+            result = jsonObject.path(""job"").path(""state"").asText();","[{'comment': 'result = jsonObject.path(""job"").path(""state"").asText() always assign a value to result ,which empty string indicating a null value . In original logic ,null value will throw NPE in the following switch. Now the result is empty string ,then getApplicationStatus method will return ExecutionStatus.RUNNING_EXEUTION. I think you\'d better optimize the switch logic. only a suggestion', 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HadoopUtils.java,"@@ -669,10 +667,10 @@ public static String getRMState(String url) {
                 return null;
             }
             //to json
-            JSONObject jsonObject = JSON.parseObject(retStr);
+            ObjectNode jsonObject = JSONUtils.parseObject(retStr);
 
             //get ResourceManager state
-            return jsonObject.getJSONObject(""clusterInfo"").getString(""haState"");
+            return jsonObject.get(""clusterInfo"").path(""haState"").asText();","[{'comment': 'jsonObject.get(""clusterInfo"") will throw NPE', 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/ProcessDefinition.java,"@@ -271,7 +279,16 @@ public String getGlobalParams() {
     }
 
     public void setGlobalParams(String globalParams) {
-        this.globalParamList = JSON.parseArray(globalParams, Property.class);
+        if (globalParams == null){
+            this.globalParamList = new ArrayList<>();
+        }else {
+            try {
+                this.globalParamList = JSONUtils.getMapper().readValue(globalParams, new TypeReference<List<Property>>() {","[{'comment': ""don't use getMapper directly"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/ProcessDefinition.java,"@@ -280,15 +297,21 @@ public void setGlobalParams(String globalParams) {
     }
 
     public void setGlobalParamList(List<Property> globalParamList) {
-        this.globalParams = JSON.toJSONString(globalParamList);
+        this.globalParams = JSONUtils.toJsonString(globalParamList);
         this.globalParamList = globalParamList;
     }
 
     public Map<String, String> getGlobalParamMap() {
-        List<Property> propList;
+        List<Property> propList = new ArrayList<> ();
 
         if (globalParamMap == null && StringUtils.isNotEmpty(globalParams)) {
-            propList = JSON.parseArray(globalParams, Property.class);
+            try {
+                propList = JSONUtils.getMapper().readValue(globalParams, new TypeReference<List<Property>>() {","[{'comment': ""don't use getMapper directly"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/TaskExecuteRequestCommand.java,"@@ -1 +1 @@
-/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.FastJsonSerializer;import java.io.Serializable;/** *  execute task request command */public class TaskExecuteRequestCommand implements Serializable {    /**     *  task execution context     */    private String taskExecutionContext;    public String getTaskExecutionContext() {        return taskExecutionContext;    }    public void setTaskExecutionContext(String taskExecutionContext) {        this.taskExecutionContext = taskExecutionContext;    }    public TaskExecuteRequestCommand() {    }    public TaskExecuteRequestCommand(String taskExecutionContext) {        this.taskExecutionContext = taskExecutionContext;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_EXECUTE_REQUEST);        byte[] body = FastJsonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskExecuteRequestCommand{"" +                ""taskExecutionContext='"" + taskExecutionContext + '\'' +                '}';    }}
\ No newline at end of file
+/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.JacksonSerializer;import java.io.Serializable;/** *  execute task request command */public class TaskExecuteRequestCommand implements Serializable {    /**     *  task execution context     */    private String taskExecutionContext;    public String getTaskExecutionContext() {        return taskExecutionContext;    }    public void setTaskExecutionContext(String taskExecutionContext) {        this.taskExecutionContext = taskExecutionContext;    }    public TaskExecuteRequestCommand() {    }    public TaskExecuteRequestCommand(String taskExecutionContext) {        this.taskExecutionContext = taskExecutionContext;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_EXECUTE_REQUEST);        byte[] body = JacksonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskExecuteRequestCommand{"" +                ""taskExecutionContext='"" + taskExecutionContext + '\'' +                '}';    }}","[{'comment': ""wow, what's format of this file!"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/TaskExecuteAckCommand.java,"@@ -1 +1 @@
-/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.FastJsonSerializer;import java.io.Serializable;import java.util.Date;/** *  execute task request command */public class TaskExecuteAckCommand implements Serializable {    /**     * taskInstanceId     */    private int taskInstanceId;    /**     * startTime     */    private Date startTime;    /**     * host     */    private String host;    /**     * status     */    private int status;    /**     * logPath     */    private String logPath;    /**     * executePath     */    private String executePath;    public Date getStartTime() {        return startTime;    }    public void setStartTime(Date startTime) {        this.startTime = startTime;    }    public String getHost() {        return host;    }    public void setHost(String host) {        this.host = host;    }    public int getStatus() {        return status;    }    public void setStatus(int status) {        this.status = status;    }    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    public String getLogPath() {        return logPath;    }    public void setLogPath(String logPath) {        this.logPath = logPath;    }    public String getExecutePath() {        return executePath;    }    public void setExecutePath(String executePath) {        this.executePath = executePath;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_EXECUTE_ACK);        byte[] body = FastJsonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskExecuteAckCommand{"" +                ""taskInstanceId="" + taskInstanceId +                "", startTime="" + startTime +                "", host='"" + host + '\'' +                "", status="" + status +                "", logPath='"" + logPath + '\'' +                "", executePath='"" + executePath + '\'' +                '}';    }}
\ No newline at end of file
+/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.JacksonSerializer;import java.io.Serializable;import java.util.Date;/** *  execute task request command */public class TaskExecuteAckCommand implements Serializable {    /**     * taskInstanceId     */    private int taskInstanceId;    /**     * startTime     */    private Date startTime;    /**     * host     */    private String host;    /**     * status     */    private int status;    /**     * logPath     */    private String logPath;    /**     * executePath     */    private String executePath;    public Date getStartTime() {        return startTime;    }    public void setStartTime(Date startTime) {        this.startTime = startTime;    }    public String getHost() {        return host;    }    public void setHost(String host) {        this.host = host;    }    public int getStatus() {        return status;    }    public void setStatus(int status) {        this.status = status;    }    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    public String getLogPath() {        return logPath;    }    public void setLogPath(String logPath) {        this.logPath = logPath;    }    public String getExecutePath() {        return executePath;    }    public void setExecutePath(String executePath) {        this.executePath = executePath;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_EXECUTE_ACK);        byte[] body = JacksonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskExecuteAckCommand{"" +                ""taskInstanceId="" + taskInstanceId +                "", startTime="" + startTime +                "", host='"" + host + '\'' +                "", status="" + status +                "", logPath='"" + logPath + '\'' +                "", executePath='"" + executePath + '\'' +                '}';    }}","[{'comment': ""wow, what's format of this file!"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/TaskExecuteResponseCommand.java,"@@ -1 +1 @@
-/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.FastJsonSerializer;import java.io.Serializable;import java.util.Date;/** *  execute task response command */public class TaskExecuteResponseCommand implements Serializable {    public TaskExecuteResponseCommand() {    }    public TaskExecuteResponseCommand(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    /**     *  task instance id     */    private int taskInstanceId;    /**     *  status     */    private int status;    /**     *  end time     */    private Date endTime;    /**     * processId     */    private int processId;    /**     * appIds     */    private String appIds;    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    public int getStatus() {        return status;    }    public void setStatus(int status) {        this.status = status;    }    public Date getEndTime() {        return endTime;    }    public void setEndTime(Date endTime) {        this.endTime = endTime;    }    public int getProcessId() {        return processId;    }    public void setProcessId(int processId) {        this.processId = processId;    }    public String getAppIds() {        return appIds;    }    public void setAppIds(String appIds) {        this.appIds = appIds;    }    /**     * package response command     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_EXECUTE_RESPONSE);        byte[] body = FastJsonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskExecuteResponseCommand{"" +                ""taskInstanceId="" + taskInstanceId +                "", status="" + status +                "", endTime="" + endTime +                "", processId="" + processId +                "", appIds='"" + appIds + '\'' +                '}';    }}
\ No newline at end of file
+/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.JacksonSerializer;import java.io.Serializable;import java.util.Date;/** *  execute task response command */public class TaskExecuteResponseCommand implements Serializable {    public TaskExecuteResponseCommand() {    }    public TaskExecuteResponseCommand(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    /**     *  task instance id     */    private int taskInstanceId;    /**     *  status     */    private int status;    /**     *  end time     */    private Date endTime;    /**     * processId     */    private int processId;    /**     * appIds     */    private String appIds;    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    public int getStatus() {        return status;    }    public void setStatus(int status) {        this.status = status;    }    public Date getEndTime() {        return endTime;    }    public void setEndTime(Date endTime) {        this.endTime = endTime;    }    public int getProcessId() {        return processId;    }    public void setProcessId(int processId) {        this.processId = processId;    }    public String getAppIds() {        return appIds;    }    public void setAppIds(String appIds) {        this.appIds = appIds;    }    /**     * package response command     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_EXECUTE_RESPONSE);        byte[] body = JacksonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskExecuteResponseCommand{"" +                ""taskInstanceId="" + taskInstanceId +                "", status="" + status +                "", endTime="" + endTime +                "", processId="" + processId +                "", appIds='"" + appIds + '\'' +                '}';    }}","[{'comment': ""wow, what's format of this file! "", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/TaskKillRequestCommand.java,"@@ -1 +1 @@
-/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.FastJsonSerializer;import java.io.Serializable;/** *  kill task request command */public class TaskKillRequestCommand implements Serializable {    /**     *  task id     */    private int taskInstanceId;    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_KILL_REQUEST);        byte[] body = FastJsonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskKillRequestCommand{"" +                ""taskInstanceId="" + taskInstanceId +                '}';    }}
\ No newline at end of file
+/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.JacksonSerializer;import java.io.Serializable;/** *  kill task request command */public class TaskKillRequestCommand implements Serializable {    /**     *  task id     */    private int taskInstanceId;    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_KILL_REQUEST);        byte[] body = JacksonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskKillRequestCommand{"" +                ""taskInstanceId="" + taskInstanceId +                '}';    }}","[{'comment': ""wow, what's format of this file!"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/TaskKillResponseCommand.java,"@@ -1 +1 @@
-/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.FastJsonSerializer;import java.io.Serializable;import java.util.Date;import java.util.List;/** *  kill task response command */public class TaskKillResponseCommand implements Serializable {    /**     * taskInstanceId     */    private int taskInstanceId;    /**     * host     */    private String host;    /**     * status     */    private int status;    /**     * processId     */    private int processId;    /**     * other resource manager appId , for example : YARN etc     */    protected List<String> appIds;    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    public String getHost() {        return host;    }    public void setHost(String host) {        this.host = host;    }    public int getStatus() {        return status;    }    public void setStatus(int status) {        this.status = status;    }    public int getProcessId() {        return processId;    }    public void setProcessId(int processId) {        this.processId = processId;    }    public List<String> getAppIds() {        return appIds;    }    public void setAppIds(List<String> appIds) {        this.appIds = appIds;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_KILL_RESPONSE);        byte[] body = FastJsonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskKillResponseCommand{"" +                ""taskInstanceId="" + taskInstanceId +                "", host='"" + host + '\'' +                "", status="" + status +                "", processId="" + processId +                "", appIds="" + appIds +                '}';    }}
\ No newline at end of file
+/* * Licensed to the Apache Software Foundation (ASF) under one or more * contributor license agreements.  See the NOTICE file distributed with * this work for additional information regarding copyright ownership. * The ASF licenses this file to You under the Apache License, Version 2.0 * (the ""License""); you may not use this file except in compliance with * the License.  You may obtain a copy of the License at * *    http://www.apache.org/licenses/LICENSE-2.0 * * Unless required by applicable law or agreed to in writing, software * distributed under the License is distributed on an ""AS IS"" BASIS, * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. * See the License for the specific language governing permissions and * limitations under the License. */package org.apache.dolphinscheduler.remote.command;import org.apache.dolphinscheduler.remote.utils.JacksonSerializer;import java.io.Serializable;import java.util.List;/** *  kill task response command */public class TaskKillResponseCommand implements Serializable {    /**     * taskInstanceId     */    private int taskInstanceId;    /**     * host     */    private String host;    /**     * status     */    private int status;    /**     * processId     */    private int processId;    /**     * other resource manager appId , for example : YARN etc     */    protected List<String> appIds;    public int getTaskInstanceId() {        return taskInstanceId;    }    public void setTaskInstanceId(int taskInstanceId) {        this.taskInstanceId = taskInstanceId;    }    public String getHost() {        return host;    }    public void setHost(String host) {        this.host = host;    }    public int getStatus() {        return status;    }    public void setStatus(int status) {        this.status = status;    }    public int getProcessId() {        return processId;    }    public void setProcessId(int processId) {        this.processId = processId;    }    public List<String> getAppIds() {        return appIds;    }    public void setAppIds(List<String> appIds) {        this.appIds = appIds;    }    /**     *  package request command     *     * @return command     */    public Command convert2Command(){        Command command = new Command();        command.setType(CommandType.TASK_KILL_RESPONSE);        byte[] body = JacksonSerializer.serialize(this);        command.setBody(body);        return command;    }    @Override    public String toString() {        return ""TaskKillResponseCommand{"" +                ""taskInstanceId="" + taskInstanceId +                "", host='"" + host + '\'' +                "", status="" + status +                "", processId="" + processId +                "", appIds="" + appIds +                '}';    }}","[{'comment': ""wow, what's format of this file!"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/log/GetLogBytesRequestCommand.java,"@@ -56,7 +56,7 @@ public void setPath(String path) {
     public Command convert2Command(){
         Command command = new Command();
         command.setType(CommandType.GET_LOG_BYTES_REQUEST);
-        byte[] body = FastJsonSerializer.serialize(this);
+        byte[] body = JacksonSerializer.serialize(this);","[{'comment': ""It's better to rename JacksonSerialize to JsonSerializer"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/log/GetLogBytesResponseCommand.java,"@@ -57,7 +57,7 @@ public void setData(byte[] data) {
     public Command convert2Command(long opaque){
         Command command = new Command(opaque);
         command.setType(CommandType.GET_LOG_BYTES_RESPONSE);
-        byte[] body = FastJsonSerializer.serialize(this);
+        byte[] body = JacksonSerializer.serialize(this);","[{'comment': ""It's better to rename JacksonSerialize to JsonSerializer"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/log/RollViewLogRequestCommand.java,"@@ -84,7 +84,7 @@ public void setLimit(int limit) {
     public Command convert2Command(){
         Command command = new Command();
         command.setType(CommandType.ROLL_VIEW_LOG_REQUEST);
-        byte[] body = FastJsonSerializer.serialize(this);
+        byte[] body = JacksonSerializer.serialize(this);","[{'comment': ""It's better to rename JacksonSerialize to JsonSerializer"", 'commenter': 'gabrywu'}]"
2872,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/log/RollViewLogResponseCommand.java,"@@ -57,7 +57,7 @@ public void setMsg(String msg) {
     public Command convert2Command(long opaque){
         Command command = new Command(opaque);
         command.setType(CommandType.ROLL_VIEW_LOG_RESPONSE);
-        byte[] body = FastJsonSerializer.serialize(this);
+        byte[] body = JacksonSerializer.serialize(this);","[{'comment': ""It's better to rename JacksonSerialize to JsonSerializer"", 'commenter': 'gabrywu'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -95,27 +95,33 @@ public Result createProcessDefinition(@ApiIgnore @RequestAttribute(value = Const
     }
 
     /**
-     * copy process definition
+     * copy or move process definition
      *
      * @param loginUser   login user
      * @param projectName project name
-     * @param processId   process definition id
+     * @param isCopy  isCopy
+     * @param processDefinitionIds   process definition ids
+     * @param targetProjectName target project name
      * @return copy result code
      */
-    @ApiOperation(value = ""copyProcessDefinition"", notes= ""COPY_PROCESS_DEFINITION_NOTES"")
+    @ApiOperation(value = ""copyOrMoveProcessDefinition"", notes= ""COPY_OR_MOVE_PROCESS_DEFINITION_NOTES"")
     @ApiImplicitParams({
-            @ApiImplicitParam(name = ""processId"", value = ""PROCESS_DEFINITION_ID"", required = true, dataType = ""Int"", example = ""100"")
+            @ApiImplicitParam(name = ""processDefinitionIds"", value = ""PROCESS_DEFINITION_IDS"", required = true, dataType = ""String"", example = ""3,4"")
     })
-    @PostMapping(value = ""/copy"")
+    @PostMapping(value = ""/copy-or-move"")
     @ResponseStatus(HttpStatus.OK)
-    @ApiException(COPY_PROCESS_DEFINITION_ERROR)
-    public Result copyProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
-                                        @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
-                                        @RequestParam(value = ""processId"", required = true) int processId) throws JsonProcessingException {
-        logger.info(""copy process definition, login user:{}, project name:{}, process definition id:{}"",
-                loginUser.getUserName(), projectName, processId);
-        Map<String, Object> result = processDefinitionService.copyProcessDefinition(loginUser, projectName, processId);
-        return returnDataList(result);
+    @ApiException(COPY_OR_MOVE_PROCESS_DEFINITION_ERROR)
+    public Result copyOrMoveProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                              @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
+                                              @RequestParam(value = ""processDefinitionIds"", required = true) String processDefinitionIds,
+                                              @RequestParam(value = ""targetProjectName"",required = true) String targetProjectName,
+                                              @RequestParam(value = ""isCopy"", required = true) boolean isCopy)  {","[{'comment': 'Please add parameters to ApiImplicitParams()', 'commenter': 'wen-hemin'}, {'comment': 'problem fixed', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -95,27 +95,33 @@ public Result createProcessDefinition(@ApiIgnore @RequestAttribute(value = Const
     }
 
     /**
-     * copy process definition
+     * copy or move process definition
      *
      * @param loginUser   login user
      * @param projectName project name
-     * @param processId   process definition id
+     * @param isCopy  isCopy
+     * @param processDefinitionIds   process definition ids
+     * @param targetProjectName target project name
      * @return copy result code
      */
-    @ApiOperation(value = ""copyProcessDefinition"", notes= ""COPY_PROCESS_DEFINITION_NOTES"")
+    @ApiOperation(value = ""copyOrMoveProcessDefinition"", notes= ""COPY_OR_MOVE_PROCESS_DEFINITION_NOTES"")
     @ApiImplicitParams({
-            @ApiImplicitParam(name = ""processId"", value = ""PROCESS_DEFINITION_ID"", required = true, dataType = ""Int"", example = ""100"")
+            @ApiImplicitParam(name = ""processDefinitionIds"", value = ""PROCESS_DEFINITION_IDS"", required = true, dataType = ""String"", example = ""3,4"")
     })
-    @PostMapping(value = ""/copy"")
+    @PostMapping(value = ""/copy-or-move"")
     @ResponseStatus(HttpStatus.OK)
-    @ApiException(COPY_PROCESS_DEFINITION_ERROR)
-    public Result copyProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
-                                        @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
-                                        @RequestParam(value = ""processId"", required = true) int processId) throws JsonProcessingException {
-        logger.info(""copy process definition, login user:{}, project name:{}, process definition id:{}"",
-                loginUser.getUserName(), projectName, processId);
-        Map<String, Object> result = processDefinitionService.copyProcessDefinition(loginUser, projectName, processId);
-        return returnDataList(result);
+    @ApiException(COPY_OR_MOVE_PROCESS_DEFINITION_ERROR)
+    public Result copyOrMoveProcessDefinition(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                              @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
+                                              @RequestParam(value = ""processDefinitionIds"", required = true) String processDefinitionIds,
+                                              @RequestParam(value = ""targetProjectName"",required = true) String targetProjectName,
+                                              @RequestParam(value = ""isCopy"", required = true) boolean isCopy)  {
+
+
+        logger.info(""batch {} process definition, login user:{}, project name:{}, process definition ids:{}，target project name:{}"",
+                isCopy?""copy"":""move"",StringUtils.replaceNRTtoUnderline(loginUser.getUserName()), StringUtils.replaceNRTtoUnderline(projectName), StringUtils.replaceNRTtoUnderline(processDefinitionIds),StringUtils.replaceNRTtoUnderline(targetProjectName));","[{'comment': 'Please add parameters to log', 'commenter': 'wen-hemin'}, {'comment': 'Parameters already exist', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -176,6 +176,10 @@
     DELETE_WORKER_GROUP_FAIL(10147,""delete worker group fail "", ""删除worker分组失败""),
     COPY_PROCESS_DEFINITION_ERROR(10148,""copy process definition error"", ""复制工作流错误""),
     USER_DISABLED(10149,""The current user is disabled"", ""当前用户已停用""),
+    QUERY_USER_CREATED_PROJECT_ERROR(10151,""query user created project error error"", ""查询用户创建的项目错误""),
+    PROCESS_DEFINITION_IDS_IS_EMPTY(10152,""process definition ids is empty"", ""工作流IDS不能为空""),
+    COPY_OR_MOVE_PROCESS_DEFINITION_ERROR(10148,""copy or move process definition error"", ""复制或者移动工作流错误""),
+    MOVE_PROCESS_DEFINITION_ERROR(10150,""move process definition error"", ""移动工作流错误""),","[{'comment': '1. 10148 repeat\r\n2. arranged in order', 'commenter': 'wen-hemin'}, {'comment': 'problem fixed', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,36 +295,188 @@ private String getResourceIds(ProcessData processData) {
 
     /**
      * copy process definition
-     *
      * @param loginUser   login user
-     * @param projectName project name
      * @param processId   process definition id
      * @return copy result code
      */","[{'comment': 'Annotate is wrong', 'commenter': 'wen-hemin'}, {'comment': 'problem fixed', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,36 +295,188 @@ private String getResourceIds(ProcessData processData) {
 
     /**
      * copy process definition
-     *
      * @param loginUser   login user
-     * @param projectName project name
      * @param processId   process definition id
      * @return copy result code
      */
-    public Map<String, Object> copyProcessDefinition(User loginUser, String projectName, Integer processId) throws JsonProcessingException {
+    private Map<String, Object> copyProcessDefinition(User loginUser,
+                                                     Integer processId,
+                                                     String targetProjectName) throws JsonProcessingException {
 
         Map<String, Object> result = new HashMap<>(5);
+
+        ProcessDefinition processDefinition = processDefineMapper.selectById(processId);
+        if (processDefinition == null) {
+            putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processId);
+            return result;
+        } else {
+            Project targetProject = projectMapper.queryByName(targetProjectName);","[{'comment': 'It is recommended to use the project ID.\r\nFuture projects will be logic delete, The project name may be duplicated.', 'commenter': 'wen-hemin'}, {'comment': 'problem fixed', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,36 +295,188 @@ private String getResourceIds(ProcessData processData) {
 
     /**
      * copy process definition
-     *
      * @param loginUser   login user
-     * @param projectName project name
      * @param processId   process definition id
      * @return copy result code
      */
-    public Map<String, Object> copyProcessDefinition(User loginUser, String projectName, Integer processId) throws JsonProcessingException {
+    private Map<String, Object> copyProcessDefinition(User loginUser,
+                                                     Integer processId,
+                                                     String targetProjectName) throws JsonProcessingException {
 
         Map<String, Object> result = new HashMap<>(5);
+
+        ProcessDefinition processDefinition = processDefineMapper.selectById(processId);
+        if (processDefinition == null) {
+            putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processId);
+            return result;
+        } else {
+            Project targetProject = projectMapper.queryByName(targetProjectName);
+            if(targetProject == null){
+                putMsg(result, Status.PROJECT_NOT_FOUNT, targetProjectName);
+                return result;
+            }else{
+                return createProcessDefinition(
+                        loginUser,
+                        targetProjectName,
+                        processDefinition.getName() + ""_copy_"" + System.currentTimeMillis(),
+                        processDefinition.getProcessDefinitionJson(),
+                        processDefinition.getDescription(),
+                        processDefinition.getLocations(),
+                        processDefinition.getConnects());
+            }
+        }
+    }
+
+    /**
+     * batch copy or move process definition
+     * @param loginUser loginUser
+     * @param projectName projectName
+     * @param processDefinitionIds processDefinitionIds
+     * @param targetProjectName targetProjectName
+     * @return
+     */
+    public Map<String, Object> batchCopyOrMoveProcessDefinition(User loginUser,
+                                                          String projectName,
+                                                          String processDefinitionIds,
+                                                          String targetProjectName, boolean isCopy){
+        Map<String, Object> result = new HashMap<>(5);
+        List<String> failedIdList = new ArrayList<>();
+
+        if (StringUtils.isEmpty(processDefinitionIds)) {
+            putMsg(result, Status.PROCESS_DEFINITION_IDS_IS_EMPTY, targetProjectName);
+            return result;
+        }
+
+        //check src project auth
+        Map<String, Object> checkResult = checkProjectAndAuth(loginUser, projectName);
+        if (checkResult != null) {
+            return checkResult;
+        }
+
+        if(!targetProjectName.equals(projectName)){
+            Map<String, Object> checkTargetProjectResult = checkProjectAndAuth(loginUser, targetProjectName);
+            if (checkTargetProjectResult != null) {
+                return checkTargetProjectResult;
+            }
+        }
+
+        String[] processDefinitionIdList = processDefinitionIds.split(Constants.COMMA);
+        if(isCopy){
+            doBatchCopyProcessDefinition(loginUser, targetProjectName, failedIdList, processDefinitionIdList);
+        }else{
+            doBatchMoveProcessDefinition(targetProjectName, failedIdList, processDefinitionIdList);
+        }
+
+        checkBatchOperateResult(result, failedIdList);
+
+        return result;
+    }
+
+    /**
+     * batch move process definition
+     * @param targetProjectName targetProjectName
+     * @param failedIdList failedIdList
+     * @param processDefinitionIdList processDefinitionIdList
+     */
+    private void doBatchMoveProcessDefinition(String targetProjectName, List<String> failedIdList, String[] processDefinitionIdList) {
+        for(String processDefinitionId:processDefinitionIdList){
+            try {
+                Map<String, Object> moveProcessDefinitionResult =
+                        moveProcessDefinition(Integer.valueOf(processDefinitionId),targetProjectName);
+                if (!Status.SUCCESS.equals(moveProcessDefinitionResult.get(Constants.STATUS))) {
+                    failedIdList.add(processDefinitionId);
+                    logger.error((String) moveProcessDefinitionResult.get(Constants.MSG));
+                }
+            } catch (Exception e) {
+                failedIdList.add(processDefinitionId);
+            }
+        }
+    }
+
+    /**
+     * batch copy process definition
+     * @param loginUser loginUser
+     * @param targetProjectName targetProjectName
+     * @param failedIdList failedIdList
+     * @param processDefinitionIdList processDefinitionIdList
+     */
+    private void doBatchCopyProcessDefinition(User loginUser, String targetProjectName, List<String> failedIdList, String[] processDefinitionIdList) {
+        for(String processDefinitionId:processDefinitionIdList){
+            try {
+                Map<String, Object> copyProcessDefinitionResult =
+                        copyProcessDefinition(loginUser,Integer.valueOf(processDefinitionId),targetProjectName);
+                if (!Status.SUCCESS.equals(copyProcessDefinitionResult.get(Constants.STATUS))) {
+                    failedIdList.add(processDefinitionId);
+                    logger.error((String) copyProcessDefinitionResult.get(Constants.MSG));
+                }
+            } catch (Exception e) {
+                failedIdList.add(processDefinitionId);
+            }
+        }
+    }
+
+    /**
+     * check project and auth
+     * @param loginUser
+     * @param projectName
+     * @return
+     */
+    private Map<String, Object> checkProjectAndAuth(User loginUser, String projectName) {
         Project project = projectMapper.queryByName(projectName);
 
+        //check user access for project
         Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
         Status resultStatus = (Status) checkResult.get(Constants.STATUS);
+
         if (resultStatus != Status.SUCCESS) {
             return checkResult;
         }
+        return null;
+    }
+
+    /**
+     * move process definition
+     * @param processId processId
+     * @param targetProjectName targetProjectName
+     * @return move result code
+     */
+    private Map<String, Object> moveProcessDefinition(Integer processId,
+                                                     String targetProjectName) {
+
+        Map<String, Object> result = new HashMap<>(5);
 
         ProcessDefinition processDefinition = processDefineMapper.selectById(processId);
         if (processDefinition == null) {
             putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processId);
             return result;
         } else {
-            return createProcessDefinition(
-                    loginUser,
-                    projectName,
-                    processDefinition.getName() + ""_copy_"" + System.currentTimeMillis(),
-                    processDefinition.getProcessDefinitionJson(),
-                    processDefinition.getDescription(),
-                    processDefinition.getLocations(),
-                    processDefinition.getConnects());
+            Project targetProject = projectMapper.queryByName(targetProjectName);
+            if(targetProject == null){
+                putMsg(result, Status.PROJECT_NOT_FOUNT, processId);
+                return result;
+            }else{
+                processDefinition.setProjectId(targetProject.getId());
+                processDefinition.setUpdateTime(new Date());
+                if (processDefineMapper.updateById(processDefinition) > 0) {
+                    putMsg(result, Status.SUCCESS);
+                } else {
+                    putMsg(result, Status.UPDATE_PROCESS_DEFINITION_ERROR);
+                }
+                return result;
+            }
+        }
+    }
+
+    /**
+     * check batch operate result
+     * @param result
+     * @param failedIdList
+     */
+    private void checkBatchOperateResult(Map<String, Object> result, List<String> failedIdList) {
+        if (!failedIdList.isEmpty()) {
+            putMsg(result, Status.MOVE_PROCESS_DEFINITION_ERROR, String.join("","", failedIdList));","[{'comment': 'It is recommended the error message return project name.', 'commenter': 'wen-hemin'}, {'comment': 'already add project name', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,38 +294,209 @@ private String getResourceIds(ProcessData processData) {
     /**
      * copy process definition
      *
-     * @param loginUser   login user
-     * @param projectName project name
-     * @param processId   process definition id
-     * @return copy result code
+     * @param loginUser loginUser
+     * @param processId processId
+     * @param targetProject targetProject
+     * @return
+     * @throws JsonProcessingException
      */
-    public Map<String, Object> copyProcessDefinition(User loginUser, String projectName, Integer processId) throws JsonProcessingException {
+    private Map<String, Object> copyProcessDefinition(User loginUser,
+                                                     Integer processId,
+                                                     Project targetProject) throws JsonProcessingException {
 
         Map<String, Object> result = new HashMap<>(5);
-        Project project = projectMapper.queryByName(projectName);
-
-        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
-        Status resultStatus = (Status) checkResult.get(Constants.STATUS);
-        if (resultStatus != Status.SUCCESS) {
-            return checkResult;
-        }
 
         ProcessDefinition processDefinition = processDefineMapper.selectById(processId);
         if (processDefinition == null) {
             putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processId);
             return result;
         } else {
+
             return createProcessDefinition(
                     loginUser,
-                    projectName,
+                    targetProject.getName(),
                     processDefinition.getName() + ""_copy_"" + System.currentTimeMillis(),
                     processDefinition.getProcessDefinitionJson(),
                     processDefinition.getDescription(),
                     processDefinition.getLocations(),
                     processDefinition.getConnects());
+
+        }
+    }
+
+    /**
+     * batch copy or move process definition
+     * @param loginUser loginUser
+     * @param projectName projectName
+     * @param processDefinitionIds processDefinitionIds
+     * @param targetProjectId targetProjectId
+     * @param isCopy isCopy
+     * @return
+     */
+    public Map<String, Object> batchCopyOrMoveProcessDefinition(User loginUser,
+                                                          String projectName,
+                                                          String processDefinitionIds,
+                                                          int targetProjectId, boolean isCopy){
+        Map<String, Object> result = new HashMap<>(5);","[{'comment': 'Hashmap does not recommend the initial value odd，No need to initialize', 'commenter': 'samz406'}, {'comment': 'The initial value of HashMap in all Controller and Service in DolphinScheduler is 5, so if you want to modify it, then it is best to unify all changes after discussion\r\n\r\n————————————————————————————————————————————\r\n在DolphinScheduler中所有的Controller和Service中HashMap的初始值都为5，所以如果要修改的话，那么最好经过讨论以后，统一全部修改', 'commenter': 'zixi0825'}, {'comment': 'This was discussed before, you can send an email and change it in a unified way\r\n这个之前讨论过，你可以发个邮件，统一改了', 'commenter': 'samz406'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,38 +294,209 @@ private String getResourceIds(ProcessData processData) {
     /**
      * copy process definition
      *
-     * @param loginUser   login user
-     * @param projectName project name
-     * @param processId   process definition id
-     * @return copy result code
+     * @param loginUser loginUser
+     * @param processId processId
+     * @param targetProject targetProject
+     * @return
+     * @throws JsonProcessingException
      */
-    public Map<String, Object> copyProcessDefinition(User loginUser, String projectName, Integer processId) throws JsonProcessingException {
+    private Map<String, Object> copyProcessDefinition(User loginUser,
+                                                     Integer processId,
+                                                     Project targetProject) throws JsonProcessingException {
 
         Map<String, Object> result = new HashMap<>(5);","[{'comment': 'Hashmap does not recommend the initial value odd，No need to initialize', 'commenter': 'samz406'}]"
2884,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionControllerTest.java,"@@ -179,16 +181,33 @@ public void testQueryProcessDefinitionById() throws Exception {
     }
 
     @Test
-    public void testCopyProcessDefinition() throws Exception {
+    public void testBatchCopyProcessDefinition() throws Exception {
 
         String projectName = ""test"";
-        int id = 1;
+        int targetProjectId = 2;
+        String id = ""1"";
+
+        Map<String, Object> result = new HashMap<>(5);","[{'comment': 'Hashmap does not recommend the initial value odd，No need to initialize', 'commenter': 'samz406'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,38 +294,209 @@ private String getResourceIds(ProcessData processData) {
     /**
      * copy process definition
      *
-     * @param loginUser   login user
-     * @param projectName project name
-     * @param processId   process definition id
-     * @return copy result code
+     * @param loginUser loginUser
+     * @param processId processId
+     * @param targetProject targetProject
+     * @return
+     * @throws JsonProcessingException
      */
-    public Map<String, Object> copyProcessDefinition(User loginUser, String projectName, Integer processId) throws JsonProcessingException {
+    private Map<String, Object> copyProcessDefinition(User loginUser,
+                                                     Integer processId,
+                                                     Project targetProject) throws JsonProcessingException {
 
         Map<String, Object> result = new HashMap<>(5);
-        Project project = projectMapper.queryByName(projectName);
-
-        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
-        Status resultStatus = (Status) checkResult.get(Constants.STATUS);
-        if (resultStatus != Status.SUCCESS) {
-            return checkResult;
-        }
 
         ProcessDefinition processDefinition = processDefineMapper.selectById(processId);
         if (processDefinition == null) {
             putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processId);
             return result;
         } else {
+
             return createProcessDefinition(
                     loginUser,
-                    projectName,
+                    targetProject.getName(),
                     processDefinition.getName() + ""_copy_"" + System.currentTimeMillis(),
                     processDefinition.getProcessDefinitionJson(),
                     processDefinition.getDescription(),
                     processDefinition.getLocations(),
                     processDefinition.getConnects());
+
+        }
+    }
+
+    /**
+     * batch copy or move process definition
+     * @param loginUser loginUser
+     * @param projectName projectName
+     * @param processDefinitionIds processDefinitionIds
+     * @param targetProjectId targetProjectId
+     * @param isCopy isCopy
+     * @return
+     */
+    public Map<String, Object> batchCopyOrMoveProcessDefinition(User loginUser,
+                                                          String projectName,
+                                                          String processDefinitionIds,
+                                                          int targetProjectId, boolean isCopy){
+        Map<String, Object> result = new HashMap<>(5);
+        List<String> failedIdList = new ArrayList<>();
+
+        if (StringUtils.isEmpty(processDefinitionIds)) {
+            putMsg(result, Status.PROCESS_DEFINITION_IDS_IS_EMPTY, processDefinitionIds);
+            return result;
+        }
+
+        //check src project auth
+        Map<String, Object> checkResult = checkProjectAndAuth(loginUser, projectName);
+        if (checkResult != null) {
+            return checkResult;
+        }
+
+        Project targetProject = projectMapper.queryDetailById(targetProjectId);
+        if(targetProject == null){
+            putMsg(result, Status.PROJECT_NOT_FOUNT, targetProjectId);
+            return result;
+        }
+
+        if(!(targetProject.getName()).equals(projectName)){
+            Map<String, Object> checkTargetProjectResult = checkProjectAndAuth(loginUser, targetProject.getName());
+            if (checkTargetProjectResult != null) {
+                return checkTargetProjectResult;
+            }
+        }
+
+        String[] processDefinitionIdList = processDefinitionIds.split(Constants.COMMA);
+        if(isCopy){
+            doBatchCopyProcessDefinition(loginUser, targetProject, failedIdList, processDefinitionIdList);
+        }else{
+            doBatchMoveProcessDefinition(targetProject, failedIdList, processDefinitionIdList);
+        }
+
+        checkBatchOperateResult(projectName,targetProject.getName(),result, failedIdList,isCopy);
+
+        return result;
+    }
+
+    /**
+     * batch move process definition
+     * @param targetProject targetProject
+     * @param failedIdList failedIdList
+     * @param processDefinitionIdList processDefinitionIdList
+     */
+    private void doBatchMoveProcessDefinition(Project targetProject, List<String> failedIdList, String[] processDefinitionIdList) {
+        for(String processDefinitionId:processDefinitionIdList){
+            try {
+                Map<String, Object> moveProcessDefinitionResult =
+                        moveProcessDefinition(Integer.valueOf(processDefinitionId),targetProject);
+                if (!Status.SUCCESS.equals(moveProcessDefinitionResult.get(Constants.STATUS))) {
+                    failedIdList.add((String) moveProcessDefinitionResult.get(Constants.MSG));
+                    logger.error((String) moveProcessDefinitionResult.get(Constants.MSG));
+                }
+            } catch (Exception e) {
+                failedIdList.add(processDefinitionId);
+            }
+        }
+    }
+
+    /**
+     * batch copy process definition
+     * @param loginUser loginUser
+     * @param targetProject targetProject
+     * @param failedIdList failedIdList
+     * @param processDefinitionIdList processDefinitionIdList
+     */
+    private void doBatchCopyProcessDefinition(User loginUser, Project targetProject, List<String> failedIdList, String[] processDefinitionIdList) {
+        for(String processDefinitionId:processDefinitionIdList){
+            try {
+                Map<String, Object> copyProcessDefinitionResult =
+                        copyProcessDefinition(loginUser,Integer.valueOf(processDefinitionId),targetProject);
+                if (!Status.SUCCESS.equals(copyProcessDefinitionResult.get(Constants.STATUS))) {
+                    failedIdList.add((String) copyProcessDefinitionResult.get(Constants.MSG));
+                    logger.error((String) copyProcessDefinitionResult.get(Constants.MSG));
+                }
+            } catch (Exception e) {
+                failedIdList.add(processDefinitionId);
+            }
+        }
+    }
+
+    /**
+     * check project and auth
+     * @param loginUser
+     * @param projectName
+     * @return
+     */
+    private Map<String, Object> checkProjectAndAuth(User loginUser, String projectName) {
+        Project project = projectMapper.queryByName(projectName);
+
+        //check user access for project
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultStatus = (Status) checkResult.get(Constants.STATUS);
+
+        if (resultStatus != Status.SUCCESS) {
+            return checkResult;
+        }
+        return null;
+    }
+
+    /**
+     * move process definition
+     * @param processId processId
+     * @param targetProject targetProject
+     * @return move result code
+     */
+    private Map<String, Object> moveProcessDefinition(Integer processId,
+                                                     Project targetProject) {
+
+        Map<String, Object> result = new HashMap<>(5);","[{'comment': 'Hashmap does not recommend the initial value odd，No need to initialize', 'commenter': 'samz406'}]"
2884,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -224,8 +226,52 @@ public void testCopyProcessDefinition()  throws Exception{
                 definition.getLocations(),
                 definition.getConnects())).thenReturn(createProcessResult);
 
-        Map<String, Object> successRes = processDefinitionService.copyProcessDefinition(loginUser,
-                ""project_test1"", 46);
+        Map<String, Object> successRes = processDefinitionService.batchCopyOrMoveProcessDefinition(loginUser,""project_test1"",
+                 ""46"",1,true);
+
+        Assert.assertEquals(Status.SUCCESS, successRes.get(Constants.STATUS));
+    }
+
+    @Test
+    public void testBatchMoveProcessDefinition()  throws Exception{
+        String projectName = ""project_test1"";
+        Mockito.when(projectMapper.queryByName(projectName)).thenReturn(getProject(projectName));
+
+        String projectName2 = ""project_test2"";
+        Mockito.when(projectMapper.queryByName(projectName2)).thenReturn(getProject(projectName2));
+
+        int targetProjectId = 2;
+        Mockito.when(projectMapper.queryDetailById(targetProjectId)).thenReturn(getProjectById(targetProjectId));
+
+        Project project = getProject(projectName);
+        Project targetProject = getProjectById(targetProjectId);
+
+        User loginUser = new User();
+        loginUser.setId(-1);
+        loginUser.setUserType(UserType.GENERAL_USER);
+
+        Map<String, Object> result = new HashMap<>(5);","[{'comment': 'Hashmap does not recommend the initial value odd，No need to initialize', 'commenter': 'samz406'}]"
2884,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionControllerTest.java,"@@ -179,16 +181,33 @@ public void testQueryProcessDefinitionById() throws Exception {
     }
 
     @Test
-    public void testCopyProcessDefinition() throws Exception {
+    public void testBatchCopyProcessDefinition() throws Exception {
 
         String projectName = ""test"";
-        int id = 1;
+        int targetProjectId = 2;
+        String id = ""1"";
+
+        Map<String, Object> result = new HashMap<>(5);
+        putMsg(result, Status.SUCCESS);
+
+        Mockito.when(processDefinitionService.batchCopyOrMoveProcessDefinition(user,projectName,id,targetProjectId,true)).thenReturn(result);
+        Result response = processDefinitionController.copyOrMoveProcessDefinition(user, projectName,id,targetProjectId,true);
+
+        Assert.assertEquals(Status.SUCCESS.getCode(),response.getCode().intValue());
+    }
+
+    @Test
+    public void testBatchMoveProcessDefinition() throws Exception {
+
+        String projectName = ""test"";
+        int targetProjectId = 2;
+        String id = ""1"";
 
         Map<String, Object> result = new HashMap<>(5);","[{'comment': 'Hashmap does not recommend the initial value odd，No need to initialize', 'commenter': 'samz406'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -295,38 +294,209 @@ private String getResourceIds(ProcessData processData) {
     /**
      * copy process definition
      *
-     * @param loginUser   login user
-     * @param projectName project name
-     * @param processId   process definition id
-     * @return copy result code
+     * @param loginUser loginUser
+     * @param processId processId
+     * @param targetProject targetProject
+     * @return
+     * @throws JsonProcessingException
      */
-    public Map<String, Object> copyProcessDefinition(User loginUser, String projectName, Integer processId) throws JsonProcessingException {
+    private Map<String, Object> copyProcessDefinition(User loginUser,
+                                                     Integer processId,
+                                                     Project targetProject) throws JsonProcessingException {
 
         Map<String, Object> result = new HashMap<>(5);
-        Project project = projectMapper.queryByName(projectName);
-
-        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
-        Status resultStatus = (Status) checkResult.get(Constants.STATUS);
-        if (resultStatus != Status.SUCCESS) {
-            return checkResult;
-        }
 
         ProcessDefinition processDefinition = processDefineMapper.selectById(processId);
         if (processDefinition == null) {
             putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, processId);
             return result;
         } else {
+
             return createProcessDefinition(
                     loginUser,
-                    projectName,
+                    targetProject.getName(),
                     processDefinition.getName() + ""_copy_"" + System.currentTimeMillis(),
                     processDefinition.getProcessDefinitionJson(),
                     processDefinition.getDescription(),
                     processDefinition.getLocations(),
                     processDefinition.getConnects());
+
+        }
+    }
+
+    /**
+     * batch copy or move process definition
+     * @param loginUser loginUser
+     * @param projectName projectName
+     * @param processDefinitionIds processDefinitionIds
+     * @param targetProjectId targetProjectId
+     * @param isCopy isCopy
+     * @return
+     */
+    public Map<String, Object> batchCopyOrMoveProcessDefinition(User loginUser,
+                                                          String projectName,
+                                                          String processDefinitionIds,
+                                                          int targetProjectId, boolean isCopy){
+        Map<String, Object> result = new HashMap<>(5);
+        List<String> failedIdList = new ArrayList<>();
+
+        if (StringUtils.isEmpty(processDefinitionIds)) {
+            putMsg(result, Status.PROCESS_DEFINITION_IDS_IS_EMPTY, processDefinitionIds);
+            return result;
+        }
+
+        //check src project auth
+        Map<String, Object> checkResult = checkProjectAndAuth(loginUser, projectName);
+        if (checkResult != null) {
+            return checkResult;
+        }
+
+        Project targetProject = projectMapper.queryDetailById(targetProjectId);
+        if(targetProject == null){
+            putMsg(result, Status.PROJECT_NOT_FOUNT, targetProjectId);
+            return result;
+        }
+
+        if(!(targetProject.getName()).equals(projectName)){
+            Map<String, Object> checkTargetProjectResult = checkProjectAndAuth(loginUser, targetProject.getName());
+            if (checkTargetProjectResult != null) {
+                return checkTargetProjectResult;
+            }
+        }
+
+        String[] processDefinitionIdList = processDefinitionIds.split(Constants.COMMA);
+        if(isCopy){
+            doBatchCopyProcessDefinition(loginUser, targetProject, failedIdList, processDefinitionIdList);
+        }else{
+            doBatchMoveProcessDefinition(targetProject, failedIdList, processDefinitionIdList);
+        }
+
+        checkBatchOperateResult(projectName,targetProject.getName(),result, failedIdList,isCopy);
+
+        return result;
+    }
+
+    /**
+     * batch move process definition
+     * @param targetProject targetProject
+     * @param failedIdList failedIdList
+     * @param processDefinitionIdList processDefinitionIdList
+     */
+    private void doBatchMoveProcessDefinition(Project targetProject, List<String> failedIdList, String[] processDefinitionIdList) {
+        for(String processDefinitionId:processDefinitionIdList){
+            try {
+                Map<String, Object> moveProcessDefinitionResult =
+                        moveProcessDefinition(Integer.valueOf(processDefinitionId),targetProject);
+                if (!Status.SUCCESS.equals(moveProcessDefinitionResult.get(Constants.STATUS))) {
+                    failedIdList.add((String) moveProcessDefinitionResult.get(Constants.MSG));
+                    logger.error((String) moveProcessDefinitionResult.get(Constants.MSG));
+                }
+            } catch (Exception e) {
+                failedIdList.add(processDefinitionId);
+            }
+        }
+    }
+
+    /**
+     * batch copy process definition
+     * @param loginUser loginUser
+     * @param targetProject targetProject
+     * @param failedIdList failedIdList
+     * @param processDefinitionIdList processDefinitionIdList
+     */
+    private void doBatchCopyProcessDefinition(User loginUser, Project targetProject, List<String> failedIdList, String[] processDefinitionIdList) {
+        for(String processDefinitionId:processDefinitionIdList){
+            try {
+                Map<String, Object> copyProcessDefinitionResult =
+                        copyProcessDefinition(loginUser,Integer.valueOf(processDefinitionId),targetProject);
+                if (!Status.SUCCESS.equals(copyProcessDefinitionResult.get(Constants.STATUS))) {
+                    failedIdList.add((String) copyProcessDefinitionResult.get(Constants.MSG));","[{'comment': 'i think failedIdList   should store the id, but there added may be a failed description statement not the id', 'commenter': 'samz406'}, {'comment': 'In my opinion, simply returning the id does not fully express the reason for the failure, I designed it to return a more complete cause of the error\r\n\r\n---------------------------------------------------------------------------------------------------------------------------------\r\n在我看来，仅仅返回id并不能完全表达失败的原因，我这么设计是为了返回更加完整的错误原因', 'commenter': 'zixi0825'}, {'comment': 'I have two questions:\r\n1 Follow your current design. There may be a splicing return. Part of the error description and part of the id situation are not clear.\r\n2 I think that the id should not be returned here, the process name should be returned, and the front end should be prompted, which of the several process errors is ok. If the id is returned, the front-end operator does not understand which process problem these id refers to\r\n\r\n我有两点疑问，\r\n1 按照你现在设计。有可能会出现拼接返回 一部分是错误描述，一部分是id情况 ,这样描述不清晰了。\r\n2 我觉得这里不应该返回id，应该返回流程名称。给前端提示，哪个几个流程错误就ok了，如果返回id，前端操作人员也不理解这些id指的是哪个流程问题。你觉得了', 'commenter': 'samz406'}, {'comment': 'I have changed it to the name of the workflow that returned the error. If the error information is returned, it cannot be ruled out that the information is incomplete\r\n\r\n我已经将其修改为返回出错的工作流名称了，返回错误描述的话确实不能排除信息不完整的情况\r\n\r\n例子：如果工作流不存在的话，返回的信息如下：\r\n从project_test1复制工作流到project_test1错误 : 47[null]', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProjectService.java,"@@ -43,7 +43,7 @@
  *HttpTask./","[{'comment': 'Modify note description', 'commenter': 'samz406'}, {'comment': 'Makes no sense, I changed it back', 'commenter': 'zixi0825'}]"
2884,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java,"@@ -226,6 +227,23 @@ public Result queryAuthorizedProject(@ApiIgnore @RequestAttribute(value = Consta
         return returnDataList(result);
     }
 
+    /**
+     * query user created project
+     *
+     * @param loginUser login user
+     * @return projects which the user create
+     */
+    @ApiOperation(value = ""queryProjectCreatedByUser"", notes = ""QUERY_USER_CREATED_PROJECT_NOTES"")
+
+    @GetMapping(value = ""/login-user-created-project"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_USER_CREATED_PROJECT_ERROR)
+    public Result queryProjectCreatedByUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {
+        logger.info(""login user {}, query authorized project by user id: {}."", StringUtils.replaceNRTtoUnderline(loginUser.getUserName()), StringUtils.replaceNRTtoUnderline(String.valueOf(loginUser.getId())));
+        Map<String, Object> result = projectService.queryProjectCreatedByUser(loginUser, loginUser.getId());","[{'comment': 'queryProjectCreatedByUser can define a parameter, you can not userid', 'commenter': 'samz406'}, {'comment': 'The purpose of this function design is to get the project created by the logged-in user, so I think there is no problem using userid\r\n\r\n————————————————————————————————————————————————————\r\n\r\n这个函数设计的目的就是获取登录用户所创建的项目，所以我认为使用userid没有问题', 'commenter': 'zixi0825'}, {'comment': 'queryProjectCreatedByUser 方法其实传loginUser 值就可以了啊。在方法里面直接loginUser.getId() 获取userid。不影响功能啊。', 'commenter': 'samz406'}, {'comment': ""You're right"", 'commenter': 'zixi0825'}]"
2920,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/CollectionUtils.java,"@@ -98,8 +98,8 @@ public static boolean isEmpty(Collection coll) {
         }
         String[] strings = str.split(separator);
         Map<String, String> map = new HashMap<>(strings.length);
-        for (int i = 0; i < strings.length; i++) {
-            String[] strArray = strings[i].split(""="");
+        for (String string : strings) {","[{'comment': 'I do not think foreach is better than fori ,especial for [] ', 'commenter': 'gabrywu'}, {'comment': '> I do not think foreach is better than fori ,especial for []\r\n\r\nWhen he doesn’t use the index, it’s not so elegant to use this form, what do you think?', 'commenter': 'CalvinKirs'}, {'comment': ""I don't think so .Using index to traverse array [] is a standard way ,right ? Why is it not elegant?\r\nforeach is better than fori when traversing List, Set, Array ,etc. "", 'commenter': 'gabrywu'}]"
2920,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/IpUtils.java,"@@ -49,12 +49,11 @@ public static String longToIp(long ipLong) {
     ipNumbers[2] = ipLong >> 8 & tmp;
     ipNumbers[3] = ipLong & tmp;
 
-    StringBuilder sb = new StringBuilder(16);
-    sb.append(ipNumbers[0]).append(DOT)
-            .append(ipNumbers[1]).append(DOT)
-            .append(ipNumbers[2]).append(DOT)
-            .append(ipNumbers[3]);
-    return sb.toString();
+    String sb = ipNumbers[0] + DOT +","[{'comment': 'why not StringBuilder?', 'commenter': 'gabrywu'}, {'comment': 'Because the use here is the same, and String performance is better in this case, the code is also more concise', 'commenter': 'CalvinKirs'}, {'comment': ""In this case ,I think it's hard to say which one is better, however you might be right."", 'commenter': 'gabrywu'}]"
2945,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/task/HttpParametersTest.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.common.task;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.dolphinscheduler.common.enums.HttpCheckCondition;
+import org.apache.dolphinscheduler.common.enums.HttpMethod;
+import org.apache.dolphinscheduler.common.process.HttpProperty;
+import org.apache.dolphinscheduler.common.process.ResourceInfo;
+import org.apache.dolphinscheduler.common.task.http.HttpParameters;
+import org.junit.Assert;
+import org.junit.Test;
+
+import com.alibaba.fastjson.JSON;
+
+/**
+ * http parameter
+ */
+public class HttpParametersTest  {
+
+
+    @Test
+    public void testGenerator(){
+        String data1 = ""{\""localParams\"":[],\""httpParams\"":[],\""url\"":\""https://www.baidu.com/\"","" +
+                ""\""httpMethod\"":\""GET\"",\""httpCheckCondition\"":\""STATUS_CODE_DEFAULT\"",\""condition\"":\""\"",\""connectTimeout\"":\""10000\"",\""socketTimeout\"":\""10000\""}"";
+        HttpParameters httpParameters = JSON.parseObject(data1, HttpParameters.class);
+
+
+        Assert.assertEquals(10000,httpParameters.getConnectTimeout() );
+        Assert.assertEquals(10000,httpParameters.getSocketTimeout());
+        Assert.assertEquals(""https://www.baidu.com/"",httpParameters.getUrl());
+        Assert.assertEquals(HttpMethod.GET,httpParameters.getHttpMethod());
+        Assert.assertEquals(HttpCheckCondition.STATUS_CODE_DEFAULT,httpParameters.getHttpCheckCondition());
+        Assert.assertEquals("""",httpParameters.getCondition());
+
+    }
+
+
+    @Test
+    public void testCheckParameters(){
+        String data1 = ""{\""localParams\"":[],\""httpParams\"":[],\""url\"":\""https://www.baidu.com/\"","" +","[{'comment': 'Use meaningful variable names， not data1, data2', 'commenter': 'Eights-Li'}]"
2945,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/task/HttpParametersTest.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.common.task;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.apache.commons.lang.StringUtils;
+import org.apache.dolphinscheduler.common.enums.HttpCheckCondition;
+import org.apache.dolphinscheduler.common.enums.HttpMethod;
+import org.apache.dolphinscheduler.common.process.HttpProperty;
+import org.apache.dolphinscheduler.common.process.ResourceInfo;
+import org.apache.dolphinscheduler.common.task.http.HttpParameters;
+import org.junit.Assert;
+import org.junit.Test;
+
+import com.alibaba.fastjson.JSON;
+
+/**
+ * http parameter
+ */
+public class HttpParametersTest  {
+
+
+    @Test
+    public void testGenerator(){
+        String data1 = ""{\""localParams\"":[],\""httpParams\"":[],\""url\"":\""https://www.baidu.com/\"","" +","[{'comment': 'Use meaningful variable names， not data1, data2', 'commenter': 'Eights-Li'}]"
2945,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/worker/task/http/HttpTaskTest.java,"@@ -0,0 +1,208 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.dolphinscheduler.server.worker.task.http;
+
+import static org.apache.dolphinscheduler.common.enums.CommandType.*;
+
+import java.io.IOException;
+import java.util.Date;
+
+import org.apache.dolphinscheduler.common.enums.HttpCheckCondition;
+import org.apache.dolphinscheduler.common.enums.HttpMethod;
+import org.apache.dolphinscheduler.common.task.http.HttpParameters;
+import org.apache.dolphinscheduler.common.utils.OSUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;
+import org.apache.dolphinscheduler.server.worker.task.ShellCommandExecutor;
+import org.apache.dolphinscheduler.server.worker.task.TaskProps;
+import org.apache.dolphinscheduler.service.bean.SpringApplicationContext;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+import org.apache.http.client.methods.CloseableHttpResponse;
+import org.apache.http.client.methods.RequestBuilder;
+import org.apache.http.impl.client.CloseableHttpClient;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mockito;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.context.ApplicationContext;
+
+import com.alibaba.fastjson.JSON;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest(OSUtils.class)
+@PowerMockIgnore({""javax.management.*"",""javax.net.ssl.*""})
+public class HttpTaskTest {
+    private static final Logger logger = LoggerFactory.getLogger(HttpTaskTest.class);
+
+
+
+    private HttpTask httpTask;
+
+    private ProcessService processService;
+
+    private ShellCommandExecutor shellCommandExecutor;
+
+    private ApplicationContext applicationContext;
+    private TaskExecutionContext taskExecutionContext;
+
+    @Before
+    public void before() throws Exception {
+        taskExecutionContext = new TaskExecutionContext();
+
+        PowerMockito.mockStatic(OSUtils.class);
+        processService = PowerMockito.mock(ProcessService.class);
+        shellCommandExecutor = PowerMockito.mock(ShellCommandExecutor.class);
+
+        applicationContext = PowerMockito.mock(ApplicationContext.class);
+        SpringApplicationContext springApplicationContext = new SpringApplicationContext();
+        springApplicationContext.setApplicationContext(applicationContext);
+        PowerMockito.when(applicationContext.getBean(ProcessService.class)).thenReturn(processService);
+
+        TaskProps props = new TaskProps();
+        props.setExecutePath(""/tmp"");
+        props.setTaskAppId(String.valueOf(System.currentTimeMillis()));
+        props.setTaskInstanceId(1);
+        props.setTenantCode(""1"");
+        props.setEnvFile("".dolphinscheduler_env.sh"");
+        props.setTaskStartTime(new Date());
+        props.setTaskTimeout(0);
+        props.setTaskParams(
+                ""{\""localParams\"":[],\""httpParams\"":[],\""url\"":\""https://github.com/\"",\""httpMethod\"":\""GET\"","" +
+                        ""\""httpCheckCondition\"":\""STATUS_CODE_DEFAULT\"",\""condition\"":\""https://github.com/\"","" +
+                        ""\""connectTimeout\"":\""1000\"",\""socketTimeout\"":\""1000\""}"");
+
+
+        taskExecutionContext = Mockito.mock(TaskExecutionContext.class);
+        Mockito.when(taskExecutionContext.getTaskParams()).thenReturn(props.getTaskParams());
+        Mockito.when(taskExecutionContext.getExecutePath()).thenReturn(""/tmp"");
+        Mockito.when(taskExecutionContext.getTaskAppId()).thenReturn(""1"");
+        Mockito.when(taskExecutionContext.getTenantCode()).thenReturn(""root"");
+        Mockito.when(taskExecutionContext.getStartTime()).thenReturn(new Date());
+        Mockito.when(taskExecutionContext.getTaskTimeout()).thenReturn(10000);
+        Mockito.when(taskExecutionContext.getLogPath()).thenReturn(""/tmp/dx"");
+
+        httpTask = new HttpTask(taskExecutionContext, logger);
+        httpTask.init();
+
+    }
+
+    @Test
+    public void testGetParameters() {
+        Assert.assertNotNull(httpTask.getParameters());
+    }
+
+
+    @Test
+    public void testCheckParameters() {
+        Assert.assertTrue(httpTask.getParameters().checkParameters());
+    }
+
+
+    @Test
+    public void testGenerator(){
+        String data1 = ""{\""localParams\"":[],\""httpParams\"":[],\""url\"":\""https://github.com/\"","" +","[{'comment': 'Use meaningful variable names， not data1, data2', 'commenter': 'Eights-Li'}]"
3169,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml,"@@ -36,7 +36,12 @@
         </foreach>
         order by id asc
     </select>
-
+    <select id=""queryTopNProcessInstanceOrderByDuration"" resultType=""org.apache.dolphinscheduler.dao.entity.ProcessInstance"">
+        select *","[{'comment': 'According to the definition of tasks, the top n here should only query tasks in succes state, and can filter according to time.', 'commenter': 'nauu'}]"
3290,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java,"@@ -204,6 +204,28 @@ public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Cons
         return returnDataList(result);
     }
 
+    @ApiOperation(value = ""queryTopNLongestRunningProcessInstance"", notes = ""QUERY_TOPN_LONGEST_RUNNING_PROCESS_INSTANCE_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""size"", value = ""PROCESS_INSTANCE_SIZE"", dataType = ""Int"", example = ""10""),
+            @ApiImplicitParam(name = ""startTime"", value = ""PROCESS_INSTANCE_START_TIME"", dataType = ""String""),
+            @ApiImplicitParam(name = ""endTime"", value = ""PROCESS_INSTANCE_END_TIME"", dataType = ""String""),
+    })
+    @GetMapping(value = ""/top-n"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_PROCESS_INSTANCE_BY_ID_ERROR)
+    public Result queryTopNLongestRunningProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                                         @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
+                                                         @RequestParam(""size"") Integer size,
+                                                         @RequestParam(value = ""startTime"",required = true) String startTime,
+                                                         @RequestParam(value = ""endTime"",required = true) String endTime
+
+    ){
+        logger.info(""query top {} SUCCESS process instance order by running time which started between startTime and endTime ,login user:{},project name:{}"",size,
+                loginUser.getUserName(),projectName);","[{'comment': ""good job, but I don't think this log is meaningful"", 'commenter': 'CalvinKirs'}, {'comment': 'can you give me some advice?It seems other method log the same way', 'commenter': 'RedemptionC'}, {'comment': 'In this case,  this kind of log does not make much sense, on the other hand, it makes our log files huge.', 'commenter': 'CalvinKirs'}, {'comment': 'could you please \r\n\r\n> In this case, this kind of log does not make much sense, on the other hand, it makes our log files huge.\r\n\r\ncould you please give me some advice on how to make the log meaningful?\r\nI have found that I should replace the starttime and endtime with params', 'commenter': 'RedemptionC'}]"
3290,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -98,6 +98,50 @@
     @Autowired
     UsersService usersService;
 
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     * @param loginUser
+     * @param projectName
+     * @param size
+     * @param startTime
+     * @param endTime
+     * @return
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser,String projectName,int size, String startTime, String endTime) {
+        Map<String, Object> result = new HashMap<>();
+
+        Project project = projectMapper.queryByName(projectName);
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        if (0 > size) {
+            putMsg(result, Status.NEGTIVE_SIZE_NUMBER_ERROR, size);
+            return result;
+        }
+        if (Objects.isNull(startTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.START_TIME);
+            return result;
+        }
+        Date start=DateUtils.stringToDate(startTime);
+        if (Objects.isNull(endTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.END_TIME);
+            return result;
+        }
+        // TODO the format really matters
+        Date end=DateUtils.stringToDate(endTime);
+        if (start.getTime() > end.getTime()) {
+            putMsg(result, Status.START_TIME_BIGGER_THAN_END_TIME_ERROR, startTime, endTime);
+            return result;
+        }","[{'comment': 'The verification should be advanced', 'commenter': 'CalvinKirs'}, {'comment': ""I don't understand...\r\nand, I wonder why some unit test cause error while I never modify them?"", 'commenter': 'RedemptionC'}, {'comment': ""> I don't understand...\r\n> and, I wonder why some unit test cause error while I never modify them?\r\n1:These parameter verification should be judged before SQL execution.\r\n2:Single test failure is not your problem, we will fix it later, if you are interested, you can also try to solve it"", 'commenter': 'CalvinKirs'}, {'comment': 'which sql ? I did put the queryTopNProcessInstance query after the params verification', 'commenter': 'RedemptionC'}]"
3291,docker/build/Dockerfile,"@@ -1,82 +1,49 @@
-#","[{'comment': 'why delete the license header?', 'commenter': 'khadgarmage'}, {'comment': 'Added back', 'commenter': 'rockxsj'}]"
3291,docker/build/hooks/build,"@@ -38,16 +38,8 @@ echo ""Repo: $DOCKER_REPO""
 
 echo -e ""Current Directory is $(pwd)\n""
 
-# maven package(Project Directory)
-echo -e ""mvn -B clean compile package -Prelease -Dmaven.test.skip=true""
-mvn -B clean compile package -Prelease -Dmaven.test.skip=true
-
-# mv dolphinscheduler-bin.tar.gz file to docker/build directory
-echo -e ""mv $(pwd)/dolphinscheduler-dist/target/apache-dolphinscheduler-incubating-${VERSION}-dolphinscheduler-bin.tar.gz $(pwd)/docker/build/\n""
-mv $(pwd)/dolphinscheduler-dist/target/apache-dolphinscheduler-incubating-${VERSION}-dolphinscheduler-bin.tar.gz $(pwd)/docker/build/
-
 # docker build
-echo -e ""docker build --build-arg VERSION=${VERSION} -t $DOCKER_REPO:${VERSION} $(pwd)/docker/build/\n""
-sudo docker build --build-arg VERSION=${VERSION} -t $DOCKER_REPO:${VERSION} $(pwd)/docker/build/
+echo -e ""docker build -f docker/build/Dockerfile -t $DOCKER_REPO:${VERSION} $(pwd)\n""","[{'comment': 'alter the path?', 'commenter': 'khadgarmage'}, {'comment': 'Because of at the builder phase, copy src should from root path.', 'commenter': 'rockxsj'}]"
3305,.github/workflows/ci_frontend.yml,"@@ -1,71 +1,71 @@
+##
+## Licensed to the Apache Software Foundation (ASF) under one or more
+## contributor license agreements.  See the NOTICE file distributed with
+## this work for additional information regarding copyright ownership.
+## The ASF licenses this file to You under the Apache License, Version 2.0
+## (the ""License""); you may not use this file except in compliance with
+## the License.  You may obtain a copy of the License at
+##
+##     http://www.apache.org/licenses/LICENSE-2.0
+##
+## Unless required by applicable law or agreed to in writing, software
+## distributed under the License is distributed on an ""AS IS"" BASIS,
+## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+## See the License for the specific language governing permissions and
+## limitations under the License.
+##
 #
-# Licensed to the Apache Software Foundation (ASF) under one or more
-# contributor license agreements.  See the NOTICE file distributed with
-# this work for additional information regarding copyright ownership.
-# The ASF licenses this file to You under the Apache License, Version 2.0
-# (the ""License""); you may not use this file except in compliance with
-# the License.  You may obtain a copy of the License at
+#name: Frontend
 #
-#     http://www.apache.org/licenses/LICENSE-2.0
+#on:
+#  push:
+#    paths:
+#      - '.github/workflows/ci_frontend.yml'
+#      - 'dolphinscheduler-ui/**'
+#  pull_request:
+#    paths:
+#      - '.github/workflows/ci_frontend.yml'
+#      - 'dolphinscheduler-ui/**'
 #
-# Unless required by applicable law or agreed to in writing, software
-# distributed under the License is distributed on an ""AS IS"" BASIS,
-# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-# See the License for the specific language governing permissions and
-# limitations under the License.
+#jobs:
+#  Compile-check:
+#    runs-on: ${{ matrix.os }}
+#    strategy:
+#      matrix:
+#        os: [ubuntu-latest, macos-latest]
+#    steps:
+#      - uses: actions/checkout@v2
+#      # In the checkout@v2, it doesn't support git submodule. Execute the commands manually.
+#      - name: checkout submodules
+#        shell: bash
+#        run: |
+#          git submodule sync --recursive
+#          git -c protocol.version=2 submodule update --init --force --recursive --depth=1
+#      - name: Set up Node.js
+#        uses: actions/setup-node@v1
+#        with:
+#          version: 8
+#      - name: Compile
+#        run: |
+#          cd dolphinscheduler-ui
+#          npm install node-sass --unsafe-perm
+#          npm install
+#          npm run lint
+#          npm run build
 #
-
-name: Frontend
-
-on:
-  push:
-    paths:
-      - '.github/workflows/ci_frontend.yml'
-      - 'dolphinscheduler-ui/**'
-  pull_request:
-    paths:
-      - '.github/workflows/ci_frontend.yml'
-      - 'dolphinscheduler-ui/**'
-
-jobs:
-  Compile-check:
-    runs-on: ${{ matrix.os }}
-    strategy:
-      matrix:
-        os: [ubuntu-latest, macos-latest]
-    steps:
-      - uses: actions/checkout@v2
-      # In the checkout@v2, it doesn't support git submodule. Execute the commands manually.
-      - name: checkout submodules
-        shell: bash
-        run: |
-          git submodule sync --recursive
-          git -c protocol.version=2 submodule update --init --force --recursive --depth=1
-      - name: Set up Node.js
-        uses: actions/setup-node@v1
-        with:
-          version: 8
-      - name: Compile
-        run: |
-          cd dolphinscheduler-ui
-          npm install node-sass --unsafe-perm
-          npm install
-          npm run lint
-          npm run build
-
-  License-check:
-    runs-on: ubuntu-latest
-    steps:
-      - uses: actions/checkout@v2
-      # In the checkout@v2, it doesn't support git submodule. Execute the commands manually.
-      - name: checkout submodules
-        shell: bash
-        run: |
-          git submodule sync --recursive
-          git -c protocol.version=2 submodule update --init --force --recursive --depth=1
-      - name: Set up JDK 1.8
-        uses: actions/setup-java@v1
-        with:
-          java-version: 1.8
-      - name: Check
-        run: mvn -B apache-rat:check
+#  License-check:
+#    runs-on: ubuntu-latest
+#    steps:
+#      - uses: actions/checkout@v2
+#      # In the checkout@v2, it doesn't support git submodule. Execute the commands manually.
+#      - name: checkout submodules
+#        shell: bash
+#        run: |
+#          git submodule sync --recursive
+#          git -c protocol.version=2 submodule update --init --force --recursive --depth=1
+#      - name: Set up JDK 1.8
+#        uses: actions/setup-java@v1
+#        with:
+#          java-version: 1.8
+#      - name: Check
+#        run: mvn -B apache-rat:check","[{'comment': 'During the project incubation stage, it is not recommended to remove the license check', 'commenter': 'CalvinKirs'}, {'comment': 'I just want to test ut ci, so I removed the other ci for more quickly result, I will add it back when I finished the test.', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java,"@@ -204,6 +205,29 @@ public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Cons
         return returnDataList(result);
     }
 
+    @ApiOperation(value = ""queryTopNLongestRunningProcessInstance"", notes = ""QUERY_TOPN_LONGEST_RUNNING_PROCESS_INSTANCE_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""size"", value = ""PROCESS_INSTANCE_SIZE"", dataType = ""Int"", example = ""10""),
+            @ApiImplicitParam(name = ""startTime"", value = ""PROCESS_INSTANCE_START_TIME"", dataType = ""String""),
+            @ApiImplicitParam(name = ""endTime"", value = ""PROCESS_INSTANCE_END_TIME"", dataType = ""String""),
+    })
+    @GetMapping(value = ""/top-n"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_PROCESS_INSTANCE_BY_ID_ERROR)
+    public Result<ProcessInstance> queryTopNLongestRunningProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                                         @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
+                                                         @RequestParam(""size"") Integer size,
+                                                         @RequestParam(value = ""startTime"",required = true) String startTime,
+                                                         @RequestParam(value = ""endTime"",required = true) String endTime
+
+    ){
+        projectName=projectName.replaceAll(""[\n|\r\t]"", ""_"");","[{'comment': 'You should improve the handleEscapes method, this is a historical problem.  like this:return inputString.replace(""%"", ""////%"").replaceAll(""[\\n|\\r|\\t]"", ""_"");', 'commenter': 'CalvinKirs'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java,"@@ -204,6 +205,29 @@ public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Cons
         return returnDataList(result);
     }
 
+    @ApiOperation(value = ""queryTopNLongestRunningProcessInstance"", notes = ""QUERY_TOPN_LONGEST_RUNNING_PROCESS_INSTANCE_NOTES"")","[{'comment': 'Hi,\r\nIt will be better to add the java docs like[1] here. can you do it?\r\n[1] ![image](https://user-images.githubusercontent.com/29545877/88796597-8140c900-d1d4-11ea-87a6-3d115faafa69.png)\r\n', 'commenter': 'yangyichao-mango'}, {'comment': 'ok , I will do it in next commit ', 'commenter': 'RedemptionC'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -98,6 +98,53 @@
     @Autowired
     UsersService usersService;
 
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     * @param loginUser
+     * @param projectName
+     * @param size
+     * @param startTime
+     * @param endTime
+     * @return
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser,String projectName,int size, String startTime, String endTime) {
+        Map<String, Object> result = new HashMap<>();
+
+        Project project = projectMapper.queryByName(projectName);
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        if (0 > size) {
+            putMsg(result, Status.NEGTIVE_SIZE_NUMBER_ERROR, size);
+            return result;
+        }
+        if (Objects.isNull(startTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.START_TIME);
+            return result;
+        }
+        Date start=DateUtils.stringToDate(startTime);
+        if (Objects.isNull(endTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.END_TIME);
+            return result;
+        }
+        Date end=DateUtils.stringToDate(endTime);","[{'comment': '```suggestion\r\n        Date end = DateUtils.stringToDate(endTime);\r\n```', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -98,6 +98,53 @@
     @Autowired
     UsersService usersService;
 
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     * @param loginUser
+     * @param projectName
+     * @param size
+     * @param startTime
+     * @param endTime
+     * @return
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser,String projectName,int size, String startTime, String endTime) {
+        Map<String, Object> result = new HashMap<>();
+
+        Project project = projectMapper.queryByName(projectName);
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        if (0 > size) {
+            putMsg(result, Status.NEGTIVE_SIZE_NUMBER_ERROR, size);
+            return result;
+        }
+        if (Objects.isNull(startTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.START_TIME);
+            return result;
+        }
+        Date start=DateUtils.stringToDate(startTime);","[{'comment': '```suggestion\r\n        Date start = DateUtils.stringToDate(startTime);\r\n```', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -98,6 +98,53 @@
     @Autowired
     UsersService usersService;
 
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     * @param loginUser
+     * @param projectName
+     * @param size
+     * @param startTime
+     * @param endTime
+     * @return
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser,String projectName,int size, String startTime, String endTime) {","[{'comment': '```suggestion\r\n    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser, String projectName, int size, String startTime, String endTime) {\r\n```', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -978,6 +978,8 @@ private Constants() {
     public static final int NORAML_NODE_STATUS = 0;
     public static final int ABNORMAL_NODE_STATUS = 1;
 
+    public static final String START_TIME=""start time"";
+    public static final String END_TIME=""end time"";","[{'comment': '```suggestion\r\n    public static final String START_TIME = ""start time"";\r\n    public static final String END_TIME = ""end time"";\r\n```', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessInstanceServiceTest.java,"@@ -147,6 +147,40 @@ public void testQueryProcessInstanceList() {
 
     }
 
+    @Test
+    public void testQueryTopNLongestRunningProcessInstance(){","[{'comment': '```suggestion\r\n    public void testQueryTopNLongestRunningProcessInstance() {\r\n```', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -98,6 +98,53 @@
     @Autowired
     UsersService usersService;
 
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     * @param loginUser
+     * @param projectName
+     * @param size
+     * @param startTime
+     * @param endTime
+     * @return
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser,String projectName,int size, String startTime, String endTime) {
+        Map<String, Object> result = new HashMap<>();
+
+        Project project = projectMapper.queryByName(projectName);
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        if (0 > size) {
+            putMsg(result, Status.NEGTIVE_SIZE_NUMBER_ERROR, size);
+            return result;
+        }
+        if (Objects.isNull(startTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.START_TIME);
+            return result;
+        }
+        Date start=DateUtils.stringToDate(startTime);
+        if (Objects.isNull(endTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.END_TIME);
+            return result;
+        }
+        Date end=DateUtils.stringToDate(endTime);
+        if(start == null || end == null){","[{'comment': '```suggestion\r\n        if(start == null || end == null) {\r\n```', 'commenter': 'yangyichao-mango'}]"
3315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java,"@@ -204,6 +205,29 @@ public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Cons
         return returnDataList(result);
     }
 
+    @ApiOperation(value = ""queryTopNLongestRunningProcessInstance"", notes = ""QUERY_TOPN_LONGEST_RUNNING_PROCESS_INSTANCE_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""size"", value = ""PROCESS_INSTANCE_SIZE"", dataType = ""Int"", example = ""10""),
+            @ApiImplicitParam(name = ""startTime"", value = ""PROCESS_INSTANCE_START_TIME"", dataType = ""String""),
+            @ApiImplicitParam(name = ""endTime"", value = ""PROCESS_INSTANCE_END_TIME"", dataType = ""String""),
+    })
+    @GetMapping(value = ""/top-n"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_PROCESS_INSTANCE_BY_ID_ERROR)
+    public Result<ProcessInstance> queryTopNLongestRunningProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                                         @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
+                                                         @RequestParam(""size"") Integer size,
+                                                         @RequestParam(value = ""startTime"",required = true) String startTime,
+                                                         @RequestParam(value = ""endTime"",required = true) String endTime
+
+    ){","[{'comment': '```suggestion\r\n    ) {\r\n```', 'commenter': 'yangyichao-mango'}]"
3322,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/zk/ZookeeperCachedOperator.java,"@@ -83,6 +83,7 @@ public void close() {
         try {
             Thread.sleep(500);
         } catch (InterruptedException ignore) {
+            Thread.currentThread().interrupt();","[{'comment': 'why not simply remove the catch block ?', 'commenter': 'gabrywu'}, {'comment': '> why not simply remove the catch block ?\r\n\r\nThank you very much for your suggestion, I will finish it later', 'commenter': 'CalvinKirs'}]"
3322,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/handler/NettyClientHandler.java,"@@ -75,7 +75,7 @@ public NettyClientHandler(NettyRemotingClient nettyRemotingClient, ExecutorServi
      * @throws Exception
      */
     @Override
-    public void channelInactive(ChannelHandlerContext ctx) throws Exception {
+    public void channelInactive(ChannelHandlerContext ctx) {","[{'comment': ""why remove 'throws Exception'?"", 'commenter': 'gabrywu'}]"
3322,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/handler/NettyServerHandler.java,"@@ -139,7 +138,7 @@ public void run() {
      * @throws Exception
      */
     @Override
-    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception {
+    public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) {","[{'comment': ""why remove 'throws Exception'?"", 'commenter': 'gabrywu'}, {'comment': ""Exception 'java.lang.Exception' is never thrown in the method"", 'commenter': 'CalvinKirs'}, {'comment': 'If it occurs, it should also be handed over to the upper caller.', 'commenter': 'CalvinKirs'}]"
3322,e2e/src/test/java/org/apache/dolphinscheduler/locator/project/ProcessInstanceLocator.java,"@@ -21,7 +21,7 @@
 public class ProcessInstanceLocator {
     // jump Process Instance page
     //click Process Instance name
-    public static final By CLICK_PROCESS_INSTANCE_NAME = By.xpath(""//div[3]/div/ul/li[2]"");
+    public static final By CLICK_PROCESS_INSTANCE_NAME = By.xpath(""//div[4]/div/ul/li[2]"");","[{'comment': 'Is this a bug?Is there a related issue?', 'commenter': 'gabrywu'}, {'comment': 'This is to solve the bug of e2e test', 'commenter': 'CalvinKirs'}, {'comment': 'OK,cool', 'commenter': 'gabrywu'}]"
3328,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterExecThread.java,"@@ -670,6 +670,11 @@ private DependResult isTaskDepsComplete(String taskName) {
         }
 
         TaskNode taskNode = dag.getNode(taskName);
+        // condition node directly return success
+        if (taskNode.isConditionsTask()) {
+            return DependResult.SUCCESS;","[{'comment': ""good job, but condition task also need check all the depend nodes complete, so it cannot directly return 'success' in here."", 'commenter': 'lenboo'}, {'comment': ""sorry, I didn't think it through. You are right, it needs to check all depend nodes. **So, the three lines here is not necessary.**"", 'commenter': 'legen618'}]"
3328,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterExecThread.java,"@@ -682,10 +687,16 @@ private DependResult isTaskDepsComplete(String taskName) {
                 return DependResult.WAITING;
             }
             ExecutionStatus depTaskState = completeTaskList.get(depsNode).getState();
-            // conditions task would not return failed.
-            if(depTaskState.typeIsFailure()
-                    && !DagHelper.haveConditionsAfterNode(depsNode, dag )
-                    && !dag.getNode(depsNode).isConditionsTask()){
+            // conditions task should be handled separately
+            if (dag.getNode(depsNode).isConditionsTask()) {
+                List<String> tmpTaskList = parseConditionTask(depsNode);
+                if (tmpTaskList.contains(taskName)){","[{'comment': ' you must scan all the depend nodes before return success.', 'commenter': 'lenboo'}, {'comment': 'In fact, in the loop it is supposed to return FAILED when dependency is not satisfied. And if all dependencies are satisfied it will **return SUCCESS outside the loop.**', 'commenter': 'legen618'}, {'comment': ""you are right, but there would be one situation is missing in this 'if{}',  task C depends on task B(condition) & A(shell or others) ,  B is done but A is running, but C may depend successfully in this 'if{}'."", 'commenter': 'lenboo'}]"
3415,dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/mapper/ResourceMapperTest.java,"@@ -76,8 +76,10 @@ private Resource insertOne(){
         resource.setDirectory(false);
         resource.setType(ResourceType.FILE);
         resource.setUserId(111);
-        resourceMapper.insert(resource);
-        return resource;
+        if( resourceMapper.insert(resource)>0 ){
+            return resource;
+        }
+        throw new RuntimeException(""insert data error"");","[{'comment': 'If the RuntimeException, how the invokers to handle it ?', 'commenter': 'gabrywu'}, {'comment': 'I also think assert.fail() is better.', 'commenter': 'yangyichao-mango'}, {'comment': 'Thanks for your review, I will finish it later', 'commenter': 'CalvinKirs'}]"
3427,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/codec/NettyDecoder.java,"@@ -55,15 +55,18 @@ protected void decode(ChannelHandlerContext ctx, ByteBuf in, List<Object> out) t
             case MAGIC:
                 checkMagic(in.readByte());
                 checkpoint(State.COMMAND);
+                break;
             case COMMAND:
                 commandHeader.setType(in.readByte());
                 checkpoint(State.OPAQUE);
+                break;
             case OPAQUE:
                 commandHeader.setOpaque(in.readLong());
                 checkpoint(State.BODY_LENGTH);
             case BODY_LENGTH:
                 commandHeader.setBodyLength(in.readInt());
                 checkpoint(State.BODY);
+                break;","[{'comment': 'You cannot directly break here, please refer to #3035 ', 'commenter': 'CalvinKirs'}, {'comment': '@gabrywu gabrywu gave some suggestions, maybe you can complete it. You can refer to https://github.com/apache/incubator-dolphinscheduler/pull/2969', 'commenter': 'CalvinKirs'}, {'comment': ""> You cannot directly break here, please refer to #3035\r\n\r\nI know the reason for removing break. Should I add a break at the last case? If don't do this, there will be many WARN logs that shouldn't appear in the log.\r\n"", 'commenter': 'vanilla111'}, {'comment': 'Of course, you can add a break at the last case. ', 'commenter': 'gabrywu'}]"
3427,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java,"@@ -84,6 +82,12 @@
      */
     private ExecutionStatus state;
 
+    /**
+     * task first submit time
+     */
+    @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"",timezone=""GMT+8"")","[{'comment': '```suggestion\r\n    @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"", timezone=""GMT+8"")\r\n```\r\nHi,\r\nPlease configure `checkstyle.xml` and `code style xml` in style directory. After configure that, you can use `option+command+L` to automatic format the code.\r\n\r\nCheckstyle.xml configuration lesson: https://www.cnblogs.com/wanshi1989/p/5478050.html\r\ncode style xml configuration lesson: https://blog.csdn.net/qq_34579060/article/details/80100040', 'commenter': 'yangyichao-mango'}]"
3427,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThread.java,"@@ -256,4 +272,60 @@ private void downloadResource(String execLocalPath,
             }
         }
     }
+
+    /**
+     * delay execution if needed
+     */
+    private void delayExecutionIfNeeded() {
+        long remainTime = DateUtils.getRemainTime(taskExecutionContext.getFirstSubmitTime(),
+                taskExecutionContext.getDelayTime() * 60L);
+        logger.info(""delay execution time: {} s"", remainTime < 0 ? 0 : remainTime);
+        if (remainTime > 0) {
+            try {
+                Thread.sleep(remainTime * Constants.SLEEP_TIME_MILLIS);
+            } catch (Exception e) {
+                logger.error(""exception"", e);
+                logger.error(""delay task execution failure, the task will be executed directly."" +","[{'comment': '```suggestion\r\n                logger.error(""exception"", e);\r\n                logger.error(""delay task execution failure, the task will be executed directly."" +\r\n```\r\nHi,\r\nIt will be better to combine these error log to one error log.', 'commenter': 'yangyichao-mango'}]"
3427,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/zk/ZKMasterClient.java,"@@ -16,6 +16,9 @@
  */
 package org.apache.dolphinscheduler.server.zk;
 
+import java.util.Date;","[{'comment': 'Hi~\r\nLooks like these files not need to be changed, you should revert these changes.\r\nThe same with `TaskResponseService.java`, `TaskResponseEvent.java`, `TaskExecuteResponseCommand.java`, `BaseDataSource.java `, `common.properties`, `ZookeeperNodeManagerTest.java`.', 'commenter': 'yangyichao-mango'}]"
3427,sql/dolphinscheduler-postgre.sql,"@@ -566,8 +566,10 @@ CREATE TABLE t_ds_task_instance (
   retry_interval int DEFAULT NULL ,
   max_retry_times int DEFAULT NULL ,
   task_instance_priority int DEFAULT NULL ,
-   worker_group varchar(64),
+  worker_group varchar(64),","[{'comment': 'You can add the sql updater in this directory.\r\n![image](https://user-images.githubusercontent.com/29545877/89790938-3cfae480-db55-11ea-8543-17e7b9d2ce82.png)\r\n', 'commenter': 'yangyichao-mango'}]"
3427,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java,"@@ -298,6 +305,14 @@ public void setState(ExecutionStatus state) {
         this.state = state;
     }
 
+    public Date getFirstSubmitTime() {
+        return firstSubmitTime;","[{'comment': ""what's the difference between 'submitTime' and 'firstSubmitTime'？"", 'commenter': 'lenboo'}, {'comment': 'If a task can be retried after failure and has been delayed enough time, it will no longer enter the state of delayed execution. This attribute is used to achieve this feature.', 'commenter': 'vanilla111'}]"
3427,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThread.java,"@@ -256,4 +275,59 @@ private void downloadResource(String execLocalPath,
             }
         }
     }
+
+    /**
+     * delay execution if needed
+     */
+    private void delayExecutionIfNeeded() {
+        long remainTime = DateUtils.getRemainTime(taskExecutionContext.getFirstSubmitTime(),
+                taskExecutionContext.getDelayTime() * 60L);
+        logger.info(""delay execution time: {} s"", remainTime < 0 ? 0 : remainTime);
+        if (remainTime > 0) {
+            try {
+                Thread.sleep(remainTime * Constants.SLEEP_TIME_MILLIS);","[{'comment': 'Hi,\r\nAfter this PR is merged, we can further talk about the optimize of the delayed task execution. The current implementation method is `Thread.sleep()`。\r\n\r\nI personally understand that many scenarios that need to use delay should be tens of minutes or several hours. In this scenario, task threads will be occupied all the time and will not be released, which will consume a lot of resources. After this PR is merged, we can talk about the optimization. For example, we can put the delayed tasks into a deferred execution pool and have a separate thread to scan whether they can be executed, and take out the tasks to be executed.\r\n\r\n---------------\r\n\r\n等这个pr合了之后，我们可以再讨论下把延迟的任务执行优化下，现在的实现方式是`Thread.sleep()`。\r\n\r\n我个人理解，很多需要用到延迟的场景应该都是几十分钟或者几个小时的延迟，这种场景下任务线程会一直被占用，得不到释放，会对资源消耗很大。之后可以讨论下是不是可以把延迟执行的任务放在一个延迟执行池里，单独有一个线程去扫描是否可以执行，将需要执行的任务拿出来进行执行。\r\n\r\nIf you have any suggestions or questions, welcome to put forward~\r\n', 'commenter': 'yangyichao-mango'}, {'comment': 'This is indeed a good suggestion, and I have a preliminary idea for its realization. I will start to implement it immediately after I complete another feature.', 'commenter': 'vanilla111'}]"
3427,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/entity/TaskExecutionContext.java,"@@ -42,6 +43,12 @@
      */
     private String taskName;
 
+    /**
+     *  task first submit time
+     */
+    @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"",timezone=""GMT+8"")","[{'comment': '```suggestion\r\n    @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"", timezone=""GMT+8"")\r\n```', 'commenter': 'yangyichao-mango'}, {'comment': 'I will modify it now.', 'commenter': 'vanilla111'}]"
3427,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThreadTest.java,"@@ -0,0 +1,182 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.worker.runner;
+
+import java.util.Date;
+
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.task.AbstractParameters;
+import org.apache.dolphinscheduler.common.utils.CommonUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.LoggerUtils;
+import org.apache.dolphinscheduler.remote.command.Command;
+import org.apache.dolphinscheduler.remote.command.TaskExecuteAckCommand;
+import org.apache.dolphinscheduler.remote.command.TaskExecuteResponseCommand;
+import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;
+import org.apache.dolphinscheduler.server.worker.cache.impl.TaskExecutionContextCacheManagerImpl;
+import org.apache.dolphinscheduler.server.worker.processor.TaskCallbackService;
+import org.apache.dolphinscheduler.server.worker.task.AbstractTask;
+import org.apache.dolphinscheduler.server.worker.task.TaskManager;
+import org.apache.dolphinscheduler.service.bean.SpringApplicationContext;
+import org.junit.After;
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * test task execute thread
+ */
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({TaskManager.class, JSONUtils.class, CommonUtils.class, SpringApplicationContext.class})
+public class TaskExecuteThreadTest {
+
+    private TaskExecutionContext taskExecutionContext;
+
+    private TaskCallbackService taskCallbackService;
+
+    private Command ackCommand;
+
+    private Command responseCommand;
+
+    private Logger taskLogger;
+
+    private TaskExecutionContextCacheManagerImpl taskExecutionContextCacheManager;
+
+    @Before
+    public void before() {
+        // init task execution context, logger
+        taskExecutionContext = new TaskExecutionContext();
+        taskExecutionContext.setProcessId(12345);
+        taskExecutionContext.setProcessDefineId(1);
+        taskExecutionContext.setProcessInstanceId(1);
+        taskExecutionContext.setTaskInstanceId(1);
+        taskExecutionContext.setTaskType("""");
+        taskExecutionContext.setFirstSubmitTime(new Date());
+        taskExecutionContext.setDelayTime(0);
+        taskExecutionContext.setLogPath(""/tmp/test.log"");
+        taskExecutionContext.setHost(""localhost"");
+        taskExecutionContext.setExecutePath(""/tmp/dolphinscheduler/exec/process/1/2/3/4"");
+
+        ackCommand = new TaskExecuteAckCommand().convert2Command();
+        responseCommand = new TaskExecuteResponseCommand(taskExecutionContext.getTaskInstanceId()).convert2Command();
+
+        taskLogger = LoggerFactory.getLogger(LoggerUtils.buildTaskId(
+                LoggerUtils.TASK_LOGGER_INFO_PREFIX,
+                taskExecutionContext.getProcessDefineId(),
+                taskExecutionContext.getProcessInstanceId(),
+                taskExecutionContext.getTaskInstanceId()
+        ));
+
+        taskExecutionContextCacheManager = new TaskExecutionContextCacheManagerImpl();
+        taskExecutionContextCacheManager.cacheTaskExecutionContext(taskExecutionContext);
+
+        taskCallbackService = PowerMockito.mock(TaskCallbackService.class);
+        PowerMockito.doNothing().when(taskCallbackService).sendAck(taskExecutionContext.getTaskInstanceId(), ackCommand);
+        PowerMockito.doNothing().when(taskCallbackService).sendResult(taskExecutionContext.getTaskInstanceId(), responseCommand);
+
+        PowerMockito.mockStatic(SpringApplicationContext.class);
+        PowerMockito.when(SpringApplicationContext.getBean(TaskExecutionContextCacheManagerImpl.class))
+                .thenReturn(taskExecutionContextCacheManager);
+
+        PowerMockito.mockStatic(TaskManager.class);
+        PowerMockito.when(TaskManager.newTask(taskExecutionContext, taskLogger))
+                .thenReturn(new SimpleTask(taskExecutionContext, taskLogger));
+
+        PowerMockito.mockStatic(JSONUtils.class);
+        PowerMockito.when(JSONUtils.parseObject(taskExecutionContext.getTaskJson(), TaskNode.class))
+                .thenReturn(new TaskNode());
+
+        PowerMockito.mockStatic(CommonUtils.class);
+        PowerMockito.when(CommonUtils.getSystemEnvPath()).thenReturn(""/user_home/.bash_profile"");
+    }
+
+    @Test
+    public void testNormalExecution() {
+        taskExecutionContext.setTaskType(""SQL"");
+        taskExecutionContext.setStartTime(new Date());
+        taskExecutionContext.setCurrentExecutionStatus(ExecutionStatus.RUNNING_EXECUTION);
+        TaskExecuteThread taskExecuteThread = new TaskExecuteThread(taskExecutionContext, taskCallbackService, taskLogger);
+        taskExecuteThread.run();
+
+        Assert.assertEquals(ExecutionStatus.SUCCESS, taskExecutionContext.getCurrentExecutionStatus());
+    }
+
+    @Test
+    public void testDelayExecution() {
+        taskExecutionContext.setTaskType(""PYTHON"");
+        taskExecutionContext.setStartTime(null);
+        taskExecutionContext.setDelayTime(1);
+        taskExecutionContext.setCurrentExecutionStatus(ExecutionStatus.DELAY_EXECUTION);
+        TaskExecuteThread taskExecuteThread = new TaskExecuteThread(taskExecutionContext, taskCallbackService, taskLogger);
+        taskExecuteThread.run();
+
+        Assert.assertEquals(ExecutionStatus.SUCCESS, taskExecutionContext.getCurrentExecutionStatus());
+    }
+
+    @After
+    public void after() throws Exception {
+        //
+    }","[{'comment': 'Delete unused function, or you can check whether there is the unreleased resources(eg. Unreleased thread poll) in tests that can be released in this fucntion.\r\n\r\n----------\r\n删除没有用到的function，或者可以检查下之前的测试用例中是否有没有释放的资源（比如没有关闭的线程池），可以在这个方法中释放资源。', 'commenter': 'yangyichao-mango'}, {'comment': 'OK, I got it.', 'commenter': 'vanilla111'}]"
3449,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/ShowType.java,"@@ -23,11 +23,13 @@
  */
 public enum ShowType {
     /**
+     * -1 NONE;
      * 0 TABLE;
      * 1 TEXT;
      * 2 attachment;
      * 3 TABLE+attachment;
      */
+    NONE(-1, ""none""),","[{'comment': 'In my opinion, it is not needed.', 'commenter': 'CalvinKirs'}]"
3481,dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java,"@@ -101,11 +101,10 @@ public static String getToken() throws IOException {
             }
 
             Map<String, String> map = JSONUtils.toMap(resp);
-            if (map != null) {
-                return map.get(""access_token"");
-            } else {
+            if (map == null) {
                 return null;
             }
+            return map.get(""access_token"");","[{'comment': 'return map==null?null: map.get(""access_token"")', 'commenter': 'gabrywu'}, {'comment': 'please review.thx', 'commenter': 'CalvinKirs'}]"
3519,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ResourcesService.java,"@@ -87,7 +87,7 @@
      * @return create directory result
      */
     @Transactional(rollbackFor = RuntimeException.class)
-    public Result createDirectory(User loginUser,
+    public synchronized Result createDirectory(User loginUser,","[{'comment': 'Hi,\r\nWe just need make the same dir name synchronized, put synchronized in function will make createDirectory of  this model synchronized, it will cause bad performance.\r\nIs there better way to fix this bug?', 'commenter': 'yangyichao-mango'}, {'comment': 'Agree wtth yangyichao-mango,we also need ensure the concurrent', 'commenter': 'lgcareer'}, {'comment': 'Ok\r\nI will test it later.', 'commenter': 'yangyichao-mango'}]"
3519,sql/dolphinscheduler-postgre.sql,"@@ -499,7 +499,8 @@ CREATE TABLE t_ds_resources (
   pid int,
   full_name varchar(64),
   is_directory int,
-  PRIMARY KEY (id)
+  PRIMARY KEY (id),
+  CONSTRAINT t_ds_resources_un UNIQUE (full_name, type)","[{'comment': 'Hi,\r\nI add the CONSTRAINT and test in my local multithread env, it will show the error like[1], not [2]. But I think this solution LGTM.\r\n\r\nBTW, the db sql schema changes should be add in a new dir maybe `1.3.3_schema`  in `upgrade` dir[3] that should be decide by @dailidong .\r\n\r\n[1] ![image](https://user-images.githubusercontent.com/29545877/90583796-ab9a0b00-e203-11ea-9696-fa617105b1b2.png)\r\n[2] ![image](https://user-images.githubusercontent.com/29545877/90583906-e13ef400-e203-11ea-84d3-3c0c9a4d0cc8.png)\r\n[3] ![image](https://user-images.githubusercontent.com/29545877/90584020-2b27da00-e204-11ea-9226-af4917c2ff36.png)\r\n', 'commenter': 'yangyichao-mango'}, {'comment': '> Hi,\r\n> I add the CONSTRAINT and test in my local multithread env, it will show the error like[1], not [2]. But I think this solution LGTM.\r\n> \r\n> BTW, the db sql schema changes should be add in a new dir maybe `1.3.3_schema` in `upgrade` dir[3] that should be decide by @dailidong .\r\n> \r\n> [1] ![image](https://user-images.githubusercontent.com/29545877/90583796-ab9a0b00-e203-11ea-9696-fa617105b1b2.png)\r\n> [2] ![image](https://user-images.githubusercontent.com/29545877/90583906-e13ef400-e203-11ea-84d3-3c0c9a4d0cc8.png)\r\n> [3] ![image](https://user-images.githubusercontent.com/29545877/90584020-2b27da00-e204-11ea-9226-af4917c2ff36.png)\r\n\r\nLGTM', 'commenter': 'davidzollo'}]"
3519,sql/upgrade/1.3.3_schema/mysql/dolphinscheduler_ddl.sql,"@@ -87,3 +87,9 @@ delimiter ;
 CALL ct_dolphin_T_t_ds_process_definition_version;
 DROP PROCEDURE ct_dolphin_T_t_ds_process_definition_version;
 
+
+-- add t_ds_resources_un
+ALTER TABLE t_ds_resources ADD CONSTRAINT t_ds_resources_un UNIQUE KEY (full_name,`type`);","[{'comment': 'Hi,This place need judge whether t_ds_resources_un exist,you can use the process function like the above uc_dolphin_T_t_ds_task_instance_A_first_submit_time', 'commenter': 'lgcareer'}]"
3519,sql/upgrade/1.3.3_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -79,4 +80,9 @@ d//
 
 delimiter ;
 SELECT ct_dolphin_T_t_ds_process_definition_version();
-DROP FUNCTION IF EXISTS ct_dolphin_T_t_ds_process_definition_version();
\ No newline at end of file
+DROP FUNCTION IF EXISTS ct_dolphin_T_t_ds_process_definition_version();
+
+-- add t_ds_resources_un
+ALTER TABLE t_ds_resources ADD CONSTRAINT t_ds_resources_un UNIQUE (full_name,""type"");","[{'comment': 'Hi,This place need judge whether t_ds_resources_un exist,you can use the process function like the above uc_dolphin_T_t_ds_task_instance_A_first_submit_time', 'commenter': 'lgcareer'}]"
3559,dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/utils/EnterpriseWeChatUtils.java,"@@ -48,8 +55,8 @@
 
     private static final String ENTERPRISE_WE_CHAT_TOKEN_URL = PropertyUtils.getString(Constants.ENTERPRISE_WECHAT_TOKEN_URL);
     private static final String ENTERPRISE_WE_CHAT_TOKEN_URL_REPLACE = ENTERPRISE_WE_CHAT_TOKEN_URL == null ? null : ENTERPRISE_WE_CHAT_TOKEN_URL
-    .replaceAll(""\\{corpId\\}"", ENTERPRISE_WE_CHAT_CORP_ID)
-    .replaceAll(""\\{secret\\}"", ENTERPRISE_WE_CHAT_SECRET);
+            .replaceAll(""\\{corpId\\}"", ENTERPRISE_WE_CHAT_CORP_ID)
+            .replaceAll(""\\{secret\\}"", ENTERPRISE_WE_CHAT_SECRET);","[{'comment': '```suggestion\r\n            .replaceAll(""\\\\{corpId}"", ENTERPRISE_WE_CHAT_CORP_ID)\r\n            .replaceAll(""\\\\{secret}"", ENTERPRISE_WE_CHAT_SECRET);\r\n```\r\nPlease change the other part of `replaceAll`.', 'commenter': 'yangyichao-mango'}]"
3559,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/AlertWarnLevel.java,"@@ -0,0 +1,23 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.enums;
+
+public enum AlertWarnLevel {
+
+    MIDDLE,SERIOUS","[{'comment': 'Is it better to match the logger?\r\nFor excample: debug, info, warning, error', 'commenter': 'yangyichao-mango'}, {'comment': ""\r\n\r\n> Is it better to match the logger?\r\n> For excample: debug, info, warning, error\r\nThis is a way of storing the string directly into the content of the message and sending it out, and if it's a number it needs to be sent out under conversion.\r\n"", 'commenter': 'felix-thinkingdata'}, {'comment': '![image](https://user-images.githubusercontent.com/59079269/90854112-ab8a3e80-e3ae-11ea-8c9e-1adadf86d3ee.png)\r\n![image](https://user-images.githubusercontent.com/59079269/90854123-b644d380-e3ae-11ea-9185-cee15f098059.png)\r\n', 'commenter': 'felix-thinkingdata'}]"
3559,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/registry/ZookeeperNodeManager.java,"@@ -38,33 +35,37 @@
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
 
-import static org.apache.dolphinscheduler.common.Constants.DEFAULT_WORKER_GROUP;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.InitializingBean;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
 
 /**
- *  zookeeper node manager
+ * zookeeper node manager","[{'comment': 'Is this file changes related with this pr?\r\nIf not related, please revert.', 'commenter': 'yangyichao-mango'}, {'comment': '\r\n> Is this file changes related with this pr?\r\n> If not related, please revert.\r\nI\'ve optimized this part\r\n```\r\nString host = org.apache.commons.lang.StringUtils.substringAfterLast(path, ""/"");\r\n```\r\nbecause code style,Become less obvious ,lint 226 ,265', 'commenter': 'felix-thinkingdata'}, {'comment': 'Extract the exact host information in the path of zookeeper', 'commenter': 'felix-thinkingdata'}, {'comment': 'modified', 'commenter': 'felix-thinkingdata'}]"
3561,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/DataSourceServiceTest.java,"@@ -51,46 +55,206 @@
     private DataSourceService dataSourceService;
     @Mock
     private DataSourceMapper dataSourceMapper;
+    @Mock","[{'comment': 'You can remove this unused logger.\r\n![image](https://user-images.githubusercontent.com/29545877/90771663-37a45380-e326-11ea-9736-14d2fb4687cf.png)\r\n', 'commenter': 'yangyichao-mango'}]"
3561,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/DataSourceServiceTest.java,"@@ -51,46 +55,206 @@
     private DataSourceService dataSourceService;
     @Mock
     private DataSourceMapper dataSourceMapper;
+    @Mock
+    private DataSourceUserMapper datasourceUserMapper;
+
+
+    @Test
+    public void createDataSourceTest() {
+        User loginUser = getAdminUser();
+
+        String dataSourceName = ""dataSource01"";
+        String dataSourceDesc = ""test dataSource"";
+        DbType dataSourceType = DbType.POSTGRESQL;
+        String parameter = dataSourceService.buildParameter(dataSourceType, ""172.16.133.200"", ""5432"", ""dolphinscheduler"", null, ""postgres"", """", null, null);
+
+        // data source exits
+        List<DataSource> dataSourceList = new ArrayList<>();
+        DataSource dataSource = new DataSource();
+        dataSource.setName(dataSourceName);
+        dataSourceList.add(dataSource);
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName.trim())).thenReturn(dataSourceList);
+        Map<String, Object> dataSourceExitsResult = dataSourceService.createDataSource(loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.DATASOURCE_EXIST, dataSourceExitsResult.get(Constants.STATUS));
+
+        // data source exits
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName.trim())).thenReturn(null);
+        when(dataSourceService.checkConnection(dataSourceType, parameter)).thenReturn(false);
+        Map<String, Object> connectFailedResult = dataSourceService.createDataSource(loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.DATASOURCE_CONNECT_FAILED, connectFailedResult.get(Constants.STATUS));
+
+        // data source exits
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName.trim())).thenReturn(null);
+        when(dataSourceService.checkConnection(dataSourceType, parameter)).thenReturn(true);
+        when(DataSourceFactory.getDatasource(dataSourceType, parameter)).thenReturn(null);
+        Map<String, Object> notValidError = dataSourceService.createDataSource(loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.REQUEST_PARAMS_NOT_VALID_ERROR, notValidError.get(Constants.STATUS));
+
+        // success
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName.trim())).thenReturn(null);
+        when(dataSourceService.checkConnection(dataSourceType, parameter)).thenReturn(true);
+        when(DataSourceFactory.getDatasource(dataSourceType, parameter)).thenReturn(JSONUtils.parseObject(parameter, MySQLDataSource.class));
+        Map<String, Object> success = dataSourceService.createDataSource(loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.SUCCESS, success.get(Constants.STATUS));
+    }
+
+    @Test
+    public void updateDataSourceTest() {
+        User loginUser = getAdminUser();
+
+        int dataSourceId = 12;
+        String dataSourceName = ""dataSource01"";
+        String dataSourceDesc = ""test dataSource"";
+        DbType dataSourceType = DbType.POSTGRESQL;
+        String parameter = dataSourceService.buildParameter(dataSourceType, ""172.16.133.200"", ""5432"", ""dolphinscheduler"", null, ""postgres"", """", null, null);
+
+        // data source not exits
+        when(dataSourceMapper.selectById(dataSourceId)).thenReturn(null);
+        Map<String, Object> resourceNotExits = dataSourceService.updateDataSource(dataSourceId, loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.RESOURCE_NOT_EXIST, resourceNotExits.get(Constants.STATUS));
+        // user no operation perm
+        DataSource dataSource = new DataSource();
+        dataSource.setUserId(0);
+        when(dataSourceMapper.selectById(dataSourceId)).thenReturn(dataSource);
+        Map<String, Object> userNoOperationPerm = dataSourceService.updateDataSource(dataSourceId, loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.USER_NO_OPERATION_PERM, userNoOperationPerm.get(Constants.STATUS));
+
+        // data source name exits
+        dataSource.setUserId(-1);
+        List<DataSource> dataSourceList = new ArrayList<>();
+        dataSourceList.add(dataSource);
+        when(dataSourceMapper.selectById(dataSourceId)).thenReturn(dataSource);
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName)).thenReturn(dataSourceList);
+        Map<String, Object> dataSourceNameExist = dataSourceService.updateDataSource(dataSourceId, loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.DATASOURCE_EXIST, dataSourceNameExist.get(Constants.STATUS));
+
+        // data source connect failed
+        when(dataSourceMapper.selectById(dataSourceId)).thenReturn(dataSource);
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName)).thenReturn(null);
+        when(dataSourceService.checkConnection(dataSourceType, parameter)).thenReturn(true);
+        Map<String, Object> connectFailed = dataSourceService.updateDataSource(dataSourceId, loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.DATASOURCE_CONNECT_FAILED, connectFailed.get(Constants.STATUS));
+
+        //success
+        when(dataSourceMapper.selectById(dataSourceId)).thenReturn(dataSource);
+        when(dataSourceMapper.queryDataSourceByName(dataSourceName)).thenReturn(null);
+        when(dataSourceService.checkConnection(dataSourceType, parameter)).thenReturn(false);
+        Map<String, Object> success = dataSourceService.updateDataSource(dataSourceId, loginUser, dataSourceName, dataSourceDesc, dataSourceType, parameter);
+        Assert.assertEquals(Status.SUCCESS, connectFailed.get(Constants.STATUS));
+
+    }
+
+    @Test
+    public void queryDataSourceListPagingTest() {
+        User loginUser = getAdminUser();
+        String searchVal = """";
+        int pageNo = 1;
+        int pageSize = 10;
+        Map<String, Object> success = dataSourceService.queryDataSourceListPaging(loginUser, searchVal, pageNo, pageSize);
+        Assert.assertEquals(Status.SUCCESS, success.get(Constants.STATUS));
+    }
 
     @Test
-    public void queryDataSourceListTest(){
+    public void connectionTest() {
+        int dataSourceId = -1;
+        when(dataSourceMapper.selectById(dataSourceId)).thenReturn(null);
+        Assert.assertEquals(false, dataSourceService.connectionTest(dataSourceId));","[{'comment': '```suggestion\r\n        Assert.assertFalse(dataSourceService.connectionTest(dataSourceId));\r\n```', 'commenter': 'yangyichao-mango'}]"
3561,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/DataSourceServiceTest.java,"@@ -101,31 +265,49 @@ private DataSource getOracleDataSource(){
     }
 
     @Test
-    public void buildParameter(){
-        String param = dataSourceService.buildParameter("""","""", DbType.ORACLE, ""192.168.9.1"",""1521"",""im""
-                ,"""",""test"",""test"", DbConnectType.ORACLE_SERVICE_NAME,"""");
+    public void buildParameter() {
+        String param = dataSourceService.buildParameter(DbType.ORACLE, ""192.168.9.1"", ""1521"", ""im""
+                , """", ""test"", ""test"", DbConnectType.ORACLE_SERVICE_NAME, """");
         String expected = ""{\""connectType\"":\""ORACLE_SERVICE_NAME\"",\""type\"":\""ORACLE_SERVICE_NAME\"",\""address\"":\""jdbc:oracle:thin:@//192.168.9.1:1521\"",\""database\"":\""im\"",\""jdbcUrl\"":\""jdbc:oracle:thin:@//192.168.9.1:1521/im\"",\""user\"":\""test\"",\""password\"":\""test\""}"";
         Assert.assertEquals(expected, param);
     }
 
     @Test
-    public void buildParameterWithDecodePassword(){
-        PropertyUtils.setValue(Constants.DATASOURCE_ENCRYPTION_ENABLE,""true"");
-        String param = dataSourceService.buildParameter(""name"",""desc"", DbType.MYSQL, ""192.168.9.1"",""1521"",""im""
-                ,"""",""test"",""123456"", null,"""");
+    public void buildParameterWithDecodePassword() {
+        PropertyUtils.setValue(Constants.DATASOURCE_ENCRYPTION_ENABLE, ""true"");
+        String param = dataSourceService.buildParameter(DbType.MYSQL, ""192.168.9.1"", ""1521"", ""im""
+                , """", ""test"", ""123456"", null, """");
         String expected = ""{\""type\"":null,\""address\"":\""jdbc:mysql://192.168.9.1:1521\"",\""database\"":\""im\"",\""jdbcUrl\"":\""jdbc:mysql://192.168.9.1:1521/im\"",\""user\"":\""test\"",\""password\"":\""IUAjJCVeJipNVEl6TkRVMg==\""}"";
         Assert.assertEquals(expected, param);
 
 
-        PropertyUtils.setValue(Constants.DATASOURCE_ENCRYPTION_ENABLE,""false"");
-        param = dataSourceService.buildParameter(""name"",""desc"", DbType.MYSQL, ""192.168.9.1"",""1521"",""im""
-                ,"""",""test"",""123456"", null,"""");
+        PropertyUtils.setValue(Constants.DATASOURCE_ENCRYPTION_ENABLE, ""false"");
+        param = dataSourceService.buildParameter(DbType.MYSQL, ""192.168.9.1"", ""1521"", ""im""
+                , """", ""test"", ""123456"", null, """");
         expected = ""{\""type\"":null,\""address\"":\""jdbc:mysql://192.168.9.1:1521\"",\""database\"":\""im\"",\""jdbcUrl\"":\""jdbc:mysql://192.168.9.1:1521/im\"",\""user\"":\""test\"",\""password\"":\""123456\""}"";
         Assert.assertEquals(expected, param);
     }
 
+    /**
+     * get Mock Admin User
+     *
+     * @return admin user
+     */
+    private User getAdminUser() {
+        User loginUser = new User();
+        loginUser.setId(-1);
+        loginUser.setUserName(""admin"");
+        loginUser.setUserType(UserType.GENERAL_USER);
+        return loginUser;
+    }
 
-
-
+    private void putMsg(Map<String, Object> result, Status status, Object... statusParams) {
+        result.put(Constants.STATUS, status);
+        if (statusParams != null && statusParams.length > 0) {
+            result.put(Constants.MSG, MessageFormat.format(status.getMsg(), statusParams));
+        } else {
+            result.put(Constants.MSG, status.getMsg());
+        }
+    }","[{'comment': '```suggestion\r\n```\r\nPlease remove this unused block.', 'commenter': 'yangyichao-mango'}]"
3563,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/TaskInstanceService.java,"@@ -93,23 +99,17 @@
         }
 
         int[] statusArray = null;
-        if(stateType != null){
+        if (stateType != null) {
             statusArray = new int[]{stateType.ordinal()};
         }
 
         Date start = null;
         Date end = null;
-        try {
-            if(StringUtils.isNotEmpty(startDate)){
-                start = DateUtils.getScheduleDate(startDate);
-            }
-            if(StringUtils.isNotEmpty( endDate)){
-                end = DateUtils.getScheduleDate(endDate);
-            }
-        } catch (Exception e) {
-            result.put(Constants.STATUS, Status.REQUEST_PARAMS_NOT_VALID_ERROR);
-            result.put(Constants.MSG, MessageFormat.format(Status.REQUEST_PARAMS_NOT_VALID_ERROR.getMsg(), ""startDate,endDate""));
-            return result;
+        if (StringUtils.isNotEmpty(startDate)) {
+            start = DateUtils.getScheduleDate(startDate);
+        }
+        if (StringUtils.isNotEmpty(endDate)) {
+            end = DateUtils.getScheduleDate(endDate);","[{'comment': 'Hi~\r\nPlease add null judge for `startDate` and `endDate`, because in this case, we can not judge the null result of `start` or `end` is because of the null value of `startDate` and `endDate` or having exception when processing `getScheduleDate`. If the cause is the exception of processing `getScheduleDate` [1], we need to return the result `Status.REQUEST_PARAMS_NOT_VALID_ERROR` to user.\r\n\r\nI think you can define the `Status.START_OR_END_DATE_VALID_ERROR`.\r\n\r\n\r\n--------------\r\n请添加 `startDate` and `endDate` 为 null 时的判断，因为当 `start` 或 `end` 的值为 null 时，我们无法判断是由于 startDate 或者 endDate 为null 导致的，还是由于脏数据导致在执行 `getScheduleDate` 发生异常导致的。如果发生异常导致的[1]，我们应该返回 `Status.REQUEST_PARAMS_NOT_VALID_ERROR`.\r\n\r\n你可以看下有没有已经定义好的异常类型，如果没有的话，可以自定义一个错误，详细描述错误内容，比如 `Status.START_OR_END_DATE_VALID_ERROR`.\r\n\r\n[1] ![image](https://user-images.githubusercontent.com/29545877/90843629-a7512780-e394-11ea-8630-ba7d89c8b5ef.png)\r\n', 'commenter': 'yangyichao-mango'}, {'comment': 'thanks for review.\r\ni just use `Status.REQUEST_PARAMS_NOT_VALID_ERROR` to return the error when date param is not right', 'commenter': 'geosmart'}]"
3582,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -488,6 +488,12 @@ private String getResourceIds(ProcessData processData) {
             putMsg(result, Status.PROCESS_DEFINE_STATE_ONLINE, processDefinitionId);
             return result;
         }
+        // check process instances is already running
+        List<ProcessInstance> processInstances =  processInstanceMapper.queryByProcessDefineIdAndStatus(processDefinitionId, Constants.NOT_TERMINATED_STATES);
+        if (CollectionUtils.isNotEmpty(processInstances)) {
+            putMsg(result, Status.DELETE_PROCESS_DEFINITION_BY_ID_FAIL,processInstances.size());
+            return result;
+        }","[{'comment': '```suggestion\r\n        List<ProcessInstance> processInstances =  processInstanceService.queryByProcessDefineIdAndStatus(processDefinitionId, Constants.NOT_TERMINATED_STATES);\r\n        if (CollectionUtils.isNotEmpty(processInstances)) {\r\n            putMsg(result, Status.DELETE_PROCESS_DEFINITION_BY_ID_FAIL,processInstances.size());\r\n            return result;\r\n        }\r\n```\r\n\r\nHi,\r\nIn `processDefinitionService` service layer, it is not recommended straightly use `processInstanceMapper` dao layer, this part should be in `processInstanceService`, use `processInstanceService` here. ', 'commenter': 'yangyichao-mango'}, {'comment': 'Processinstanceservice has been used. Processinstanceservice should implement the interface. There are contributors who have submitted branches. I have not changed this.\r\n\r\n---\r\n\r\n已使用processInstanceService ，processInstanceService 应该实现接口，已经有贡献者提交分支，这块我没有改.', 'commenter': 'zhuangchong'}]"
3587,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/Stopper.java,"@@ -14,26 +14,34 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+
 package org.apache.dolphinscheduler.common.thread;
 
 import java.util.concurrent.atomic.AtomicBoolean;
 
 /**
- *  if the process closes, a signal is placed as true, and all threads get this flag to stop working
+ * if the process closes, a signal is placed as true, and all threads get this flag to stop working
  */
 public class Stopper {
 
-	private static AtomicBoolean signal = new AtomicBoolean(false);
-	
-	public static final boolean isStopped(){
-		return signal.get();
-	}
-	
-	public static final boolean isRunning(){
-		return !signal.get();
-	}
-	
-	public static final void stop(){
-		signal.set(true);
-	}
+    private static AtomicBoolean signal = new AtomicBoolean(false);
+
+    public static final boolean isStopped() {
+        return signal.get();
+    }
+
+    public static final boolean isRunning() {
+        return !signal.get();
+    }
+
+    public static final void stop() {
+        signal.set(true);
+    }
+
+    /**
+     * should only be used for test
+     */
+    public static final void reset() {","[{'comment': '```suggestion\r\n    public static final void reset() {\r\n```\r\n\r\nSuggest do not to write this method just for test, and it also will cause the system error if we use this method in the project.', 'commenter': 'yangyichao-mango'}, {'comment': 'reverted.', 'commenter': 'hsupu'}]"
3587,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/master/SubProcessTaskTest.java,"@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master;
+
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.common.enums.TaskType;
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.thread.Stopper;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.server.master.config.MasterConfig;
+import org.apache.dolphinscheduler.server.master.runner.SubProcessTaskExecThread;
+import org.apache.dolphinscheduler.service.bean.SpringApplicationContext;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+import org.springframework.context.ApplicationContext;
+
+@RunWith(MockitoJUnitRunner.Silent.class)
+public class SubProcessTaskTest {
+
+    /**
+     * TaskNode.runFlag : task can be run normally
+     */
+    public static final String FLOWNODE_RUN_FLAG_NORMAL = ""NORMAL"";
+
+    private ProcessService processService;
+
+    private ProcessInstance processInstance;
+
+    @Before
+    public void before() {
+        ApplicationContext applicationContext = Mockito.mock(ApplicationContext.class);
+        SpringApplicationContext springApplicationContext = new SpringApplicationContext();
+        springApplicationContext.setApplicationContext(applicationContext);
+
+        MasterConfig config = new MasterConfig();
+        Mockito.when(applicationContext.getBean(MasterConfig.class)).thenReturn(config);
+        config.setMasterTaskCommitRetryTimes(3);
+        config.setMasterTaskCommitInterval(1000);
+
+        processService = Mockito.mock(ProcessService.class);
+        Mockito.when(applicationContext.getBean(ProcessService.class)).thenReturn(processService);
+
+        processInstance = getProcessInstance();
+        Mockito.when(processService
+                .findProcessInstanceById(processInstance.getId()))
+                .thenReturn(processInstance);
+
+        // for SubProcessTaskExecThread.setTaskInstanceState
+        Mockito.when(processService
+                .updateTaskInstance(Mockito.any()))
+                .thenReturn(true);
+
+        // for MasterBaseTaskExecThread.submit
+        Mockito.when(processService
+                .submitTask(Mockito.any()))
+                .thenAnswer(t -> t.getArgument(0));
+    }
+
+    private TaskInstance testBasicInit(ExecutionStatus expectResult) {
+        TaskInstance taskInstance = getTaskInstance(getTaskNode(), processInstance);
+
+        ProcessInstance subProcessInstance = getSubProcessInstance(expectResult);
+        // for SubProcessTaskExecThread.waitTaskQuit
+        Mockito.when(processService
+                .findProcessInstanceById(subProcessInstance.getId()))
+                .thenReturn(subProcessInstance);
+        Mockito.when(processService
+                .findSubProcessInstance(processInstance.getId(), taskInstance.getId()))
+                .thenReturn(subProcessInstance);
+
+        return taskInstance;
+    }
+
+    @Test
+    public void testBasicSuccess() throws Exception {
+        if (!Stopper.isRunning()) {
+            return;
+        }","[{'comment': 'Will it directly return because the global `Stopper.isRunning()` return false?', 'commenter': 'yangyichao-mango'}]"
3605,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java,"@@ -311,59 +265,9 @@
             return result;
         }
 
-        // TODO tasksQueueList and tasksKillList is never updated.
-        List<String> tasksQueueList = new ArrayList<>();
-        List<String> tasksKillList = new ArrayList<>();
-
         Map<String, Integer> dataMap = new HashMap<>();
-        if (loginUser.getUserType() == UserType.ADMIN_USER) {
-            dataMap.put(""taskQueue"", tasksQueueList.size());
-            dataMap.put(""taskKill"", tasksKillList.size());
-
-            result.put(Constants.DATA_LIST, dataMap);
-            putMsg(result, Status.SUCCESS);
-            return result;
-        }
-
-        int[] tasksQueueIds = new int[tasksQueueList.size()];
-        int[] tasksKillIds = new int[tasksKillList.size()];
-
-        int i = 0;
-        for (String taskQueueStr : tasksQueueList) {
-            if (StringUtils.isNotEmpty(taskQueueStr)) {
-                String[] splits = taskQueueStr.split(""_"");
-                if (splits.length >= 4) {
-                    tasksQueueIds[i++] = Integer.parseInt(splits[3]);
-                }
-            }
-        }
-
-        i = 0;
-        for (String taskKillStr : tasksKillList) {
-            if (StringUtils.isNotEmpty(taskKillStr)) {
-                String[] splits = taskKillStr.split(""-"");
-                if (splits.length == 2) {
-                    tasksKillIds[i++] = Integer.parseInt(splits[1]);
-                }
-            }
-        }
-        Integer taskQueueCount = 0;
-        Integer taskKillCount = 0;
-
-        Integer[] projectIds = getProjectIdsArrays(loginUser, projectId);
-        if (tasksQueueIds.length != 0) {
-            taskQueueCount = taskInstanceMapper.countTask(
-                    projectIds,
-                    tasksQueueIds);
-        }
-
-        if (tasksKillIds.length != 0) {
-            taskKillCount = taskInstanceMapper.countTask(projectIds, tasksKillIds);
-        }
-
-        dataMap.put(""taskQueue"", taskQueueCount);
-        dataMap.put(""taskKill"", taskKillCount);","[{'comment': 'Will it produce error when we just use \r\n`dataMap.put(""taskQueue"", 0);`\r\n`dataMap.put(""taskKill"", 0);`\r\n?', 'commenter': 'yangyichao-mango'}, {'comment': 'yes, it need to add detail data info , TODO ', 'commenter': 'davidzollo'}]"
3629,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/LogUtils.java,"@@ -0,0 +1,73 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.utils;
+
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;
+import org.apache.dolphinscheduler.server.log.TaskLogDiscriminator;
+
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.Optional;
+
+import org.slf4j.LoggerFactory;
+
+import ch.qos.logback.classic.sift.SiftingAppender;
+import ch.qos.logback.classic.spi.ILoggingEvent;
+import ch.qos.logback.core.spi.AppenderAttachable;
+
+public class LogUtils {
+
+    private LogUtils() {","[{'comment': 'Please Add throw new unsupportedException.', 'commenter': 'yangyichao-mango'}]"
3629,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/utils/LogUtilsTest.java,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.utils;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.server.log.TaskLogDiscriminator;
+
+import java.nio.file.Path;
+import java.nio.file.Paths;
+
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+import org.slf4j.LoggerFactory;
+
+import ch.qos.logback.classic.Logger;
+import ch.qos.logback.classic.sift.SiftingAppender;
+
+@RunWith(MockitoJUnitRunner.class)
+public class LogUtilsTest {
+
+    @Test
+    public void testGetTaskLogPath() {
+        Assert.assertEquals(""/"", Constants.SINGLE_SLASH);","[{'comment': 'Is this constant used in logutils? If not, we can remove it,', 'commenter': 'yangyichao-mango'}]"
3659,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/utils/VarPoolUtilsTest.java,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.utils;
+
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.VarPoolUtils;
+
+import java.util.concurrent.ConcurrentHashMap;
+
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class VarPoolUtilsTest {
+    
+    private static final Logger logger = LoggerFactory.getLogger(VarPoolUtils.class);
+    
+    @Test
+    public void testSetTaskNodeLocalParams() {
+        String taskJson = ""{\""conditionResult\"":\""{\\\""successNode\\\"":[\\\""\\\""],\\\""failedNode\\\"":[\\\""\\\""]}\"",""
+            + ""\""conditionsTask\"":false,\""depList\"":[],\""dependence\"":\""{}\"",\""forbidden\"":false,\""id\"":\""tasks-75298\"",\""maxRetryTimes\"":0,\""name\"":\""a1\"",""
+            + ""\""params\"":\""{\\\""rawScript\\\"":\\\""print(\\\\\\\""this is python task \\\\\\\"",${p0})\\\"",""
+            + ""\\\""localParams\\\"":[{\\\""prop\\\"":\\\""p1\\\"",\\\""direct\\\"":\\\""IN\\\"",\\\""type\\\"":\\\""VARCHAR\\\"",\\\""value\\\"":\\\""1\\\""}],""
+            + ""\\\""resourceList\\\"":[]}\"",\""preTasks\"":\""[]\"",\""retryInterval\"":1,\""runFlag\"":\""NORMAL\"",\""taskInstancePriority\"":\""MEDIUM\"",""
+            + ""\""taskTimeoutParameter\"":{\""enable\"":false,\""interval\"":0},\""timeout\"":\""{\\\""enable\\\"":false,\\\""strategy\\\"":\\\""\\\""}\"",""
+            + ""\""type\"":\""PYTHON\"",\""workerGroup\"":\""default\""}"";
+        TaskNode taskNode = JSONUtils.parseObject(taskJson, TaskNode.class);
+        
+        VarPoolUtils.setTaskNodeLocalParams(taskNode, ""p1"", ""test1"");
+        logger.info(JSONUtils.toJsonString(taskNode));
+        
+        ConcurrentHashMap<String, Object> propToValue = new ConcurrentHashMap<String, Object>();
+        propToValue.put(""p1"", ""test2"");
+        
+        VarPoolUtils.setTaskNodeLocalParams(taskNode, propToValue);
+        logger.info(JSONUtils.toJsonString(taskNode));
+    }
+    
+    @Test
+    public void testConvertVarPoolToMap() throws Exception {
+        String varPool = ""p1,66$guyinyou$p2,69$guyinyou$"";
+        ConcurrentHashMap<String, Object> propToValue = new ConcurrentHashMap<String, Object>();
+        VarPoolUtils.convertVarPoolToMap(propToValue, varPool);
+        logger.info(propToValue.toString());
+    }
+    
+    @Test
+    public void testConvertPythonScriptPlaceholders() throws Exception {
+        String rawScript = ""print(${p1});\n${setShareVar(${p1},3)};\n${setShareVar(${p2},4)};"";
+        rawScript = VarPoolUtils.convertPythonScriptPlaceholders(rawScript);
+        logger.info(rawScript);","[{'comment': 'You need to use Assert to determine whether the result is correct, not just print logs.', 'commenter': 'simon824'}]"
3659,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/utils/VarPoolUtilsTest.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.utils;
+
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.VarPoolUtils;
+
+import java.util.concurrent.ConcurrentHashMap;
+
+import org.junit.Assert;
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class VarPoolUtilsTest {
+    
+    private static final Logger logger = LoggerFactory.getLogger(VarPoolUtils.class);
+    ","[{'comment': 'please rename VarPoolUtils to VarPoolUtilsTest', 'commenter': 'simon824'}]"
3659,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -347,8 +351,13 @@ public void run() {
                     long lastFlushTime = System.currentTimeMillis();
 
                     while ((line = inReader.readLine()) != null) {
-                        logBuffer.add(line);
-                        lastFlushTime = flush(lastFlushTime);
+                        if (line.startsWith(""${setValue("")) {
+                            varPool.append(line.substring(""${setValue("".length(), line.length() - 2));
+                            varPool.append(""$guyinyou$"");","[{'comment': ""Please replace with another separator here, don't use your name."", 'commenter': 'simon824'}]"
3659,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java,"@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.task.TaskParams;
+
+import java.text.ParseException;
+import java.util.Map;
+
+public class VarPoolUtils {
+    /**
+     * getTaskNodeLocalParam
+     * @param taskNode taskNode
+     * @param prop prop
+     * @return localParamForProp
+     */
+    public static Object getTaskNodeLocalParam(TaskNode taskNode, String prop) {
+        String taskParamsJson = taskNode.getParams();
+        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
+        if (taskParams == null) {
+            return null;
+        }
+        return taskParams.getLocalParamValue(prop);
+    }
+    
+    /**
+     * setTaskNodeLocalParams
+     * @param taskNode taskNode
+     * @param prop LocalParamName
+     * @param value LocalParamValue
+     */
+    public static void setTaskNodeLocalParams(TaskNode taskNode, String prop, Object value) {
+        String taskParamsJson = taskNode.getParams();
+        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
+        if (taskParams == null) {
+            return;
+        }
+        taskParams.setLocalParamValue(prop, value);
+        taskNode.setParams(JSONUtils.toJsonString(taskParams));
+    }
+
+    /**
+     * setTaskNodeLocalParams
+     * @param taskNode taskNode
+     * @param propToValue propToValue
+     */
+    public static void setTaskNodeLocalParams(TaskNode taskNode, Map<String, Object> propToValue) {
+        String taskParamsJson = taskNode.getParams();
+        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
+        if (taskParams == null) {
+            return;
+        }
+        taskParams.setLocalParamValue(propToValue);
+        taskNode.setParams(JSONUtils.toJsonString(taskParams));
+    }
+
+    /**
+     * convertVarPoolToMap
+     * @param propToValue propToValue
+     * @param varPool varPool
+     * @throws ParseException ParseException
+     */
+    public static void convertVarPoolToMap(Map<String, Object> propToValue, String varPool) throws ParseException {
+        if (varPool == null) {
+            return;
+        }
+        String[] splits = varPool.split(""\\$guyinyou\\$"");","[{'comment': ""Please replace with another separator here, don't use your name."", 'commenter': 'simon824'}]"
3659,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/utils/VarPoolUtilsTest.java,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.utils;
+","[{'comment': 'Keep this test class path consistent with the original class', 'commenter': 'simon824'}]"
3659,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/python/PythonTask.java,"@@ -38,103 +38,110 @@
  */
 public class PythonTask extends AbstractTask {
 
-  /**
-   *  python parameters
-   */
-  private PythonParameters pythonParameters;
-
-  /**
-   *  task dir
-   */
-  private String taskDir;
-
-  /**
-   * python command executor
-   */
-  private PythonCommandExecutor pythonCommandExecutor;
-
-  /**
-   * taskExecutionContext
-   */
-  private TaskExecutionContext taskExecutionContext;
-
-  /**
-   * constructor
-   * @param taskExecutionContext taskExecutionContext
-   * @param logger    logger
-   */
-  public PythonTask(TaskExecutionContext taskExecutionContext, Logger logger) {
-    super(taskExecutionContext, logger);
-    this.taskExecutionContext = taskExecutionContext;
-
-    this.pythonCommandExecutor = new PythonCommandExecutor(this::logHandle,
-            taskExecutionContext,
-            logger);
-  }
-
-  @Override
-  public void init() {
-    logger.info(""python task params {}"", taskExecutionContext.getTaskParams());
-
-    pythonParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), PythonParameters.class);
-
-    if (!pythonParameters.checkParameters()) {
-      throw new RuntimeException(""python task params is not valid"");
+    /**
+     *  python parameters
+     */
+    private PythonParameters pythonParameters;
+
+    /**
+     *    task dir
+     */
+    private String taskDir;
+
+    /**
+     * python command executor
+     */
+    private PythonCommandExecutor pythonCommandExecutor;
+
+    /**
+     * taskExecutionContext
+     */
+    private TaskExecutionContext taskExecutionContext;
+
+    /**
+     * constructor
+     * @param taskExecutionContext taskExecutionContext
+     * @param logger        logger
+     */
+    public PythonTask(TaskExecutionContext taskExecutionContext, Logger logger) {
+        super(taskExecutionContext, logger);
+        this.taskExecutionContext = taskExecutionContext;
+
+        this.pythonCommandExecutor = new PythonCommandExecutor(this::logHandle,
+                        taskExecutionContext,
+                        logger);
     }
-  }
 
-  @Override
-  public void handle() throws Exception {
-    try {
-      //  construct process
-      CommandExecuteResult commandExecuteResult = pythonCommandExecutor.run(buildCommand());
+    @Override
+    public void init() {
+        logger.info(""python task params {}"", taskExecutionContext.getTaskParams());
 
-      setExitStatusCode(commandExecuteResult.getExitStatusCode());
-      setAppIds(commandExecuteResult.getAppIds());
-      setProcessId(commandExecuteResult.getProcessId());
-    }
-    catch (Exception e) {
-      logger.error(""python task failure"", e);
-      setExitStatusCode(Constants.EXIT_CODE_FAILURE);
-      throw e;
-    }
-  }
-
-  @Override
-  public void cancelApplication(boolean cancelApplication) throws Exception {
-    // cancel process
-    pythonCommandExecutor.cancelApplication();
-  }
-
-  /**
-   * build command
-   * @return raw python script
-   * @throws Exception exception
-   */
-  private String buildCommand() throws Exception {
-    String rawPythonScript = pythonParameters.getRawScript().replaceAll(""\\r\\n"", ""\n"");
-
-    // replace placeholder
-    Map<String, Property> paramsMap = ParamUtils.convert(ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams()),
-            taskExecutionContext.getDefinedParams(),
-            pythonParameters.getLocalParametersMap(),
-            CommandType.of(taskExecutionContext.getCmdTypeIfComplement()),
-            taskExecutionContext.getScheduleTime());
-    if (paramsMap != null){
-      rawPythonScript = ParameterUtils.convertParameterPlaceholders(rawPythonScript, ParamUtils.convert(paramsMap));
-    }
+        pythonParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), PythonParameters.class);
 
-    logger.info(""raw python script : {}"", pythonParameters.getRawScript());
-    logger.info(""task dir : {}"", taskDir);
-
-    return rawPythonScript;
-  }
+        if (!pythonParameters.checkParameters()) {
+            throw new RuntimeException(""python task params is not valid"");
+        }
+    }
 
-  @Override
-  public AbstractParameters getParameters() {
-    return pythonParameters;
-  }
+    @Override
+    public void handle() throws Exception {
+        try {
+            //    construct process
+            CommandExecuteResult commandExecuteResult = pythonCommandExecutor.run(buildCommand());
+
+            setExitStatusCode(commandExecuteResult.getExitStatusCode());
+            setAppIds(commandExecuteResult.getAppIds());
+            setProcessId(commandExecuteResult.getProcessId());
+            setVarPool(pythonCommandExecutor.getVarPool());
+        }
+        catch (Exception e) {
+            logger.error(""python task failure"", e);
+            setExitStatusCode(Constants.EXIT_CODE_FAILURE);
+            throw e;
+        }
+    }
 
+    @Override
+    public void cancelApplication(boolean cancelApplication) throws Exception {
+        // cancel process
+        pythonCommandExecutor.cancelApplication();
+    }
 
+    /**
+     * build command
+     * @return raw python script
+     * @throws Exception exception
+     */
+    private String buildCommand() throws Exception {
+        String rawPythonScript = pythonParameters.getRawScript().replaceAll(""\\r\\n"", ""\n"");
+
+        // replace placeholder
+        Map<String, Property> paramsMap = ParamUtils.convert(ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams()),
+                        taskExecutionContext.getDefinedParams(),
+                        pythonParameters.getLocalParametersMap(),
+                        CommandType.of(taskExecutionContext.getCmdTypeIfComplement()),
+                        taskExecutionContext.getScheduleTime());
+        
+        try {
+            rawPythonScript = VarPoolUtils.convertPythonScriptPlaceholders(rawPythonScript);
+        }
+        catch (StringIndexOutOfBoundsException e) {
+            // TODO: handle exception","[{'comment': 'If there is no other way to deal with this error, then you should print the error message', 'commenter': 'zixi0825'}]"
3659,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterExecThread.java,"@@ -651,14 +653,22 @@ private void setTaskNodeSkip(List<String> taskNodesSkipList){
      * submit post node
      * @param parentNodeName parent node name
      */
+    private Map<String,Object> propToValue = new ConcurrentHashMap<String, Object>();
     private void submitPostNode(String parentNodeName){
 
         List<String> submitTaskNodeList = parsePostNodeList(parentNodeName);
 
         List<TaskInstance> taskInstances = new ArrayList<>();
         for(String taskNode : submitTaskNodeList){
+            try {
+                VarPoolUtils.convertVarPoolToMap(propToValue, processInstance.getVarPool());
+            } catch (ParseException e) {
+                logger.error(""parse {} exception"", processInstance.getVarPool(), e);","[{'comment': 'only print logger here?  can you add a comment about it?', 'commenter': 'EricJoy2048'}, {'comment': ""Thank you for your proposal. I think about it carefully, but I still can't think of how to deal with the wrong situation. Moreover, under normal circumstances, varpool will only be empty or generated according to the normal format. Generally, there will be no error."", 'commenter': 'guyinyou'}, {'comment': 'Some times varpool may updated by other people in some case . So , if the value of varpool not normal and can not convert to map , you can throw a RuntimeException.', 'commenter': 'EricJoy2048'}, {'comment': ""You're right. I'll take it"", 'commenter': 'guyinyou'}]"
3659,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/task/TaskParams.java,"@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.task;
+
+import java.util.Map;
+
+public class TaskParams {
+
+    private String rawScript;
+    private Map<String, String>[] localParams;
+
+    public void setRawScript(String rawScript) {
+        this.rawScript = rawScript;
+    }
+
+    public void setLocalParams(Map<String, String>[] localParams) {
+        this.localParams = localParams;
+    }
+
+    public String getRawScript() {
+        return rawScript;
+    }
+
+    public void setLocalParamValue(String prop, Object value) {
+        if (localParams == null) {
+            return;
+        }
+        for (int i = 0; i < localParams.length; i++) {
+            if (localParams[i].get(""prop"").equals(prop)) {
+                localParams[i].put(""value"", (String)value);
+            }
+        }
+    }
+
+    public void setLocalParamValue(Map<String, Object> propToValue) {
+        if (localParams == null) {
+            return;
+        }
+        for (int i = 0; i < localParams.length; i++) {
+            String prop = localParams[i].get(""prop"");
+            if (propToValue.containsKey(prop)) {","[{'comment': 'propToValue may be null', 'commenter': 'EricJoy2048'}, {'comment': 'propToValue  may cause Nullpointerexception', 'commenter': 'simon824'}, {'comment': 'I have fixed that on commits ""7ca9de4""', 'commenter': 'guyinyou'}]"
3659,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterExecThread.java,"@@ -651,14 +653,23 @@ private void setTaskNodeSkip(List<String> taskNodesSkipList){
      * submit post node
      * @param parentNodeName parent node name
      */
+    private Map<String,Object> propToValue = new ConcurrentHashMap<String, Object>();
     private void submitPostNode(String parentNodeName){
 
         List<String> submitTaskNodeList = parsePostNodeList(parentNodeName);
 
         List<TaskInstance> taskInstances = new ArrayList<>();
         for(String taskNode : submitTaskNodeList){
+            try {
+                VarPoolUtils.convertVarPoolToMap(propToValue, processInstance.getVarPool());
+            } catch (ParseException e) {
+                logger.error(""parse {} exception"", processInstance.getVarPool(), e);
+                throw new RuntimeException();
+            }
+            TaskNode taskNodeObject = dag.getNode(taskNode);
+            VarPoolUtils.setTaskNodeLocalParams(taskNodeObject, propToValue);","[{'comment': 'there is bug will cause the origin param be replace by the task param,so the task will get nothing when use  taskExecutionContext.getTaskParams()', 'commenter': 'hei12138'}]"
3695,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/NetUtils.java,"@@ -227,4 +230,72 @@ private static boolean isSpecifyNetworkInterface(NetworkInterface networkInterfa
         String preferredNetworkInterface = System.getProperty(DOLPHIN_SCHEDULER_PREFERRED_NETWORK_INTERFACE);
         return Objects.equals(networkInterface.getDisplayName(), preferredNetworkInterface);
     }
+
+    private static NetworkInterface findAddress(List<NetworkInterface> validNetworkInterfaces) {
+        if (validNetworkInterfaces.isEmpty()) {
+            return null;
+        }
+        String networkPriority = PropertyUtils.getString(Constants.NETWORK_PRIORITY_STRATEGY, NETWORK_PRIORITY_DEFAULT);
+        if (NETWORK_PRIORITY_DEFAULT.equalsIgnoreCase(networkPriority)) {
+            return findAddressByDefaultPolicy(validNetworkInterfaces);
+        } else if (NETWORK_PRIORITY_INNER.equalsIgnoreCase(networkPriority)) {
+            return findInnerAddress(validNetworkInterfaces);
+        } else if (NETWORK_PRIORITY_OUTER.equalsIgnoreCase(networkPriority)) {
+            return findOuterAddress(validNetworkInterfaces);
+        } else {
+            logger.error(""There is no matching network card acquisition policy!"");
+            return null;
+        }
+    }
+
+    private static NetworkInterface findAddressByDefaultPolicy(List<NetworkInterface> validNetworkInterfaces) {
+        NetworkInterface networkInterface;
+        networkInterface = findInnerAddress(validNetworkInterfaces);
+        if (networkInterface == null) {
+            networkInterface = findOuterAddress(validNetworkInterfaces);
+            if (networkInterface == null) {
+                networkInterface = validNetworkInterfaces.get(0);
+            }
+        }
+        return networkInterface;
+    }
+
+    /**
+     * Get the Intranet IP
+     *
+     * @return If no {@link NetworkInterface} is available , return <code>null</code>
+     */
+    private static NetworkInterface findInnerAddress(List<NetworkInterface> validNetworkInterfaces) {
+
+        NetworkInterface networkInterface = null;
+        for (NetworkInterface ni : validNetworkInterfaces) {
+            Enumeration<InetAddress> address = ni.getInetAddresses();
+            while (address.hasMoreElements()) {
+                InetAddress ip = address.nextElement();
+                if (ip.isSiteLocalAddress()
+                        && !ip.isLoopbackAddress()
+                        && !ip.getHostAddress().contains("":"")) {
+                    networkInterface = ni;
+                }
+            }
+        }
+        return networkInterface;
+    }
+
+    private static NetworkInterface findOuterAddress(List<NetworkInterface> validNetworkInterfaces) {
+        NetworkInterface networkInterface = null;
+        for (NetworkInterface ni : validNetworkInterfaces) {
+            Enumeration<InetAddress> address = ni.getInetAddresses();
+            while (address.hasMoreElements()) {
+                InetAddress ip = address.nextElement();
+                if (!ip.isSiteLocalAddress()
+                        && !ip.isLoopbackAddress()
+                        && !ip.getHostAddress().contains("":"")) {
+                    networkInterface = ni;","[{'comment': 'Hi, there may be a little problem here, we need to consider the IPV6 situation,', 'commenter': 'CalvinKirs'}, {'comment': 'yes  i will support ipv6  --x:--x:--x:--x:--x:--x:--x:--x,remove  && !ip.getHostAddress().contains("":"")', 'commenter': 'felix-thinkingdata'}]"
3695,dolphinscheduler-common/src/main/resources/common.properties,"@@ -72,3 +72,7 @@ kerberos.expire.time=2
 # datasource encryption salt
 datasource.encryption.enable=false
 datasource.encryption.salt=!@#$%^&*
+
+#Network IP gets priority, default inner outer","[{'comment': '```suggestion\r\n# Network IP gets priority, default inner outer\r\n```\r\n\r\nFormat the description as the others.', 'commenter': 'yangyichao-mango'}]"
3728,sql/upgrade/1.3.3_schema/mysql/dolphinscheduler_ddl.sql,"@@ -112,4 +112,42 @@ CALL uc_dolphin_T_t_ds_resources_un();
 DROP PROCEDURE IF EXISTS uc_dolphin_T_t_ds_resources_un;
 
 
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_process_definition_A_is_parallel;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_process_definition_A_is_parallel()
+   BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_process_definition'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='is_parallel')
+   THEN
+         alter table t_ds_process_definition add is_parallel tinyint default '1' comment '0:serial,1:parallel';","[{'comment': 'why we should use the procedure to add one column?', 'commenter': 'gabrywu'}, {'comment': 'I copy old ds project sql script and modify. I look old script is use  procedure to add one column', 'commenter': '597365581'}, {'comment': 'please refer to the lastest SQL script. Because the ddl SQL will be run on different DBMS, such as MySQL,Postgresql, and so on, however, they might not support procedure.', 'commenter': 'gabrywu'}, {'comment': '@gabrywu    MySQL  script and Postgresql script is separate in bofore project design。\r\n![image](https://user-images.githubusercontent.com/62982788/93727507-0bfade80-fbee-11ea-8d81-d1636afffd7f.png)\r\n', 'commenter': '597365581'}, {'comment': '> @gabrywu MySQL script and Postgresql script is separate in bofore project design。\r\n> ![image](https://user-images.githubusercontent.com/62982788/93727507-0bfade80-fbee-11ea-8d81-d1636afffd7f.png)\r\n\r\nyou can  see  bofore ‘s  sql  script， I keep it only。  hi，你可以查看之前和现有的项目，在mysql 中，都是以存储过程来加字段的，在Postgresql 中是以函数的方式来加字段的。我仅仅是尊照项目的要求来的。而且  mysql和 Postgresql  加字段的脚本 本来就没法去共用，我看ds 项目中一直是分开维护的。', 'commenter': '597365581'}]"
3728,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/CommandMapper.xml,"@@ -19,18 +19,30 @@
 <!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd"" >
 <mapper namespace=""org.apache.dolphinscheduler.dao.mapper.CommandMapper"">
     <select id=""getOneToRun"" resultType=""org.apache.dolphinscheduler.dao.entity.Command"">
-        select command.* from t_ds_command command
-        join t_ds_process_definition definition on command.process_definition_id = definition.id
-        where definition.release_state = 1 AND definition.flag = 1
-        order by command.update_time asc
-        limit 1
+        select * from","[{'comment': 'so complex the SQL is, could you simply it?', 'commenter': 'gabrywu'}, {'comment': 'sql has simply it', 'commenter': '597365581'}]"
3734,dolphinscheduler-ui/src/js/conf/home/pages/security/pages/alarmPluginExample/_source/createWarning.vue,"@@ -0,0 +1,145 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+<template>
+  <m-popup
+          ref=""popup""
+          :ok-text=""item ? $t('Edit') : $t('Submit')""
+          :nameText=""item ? $t('Edit alarm group') : $t('Create alarm group')""
+          @ok=""_ok"">
+    <template slot=""content"">
+      <div class=""create-warning-model"">
+        <m-list-box-f>
+          <template slot=""name""><strong>*</strong>{{$t('Group Name')}}</template>
+          <template slot=""content"">
+            <x-input
+                    type=""input""
+                    v-model=""groupName""
+                    maxlength=""60""
+                    :placeholder=""$t('Please enter group name')"">
+            </x-input>
+          </template>
+        </m-list-box-f>
+        <m-list-box-f>
+          <template slot=""name""><strong>*</strong>{{$t('Group Type')}}</template>","[{'comment': 'In this feature GroupType need be delete.\r\nThe previous options for groupType were email and SMS, but in this feature, AlertGroup no longer belongs to email or SMS. AlertGroup is just a collection of instances of alert plugins. So groupType should be deleted', 'commenter': 'EricJoy2048'}]"
3734,dolphinscheduler-ui/src/js/conf/home/pages/security/pages/alarmPluginExample/_source/list.vue,"@@ -0,0 +1,224 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+<template>
+  <div class=""list-model"">
+    <!-- <div class=""table-box"">
+      <table>
+        <tr>
+          <th>
+            <span>{{$t('#')}}</span>
+          </th>
+          <th>
+            <span>{{$t('Instance type')}}</span>
+          </th>
+          <th>
+            <span>{{$t('name')}}</span>
+          </th>
+          <th>
+            <span>{{$t('Create Time')}}</span>
+          </th>
+          <th>
+            <span>{{$t('Update Time')}}</span>
+          </th>
+          <th width=""120"">
+            <span>{{$t('Operation')}}</span>
+          </th>
+        </tr>
+        <tr v-for=""(item, $index) in list"" :key=""$index"">
+          <td>
+            <span>{{parseInt(pageNo === 1 ? ($index + 1) : (($index + 1) + (pageSize * (pageNo - 1))))}}</span>
+          </td>
+          <td>
+            <span>
+              {{item.groupName}}
+            </span>
+          </td>
+          <td><span>{{item.groupType === 'EMAIL' ? `${$t('Email')}` : `${$t('SMS')}`}}</span></td>","[{'comment': 'groupType need be delete too.', 'commenter': 'EricJoy2048'}]"
3734,dolphinscheduler-ui/src/js/conf/home/router/index.js,"@@ -397,6 +397,14 @@ const router = new Router({
           meta: {
             title: `${i18n.$t('Token manage')}`
           }
+        },
+        {
+          path: '/security/Alarm-plugin-example',
+          name: 'Alarm-plugin-example',
+          component: resolve => require(['../pages/security/pages/alarmPluginExample/index'], resolve),","[{'comment': 'can you change `alarm` to `alert` ?', 'commenter': 'EricJoy2048'}, {'comment': 'Okay, because the local library is re-forked, merge first, and then I modify it together', 'commenter': 'break60'}, {'comment': 'ok ', 'commenter': 'EricJoy2048'}]"
3740,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskDelayExecManagerThread.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.worker.processor;
+
+import org.apache.dolphinscheduler.common.thread.Stopper;
+import org.apache.dolphinscheduler.server.worker.runner.TaskExecuteThread;
+
+import java.util.concurrent.DelayQueue;
+import java.util.concurrent.ExecutorService;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Manage tasks that need to be delayed
+ */
+public class TaskDelayExecManagerThread implements Runnable {","[{'comment': 'Is it better to make the TaskDelayExecManagerThread singleton?', 'commenter': 'yangyichao-mango'}, {'comment': ""I don't think it is necessary. First, this class is only used in TaskExecuteProcessor. And it holds an ExecutorService object, which means that this class needs to be initialized into different instances on different occasions. So instances of this class do not need to be globally unique."", 'commenter': 'vanilla111'}]"
3746,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/TaskManager.java,"@@ -69,8 +74,9 @@ public static AbstractTask newTask(TaskExecutionContext taskExecutionContext, Lo
             case SQOOP:
                 return new SqoopTask(taskExecutionContext, logger);
             default:
-                logger.error(""unsupport task type: {}"", taskExecutionContext.getTaskType());
-                throw new IllegalArgumentException(""not support task type"");
+                String msg = String.format(""not support task type: %s"", taskExecutionContext.getTaskType());","[{'comment': 'it will be better to use log pattern，not string format.', 'commenter': 'yangyichao-mango'}, {'comment': 'done', 'commenter': 'zhuangchong'}]"
3746,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/TaskParametersUtils.java,"@@ -55,41 +55,42 @@ private TaskParametersUtils() {
      * @return task parameters
      */
     public static AbstractParameters getParameters(String taskType, String parameter) {
-        try {
-            switch (EnumUtils.getEnum(TaskType.class, taskType)) {
-                case SUB_PROCESS:
-                    return JSONUtils.parseObject(parameter, SubProcessParameters.class);
-                case SHELL:
-                case WATERDROP:
-                    return JSONUtils.parseObject(parameter, ShellParameters.class);
-                case PROCEDURE:
-                    return JSONUtils.parseObject(parameter, ProcedureParameters.class);
-                case SQL:
-                    return JSONUtils.parseObject(parameter, SqlParameters.class);
-                case MR:
-                    return JSONUtils.parseObject(parameter, MapreduceParameters.class);
-                case SPARK:
-                    return JSONUtils.parseObject(parameter, SparkParameters.class);
-                case PYTHON:
-                    return JSONUtils.parseObject(parameter, PythonParameters.class);
-                case DEPENDENT:
-                    return JSONUtils.parseObject(parameter, DependentParameters.class);
-                case FLINK:
-                    return JSONUtils.parseObject(parameter, FlinkParameters.class);
-                case HTTP:
-                    return JSONUtils.parseObject(parameter, HttpParameters.class);
-                case DATAX:
-                    return JSONUtils.parseObject(parameter, DataxParameters.class);
-                case CONDITIONS:
-                    return JSONUtils.parseObject(parameter, ConditionsParameters.class);
-                case SQOOP:
-                    return JSONUtils.parseObject(parameter, SqoopParameters.class);
-                default:
-                    return null;
-            }
-        } catch (Exception e) {
-            logger.error(e.getMessage(), e);
+        TaskType anEnum = EnumUtils.getEnum(TaskType.class, taskType);
+        if (anEnum == null) {
+            logger.error(""not support task type: {}"", taskType);
+            return null;","[{'comment': 'Why not throw InvalidArgumentException?', 'commenter': 'Technoboy-'}, {'comment': '> Why not throw InvalidArgumentException?\n\n+1， fail fast will be better.', 'commenter': 'yangyichao-mango'}, {'comment': 'This method is called by multiple methods in the project, which has a big impact. It still returns null according to the original logic of the method. This time, we mainly deal with the switch null pointer problem.\r\n\r\n---\r\n这个方法被项目里面多个方法调用，影响大，还是按方法原逻辑返回null,本次主要处理switch 空指针问题。', 'commenter': 'zhuangchong'}]"
3746,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/worker/task/TaskManagerTest.java,"@@ -95,9 +97,19 @@ public void testNewTask() {
         Assert.assertNotNull(TaskManager.newTask(taskExecutionContext,taskLogger));
         taskExecutionContext.setTaskType(""SQOOP"");
         Assert.assertNotNull(TaskManager.newTask(taskExecutionContext,taskLogger));
-        //taskExecutionContext.setTaskType(null);
-        //Assert.assertNull(TaskManager.newTask(taskExecutionContext,taskLogger));
-        //taskExecutionContext.setTaskType(""XXX"");
-        //Assert.assertNotNull(TaskManager.newTask(taskExecutionContext,taskLogger));
+        try {
+            taskExecutionContext.setTaskType(null);
+            TaskManager.newTask(taskExecutionContext,taskLogger);
+        } catch (Exception e) {
+            logger.error(e.getMessage());
+        }
+
+        try {
+            taskExecutionContext.setTaskType(""XXX"");","[{'comment': 'The best practice for this should be @Test(expected= IllegalArgumentException.class)', 'commenter': 'Technoboy-'}, {'comment': 'done', 'commenter': 'zhuangchong'}]"
3846,ambari_plugin/common-services/DOLPHIN/1.3.0/package/scripts/dolphin_api_service.py,"@@ -45,10 +45,6 @@ def start(self, env):
         init_cmd=format(""sh "" + params.dolphin_home + ""/script/create-dolphinscheduler.sh"")
         Execute(init_cmd, user=params.dolphin_user)
 
-        #upgrade
-        upgrade_cmd=format(""sh "" + params.dolphin_home + ""/script/upgrade-dolphinscheduler.sh"")","[{'comment': 'I think the problem is in the schema file. Not here.\r\nIn order to ensure that the table structure metadata is up to date, we need to execute the upgrade-dolphinscheduler.sh script at startup. This script will automatically check the current version number and execute the corresponding upgrade sql file.\r\n\r\nTherefore, we require that the sql file in the schema must meet the ability of repeatable execution.\r\nIn order to achieve this goal, if we need to create the table t_ds_process_definition_version, then we should use \r\n\r\n```\r\ncreate table IF NOT EXISTS t_ds_process_definition_version;\r\n\r\n``` \r\nor\r\n\r\n```\r\ndrop table if exists t_ds_process_definition_version;\r\ncreate table t_ds_process_definition_version;\r\n\r\n```', 'commenter': 'EricJoy2048'}, {'comment': '+1', 'commenter': 'felix-thinkingdata'}]"
3846,sql/upgrade/1.3.3_schema/mysql/dolphinscheduler_ddl.sql,"@@ -101,7 +101,7 @@ drop PROCEDURE if EXISTS ct_dolphin_T_t_ds_process_definition_version;
 delimiter d//
 CREATE PROCEDURE ct_dolphin_T_t_ds_process_definition_version()
 BEGIN
-    CREATE TABLE `t_ds_process_definition_version` (
+    CREATE TABLE IF NOT EXISTS `t_ds_process_definition_version` (","[{'comment': 'I don’t know why the author of this stored procedure wants to recreate t_ds_process_definition_version here. If this is necessary, I think it`s  better to modify it to \r\n```\r\ndrop table if exists xxx;\r\ncreate table xxx;\r\n```', 'commenter': 'EricJoy2048'}, {'comment': '> I don’t know why the author of this stored procedure wants to recreate t_ds_process_definition_version here. If this is necessary, I think it`s better to modify it to\r\n> \r\n> ```\r\n> drop table if exists xxx;\r\n> create table xxx;\r\n> ```\r\n\r\nI am a newer for dolphinscheduler. I just worry about that there store some values in this table. So I add IF NOT EXISTS.', 'commenter': 'yangruochen'}, {'comment': '@yangyichao-mango ', 'commenter': 'felix-thinkingdata'}, {'comment': ""That's fine ,Before version 1.3.3，This table does not exist.\r\n\r\n这样是可以的，这个表在1.3.3之前是不存在的。"", 'commenter': 'felix-thinkingdata'}, {'comment': ""> That's fine ,Before version 1.3.3，This table does not exist.\r\n> \r\n> 这样是可以的，这个表在1.3.3之前是不存在的。\r\n\r\nOk !"", 'commenter': 'EricJoy2048'}]"
3869,dolphinscheduler-alert-plugin/dolphinscheduler-alert-dingtalk/src/main/java/org/apache/dolphinscheduler/plugin/alert/dingtalk/DingTalkAlertChannel.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.dingtalk;
+
+import org.apache.dolphinscheduler.spi.alert.AlertChannel;
+import org.apache.dolphinscheduler.spi.alert.AlertData;
+import org.apache.dolphinscheduler.spi.alert.AlertInfo;
+import org.apache.dolphinscheduler.spi.alert.AlertResult;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * DingTalkAlertChannel
+ */
+public class DingTalkAlertChannel implements AlertChannel {
+    private static final Logger logger = LoggerFactory.getLogger(DingTalkAlertChannel.class);
+
+    @Override
+    public AlertResult process(AlertInfo alertInfo) {
+
+        AlertData alertData = alertInfo.getAlertData();
+        String alertParams = alertInfo.getAlertParams();
+        List<PluginParams> pluginParams = JSONUtils.toList(alertParams, PluginParams.class);","[{'comment': 'This lines can be replace by :\r\nMap<String, String> paramsMap = PluginParamsTransfer.getPluginParamsMap(alertParams);', 'commenter': 'EricJoy2048'}]"
3869,dolphinscheduler-alert-plugin/dolphinscheduler-alert-dingtalk/src/main/java/org/apache/dolphinscheduler/plugin/alert/dingtalk/DingTalkAlertChannel.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.dingtalk;
+
+import org.apache.dolphinscheduler.spi.alert.AlertChannel;
+import org.apache.dolphinscheduler.spi.alert.AlertData;
+import org.apache.dolphinscheduler.spi.alert.AlertInfo;
+import org.apache.dolphinscheduler.spi.alert.AlertResult;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * DingTalkAlertChannel
+ */
+public class DingTalkAlertChannel implements AlertChannel {
+    private static final Logger logger = LoggerFactory.getLogger(DingTalkAlertChannel.class);
+
+    @Override
+    public AlertResult process(AlertInfo alertInfo) {
+
+        AlertData alertData = alertInfo.getAlertData();
+        String alertParams = alertInfo.getAlertParams();
+        List<PluginParams> pluginParams = JSONUtils.toList(alertParams, PluginParams.class);
+        Map<String, String> paramsMap = new HashMap<>();
+        for (PluginParams param : pluginParams) {
+            paramsMap.put(param.getName(), param.getValue().toString());
+        }
+        AlertResult alertResult = new AlertResult();
+        alertResult.setStatus(Boolean.toString(Boolean.TRUE));
+        DingTalkSender dingTalkSender = new DingTalkSender(paramsMap);
+        try {
+            dingTalkSender.sendDingTalkMsg(alertData.getTitle(), alertData.getContent());
+        } catch (IOException e) {
+            alertResult.setStatus(Boolean.toString(Boolean.FALSE));
+            logger.error(e.getMessage(), e);","[{'comment': 'I think we need add the message to AlertResult when send message failed.\r\nYou can add it by `alertResult.setMessage()`\r\n', 'commenter': 'EricJoy2048'}, {'comment': 'Thank you for your suggestion. I will judge the response parameters of DingTalk.', 'commenter': 'CalvinKirs'}]"
3869,dolphinscheduler-alert-plugin/dolphinscheduler-alert-dingtalk/src/main/java/org/apache/dolphinscheduler/plugin/alert/dingtalk/DingTalkAlertChannelFactory.java,"@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.dingtalk;
+
+import org.apache.dolphinscheduler.spi.alert.AlertChannel;
+import org.apache.dolphinscheduler.spi.alert.AlertChannelFactory;
+import org.apache.dolphinscheduler.spi.params.InputParam;
+import org.apache.dolphinscheduler.spi.params.PasswordParam;
+import org.apache.dolphinscheduler.spi.params.RadioParam;
+import org.apache.dolphinscheduler.spi.params.base.ParamsOptions;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.params.base.Validate;
+
+import java.util.Arrays;
+import java.util.List;
+
+/**
+ * DingTalkAlertChannelFactory
+ */
+public class DingTalkAlertChannelFactory implements AlertChannelFactory {
+    @Override
+    public String getName() {
+        return ""ding talk alert"";
+    }
+
+    @Override
+    public List<PluginParams> getParams() {
+        InputParam webHookParam = InputParam.newBuilder(DingTalkParamsConstants.NAME_DING_TALK_WEB_HOOK, DingTalkParamsConstants.DING_TALK_WEB_HOOK)
+            .addValidate(Validate.newBuilder()
+                .setRequired(true)
+                .build())
+            .build();
+        InputParam keywordParam = InputParam.newBuilder(DingTalkParamsConstants.NAME_DING_TALK_KEYWORD, DingTalkParamsConstants.DING_TALK_KEYWORD)
+            .addValidate(Validate.newBuilder()
+                .setRequired(true)
+                .build())
+            .build();
+        RadioParam isEnableProxy =
+            RadioParam.newBuilder(DingTalkParamsConstants.NAME_DING_TALK_PROXY_ENABLE, DingTalkParamsConstants.NAME_DING_TALK_PROXY_ENABLE)
+                .addParamsOptions(new ParamsOptions(""NO"", false, false))","[{'comment': 'RadioParam need two options, you only gave a ""NO"" option.', 'commenter': 'EricJoy2048'}]"
3869,dolphinscheduler-alert-plugin/dolphinscheduler-alert-dingtalk/src/main/java/org/apache/dolphinscheduler/plugin/alert/dingtalk/DingTalkSender.java,"@@ -0,0 +1,205 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.dingtalk;
+
+import org.apache.dolphinscheduler.spi.alert.AlertResult;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.codec.binary.StringUtils;
+import org.apache.http.HttpEntity;
+import org.apache.http.HttpHost;
+import org.apache.http.auth.AuthScope;
+import org.apache.http.auth.UsernamePasswordCredentials;
+import org.apache.http.client.CredentialsProvider;
+import org.apache.http.client.config.RequestConfig;
+import org.apache.http.client.methods.CloseableHttpResponse;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.impl.client.BasicCredentialsProvider;
+import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.impl.client.HttpClients;
+import org.apache.http.util.EntityUtils;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Ding Talk Sender
+ */
+public class DingTalkSender {
+    private static final Logger logger = LoggerFactory.getLogger(DingTalkSender.class);
+
+    private String url;
+
+    private String keyword;
+
+    private Boolean enableProxy;
+
+    private String proxy;
+
+    private Integer port;
+
+    private String user;
+
+    private String password;
+
+    DingTalkSender(Map<String, String> config) {
+        url = config.get(DingTalkParamsConstants.NAME_DING_TALK_WEB_HOOK);
+        keyword = config.get(DingTalkParamsConstants.NAME_DING_TALK_KEYWORD);
+        enableProxy = Boolean.valueOf(config.get(DingTalkParamsConstants.NAME_DING_TALK_PROXY_ENABLE));
+        if (Boolean.TRUE.equals(enableProxy)) {
+            port = Integer.parseInt(config.get(DingTalkParamsConstants.NAME_DING_TALK_PORT));
+            proxy = config.get(DingTalkParamsConstants.NAME_DING_TALK_PROXY);
+            user = config.get(DingTalkParamsConstants.DING_TALK_USER);
+            password = config.get(DingTalkParamsConstants.NAME_DING_TALK_PASSWORD);
+        }
+
+    }
+
+    public AlertResult sendDingTalkMsg(String msg, String charset) {
+        AlertResult alertResult;
+        try {
+            String resp = sendMsg(msg, charset);
+            return checkSendDingTalkSendMsgResult(resp);
+        } catch (Exception e) {
+            logger.info(""send ding talk alert msg  exception : {}"", e.getMessage());
+            alertResult = new AlertResult();
+            alertResult.setStatus(""false"");
+            alertResult.setMessage(""send ding talk alert fail."");
+        }
+        return alertResult;
+    }
+
+    private String sendMsg(String msg, String charset) throws IOException {
+
+        String msgToJson = textToJsonString(msg + ""#"" + keyword);
+        HttpPost httpPost = constructHttpPost(url, msgToJson, charset);
+
+        CloseableHttpClient httpClient;
+        if (Boolean.TRUE.equals(enableProxy)) {
+            httpClient = getProxyClient(proxy, port, user, password);
+            RequestConfig rcf = getProxyConfig(proxy, port);
+            httpPost.setConfig(rcf);
+        } else {
+            httpClient = getDefaultClient();
+        }
+
+        try {
+            CloseableHttpResponse response = httpClient.execute(httpPost);
+            String resp;
+            try {
+                HttpEntity entity = response.getEntity();
+                resp = EntityUtils.toString(entity, charset);
+                EntityUtils.consume(entity);
+            } finally {
+                response.close();
+            }
+            logger.info(""Ding Talk send [%s], resp:{%s}"", msg, resp);
+            return resp;
+        } finally {
+            httpClient.close();
+        }
+    }
+
+    private static HttpPost constructHttpPost(String url, String msg, String charset) {
+        HttpPost post = new HttpPost(url);
+        StringEntity entity = new StringEntity(msg, charset);
+        post.setEntity(entity);
+        post.addHeader(""Content-Type"", ""application/json; charset=utf-8"");
+        return post;
+    }
+
+    private static CloseableHttpClient getProxyClient(String proxy, int port, String user, String password) {
+        HttpHost httpProxy = new HttpHost(proxy, port);
+        CredentialsProvider provider = new BasicCredentialsProvider();
+        provider.setCredentials(new AuthScope(httpProxy), new UsernamePasswordCredentials(user, password));
+        return HttpClients.custom().setDefaultCredentialsProvider(provider).build();
+    }
+
+    private static CloseableHttpClient getDefaultClient() {
+        return HttpClients.createDefault();
+    }
+
+    private static RequestConfig getProxyConfig(String proxy, int port) {
+        HttpHost httpProxy = new HttpHost(proxy, port);
+        return RequestConfig.custom().setProxy(httpProxy).build();
+    }
+
+    private static String textToJsonString(String text) {
+        Map<String, Object> items = new HashMap<>();
+        items.put(""msgtype"", ""text"");
+        Map<String, String> textContent = new HashMap<>();
+        byte[] byt = StringUtils.getBytesUtf8(text);
+        String txt = StringUtils.newStringUtf8(byt);
+        textContent.put(""content"", txt);
+        items.put(""text"", textContent);
+        return JSONUtils.toJsonString(items);
+    }
+
+    public static class DingTalkSendMsgResponse {
+        private Integer errcode;
+        private String errmsg;
+
+        public Integer getErrcode() {
+            return errcode;
+        }
+
+        public void setErrcode(Integer errcode) {
+            this.errcode = errcode;
+        }
+
+        public String getErrmsg() {
+            return errmsg;
+        }
+
+        public void setErrmsg(String errmsg) {
+            this.errmsg = errmsg;
+        }
+    }
+
+    private static AlertResult checkSendDingTalkSendMsgResult(String result) {
+        AlertResult alertResult = new AlertResult();
+        alertResult.setStatus(""false"");
+
+        if (null == result) {
+            alertResult.setMessage(""we chat alert send error"");","[{'comment': 'wechat alert ? ', 'commenter': 'EricJoy2048'}]"
3869,dolphinscheduler-alert-plugin/dolphinscheduler-alert-dingtalk/src/main/java/org/apache/dolphinscheduler/plugin/alert/dingtalk/DingTalkSender.java,"@@ -0,0 +1,205 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.dingtalk;
+
+import org.apache.dolphinscheduler.spi.alert.AlertResult;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.codec.binary.StringUtils;
+import org.apache.http.HttpEntity;
+import org.apache.http.HttpHost;
+import org.apache.http.auth.AuthScope;
+import org.apache.http.auth.UsernamePasswordCredentials;
+import org.apache.http.client.CredentialsProvider;
+import org.apache.http.client.config.RequestConfig;
+import org.apache.http.client.methods.CloseableHttpResponse;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.impl.client.BasicCredentialsProvider;
+import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.impl.client.HttpClients;
+import org.apache.http.util.EntityUtils;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Ding Talk Sender
+ */
+public class DingTalkSender {
+    private static final Logger logger = LoggerFactory.getLogger(DingTalkSender.class);
+
+    private String url;
+
+    private String keyword;
+
+    private Boolean enableProxy;
+
+    private String proxy;
+
+    private Integer port;
+
+    private String user;
+
+    private String password;
+
+    DingTalkSender(Map<String, String> config) {
+        url = config.get(DingTalkParamsConstants.NAME_DING_TALK_WEB_HOOK);
+        keyword = config.get(DingTalkParamsConstants.NAME_DING_TALK_KEYWORD);
+        enableProxy = Boolean.valueOf(config.get(DingTalkParamsConstants.NAME_DING_TALK_PROXY_ENABLE));
+        if (Boolean.TRUE.equals(enableProxy)) {
+            port = Integer.parseInt(config.get(DingTalkParamsConstants.NAME_DING_TALK_PORT));
+            proxy = config.get(DingTalkParamsConstants.NAME_DING_TALK_PROXY);
+            user = config.get(DingTalkParamsConstants.DING_TALK_USER);
+            password = config.get(DingTalkParamsConstants.NAME_DING_TALK_PASSWORD);
+        }
+
+    }
+
+    public AlertResult sendDingTalkMsg(String msg, String charset) {
+        AlertResult alertResult;
+        try {
+            String resp = sendMsg(msg, charset);
+            return checkSendDingTalkSendMsgResult(resp);
+        } catch (Exception e) {
+            logger.info(""send ding talk alert msg  exception : {}"", e.getMessage());
+            alertResult = new AlertResult();
+            alertResult.setStatus(""false"");
+            alertResult.setMessage(""send ding talk alert fail."");
+        }
+        return alertResult;
+    }
+
+    private String sendMsg(String msg, String charset) throws IOException {
+
+        String msgToJson = textToJsonString(msg + ""#"" + keyword);
+        HttpPost httpPost = constructHttpPost(url, msgToJson, charset);
+
+        CloseableHttpClient httpClient;
+        if (Boolean.TRUE.equals(enableProxy)) {
+            httpClient = getProxyClient(proxy, port, user, password);
+            RequestConfig rcf = getProxyConfig(proxy, port);
+            httpPost.setConfig(rcf);
+        } else {
+            httpClient = getDefaultClient();
+        }
+
+        try {
+            CloseableHttpResponse response = httpClient.execute(httpPost);
+            String resp;
+            try {
+                HttpEntity entity = response.getEntity();
+                resp = EntityUtils.toString(entity, charset);
+                EntityUtils.consume(entity);
+            } finally {
+                response.close();
+            }
+            logger.info(""Ding Talk send [%s], resp:{%s}"", msg, resp);
+            return resp;
+        } finally {
+            httpClient.close();
+        }
+    }
+
+    private static HttpPost constructHttpPost(String url, String msg, String charset) {
+        HttpPost post = new HttpPost(url);
+        StringEntity entity = new StringEntity(msg, charset);
+        post.setEntity(entity);
+        post.addHeader(""Content-Type"", ""application/json; charset=utf-8"");
+        return post;
+    }
+
+    private static CloseableHttpClient getProxyClient(String proxy, int port, String user, String password) {
+        HttpHost httpProxy = new HttpHost(proxy, port);
+        CredentialsProvider provider = new BasicCredentialsProvider();
+        provider.setCredentials(new AuthScope(httpProxy), new UsernamePasswordCredentials(user, password));
+        return HttpClients.custom().setDefaultCredentialsProvider(provider).build();
+    }
+
+    private static CloseableHttpClient getDefaultClient() {
+        return HttpClients.createDefault();
+    }
+
+    private static RequestConfig getProxyConfig(String proxy, int port) {
+        HttpHost httpProxy = new HttpHost(proxy, port);
+        return RequestConfig.custom().setProxy(httpProxy).build();
+    }
+
+    private static String textToJsonString(String text) {
+        Map<String, Object> items = new HashMap<>();
+        items.put(""msgtype"", ""text"");
+        Map<String, String> textContent = new HashMap<>();
+        byte[] byt = StringUtils.getBytesUtf8(text);
+        String txt = StringUtils.newStringUtf8(byt);
+        textContent.put(""content"", txt);
+        items.put(""text"", textContent);
+        return JSONUtils.toJsonString(items);
+    }
+
+    public static class DingTalkSendMsgResponse {
+        private Integer errcode;
+        private String errmsg;
+
+        public Integer getErrcode() {
+            return errcode;
+        }
+
+        public void setErrcode(Integer errcode) {
+            this.errcode = errcode;
+        }
+
+        public String getErrmsg() {
+            return errmsg;
+        }
+
+        public void setErrmsg(String errmsg) {
+            this.errmsg = errmsg;
+        }
+    }
+
+    private static AlertResult checkSendDingTalkSendMsgResult(String result) {
+        AlertResult alertResult = new AlertResult();
+        alertResult.setStatus(""false"");
+
+        if (null == result) {
+            alertResult.setMessage(""we chat alert send error"");
+            logger.info(""send ding talk msg error,ding talk server resp is null"");
+            return alertResult;
+        }
+        DingTalkSendMsgResponse sendMsgResponse = JSONUtils.parseObject(result, DingTalkSendMsgResponse.class);
+        if (null == sendMsgResponse) {
+            alertResult.setMessage(""we chat send fail"");","[{'comment': 'we chat ?', 'commenter': 'EricJoy2048'}]"
3869,dolphinscheduler-alert-plugin/dolphinscheduler-alert-wechat/src/main/java/org/apache/dolphinscheduler/plugin/alert/wechat/WeChatAlertConstants.java,"@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.wechat;
+
+/**
+ * WeChatAlertConstants
+ */
+public class WeChatAlertConstants {
+
+    static final String MARKDOWN_QUOTE = "">"";
+
+    static final String MARKDOWN_ENTER = ""\n"";
+
+    static final String CHARSET = ""UTF-8"";
+
+    static final String WE_CHAT_PUSH_URL = ""https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token={token}"";","[{'comment': 'can we add qyapi.weixin.qq.com in apache project?', 'commenter': 'EricJoy2048'}, {'comment': 'Of course, I have confirmed this problem', 'commenter': 'CalvinKirs'}]"
3869,pom.xml,"@@ -950,6 +950,11 @@
                         <include>**/plugin/alert/email/ExcelUtilsTest.java</include>
                         <include>**/plugin/alert/email/MailUtilsTest.java</include>
                         <include>**/plugin/alert/email/template/DefaultHTMLTemplateTest.java</include>
+                        <include>**/plugin/alert/dingtalk/DingTalkSenderTest.java</include>
+                        <include>**/plugin/alert/dingtalk/DingTalkAlertChannelFactoryTest.java</include>
+                        <include>**/plugin/alert/dingtalk/DingTalkAlertChannelFactoryTest.java</include>","[{'comment': 'DingTalkAlertChannelFactoryTest.java is repeated.', 'commenter': 'EricJoy2048'}]"
3880,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessInstanceMapper.xml,"@@ -168,14 +168,14 @@
         select *
         from t_ds_process_instance
         where 1=1","[{'comment': 'Hi, 1=1 ,is it possible to delete this statement?', 'commenter': 'CalvinKirs'}, {'comment': 'thank you for reminding!\r\n""1=1"" is not necessary.', 'commenter': 'lenboo'}]"
3940,dolphinscheduler-ui/src/js/conf/home/pages/security/pages/tenement/_source/createTenement.vue,"@@ -146,13 +146,6 @@
           this.$message.warning(`${i18n.$t('Please enter name')}`)
           return false
         }
-        // Verify tenant name cannot contain special characters
-        let isSpecial = /[~#^$@%&!*()<>《》:;'""{}【】	]/gi
-        if (isSpecial.test(this.tenantName)) {
-          this.$message.warning(`${i18n.$t('Please enter tenant name without special characters')}`)
-          return false
-        }
-","[{'comment': 'why remove？', 'commenter': 'zhuangchong'}, {'comment': 'Corrected back！', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-ui/src/js/module/i18n/locale/zh_CN.js,"@@ -189,7 +189,6 @@ export default {
   Queue: 'Yarn 队列',
   'Please enter the tenant code in English': '请输入租户编码只允许英文',
   'Please enter tenant code in English': '请输入英文租户编码',
-  'Please enter tenant name without special characters': '请输入不包含特殊字符的租户名称',","[{'comment': 'why remove?', 'commenter': 'zhuangchong'}, {'comment': 'Corrected back', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-ui/src/js/module/i18n/locale/en_US.js,"@@ -187,7 +187,6 @@ export default {
   'Please select a queue': 'default is tenant association queue',
   'Please enter the tenant code in English': 'Please enter the tenant code in English',
   'Please enter tenant code in English': 'Please enter tenant code in English',
-  'Please enter tenant name without special characters': 'Please enter tenant name without special characters',","[{'comment': 'This file modification should have nothing to do with this PR.', 'commenter': 'zhuangchong'}, {'comment': 'Corrected back！', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/WorkFlowLineageMapper.xml,"@@ -24,23 +24,24 @@
         left join t_ds_schedules tes on tepd.id = tes.process_definition_id
         where tepd.project_id = #{projectId}
         <if test=""searchVal != null and searchVal != ''"">
-            and  tepd.name like concat('%', #{searchVal}, '%')
+            and tepd.name like concat('%', #{searchVal}, '%')
         </if>
     </select>
     <select id=""queryByIds"" resultType=""org.apache.dolphinscheduler.dao.entity.WorkFlowLineage"" databaseId=""mysql"">
         select tepd.id as work_flow_id,tepd.name as work_flow_name,
-               (case when json_extract(tepd.process_definition_json, '$**.dependItemList') is not null then 1 else 0 end) as is_depend_work_flow,
-                          json_extract(tepd.process_definition_json, '$**.definitionId') as source_work_flow_id,
-                          tepd.release_state as work_flow_publish_status,
-                          tes.start_time as schedule_start_time,
-                          tes.end_time as schedule_end_time,
-                          tes.crontab as crontab,
-                          tes.release_state as schedule_publish_status
+        (case when json_extract(tepd.process_definition_json, '$**.dependItemList') is not null then 1 else 0 end) as","[{'comment': 'Should keep the original format.', 'commenter': 'wen-hemin'}]"
3940,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/WorkFlowLineageMapper.xml,"@@ -24,23 +24,24 @@
         left join t_ds_schedules tes on tepd.id = tes.process_definition_id
         where tepd.project_id = #{projectId}
         <if test=""searchVal != null and searchVal != ''"">
-            and  tepd.name like concat('%', #{searchVal}, '%')
+            and tepd.name like concat('%', #{searchVal}, '%')
         </if>
     </select>
     <select id=""queryByIds"" resultType=""org.apache.dolphinscheduler.dao.entity.WorkFlowLineage"" databaseId=""mysql"">
         select tepd.id as work_flow_id,tepd.name as work_flow_name,
-               (case when json_extract(tepd.process_definition_json, '$**.dependItemList') is not null then 1 else 0 end) as is_depend_work_flow,
-                          json_extract(tepd.process_definition_json, '$**.definitionId') as source_work_flow_id,
-                          tepd.release_state as work_flow_publish_status,
-                          tes.start_time as schedule_start_time,
-                          tes.end_time as schedule_end_time,
-                          tes.crontab as crontab,
-                          tes.release_state as schedule_publish_status
+        (case when json_extract(tepd.process_definition_json, '$**.dependItemList') is not null then 1 else 0 end) as
+        is_depend_work_flow,
+        json_extract(tepd.process_definition_json, '$**.definitionId') as source_work_flow_id,
+        tepd.release_state as work_flow_publish_status,
+        tes.start_time as schedule_start_time,
+        tes.end_time as schedule_end_time,
+        tes.crontab as crontab,
+        tes.release_state as schedule_publish_status","[{'comment': 'Should keep the original format.', 'commenter': 'wen-hemin'}, {'comment': 'just remain this!', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/WorkFlowLineageMapper.xml,"@@ -49,39 +50,42 @@
 
     <select id=""queryByIds"" resultType=""org.apache.dolphinscheduler.dao.entity.WorkFlowLineage"" databaseId=""pg"">
         select a.work_flow_id,
-               a.work_flow_name,
-               a.is_depend_work_flow,
-               array_agg(a.source_id) as source_id,
-               a.work_flow_publish_status,
-               a.schedule_start_time,
-               a.schedule_end_time,
-               a.crontab,
-               a.schedule_publish_status
-         from (
-               select tepd.id as work_flow_id,tepd.name as work_flow_name,
-                      case when tepd.process_definition_json::json#>'{tasks,1,dependence}' is not null then 1 else 0 end as is_depend_work_flow,
-                      (json_array_elements(tepd.process_definition_json::json#>'{tasks}')#>>'{dependence,dependTaskList,0,dependItemList,0,definitionId}') as source_id,
-                      tepd.release_state as work_flow_publish_status,
-                      tes.start_time as schedule_start_time,
-                      tes.end_time as schedule_end_time,
-                      tes.crontab as crontab,
-                      tes.release_state as schedule_publish_status
-                 from t_ds_process_definition tepd
-                 left join t_ds_schedules tes on tepd.id = tes.process_definition_id
-                 where tepd.project_id = #{projectId}
-                 <if test=""ids != null and ids.size()>0"">
-                     and  tepd.id in
-                     <foreach collection=""ids"" index=""index"" item=""i"" open=""("" separator="","" close="")"">
-                     #{i}
-                     </foreach>
-                </if>
-             ) a
+        a.work_flow_name,
+        a.is_depend_work_flow,
+        array_agg(a.source_id) as source_id,
+        a.work_flow_publish_status,
+        a.schedule_start_time,
+        a.schedule_end_time,
+        a.crontab,
+        a.schedule_publish_status
+        from (
+        select tepd.id as work_flow_id,tepd.name as work_flow_name,
+        case when tepd.process_definition_json::json#>'{tasks,1,dependence}' is not null then 1 else 0 end as
+        is_depend_work_flow,
+        (json_array_elements(tepd.process_definition_json::json#>'{tasks}')#>>'{dependence,dependTaskList,0,dependItemList,0,definitionId}')
+        as source_id,
+        tepd.release_state as work_flow_publish_status,
+        tes.start_time as schedule_start_time,
+        tes.end_time as schedule_end_time,
+        tes.crontab as crontab,
+        tes.release_state as schedule_publish_status
+        from t_ds_process_definition tepd
+        left join t_ds_schedules tes on tepd.id = tes.process_definition_id
+        where tepd.project_id = #{projectId}
+        <if test=""ids != null and ids.size()>0"">
+            and tepd.id in
+            <foreach collection=""ids"" index=""index"" item=""i"" open=""("" separator="","" close="")"">
+                #{i}
+            </foreach>
+        </if>
+        ) a","[{'comment': 'Should keep the original format.', 'commenter': 'wen-hemin'}, {'comment': 'just remain this!', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/WorkFlowLineageMapper.xml,"@@ -49,39 +50,42 @@
 
     <select id=""queryByIds"" resultType=""org.apache.dolphinscheduler.dao.entity.WorkFlowLineage"" databaseId=""pg"">
         select a.work_flow_id,
-               a.work_flow_name,
-               a.is_depend_work_flow,
-               array_agg(a.source_id) as source_id,
-               a.work_flow_publish_status,
-               a.schedule_start_time,
-               a.schedule_end_time,
-               a.crontab,
-               a.schedule_publish_status
-         from (
-               select tepd.id as work_flow_id,tepd.name as work_flow_name,
-                      case when tepd.process_definition_json::json#>'{tasks,1,dependence}' is not null then 1 else 0 end as is_depend_work_flow,
-                      (json_array_elements(tepd.process_definition_json::json#>'{tasks}')#>>'{dependence,dependTaskList,0,dependItemList,0,definitionId}') as source_id,
-                      tepd.release_state as work_flow_publish_status,
-                      tes.start_time as schedule_start_time,
-                      tes.end_time as schedule_end_time,
-                      tes.crontab as crontab,
-                      tes.release_state as schedule_publish_status
-                 from t_ds_process_definition tepd
-                 left join t_ds_schedules tes on tepd.id = tes.process_definition_id
-                 where tepd.project_id = #{projectId}
-                 <if test=""ids != null and ids.size()>0"">
-                     and  tepd.id in
-                     <foreach collection=""ids"" index=""index"" item=""i"" open=""("" separator="","" close="")"">
-                     #{i}
-                     </foreach>
-                </if>
-             ) a
+        a.work_flow_name,
+        a.is_depend_work_flow,
+        array_agg(a.source_id) as source_id,
+        a.work_flow_publish_status,
+        a.schedule_start_time,
+        a.schedule_end_time,
+        a.crontab,
+        a.schedule_publish_status
+        from (
+        select tepd.id as work_flow_id,tepd.name as work_flow_name,
+        case when tepd.process_definition_json::json#>'{tasks,1,dependence}' is not null then 1 else 0 end as
+        is_depend_work_flow,
+        (json_array_elements(tepd.process_definition_json::json#>'{tasks}')#>>'{dependence,dependTaskList,0,dependItemList,0,definitionId}')
+        as source_id,
+        tepd.release_state as work_flow_publish_status,
+        tes.start_time as schedule_start_time,
+        tes.end_time as schedule_end_time,
+        tes.crontab as crontab,
+        tes.release_state as schedule_publish_status
+        from t_ds_process_definition tepd
+        left join t_ds_schedules tes on tepd.id = tes.process_definition_id
+        where tepd.project_id = #{projectId}
+        <if test=""ids != null and ids.size()>0"">
+            and tepd.id in
+            <foreach collection=""ids"" index=""index"" item=""i"" open=""("" separator="","" close="")"">
+                #{i}
+            </foreach>
+        </if>
+        ) a
         where (a.is_depend_work_flow = 1 and source_id is not null) or (a.is_depend_work_flow = 0)
         group by a.work_flow_id,a.work_flow_name,a.is_depend_work_flow,a.work_flow_publish_status,a.schedule_start_time,
-                 a.schedule_end_time,a.crontab,a.schedule_publish_status
+        a.schedule_end_time,a.crontab,a.schedule_publish_status","[{'comment': 'Should keep the original format.', 'commenter': 'wen-hemin'}, {'comment': 'just remain this!', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-ui/src/js/conf/home/pages/security/pages/tenement/_source/createTenement.vue,"@@ -1,36 +1,36 @@
 /*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
+* Licensed to the Apache Software Foundation (ASF) under one or more
+* contributor license agreements.  See the NOTICE file distributed with
+* this work for additional information regarding copyright ownership.
+* The ASF licenses this file to You under the Apache License, Version 2.0
+* (the ""License""); you may not use this file except in compliance with
+* the License.  You may obtain a copy of the License at
+*
+*    http://www.apache.org/licenses/LICENSE-2.0
+*
+* Unless required by applicable law or agreed to in writing, software
+* distributed under the License is distributed on an ""AS IS"" BASIS,
+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+* See the License for the specific language governing permissions and
+* limitations under the License.
+*/","[{'comment': 'Should keep the original format.', 'commenter': 'wen-hemin'}, {'comment': 'Just remain this!', 'commenter': 'hermeshephaestus'}]"
3940,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml,"@@ -50,23 +72,29 @@
         order by p.create_time desc
     </select>
     <select id=""queryAuthedProjectListByUserId"" resultType=""org.apache.dolphinscheduler.dao.entity.Project"">
-        select p.*
+        select
+        <include refid=""baseSqlV2"">
+            <property name=""alias"" value=""p""/>
+        </include>
+        ,","[{'comment': 'sql Grammar mistakes', 'commenter': 'felix-thinkingdata'}]"
3957,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/VarPoolUtils.java,"@@ -62,11 +39,20 @@ public static void setTaskNodeLocalParams(TaskNode taskNode, String prop, Object
      */
     public static void setTaskNodeLocalParams(TaskNode taskNode, Map<String, Object> propToValue) {
         String taskParamsJson = taskNode.getParams();
-        TaskParams taskParams = JSONUtils.parseObject(taskParamsJson, TaskParams.class);
-        if (taskParams == null) {
-            return;
+        Map<String,Object> taskParams = JSONUtils.parseObject(taskParamsJson, HashMap.class);
+
+        Object localParamsObject = taskParams.get(LOCALPARAMS);
+        if (null != localParamsObject && null != propToValue && propToValue.size() > 0) {
+            ArrayList<Object> localParams = (ArrayList)localParamsObject;","[{'comment': ' no need to use list', 'commenter': 'CalvinKirs'}]"
4013,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/JSONUtils.java,"@@ -253,6 +268,24 @@ public static String toJsonString(Object object) {
         }
     }
 
+    /**
+     * serialize to json byte
+     *
+     * @param obj object
+     * @param <T> object type
+     * @return byte array
+     */
+    public static <T> byte[] toJsonByteArray(T obj)  {
+        String json = """";","[{'comment': 'Here should be a null operation on obj.', 'commenter': 'CalvinKirs'}, {'comment': 'done.', 'commenter': 'zhuangchong'}]"
4042,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/ProcessUtils.java,"@@ -38,368 +41,385 @@
 import java.util.regex.Pattern;
 
 /**
- *  mainly used to get the start command line of a process.
+ * mainly used to get the start command line of a process.
  */
 public class ProcessUtils {
-  /**
-   * logger.
-   */
-  private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
-
-  /**
-   * Initialization regularization, solve the problem of pre-compilation performance,
-   * avoid the thread safety problem of multi-thread operation.
-   */
-  private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
-
-  private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
-
-  /**
-   * build command line characters.
-   * @param commandList command list
-   * @return command
-   */
-  public static String buildCommandStr(List<String> commandList) {
-    String cmdstr;
-    String[] cmd = commandList.toArray(new String[commandList.size()]);
-    SecurityManager security = System.getSecurityManager();
-    boolean allowAmbiguousCommands = false;
-    if (security == null) {
-      allowAmbiguousCommands = true;
-      String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
-      if (value != null) {
-        allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
-      }
-    }
-    if (allowAmbiguousCommands) {
+    /**
+     * logger.
+     */
+    private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
+
+    /**
+     * Initialization regularization, solve the problem of pre-compilation performance,
+     * avoid the thread safety problem of multi-thread operation.
+     */
+    private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
+
+    private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
+
+    /**
+     * build command line characters.
+     *
+     * @param commandList command list
+     * @return command
+     */
+    public static String buildCommandStr(List<String> commandList) {
+        String cmdstr;
+        String[] cmd = commandList.toArray(new String[0]);
+        SecurityManager security = System.getSecurityManager();
+        boolean allowAmbiguousCommands = false;
+        if (security == null) {
+            allowAmbiguousCommands = true;
+            String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
+            if (value != null) {
+                allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
+            }
+        }
+        if (allowAmbiguousCommands) {
 
-      String executablePath = new File(cmd[0]).getPath();
+            String executablePath = new File(cmd[0]).getPath();
 
-      if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
-        executablePath = quoteString(executablePath);
-      }
+            if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
+                executablePath = quoteString(executablePath);
+            }
 
-      cmdstr = createCommandLine(
-              VERIFICATION_LEGACY, executablePath, cmd);
-    } else {
-      String executablePath;
-      try {
-        executablePath = getExecutablePath(cmd[0]);
-      } catch (IllegalArgumentException e) {
+            cmdstr = createCommandLine(
+                VERIFICATION_LEGACY, executablePath, cmd);
+        } else {
+            String executablePath;
+            try {
+                executablePath = getExecutablePath(cmd[0]);
+            } catch (IllegalArgumentException e) {
 
-        StringBuilder join = new StringBuilder();
-        for (String s : cmd) {
-          join.append(s).append(' ');
-        }
+                StringBuilder join = new StringBuilder();
+                for (String s : cmd) {
+                    join.append(s).append(' ');
+                }
 
-        cmd = getTokensFromCommand(join.toString());
-        executablePath = getExecutablePath(cmd[0]);
+                cmd = getTokensFromCommand(join.toString());
+                executablePath = getExecutablePath(cmd[0]);
 
-        // Check new executable name once more
-        if (security != null) {
-          security.checkExec(executablePath);
-        }
-      }
+                // Check new executable name once more
+                if (security != null) {
+                    security.checkExec(executablePath);
+                }
+            }
 
-      cmdstr = createCommandLine(
+            cmdstr = createCommandLine(
 
-              isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
-    }
-    return cmdstr;
-  }
-
-  /**
-   * get executable path.
-   *
-   * @param path path
-   * @return executable path
-   */
-  private static String getExecutablePath(String path) {
-    boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
-
-    File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
-    return fileToRun.getPath();
-  }
-
-  /**
-   * whether is shell file.
-   *
-   * @param executablePath executable path
-   * @return true if endsWith .CMD or .BAT
-   */
-  private static boolean isShellFile(String executablePath) {
-    String upPath = executablePath.toUpperCase();
-    return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
-  }
-
-  /**
-   * quote string.
-   *
-   * @param arg argument
-   * @return format arg
-   */
-  private static String quoteString(String arg) {
-    StringBuilder argbuf = new StringBuilder(arg.length() + 2);
-    return argbuf.append('""').append(arg).append('""').toString();
-  }
-
-  /**
-   * get tokens from command.
-   *
-   * @param command command
-   * @return token string array
-   */
-  private static String[] getTokensFromCommand(String command) {
-    ArrayList<String> matchList = new ArrayList<>(8);
-    Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
-    while (regexMatcher.find()) {
-      matchList.add(regexMatcher.group());
-    }
-    return matchList.toArray(new String[matchList.size()]);
-  }
-
-  /**
-   * Lazy Pattern.
-   */
-  private static class LazyPattern {
-    // Escape-support version:
-    // ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
-    private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
-  }
-
-  /**
-   * verification cmd bat.
-   */
-  private static final int VERIFICATION_CMD_BAT = 0;
-
-  /**
-   * verification win32.
-   */
-  private static final int VERIFICATION_WIN32 = 1;
-
-  /**
-   * verification legacy.
-   */
-  private static final int VERIFICATION_LEGACY = 2;
-
-  /**
-   * escape verification.
-   */
-  private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
-
-    {' ', '\t', '<', '>'}, {' ', '\t'}};
-
-  /**
-   * create command line.
-   * @param verificationType  verification type
-   * @param executablePath    executable path
-   * @param cmd               cmd
-   * @return command line
-   */
-  private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
-    StringBuilder cmdbuf = new StringBuilder(80);
-
-    cmdbuf.append(executablePath);
-
-    for (int i = 1; i < cmd.length; ++i) {
-      cmdbuf.append(' ');
-      String s = cmd[i];
-      if (needsEscaping(verificationType, s)) {
-        cmdbuf.append('""').append(s);
-
-        if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
-          cmdbuf.append('\\');
+                isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
         }
-        cmdbuf.append('""');
-      } else {
-        cmdbuf.append(s);
-      }
+        return cmdstr;
     }
-    return cmdbuf.toString();
-  }
-
-  /**
-   * whether is quoted.
-   * @param noQuotesInside
-   * @param arg
-   * @param errorMessage
-   * @return boolean
-   */
-  private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
-    int lastPos = arg.length() - 1;
-    if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
-      // The argument has already been quoted.
-      if (noQuotesInside) {
-        if (arg.indexOf('""', 1) != lastPos) {
-          // There is [""] inside.
-          throw new IllegalArgumentException(errorMessage);
-        }
-      }
-      return true;
+
+    /**
+     * get executable path.
+     *
+     * @param path path
+     * @return executable path
+     */
+    private static String getExecutablePath(String path) {
+        boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
+
+        File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
+        return fileToRun.getPath();
     }
-    if (noQuotesInside) {
-      if (arg.indexOf('""') >= 0) {
-        // There is [""] inside.
-        throw new IllegalArgumentException(errorMessage);
-      }
+
+    /**
+     * whether is shell file.
+     *
+     * @param executablePath executable path
+     * @return true if endsWith .CMD or .BAT
+     */
+    private static boolean isShellFile(String executablePath) {
+        String upPath = executablePath.toUpperCase();
+        return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
     }
-    return false;
-  }
-
-  /**
-   * whether needs escaping.
-   *
-   * @param verificationType  verification type
-   * @param arg               arg
-   * @return boolean
-   */
-  private static boolean needsEscaping(int verificationType, String arg) {
-
-    boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
-
-    if (!argIsQuoted) {
-      char[] testEscape = ESCAPE_VERIFICATION[verificationType];
-      for (int i = 0; i < testEscape.length; ++i) {
-        if (arg.indexOf(testEscape[i]) >= 0) {
-          return true;
-        }
-      }
+
+    /**
+     * quote string.
+     *
+     * @param arg argument
+     * @return format arg
+     */
+    private static String quoteString(String arg) {
+        return '""' + arg + '""';
     }
-    return false;
-  }
-
-  /**
-   * kill yarn application.
-   *
-   * @param appIds      app id list
-   * @param logger      logger
-   * @param tenantCode  tenant code
-   * @param executePath     execute path
-   */
-  public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
-    if (appIds.size() > 0) {
-      String appid = appIds.get(appIds.size() - 1);
-      String commandFile = String
-              .format(""%s/%s.kill"", executePath, appid);
-      String cmd = ""yarn application -kill "" + appid;
-      try {
-        StringBuilder sb = new StringBuilder();
-        sb.append(""#!/bin/sh\n"");
-        sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
-        sb.append(""cd $BASEDIR\n"");
-        if (CommonUtils.getSystemEnvPath() != null) {
-          sb.append(""source "" + CommonUtils.getSystemEnvPath() + ""\n"");
+
+    /**
+     * get tokens from command.
+     *
+     * @param command command
+     * @return token string array
+     */
+    private static String[] getTokensFromCommand(String command) {
+        ArrayList<String> matchList = new ArrayList<>(8);
+        Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
+        while (regexMatcher.find()) {
+            matchList.add(regexMatcher.group());
         }
-        sb.append(""\n\n"");
-        sb.append(cmd);
+        return matchList.toArray(new String[0]);
+    }
 
-        File f = new File(commandFile);
+    /**
+     * Lazy Pattern.
+     */
+    private static class LazyPattern {
+        // Escape-support version:
+        // ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
+        private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
+    }
 
-        if (!f.exists()) {
-          FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+    /**
+     * verification cmd bat.
+     */
+    private static final int VERIFICATION_CMD_BAT = 0;
+
+    /**
+     * verification win32.
+     */
+    private static final int VERIFICATION_WIN32 = 1;
+
+    /**
+     * verification legacy.
+     */
+    private static final int VERIFICATION_LEGACY = 2;
+
+    /**
+     * escape verification.
+     */
+    private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
+
+        {' ', '\t', '<', '>'}, {' ', '\t'}};
+
+    /**
+     * create command line.
+     *
+     * @param verificationType verification type
+     * @param executablePath   executable path
+     * @param cmd              cmd
+     * @return command line
+     */
+    private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
+        StringBuilder cmdbuf = new StringBuilder(80);
+
+        cmdbuf.append(executablePath);
+
+        for (int i = 1; i < cmd.length; ++i) {
+            cmdbuf.append(' ');
+            String s = cmd[i];
+            if (needsEscaping(verificationType, s)) {
+                cmdbuf.append('""').append(s);
+
+                if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
+                    cmdbuf.append('\\');
+                }
+                cmdbuf.append('""');
+            } else {
+                cmdbuf.append(s);
+            }
         }
+        return cmdbuf.toString();
+    }
 
-        String runCmd = ""sh "" + commandFile;
-        if (StringUtils.isNotEmpty(tenantCode)) {
-          runCmd = ""sudo -u "" + tenantCode + "" "" + runCmd;
+    /**
+     * whether is quoted.
+     *
+     * @param noQuotesInside no quotes inside
+     * @param arg            arg
+     * @param errorMessage   error message
+     * @return boolean
+     */
+    private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
+        int lastPos = arg.length() - 1;
+        if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
+            // The argument has already been quoted.
+            if (noQuotesInside) {
+                if (arg.indexOf('""', 1) != lastPos) {
+                    // There is [""] inside.
+                    throw new IllegalArgumentException(errorMessage);
+                }
+            }
+            return true;
+        }
+        if (noQuotesInside) {
+            if (arg.indexOf('""') >= 0) {
+                // There is [""] inside.
+                throw new IllegalArgumentException(errorMessage);
+            }
         }
+        return false;
+    }
 
-        logger.info(""kill cmd:{}"", runCmd);
+    /**
+     * whether needs escaping.
+     *
+     * @param verificationType verification type
+     * @param arg              arg
+     * @return boolean
+     */
+    private static boolean needsEscaping(int verificationType, String arg) {
+
+        boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
+
+        if (!argIsQuoted) {
+            char[] testEscape = ESCAPE_VERIFICATION[verificationType];
+            for (char c : testEscape) {
+                if (arg.indexOf(c) >= 0) {
+                    return true;
+                }
+            }
+        }
+        return false;
+    }
 
-        Runtime.getRuntime().exec(runCmd);
-      } catch (Exception e) {
-        logger.error(""kill application error"", e);
-      }
+    /**
+     * kill yarn application.
+     *
+     * @param appIds      app id list
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param executePath execute path
+     */
+    public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
+        if (CollectionUtils.isNotEmpty(appIds)) {
+","[{'comment': 'i think we should reduce its cognitive complexity here.', 'commenter': 'lenboo'}]"
4042,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/ProcessUtils.java,"@@ -38,368 +41,406 @@
 import java.util.regex.Pattern;
 
 /**
- *  mainly used to get the start command line of a process.
+ * mainly used to get the start command line of a process.
  */
 public class ProcessUtils {
-  /**
-   * logger.
-   */
-  private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
-
-  /**
-   * Initialization regularization, solve the problem of pre-compilation performance,
-   * avoid the thread safety problem of multi-thread operation.
-   */
-  private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
-
-  private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
-
-  /**
-   * build command line characters.
-   * @param commandList command list
-   * @return command
-   */
-  public static String buildCommandStr(List<String> commandList) {
-    String cmdstr;
-    String[] cmd = commandList.toArray(new String[commandList.size()]);
-    SecurityManager security = System.getSecurityManager();
-    boolean allowAmbiguousCommands = false;
-    if (security == null) {
-      allowAmbiguousCommands = true;
-      String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
-      if (value != null) {
-        allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
-      }
+    /**
+     * logger.
+     */
+    private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
+
+    /**
+     * Initialization regularization, solve the problem of pre-compilation performance,
+     * avoid the thread safety problem of multi-thread operation.
+     */
+    private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
+
+    private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
+
+    /**
+     * build command line characters.
+     *
+     * @param commandList command list
+     * @return command
+     */
+    public static String buildCommandStr(List<String> commandList) {
+        String cmdstr;
+        String[] cmd = commandList.toArray(new String[0]);
+        SecurityManager security = System.getSecurityManager();
+        boolean allowAmbiguousCommands = isAllowAmbiguousCommands(security);
+        if (allowAmbiguousCommands) {
+
+            String executablePath = new File(cmd[0]).getPath();
+
+            if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
+                executablePath = quoteString(executablePath);
+            }
+
+            cmdstr = createCommandLine(
+                VERIFICATION_LEGACY, executablePath, cmd);
+        } else {
+            String executablePath;
+            try {
+                executablePath = getExecutablePath(cmd[0]);
+            } catch (IllegalArgumentException e) {
+
+                StringBuilder join = new StringBuilder();
+                for (String s : cmd) {
+                    join.append(s).append(' ');
+                }
+
+                cmd = getTokensFromCommand(join.toString());
+                executablePath = getExecutablePath(cmd[0]);
+
+                // Check new executable name once more
+                if (security != null) {
+                    security.checkExec(executablePath);
+                }
+            }
+
+            cmdstr = createCommandLine(
+
+                isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+        }
+        return cmdstr;
     }
-    if (allowAmbiguousCommands) {
-
-      String executablePath = new File(cmd[0]).getPath();
-
-      if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
-        executablePath = quoteString(executablePath);
-      }
-
-      cmdstr = createCommandLine(
-              VERIFICATION_LEGACY, executablePath, cmd);
-    } else {
-      String executablePath;
-      try {
-        executablePath = getExecutablePath(cmd[0]);
-      } catch (IllegalArgumentException e) {
 
-        StringBuilder join = new StringBuilder();
-        for (String s : cmd) {
-          join.append(s).append(' ');
+    /**
+     * check is allow ambiguous commands
+     *
+     * @param security security manager
+     * @return allow ambiguous command flag
+     */
+    private static boolean isAllowAmbiguousCommands(SecurityManager security) {
+        boolean allowAmbiguousCommands = false;
+        if (security == null) {
+            allowAmbiguousCommands = true;
+            String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");","[{'comment': 'magic number here', 'commenter': 'lenboo'}, {'comment': 'fixed', 'commenter': 'Eights-Li'}]"
4042,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/ProcessUtils.java,"@@ -38,368 +41,406 @@
 import java.util.regex.Pattern;
 
 /**
- *  mainly used to get the start command line of a process.
+ * mainly used to get the start command line of a process.
  */
 public class ProcessUtils {
-  /**
-   * logger.
-   */
-  private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
-
-  /**
-   * Initialization regularization, solve the problem of pre-compilation performance,
-   * avoid the thread safety problem of multi-thread operation.
-   */
-  private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
-
-  private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
-
-  /**
-   * build command line characters.
-   * @param commandList command list
-   * @return command
-   */
-  public static String buildCommandStr(List<String> commandList) {
-    String cmdstr;
-    String[] cmd = commandList.toArray(new String[commandList.size()]);
-    SecurityManager security = System.getSecurityManager();
-    boolean allowAmbiguousCommands = false;
-    if (security == null) {
-      allowAmbiguousCommands = true;
-      String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
-      if (value != null) {
-        allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
-      }
+    /**
+     * logger.
+     */
+    private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
+
+    /**
+     * Initialization regularization, solve the problem of pre-compilation performance,
+     * avoid the thread safety problem of multi-thread operation.
+     */
+    private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
+
+    private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
+
+    /**
+     * build command line characters.
+     *
+     * @param commandList command list
+     * @return command
+     */
+    public static String buildCommandStr(List<String> commandList) {
+        String cmdstr;
+        String[] cmd = commandList.toArray(new String[0]);
+        SecurityManager security = System.getSecurityManager();
+        boolean allowAmbiguousCommands = isAllowAmbiguousCommands(security);
+        if (allowAmbiguousCommands) {
+
+            String executablePath = new File(cmd[0]).getPath();
+
+            if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
+                executablePath = quoteString(executablePath);
+            }
+
+            cmdstr = createCommandLine(
+                VERIFICATION_LEGACY, executablePath, cmd);
+        } else {
+            String executablePath;
+            try {
+                executablePath = getExecutablePath(cmd[0]);
+            } catch (IllegalArgumentException e) {
+
+                StringBuilder join = new StringBuilder();
+                for (String s : cmd) {
+                    join.append(s).append(' ');
+                }
+
+                cmd = getTokensFromCommand(join.toString());
+                executablePath = getExecutablePath(cmd[0]);
+
+                // Check new executable name once more
+                if (security != null) {
+                    security.checkExec(executablePath);
+                }
+            }
+
+            cmdstr = createCommandLine(
+
+                isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+        }
+        return cmdstr;
     }
-    if (allowAmbiguousCommands) {
-
-      String executablePath = new File(cmd[0]).getPath();
-
-      if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
-        executablePath = quoteString(executablePath);
-      }
-
-      cmdstr = createCommandLine(
-              VERIFICATION_LEGACY, executablePath, cmd);
-    } else {
-      String executablePath;
-      try {
-        executablePath = getExecutablePath(cmd[0]);
-      } catch (IllegalArgumentException e) {
 
-        StringBuilder join = new StringBuilder();
-        for (String s : cmd) {
-          join.append(s).append(' ');
+    /**
+     * check is allow ambiguous commands
+     *
+     * @param security security manager
+     * @return allow ambiguous command flag
+     */
+    private static boolean isAllowAmbiguousCommands(SecurityManager security) {
+        boolean allowAmbiguousCommands = false;
+        if (security == null) {
+            allowAmbiguousCommands = true;
+            String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
+            if (value != null) {
+                allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
+            }
         }
+        return allowAmbiguousCommands;
+    }
 
-        cmd = getTokensFromCommand(join.toString());
-        executablePath = getExecutablePath(cmd[0]);
+    /**
+     * get executable path.
+     *
+     * @param path path
+     * @return executable path
+     */
+    private static String getExecutablePath(String path) {
+        boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");","[{'comment': 'also magic number.', 'commenter': 'lenboo'}, {'comment': 'This string is error message', 'commenter': 'Eights-Li'}, {'comment': 'fixed', 'commenter': 'Eights-Li'}]"
4042,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/ProcessUtils.java,"@@ -38,368 +41,408 @@
 import java.util.regex.Pattern;
 
 /**
- *  mainly used to get the start command line of a process.
+ * mainly used to get the start command line of a process.
  */
 public class ProcessUtils {
-  /**
-   * logger.
-   */
-  private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
-
-  /**
-   * Initialization regularization, solve the problem of pre-compilation performance,
-   * avoid the thread safety problem of multi-thread operation.
-   */
-  private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
-
-  private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
-
-  /**
-   * build command line characters.
-   * @param commandList command list
-   * @return command
-   */
-  public static String buildCommandStr(List<String> commandList) {
-    String cmdstr;
-    String[] cmd = commandList.toArray(new String[commandList.size()]);
-    SecurityManager security = System.getSecurityManager();
-    boolean allowAmbiguousCommands = false;
-    if (security == null) {
-      allowAmbiguousCommands = true;
-      String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
-      if (value != null) {
-        allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
-      }
+    /**
+     * logger.
+     */
+    private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
+
+    /**
+     * Initialization regularization, solve the problem of pre-compilation performance,
+     * avoid the thread safety problem of multi-thread operation.
+     */
+    private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
+
+    private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
+
+    private static final String LOCAL_PROCESS_EXEC = ""jdk.lang.Process.allowAmbiguousCommands"";
+
+    /**
+     * build command line characters.
+     *
+     * @param commandList command list
+     * @return command
+     */
+    public static String buildCommandStr(List<String> commandList) {
+        String cmdstr;
+        String[] cmd = commandList.toArray(new String[0]);
+        SecurityManager security = System.getSecurityManager();
+        boolean allowAmbiguousCommands = isAllowAmbiguousCommands(security);
+        if (allowAmbiguousCommands) {
+
+            String executablePath = new File(cmd[0]).getPath();
+
+            if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
+                executablePath = quoteString(executablePath);
+            }
+
+            cmdstr = createCommandLine(
+                VERIFICATION_LEGACY, executablePath, cmd);
+        } else {
+            String executablePath;
+            try {
+                executablePath = getExecutablePath(cmd[0]);
+            } catch (IllegalArgumentException e) {
+
+                StringBuilder join = new StringBuilder();
+                for (String s : cmd) {
+                    join.append(s).append(' ');
+                }
+
+                cmd = getTokensFromCommand(join.toString());
+                executablePath = getExecutablePath(cmd[0]);
+
+                // Check new executable name once more
+                if (security != null) {
+                    security.checkExec(executablePath);
+                }
+            }
+
+            cmdstr = createCommandLine(
+
+                isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+        }
+        return cmdstr;
     }
-    if (allowAmbiguousCommands) {
-
-      String executablePath = new File(cmd[0]).getPath();
-
-      if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
-        executablePath = quoteString(executablePath);
-      }
-
-      cmdstr = createCommandLine(
-              VERIFICATION_LEGACY, executablePath, cmd);
-    } else {
-      String executablePath;
-      try {
-        executablePath = getExecutablePath(cmd[0]);
-      } catch (IllegalArgumentException e) {
 
-        StringBuilder join = new StringBuilder();
-        for (String s : cmd) {
-          join.append(s).append(' ');
+    /**
+     * check is allow ambiguous commands
+     *
+     * @param security security manager
+     * @return allow ambiguous command flag
+     */
+    private static boolean isAllowAmbiguousCommands(SecurityManager security) {
+        boolean allowAmbiguousCommands = false;
+        if (security == null) {
+            allowAmbiguousCommands = true;
+            String value = System.getProperty(LOCAL_PROCESS_EXEC);
+            if (value != null) {
+                allowAmbiguousCommands = !Constants.STRING_FALSE.equalsIgnoreCase(value);
+            }
         }
+        return allowAmbiguousCommands;
+    }
 
-        cmd = getTokensFromCommand(join.toString());
-        executablePath = getExecutablePath(cmd[0]);
+    /**
+     * get executable path.
+     *
+     * @param path path
+     * @return executable path
+     */
+    private static String getExecutablePath(String path) {
+        boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
+
+        File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
+        return fileToRun.getPath();
+    }
 
-        // Check new executable name once more
-        if (security != null) {
-          security.checkExec(executablePath);
-        }
-      }
+    /**
+     * whether is shell file.
+     *
+     * @param executablePath executable path
+     * @return true if endsWith .CMD or .BAT
+     */
+    private static boolean isShellFile(String executablePath) {
+        String upPath = executablePath.toUpperCase();
+        return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
+    }
 
-      cmdstr = createCommandLine(
+    /**
+     * quote string.
+     *
+     * @param arg argument
+     * @return format arg
+     */
+    private static String quoteString(String arg) {
+        return '""' + arg + '""';
+    }
 
-              isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+    /**
+     * get tokens from command.
+     *
+     * @param command command
+     * @return token string array
+     */
+    private static String[] getTokensFromCommand(String command) {
+        ArrayList<String> matchList = new ArrayList<>(8);
+        Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
+        while (regexMatcher.find()) {
+            matchList.add(regexMatcher.group());
+        }
+        return matchList.toArray(new String[0]);
     }
-    return cmdstr;
-  }
-
-  /**
-   * get executable path.
-   *
-   * @param path path
-   * @return executable path
-   */
-  private static String getExecutablePath(String path) {
-    boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
-
-    File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
-    return fileToRun.getPath();
-  }
-
-  /**
-   * whether is shell file.
-   *
-   * @param executablePath executable path
-   * @return true if endsWith .CMD or .BAT
-   */
-  private static boolean isShellFile(String executablePath) {
-    String upPath = executablePath.toUpperCase();
-    return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
-  }
-
-  /**
-   * quote string.
-   *
-   * @param arg argument
-   * @return format arg
-   */
-  private static String quoteString(String arg) {
-    StringBuilder argbuf = new StringBuilder(arg.length() + 2);
-    return argbuf.append('""').append(arg).append('""').toString();
-  }
-
-  /**
-   * get tokens from command.
-   *
-   * @param command command
-   * @return token string array
-   */
-  private static String[] getTokensFromCommand(String command) {
-    ArrayList<String> matchList = new ArrayList<>(8);
-    Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
-    while (regexMatcher.find()) {
-      matchList.add(regexMatcher.group());
+
+    /**
+     * Lazy Pattern.
+     */
+    private static class LazyPattern {
+        /**
+         * Escape-support version:
+         * ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
+         */
+        private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
     }
-    return matchList.toArray(new String[matchList.size()]);
-  }
-
-  /**
-   * Lazy Pattern.
-   */
-  private static class LazyPattern {
-    // Escape-support version:
-    // ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
-    private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
-  }
-
-  /**
-   * verification cmd bat.
-   */
-  private static final int VERIFICATION_CMD_BAT = 0;
-
-  /**
-   * verification win32.
-   */
-  private static final int VERIFICATION_WIN32 = 1;
-
-  /**
-   * verification legacy.
-   */
-  private static final int VERIFICATION_LEGACY = 2;
-
-  /**
-   * escape verification.
-   */
-  private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
-
-    {' ', '\t', '<', '>'}, {' ', '\t'}};
-
-  /**
-   * create command line.
-   * @param verificationType  verification type
-   * @param executablePath    executable path
-   * @param cmd               cmd
-   * @return command line
-   */
-  private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
-    StringBuilder cmdbuf = new StringBuilder(80);
-
-    cmdbuf.append(executablePath);
-
-    for (int i = 1; i < cmd.length; ++i) {
-      cmdbuf.append(' ');
-      String s = cmd[i];
-      if (needsEscaping(verificationType, s)) {
-        cmdbuf.append('""').append(s);
-
-        if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
-          cmdbuf.append('\\');
+
+    /**
+     * verification cmd bat.
+     */
+    private static final int VERIFICATION_CMD_BAT = 0;
+
+    /**
+     * verification win32.
+     */
+    private static final int VERIFICATION_WIN32 = 1;
+
+    /**
+     * verification legacy.
+     */
+    private static final int VERIFICATION_LEGACY = 2;
+
+    /**
+     * escape verification.
+     */
+    private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
+
+        {' ', '\t', '<', '>'}, {' ', '\t'}};
+
+    /**
+     * create command line.
+     *
+     * @param verificationType verification type
+     * @param executablePath   executable path
+     * @param cmd              cmd
+     * @return command line
+     */
+    private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
+        StringBuilder cmdbuf = new StringBuilder(80);
+
+        cmdbuf.append(executablePath);
+
+        for (int i = 1; i < cmd.length; ++i) {
+            cmdbuf.append(' ');
+            String s = cmd[i];
+            if (needsEscaping(verificationType, s)) {
+                cmdbuf.append('""').append(s);
+
+                if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
+                    cmdbuf.append('\\');
+                }
+                cmdbuf.append('""');
+            } else {
+                cmdbuf.append(s);
+            }
         }
-        cmdbuf.append('""');
-      } else {
-        cmdbuf.append(s);
-      }
+        return cmdbuf.toString();
     }
-    return cmdbuf.toString();
-  }
-
-  /**
-   * whether is quoted.
-   * @param noQuotesInside
-   * @param arg
-   * @param errorMessage
-   * @return boolean
-   */
-  private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
-    int lastPos = arg.length() - 1;
-    if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
-      // The argument has already been quoted.
-      if (noQuotesInside) {
-        if (arg.indexOf('""', 1) != lastPos) {
-          // There is [""] inside.
-          throw new IllegalArgumentException(errorMessage);
+
+    /**
+     * whether is quoted.
+     *
+     * @param noQuotesInside no quotes inside
+     * @param arg            arg
+     * @param errorMessage   error message
+     * @return boolean
+     */
+    private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
+        int lastPos = arg.length() - 1;
+        if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
+            // The argument has already been quoted.
+            if (noQuotesInside && arg.indexOf('""', 1) != lastPos) {
+                // There is [""] inside.
+                throw new IllegalArgumentException(errorMessage);
+            }
+            return true;
         }
-      }
-      return true;
-    }
-    if (noQuotesInside) {
-      if (arg.indexOf('""') >= 0) {
-        // There is [""] inside.
-        throw new IllegalArgumentException(errorMessage);
-      }
-    }
-    return false;
-  }
-
-  /**
-   * whether needs escaping.
-   *
-   * @param verificationType  verification type
-   * @param arg               arg
-   * @return boolean
-   */
-  private static boolean needsEscaping(int verificationType, String arg) {
-
-    boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
-
-    if (!argIsQuoted) {
-      char[] testEscape = ESCAPE_VERIFICATION[verificationType];
-      for (int i = 0; i < testEscape.length; ++i) {
-        if (arg.indexOf(testEscape[i]) >= 0) {
-          return true;
+        if (noQuotesInside && arg.indexOf('""') >= 0) {
+            // There is [""] inside.
+            throw new IllegalArgumentException(errorMessage);
         }
-      }
+        return false;
     }
-    return false;
-  }
-
-  /**
-   * kill yarn application.
-   *
-   * @param appIds      app id list
-   * @param logger      logger
-   * @param tenantCode  tenant code
-   * @param executePath     execute path
-   */
-  public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
-    if (appIds.size() > 0) {
-      String appid = appIds.get(appIds.size() - 1);
-      String commandFile = String
-              .format(""%s/%s.kill"", executePath, appid);
-      String cmd = ""yarn application -kill "" + appid;
-      try {
-        StringBuilder sb = new StringBuilder();
-        sb.append(""#!/bin/sh\n"");
-        sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
-        sb.append(""cd $BASEDIR\n"");
-        if (CommonUtils.getSystemEnvPath() != null) {
-          sb.append(""source "" + CommonUtils.getSystemEnvPath() + ""\n"");
-        }
-        sb.append(""\n\n"");
-        sb.append(cmd);
-
-        File f = new File(commandFile);
 
-        if (!f.exists()) {
-          FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+    /**
+     * whether needs escaping.
+     *
+     * @param verificationType verification type
+     * @param arg              arg
+     * @return boolean
+     */
+    private static boolean needsEscaping(int verificationType, String arg) {
+
+        boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
+
+        if (!argIsQuoted) {
+            char[] testEscape = ESCAPE_VERIFICATION[verificationType];
+            for (char c : testEscape) {
+                if (arg.indexOf(c) >= 0) {
+                    return true;
+                }
+            }
         }
+        return false;
+    }
 
-        String runCmd = ""sh "" + commandFile;
-        if (StringUtils.isNotEmpty(tenantCode)) {
-          runCmd = ""sudo -u "" + tenantCode + "" "" + runCmd;
+    /**
+     * kill yarn application.
+     *
+     * @param appIds      app id list
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param executePath execute path
+     */
+    public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
+        if (CollectionUtils.isNotEmpty(appIds)) {
+
+            for (String appId : appIds) {
+                try {
+                    ExecutionStatus applicationStatus = HadoopUtils.getInstance().getApplicationStatus(appId);
+
+                    if (!applicationStatus.typeIsFinished()) {
+                        String commandFile = String
+                            .format(""%s/%s.kill"", executePath, appId);
+                        String cmd = ""yarn application -kill "" + appId;
+                        execYarnKillCommand(logger, tenantCode, appId, commandFile, cmd);
+                    }
+                } catch (Exception e) {
+                    logger.error(String.format(""Get yarn application app id [%s] status failed: [%s]"", appId, e.getMessage()));
+                }
+            }
         }
+    }
 
-        logger.info(""kill cmd:{}"", runCmd);
-
-        Runtime.getRuntime().exec(runCmd);
-      } catch (Exception e) {
-        logger.error(""kill application error"", e);
-      }
+    /**
+     * build kill command for yarn application
+     *
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param appId       app id
+     * @param commandFile command file
+     * @param cmd         cmd
+     */
+    private static void execYarnKillCommand(Logger logger, String tenantCode, String appId, String commandFile, String cmd) {
+        try {
+            StringBuilder sb = new StringBuilder();
+            sb.append(""#!/bin/sh\n"");
+            sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
+            sb.append(""cd $BASEDIR\n"");
+            if (CommonUtils.getSystemEnvPath() != null) {
+                sb.append(""source "").append(CommonUtils.getSystemEnvPath()).append(""\n"");
+            }
+            sb.append(""\n\n"");
+            sb.append(cmd);
+
+            File f = new File(commandFile);
+
+            if (!f.exists()) {
+                FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+            }
+
+            String runCmd = ""sh "" + commandFile;","[{'comment': 'is this ""sh "" can be instead?\r\nI can find it elsewhere.', 'commenter': 'lenboo'}]"
4042,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/ProcessUtils.java,"@@ -38,368 +41,408 @@
 import java.util.regex.Pattern;
 
 /**
- *  mainly used to get the start command line of a process.
+ * mainly used to get the start command line of a process.
  */
 public class ProcessUtils {
-  /**
-   * logger.
-   */
-  private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
-
-  /**
-   * Initialization regularization, solve the problem of pre-compilation performance,
-   * avoid the thread safety problem of multi-thread operation.
-   */
-  private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
-
-  private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
-
-  /**
-   * build command line characters.
-   * @param commandList command list
-   * @return command
-   */
-  public static String buildCommandStr(List<String> commandList) {
-    String cmdstr;
-    String[] cmd = commandList.toArray(new String[commandList.size()]);
-    SecurityManager security = System.getSecurityManager();
-    boolean allowAmbiguousCommands = false;
-    if (security == null) {
-      allowAmbiguousCommands = true;
-      String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
-      if (value != null) {
-        allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
-      }
+    /**
+     * logger.
+     */
+    private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
+
+    /**
+     * Initialization regularization, solve the problem of pre-compilation performance,
+     * avoid the thread safety problem of multi-thread operation.
+     */
+    private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
+
+    private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
+
+    private static final String LOCAL_PROCESS_EXEC = ""jdk.lang.Process.allowAmbiguousCommands"";
+
+    /**
+     * build command line characters.
+     *
+     * @param commandList command list
+     * @return command
+     */
+    public static String buildCommandStr(List<String> commandList) {
+        String cmdstr;
+        String[] cmd = commandList.toArray(new String[0]);
+        SecurityManager security = System.getSecurityManager();
+        boolean allowAmbiguousCommands = isAllowAmbiguousCommands(security);
+        if (allowAmbiguousCommands) {
+
+            String executablePath = new File(cmd[0]).getPath();
+
+            if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
+                executablePath = quoteString(executablePath);
+            }
+
+            cmdstr = createCommandLine(
+                VERIFICATION_LEGACY, executablePath, cmd);
+        } else {
+            String executablePath;
+            try {
+                executablePath = getExecutablePath(cmd[0]);
+            } catch (IllegalArgumentException e) {
+
+                StringBuilder join = new StringBuilder();
+                for (String s : cmd) {
+                    join.append(s).append(' ');
+                }
+
+                cmd = getTokensFromCommand(join.toString());
+                executablePath = getExecutablePath(cmd[0]);
+
+                // Check new executable name once more
+                if (security != null) {
+                    security.checkExec(executablePath);
+                }
+            }
+
+            cmdstr = createCommandLine(
+
+                isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+        }
+        return cmdstr;
     }
-    if (allowAmbiguousCommands) {
-
-      String executablePath = new File(cmd[0]).getPath();
-
-      if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
-        executablePath = quoteString(executablePath);
-      }
-
-      cmdstr = createCommandLine(
-              VERIFICATION_LEGACY, executablePath, cmd);
-    } else {
-      String executablePath;
-      try {
-        executablePath = getExecutablePath(cmd[0]);
-      } catch (IllegalArgumentException e) {
 
-        StringBuilder join = new StringBuilder();
-        for (String s : cmd) {
-          join.append(s).append(' ');
+    /**
+     * check is allow ambiguous commands
+     *
+     * @param security security manager
+     * @return allow ambiguous command flag
+     */
+    private static boolean isAllowAmbiguousCommands(SecurityManager security) {
+        boolean allowAmbiguousCommands = false;
+        if (security == null) {
+            allowAmbiguousCommands = true;
+            String value = System.getProperty(LOCAL_PROCESS_EXEC);
+            if (value != null) {
+                allowAmbiguousCommands = !Constants.STRING_FALSE.equalsIgnoreCase(value);
+            }
         }
+        return allowAmbiguousCommands;
+    }
 
-        cmd = getTokensFromCommand(join.toString());
-        executablePath = getExecutablePath(cmd[0]);
+    /**
+     * get executable path.
+     *
+     * @param path path
+     * @return executable path
+     */
+    private static String getExecutablePath(String path) {
+        boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
+
+        File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
+        return fileToRun.getPath();
+    }
 
-        // Check new executable name once more
-        if (security != null) {
-          security.checkExec(executablePath);
-        }
-      }
+    /**
+     * whether is shell file.
+     *
+     * @param executablePath executable path
+     * @return true if endsWith .CMD or .BAT
+     */
+    private static boolean isShellFile(String executablePath) {
+        String upPath = executablePath.toUpperCase();
+        return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
+    }
 
-      cmdstr = createCommandLine(
+    /**
+     * quote string.
+     *
+     * @param arg argument
+     * @return format arg
+     */
+    private static String quoteString(String arg) {
+        return '""' + arg + '""';
+    }
 
-              isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+    /**
+     * get tokens from command.
+     *
+     * @param command command
+     * @return token string array
+     */
+    private static String[] getTokensFromCommand(String command) {
+        ArrayList<String> matchList = new ArrayList<>(8);
+        Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
+        while (regexMatcher.find()) {
+            matchList.add(regexMatcher.group());
+        }
+        return matchList.toArray(new String[0]);
     }
-    return cmdstr;
-  }
-
-  /**
-   * get executable path.
-   *
-   * @param path path
-   * @return executable path
-   */
-  private static String getExecutablePath(String path) {
-    boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
-
-    File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
-    return fileToRun.getPath();
-  }
-
-  /**
-   * whether is shell file.
-   *
-   * @param executablePath executable path
-   * @return true if endsWith .CMD or .BAT
-   */
-  private static boolean isShellFile(String executablePath) {
-    String upPath = executablePath.toUpperCase();
-    return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
-  }
-
-  /**
-   * quote string.
-   *
-   * @param arg argument
-   * @return format arg
-   */
-  private static String quoteString(String arg) {
-    StringBuilder argbuf = new StringBuilder(arg.length() + 2);
-    return argbuf.append('""').append(arg).append('""').toString();
-  }
-
-  /**
-   * get tokens from command.
-   *
-   * @param command command
-   * @return token string array
-   */
-  private static String[] getTokensFromCommand(String command) {
-    ArrayList<String> matchList = new ArrayList<>(8);
-    Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
-    while (regexMatcher.find()) {
-      matchList.add(regexMatcher.group());
+
+    /**
+     * Lazy Pattern.
+     */
+    private static class LazyPattern {
+        /**
+         * Escape-support version:
+         * ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
+         */
+        private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
     }
-    return matchList.toArray(new String[matchList.size()]);
-  }
-
-  /**
-   * Lazy Pattern.
-   */
-  private static class LazyPattern {
-    // Escape-support version:
-    // ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
-    private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
-  }
-
-  /**
-   * verification cmd bat.
-   */
-  private static final int VERIFICATION_CMD_BAT = 0;
-
-  /**
-   * verification win32.
-   */
-  private static final int VERIFICATION_WIN32 = 1;
-
-  /**
-   * verification legacy.
-   */
-  private static final int VERIFICATION_LEGACY = 2;
-
-  /**
-   * escape verification.
-   */
-  private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
-
-    {' ', '\t', '<', '>'}, {' ', '\t'}};
-
-  /**
-   * create command line.
-   * @param verificationType  verification type
-   * @param executablePath    executable path
-   * @param cmd               cmd
-   * @return command line
-   */
-  private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
-    StringBuilder cmdbuf = new StringBuilder(80);
-
-    cmdbuf.append(executablePath);
-
-    for (int i = 1; i < cmd.length; ++i) {
-      cmdbuf.append(' ');
-      String s = cmd[i];
-      if (needsEscaping(verificationType, s)) {
-        cmdbuf.append('""').append(s);
-
-        if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
-          cmdbuf.append('\\');
+
+    /**
+     * verification cmd bat.
+     */
+    private static final int VERIFICATION_CMD_BAT = 0;
+
+    /**
+     * verification win32.
+     */
+    private static final int VERIFICATION_WIN32 = 1;
+
+    /**
+     * verification legacy.
+     */
+    private static final int VERIFICATION_LEGACY = 2;
+
+    /**
+     * escape verification.
+     */
+    private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
+
+        {' ', '\t', '<', '>'}, {' ', '\t'}};
+
+    /**
+     * create command line.
+     *
+     * @param verificationType verification type
+     * @param executablePath   executable path
+     * @param cmd              cmd
+     * @return command line
+     */
+    private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
+        StringBuilder cmdbuf = new StringBuilder(80);
+
+        cmdbuf.append(executablePath);
+
+        for (int i = 1; i < cmd.length; ++i) {
+            cmdbuf.append(' ');
+            String s = cmd[i];
+            if (needsEscaping(verificationType, s)) {
+                cmdbuf.append('""').append(s);
+
+                if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
+                    cmdbuf.append('\\');
+                }
+                cmdbuf.append('""');
+            } else {
+                cmdbuf.append(s);
+            }
         }
-        cmdbuf.append('""');
-      } else {
-        cmdbuf.append(s);
-      }
+        return cmdbuf.toString();
     }
-    return cmdbuf.toString();
-  }
-
-  /**
-   * whether is quoted.
-   * @param noQuotesInside
-   * @param arg
-   * @param errorMessage
-   * @return boolean
-   */
-  private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
-    int lastPos = arg.length() - 1;
-    if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
-      // The argument has already been quoted.
-      if (noQuotesInside) {
-        if (arg.indexOf('""', 1) != lastPos) {
-          // There is [""] inside.
-          throw new IllegalArgumentException(errorMessage);
+
+    /**
+     * whether is quoted.
+     *
+     * @param noQuotesInside no quotes inside
+     * @param arg            arg
+     * @param errorMessage   error message
+     * @return boolean
+     */
+    private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
+        int lastPos = arg.length() - 1;
+        if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
+            // The argument has already been quoted.
+            if (noQuotesInside && arg.indexOf('""', 1) != lastPos) {
+                // There is [""] inside.
+                throw new IllegalArgumentException(errorMessage);
+            }
+            return true;
         }
-      }
-      return true;
-    }
-    if (noQuotesInside) {
-      if (arg.indexOf('""') >= 0) {
-        // There is [""] inside.
-        throw new IllegalArgumentException(errorMessage);
-      }
-    }
-    return false;
-  }
-
-  /**
-   * whether needs escaping.
-   *
-   * @param verificationType  verification type
-   * @param arg               arg
-   * @return boolean
-   */
-  private static boolean needsEscaping(int verificationType, String arg) {
-
-    boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
-
-    if (!argIsQuoted) {
-      char[] testEscape = ESCAPE_VERIFICATION[verificationType];
-      for (int i = 0; i < testEscape.length; ++i) {
-        if (arg.indexOf(testEscape[i]) >= 0) {
-          return true;
+        if (noQuotesInside && arg.indexOf('""') >= 0) {
+            // There is [""] inside.
+            throw new IllegalArgumentException(errorMessage);
         }
-      }
+        return false;
     }
-    return false;
-  }
-
-  /**
-   * kill yarn application.
-   *
-   * @param appIds      app id list
-   * @param logger      logger
-   * @param tenantCode  tenant code
-   * @param executePath     execute path
-   */
-  public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
-    if (appIds.size() > 0) {
-      String appid = appIds.get(appIds.size() - 1);
-      String commandFile = String
-              .format(""%s/%s.kill"", executePath, appid);
-      String cmd = ""yarn application -kill "" + appid;
-      try {
-        StringBuilder sb = new StringBuilder();
-        sb.append(""#!/bin/sh\n"");
-        sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
-        sb.append(""cd $BASEDIR\n"");
-        if (CommonUtils.getSystemEnvPath() != null) {
-          sb.append(""source "" + CommonUtils.getSystemEnvPath() + ""\n"");
-        }
-        sb.append(""\n\n"");
-        sb.append(cmd);
-
-        File f = new File(commandFile);
 
-        if (!f.exists()) {
-          FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+    /**
+     * whether needs escaping.
+     *
+     * @param verificationType verification type
+     * @param arg              arg
+     * @return boolean
+     */
+    private static boolean needsEscaping(int verificationType, String arg) {
+
+        boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
+
+        if (!argIsQuoted) {
+            char[] testEscape = ESCAPE_VERIFICATION[verificationType];
+            for (char c : testEscape) {
+                if (arg.indexOf(c) >= 0) {
+                    return true;
+                }
+            }
         }
+        return false;
+    }
 
-        String runCmd = ""sh "" + commandFile;
-        if (StringUtils.isNotEmpty(tenantCode)) {
-          runCmd = ""sudo -u "" + tenantCode + "" "" + runCmd;
+    /**
+     * kill yarn application.
+     *
+     * @param appIds      app id list
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param executePath execute path
+     */
+    public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
+        if (CollectionUtils.isNotEmpty(appIds)) {
+
+            for (String appId : appIds) {
+                try {
+                    ExecutionStatus applicationStatus = HadoopUtils.getInstance().getApplicationStatus(appId);
+
+                    if (!applicationStatus.typeIsFinished()) {
+                        String commandFile = String
+                            .format(""%s/%s.kill"", executePath, appId);
+                        String cmd = ""yarn application -kill "" + appId;
+                        execYarnKillCommand(logger, tenantCode, appId, commandFile, cmd);
+                    }
+                } catch (Exception e) {
+                    logger.error(String.format(""Get yarn application app id [%s] status failed: [%s]"", appId, e.getMessage()));
+                }
+            }
         }
+    }
 
-        logger.info(""kill cmd:{}"", runCmd);
-
-        Runtime.getRuntime().exec(runCmd);
-      } catch (Exception e) {
-        logger.error(""kill application error"", e);
-      }
+    /**
+     * build kill command for yarn application
+     *
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param appId       app id
+     * @param commandFile command file
+     * @param cmd         cmd
+     */
+    private static void execYarnKillCommand(Logger logger, String tenantCode, String appId, String commandFile, String cmd) {
+        try {
+            StringBuilder sb = new StringBuilder();
+            sb.append(""#!/bin/sh\n"");
+            sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
+            sb.append(""cd $BASEDIR\n"");
+            if (CommonUtils.getSystemEnvPath() != null) {
+                sb.append(""source "").append(CommonUtils.getSystemEnvPath()).append(""\n"");
+            }
+            sb.append(""\n\n"");
+            sb.append(cmd);
+
+            File f = new File(commandFile);
+
+            if (!f.exists()) {
+                FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+            }
+
+            String runCmd = ""sh "" + commandFile;
+            if (StringUtils.isNotEmpty(tenantCode)) {
+                runCmd = ""sudo -u "" + tenantCode + "" "" + runCmd;
+            }
+
+            logger.info(""kill cmd:{}"", runCmd);
+            Runtime.getRuntime().exec(runCmd);
+        } catch (Exception e) {
+            logger.error(String.format(""Kill yarn application app id [%s] failed: [%s]"", appId, e.getMessage()));
+        }
     }
-  }
 
-  /**
-   * kill tasks according to different task types.
-   *
-   * @param taskExecutionContext  taskExecutionContext
-   */
-  public static void kill(TaskExecutionContext taskExecutionContext) {
-    try {
-      int processId = taskExecutionContext.getProcessId();
-      if (processId == 0) {
-        logger.error(""process kill failed, process id :{}, task id:{}"",
-                processId, taskExecutionContext.getTaskInstanceId());
-        return;
-      }
+    /**
+     * kill tasks according to different task types.
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    public static void kill(TaskExecutionContext taskExecutionContext) {
+        try {
+            int processId = taskExecutionContext.getProcessId();
+            if (processId == 0) {
+                logger.error(""process kill failed, process id :{}, task id:{}"",
+                    processId, taskExecutionContext.getTaskInstanceId());
+                return;
+            }
 
-      String cmd = String.format(""sudo kill -9 %s"", getPidsStr(processId));
+            String cmd = String.format(""sudo kill -9 %s"", getPidsStr(processId));
 
-      logger.info(""process id:{}, cmd:{}"", processId, cmd);
+            logger.info(""process id:{}, cmd:{}"", processId, cmd);
 
-      OSUtils.exeCmd(cmd);
+            OSUtils.exeCmd(cmd);
 
-      // find log and kill yarn job
-      killYarnJob(taskExecutionContext);
+            // find log and kill yarn job
+            killYarnJob(taskExecutionContext);
 
-    } catch (Exception e) {
-      logger.error(""kill task failed"", e);
-    }
-  }
-
-  /**
-   * get pids str.
-   *
-   * @param processId process id
-   * @return pids
-   * @throws Exception exception
-   */
-  public static String getPidsStr(int processId) throws Exception {
-    StringBuilder sb = new StringBuilder();
-    Matcher mat;
-    // pstree pid get sub pids
-    if (OSUtils.isMacOS()) {
-      String pids = OSUtils.exeCmd(""pstree -sp "" + processId);
-      mat = MACPATTERN.matcher(pids);
-    } else {
-      String pids = OSUtils.exeCmd(""pstree -p "" + processId);
-      mat = WINDOWSATTERN.matcher(pids);
+        } catch (Exception e) {
+            logger.error(""kill task failed"", e);
+        }
     }
 
-    while (mat.find()) {
-      sb.append(mat.group(1)).append("" "");
-    }
-    return sb.toString().trim();
-  }
-
-  /**
-   * find logs and kill yarn tasks.
-   *
-   * @param taskExecutionContext  taskExecutionContext
-   */
-  public static void killYarnJob(TaskExecutionContext taskExecutionContext) {
-    try {
-      Thread.sleep(Constants.SLEEP_TIME_MILLIS);
-      LogClientService logClient = null;
-      String log = null;
-      try {
-        logClient = new LogClientService();
-        log = logClient.viewLog(Host.of(taskExecutionContext.getHost()).getIp(),
-                Constants.RPC_PORT,
-                taskExecutionContext.getLogPath());
-      } finally {
-        if (logClient != null) {
-          logClient.close();
-        }
-      }
-      if (StringUtils.isNotEmpty(log)) {
-        List<String> appIds = LoggerUtils.getAppIds(log, logger);
-        String workerDir = taskExecutionContext.getExecutePath();
-        if (StringUtils.isEmpty(workerDir)) {
-          logger.error(""task instance work dir is empty"");
-          throw new RuntimeException(""task instance work dir is empty"");
+    /**
+     * get pids str.
+     *
+     * @param processId process id
+     * @return pids pid String
+     * @throws Exception exception
+     */
+    public static String getPidsStr(int processId) throws Exception {
+        StringBuilder sb = new StringBuilder();
+        Matcher mat = null;
+        // pstree pid get sub pids
+        if (OSUtils.isMacOS()) {
+            String pids = OSUtils.exeCmd(""pstree -sp "" + processId);
+            if (null != pids) {
+                mat = MACPATTERN.matcher(pids);
+            }
+        } else {
+            String pids = OSUtils.exeCmd(""pstree -p "" + processId);","[{'comment': 'i think this ""pstree "" can be extracted to one variable,  then I can easily replace this variable.', 'commenter': 'lenboo'}]"
4042,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/ProcessUtils.java,"@@ -38,368 +41,408 @@
 import java.util.regex.Pattern;
 
 /**
- *  mainly used to get the start command line of a process.
+ * mainly used to get the start command line of a process.
  */
 public class ProcessUtils {
-  /**
-   * logger.
-   */
-  private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
-
-  /**
-   * Initialization regularization, solve the problem of pre-compilation performance,
-   * avoid the thread safety problem of multi-thread operation.
-   */
-  private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
-
-  private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
-
-  /**
-   * build command line characters.
-   * @param commandList command list
-   * @return command
-   */
-  public static String buildCommandStr(List<String> commandList) {
-    String cmdstr;
-    String[] cmd = commandList.toArray(new String[commandList.size()]);
-    SecurityManager security = System.getSecurityManager();
-    boolean allowAmbiguousCommands = false;
-    if (security == null) {
-      allowAmbiguousCommands = true;
-      String value = System.getProperty(""jdk.lang.Process.allowAmbiguousCommands"");
-      if (value != null) {
-        allowAmbiguousCommands = !""false"".equalsIgnoreCase(value);
-      }
+    /**
+     * logger.
+     */
+    private static final Logger logger = LoggerFactory.getLogger(ProcessUtils.class);
+
+    /**
+     * Initialization regularization, solve the problem of pre-compilation performance,
+     * avoid the thread safety problem of multi-thread operation.
+     */
+    private static final Pattern MACPATTERN = Pattern.compile(""-[+|-]-\\s(\\d+)"");
+
+    private static final Pattern WINDOWSATTERN = Pattern.compile(""(\\d+)"");
+
+    private static final String LOCAL_PROCESS_EXEC = ""jdk.lang.Process.allowAmbiguousCommands"";
+
+    /**
+     * build command line characters.
+     *
+     * @param commandList command list
+     * @return command
+     */
+    public static String buildCommandStr(List<String> commandList) {
+        String cmdstr;
+        String[] cmd = commandList.toArray(new String[0]);
+        SecurityManager security = System.getSecurityManager();
+        boolean allowAmbiguousCommands = isAllowAmbiguousCommands(security);
+        if (allowAmbiguousCommands) {
+
+            String executablePath = new File(cmd[0]).getPath();
+
+            if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
+                executablePath = quoteString(executablePath);
+            }
+
+            cmdstr = createCommandLine(
+                VERIFICATION_LEGACY, executablePath, cmd);
+        } else {
+            String executablePath;
+            try {
+                executablePath = getExecutablePath(cmd[0]);
+            } catch (IllegalArgumentException e) {
+
+                StringBuilder join = new StringBuilder();
+                for (String s : cmd) {
+                    join.append(s).append(' ');
+                }
+
+                cmd = getTokensFromCommand(join.toString());
+                executablePath = getExecutablePath(cmd[0]);
+
+                // Check new executable name once more
+                if (security != null) {
+                    security.checkExec(executablePath);
+                }
+            }
+
+            cmdstr = createCommandLine(
+
+                isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+        }
+        return cmdstr;
     }
-    if (allowAmbiguousCommands) {
-
-      String executablePath = new File(cmd[0]).getPath();
-
-      if (needsEscaping(VERIFICATION_LEGACY, executablePath)) {
-        executablePath = quoteString(executablePath);
-      }
-
-      cmdstr = createCommandLine(
-              VERIFICATION_LEGACY, executablePath, cmd);
-    } else {
-      String executablePath;
-      try {
-        executablePath = getExecutablePath(cmd[0]);
-      } catch (IllegalArgumentException e) {
 
-        StringBuilder join = new StringBuilder();
-        for (String s : cmd) {
-          join.append(s).append(' ');
+    /**
+     * check is allow ambiguous commands
+     *
+     * @param security security manager
+     * @return allow ambiguous command flag
+     */
+    private static boolean isAllowAmbiguousCommands(SecurityManager security) {
+        boolean allowAmbiguousCommands = false;
+        if (security == null) {
+            allowAmbiguousCommands = true;
+            String value = System.getProperty(LOCAL_PROCESS_EXEC);
+            if (value != null) {
+                allowAmbiguousCommands = !Constants.STRING_FALSE.equalsIgnoreCase(value);
+            }
         }
+        return allowAmbiguousCommands;
+    }
 
-        cmd = getTokensFromCommand(join.toString());
-        executablePath = getExecutablePath(cmd[0]);
+    /**
+     * get executable path.
+     *
+     * @param path path
+     * @return executable path
+     */
+    private static String getExecutablePath(String path) {
+        boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
+
+        File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
+        return fileToRun.getPath();
+    }
 
-        // Check new executable name once more
-        if (security != null) {
-          security.checkExec(executablePath);
-        }
-      }
+    /**
+     * whether is shell file.
+     *
+     * @param executablePath executable path
+     * @return true if endsWith .CMD or .BAT
+     */
+    private static boolean isShellFile(String executablePath) {
+        String upPath = executablePath.toUpperCase();
+        return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
+    }
 
-      cmdstr = createCommandLine(
+    /**
+     * quote string.
+     *
+     * @param arg argument
+     * @return format arg
+     */
+    private static String quoteString(String arg) {
+        return '""' + arg + '""';
+    }
 
-              isShellFile(executablePath) ? VERIFICATION_CMD_BAT : VERIFICATION_WIN32, quoteString(executablePath), cmd);
+    /**
+     * get tokens from command.
+     *
+     * @param command command
+     * @return token string array
+     */
+    private static String[] getTokensFromCommand(String command) {
+        ArrayList<String> matchList = new ArrayList<>(8);
+        Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
+        while (regexMatcher.find()) {
+            matchList.add(regexMatcher.group());
+        }
+        return matchList.toArray(new String[0]);
     }
-    return cmdstr;
-  }
-
-  /**
-   * get executable path.
-   *
-   * @param path path
-   * @return executable path
-   */
-  private static String getExecutablePath(String path) {
-    boolean pathIsQuoted = isQuoted(true, path, ""Executable name has embedded quote, split the arguments"");
-
-    File fileToRun = new File(pathIsQuoted ? path.substring(1, path.length() - 1) : path);
-    return fileToRun.getPath();
-  }
-
-  /**
-   * whether is shell file.
-   *
-   * @param executablePath executable path
-   * @return true if endsWith .CMD or .BAT
-   */
-  private static boolean isShellFile(String executablePath) {
-    String upPath = executablePath.toUpperCase();
-    return (upPath.endsWith("".CMD"") || upPath.endsWith("".BAT""));
-  }
-
-  /**
-   * quote string.
-   *
-   * @param arg argument
-   * @return format arg
-   */
-  private static String quoteString(String arg) {
-    StringBuilder argbuf = new StringBuilder(arg.length() + 2);
-    return argbuf.append('""').append(arg).append('""').toString();
-  }
-
-  /**
-   * get tokens from command.
-   *
-   * @param command command
-   * @return token string array
-   */
-  private static String[] getTokensFromCommand(String command) {
-    ArrayList<String> matchList = new ArrayList<>(8);
-    Matcher regexMatcher = LazyPattern.PATTERN.matcher(command);
-    while (regexMatcher.find()) {
-      matchList.add(regexMatcher.group());
+
+    /**
+     * Lazy Pattern.
+     */
+    private static class LazyPattern {
+        /**
+         * Escape-support version:
+         * ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
+         */
+        private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
     }
-    return matchList.toArray(new String[matchList.size()]);
-  }
-
-  /**
-   * Lazy Pattern.
-   */
-  private static class LazyPattern {
-    // Escape-support version:
-    // ""(\"")((?:\\\\\\1|.)+?)\\1|([^\\s\""]+)"";
-    private static final Pattern PATTERN = Pattern.compile(""[^\\s\""]+|\""[^\""]*\"""");
-  }
-
-  /**
-   * verification cmd bat.
-   */
-  private static final int VERIFICATION_CMD_BAT = 0;
-
-  /**
-   * verification win32.
-   */
-  private static final int VERIFICATION_WIN32 = 1;
-
-  /**
-   * verification legacy.
-   */
-  private static final int VERIFICATION_LEGACY = 2;
-
-  /**
-   * escape verification.
-   */
-  private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
-
-    {' ', '\t', '<', '>'}, {' ', '\t'}};
-
-  /**
-   * create command line.
-   * @param verificationType  verification type
-   * @param executablePath    executable path
-   * @param cmd               cmd
-   * @return command line
-   */
-  private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
-    StringBuilder cmdbuf = new StringBuilder(80);
-
-    cmdbuf.append(executablePath);
-
-    for (int i = 1; i < cmd.length; ++i) {
-      cmdbuf.append(' ');
-      String s = cmd[i];
-      if (needsEscaping(verificationType, s)) {
-        cmdbuf.append('""').append(s);
-
-        if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
-          cmdbuf.append('\\');
+
+    /**
+     * verification cmd bat.
+     */
+    private static final int VERIFICATION_CMD_BAT = 0;
+
+    /**
+     * verification win32.
+     */
+    private static final int VERIFICATION_WIN32 = 1;
+
+    /**
+     * verification legacy.
+     */
+    private static final int VERIFICATION_LEGACY = 2;
+
+    /**
+     * escape verification.
+     */
+    private static final char[][] ESCAPE_VERIFICATION = {{' ', '\t', '<', '>', '&', '|', '^'},
+
+        {' ', '\t', '<', '>'}, {' ', '\t'}};
+
+    /**
+     * create command line.
+     *
+     * @param verificationType verification type
+     * @param executablePath   executable path
+     * @param cmd              cmd
+     * @return command line
+     */
+    private static String createCommandLine(int verificationType, final String executablePath, final String[] cmd) {
+        StringBuilder cmdbuf = new StringBuilder(80);
+
+        cmdbuf.append(executablePath);
+
+        for (int i = 1; i < cmd.length; ++i) {
+            cmdbuf.append(' ');
+            String s = cmd[i];
+            if (needsEscaping(verificationType, s)) {
+                cmdbuf.append('""').append(s);
+
+                if ((verificationType != VERIFICATION_CMD_BAT) && s.endsWith(""\\"")) {
+                    cmdbuf.append('\\');
+                }
+                cmdbuf.append('""');
+            } else {
+                cmdbuf.append(s);
+            }
         }
-        cmdbuf.append('""');
-      } else {
-        cmdbuf.append(s);
-      }
+        return cmdbuf.toString();
     }
-    return cmdbuf.toString();
-  }
-
-  /**
-   * whether is quoted.
-   * @param noQuotesInside
-   * @param arg
-   * @param errorMessage
-   * @return boolean
-   */
-  private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
-    int lastPos = arg.length() - 1;
-    if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
-      // The argument has already been quoted.
-      if (noQuotesInside) {
-        if (arg.indexOf('""', 1) != lastPos) {
-          // There is [""] inside.
-          throw new IllegalArgumentException(errorMessage);
+
+    /**
+     * whether is quoted.
+     *
+     * @param noQuotesInside no quotes inside
+     * @param arg            arg
+     * @param errorMessage   error message
+     * @return boolean
+     */
+    private static boolean isQuoted(boolean noQuotesInside, String arg, String errorMessage) {
+        int lastPos = arg.length() - 1;
+        if (lastPos >= 1 && arg.charAt(0) == '""' && arg.charAt(lastPos) == '""') {
+            // The argument has already been quoted.
+            if (noQuotesInside && arg.indexOf('""', 1) != lastPos) {
+                // There is [""] inside.
+                throw new IllegalArgumentException(errorMessage);
+            }
+            return true;
         }
-      }
-      return true;
-    }
-    if (noQuotesInside) {
-      if (arg.indexOf('""') >= 0) {
-        // There is [""] inside.
-        throw new IllegalArgumentException(errorMessage);
-      }
-    }
-    return false;
-  }
-
-  /**
-   * whether needs escaping.
-   *
-   * @param verificationType  verification type
-   * @param arg               arg
-   * @return boolean
-   */
-  private static boolean needsEscaping(int verificationType, String arg) {
-
-    boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
-
-    if (!argIsQuoted) {
-      char[] testEscape = ESCAPE_VERIFICATION[verificationType];
-      for (int i = 0; i < testEscape.length; ++i) {
-        if (arg.indexOf(testEscape[i]) >= 0) {
-          return true;
+        if (noQuotesInside && arg.indexOf('""') >= 0) {
+            // There is [""] inside.
+            throw new IllegalArgumentException(errorMessage);
         }
-      }
+        return false;
     }
-    return false;
-  }
-
-  /**
-   * kill yarn application.
-   *
-   * @param appIds      app id list
-   * @param logger      logger
-   * @param tenantCode  tenant code
-   * @param executePath     execute path
-   */
-  public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
-    if (appIds.size() > 0) {
-      String appid = appIds.get(appIds.size() - 1);
-      String commandFile = String
-              .format(""%s/%s.kill"", executePath, appid);
-      String cmd = ""yarn application -kill "" + appid;
-      try {
-        StringBuilder sb = new StringBuilder();
-        sb.append(""#!/bin/sh\n"");
-        sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
-        sb.append(""cd $BASEDIR\n"");
-        if (CommonUtils.getSystemEnvPath() != null) {
-          sb.append(""source "" + CommonUtils.getSystemEnvPath() + ""\n"");
-        }
-        sb.append(""\n\n"");
-        sb.append(cmd);
-
-        File f = new File(commandFile);
 
-        if (!f.exists()) {
-          FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+    /**
+     * whether needs escaping.
+     *
+     * @param verificationType verification type
+     * @param arg              arg
+     * @return boolean
+     */
+    private static boolean needsEscaping(int verificationType, String arg) {
+
+        boolean argIsQuoted = isQuoted((verificationType == VERIFICATION_CMD_BAT), arg, ""Argument has embedded quote, use the explicit CMD.EXE call."");
+
+        if (!argIsQuoted) {
+            char[] testEscape = ESCAPE_VERIFICATION[verificationType];
+            for (char c : testEscape) {
+                if (arg.indexOf(c) >= 0) {
+                    return true;
+                }
+            }
         }
+        return false;
+    }
 
-        String runCmd = ""sh "" + commandFile;
-        if (StringUtils.isNotEmpty(tenantCode)) {
-          runCmd = ""sudo -u "" + tenantCode + "" "" + runCmd;
+    /**
+     * kill yarn application.
+     *
+     * @param appIds      app id list
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param executePath execute path
+     */
+    public static void cancelApplication(List<String> appIds, Logger logger, String tenantCode, String executePath) {
+        if (CollectionUtils.isNotEmpty(appIds)) {
+
+            for (String appId : appIds) {
+                try {
+                    ExecutionStatus applicationStatus = HadoopUtils.getInstance().getApplicationStatus(appId);
+
+                    if (!applicationStatus.typeIsFinished()) {
+                        String commandFile = String
+                            .format(""%s/%s.kill"", executePath, appId);
+                        String cmd = ""yarn application -kill "" + appId;
+                        execYarnKillCommand(logger, tenantCode, appId, commandFile, cmd);
+                    }
+                } catch (Exception e) {
+                    logger.error(String.format(""Get yarn application app id [%s] status failed: [%s]"", appId, e.getMessage()));
+                }
+            }
         }
+    }
 
-        logger.info(""kill cmd:{}"", runCmd);
-
-        Runtime.getRuntime().exec(runCmd);
-      } catch (Exception e) {
-        logger.error(""kill application error"", e);
-      }
+    /**
+     * build kill command for yarn application
+     *
+     * @param logger      logger
+     * @param tenantCode  tenant code
+     * @param appId       app id
+     * @param commandFile command file
+     * @param cmd         cmd
+     */
+    private static void execYarnKillCommand(Logger logger, String tenantCode, String appId, String commandFile, String cmd) {
+        try {
+            StringBuilder sb = new StringBuilder();
+            sb.append(""#!/bin/sh\n"");
+            sb.append(""BASEDIR=$(cd `dirname $0`; pwd)\n"");
+            sb.append(""cd $BASEDIR\n"");
+            if (CommonUtils.getSystemEnvPath() != null) {
+                sb.append(""source "").append(CommonUtils.getSystemEnvPath()).append(""\n"");
+            }
+            sb.append(""\n\n"");
+            sb.append(cmd);
+
+            File f = new File(commandFile);
+
+            if (!f.exists()) {
+                FileUtils.writeStringToFile(new File(commandFile), sb.toString(), StandardCharsets.UTF_8);
+            }
+
+            String runCmd = String.format(""%s %s"", Constants.SH, commandFile);
+            if (StringUtils.isNotEmpty(tenantCode)) {
+                runCmd = ""sudo -u "" + tenantCode + "" "" + runCmd;
+            }
+
+            logger.info(""kill cmd:{}"", runCmd);
+            Runtime.getRuntime().exec(runCmd);","[{'comment': 'please use OSUtils.exeCmd method instead，thx', 'commenter': 'davidzollo'}, {'comment': 'yes, fixed', 'commenter': 'Eights-Li'}]"
4055,dolphinscheduler-dao/src/main/resources/datasource.properties,"@@ -14,12 +14,12 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-        
+
 # postgresql
-spring.datasource.driver-class-name=org.postgresql.Driver
-spring.datasource.url=jdbc:postgresql://localhost:5432/dolphinscheduler
-spring.datasource.username=test
-spring.datasource.password=test
+spring.datasource.driver-class-name=com.mysql.jdbc.Driver","[{'comment': 'please do not change the default settings.', 'commenter': 'lenboo'}]"
4061,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/SparkArgsUtils.java,"@@ -43,11 +42,11 @@
         String deployMode = ""cluster"";
 
         args.add(Constants.MASTER);
-        if(StringUtils.isNotEmpty(param.getDeployMode())){
+        if (StringUtils.isNotEmpty(param.getDeployMode())) {
             deployMode = param.getDeployMode();
 
         }
-        if(!""local"".equals(deployMode)){
+        if (!""local"".equals(deployMode)) {","[{'comment': 'magic number', 'commenter': 'lenboo'}]"
4061,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/spark/SparkTask.java,"@@ -22,133 +23,132 @@
 import org.apache.dolphinscheduler.common.process.ResourceInfo;
 import org.apache.dolphinscheduler.common.task.AbstractParameters;
 import org.apache.dolphinscheduler.common.task.spark.SparkParameters;
-import org.apache.dolphinscheduler.common.utils.*;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
 import org.apache.dolphinscheduler.common.utils.ParameterUtils;
-import org.apache.dolphinscheduler.common.utils.StringUtils;
-import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;
 import org.apache.dolphinscheduler.dao.entity.Resource;
+import org.apache.dolphinscheduler.server.entity.TaskExecutionContext;
 import org.apache.dolphinscheduler.server.utils.ParamUtils;
 import org.apache.dolphinscheduler.server.utils.SparkArgsUtils;
 import org.apache.dolphinscheduler.server.worker.task.AbstractYarnTask;
-import org.slf4j.Logger;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 
+import org.slf4j.Logger;
+
 /**
  * spark task
  */
 public class SparkTask extends AbstractYarnTask {
 
-  /**
-   * spark1 command
-   */
-  private static final String SPARK1_COMMAND = ""${SPARK_HOME1}/bin/spark-submit"";
+    /**
+     * spark1 command
+     */
+    private static final String SPARK1_COMMAND = ""${SPARK_HOME1}/bin/spark-submit"";
+
+    /**
+     * spark2 command
+     */
+    private static final String SPARK2_COMMAND = ""${SPARK_HOME2}/bin/spark-submit"";
+
+    /**
+     * spark parameters
+     */
+    private SparkParameters sparkParameters;
+
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext sparkTaskExecutionContext;
+
+    public SparkTask(TaskExecutionContext taskExecutionContext, Logger logger) {
+        super(taskExecutionContext, logger);
+        this.sparkTaskExecutionContext = taskExecutionContext;
+    }
 
-  /**
-   * spark2 command
-   */
-  private static final String SPARK2_COMMAND = ""${SPARK_HOME2}/bin/spark-submit"";
+    @Override
+    public void init() {
 
-  /**
-   *  spark parameters
-   */
-  private SparkParameters sparkParameters;
+        logger.info(""spark task params {}"", sparkTaskExecutionContext.getTaskParams());
 
-  /**
-   * taskExecutionContext
-   */
-  private TaskExecutionContext taskExecutionContext;
+        sparkParameters = JSONUtils.parseObject(sparkTaskExecutionContext.getTaskParams(), SparkParameters.class);
 
-  public SparkTask(TaskExecutionContext taskExecutionContext, Logger logger) {
-    super(taskExecutionContext, logger);
-    this.taskExecutionContext = taskExecutionContext;
-  }
+        if (null == sparkParameters) {
+            logger.error(""Spark params is null"");
+            return;
+        }
 
-  @Override
-  public void init() {
+        if (!sparkParameters.checkParameters()) {
+            throw new RuntimeException(""spark task params is not valid"");
+        }
+        sparkParameters.setQueue(sparkTaskExecutionContext.getQueue());
+        setMainJarName();
+    }
 
-    logger.info(""spark task params {}"", taskExecutionContext.getTaskParams());
+    /**
+     * create command
+     *
+     * @return command
+     */
+    @Override
+    protected String buildCommand() {
+        List<String> args = new ArrayList<>();
 
-    sparkParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), SparkParameters.class);
+        //spark version
+        String sparkCommand = SPARK2_COMMAND;
 
-    if (!sparkParameters.checkParameters()) {
-      throw new RuntimeException(""spark task params is not valid"");
-    }
-    sparkParameters.setQueue(taskExecutionContext.getQueue());
+        if (SparkVersion.SPARK1.name().equals(sparkParameters.getSparkVersion())) {
+            sparkCommand = SPARK1_COMMAND;
+        }
 
-    setMainJarName();
+        args.add(sparkCommand);
 
-    if (StringUtils.isNotEmpty(sparkParameters.getMainArgs())) {
-      String args = sparkParameters.getMainArgs();
+        // other parameters
+        args.addAll(SparkArgsUtils.buildArgs(sparkParameters));
 
-      // replace placeholder
-      Map<String, Property> paramsMap = ParamUtils.convert(ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams()),
-              taskExecutionContext.getDefinedParams(),
-              sparkParameters.getLocalParametersMap(),
-              CommandType.of(taskExecutionContext.getCmdTypeIfComplement()),
-              taskExecutionContext.getScheduleTime());
+        // replace placeholder
+        Map<String, Property> paramsMap = ParamUtils.convert(ParamUtils.getUserDefParamsMap(sparkTaskExecutionContext.getDefinedParams()),
+            sparkTaskExecutionContext.getDefinedParams(),
+            sparkParameters.getLocalParametersMap(),
+            CommandType.of(sparkTaskExecutionContext.getCmdTypeIfComplement()),
+            sparkTaskExecutionContext.getScheduleTime());
 
-      if (paramsMap != null ){
-        args = ParameterUtils.convertParameterPlaceholders(args, ParamUtils.convert(paramsMap));
-      }
-      sparkParameters.setMainArgs(args);
-    }
-  }
+        String command = null;
 
-  /**
-   * create command
-   * @return command
-   */
-  @Override
-  protected String buildCommand() {
-    List<String> args = new ArrayList<>();
+        if (null != paramsMap) {
+            command = ParameterUtils.convertParameterPlaceholders(String.join("" "", args), ParamUtils.convert(paramsMap));
+        }
 
-    //spark version
-    String sparkCommand = SPARK2_COMMAND;
+        logger.info(""spark task command: {}"", command);
 
-    if (SparkVersion.SPARK1.name().equals(sparkParameters.getSparkVersion())) {
-      sparkCommand = SPARK1_COMMAND;
+        return command;
     }
 
-    args.add(sparkCommand);
-
-    // other parameters
-    args.addAll(SparkArgsUtils.buildArgs(sparkParameters));
-
-    String command = ParameterUtils
-            .convertParameterPlaceholders(String.join("" "", args), taskExecutionContext.getDefinedParams());
-
-    logger.info(""spark task command : {}"", command);
-
-    return command;
-  }
-
-  @Override
-  protected void setMainJarName() {
-    // main jar
-    ResourceInfo mainJar = sparkParameters.getMainJar();
-    if (mainJar != null) {
-      int resourceId = mainJar.getId();
-      String resourceName;
-      if (resourceId == 0) {
-        resourceName = mainJar.getRes();
-      } else {
-        Resource resource = processService.getResourceById(sparkParameters.getMainJar().getId());
-        if (resource == null) {
-          logger.error(""resource id: {} not exist"", resourceId);
-          throw new RuntimeException(String.format(""resource id: %d not exist"", resourceId));
+    @Override
+    protected void setMainJarName() {
+        // main jar
+        ResourceInfo mainJar = sparkParameters.getMainJar();
+        if (mainJar != null) {","[{'comment': ""i think it's better to return void or throw ex if null."", 'commenter': 'lenboo'}]"
4165,dolphinscheduler-alert-plugin/dolphinscheduler-alert-http/src/main/java/org/apache/dolphinscheduler/plugin/alert/http/HttpAlertChannel.java,"@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.alert.http;
+
+import org.apache.dolphinscheduler.spi.alert.AlertChannel;
+import org.apache.dolphinscheduler.spi.alert.AlertData;
+import org.apache.dolphinscheduler.spi.alert.AlertInfo;
+import org.apache.dolphinscheduler.spi.alert.AlertResult;
+import org.apache.dolphinscheduler.spi.params.PluginParamsTransfer;
+
+import java.util.Map;
+
+/**
+ * http alert channel,use sms message to seed the alertInfo
+ */
+public class HttpAlertChannel implements AlertChannel {
+    @Override
+    public AlertResult process(AlertInfo alertInfo) {
+
+        AlertData alertData = alertInfo.getAlertData();
+        String alertParams = alertInfo.getAlertParams();
+        Map<String, String> paramsMap = PluginParamsTransfer.getPluginParamsMap(alertParams);
+
+        return new HttpSender(paramsMap).send(alertData.getContent());","[{'comment': 'The key fields of alert are title and content. I suggest to combine title and content to form complete information.', 'commenter': 'CalvinKirs'}, {'comment': 'I will modify it later', 'commenter': 'CalvinKirs'}]"
4303,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java,"@@ -74,20 +90,20 @@
      */
     @ApiOperation(value = ""startProcessInstance"", notes = ""RUN_PROCESS_INSTANCE_NOTES"")
     @ApiImplicitParams({
-            @ApiImplicitParam(name = ""processDefinitionId"", value = ""PROCESS_DEFINITION_ID"", required = true, dataType = ""Int"", example = ""100""),
-            @ApiImplicitParam(name = ""scheduleTime"", value = ""SCHEDULE_TIME"", required = true, dataType = ""String""),
-            @ApiImplicitParam(name = ""failureStrategy"", value = ""FAILURE_STRATEGY"", required = true, dataType = ""FailureStrategy""),
-            @ApiImplicitParam(name = ""startNodeList"", value = ""START_NODE_LIST"", dataType = ""String""),
-            @ApiImplicitParam(name = ""taskDependType"", value = ""TASK_DEPEND_TYPE"", dataType = ""TaskDependType""),
-            @ApiImplicitParam(name = ""execType"", value = ""COMMAND_TYPE"", dataType = ""CommandType""),
-            @ApiImplicitParam(name = ""warningType"", value = ""WARNING_TYPE"", required = true, dataType = ""WarningType""),
-            @ApiImplicitParam(name = ""warningGroupId"", value = ""WARNING_GROUP_ID"", required = true, dataType = ""Int"", example = ""100""),
-            @ApiImplicitParam(name = ""receivers"", value = ""RECEIVERS"", dataType = ""String""),
-            @ApiImplicitParam(name = ""receiversCc"", value = ""RECEIVERS_CC"", dataType = ""String""),
-            @ApiImplicitParam(name = ""runMode"", value = ""RUN_MODE"", dataType = ""RunMode""),
-            @ApiImplicitParam(name = ""processInstancePriority"", value = ""PROCESS_INSTANCE_PRIORITY"", required = true, dataType = ""Priority""),
-            @ApiImplicitParam(name = ""workerGroup"", value = ""WORKER_GROUP"", dataType = ""String"", example = ""default""),
-            @ApiImplicitParam(name = ""timeout"", value = ""TIMEOUT"", dataType = ""Int"", example = ""100""),
+        @ApiImplicitParam(name = ""processDefinitionId"", value = ""PROCESS_DEFINITION_ID"", required = true, dataType = ""Int"", example = ""100""),
+        @ApiImplicitParam(name = ""scheduleTime"", value = ""SCHEDULE_TIME"", required = true, dataType = ""String""),
+        @ApiImplicitParam(name = ""failureStrategy"", value = ""FAILURE_STRATEGY"", required = true, dataType = ""FailureStrategy""),
+        @ApiImplicitParam(name = ""startNodeList"", value = ""START_NODE_LIST"", dataType = ""String""),
+        @ApiImplicitParam(name = ""taskDependType"", value = ""TASK_DEPEND_TYPE"", dataType = ""TaskDependType""),
+        @ApiImplicitParam(name = ""execType"", value = ""COMMAND_TYPE"", dataType = ""CommandType""),
+        @ApiImplicitParam(name = ""warningType"", value = ""WARNING_TYPE"", required = true, dataType = ""WarningType""),
+        @ApiImplicitParam(name = ""warningGroupId"", value = ""WARNING_GROUP_ID"", required = true, dataType = ""Int"", example = ""100""),
+        @ApiImplicitParam(name = ""receivers"", value = ""RECEIVERS"", dataType = ""String""),","[{'comment': 'Why is there still receivers and receiversCc here ?', 'commenter': 'EricJoy2048'}]"
4303,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -99,31 +97,31 @@ public int updateAlert(AlertStatus alertStatus, String log, int id) {
     /**
      * query user list by alert group id
      *
-     * @param alerGroupId alerGroupId
+     * @param alertGroupId alertGroupId
      * @return user list
      */
-    public List<User> queryUserByAlertGroupId(int alerGroupId) {
+    public List<User> queryUserByAlertGroupId(int alertGroupId) {","[{'comment': 'I think alert group and user no longer have any relationship in this feature. So this method need be delete.', 'commenter': 'EricJoy2048'}]"
4303,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -207,11 +193,11 @@ public void sendTaskTimeoutAlert(int alertgroupId, String receivers, String rece
     /**
      * list user information by alert group id
      *
-     * @param alertgroupId alertgroupId
+     * @param alertGroupId alertGroupId
      * @return user list
      */
-    public List<User> listUserByAlertgroupId(int alertgroupId) {
-        return userAlertGroupMapper.listUserByAlertgroupId(alertgroupId);
+    public List<User> listUserByAlertGroupId(int alertGroupId) {
+        return userAlertGroupMapper.listUserByAlertGroupId(alertGroupId);","[{'comment': 'UserAlertGroupMapper need be delete in this feature.', 'commenter': 'EricJoy2048'}]"
4303,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/mapper/UserAlertGroupMapper.java,"@@ -30,16 +30,18 @@
 
     /**
      * delete user alertgroup relation by alertgroupId
-     * @param alertgroupId alertgroupId
+     *
+     * @param alertGroupId alertGroupId
      * @return delete result
      */
-    int deleteByAlertgroupId(@Param(""alertgroupId"") int alertgroupId);
+    int deleteByAlertGroupId(@Param(""alertgroupId"") int alertGroupId);
 
     /**
-     *  list user by alertgroupId
-     * @param alertgroupId alertgroupId
+     * list user by alertgroupId
+     *
+     * @param alertGroupId alertgroupId
      * @return user list
      */
-    List<User> listUserByAlertgroupId(@Param(""alertgroupId"") int alertgroupId);
+    List<User> listUserByAlertGroupId(@Param(""alertgroupId"") int alertGroupId);","[{'comment': 'UserAlertGroupMapper is need be delete in this feature.', 'commenter': 'EricJoy2048'}]"
4374,README.md,"@@ -17,20 +17,20 @@ Dolphin Scheduler Official Website
 
 ### Design features:
 
-A distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for data processing.
+Dolphin Scheduler is a distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for the data processing process.
 
 Its main objectives are as follows:
 
- - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of task in real time.
- - Support many task types: Shell, MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Sub_Process, Procedure, etc.
+ - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of the task in real-time.
+ - Support many task types: Shell, MR, Spark, SQL (MySQL, PostgreSQL, hive, spark SQL), Python, Sub_Process, Procedure, etc.
  - Support process scheduling, dependency scheduling, manual scheduling, manual pause/stop/recovery, support for failed retry/alarm, recovery from specified nodes, Kill task, etc.
- - Support process priority, task priority and task failover and task timeout alarm/failure
+ - Support process priority, task priority and task failover, and task timeout alarm/failure
  - Support process global parameters and node custom parameter settings
  - Support online upload/download of resource files, management, etc. Support online file creation and editing
  - Support task log online viewing and scrolling, online download log, etc.
  - Implement cluster HA, decentralize Master cluster and Worker cluster through Zookeeper
- - Support online viewing of `Master/Worker` cpu load, memory
- - Support process running history tree/gantt chart display, support task status statistics, process status statistics
+ - Support online viewing of `Master/Worker` CPU load, memory","[{'comment': ' - Support viewing of `Master/Worker` CPU load, memory, and CPU usage metrics', 'commenter': 'Tianqi-Dotes'}]"
4374,README.md,"@@ -17,20 +17,20 @@ Dolphin Scheduler Official Website
 
 ### Design features:
 
-A distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for data processing.
+Dolphin Scheduler is a distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for the data processing process.
 
 Its main objectives are as follows:
 
- - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of task in real time.
- - Support many task types: Shell, MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Sub_Process, Procedure, etc.
+ - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of the task in real-time.
+ - Support many task types: Shell, MR, Spark, SQL (MySQL, PostgreSQL, hive, spark SQL), Python, Sub_Process, Procedure, etc.
  - Support process scheduling, dependency scheduling, manual scheduling, manual pause/stop/recovery, support for failed retry/alarm, recovery from specified nodes, Kill task, etc.
- - Support process priority, task priority and task failover and task timeout alarm/failure
+ - Support process priority, task priority and task failover, and task timeout alarm/failure","[{'comment': ""I hold the view that no need to use double 'and' here.\r\n - Support process priority, task priority, task failover, and task timeout alarm or failure\r\nor\r\n - Support process priority, task priority, failover, and timeout alarm or failure\r\nmaybe better and please consider using 'workflow' instead of 'process'"", 'commenter': 'Tianqi-Dotes'}]"
4374,README.md,"@@ -17,20 +17,20 @@ Dolphin Scheduler Official Website
 
 ### Design features:
 
-A distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for data processing.
+Dolphin Scheduler is a distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for the data processing process.
 
 Its main objectives are as follows:
 
- - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of task in real time.
- - Support many task types: Shell, MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Sub_Process, Procedure, etc.
+ - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of the task in real-time.
+ - Support many task types: Shell, MR, Spark, SQL (MySQL, PostgreSQL, hive, spark SQL), Python, Sub_Process, Procedure, etc.
  - Support process scheduling, dependency scheduling, manual scheduling, manual pause/stop/recovery, support for failed retry/alarm, recovery from specified nodes, Kill task, etc.
- - Support process priority, task priority and task failover and task timeout alarm/failure
+ - Support process priority, task priority and task failover, and task timeout alarm/failure
  - Support process global parameters and node custom parameter settings
  - Support online upload/download of resource files, management, etc. Support online file creation and editing
  - Support task log online viewing and scrolling, online download log, etc.
  - Implement cluster HA, decentralize Master cluster and Worker cluster through Zookeeper
- - Support online viewing of `Master/Worker` cpu load, memory
- - Support process running history tree/gantt chart display, support task status statistics, process status statistics
+ - Support online viewing of `Master/Worker` CPU load, memory
+ - Support process running history tree/Gantt chart display, support task status statistics, process status statistics","[{'comment': ' - Support graphing history tree/Gantt chart, task status statistics, and process status statistics (to the workflow)\r\nmight be better.', 'commenter': 'Tianqi-Dotes'}, {'comment': 'Hi, \r\n""Support presenting tree or Gantt chart of workflow history as well as the statistics results of task & process status in each workflow."" \r\nCould you please check if this version clearly and precisely shows the original meaning? I am afraid I misunderstood this sentence to the other side.', 'commenter': 'ptyp'}]"
4374,README.md,"@@ -41,9 +41,9 @@ Its main objectives are as follows:
 
  Stability | Easy to use | Features | Scalability |
  -- | -- | -- | --
-Decentralized multi-master and multi-worker | Visualization process defines key information such as task status, task type, retry times, task running machine, visual variables and so on at a glance.  |  Support pause, recover operation | support custom task types
-HA is supported by itself | All process definition operations are visualized, dragging tasks to draw DAGs, configuring data sources and resources. At the same time, for third-party systems, the api mode operation is provided. | Users on DolphinScheduler can achieve many-to-one or one-to-one mapping relationship through tenants and Hadoop users, which is very important for scheduling large data jobs. "" | The scheduler uses distributed scheduling, and the overall scheduling capability will increase linearly with the scale of the cluster. Master and Worker support dynamic online and offline.
-Overload processing: Task queue mechanism, the number of schedulable tasks on a single machine can be flexibly configured, when too many tasks will be cached in the task queue, will not cause machine jam. | One-click deployment | Supports traditional shell tasks, and also support big data platform task scheduling: MR, Spark, SQL (mysql, postgresql, hive, sparksql), Python, Procedure, Sub_Process |  |
+Decentralized multi-master and multi-worker | Visualization process defines key information such as task status, task type, retry times, task running machine, visual variables, and so on at a glance.  |  Support pause, recover operation | Support custom task types
+HA is supported by itself | All process definition operations are visualized, dragging tasks to draw DAGs, configuring data sources and resources. At the same time, for third-party systems, the API mode operation is provided. | Users on Dolphin Scheduler can achieve many-to-one or one-to-one mapping relationship through tenants and Hadoop users, which is very important for scheduling large data jobs.  | The scheduler uses distributed scheduling, and the overall scheduling capability will increase linearly with the scale of the cluster. Master and Worker support dynamic online and offline.","[{'comment': ""hi, please consider the accordance of the verb 'Support' or 'Supports' in column 'Features'"", 'commenter': 'Tianqi-Dotes'}, {'comment': ""Hi, actually I can't quite understand these sentences or phrases and this chart is missing in the Chinese version. Hence, I just roughly had a look and modified this part. I will fix the third person singular later but sorry I can't go deeper."", 'commenter': 'ptyp'}]"
4374,README.md,"@@ -59,12 +59,11 @@ Overload processing: Task queue mechanism, the number of schedulable tasks on a
 
 
 ### Recent R&D plan
-Work plan of Dolphin Scheduler: [R&D plan](https://github.com/apache/incubator-dolphinscheduler/projects/1), which `In Develop` card shows the features that are currently being developed and TODO card means what needs to be done(including feature ideas).
+The work plan of Dolphin Scheduler: [R&D plan](https://github.com/apache/incubator-dolphinscheduler/projects/1), which `In Develop` card shows the features that are currently being developed and TODO card lists what needs to be done(including feature ideas).","[{'comment': 'The work plan of Dolphin Scheduler: [R&D plan](https://github.com/apache/incubator-dolphinscheduler/projects/1), in which the `Doing` column shows the features are currently being developed and the `TODO` column lists what needs to be done (including feature ideas).\r\n ', 'commenter': 'Tianqi-Dotes'}, {'comment': 'Hi, I thought ""develop"" here is considered as a transitive verb. I keep the idea of not add the preposition ""in"" since the precondition of placing the preposition before the which clause instead of the end of a sentence is the preposition exists. Whats\' your opinion here?', 'commenter': 'ptyp'}]"
4374,README.md,"@@ -81,14 +80,14 @@ dolphinscheduler-dist/target/apache-dolphinscheduler-incubating-${latest.release
 
 ### Thanks
 
-Dolphin Scheduler is based on a lot of excellent open-source projects, such as google guava, guice, grpc, netty, ali bonecp, quartz, and many open source projects of apache and so on.
-Thanks to the contributions of these open source projects, the birth of Dolphin Scheduler comes true. We are very grateful for all the open source software used! We hope that we are not only the beneficiaries of open source, but also be the open source contributors. Besides, we also hope that partners who have the same passion and conviction for open source will join in and contribute to open source!
+Dolphin Scheduler is based on a lot of excellent open-source projects, such as google guava, guice, grpc, netty, ali bonecp, quartz, and many open-source projects of Apache and so on.
+Thanks to the contributions of these open-source projects, the dream of Dolphin Scheduler comes true. We are very grateful for all the open-source softwares used! We hope that we are not only the beneficiaries of open-source, but also be the open-source contributors. Besides, we expect the partners who have the same passion and conviction to open-source will join in and contribute to open-source community!","[{'comment': 'Thanks to the contributions of these open-source projects, the dream of Dolphin Scheduler comes true.\r\nThanks to the contributions of these open-source projects make (or assist) the dream of Dolphin Scheduler comes true.\r\n\r\nbut also be the open-source contributors.\r\nbut also reward back to the community.(maybe better)', 'commenter': 'Tianqi-Dotes'}]"
4441,dolphinscheduler-ui/src/js/module/i18n/locale/en_US.js,"@@ -211,8 +211,13 @@ export default {
   'Edit alarm group': 'Edit alarm group',
   'Create alarm group': 'Create alarm group',
   'Group Name': 'Group Name',
+  'Create Alarm Instance': 'Create Alarm Instance',","[{'comment': 'In `en_US.js` and `zh_CN.js`, it would be better to keep one-to-one correspondence line by line.\r\n\r\nThe`The os tenant code cannot be all numbers` at line 195 in `en_US.js` should be removed.\r\n\r\nAnd then, the order of `Create Alarm Instance`, `Edit Alarm Instanc` and `Alarm instance name` should be same with `zh_CN.js`\r\n\r\nSimilarly, there is also a pair of `Tenant Name` and `Queue`.\r\n', 'commenter': 'chengshiwen'}, {'comment': 'The number of English lines has been adjusted', 'commenter': 'break60'}]"
4441,dolphinscheduler-ui/src/js/conf/home/pages/security/pages/warningInstance/index.vue,"@@ -0,0 +1,169 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+<template>
+  <m-list-construction :title=""$t('Warning instance manage')"">
+    <template slot=""conditions"">
+      <m-conditions @on-conditions=""_onConditions"">
+        <template slot=""button-group"" v-if=""isADMIN"">
+          <el-button size=""mini"" @click=""_create('')"">{{$t('Create Alarm Instance')}}</el-button>
+          <el-dialog
+            :visible.sync=""createWarningDialog""
+            width=""45%"">","[{'comment': 'The `width` should be `auto`, otherwise widescreen problem will occur. ', 'commenter': 'chengshiwen'}, {'comment': 'This is because form-create itself has a style. If it is not fixed, it will turn the bullet box into 100%. I will fix this problem in the next pr', 'commenter': 'break60'}]"
4586,pom.xml,"@@ -563,21 +563,18 @@
                 <groupId>org.sonatype.aether</groupId>
                 <artifactId>aether-api</artifactId>
                 <version>1.13.1</version>
-                <scope>provided</scope>","[{'comment': 'Why change this ""scope"" ?', 'commenter': 'EricJoy2048'}]"
4586,pom.xml,"@@ -563,21 +563,18 @@
                 <groupId>org.sonatype.aether</groupId>
                 <artifactId>aether-api</artifactId>
                 <version>1.13.1</version>
-                <scope>provided</scope>
             </dependency>
 
             <dependency>
                 <groupId>io.airlift.resolver</groupId>
                 <artifactId>resolver</artifactId>
                 <version>1.5</version>
-                <scope>provided</scope>","[{'comment': 'aether-api, resolver and asm only used in local development mode, used to load the plug-in through maven to load the plug-in pom.xml file configured in alert.properties to facilitate debugging during development. Not required when the server deployment is running.\r\n', 'commenter': 'EricJoy2048'}]"
4586,dolphinscheduler-alert/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java,"@@ -20,8 +20,8 @@
 import static org.apache.dolphinscheduler.common.Constants.ALERT_RPC_PORT;
 
 import org.apache.dolphinscheduler.alert.plugin.AlertPluginManager;
-import org.apache.dolphinscheduler.alert.plugin.DolphinPluginLoader;
-import org.apache.dolphinscheduler.alert.plugin.DolphinPluginManagerConfig;
+import org.apache.dolphinscheduler.common.plugin.DolphinPluginLoader;
+import org.apache.dolphinscheduler.common.plugin.DolphinPluginManagerConfig;","[{'comment': 'These lines will resulting **import order** problems and **check style failure**', 'commenter': 'chengshiwen'}]"
4586,dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/AlertServerTest.java,"@@ -18,8 +18,8 @@
 package org.apache.dolphinscheduler.alert;
 
 import org.apache.dolphinscheduler.alert.plugin.AlertPluginManager;
-import org.apache.dolphinscheduler.alert.plugin.DolphinPluginLoader;
-import org.apache.dolphinscheduler.alert.plugin.DolphinPluginManagerConfig;
+import org.apache.dolphinscheduler.common.plugin.DolphinPluginLoader;
+import org.apache.dolphinscheduler.common.plugin.DolphinPluginManagerConfig;","[{'comment': 'import order problem', 'commenter': 'chengshiwen'}]"
4586,dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/plugin/AlertPluginManagerTest.java,"@@ -60,6 +62,6 @@ public void testLoadPlugins() throws Exception {
             throw new RuntimeException(""load Alert Plugin Failed !"", e);
         }
 
-        Assert.assertNotNull(alertPluginManager.getAlertChannelFactoryMap().get(""email alert""));
+        Assert.assertNotNull(alertPluginManager.getAlertChannelFactoryMap().get(""Email""));","[{'comment': ""Avoid the magic number `Email`, and it's better to use a **Constant**"", 'commenter': 'chengshiwen'}]"
4586,dolphinscheduler-alert/src/test/java/org/apache/dolphinscheduler/alert/plugin/DolphinPluginLoaderTest.java,"@@ -55,6 +48,6 @@ public void testLoadPlugins() throws Exception {
             throw new RuntimeException(""load Alert Plugin Failed !"", e);
         }
 
-        Assert.assertNotNull(alertPluginManager.getAlertChannelFactoryMap().get(""email alert""));
+        Assert.assertNotNull(alertPluginManager.getAlertChannelFactoryMap().get(""Email""));","[{'comment': 'Avoid the magic number `Email`', 'commenter': 'chengshiwen'}, {'comment': 'The alert module does not depend on specific plug-in modules, so defining constants here may not be a good solution.', 'commenter': 'CalvinKirs'}]"
4614,README.md,"@@ -15,38 +15,38 @@ Dolphin Scheduler Official Website
 [![CN doc](https://img.shields.io/badge/文档-中文版-blue.svg)](README_zh_CN.md)
 
 
-### Design features:
+### Design Features:
 
-Dolphin Scheduler is a distributed and easy-to-extend visual DAG workflow scheduling system. It dedicates to solving the complex dependencies in data processing to make the scheduling system `out of the box` for the data processing process.
+DolphinScheduler is a distributed and extensible workflow scheduler platform with powerful DAG visual interfaces, dedicated to solving complex job dependencies in the data pipeline and providing multiple types of jobs available `out of the box`. 
 
 Its main objectives are as follows:
 
  - Associate the tasks according to the dependencies of the tasks in a DAG graph, which can visualize the running state of the task in real-time.
- - Support many task types: Shell, MR, Spark, SQL (MySQL, PostgreSQL, hive, spark SQL), Python, Sub_Process, Procedure, etc.
- - Support process scheduling, dependency scheduling, manual scheduling, manual pause/stop/recovery, support for failed retry/alarm, recovery from specified nodes, Kill task, etc.
- - Support the priority of process & task, task failover, and task timeout alarm or failure.
- - Support process global parameters and node custom parameter settings.
- - Support online upload/download of resource files, management, etc. Support online file creation and editing.
- - Support task log online viewing and scrolling, online download log, etc.
- - Implement cluster HA, decentralize Master cluster and Worker cluster through Zookeeper.
+ - Support various task types: Shell, MR, Spark, SQL (MySQL, PostgreSQL, hive, spark SQL), Python, Sub_Process, Procedure, etc.
+ - Support scheduling of workflows and dependencies, manual scheduling to pause/stop/recovery task, support failure task retry/alarm, recovery specified nodes from failure, kill task, etc.","[{'comment': '`pause/stop/recovery` should be `pause/stop/recover`', 'commenter': 'Segun-Ogundipe'}, {'comment': '`recovery specified nodes` should be `recover specified nodes`', 'commenter': 'Segun-Ogundipe'}, {'comment': '@Segun-Ogundipe \r\nhi Segun,\r\nDeeply thanx for reviewing this passage.\r\nThanks\r\nYours sincerely\r\nTIanqi', 'commenter': 'Tianqi-Dotes'}, {'comment': ""You're welcome @Tianqi-Dotes\r\n\r\nRegards"", 'commenter': 'Segun-Ogundipe'}]"
4614,README.md,"@@ -81,7 +81,7 @@ dolphinscheduler-dist/target/apache-dolphinscheduler-incubating-${latest.release
 ### Thanks
 
 Dolphin Scheduler is based on a lot of excellent open-source projects, such as google guava, guice, grpc, netty, ali bonecp, quartz, and many open-source projects of Apache and so on.
-We would like to express our deep gratitude to all the open-source projects which contribute to making the dream of Dolphin Scheduler comes true. We hope that we are not only the beneficiaries of open-source, but also give back to the community. Besides, we expect the partners who have the same passion and conviction to open-source will join in and contribute to the open-source community!
+We would like to express our deep gratitude to all the open-source projects assist Dolphin Scheduler. We hope that we are not only the beneficiaries of open-source, but also give back to the community. Besides, we expect the partners who have the same passion and conviction to open-source could join in and contribute to the open-source community!","[{'comment': '`We would like to express our deep gratitude to all the open-source projects assist Dolphin Scheduler` should be `We would like to express our deep gratitude to all the open-source projects used in Dolphin Scheduler`', 'commenter': 'Segun-Ogundipe'}, {'comment': '`we expect the partners who have the same passion and conviction to open-source could join in and contribute to the open-source community!` should be `we hope that partners who have the same enthusiasm and passion for open source could join in and contribute to the open-source community!`', 'commenter': 'Segun-Ogundipe'}, {'comment': 'I update the relate content, thanks for all your greate work', 'commenter': 'davidzollo'}]"
4618,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -348,12 +348,14 @@ public void run() {
 
                     long lastFlushTime = System.currentTimeMillis();
 
-                    while ((line = inReader.readLine()) != null) {
+                    while ((line = inReader.readLine()) != null || logBuffer.size() > 0) {","[{'comment': 'If line is `null`, an Exception will occur', 'commenter': 'chengshiwen'}, {'comment': 'If line is null  check logBuffer.size()>0 ，so lastFlushTime = flush(lastFlushTime); can have a chance to exec. old code  while ((line = inReader.readLine()) != null)   cause  lastFlushTime = flush(lastFlushTime);  have no chance to exec.', 'commenter': '597365581'}, {'comment': 'If line is null, an Exception will occur--->has modify', 'commenter': '597365581'}, {'comment': 'Do you have tested it? And could you give why it can take effect?', 'commenter': 'chengshiwen'}, {'comment': 'yes   test is ok.   log  refresh in time', 'commenter': '597365581'}, {'comment': 'of course, test is ok so I commit this pr.', 'commenter': '597365581'}, {'comment': '兄弟，空了帮忙再review下，我现在改成了 inReader.readLine() 和logBuffer 处理 放在两个线程中处理了。', 'commenter': '597365581'}, {'comment': '@597365581 Maybe you should pass the **SonarCloud Code Analysis** at first', 'commenter': 'chengshiwen'}, {'comment': '@chengshiwen of course，the SonarCloud Code Analysis must pass', 'commenter': '597365581'}, {'comment': '@chengshiwen @dailidong  please help to review ，thanks', 'commenter': '597365581'}, {'comment': '@lenboo please help to review ，thanks', 'commenter': '597365581'}, {'comment': '@CalvinKirs  please help to review ，thanks', 'commenter': '597365581'}]"
4618,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -336,32 +338,50 @@ private void clear() {
      */
     private void parseProcessOutput(Process process) {
         String threadLoggerInfoName = String.format(LoggerUtils.TASK_LOGGER_THREAD_NAME + ""-%s"", taskExecutionContext.getTaskAppId());
-        ExecutorService parseProcessOutputExecutorService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName);
-        parseProcessOutputExecutorService.submit(new Runnable() {
+        ExecutorService getOutputLogService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName + ""-"" + ""getOutputLogService"");
+        getOutputLogService.submit(new Runnable() {","[{'comment': 'Use lambda expression substitution, which will make the code look concise.', 'commenter': 'CalvinKirs'}, {'comment': 'ok，code  had changed', 'commenter': '597365581'}, {'comment': '` \r\nparseProcessOutputExecutorService.submit(() -> {\r\n            BufferedReader inReader = null;\r\n\r\n            try {\r\n                inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));\r\n                String line;\r\n\r\n                long lastFlushTime = System.currentTimeMillis();\r\n\r\n                while ((line = inReader.readLine()) != null) {\r\n                    if (line.startsWith(""${setValue("")) {\r\n                        varPool.append(line.substring(""${setValue("".length(), line.length() - 2));\r\n                        varPool.append(""$VarPool$"");\r\n                    } else {\r\n                        logBuffer.add(line);\r\n                        lastFlushTime = flush(lastFlushTime);\r\n                    }\r\n                }\r\n            } catch (Exception e) {\r\n                logger.error(e.getMessage(), e);\r\n            } finally {\r\n                clear();\r\n                close(inReader);\r\n            }\r\n        });\r\n`', 'commenter': 'CalvinKirs'}, {'comment': 'what？', 'commenter': '597365581'}]"
4618,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -336,32 +338,50 @@ private void clear() {
      */
     private void parseProcessOutput(Process process) {
         String threadLoggerInfoName = String.format(LoggerUtils.TASK_LOGGER_THREAD_NAME + ""-%s"", taskExecutionContext.getTaskAppId());
-        ExecutorService parseProcessOutputExecutorService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName);
-        parseProcessOutputExecutorService.submit(new Runnable() {
+        ExecutorService getOutputLogService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName + ""-"" + ""getOutputLogService"");
+        getOutputLogService.submit(new Runnable() {
             @Override
             public void run() {
                 BufferedReader inReader = null;
 
                 try {
                     inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));","[{'comment': 'Is there a problem here? Does ErrorStream cause blocking?', 'commenter': 'CalvinKirs'}, {'comment': 'I found DS code  has set processBuilder.redirectErrorStream(true);  before.', 'commenter': '597365581'}]"
4620,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/WorkerGroupService.java,"@@ -159,13 +159,19 @@
         for (String workerGroup : workerGroupList) {
             String workerGroupPath = workerPath + ""/"" + workerGroup;
             List<String> childrenNodes = zookeeperCachedOperator.getChildrenKeys(workerGroupPath);
+            String timeStamp = """";
+            for (int i = 0; i < childrenNodes.size(); i++) {
+                String ip = childrenNodes.get(i);
+                childrenNodes.set(i, ip.substring(0, ip.lastIndexOf("":"")));
+                timeStamp = ip.substring(ip.lastIndexOf("":""));
+            }
             if (CollectionUtils.isNotEmpty(childrenNodes)) {
                 availableWorkerGroupList.add(workerGroup);","[{'comment': 'delete it', 'commenter': 'CalvinKirs'}]"
4722,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/StringUtils.java,"@@ -69,4 +72,40 @@ public static String defaultIfBlank(String str, String defaultStr) {
     public static boolean equalsIgnoreCase(String str1, String str2) {
         return str1 == null ? str2 == null : str1.equalsIgnoreCase(str2);
     }
+","[{'comment': 'Please add comments for public methods.', 'commenter': 'CalvinKirs'}, {'comment': 'done.', 'commenter': 'zhuangchong'}]"
4747,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -125,10 +125,6 @@ public void run() {
                 int fetchTaskNum = masterConfig.getMasterDispatchTaskNumber();
                 failedDispatchTasks.clear();
                 for (int i = 0; i < fetchTaskNum; i++) {
-                    if (taskPriorityQueue.size() <= 0) {
-                        Thread.sleep(Constants.SLEEP_TIME_MILLIS);","[{'comment': 'See for specific reasons #4140', 'commenter': 'CalvinKirs'}]"
4763,sql/dolphinscheduler-postgre.sql,"@@ -769,8 +769,7 @@ VALUES ('admin', '7ad2410b2f4c074479a8937a28a22b8f', '0', 'xxx@qq.com', '', '0',
 
 -- Records of t_ds_alertgroup，dolphinscheduler warning group
 INSERT INTO t_ds_alertgroup(id,alert_instance_ids, create_user_id, group_name, description, create_time, update_time)
-VALUES (1, '1,2','dolphinscheduler warning group', 'dolphinscheduler warning group', '2018-11-29 10:20:39',
-        '2018-11-29 10:20:39');
+VALUES (1,'1,2', 1, 'default admin warning group', 'default admin warning group', '2018-11-29 10:20:39', '2018-11-29 10:20:39');","[{'comment': 'Please replace `dolphinscheduler warning group` with `default admin warning group` globally. There should be four places that need to be modified including comments.', 'commenter': 'chengshiwen'}, {'comment': ""> Please replace `dolphinscheduler warning group` with `default admin warning group` globally. There should be four places that need to be modified including comments.\r\n\r\nConsidering this is  yakcy's first time for contributing, replacing the comments could submit another PR"", 'commenter': 'davidzollo'}]"
4765,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessInstanceServiceImpl.java,"@@ -0,0 +1,741 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import static org.apache.dolphinscheduler.common.Constants.DATA_LIST;
+import static org.apache.dolphinscheduler.common.Constants.DEPENDENT_SPLIT;
+import static org.apache.dolphinscheduler.common.Constants.GLOBAL_PARAMS;
+import static org.apache.dolphinscheduler.common.Constants.LOCAL_PARAMS;
+import static org.apache.dolphinscheduler.common.Constants.PROCESS_INSTANCE_STATE;
+import static org.apache.dolphinscheduler.common.Constants.TASK_LIST;
+
+import org.apache.dolphinscheduler.api.dto.gantt.GanttDto;
+import org.apache.dolphinscheduler.api.dto.gantt.Task;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.ExecutorService;
+import org.apache.dolphinscheduler.api.service.LoggerService;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionVersionService;
+import org.apache.dolphinscheduler.api.service.ProcessInstanceService;
+import org.apache.dolphinscheduler.api.service.ProjectService;
+import org.apache.dolphinscheduler.api.service.UsersService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.DependResult;
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.common.enums.Flag;
+import org.apache.dolphinscheduler.common.enums.TaskType;
+import org.apache.dolphinscheduler.common.graph.DAG;
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.model.TaskNodeRelation;
+import org.apache.dolphinscheduler.common.process.ProcessDag;
+import org.apache.dolphinscheduler.common.process.Property;
+import org.apache.dolphinscheduler.common.utils.CollectionUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.StringUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessData;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.dao.entity.Tenant;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.ProcessDefinitionMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProcessInstanceMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.TaskInstanceMapper;
+import org.apache.dolphinscheduler.dao.utils.DagHelper;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.nio.charset.StandardCharsets;
+import java.text.ParseException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.stream.Collectors;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+import org.springframework.transaction.annotation.Transactional;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
+import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
+
+/**
+ * process instance service impl
+ */
+@Service
+public class ProcessInstanceServiceImpl extends BaseService implements ProcessInstanceService {
+
+    @Autowired
+    ProjectMapper projectMapper;
+
+    @Autowired
+    ProjectService projectService;
+
+    @Autowired
+    ProcessService processService;
+
+    @Autowired
+    ProcessInstanceMapper processInstanceMapper;
+
+    @Autowired
+    ProcessDefinitionMapper processDefineMapper;
+
+    @Autowired
+    ProcessDefinitionService processDefinitionService;
+
+    @Autowired
+    ProcessDefinitionVersionService processDefinitionVersionService;
+
+    @Autowired
+    ExecutorService execService;
+
+    @Autowired
+    TaskInstanceMapper taskInstanceMapper;
+
+    @Autowired
+    LoggerService loggerService;
+
+
+    @Autowired
+    UsersService usersService;
+
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser, String projectName, int size, String startTime, String endTime) {
+        Map<String, Object> result = new HashMap<>();
+
+        Project project = projectMapper.queryByName(projectName);
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        if (0 > size) {
+            putMsg(result, Status.NEGTIVE_SIZE_NUMBER_ERROR, size);
+            return result;
+        }
+        if (Objects.isNull(startTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.START_TIME);
+            return result;
+        }
+        Date start = DateUtils.stringToDate(startTime);
+        if (Objects.isNull(endTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.END_TIME);
+            return result;
+        }
+        Date end = DateUtils.stringToDate(endTime);
+        if (start == null || end == null) {
+            putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, ""startDate,endDate"");
+            return result;
+        }
+        if (start.getTime() > end.getTime()) {
+            putMsg(result, Status.START_TIME_BIGGER_THAN_END_TIME_ERROR, startTime, endTime);","[{'comment': ""It's best not to show magic numbers"", 'commenter': 'CalvinKirs'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
4765,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessInstanceServiceImpl.java,"@@ -0,0 +1,741 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import static org.apache.dolphinscheduler.common.Constants.DATA_LIST;
+import static org.apache.dolphinscheduler.common.Constants.DEPENDENT_SPLIT;
+import static org.apache.dolphinscheduler.common.Constants.GLOBAL_PARAMS;
+import static org.apache.dolphinscheduler.common.Constants.LOCAL_PARAMS;
+import static org.apache.dolphinscheduler.common.Constants.PROCESS_INSTANCE_STATE;
+import static org.apache.dolphinscheduler.common.Constants.TASK_LIST;
+
+import org.apache.dolphinscheduler.api.dto.gantt.GanttDto;
+import org.apache.dolphinscheduler.api.dto.gantt.Task;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.ExecutorService;
+import org.apache.dolphinscheduler.api.service.LoggerService;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionVersionService;
+import org.apache.dolphinscheduler.api.service.ProcessInstanceService;
+import org.apache.dolphinscheduler.api.service.ProjectService;
+import org.apache.dolphinscheduler.api.service.UsersService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.DependResult;
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.common.enums.Flag;
+import org.apache.dolphinscheduler.common.enums.TaskType;
+import org.apache.dolphinscheduler.common.graph.DAG;
+import org.apache.dolphinscheduler.common.model.TaskNode;
+import org.apache.dolphinscheduler.common.model.TaskNodeRelation;
+import org.apache.dolphinscheduler.common.process.ProcessDag;
+import org.apache.dolphinscheduler.common.process.Property;
+import org.apache.dolphinscheduler.common.utils.CollectionUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.StringUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessData;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.dao.entity.Tenant;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.ProcessDefinitionMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProcessInstanceMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.TaskInstanceMapper;
+import org.apache.dolphinscheduler.dao.utils.DagHelper;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayInputStream;
+import java.io.IOException;
+import java.io.InputStreamReader;
+import java.nio.charset.StandardCharsets;
+import java.text.ParseException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Objects;
+import java.util.Optional;
+import java.util.stream.Collectors;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+import org.springframework.transaction.annotation.Transactional;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
+import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
+
+/**
+ * process instance service impl
+ */
+@Service
+public class ProcessInstanceServiceImpl extends BaseService implements ProcessInstanceService {
+
+    @Autowired
+    ProjectMapper projectMapper;
+
+    @Autowired
+    ProjectService projectService;
+
+    @Autowired
+    ProcessService processService;
+
+    @Autowired
+    ProcessInstanceMapper processInstanceMapper;
+
+    @Autowired
+    ProcessDefinitionMapper processDefineMapper;
+
+    @Autowired
+    ProcessDefinitionService processDefinitionService;
+
+    @Autowired
+    ProcessDefinitionVersionService processDefinitionVersionService;
+
+    @Autowired
+    ExecutorService execService;
+
+    @Autowired
+    TaskInstanceMapper taskInstanceMapper;
+
+    @Autowired
+    LoggerService loggerService;
+
+
+    @Autowired
+    UsersService usersService;
+
+    /**
+     * return top n SUCCESS process instance order by running time which started between startTime and endTime
+     */
+    public Map<String, Object> queryTopNLongestRunningProcessInstance(User loginUser, String projectName, int size, String startTime, String endTime) {
+        Map<String, Object> result = new HashMap<>();
+
+        Project project = projectMapper.queryByName(projectName);
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        if (0 > size) {
+            putMsg(result, Status.NEGTIVE_SIZE_NUMBER_ERROR, size);
+            return result;
+        }
+        if (Objects.isNull(startTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.START_TIME);
+            return result;
+        }
+        Date start = DateUtils.stringToDate(startTime);
+        if (Objects.isNull(endTime)) {
+            putMsg(result, Status.DATA_IS_NULL, Constants.END_TIME);
+            return result;
+        }
+        Date end = DateUtils.stringToDate(endTime);
+        if (start == null || end == null) {
+            putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, ""startDate,endDate"");
+            return result;
+        }
+        if (start.getTime() > end.getTime()) {
+            putMsg(result, Status.START_TIME_BIGGER_THAN_END_TIME_ERROR, startTime, endTime);
+            return result;
+        }
+
+        List<ProcessInstance> processInstances = processInstanceMapper.queryTopNProcessInstance(size, start, end, ExecutionStatus.SUCCESS);
+        result.put(DATA_LIST, processInstances);
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    /**
+     * query process instance by id
+     *
+     * @param loginUser login user
+     * @param projectName project name
+     * @param processId process instance id
+     * @return process instance detail
+     */
+    public Map<String, Object> queryProcessInstanceById(User loginUser, String projectName, Integer processId) {
+        Map<String, Object> result = new HashMap<>();
+        Project project = projectMapper.queryByName(projectName);
+
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+        ProcessInstance processInstance = processService.findProcessInstanceDetailById(processId);
+
+        ProcessDefinition processDefinition = processService.findProcessDefineById(processInstance.getProcessDefinitionId());
+        processInstance.setWarningGroupId(processDefinition.getWarningGroupId());
+        result.put(DATA_LIST, processInstance);
+        putMsg(result, Status.SUCCESS);
+
+        return result;
+    }
+
+    /**
+     * paging query process instance list, filtering according to project, process definition, time range, keyword, process status
+     *
+     * @param loginUser login user
+     * @param projectName project name
+     * @param pageNo page number
+     * @param pageSize page size
+     * @param processDefineId process definition id
+     * @param searchVal search value
+     * @param stateType state type
+     * @param host host
+     * @param startDate start time
+     * @param endDate end time
+     * @return process instance list
+     */
+    public Map<String, Object> queryProcessInstanceList(User loginUser, String projectName, Integer processDefineId,
+                                                        String startDate, String endDate,
+                                                        String searchVal, String executorName, ExecutionStatus stateType, String host,
+                                                        Integer pageNo, Integer pageSize) {
+
+        Map<String, Object> result = new HashMap<>();
+        Project project = projectMapper.queryByName(projectName);
+
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+
+        int[] statusArray = null;
+        // filter by state
+        if (stateType != null) {
+            statusArray = new int[]{stateType.ordinal()};
+        }
+
+        Date start = null;
+        Date end = null;
+        try {
+            if (StringUtils.isNotEmpty(startDate)) {
+                start = DateUtils.getScheduleDate(startDate);
+            }
+            if (StringUtils.isNotEmpty(endDate)) {
+                end = DateUtils.getScheduleDate(endDate);
+            }
+        } catch (Exception e) {
+            putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, ""startDate,endDate"");
+            return result;
+        }
+
+        Page<ProcessInstance> page = new Page<>(pageNo, pageSize);
+        PageInfo<ProcessInstance> pageInfo = new PageInfo<>(pageNo, pageSize);
+        int executorId = usersService.getUserIdByName(executorName);
+
+        IPage<ProcessInstance> processInstanceList =
+                processInstanceMapper.queryProcessInstanceListPaging(page,
+                        project.getId(), processDefineId, searchVal, executorId, statusArray, host, start, end);
+
+        List<ProcessInstance> processInstances = processInstanceList.getRecords();
+
+        for (ProcessInstance processInstance : processInstances) {
+            processInstance.setDuration(DateUtils.format2Duration(processInstance.getStartTime(), processInstance.getEndTime()));
+            User executor = usersService.queryUser(processInstance.getExecutorId());
+            if (null != executor) {
+                processInstance.setExecutorName(executor.getUserName());
+            }
+        }
+
+        pageInfo.setTotalCount((int) processInstanceList.getTotal());
+        pageInfo.setLists(processInstances);
+        result.put(DATA_LIST, pageInfo);
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    /**
+     * query task list by process instance id
+     *
+     * @param loginUser login user
+     * @param projectName project name
+     * @param processId process instance id
+     * @return task list for the process instance
+     * @throws IOException io exception
+     */
+    public Map<String, Object> queryTaskListByProcessId(User loginUser, String projectName, Integer processId) throws IOException {
+        Map<String, Object> result = new HashMap<>();
+        Project project = projectMapper.queryByName(projectName);
+
+        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Status resultEnum = (Status) checkResult.get(Constants.STATUS);
+        if (resultEnum != Status.SUCCESS) {
+            return checkResult;
+        }
+        ProcessInstance processInstance = processService.findProcessInstanceDetailById(processId);
+        List<TaskInstance> taskInstanceList = processService.findValidTaskListByProcessId(processId);
+        addDependResultForTaskList(taskInstanceList);
+        Map<String, Object> resultMap = new HashMap<>();
+        resultMap.put(PROCESS_INSTANCE_STATE, processInstance.getState().toString());
+        resultMap.put(TASK_LIST, taskInstanceList);
+        result.put(DATA_LIST, resultMap);
+
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    /**
+     * add dependent result for dependent task
+     */
+    private void addDependResultForTaskList(List<TaskInstance> taskInstanceList) throws IOException {
+        for (TaskInstance taskInstance : taskInstanceList) {
+            if (taskInstance.getTaskType().equalsIgnoreCase(TaskType.DEPENDENT.toString())) {
+                Result<String> logResult = loggerService.queryLog(
+                        taskInstance.getId(), 0, 4098);","[{'comment': ""It's best not to show magic numbers"", 'commenter': 'CalvinKirs'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
4766,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -0,0 +1,1313 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import static org.apache.dolphinscheduler.common.Constants.ALIAS;
+import static org.apache.dolphinscheduler.common.Constants.CONTENT;
+import static org.apache.dolphinscheduler.common.Constants.JAR;
+
+import org.apache.dolphinscheduler.api.dto.resources.ResourceComponent;
+import org.apache.dolphinscheduler.api.dto.resources.filter.ResourceFilter;
+import org.apache.dolphinscheduler.api.dto.resources.visitor.ResourceTreeVisitor;
+import org.apache.dolphinscheduler.api.dto.resources.visitor.Visitor;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ServiceException;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.ResourcesService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.RegexUtils;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.ProgramType;
+import org.apache.dolphinscheduler.common.enums.ResourceType;
+import org.apache.dolphinscheduler.common.utils.CollectionUtils;
+import org.apache.dolphinscheduler.common.utils.FileUtils;
+import org.apache.dolphinscheduler.common.utils.HadoopUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.PropertyUtils;
+import org.apache.dolphinscheduler.common.utils.StringUtils;
+import org.apache.dolphinscheduler.dao.entity.Resource;
+import org.apache.dolphinscheduler.dao.entity.ResourcesUser;
+import org.apache.dolphinscheduler.dao.entity.Tenant;
+import org.apache.dolphinscheduler.dao.entity.UdfFunc;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.ProcessDefinitionMapper;
+import org.apache.dolphinscheduler.dao.mapper.ResourceMapper;
+import org.apache.dolphinscheduler.dao.mapper.ResourceUserMapper;
+import org.apache.dolphinscheduler.dao.mapper.TenantMapper;
+import org.apache.dolphinscheduler.dao.mapper.UdfFuncMapper;
+import org.apache.dolphinscheduler.dao.mapper.UserMapper;
+import org.apache.dolphinscheduler.dao.utils.ResourceProcessDefinitionUtils;
+
+import org.apache.commons.beanutils.BeanMap;
+
+import java.io.IOException;
+import java.text.MessageFormat;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.Date;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.UUID;
+import java.util.regex.Matcher;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.dao.DuplicateKeyException;
+import org.springframework.stereotype.Service;
+import org.springframework.transaction.annotation.Transactional;
+import org.springframework.web.multipart.MultipartFile;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
+import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
+import com.fasterxml.jackson.databind.SerializationFeature;
+
+/**
+ * resources service impl
+ */
+@Service
+public class ResourcesServiceImpl extends BaseService implements ResourcesService {
+
+    private static final Logger logger = LoggerFactory.getLogger(ResourcesServiceImpl.class);
+
+    @Autowired
+    private ResourceMapper resourcesMapper;
+
+    @Autowired
+    private UdfFuncMapper udfFunctionMapper;
+
+    @Autowired
+    private TenantMapper tenantMapper;
+
+    @Autowired
+    private UserMapper userMapper;
+
+    @Autowired
+    private ResourceUserMapper resourceUserMapper;
+
+    @Autowired
+    private ProcessDefinitionMapper processDefinitionMapper;
+
+    /**
+     * create directory
+     *
+     * @param loginUser login user
+     * @param name alias
+     * @param description description
+     * @param type type
+     * @param pid parent id
+     * @param currentDir current directory
+     * @return create directory result
+     */
+    @Transactional(rollbackFor = Exception.class)
+    public Result<Object> createDirectory(User loginUser,
+                                          String name,
+                                          String description,
+                                          ResourceType type,
+                                          int pid,
+                                          String currentDir) {
+        Result<Object> result = checkResourceUploadStartupState();
+        if (!result.getCode().equals(Status.SUCCESS.getCode())) {
+            return result;
+        }
+        String fullName = currentDir.equals(""/"") ? String.format(""%s%s"",currentDir,name) : String.format(""%s/%s"",currentDir,name);
+        result = verifyResource(loginUser, type, fullName, pid);
+        if (!result.getCode().equals(Status.SUCCESS.getCode())) {
+            return result;
+        }
+
+        if (checkResourceExists(fullName, 0, type.ordinal())) {
+            logger.error(""resource directory {} has exist, can't recreate"", fullName);
+            putMsg(result, Status.RESOURCE_EXIST);
+            return result;
+        }
+
+        Date now = new Date();
+
+        Resource resource = new Resource(pid,name,fullName,true,description,name,loginUser.getId(),type,0,now,now);
+
+        try {
+            resourcesMapper.insert(resource);
+            putMsg(result, Status.SUCCESS);
+            Map<Object, Object> dataMap = new BeanMap(resource);","[{'comment': 'Recommended to use org.apache.commons.beanutils.BeanMap;', 'commenter': 'CalvinKirs'}, {'comment': '![image](https://user-images.githubusercontent.com/4902714/108358825-26cb9080-722a-11eb-9832-494cff1f785b.png)\r\n`org.apache.commons.beanutils.BeanMap` has been used in the latest code.', 'commenter': 'chengshiwen'}]"
4768,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -0,0 +1,182 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import static org.apache.dolphinscheduler.common.Constants.DEFAULT_WORKER_GROUP;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.WorkerGroupService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.utils.CollectionUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.StringUtils;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.entity.WorkerGroup;
+import org.apache.dolphinscheduler.dao.mapper.ProcessInstanceMapper;
+import org.apache.dolphinscheduler.service.zk.ZookeeperCachedOperator;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+
+/**
+ * work group service impl
+ */
+@Service
+public class WorkerGroupServiceImpl extends BaseService implements WorkerGroupService {
+
+    private static final String NO_NODE_EXCEPTION_REGEX = ""KeeperException$NoNodeException"";
+
+    @Autowired
+    protected ZookeeperCachedOperator zookeeperCachedOperator;
+
+    @Autowired
+    ProcessInstanceMapper processInstanceMapper;
+
+    /**
+     * query worker group paging
+     *
+     * @param loginUser login user
+     * @param pageNo page number
+     * @param searchVal search value
+     * @param pageSize page size
+     * @return worker group list page
+     */
+    public Map<String, Object> queryAllGroupPaging(User loginUser, Integer pageNo, Integer pageSize, String searchVal) {
+        // list from index
+        Integer fromIndex = (pageNo - 1) * pageSize;","[{'comment': 'Modified to basic type', 'commenter': 'CalvinKirs'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
4768,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -0,0 +1,182 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import static org.apache.dolphinscheduler.common.Constants.DEFAULT_WORKER_GROUP;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.WorkerGroupService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.utils.CollectionUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.StringUtils;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.entity.WorkerGroup;
+import org.apache.dolphinscheduler.dao.mapper.ProcessInstanceMapper;
+import org.apache.dolphinscheduler.service.zk.ZookeeperCachedOperator;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+
+/**
+ * work group service impl
+ */
+@Service
+public class WorkerGroupServiceImpl extends BaseService implements WorkerGroupService {
+
+    private static final String NO_NODE_EXCEPTION_REGEX = ""KeeperException$NoNodeException"";
+
+    @Autowired
+    protected ZookeeperCachedOperator zookeeperCachedOperator;
+
+    @Autowired
+    ProcessInstanceMapper processInstanceMapper;
+
+    /**
+     * query worker group paging
+     *
+     * @param loginUser login user
+     * @param pageNo page number
+     * @param searchVal search value
+     * @param pageSize page size
+     * @return worker group list page
+     */
+    public Map<String, Object> queryAllGroupPaging(User loginUser, Integer pageNo, Integer pageSize, String searchVal) {
+        // list from index
+        Integer fromIndex = (pageNo - 1) * pageSize;
+        // list to index
+        Integer toIndex = (pageNo - 1) * pageSize + pageSize;
+
+        Map<String, Object> result = new HashMap<>();
+        if (isNotAdmin(loginUser, result)) {
+            return result;
+        }
+
+        List<WorkerGroup> workerGroups = getWorkerGroups(true);
+
+        List<WorkerGroup> resultDataList = new ArrayList<>();
+
+        if (CollectionUtils.isNotEmpty(workerGroups)) {
+            List<WorkerGroup> searchValDataList = new ArrayList<>();
+
+            if (StringUtils.isNotEmpty(searchVal)) {
+                for (WorkerGroup workerGroup : workerGroups) {
+                    if (workerGroup.getName().contains(searchVal)) {
+                        searchValDataList.add(workerGroup);
+                    }
+                }
+            } else {
+                searchValDataList = workerGroups;
+            }
+
+            if (searchValDataList.size() < pageSize) {
+                toIndex = (pageNo - 1) * pageSize + searchValDataList.size();
+            }
+            resultDataList = searchValDataList.subList(fromIndex, toIndex);
+        }
+
+        PageInfo<WorkerGroup> pageInfo = new PageInfo<>(pageNo, pageSize);
+        pageInfo.setTotalCount(resultDataList.size());
+        pageInfo.setLists(resultDataList);
+
+        result.put(Constants.DATA_LIST, pageInfo);
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    /**
+     * query all worker group
+     *
+     * @return all worker group list
+     */
+    public Map<String, Object> queryAllGroup() {
+        Map<String, Object> result = new HashMap<>();
+
+        List<WorkerGroup> workerGroups = getWorkerGroups(false);
+
+        Set<String> availableWorkerGroupSet = workerGroups.stream()
+                .map(WorkerGroup::getName)
+                .collect(Collectors.toSet());
+        result.put(Constants.DATA_LIST, availableWorkerGroupSet);
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    /**
+     * get worker groups
+     *
+     * @param isPaging whether paging
+     * @return WorkerGroup list
+     */
+    private List<WorkerGroup> getWorkerGroups(boolean isPaging) {
+        String workerPath = zookeeperCachedOperator.getZookeeperConfig().getDsRoot() + Constants.ZOOKEEPER_DOLPHINSCHEDULER_WORKERS;
+        List<WorkerGroup> workerGroups = new ArrayList<>();
+        List<String> workerGroupList;
+        try {
+            workerGroupList = zookeeperCachedOperator.getChildrenKeys(workerPath);
+        } catch (Exception e) {
+            if (e.getMessage().contains(NO_NODE_EXCEPTION_REGEX)) {
+                if (isPaging) {
+                    return workerGroups;
+                } else {
+                    //ignore noNodeException return Default
+                    WorkerGroup wg = new WorkerGroup();
+                    wg.setName(DEFAULT_WORKER_GROUP);
+                    workerGroups.add(wg);
+                    return workerGroups;
+                }
+            } else {
+                throw e;","[{'comment': ""This approach doesn't look very good"", 'commenter': 'CalvinKirs'}, {'comment': ""![image](https://user-images.githubusercontent.com/4902714/108337069-b0219980-720f-11eb-94f7-7c15cbd3ebfa.png)\r\nException 'org.apache.zookeeper.KeeperException.NoNodeException' is never thrown in the corresponding try block\r\nWithout looking at the code details, I can only simply modify this piece of code"", 'commenter': 'chengshiwen'}]"
4768,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkFlowLineageServiceImpl.java,"@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.WorkFlowLineageService;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.WorkFlowLineage;
+import org.apache.dolphinscheduler.dao.entity.WorkFlowRelation;
+import org.apache.dolphinscheduler.dao.mapper.WorkFlowLineageMapper;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+/**
+ * work flow lineage service impl
+ */
+@Service
+public class WorkFlowLineageServiceImpl extends BaseService implements WorkFlowLineageService {
+
+    @Autowired
+    private WorkFlowLineageMapper workFlowLineageMapper;
+
+    public Map<String, Object> queryWorkFlowLineageByName(String workFlowName, int projectId) {
+        Map<String, Object> result = new HashMap<>(5);","[{'comment': ""It doesn't make much sense to declare the initial size as 5"", 'commenter': 'CalvinKirs'}, {'comment': 'Has modified to 0', 'commenter': 'chengshiwen'}]"
4768,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkFlowLineageServiceImpl.java,"@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.WorkFlowLineageService;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.WorkFlowLineage;
+import org.apache.dolphinscheduler.dao.entity.WorkFlowRelation;
+import org.apache.dolphinscheduler.dao.mapper.WorkFlowLineageMapper;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+/**
+ * work flow lineage service impl
+ */
+@Service
+public class WorkFlowLineageServiceImpl extends BaseService implements WorkFlowLineageService {
+
+    @Autowired
+    private WorkFlowLineageMapper workFlowLineageMapper;
+
+    public Map<String, Object> queryWorkFlowLineageByName(String workFlowName, int projectId) {
+        Map<String, Object> result = new HashMap<>(5);
+        List<WorkFlowLineage> workFlowLineageList = workFlowLineageMapper.queryByName(workFlowName, projectId);
+        result.put(Constants.DATA_LIST, workFlowLineageList);
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    private List<WorkFlowRelation> getWorkFlowRelationRecursion(Set<Integer> ids, List<WorkFlowRelation> workFlowRelations,Set<Integer> sourceIds) {","[{'comment': 'This method may be better declared as void', 'commenter': 'CalvinKirs'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
4768,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkFlowLineageServiceImpl.java,"@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.BaseService;
+import org.apache.dolphinscheduler.api.service.WorkFlowLineageService;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.WorkFlowLineage;
+import org.apache.dolphinscheduler.dao.entity.WorkFlowRelation;
+import org.apache.dolphinscheduler.dao.mapper.WorkFlowLineageMapper;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+/**
+ * work flow lineage service impl
+ */
+@Service
+public class WorkFlowLineageServiceImpl extends BaseService implements WorkFlowLineageService {
+
+    @Autowired
+    private WorkFlowLineageMapper workFlowLineageMapper;
+
+    public Map<String, Object> queryWorkFlowLineageByName(String workFlowName, int projectId) {
+        Map<String, Object> result = new HashMap<>(5);
+        List<WorkFlowLineage> workFlowLineageList = workFlowLineageMapper.queryByName(workFlowName, projectId);
+        result.put(Constants.DATA_LIST, workFlowLineageList);
+        putMsg(result, Status.SUCCESS);
+        return result;
+    }
+
+    private List<WorkFlowRelation> getWorkFlowRelationRecursion(Set<Integer> ids, List<WorkFlowRelation> workFlowRelations,Set<Integer> sourceIds) {
+        for (int id : ids) {
+            sourceIds.addAll(ids);
+            List<WorkFlowRelation> workFlowRelationsTmp = workFlowLineageMapper.querySourceTarget(id);
+            if (workFlowRelationsTmp != null && !workFlowRelationsTmp.isEmpty()) {
+                Set<Integer> idsTmp = new HashSet<>();
+                for (WorkFlowRelation workFlowRelation:workFlowRelationsTmp) {
+                    if (!sourceIds.contains(workFlowRelation.getTargetWorkFlowId())) {
+                        idsTmp.add(workFlowRelation.getTargetWorkFlowId());
+                    }
+                }
+                workFlowRelations.addAll(workFlowRelationsTmp);
+                getWorkFlowRelationRecursion(idsTmp, workFlowRelations,sourceIds);
+            }
+        }
+        return workFlowRelations;
+    }
+
+    public Map<String, Object> queryWorkFlowLineageByIds(Set<Integer> ids,int projectId) {
+        Map<String, Object> result = new HashMap<>(5);
+        List<WorkFlowLineage> workFlowLineageList = workFlowLineageMapper.queryByIds(ids, projectId);
+        Map<String, Object> workFlowLists = new HashMap<>(5);
+        Set<Integer> idsV = new HashSet<>();
+        if (ids == null || ids.isEmpty()) {
+            for (WorkFlowLineage workFlowLineage:workFlowLineageList) {
+                idsV.add(workFlowLineage.getWorkFlowId());
+            }
+        } else {
+            idsV = ids;
+        }
+        List<WorkFlowRelation> workFlowRelations = new ArrayList<>();
+        Set<Integer> sourceIds = new HashSet<>();
+        getWorkFlowRelationRecursion(idsV, workFlowRelations, sourceIds);
+
+        Set<Integer> idSet = new HashSet<>();
+        //If the incoming parameter is not empty, you need to add downstream workflow detail attributes
+        if (ids != null && !ids.isEmpty()) {
+            for (WorkFlowRelation workFlowRelation : workFlowRelations) {
+                idSet.add(workFlowRelation.getTargetWorkFlowId());
+            }
+            for (int id : ids) {
+                idSet.remove(id);
+            }
+            if (!idSet.isEmpty()) {
+                workFlowLineageList.addAll(workFlowLineageMapper.queryByIds(idSet, projectId));
+            }
+        }
+
+        workFlowLists.put(""workFlowList"",workFlowLineageList);","[{'comment': ""It's best not to show magic numbers"", 'commenter': 'CalvinKirs'}, {'comment': 'Replaced with `Constants.WORKFLOW_LIST` and `Constants.WORKFLOW_RELATION_LIST`', 'commenter': 'chengshiwen'}]"
4779,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessService.java,"@@ -575,23 +596,6 @@ private ProcessInstance generateNewProcessInstance(ProcessDefinition processDefi
                 }
             }
         }
-","[{'comment': 'This piece of code should remain unchanged', 'commenter': 'CalvinKirs'}, {'comment': ""@CalvinKirs \r\nSure, that piece of code was rolled back to it's origin status.\r\nOnly those which related to repeat running were changed.\r\n\r\n![image](https://user-images.githubusercontent.com/58684828/108458003-ab5ff280-72ae-11eb-96e5-bdcf9a4a1237.png)\r\nAlso, I have tested recover failed function of a process instance, the same problem occured as this issue.\r\nI'm going to fix this bug too.\r\nShould I create another issue to report this situation?"", 'commenter': 'WilliamChen-luckbob'}, {'comment': 'sure, one issue should correspond to one pr, welcome submit', 'commenter': 'CalvinKirs'}, {'comment': ""@CalvinKirs \r\nHi! Thanks a lot for your help.\r\n\r\nSo far I've met a little question about code coverage failed.\r\n\r\nI've tested my commitment in my produce environment.\r\nBut if I wanted to submit this PR, I have to pass the sonar Analysis too , but failed.\r\n\r\nAccording to the details of sonar cloud, I think if I want to cover my commitment, I have to create a unit test for those I have changed by creating process definition first, and then run it with my customized start parameter and then rerun it.\r\n\r\nIn order to achieve this goal I have to get process definition id and process instance id, it seems to have no way to get this two parameters. Maybe it will work if I test my code as the same way as org.apache.dolphinscheduler.api.service.ExecutorService2Test.java.\r\n\r\nSo far, I don't have confidence if it would work. I'll try it later after work.\r\n\r\nCould you please give me some instructions?"", 'commenter': 'WilliamChen-luckbob'}]"
4779,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessService.java,"@@ -599,6 +599,26 @@ private ProcessInstance generateNewProcessInstance(ProcessDefinition processDefi
         return processInstance;
     }
 
+    private void setGlobalParamIfCommanded(ProcessDefinition processDefinition, Map<String, String> cmdParam) {
+        // get start params from command param","[{'comment': 'Thank you very much for your contribution, but I noticed that this piece of code is also used elsewhere (generateNewProcessInstance), and it is best to modify it.', 'commenter': 'CalvinKirs'}]"
4799,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -134,45 +136,48 @@
      * @return WorkerGroup list
      */
     private List<WorkerGroup> getWorkerGroups(boolean isPaging) {
+
         String workerPath = zookeeperCachedOperator.getZookeeperConfig().getDsRoot() + Constants.ZOOKEEPER_DOLPHINSCHEDULER_WORKERS;
         List<WorkerGroup> workerGroups = new ArrayList<>();
         List<String> workerGroupList;
         try {
             workerGroupList = zookeeperCachedOperator.getChildrenKeys(workerPath);
         } catch (Exception e) {
             if (e.getMessage().contains(NO_NODE_EXCEPTION_REGEX)) {
-                if (!isPaging) {
+                if (isPaging) {
+                    return workerGroups;
+                } else {
                     //ignore noNodeException return Default
                     WorkerGroup wg = new WorkerGroup();
                     wg.setName(DEFAULT_WORKER_GROUP);
                     workerGroups.add(wg);
+                    return workerGroups;","[{'comment': ""If there is no better modification, it's better to keep the old code\r\n![image](https://user-images.githubusercontent.com/4902714/108506475-d02a8900-72f3-11eb-8867-a66c41c97f90.png)\r\n"", 'commenter': 'chengshiwen'}]"
4799,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/zk/ZookeeperNodeHandler.java,"@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.zk;
+
+import static org.apache.dolphinscheduler.common.Constants.COLON;
+
+import org.apache.dolphinscheduler.common.model.WorkerZkNode;
+import org.apache.dolphinscheduler.common.utils.StringUtils;
+
+/**
+ * zookeeper node handler
+ */
+public class ZookeeperNodeHandler {
+
+    private ZookeeperNodeHandler() {
+        throw new UnsupportedOperationException(""Construct ZookeeperNodeHandler"");
+    }
+
+    /**
+     * generate worker zookeeper node name
+     *
+     * @param address address
+     * @param weight weight
+     * @param workerStartTime workerStartTime
+     * @return worker address:weight:startTime
+     */
+    public static String generateWorkerZkNodeName(String address, String weight, long workerStartTime) {
+        StringBuilder workerZkNodeNameBuilder = new StringBuilder(address);
+        workerZkNodeNameBuilder.append(COLON);
+        workerZkNodeNameBuilder.append(weight);
+        workerZkNodeNameBuilder.append(COLON);
+        workerZkNodeNameBuilder.append(workerStartTime);
+        return workerZkNodeNameBuilder.toString();
+    }
+
+    /**
+     * get worker info according to zookeeper node
+     *
+     * @param zkNode zookeeper node
+     * @return worker zookeeper node
+     */
+    public static WorkerZkNode getWorkerZkNodeName(String zkNode) {
+        if (StringUtils.isBlank(zkNode)) {
+            return null;
+        }
+        String[] split = zkNode.split(COLON);
+        return new WorkerZkNode(split[0], split[1], split[2], split[3]);
+    }
+
+    /**
+     * get worker address
+     *
+     * @param workerZkNode worker zookeeper node
+     * @return worker address
+     */
+    public static String getWorkerAddress(WorkerZkNode workerZkNode) {
+        return workerZkNode == null ? null : workerZkNode.getAddressHost() + COLON + workerZkNode.getAddressPort();
+    }
+
+    /**
+     * get worker address
+     *
+     * @param zkNode zookeeper node
+     * @return worker address
+     */
+    public static String getWorkerAddress(String zkNode) {
+        return getWorkerAddress(getWorkerZkNodeName(zkNode));
+    }
+
+    /**
+     * get worker address and weight
+     *
+     * @param workerZkNode worker zookeeper node
+     * @return worker address:weight
+     */
+    public static String getWorkerAddressAndWeight(WorkerZkNode workerZkNode) {
+        return workerZkNode == null ? null : getWorkerAddress(workerZkNode) + COLON + workerZkNode.getWeight();
+    }
+
+    /**
+     * get worker address and weight
+     *
+     * @param zkNode zookeeper node
+     * @return worker address:weight
+     */
+    public static String getWorkerAddressAndWeight(String zkNode) {
+        return getWorkerAddressAndWeight(getWorkerZkNodeName(zkNode));
+    }
+
+    /**
+     * get worker startTime
+     * @param workerZkNode worker zookeeper node
+     * @return worker startTime
+     */
+    public static String getWorkerStartTime(WorkerZkNode workerZkNode) {
+        return workerZkNode == null ? null : workerZkNode.getStartTime();
+    }
+
+}","[{'comment': 'Require zookeeper unit test. Now the unit test coverage is less than 33%', 'commenter': 'chengshiwen'}]"
4799,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/model/WorkerZkNode.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.model;
+
+/**
+ * worker zookeeper node
+ */
+public class WorkerZkNode {","[{'comment': 'We have calculations similar to this in many places(eg: Host. class), can we organize them into one?', 'commenter': 'CalvinKirs'}, {'comment': 'done.', 'commenter': 'zhuangchong'}]"
4802,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/DateUtilsTest.java,"@@ -196,4 +196,12 @@ public void testFormat2Duration() {
 
     }
 
+    @Test
+    public void testNullDuration() {
+        // days hours minutes seconds
+        Date d1 = DateUtils.stringToDate(""2020-01-20 11:00:00"");
+        Date d2 = null;
+        Assert.assertEquals("""",DateUtils.format2Duration(d1,d2));","[{'comment': ""It's better to add a trailing space after each comma"", 'commenter': 'chengshiwen'}, {'comment': 'ok', 'commenter': 'felix-thinkingdata'}]"
4802,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/DateUtils.java,"@@ -259,6 +259,9 @@ public static String format2Readable(long ms) {
      * @return format time
      */
     public static String format2Duration(Date d1, Date d2) {
+        if (d1 == null || d2 == null) {
+            return """";","[{'comment': 'Better to `return null`', 'commenter': 'zhanguohao'}, {'comment': 'ok', 'commenter': 'felix-thinkingdata'}]"
4883,.github/workflows/ci_ut.yml,"@@ -36,7 +36,7 @@ jobs:
         with:
           submodule: true
       - name: Check License Header
-        uses: apache/skywalking-eyes@9bd5feb
+        uses: apache/skywalking-eyes@9bd5feb86b5817aa6072b008f9866a2c3bbc8587
         env:","[{'comment': 'Should be consistent with the master, do not modify it', 'commenter': 'CalvinKirs'}, {'comment': ""'apache/skywalking-eyes' has been updated to the latest"", 'commenter': 'zixi0825'}]"
4916,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/zk/ZKMasterClient.java,"@@ -72,6 +79,9 @@ public void start() {
 			mutex = new InterProcessMutex(getZkClient(), znodeLock);
 			mutex.acquire();
 
+            //  Master registry
+            masterRegistry.registry();
+","[{'comment': 'Indent problem', 'commenter': 'chengshiwen'}]"
4916,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/zk/ZKMasterClient.java,"@@ -94,6 +104,7 @@ public void start() {
 	@Override
 	public void close(){
 		super.close();
+        masterRegistry.unRegistry();","[{'comment': 'Indent problem', 'commenter': 'chengshiwen'}]"
4916,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/zk/ZKMasterClient.java,"@@ -160,6 +171,9 @@ private void removeZKNodePath(String path, ZKNodeType zkNodeType, boolean failov
 	 * @throws Exception	exception
 	 */
 	private void failoverServerWhenDown(String serverHost, ZKNodeType zkNodeType) throws Exception {
+        if (StringUtils.isEmpty(serverHost)) {","[{'comment': 'Indent problem', 'commenter': 'chengshiwen'}]"
4916,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/zk/ZKMasterClient.java,"@@ -272,9 +286,8 @@ private boolean checkTaskAfterWorkerStart(TaskInstance taskInstance) {
 
 		if(workerServerStartDate != null){
 			return taskInstance.getStartTime().after(workerServerStartDate);
-		}else{
-			return false;
-		}
+        }
+		return false;","[{'comment': 'Indent problem', 'commenter': 'chengshiwen'}, {'comment': 'hi, thanks for your review , I have resolved the code style, please take a look.', 'commenter': 'CalvinKirs'}]"
4922,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/log.vue,"@@ -168,7 +168,7 @@
        * Download log
        */
       _downloadLog () {
-        downloadFile('/log/download-log', {
+        downloadFile('/dolphinscheduler/log/download-log', {","[{'comment': ""Don't do this, please change to `downloadFile('log/download-log'`"", 'commenter': 'chengshiwen'}]"
4943,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/LoggerUtils.java,"@@ -101,6 +108,26 @@ public static String buildTaskId(String affix,
         return appIds;
     }
 
+    /**
+     * read whole file content
+     *
+     * @param filePath file path
+     * @return whole file content
+     */
+    public static String readWholeFileContent(String filePath) {
+        String line;
+        StringBuilder sb = new StringBuilder();
+        try (BufferedReader br = new BufferedReader(new InputStreamReader(new FileInputStream(filePath)))) {
+            while ((line = br.readLine()) != null) {
+                sb.append(line + ""\r\n"");
+            }
+            return sb.toString();
+        } catch (IOException e) {
+            logger.error(""read file error"", e);
+        }
+        return """";
+    }","[{'comment': 'Did you forget to close the stream?', 'commenter': 'CalvinKirs'}, {'comment': ' Due to the BufferedReader inherits AutoCloseable, so sonor suggest us to use try with resources to close the stream.', 'commenter': 'ruanwenjun'}]"
5019,docker/kubernetes/dolphinscheduler/values.yaml,"@@ -76,12 +76,12 @@ common:
     - ""export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop""
     - ""export SPARK_HOME1=/opt/soft/spark1""
     - ""export SPARK_HOME2=/opt/soft/spark2""
-    #- ""export PYTHON_HOME=/opt/soft/python""
+    - ""export PYTHON_HOME=/usr""
     - ""export JAVA_HOME=/usr/lib/jvm/java-1.8-openjdk""
     - ""export HIVE_HOME=/opt/soft/hive""
     - ""export FLINK_HOME=/opt/soft/flink""
-    - ""export DATAX_HOME=/opt/soft/datax/bin/datax.py""
-    - ""export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH""
+    - ""export DATAX_HOME=/opt/soft/datax""
+    - ""export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$DATAX_HOME/bin:$PATH""","[{'comment': 'There is no need to add to path.', 'commenter': 'wen-hemin'}, {'comment': 'The semantics of `PYTHON_HOME` has changed. In order to ensure that docker/k8s can execute python task normally, I need to make this modification. At the same time, just keep consistency with other `dolphinscheduler_env.sh`', 'commenter': 'chengshiwen'}, {'comment': 'Yes, DATAX_HOME is no need', 'commenter': 'wen-hemin'}, {'comment': 'Just keep consistency with other `dolphinscheduler_env.sh`. In fact, none of these environment variables such as `SPARK_HOME1`, `SPARK_HOME2`, `PYTHON_HOME` and `DATAX_HOME` in `PATH` are needed. In future, I will give a refactoring for the `HOME` environment variables, please refer to #5035. We don’t need the PATH environment variable at all.', 'commenter': 'chengshiwen'}, {'comment': 'OK', 'commenter': 'wen-hemin'}]"
5019,docker/docker-swarm/docker-stack.yml,"@@ -171,11 +171,11 @@ services:
       HADOOP_CONF_DIR: ""/opt/soft/hadoop/etc/hadoop""
       SPARK_HOME1: ""/opt/soft/spark1""
       SPARK_HOME2: ""/opt/soft/spark2""
-      #PYTHON_HOME: ""/opt/soft/python""
+      PYTHON_HOME: ""/usr""","[{'comment': 'This is not within the scope of this change and no modification is recommended.', 'commenter': 'wen-hemin'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
5019,docker/docker-swarm/docker-compose.yml,"@@ -177,11 +177,11 @@ services:
       HADOOP_CONF_DIR: ""/opt/soft/hadoop/etc/hadoop""
       SPARK_HOME1: ""/opt/soft/spark1""
       SPARK_HOME2: ""/opt/soft/spark2""
-      #PYTHON_HOME: ""/opt/soft/python""
+      PYTHON_HOME: ""/usr""","[{'comment': 'This is not within the scope of this change and no modification is recommended.', 'commenter': 'wen-hemin'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
5019,docker/build/conf/dolphinscheduler/env/dolphinscheduler_env.sh.tpl,"@@ -25,4 +25,4 @@ export HIVE_HOME=$HIVE_HOME
 export FLINK_HOME=$FLINK_HOME
 export DATAX_HOME=$DATAX_HOME
 
-export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH
+export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$DATAX_HOME/bin:$PATH","[{'comment': 'There is no need to add to path.', 'commenter': 'wen-hemin'}, {'comment': 'I think there is no problem with this line', 'commenter': 'chengshiwen'}, {'comment': 'Yes, DATAX_HOME is no need', 'commenter': 'wen-hemin'}, {'comment': 'Just keep consistency with other `dolphinscheduler_env.sh`. In fact, none of these environment variables such as `SPARK_HOME1`, `SPARK_HOME2`, `PYTHON_HOME` and `DATAX_HOME` in `PATH` are needed. In future, I will give a refactoring for the `HOME` environment variables, please refer to #5035. We don’t need the PATH environment variable at all.', 'commenter': 'chengshiwen'}]"
5036,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/PythonCommandExecutor.java,"@@ -118,7 +118,7 @@ protected String commandInterpreter() {
         if (StringUtils.isEmpty(pythonHome)){
             return PYTHON;
         }
-        return pythonHome;
+        return pythonHome + ""/bin/python"";","[{'comment': 'By the way, could you modify the incorrect java docs of `private static String getPythonHome(String envPath)` and modify the `$PYTHON_HOME` to `$PYTHON_HOME/bin` in `export PATH`', 'commenter': 'chengshiwen'}, {'comment': 'By searching `PYTHON_HOME` globally, also pay attention to modify the default value of `PYTHON_HOME`', 'commenter': 'chengshiwen'}, {'comment': 'ok', 'commenter': 'wa-ooo'}]"
5036,docker/docker-swarm/docker-compose.yml,"@@ -177,7 +177,7 @@ services:
       HADOOP_CONF_DIR: ""/opt/soft/hadoop/etc/hadoop""
       SPARK_HOME1: ""/opt/soft/spark1""
       SPARK_HOME2: ""/opt/soft/spark2""
-      PYTHON_HOME: ""/usr/bin/python""
+      #PYTHON_HOME: ""/opt/soft/python""","[{'comment': '`/usr` is better without comment', 'commenter': 'chengshiwen'}]"
5036,docker/docker-swarm/docker-stack.yml,"@@ -171,7 +171,7 @@ services:
       HADOOP_CONF_DIR: ""/opt/soft/hadoop/etc/hadoop""
       SPARK_HOME1: ""/opt/soft/spark1""
       SPARK_HOME2: ""/opt/soft/spark2""
-      PYTHON_HOME: ""/usr/bin/python""
+      #PYTHON_HOME: ""/opt/soft/python""","[{'comment': '`/usr` is better without comment', 'commenter': 'chengshiwen'}]"
5036,docker/kubernetes/dolphinscheduler/values.yaml,"@@ -76,12 +76,12 @@ common:
     - ""export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop""
     - ""export SPARK_HOME1=/opt/soft/spark1""
     - ""export SPARK_HOME2=/opt/soft/spark2""
-    - ""export PYTHON_HOME=/usr/bin/python""
+    #- ""export PYTHON_HOME=/opt/soft/python""","[{'comment': '`/usr` is better without comment', 'commenter': 'chengshiwen'}]"
5036,docker/kubernetes/dolphinscheduler/values.yaml,"@@ -76,12 +76,12 @@ common:
     - ""export HADOOP_CONF_DIR=/opt/soft/hadoop/etc/hadoop""
     - ""export SPARK_HOME1=/opt/soft/spark1""
     - ""export SPARK_HOME2=/opt/soft/spark2""
-    - ""export PYTHON_HOME=/usr/bin/python""
+    #- ""export PYTHON_HOME=/opt/soft/python""
     - ""export JAVA_HOME=/usr/lib/jvm/java-1.8-openjdk""
     - ""export HIVE_HOME=/opt/soft/hive""
     - ""export FLINK_HOME=/opt/soft/flink""
     - ""export DATAX_HOME=/opt/soft/datax/bin/datax.py""
-    - ""export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH""
+    - ""export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH""","[{'comment': 'All PATHs should be consistent as `PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH`', 'commenter': 'chengshiwen'}]"
5036,script/env/dolphinscheduler_env.sh,"@@ -25,4 +25,4 @@ export HIVE_HOME=/opt/soft/hive
 export FLINK_HOME=/opt/soft/flink
 export DATAX_HOME=/opt/soft/datax/bin/datax.py
 
-export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH
+export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH","[{'comment': '`PYTHON_HOME` needs to be set to `/usr`', 'commenter': 'chengshiwen'}, {'comment': 'All PATHs should be consistent as `PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH`', 'commenter': 'chengshiwen'}, {'comment': 'In this file, `PYTHON_HOME` needs to be set to `/usr`, otherwise the default python program cannot be executed.', 'commenter': 'chengshiwen'}, {'comment': 'In this file, PYTHON_HOME and HADOOP_HOME have the same meaning, not the actual configuration but just telling the user to change to the installation directory of the program, so I set the value of PYTHON_HOME to /opt/soft/python instead of /usr', 'commenter': 'wa-ooo'}]"
5036,docker/build/conf/dolphinscheduler/env/dolphinscheduler_env.sh.tpl,"@@ -25,4 +25,4 @@ export HIVE_HOME=$HIVE_HOME
 export FLINK_HOME=$FLINK_HOME
 export DATAX_HOME=$DATAX_HOME
 
-export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH
+export PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$PATH:$FLINK_HOME/bin:$DATAX_HOME:$PATH","[{'comment': 'All PATHs should be consistent as `PATH=$HADOOP_HOME/bin:$SPARK_HOME1/bin:$SPARK_HOME2/bin:$PYTHON_HOME/bin:$JAVA_HOME/bin:$HIVE_HOME/bin:$FLINK_HOME/bin:$PATH`', 'commenter': 'chengshiwen'}]"
5036,docker/build/README.md,"@@ -193,7 +193,7 @@ This environment variable sets `SPARK_HOME2`. The default value is `/opt/soft/sp
 
 **`PYTHON_HOME`**
 
-This environment variable sets `PYTHON_HOME`. The default value is `/usr/bin/python`.","[{'comment': 'The default value should be `/usr`', 'commenter': 'wa-ooo'}]"
5036,docker/build/README_zh_CN.md,"@@ -193,7 +193,7 @@ DolphinScheduler Docker 容器通过环境变量进行配置，缺省时将会
 
 **`PYTHON_HOME`**
 
-配置`dolphinscheduler`的`PYTHON_HOME`，默认值 `/usr/bin/python`。","[{'comment': '默认值是`/usr`', 'commenter': 'wa-ooo'}]"
5056,dolphinscheduler-ui/src/js/module/components/fileUpdate/fileChildUpdate.vue,"@@ -174,8 +174,8 @@
           formData.append('file', this.file)
           formData.append('type', this.type)
           formData.append('name', this.name)
-          formData.append('pid', this.pid)
-          formData.append('currentDir', this.currentDir)
+          formData.append('pid', localStore.getItem('pid') || this.id)
+          formData.append('currentDir', localStore.getItem('currentDir') || this.currentDir)","[{'comment': 'This problem may also appear in `definitionUpdate.vue`, `fileChildReUpdate.vue`, `fileReUpload.vue`, `fileUpdate.vue`, `resourceChildUpdate.vue` and `udfUpdate.vue` under directory `dolphinscheduler-ui/src/js/module/components/fileUpdate`, please check together, thanks a lot!', 'commenter': 'chengshiwen'}, {'comment': 'ok,I will check it', 'commenter': 'lijufeng2016'}, {'comment': 'I fix all bugs for upload resource file and udf,by the way,I fix when delete udf resource file,the page not refresh', 'commenter': 'lijufeng2016'}]"
5066,sql/upgrade/1.3.6_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -0,0 +1,18 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+-- Add foreign key constraints for t_ds_task_instance --
+alter table t_ds_task_instance add FOREIGN key(process_instance_id) REFERENCES t_ds_process_instance(id) ON DELETE CASCADE;","[{'comment': ""It would be better to keep the key world's case consistent"", 'commenter': 'chengshiwen'}, {'comment': 'Thx.done.', 'commenter': 'CalvinKirs'}]"
5066,sql/dolphinscheduler_postgre.sql,"@@ -556,7 +556,7 @@ CREATE TABLE t_ds_task_instance (
   name varchar(255) DEFAULT NULL ,
   task_type varchar(64) DEFAULT NULL ,
   process_definition_id int DEFAULT NULL ,
-  process_instance_id int DEFAULT NULL ,
+  process_instance_id int REFERENCES  t_ds_process_instance (id) DEFAULT NULL ,","[{'comment': 'It would be better to reduce an extra space', 'commenter': 'chengshiwen'}]"
5066,sql/upgrade/1.3.6_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -0,0 +1,18 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+-- Add foreign key constraints for t_ds_task_instance --
+ALTER TABLE t_ds_task_instance ADD CONSTRAINT foreign_key_instance_id  FOREIGN KEY(process_instance_id) REFERENCES t_ds_process_instance(id) ON DELETE CASCADE;","[{'comment': 'Will this SQL modification be released to 1.3.6? If not, the naming of 1.3.6 may not be suitable', 'commenter': 'chengshiwen'}, {'comment': 'need released.', 'commenter': 'CalvinKirs'}]"
5074,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -349,28 +352,40 @@ private void clear() {
      */
     private void parseProcessOutput(Process process) {
         String threadLoggerInfoName = String.format(LoggerUtils.TASK_LOGGER_THREAD_NAME + ""-%s"", taskExecutionContext.getTaskAppId());
-        ExecutorService parseProcessOutputExecutorService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName);
-        parseProcessOutputExecutorService.submit(new Runnable(){
-            @Override
-            public void run() {
-                BufferedReader inReader = null;
-
-                try {
-                    inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
-                    String line;
-
-                    long lastFlushTime = System.currentTimeMillis();
-
-                    while ((line = inReader.readLine()) != null) {
+        ExecutorService getOutputLogService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName + ""-"" + ""getOutputLogService"");
+        getOutputLogService.submit(() -> {
+            BufferedReader inReader = null;
+            try {
+                inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
+                String line;
+                logBuffer.add(""welcome to use bigdata scheduling system..."");","[{'comment': 'I think this line should be removed', 'commenter': 'chengshiwen'}]"
5074,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -349,28 +352,40 @@ private void clear() {
      */
     private void parseProcessOutput(Process process) {
         String threadLoggerInfoName = String.format(LoggerUtils.TASK_LOGGER_THREAD_NAME + ""-%s"", taskExecutionContext.getTaskAppId());
-        ExecutorService parseProcessOutputExecutorService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName);
-        parseProcessOutputExecutorService.submit(new Runnable(){
-            @Override
-            public void run() {
-                BufferedReader inReader = null;
-
-                try {
-                    inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
-                    String line;
-
-                    long lastFlushTime = System.currentTimeMillis();
-
-                    while ((line = inReader.readLine()) != null) {
+        ExecutorService getOutputLogService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName + ""-"" + ""getOutputLogService"");
+        getOutputLogService.submit(() -> {
+            BufferedReader inReader = null;
+            try {
+                inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
+                String line;
+                logBuffer.add(""welcome to use bigdata scheduling system..."");
+                while ((line = inReader.readLine()) != null) {
                         logBuffer.add(line);","[{'comment': 'The indent problem', 'commenter': 'chengshiwen'}]"
5074,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/AbstractCommandExecutor.java,"@@ -349,28 +352,40 @@ private void clear() {
      */
     private void parseProcessOutput(Process process) {
         String threadLoggerInfoName = String.format(LoggerUtils.TASK_LOGGER_THREAD_NAME + ""-%s"", taskExecutionContext.getTaskAppId());
-        ExecutorService parseProcessOutputExecutorService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName);
-        parseProcessOutputExecutorService.submit(new Runnable(){
-            @Override
-            public void run() {
-                BufferedReader inReader = null;
-
-                try {
-                    inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
-                    String line;
-
-                    long lastFlushTime = System.currentTimeMillis();
-
-                    while ((line = inReader.readLine()) != null) {
+        ExecutorService getOutputLogService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName + ""-"" + ""getOutputLogService"");
+        getOutputLogService.submit(() -> {
+            BufferedReader inReader = null;
+            try {
+                inReader = new BufferedReader(new InputStreamReader(process.getInputStream()));
+                String line;
+                logBuffer.add(""welcome to use bigdata scheduling system..."");
+                while ((line = inReader.readLine()) != null) {
                         logBuffer.add(line);
+                }
+            } catch (Exception e) {
+                logger.error(e.getMessage(), e);
+            } finally {
+                logOutputIsSuccess = true;
+                close(inReader);
+            }
+        });
+        getOutputLogService.shutdown();
+        ExecutorService parseProcessOutputExecutorService = ThreadUtils.newDaemonSingleThreadExecutor(threadLoggerInfoName);
+        parseProcessOutputExecutorService.submit(() -> {
+            try {
+                long lastFlushTime = System.currentTimeMillis();
+                while (logBuffer.size() > 0 || !logOutputIsSuccess) {
+                    if (logBuffer.size() > 0) {
                         lastFlushTime = flush(lastFlushTime);
+                    } else {
+                        Thread.sleep(Constants.DEFAULT_LOG_FLUSH_INTERVAL);
+","[{'comment': 'The empty line', 'commenter': 'chengshiwen'}]"
5092,dolphinscheduler-dao/src/main/resources/datasource.properties,"@@ -16,16 +16,16 @@
 #
 
 # postgresql
-spring.datasource.driver-class-name=org.postgresql.Driver
-spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
-spring.datasource.username=test
-spring.datasource.password=test
+#spring.datasource.driver-class-name=org.postgresql.Driver
+#spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
+#spring.datasource.username=test
+#spring.datasource.password=test
 
 # mysql
-#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
-#spring.datasource.url=jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8
-#spring.datasource.username=xxxx
-#spring.datasource.password=xxxx
+spring.datasource.driver-class-name=com.mysql.jdbc.Driver
+spring.datasource.url=jdbc:mysql://localhost:3306/dolphinscheduler
+spring.datasource.username=ds_user
+spring.datasource.password=dolphinscheduler","[{'comment': 'Do not submit this changes', 'commenter': 'chengshiwen'}]"
5092,dolphinscheduler-ui/.env,"@@ -14,7 +14,7 @@
  # limitations under the License.
 
 # back end interface address
-API_BASE = http://192.168.xx.xx:12345
+API_BASE = http://127.0.0.1:12345","[{'comment': 'Do not submit this changes', 'commenter': 'chengshiwen'}]"
5092,dolphinscheduler-ui/src/js/conf/login/App.vue,"@@ -138,6 +138,9 @@
       }
     },
     created () {
+      console.log(process.env.NODE_ENV)
+      console.log(process.env.API_BASE)
+      console.log(process.env.VUE_APP_API_BASE)","[{'comment': 'Do not submit this changes', 'commenter': 'chengshiwen'}]"
5092,pom.xml,"@@ -383,7 +383,7 @@
                 <groupId>mysql</groupId>
                 <artifactId>mysql-connector-java</artifactId>
                 <version>${mysql.connector.version}</version>
-                <scope>test</scope>
+                <scope>compile</scope>","[{'comment': 'Do not submit this changes', 'commenter': 'chengshiwen'}]"
5093,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/RegexUtils.java,"@@ -30,6 +30,8 @@
      */
     private static final String CHECK_NUMBER = ""^-?\\d+(\\.\\d+)?$"";
 
+    private static final String LINUX_USERNAME_PATTERN = ""[a-z_][a-z\\d_]{0,30}"";","[{'comment': 'This regular expression pattern is not correct. `[a-zA-Z0-9_.][a-zA-Z0-9_.-]*[$]?` should be used by `man useradd` and it has better compatibility.\r\n\r\n![image](https://user-images.githubusercontent.com/4902714/111784824-cdbd4e00-88f6-11eb-8806-4c879755ed2a.png)\r\n', 'commenter': 'chengshiwen'}, {'comment': '\r\n![image](https://user-images.githubusercontent.com/21101605/111860431-5d5c0e80-8982-11eb-8547-9af6881359a6.png)\r\n\r\nThis is the constraints of ubuntu OS above. different Linux OS have different constraints of username.  \r\nWe can give the strictest rules to fit all of those different OS. which refers to https://stackoverflow.com/questions/6949667/what-are-the-real-rules-for-linux-usernames-on-centos-6-and-rhel-6', 'commenter': 'haydenzhourepo'}, {'comment': 'make sense', 'commenter': 'chengshiwen'}]"
5156,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessService.java,"@@ -711,6 +700,14 @@ private ProcessInstance constructProcessInstance(Command command, String host) {
                 if (commandTypeIfComplement == CommandType.REPEAT_RUNNING) {
                     setGlobalParamIfCommanded(processDefinition, cmdParam);
                 }
+
+                // Recalculate global parameters after rerun.
+
+                processInstance.setGlobalParams(ParameterUtils.curingGlobalParams(
+                        processDefinition.getGlobalParamMap(),
+                        processDefinition.getGlobalParamList(),
+                        commandTypeIfComplement,
+                        processInstance.getScheduleTime()));","[{'comment': 'What problem does this part of the code solve?', 'commenter': 'zhuangchong'}, {'comment': 'It is useless, has been deleted, thanks for correcting', 'commenter': 'lyyprean'}]"
5177,LICENSE,"@@ -200,9 +200,9 @@
    See the License for the specific language governing permissions and
    limitations under the License.
 =======================================================================
-Apache DolphinScheduler (incubating) Subcomponents:
+Apache DolphinScheduler  Subcomponents:","[{'comment': 'I have checked and there is no problem.\r\nIt would be better if the extra space could be removed.', 'commenter': 'chengshiwen'}]"
5179,ambari_plugin/common-services/DOLPHIN/1.3.6/configuration/dolphin-common.xml,"@@ -1,3 +1,4 @@
+","[{'comment': 'One more empty line', 'commenter': 'chengshiwen'}]"
5200,dolphinscheduler-common/src/main/resources/common.properties,"@@ -14,71 +14,50 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-","[{'comment': 'Can the modification of this document be reverted?', 'commenter': 'CalvinKirs'}, {'comment': 'How to modify it', 'commenter': 'didiaode18'}, {'comment': '![image](https://user-images.githubusercontent.com/4902714/114173866-654c1480-996a-11eb-8ace-027d13c7882c.png)\r\n\r\n![image](https://user-images.githubusercontent.com/4902714/114173974-8ad91e00-996a-11eb-80fb-2c94b3c4c1b6.png)\r\n', 'commenter': 'chengshiwen'}, {'comment': 'As for you, the commit `8b53ed7` introduced the deleted changes, so you can execute `git checkout 8b53ed7~1 -- dolphinscheduler-common/src/main/resources/common.properties`', 'commenter': 'chengshiwen'}]"
5200,dolphinscheduler-dist/release-docs/licenses/ui-licenses/LICENSE-@form-create-element-ui,"@@ -1,21 +0,0 @@
-MIT License
-","[{'comment': 'This file should be kept. `git checkout 47a751f~1 -- dolphinscheduler-dist/release-docs/licenses/ui-licenses/LICENSE-@form-create-element-ui`', 'commenter': 'chengshiwen'}, {'comment': 'Thanks for your code  review，And I want to know whether this code contribution is successful ?', 'commenter': 'didiaode18'}]"
5200,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HadoopUtils.java,"@@ -420,9 +419,7 @@ public ExecutionStatus getApplicationStatus(String applicationId) throws Excepti
 
         String result = Constants.FAILED;
         String applicationUrl = getApplicationUrl(applicationId);
-        if (logger.isDebugEnabled()) {
-            logger.debug(""generate yarn application url, applicationUrl={}"", applicationUrl);
-        }
+        logger.info(""applicationUrl={}"", applicationUrl);","[{'comment': 'The outer loop calls this method, and if the log level is changed to INFO here, This information will always be printed(the YARN task runtime)', 'commenter': 'zhuangchong'}, {'comment': 'Sorry, I did not modify the code, it may be caused by a git conflict', 'commenter': 'didiaode18'}]"
5200,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HadoopUtils.java,"@@ -435,9 +432,7 @@ public ExecutionStatus getApplicationStatus(String applicationId) throws Excepti
         } else {
             //may be in job history
             String jobHistoryUrl = getJobHistoryUrl(applicationId);
-            if (logger.isDebugEnabled()) {
-                logger.debug(""generate yarn job history application url, jobHistoryUrl={}"", jobHistoryUrl);
-            }
+            logger.info(""jobHistoryUrl={}"", jobHistoryUrl);","[{'comment': 'The outer loop calls this method, and if the log level is changed to INFO here, This information will always be printed(the YARN task runtime)', 'commenter': 'zhuangchong'}, {'comment': 'Sorry, I did not modify the code, it may be caused by a git conflict', 'commenter': 'didiaode18'}, {'comment': 'It is suggested to pull the latest branch code, modify and submit PR again', 'commenter': 'zhuangchong'}, {'comment': 'ok,Thanks for your code review very much.', 'commenter': 'didiaode18'}]"
5200,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HadoopUtils.java,"@@ -612,7 +607,9 @@ public static String getAppAddress(String appAddress, String rmHa) {
             return null;
         }
 
-        String end = Constants.COLON + split2[1];
+        String activeResourceManagerPort = String.valueOf(PropertyUtils.getInt(Constants.HADOOP_RESOURCE_MANAGER_HTTPADDRESS_PORT, 8088));
+        String rest = split2[1].substring(activeResourceManagerPort.length());
+        String end = Constants.COLON + activeResourceManagerPort + rest;","[{'comment': ""1. How do you configure this property 'yarn.application.status.address' in the common.properties file?\r\n\r\n2. In the common.properties file, the property 'yarn.application.status.address=http://ds1:8088/ws/v1/cluster/apps/%s' have configured in the port, the changes of the code is also increase the port handling, This will send a conflict.\r\n"", 'commenter': 'zhuangchong'}, {'comment': '1 # if resourcemanager HA enable or not use resourcemanager, please keep the default value; If resourcemanager is single, you only need to replace ds1 to actual resourcemanager hostname.\r\nyarn.application.status.address=http://ds1:8088/ws/v1/cluster/apps/%s\r\n# if custom you  resourcemanager port ,you need to replace 8088 else default value.\r\nresource.manager.httpaddress.port=8088\r\n2 I think this port should be set separately', 'commenter': 'didiaode18'}, {'comment': 'I understand what you think. At present, there are two attributes that represent yarn resource manager HTTP port. It is suggested to change them to one', 'commenter': 'zhuangchong'}, {'comment': 'Right, don’t you know it’s solved now?', 'commenter': 'didiaode18'}, {'comment': ""In  the common.properties file there are two properties(yarn.application.status.address=http://ds1:8088/ws/v1/cluster/apps/%s;resource.manager.httpaddress.port=8088) that both represent the yarn resource manager http port. It is recommended to use only one property to represent.\r\n\r\n\r\nSolution 1: Keep the status quo. When customizing the port, you need to modify 'resource.manager.httpaddress.port=8088' and 'yarn.application.status.address=http://ds1:8088/ws/v1/cluster/apps /%s' port value\r\nSolution 2:'yarn.application.status.address=http://ds1:8088/ws/v1/cluster/apps/%s' is modified to 'yarn.application.status.address=http://ds1:%s /ws/v1/cluster/apps/%s', use 'resource.manager.httpaddress.port=8088' in the code to replace the port value\r\n\r\n\r\n"", 'commenter': 'zhuangchong'}, {'comment': 'I agree Solution 2,I will revise and submit again', 'commenter': 'didiaode18'}]"
5243,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/task/datax/DataxTask.java,"@@ -462,7 +462,10 @@ public String loadJvmEnv(DataxParameters dataXParameters) {
 
         try {
             SQLStatementParser parser = DataxUtils.getSqlStatementParser(dbType, sql);
-            notNull(parser, String.format(""database driver [%s] is not support"", dbType.toString()));
+            if (parser == null) {
+                logger.warn(""database driver [{}] is not support grammatical analysis sql"", dbType);
+                return new String[0];","[{'comment': 'Why not ""return null;""', 'commenter': 'wen-hemin'}, {'comment': 'I think there is no problem returning null, but the code smell check suggest we should use empty array to replace null.', 'commenter': 'ruanwenjun'}]"
5246,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/worker/sql/SqlExecutorTest.java,"@@ -114,16 +112,16 @@ private void sharedTestSqlTask(String nodeName, String taskAppId, String tenantC
 
 
         // custom logger
-        Logger taskLogger = LoggerFactory.getLogger(LoggerUtils.buildTaskId(LoggerUtils.TASK_LOGGER_INFO_PREFIX,
-                taskInstance.getProcessDefinitionId(),
-                taskInstance.getProcessInstanceId(),
-                taskInstance.getId()));
+//        Logger taskLogger = LoggerFactory.getLogger(LoggerUtils.buildTaskId(LoggerUtils.TASK_LOGGER_INFO_PREFIX,
+//                taskInstance.getProcessDefinitionId(),
+//                taskInstance.getProcessInstanceId(),
+//                taskInstance.getId()));","[{'comment': 'It can be deleted here', 'commenter': 'wen-hemin'}]"
5246,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/LoggerUtils.java,"@@ -67,20 +67,15 @@ private LoggerUtils() {
      * build job id
      *
      * @param affix Task Logger's prefix
-     * @param processDefId process define id
      * @param processInstId process instance id
      * @param taskId task id
      * @return task id format
      */
     public static String buildTaskId(String affix,
-                                     int processDefId,
                                      int processInstId,
                                      int taskId) {
         // - [taskAppId=TASK_79_4084_15210]
-        return String.format("" - %s%s-%s-%s-%s]"", TASK_APPID_LOG_FORMAT, affix,
-                processDefId,
-                processInstId,
-                taskId);
+        return String.format("" - %s%s-%s-%s]"", TASK_APPID_LOG_FORMAT, affix, processInstId, taskId);","[{'comment': 'It is suggested to modify it to be consistent with the log path rule.\r\nIt is convenient to debug through log.', 'commenter': 'wen-hemin'}, {'comment': 'This is taskAppId, not log path', 'commenter': 'brave-lee'}]"
5265,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/plugIn/jsPlumbHandle.js,"@@ -271,9 +271,10 @@ JSP.prototype.initNode = function (el) {
  */
 JSP.prototype.tasksContextmenu = function (event) {
   if (this.config.isContextmenu) {
-    const routerName = router.history.current.name
+    const isDefinition = router.history.current.name === 'projects-definition-details'
     // state
-    const isOne = routerName === 'projects-definition-details' && this.dag.releaseState !== 'NOT_RELEASE'
+    // const isOne = routerName === 'projects-definition-details' && this.dag.releaseState !== 'NOT_RELEASE'
+    const isOne = true","[{'comment': '`const isOne` is always `true`, seem to forget the comment?', 'commenter': 'chengshiwen'}]"
5285,pom.xml,"@@ -35,17 +35,17 @@
         </license>
     </licenses>
     <scm>
-        <connection>scm:git:https://github.com/apache/incubator-dolphinscheduler.git</connection>
-        <developerConnection>scm:git:https://github.com/apache/incubator-dolphinscheduler.git</developerConnection>
-        <url>https://github.com/apache/incubator-dolphinscheduler</url>
+        <connection>scm:git:https://github.com/apache/dolphinscheduler.git</connection>
+        <developerConnection>scm:git:https://github.com/apache/dolphinscheduler.git</developerConnection>
+        <url>https://github.com/apache/dolphinscheduler</url>
         <tag>HEAD</tag>
     </scm>
     <mailingLists>
         <mailingList>
             <name>DolphinScheduler Developer List</name>
-            <post>dev@dolphinscheduler.incubator.apache.org</post>
-            <subscribe>dev-subscribe@dolphinscheduler.incubator.apache.org</subscribe>
-            <unsubscribe>dev-unsubscribe@dolphinscheduler.incubator.apache.org</unsubscribe>
+            <post>dev-subscribe@dolphinscheduler.apache.org</post>","[{'comment': '`-subscribe` is not needed', 'commenter': 'chengshiwen'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAspect.java,"@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.Arrays;
+
+import javax.servlet.http.HttpServletRequest;
+
+import org.aspectj.lang.ProceedingJoinPoint;
+import org.aspectj.lang.annotation.Around;
+import org.aspectj.lang.annotation.Aspect;
+import org.aspectj.lang.annotation.Pointcut;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Component;
+import org.springframework.web.context.request.RequestContextHolder;
+import org.springframework.web.context.request.ServletRequestAttributes;
+
+@Aspect
+@Component
+public class AccessLogAspect {
+    private static final Logger logger = LoggerFactory.getLogger(AccessLogAspect.class);
+
+    @Pointcut(""@annotation(org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation)"")
+    public void logPointCut(){}
+
+    @Around(""logPointCut()"")
+    public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
+        long startTime = System.currentTimeMillis();
+
+        ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
+        if (attributes != null) {
+            HttpServletRequest request = attributes.getRequest();
+            String userName = ""NOT LOGIN"";
+            User loginUser = (User) (request.getAttribute(Constants.SESSION_USER));
+            if (loginUser != null) {
+                userName = loginUser.getUserName();
+            }
+
+            logger.info(""REQUEST LOGIN_USER:{}, URI:{}, METHOD:{}, HANDLER:{}, ARGS:{}"",
+                    userName,
+                    request.getRequestURI(),
+                    request.getMethod(),
+                    proceedingJoinPoint.getSignature().getDeclaringTypeName() + ""."" + proceedingJoinPoint.getSignature().getName(),
+                    Arrays.toString(proceedingJoinPoint.getArgs()));","[{'comment': 'Can we consider adding traceId? Otherwise, it seems difficult to connect request and response 😁 ', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoggerController.java,"@@ -102,6 +99,7 @@
     @GetMapping(value = ""/download-log"")
     @ResponseBody
     @ApiException(DOWNLOAD_TASK_INSTANCE_LOG_FILE_ERROR)
+    @AccessLogAnnotation
     public ResponseEntity downloadTaskLog(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                                           @RequestParam(value = ""taskInstanceId"") int taskInstanceId) {
         byte[] logBytes = loggerService.getLogBytes(taskInstanceId);","[{'comment': 'There is no need to record the result of this method, it will print the byte array.', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java,"@@ -108,8 +110,6 @@ public Result createUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_
                              @RequestParam(value = ""email"") String email,
                              @RequestParam(value = ""phone"", required = false) String phone,
                              @RequestParam(value = ""state"", required = false) int state) throws Exception {
-        logger.info(""login user {}, create user, userName: {}, email: {}, tenantId: {}, userPassword: {}, phone: {}, user queue: {}, state: {}"",","[{'comment': 'Maybe we need to filter the password as before?', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAnnotation.java,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import java.lang.annotation.Documented;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import java.lang.annotation.Target;
+
+@Target(ElementType.METHOD)
+@Retention(RetentionPolicy.RUNTIME)
+@Documented
+public @interface AccessLogAnnotation {
+    String[] ignoreRequestArgs() default {};
+
+    boolean ignoreRequest() default false;
+
+    boolean ignoreResponse() default true;","[{'comment': 'Maybe the default value of `ignoreResponse` should be false? I am not sure. ', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAspect.java,"@@ -0,0 +1,116 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.lang.reflect.Method;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import javax.servlet.http.HttpServletRequest;
+
+import org.aspectj.lang.ProceedingJoinPoint;
+import org.aspectj.lang.annotation.Around;
+import org.aspectj.lang.annotation.Aspect;
+import org.aspectj.lang.annotation.Pointcut;
+import org.aspectj.lang.reflect.MethodSignature;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Component;
+import org.springframework.web.context.request.RequestContextHolder;
+import org.springframework.web.context.request.ServletRequestAttributes;
+
+@Aspect
+@Component
+public class AccessLogAspect {
+    private static final Logger logger = LoggerFactory.getLogger(AccessLogAspect.class);
+
+    @Pointcut(""@annotation(org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation)"")
+    public void logPointCut(){}
+
+    @Around(""logPointCut()"")
+    public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
+        long startTime = System.currentTimeMillis();
+
+        // fetch AccessLogAnnotation
+        MethodSignature sign =  (MethodSignature) proceedingJoinPoint.getSignature();
+        Method method = sign.getMethod();
+        AccessLogAnnotation annotation = method.getAnnotation(AccessLogAnnotation.class);
+
+        Object ob = proceedingJoinPoint.proceed();
+
+        String logText = """";
+
+        // log request
+        if (!annotation.ignoreRequest()) {
+            ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
+            if (attributes != null) {
+                HttpServletRequest request = attributes.getRequest();
+
+                // handle login info
+                String userName = ""NOT LOGIN"";
+                User loginUser = (User) (request.getAttribute(Constants.SESSION_USER));
+                if (loginUser != null) {
+                    userName = loginUser.getUserName();
+                }
+
+                // handle args
+                Object[] args = proceedingJoinPoint.getArgs();
+                String argsString = Arrays.toString(args);","[{'comment': 'It seems that changing ignoreRequestArgs from argsName to argsIndex is more efficient? What do you think', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAnnotation.java,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import java.lang.annotation.Documented;
+import java.lang.annotation.ElementType;
+import java.lang.annotation.Retention;
+import java.lang.annotation.RetentionPolicy;
+import java.lang.annotation.Target;
+
+@Target(ElementType.METHOD)
+@Retention(RetentionPolicy.RUNTIME)
+@Documented
+public @interface AccessLogAnnotation {
+    String[] ignoreRequestArgs() default {};
+
+    boolean ignoreRequest() default false;","[{'comment': 'I think you can add some notes, because this might be a general annotation and other people will use it.', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAspect.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.lang.reflect.Method;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import javax.servlet.http.HttpServletRequest;
+
+import org.aspectj.lang.ProceedingJoinPoint;
+import org.aspectj.lang.annotation.Around;
+import org.aspectj.lang.annotation.Aspect;
+import org.aspectj.lang.annotation.Pointcut;
+import org.aspectj.lang.reflect.MethodSignature;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Component;
+import org.springframework.web.context.request.RequestContextHolder;
+import org.springframework.web.context.request.ServletRequestAttributes;
+
+@Aspect
+@Component
+public class AccessLogAspect {
+    private static final Logger logger = LoggerFactory.getLogger(AccessLogAspect.class);
+
+    @Pointcut(""@annotation(org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation)"")
+    public void logPointCut(){
+        // Do nothing because of it's a pointcut
+    }
+
+    @Around(""logPointCut()"")
+    public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
+        long startTime = System.currentTimeMillis();
+
+        // fetch AccessLogAnnotation
+        MethodSignature sign =  (MethodSignature) proceedingJoinPoint.getSignature();
+        Method method = sign.getMethod();
+        AccessLogAnnotation annotation = method.getAnnotation(AccessLogAnnotation.class);
+
+        Object ob = proceedingJoinPoint.proceed();
+
+        String logText = """";
+
+        // log request
+        if (!annotation.ignoreRequest()) {
+            ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
+            if (attributes != null) {
+                HttpServletRequest request = attributes.getRequest();
+
+                // handle login info
+                String userName = parseLoginInfo(request);
+
+                // handle args
+                String argsString = parseArgs(proceedingJoinPoint, annotation);
+                logText = String.format(""REQUEST LOGIN_USER:%s, URI:%s, METHOD:%s, HANDLER:%s, ARGS:%s"",
+                        userName,
+                        request.getRequestURI(),
+                        request.getMethod(),
+                        proceedingJoinPoint.getSignature().getDeclaringTypeName() + ""."" + proceedingJoinPoint.getSignature().getName(),
+                        argsString);
+
+            }
+        }
+
+        // log response
+        if (!annotation.ignoreResponse()) {
+            logText += String.format(""%nRESPONSE:%s, REQUEST DURATION:%s milliseconds"",","[{'comment': ""If the `logText` is empty, do you still need to add '%n' ？"", 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAspect.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.lang.reflect.Method;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import javax.servlet.http.HttpServletRequest;
+
+import org.aspectj.lang.ProceedingJoinPoint;
+import org.aspectj.lang.annotation.Around;
+import org.aspectj.lang.annotation.Aspect;
+import org.aspectj.lang.annotation.Pointcut;
+import org.aspectj.lang.reflect.MethodSignature;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Component;
+import org.springframework.web.context.request.RequestContextHolder;
+import org.springframework.web.context.request.ServletRequestAttributes;
+
+@Aspect
+@Component
+public class AccessLogAspect {
+    private static final Logger logger = LoggerFactory.getLogger(AccessLogAspect.class);
+
+    @Pointcut(""@annotation(org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation)"")
+    public void logPointCut(){
+        // Do nothing because of it's a pointcut
+    }
+
+    @Around(""logPointCut()"")
+    public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
+        long startTime = System.currentTimeMillis();
+
+        // fetch AccessLogAnnotation
+        MethodSignature sign =  (MethodSignature) proceedingJoinPoint.getSignature();
+        Method method = sign.getMethod();
+        AccessLogAnnotation annotation = method.getAnnotation(AccessLogAnnotation.class);
+
+        Object ob = proceedingJoinPoint.proceed();
+
+        String logText = """";
+
+        // log request
+        if (!annotation.ignoreRequest()) {
+            ServletRequestAttributes attributes = (ServletRequestAttributes) RequestContextHolder.getRequestAttributes();
+            if (attributes != null) {
+                HttpServletRequest request = attributes.getRequest();
+
+                // handle login info
+                String userName = parseLoginInfo(request);
+
+                // handle args
+                String argsString = parseArgs(proceedingJoinPoint, annotation);
+                logText = String.format(""REQUEST LOGIN_USER:%s, URI:%s, METHOD:%s, HANDLER:%s, ARGS:%s%n"",
+                        userName,
+                        request.getRequestURI(),
+                        request.getMethod(),
+                        proceedingJoinPoint.getSignature().getDeclaringTypeName() + ""."" + proceedingJoinPoint.getSignature().getName(),
+                        argsString);
+
+            }
+        }
+
+        // log response
+        if (!annotation.ignoreResponse()) {
+            logText += String.format(""RESPONSE:%s, REQUEST DURATION:%s milliseconds%n"",","[{'comment': 'The `%n` should be removed here ? Otherwise, the log will get an extra blank line. \r\n```\r\nRESPONSE:%s, REQUEST DURATION:%s milliseconds\r\n\r\nRESPONSE:%s, REQUEST DURATION:%s milliseconds\r\n```', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/resources/logback-api.xml,"@@ -58,4 +58,4 @@
         <appender-ref ref=""APILOGFILE""/>
     </root>
 
-</configuration>
\ No newline at end of file
+</configuration>","[{'comment': ""It's better to ignore this change?"", 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/aspect/AccessLogAspect.java,"@@ -0,0 +1,128 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.aspect;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.lang.reflect.Method;
+import java.util.Arrays;
+import java.util.HashMap;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import javax.servlet.http.HttpServletRequest;
+
+import org.aspectj.lang.ProceedingJoinPoint;
+import org.aspectj.lang.annotation.Around;
+import org.aspectj.lang.annotation.Aspect;
+import org.aspectj.lang.annotation.Pointcut;
+import org.aspectj.lang.reflect.MethodSignature;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Component;
+import org.springframework.web.context.request.RequestContextHolder;
+import org.springframework.web.context.request.ServletRequestAttributes;
+
+@Aspect
+@Component
+public class AccessLogAspect {
+    private static final Logger logger = LoggerFactory.getLogger(AccessLogAspect.class);
+
+    @Pointcut(""@annotation(org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation)"")
+    public void logPointCut(){
+        // Do nothing because of it's a pointcut
+    }
+
+    @Around(""logPointCut()"")
+    public Object doAround(ProceedingJoinPoint proceedingJoinPoint) throws Throwable {
+        long startTime = System.currentTimeMillis();
+
+        // fetch AccessLogAnnotation
+        MethodSignature sign =  (MethodSignature) proceedingJoinPoint.getSignature();
+        Method method = sign.getMethod();
+        AccessLogAnnotation annotation = method.getAnnotation(AccessLogAnnotation.class);
+
+        Object ob = proceedingJoinPoint.proceed();","[{'comment': 'It seems that if the method `proceedingJoinPoint.proceed()` throws an exception, the request log will not recorded.', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java,"@@ -87,12 +83,11 @@
     })
     @PostMapping(value = ""/login"")
     @ApiException(USER_LOGIN_FAILURE)
+    @AccessLogAnnotation
     public Result login(@RequestParam(value = ""userName"") String userName,","[{'comment': ""Ignore the request and response, and we shouldn't log the password."", 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java,"@@ -132,9 +127,9 @@ public Result login(@RequestParam(value = ""userName"") String userName,
     @ApiOperation(value = ""signOut"", notes = ""SIGNOUT_NOTES"")
     @PostMapping(value = ""/signOut"")
     @ApiException(SIGN_OUT_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
     public Result signOut(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                           HttpServletRequest request) {","[{'comment': 'Ignore the request', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/MonitorController.java,"@@ -67,9 +64,8 @@
     @GetMapping(value = ""/master/list"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(LIST_MASTERS_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")","[{'comment': ""If you don’t want to log any parameters, you needn't add this annotation here."", 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -720,16 +646,13 @@ public Result batchDeleteProcessDefinitionByIds(@ApiIgnore @RequestAttribute(val
     })
     @GetMapping(value = ""/export"")
     @ResponseBody
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
     public void batchExportProcessDefinitionByIds(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                                                   @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
                                                   @RequestParam(""processDefinitionIds"") String processDefinitionIds,
                                                   HttpServletResponse response) {","[{'comment': 'Ignore the response here', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java,"@@ -281,12 +274,11 @@ public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Cons
     @GetMapping(value = ""/delete"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(DELETE_PROCESS_INSTANCE_BY_ID_ERROR)
+    @AccessLogAnnotation","[{'comment': 'ignoreRequestArgs = ""loginUser""', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java,"@@ -282,11 +277,10 @@ public Result queryProjectCreatedAndAuthorizedByUser(@ApiIgnore @RequestAttribut
     })
     @PostMapping(value = ""/import-definition"")
     @ApiException(IMPORT_PROCESS_DEFINE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")","[{'comment': 'Filter the file.', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java,"@@ -132,12 +132,11 @@ public Result createUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_
     @GetMapping(value = ""/list-paging"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(QUERY_USER_LIST_PAGING_ERROR)
+    @AccessLogAnnotation","[{'comment': 'Filter the loginUser?', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java,"@@ -175,6 +174,7 @@ public Result queryUserList(@ApiIgnore @RequestAttribute(value = Constants.SESSI
     @PostMapping(value = ""/update"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(UPDATE_USER_ERROR)
+    @AccessLogAnnotation
     public Result updateUser(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                              @RequestParam(value = ""id"") int id,
                              @RequestParam(value = ""userName"") String userName,","[{'comment': 'Filter loginUser and password', 'commenter': 'ruanwenjun'}]"
5315,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessInstanceController.java,"@@ -307,6 +299,7 @@ public Result queryProcessInstanceById(@ApiIgnore @RequestAttribute(value = Cons
     @GetMapping(value = ""/select-sub-process"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(QUERY_SUB_PROCESS_INSTANCE_DETAIL_INFO_BY_TASK_ID_ERROR)
+    @AccessLogAnnotation","[{'comment': 'Need to add `ignoreRequestArgs = ""loginUser""` here ?', 'commenter': 'ruanwenjun'}]"
5390,sql/dolphinscheduler_mysql.sql,"@@ -391,59 +391,162 @@ CREATE TABLE `t_ds_error_command` (
 -- ----------------------------
 DROP TABLE IF EXISTS `t_ds_process_definition`;
 CREATE TABLE `t_ds_process_definition` (
-  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'key',
-  `name` varchar(255) DEFAULT NULL COMMENT 'process definition name',
+  `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'self-increasing id',
+  `code` bigint(20) NOT NULL COMMENT 'encoding',
+  `name` varchar(200) DEFAULT NULL COMMENT 'process definition name',","[{'comment': 'The length of the field should be the same as before.', 'commenter': 'wen-hemin'}]"
5390,sql/dolphinscheduler_mysql.sql,"@@ -704,6 +805,7 @@ CREATE TABLE `t_ds_task_instance` (
   `retry_times` int(4) DEFAULT '0' COMMENT 'task retry times',
   `pid` int(4) DEFAULT NULL COMMENT 'pid of task',
   `app_link` text COMMENT 'yarn app id',
+  `task_params` text COMMENT 'job custom parameters',","[{'comment': 'text -> longtext', 'commenter': 'wen-hemin'}]"
5390,sql/dolphinscheduler_postgre.sql,"@@ -287,52 +287,146 @@ CREATE TABLE t_ds_error_command (
 DROP TABLE IF EXISTS t_ds_process_definition;
 CREATE TABLE t_ds_process_definition (
   id int NOT NULL  ,
+  code bigint NOT NULL,
   name varchar(255) DEFAULT NULL ,
   version int DEFAULT NULL ,
+  description text ,
+  project_code bigint DEFAULT NULL ,
   release_state int DEFAULT NULL ,
-  project_id int DEFAULT NULL ,
   user_id int DEFAULT NULL ,
-  process_definition_json text ,
-  description text ,
   global_params text ,
-  flag int DEFAULT NULL ,
   locations text ,
   connects text ,
-  warning_group_id int4 DEFAULT NULL ,
-  create_time timestamp DEFAULT NULL ,
+  warning_group_id int DEFAULT NULL ,
+  flag int DEFAULT NULL ,
   timeout int DEFAULT '0' ,
-  tenant_id int NOT NULL DEFAULT '-1' ,
+  tenant_id int DEFAULT '-1' ,
+  create_time timestamp DEFAULT NULL ,
   update_time timestamp DEFAULT NULL ,
-  modify_by varchar(36) DEFAULT '' ,
-  resource_ids varchar(64),
-  PRIMARY KEY (id),
-  CONSTRAINT process_definition_unique UNIQUE (name, project_id)
+  PRIMARY KEY (id) ,
+  CONSTRAINT process_definition_unique UNIQUE (name, project_code)
 ) ;
 
-create index process_definition_index on t_ds_process_definition (project_id,id);
-
---
--- Table structure for table t_ds_process_definition_version
---
+create index process_definition_index on t_ds_process_definition (code,id);
 
-DROP TABLE IF EXISTS t_ds_process_definition_version;
-CREATE TABLE t_ds_process_definition_version (
+DROP TABLE IF EXISTS t_ds_process_definition_log;
+CREATE TABLE t_ds_process_definition_log (
   id int NOT NULL  ,
-  process_definition_id int NOT NULL  ,
+  code bigint NOT NULL,
+  name varchar(255) DEFAULT NULL ,
   version int DEFAULT NULL ,
-  process_definition_json text ,
   description text ,
+  project_code bigint DEFAULT NULL ,
+  release_state int DEFAULT NULL ,
+  user_id int DEFAULT NULL ,
   global_params text ,
   locations text ,
   connects text ,
-  warning_group_id int4 DEFAULT NULL,
+  warning_group_id int DEFAULT NULL ,
+  flag int DEFAULT NULL ,
+  timeout int DEFAULT '0' ,
+  tenant_id int DEFAULT '-1' ,
+  operator int DEFAULT NULL ,
+  operate_time timestamp DEFAULT NULL ,
   create_time timestamp DEFAULT NULL ,
+  update_time timestamp DEFAULT NULL ,
+  PRIMARY KEY (id)
+) ;
+
+DROP TABLE IF EXISTS t_ds_task_definition;
+CREATE TABLE t_ds_task_definition (
+  id int NOT NULL  ,
+  code bigint NOT NULL,
+  name varchar(255) DEFAULT NULL ,
+  version int DEFAULT NULL ,
+  description text ,
+  project_code bigint DEFAULT NULL ,
+  user_id int DEFAULT NULL ,
+  task_type varchar(50) DEFAULT NULL ,
+  task_params text ,
+  flag int DEFAULT NULL ,
+  task_priority int DEFAULT NULL ,
+  worker_group varchar(255) DEFAULT NULL ,
+  fail_retry_times int DEFAULT NULL ,
+  fail_retry_interval int DEFAULT NULL ,
+  timeout_flag int DEFAULT NULL ,
+  timeout_notify_strategy int DEFAULT NULL ,
   timeout int DEFAULT '0' ,
-  resource_ids varchar(64),
+  delay_time int DEFAULT '0' ,
+  resource_ids varchar(255) DEFAULT NULL ,
+  create_time timestamp DEFAULT NULL ,
+  update_time timestamp DEFAULT NULL ,
+  PRIMARY KEY (id) ,
+  CONSTRAINT task_definition_unique UNIQUE (name, project_code)
+) ;
+
+create index task_definition_index on t_ds_task_definition (project_code,id);
+
+DROP TABLE IF EXISTS t_ds_task_definition_log;
+CREATE TABLE t_ds_task_definition_log (
+  id int NOT NULL  ,
+  code bigint NOT NULL,
+  name varchar(255) DEFAULT NULL ,
+  version int DEFAULT NULL ,
+  description text ,
+  project_code bigint DEFAULT NULL ,
+  user_id int DEFAULT NULL ,
+  task_type varchar(50) DEFAULT NULL ,
+  task_params text ,
+  flag int DEFAULT NULL ,
+  task_priority int DEFAULT NULL ,
+  worker_group varchar(255) DEFAULT NULL ,
+  fail_retry_times int DEFAULT NULL ,
+  fail_retry_interval int DEFAULT NULL ,
+  timeout_flag int DEFAULT NULL ,
+  timeout_notify_strategy int DEFAULT NULL ,
+  timeout int DEFAULT '0' ,
+  delay_time int DEFAULT '0' ,
+  resource_ids varchar(255) DEFAULT NULL ,
+  operator int DEFAULT NULL ,
+  operate_time timestamp DEFAULT NULL ,
+  create_time timestamp DEFAULT NULL ,
+  update_time timestamp DEFAULT NULL ,
+  PRIMARY KEY (id)
+) ;
+
+DROP TABLE IF EXISTS t_ds_process_task_relation;
+CREATE TABLE t_ds_process_task_relation (
+  id int NOT NULL  ,
+  name varchar(255) DEFAULT NULL ,
+  process_definition_version int DEFAULT NULL ,
+  project_code bigint DEFAULT NULL ,
+  process_definition_code bigint DEFAULT NULL ,
+  pre_task_code bigint DEFAULT NULL ,
+  pre_task_version int DEFAULT '0' ,
+  post_task_code bigint DEFAULT NULL ,
+  post_task_version int DEFAULT '0' ,
+  condition_type int DEFAULT NULL ,
+  condition_params text ,
+  create_time timestamp DEFAULT NULL ,
+  update_time timestamp DEFAULT NULL ,
   PRIMARY KEY (id)
 ) ;
 
-create index process_definition_id_and_version on t_ds_process_definition_version (process_definition_id,version);
+DROP TABLE IF EXISTS t_ds_process_task_relation_log;
+CREATE TABLE t_ds_process_task_relation_log (
+  id int NOT NULL  ,
+  name varchar(255) DEFAULT NULL ,
+  process_definition_version int DEFAULT NULL ,
+  project_code bigint DEFAULT NULL ,
+  process_definition_code bigint DEFAULT NULL ,
+  pre_task_code bigint DEFAULT NULL ,
+  pre_task_version int DEFAULT '0' ,
+  post_task_code bigint DEFAULT NULL ,
+  post_task_version int DEFAULT '0' ,
+  condition_type int DEFAULT NULL ,
+  condition_params text ,
+  operator int DEFAULT NULL ,
+  operate_time timestamp DEFAULT NULL ,
+  create_time timestamp DEFAULT NULL ,
+  update_time timestamp DEFAULT NULL ,","[{'comment': 'Why don’t the update_time and create_time be handed over to the database for management?Settings in the program can be confusing and easy to forget', 'commenter': 'CalvinKirs'}, {'comment': 'not all database can manage the time, and we will support other databases in the future.\r\nso we can manage it ourself.\r\n', 'commenter': 'lenboo'}]"
5390,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/SnowFlakeUtils.java,"@@ -0,0 +1,91 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import java.net.InetAddress;
+import java.net.UnknownHostException;
+import java.util.Objects;
+
+public class SnowFlakeUtils {
+    // start timestamp
+    private static final long START_TIMESTAMP = 1609430400L; //2021-01-01
+    // Number of digits
+    private static final long SEQUENCE_BIT = 13;
+    private static final long MACHINE_BIT = 2;
+    private static final long MAX_SEQUENCE = ~(-1L << SEQUENCE_BIT);
+    // The displacement to the left
+    private static final long MACHINE_LEFT = SEQUENCE_BIT;
+    private static final long TIMESTAMP_LEFT = SEQUENCE_BIT + MACHINE_BIT;
+    private final int machineId;
+    private long sequence = 0L;
+    private long lastTimestamp = -1L;
+
+    private SnowFlakeUtils() throws SnowFlakeException {
+        try {
+            this.machineId = Math.abs(Objects.hash(InetAddress.getLocalHost().getHostName())) % 32;
+        } catch (UnknownHostException e) {
+            throw new SnowFlakeException(e.getMessage());","[{'comment': 'Maybe it would be better to use & :) This is a boring suggestion. Not much effect. It just looks more professional.', 'commenter': 'CalvinKirs'}]"
5390,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -502,72 +491,69 @@ public Result viewTree(@ApiIgnore @RequestAttribute(value = Constants.SESSION_US
                            @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
                            @RequestParam(""processId"") Integer id,
                            @RequestParam(""limit"") Integer limit) throws Exception {
-
         Map<String, Object> result = processDefinitionService.viewTree(id, limit);
         return returnDataList(result);
     }
 
     /**
-     * get tasks list by process definition id
+     * get tasks list by process definition code
      *
-     * @param loginUser           login user
-     * @param projectName         project name
-     * @param processDefinitionId process definition id
+     * @param loginUser login user
+     * @param projectName project name
+     * @param processDefinitionCode process definition code
      * @return task list
      */
-    @ApiOperation(value = ""getNodeListByDefinitionId"", notes = ""GET_NODE_LIST_BY_DEFINITION_ID_NOTES"")
+    @ApiOperation(value = ""getNodeListByDefinitionCode"", notes = ""GET_NODE_LIST_BY_DEFINITION_CODE_NOTES"")
     @ApiImplicitParams({
-        @ApiImplicitParam(name = ""processDefinitionId"", value = ""PROCESS_DEFINITION_ID"", required = true, dataType = ""Int"", example = ""100"")
+            @ApiImplicitParam(name = ""processDefinitionCode"", value = ""PROCESS_DEFINITION_CODE"", required = true, dataType = ""Long"", example = ""100"")
     })
     @GetMapping(value = ""gen-task-list"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(GET_TASKS_LIST_BY_PROCESS_DEFINITION_ID_ERROR)
-    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
-    public Result getNodeListByDefinitionId(
-        @ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
-        @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
-        @RequestParam(""processDefinitionId"") Integer processDefinitionId) throws Exception {
-
-        Map<String, Object> result = processDefinitionService.getTaskNodeListByDefinitionId(processDefinitionId);
+    public Result getNodeListByDefinitionCode(
+            @ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+            @ApiParam(name = ""projectName"", value = ""PROJECT_NAME"", required = true) @PathVariable String projectName,
+            @RequestParam(""processDefinitionCode"") Long processDefinitionCode) throws Exception {
+        logger.info(""query task node name list by definitionCode, login user:{}, project name:{}, code : {}"",
+                loginUser.getUserName(), projectName, processDefinitionCode);","[{'comment': ""It's best to be consistent with dev  "", 'commenter': 'CalvinKirs'}]"
5449,dolphinscheduler-common/src/main/resources/common.properties,"@@ -58,7 +58,7 @@ fs.s3a.secret.key=OloCLq3n+8+sdPHUhJ21XrSxTC+JK
 yarn.resourcemanager.ha.rm.ids=192.168.xx.xx,192.168.xx.xx
 
 # if resourcemanager HA enable or not use resourcemanager, please keep the default value; If resourcemanager is single, you only need to replace ds1 to actual resourcemanager hostname.
-yarn.application.status.address=http://10.172.33.1:%s/ws/v1/cluster/apps/%s
+yarn.application.status.address=http://ds1:8088/ws/v1/cluster/apps/%s","[{'comment': ""Thank you very much for your PR.\r\nThe port value in the yarn application url 'yarn.application.status.address' is configured in the 'resource.manager.httpaddress.port' property, So here should be modified to 'yarn.application.status.address=http://ds1:%s/ws/v1/cluster/apps/%s'"", 'commenter': 'zhuangchong'}]"
5453,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -870,6 +870,7 @@ private Constants() {
     public static final String FLINK_MAIN_CLASS = ""-c"";
     public static final String FLINK_PARALLELISM = ""-p"";
     public static final String FLINK_SHUTDOWN_ON_ATTACHED_EXIT = ""-sae"";
+    public static final String FLINK_CLI_OPTION_PYTHON = ""-py"";","[{'comment': 'I think maybe `FLINK_PYTHON` is shorter and better', 'commenter': 'chengshiwen'}]"
5453,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/utils/FlinkArgsUtils.java,"@@ -124,6 +124,10 @@ private FlinkArgsUtils() {
 
         ResourceInfo mainJar = param.getMainJar();
         if (mainJar != null) {
+            if (ProgramType.PYTHON == programType) {
+                // -py
+                args.add(Constants.FLINK_CLI_OPTION_PYTHON);
+            }","[{'comment': ""These lines should not place here. It's better to modify them to:\r\n```java\r\n        if (programType != null) {\r\n            if (programType == ProgramType.PYTHON) {\r\n                args.add(Constants.FLINK_PYTHON);        //-py\r\n            } else if (StringUtils.isNotEmpty(mainClass)) {\r\n                args.add(Constants.FLINK_MAIN_CLASS);    //-c\r\n                args.add(param.getMainClass());          //main class\r\n            }\r\n        }\r\n```"", 'commenter': 'chengshiwen'}]"
5465,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java,"@@ -94,7 +94,8 @@
     @ApiOperation(value = ""createSchedule"", notes = ""CREATE_SCHEDULE_NOTES"")
     @ApiImplicitParams({
             @ApiImplicitParam(name = ""processDefinitionId"", value = ""PROCESS_DEFINITION_ID"", required = true, dataType = ""Int"", example = ""100""),
-            @ApiImplicitParam(name = ""schedule"", value = ""SCHEDULE"", dataType = ""String"", example = ""{'startTime':'2019-06-10 00:00:00','endTime':'2019-06-13 00:00:00','crontab':'0 0 3/6 * * ? *'}""),
+            @ApiImplicitParam(name = ""schedule"", value = ""SCHEDULE"", dataType = ""String"",
+                    example = ""{'startTime':'2019-06-10 00:00:00','endTime':'2019-06-13 00:00:00', 'timezoneId':'', 'crontab':'0 0 3/6 * * ? *'}""),","[{'comment': 'Keep space style consistent in `example`', 'commenter': 'chengshiwen'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
5465,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ScheduleMapper.xml,"@@ -19,11 +19,11 @@
 <!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd"" >
 <mapper namespace=""org.apache.dolphinscheduler.dao.mapper.ScheduleMapper"">
     <sql id=""baseSql"">
-        id, process_definition_id, start_time, end_time, crontab, failure_strategy, user_id, release_state,
+        id, process_definition_id, start_time, end_time, timezone_id, crontab, failure_strategy, user_id, release_state,
         warning_type, warning_group_id, process_instance_priority, worker_group, create_time, update_time
     </sql>
     <sql id=""baseSqlV2"">
-        ${alias}.id, ${alias}.process_definition_id, ${alias}.start_time, ${alias}.end_time, ${alias}.crontab, ${alias}.failure_strategy, ${alias}.user_id, ${alias}.release_state,
+        ${alias}.id, ${alias}.process_definition_id, ${alias}.start_time, ${alias}.end_time,${alias}.timezone_id, ${alias}.crontab, ${alias}.failure_strategy, ${alias}.user_id, ${alias}.release_state,","[{'comment': 'Keep space style consistent', 'commenter': 'chengshiwen'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
5465,dolphinscheduler-ui/src/js/conf/home/pages/projects/pages/definition/pages/list/_source/timing.vue,"@@ -61,6 +61,22 @@
         </template>
       </div>
     </div>
+    <div class=""clearfix list"">
+      <div class=""text"">
+        {{$t('Timezone')}}
+      </div>
+      <div class=""cont"">
+        <el-select v-model=timezoneId filterable placeholder=""Timezone"">
+          <el-option
+            v-for=""item in availableTimezoneIDList""
+            :key=""item""
+            :label=""item""
+            :value=""item"">
+          </el-option>
+        </el-select>
+","[{'comment': 'Delete the extra empty line', 'commenter': 'chengshiwen'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
5465,dolphinscheduler-ui/src/js/conf/home/pages/projects/pages/definition/pages/list/_source/timing.vue,"@@ -160,12 +176,14 @@
         processDefinitionId: 0,
         failureStrategy: 'CONTINUE',
         warningTypeList: warningTypeList,
+        availableTimezoneIDList: availableTimezoneIDList,
         warningType: 'NONE',
         notifyGroupList: [],
         warningGroupId: '',
         spinnerLoading: false,
         scheduleTime: '',
         crontab: '0 0 * * * ? *',
+        timezoneId: Intl.DateTimeFormat().resolvedOptions().timeZone,","[{'comment': 'Do not use `Intl`, since it is not supported on old browsers such as IE 11. We need to consider the browser compatibility in next release. You can consider `dayjs` or `momentjs`, and `dayjs` has been introduced in https://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-ui/src/js/module/filter/filter.js', 'commenter': 'chengshiwen'}, {'comment': 'Done, use `moment-timezone` lib to get timezone', 'commenter': 'ruanwenjun'}]"
5465,dolphinscheduler-ui/src/js/conf/home/pages/projects/pages/definition/pages/list/_source/util.js,"@@ -53,8 +53,11 @@ const fuzzyQuery = (list, keyWord) => {
   return arr
 }
 
+const availableTimezoneIDList = ['Africa/Abidjan', 'Africa/Accra', 'Africa/Addis_Ababa', 'Africa/Algiers', 'Africa/Asmara', 'Africa/Asmera', 'Africa/Bamako', 'Africa/Bangui', 'Africa/Banjul', 'Africa/Bissau', 'Africa/Blantyre', 'Africa/Brazzaville', 'Africa/Bujumbura', 'Africa/Cairo', 'Africa/Casablanca', 'Africa/Ceuta', 'Africa/Conakry', 'Africa/Dakar', 'Africa/Dar_es_Salaam', 'Africa/Djibouti', 'Africa/Douala', 'Africa/El_Aaiun', 'Africa/Freetown', 'Africa/Gaborone', 'Africa/Harare', 'Africa/Johannesburg', 'Africa/Juba', 'Africa/Kampala', 'Africa/Khartoum', 'Africa/Kigali', 'Africa/Kinshasa', 'Africa/Lagos', 'Africa/Libreville', 'Africa/Lome', 'Africa/Luanda', 'Africa/Lubumbashi', 'Africa/Lusaka', 'Africa/Malabo', 'Africa/Maputo', 'Africa/Maseru', 'Africa/Mbabane', 'Africa/Mogadishu', 'Africa/Monrovia', 'Africa/Nairobi', 'Africa/Ndjamena', 'Africa/Niamey', 'Africa/Nouakchott', 'Africa/Ouagadougou', 'Africa/Porto-Novo', 'Africa/Sao_Tome', 'Africa/Timbuktu', 'Africa/Tripoli', 'Africa/Tunis', 'Africa/Windhoek', 'America/Adak', 'America/Anchorage', 'America/Anguilla', 'America/Antigua', 'America/Araguaina', 'America/Argentina/Buenos_Aires', 'America/Argentina/Catamarca', 'America/Argentina/ComodRivadavia', 'America/Argentina/Cordoba', 'America/Argentina/Jujuy', 'America/Argentina/La_Rioja', 'America/Argentina/Mendoza', 'America/Argentina/Rio_Gallegos', 'America/Argentina/Salta', 'America/Argentina/San_Juan', 'America/Argentina/San_Luis', 'America/Argentina/Tucuman', 'America/Argentina/Ushuaia', 'America/Aruba', 'America/Asuncion', 'America/Atikokan', 'America/Atka', 'America/Bahia', 'America/Bahia_Banderas', 'America/Barbados', 'America/Belem', 'America/Belize', 'America/Blanc-Sablon', 'America/Boa_Vista', 'America/Bogota', 'America/Boise', 'America/Buenos_Aires', 'America/Cambridge_Bay', 'America/Campo_Grande', 'America/Cancun', 'America/Caracas', 'America/Catamarca', 'America/Cayenne', 'America/Cayman', 'America/Chicago', 'America/Chihuahua', 'America/Coral_Harbour', 'America/Cordoba', 'America/Costa_Rica', 'America/Creston', 'America/Cuiaba', 'America/Curacao', 'America/Danmarkshavn', 'America/Dawson', 'America/Dawson_Creek', 'America/Denver', 'America/Detroit', 'America/Dominica', 'America/Edmonton', 'America/Eirunepe', 'America/El_Salvador', 'America/Ensenada', 'America/Fort_Nelson', 'America/Fort_Wayne', 'America/Fortaleza', 'America/Glace_Bay', 'America/Godthab', 'America/Goose_Bay', 'America/Grand_Turk', 'America/Grenada', 'America/Guadeloupe', 'America/Guatemala', 'America/Guayaquil', 'America/Guyana', 'America/Halifax', 'America/Havana', 'America/Hermosillo', 'America/Indiana/Indianapolis', 'America/Indiana/Knox', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Tell_City', 'America/Indiana/Vevay', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Indianapolis', 'America/Inuvik', 'America/Iqaluit', 'America/Jamaica', 'America/Jujuy', 'America/Juneau', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Knox_IN', 'America/Kralendijk', 'America/La_Paz', 'America/Lima', 'America/Los_Angeles', 'America/Louisville', 'America/Lower_Princes', 'America/Maceio', 'America/Managua', 'America/Manaus', 'America/Marigot', 'America/Martinique', 'America/Matamoros', 'America/Mazatlan', 'America/Mendoza', 'America/Menominee', 'America/Merida', 'America/Metlakatla', 'America/Mexico_City', 'America/Miquelon', 'America/Moncton', 'America/Monterrey', 'America/Montevideo', 'America/Montreal', 'America/Montserrat', 'America/Nassau', 'America/New_York', 'America/Nipigon', 'America/Nome', 'America/Noronha', 'America/North_Dakota/Beulah', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/Nuuk', 'America/Ojinaga', 'America/Panama', 'America/Pangnirtung', 'America/Paramaribo', 'America/Phoenix', 'America/Port-au-Prince', 'America/Port_of_Spain', 'America/Porto_Acre', 'America/Porto_Velho', 'America/Puerto_Rico', 'America/Punta_Arenas', 'America/Rainy_River', 'America/Rankin_Inlet', 'America/Recife', 'America/Regina', 'America/Resolute', 'America/Rio_Branco', 'America/Rosario', 'America/Santa_Isabel', 'America/Santarem', 'America/Santiago', 'America/Santo_Domingo', 'America/Sao_Paulo', 'America/Scoresbysund', 'America/Shiprock', 'America/Sitka', 'America/St_Barthelemy', 'America/St_Johns', 'America/St_Kitts', 'America/St_Lucia', 'America/St_Thomas', 'America/St_Vincent', 'America/Swift_Current', 'America/Tegucigalpa', 'America/Thule', 'America/Thunder_Bay', 'America/Tijuana', 'America/Toronto', 'America/Tortola', 'America/Vancouver', 'America/Virgin', 'America/Whitehorse', 'America/Winnipeg', 'America/Yakutat', 'America/Yellowknife', 'Antarctica/Casey', 'Antarctica/Davis', 'Antarctica/DumontDUrville', 'Antarctica/Macquarie', 'Antarctica/Mawson', 'Antarctica/McMurdo', 'Antarctica/Palmer', 'Antarctica/Rothera', 'Antarctica/South_Pole', 'Antarctica/Syowa', 'Antarctica/Troll', 'Antarctica/Vostok', 'Arctic/Longyearbyen', 'Asia/Aden', 'Asia/Almaty', 'Asia/Amman', 'Asia/Anadyr', 'Asia/Aqtau', 'Asia/Aqtobe', 'Asia/Ashgabat', 'Asia/Ashkhabad', 'Asia/Atyrau', 'Asia/Baghdad', 'Asia/Bahrain', 'Asia/Baku', 'Asia/Bangkok', 'Asia/Barnaul', 'Asia/Beirut', 'Asia/Bishkek', 'Asia/Brunei', 'Asia/Calcutta', 'Asia/Chita', 'Asia/Choibalsan', 'Asia/Chongqing', 'Asia/Chungking', 'Asia/Colombo', 'Asia/Dacca', 'Asia/Damascus', 'Asia/Dhaka', 'Asia/Dili', 'Asia/Dubai', 'Asia/Dushanbe', 'Asia/Famagusta', 'Asia/Gaza', 'Asia/Harbin', 'Asia/Hebron', 'Asia/Ho_Chi_Minh', 'Asia/Hong_Kong', 'Asia/Hovd', 'Asia/Irkutsk', 'Asia/Istanbul', 'Asia/Jakarta', 'Asia/Jayapura', 'Asia/Jerusalem', 'Asia/Kabul', 'Asia/Kamchatka', 'Asia/Karachi', 'Asia/Kashgar', 'Asia/Kathmandu', 'Asia/Katmandu', 'Asia/Khandyga', 'Asia/Kolkata', 'Asia/Krasnoyarsk', 'Asia/Kuala_Lumpur', 'Asia/Kuching', 'Asia/Kuwait', 'Asia/Macao', 'Asia/Macau', 'Asia/Magadan', 'Asia/Makassar', 'Asia/Manila', 'Asia/Muscat', 'Asia/Nicosia', 'Asia/Novokuznetsk', 'Asia/Novosibirsk', 'Asia/Omsk', 'Asia/Oral', 'Asia/Phnom_Penh', 'Asia/Pontianak', 'Asia/Pyongyang', 'Asia/Qatar', 'Asia/Qostanay', 'Asia/Qyzylorda', 'Asia/Rangoon', 'Asia/Riyadh', 'Asia/Saigon', 'Asia/Sakhalin', 'Asia/Samarkand', 'Asia/Seoul', 'Asia/Shanghai', 'Asia/Singapore', 'Asia/Srednekolymsk', 'Asia/Taipei', 'Asia/Tashkent', 'Asia/Tbilisi', 'Asia/Tehran', 'Asia/Tel_Aviv', 'Asia/Thimbu', 'Asia/Thimphu', 'Asia/Tokyo', 'Asia/Tomsk', 'Asia/Ujung_Pandang', 'Asia/Ulaanbaatar', 'Asia/Ulan_Bator', 'Asia/Urumqi', 'Asia/Ust-Nera', 'Asia/Vientiane', 'Asia/Vladivostok', 'Asia/Yakutsk', 'Asia/Yangon', 'Asia/Yekaterinburg', 'Asia/Yerevan', 'Atlantic/Azores', 'Atlantic/Bermuda', 'Atlantic/Canary', 'Atlantic/Cape_Verde', 'Atlantic/Faeroe', 'Atlantic/Faroe', 'Atlantic/Jan_Mayen', 'Atlantic/Madeira', 'Atlantic/Reykjavik', 'Atlantic/South_Georgia', 'Atlantic/St_Helena', 'Atlantic/Stanley', 'Australia/ACT', 'Australia/Adelaide', 'Australia/Brisbane', 'Australia/Broken_Hill', 'Australia/Canberra', 'Australia/Currie', 'Australia/Darwin', 'Australia/Eucla', 'Australia/Hobart', 'Australia/LHI', 'Australia/Lindeman', 'Australia/Lord_Howe', 'Australia/Melbourne', 'Australia/NSW', 'Australia/North', 'Australia/Perth', 'Australia/Queensland', 'Australia/South', 'Australia/Sydney', 'Australia/Tasmania', 'Australia/Victoria', 'Australia/West', 'Australia/Yancowinna', 'Brazil/Acre', 'Brazil/DeNoronha', 'Brazil/East', 'Brazil/West', 'CET', 'CST6CDT', 'Canada/Atlantic', 'Canada/Central', 'Canada/Eastern', 'Canada/Mountain', 'Canada/Newfoundland', 'Canada/Pacific', 'Canada/Saskatchewan', 'Canada/Yukon', 'Chile/Continental', 'Chile/EasterIsland', 'Cuba', 'EET', 'EST5EDT', 'Egypt', 'Eire', 'Etc/GMT', 'Etc/GMT+0', 'Etc/GMT+1', 'Etc/GMT+10', 'Etc/GMT+11', 'Etc/GMT+12', 'Etc/GMT+2', 'Etc/GMT+3', 'Etc/GMT+4', 'Etc/GMT+5', 'Etc/GMT+6', 'Etc/GMT+7', 'Etc/GMT+8', 'Etc/GMT+9', 'Etc/GMT-0', 'Etc/GMT-1', 'Etc/GMT-10', 'Etc/GMT-11', 'Etc/GMT-12', 'Etc/GMT-13', 'Etc/GMT-14', 'Etc/GMT-2', 'Etc/GMT-3', 'Etc/GMT-4', 'Etc/GMT-5', 'Etc/GMT-6', 'Etc/GMT-7', 'Etc/GMT-8', 'Etc/GMT-9', 'Etc/GMT0', 'Etc/Greenwich', 'Etc/UCT', 'Etc/UTC', 'Etc/Universal', 'Etc/Zulu', 'Europe/Amsterdam', 'Europe/Andorra', 'Europe/Astrakhan', 'Europe/Athens', 'Europe/Belfast', 'Europe/Belgrade', 'Europe/Berlin', 'Europe/Bratislava', 'Europe/Brussels', 'Europe/Bucharest', 'Europe/Budapest', 'Europe/Busingen', 'Europe/Chisinau', 'Europe/Copenhagen', 'Europe/Dublin', 'Europe/Gibraltar', 'Europe/Guernsey', 'Europe/Helsinki', 'Europe/Isle_of_Man', 'Europe/Istanbul', 'Europe/Jersey', 'Europe/Kaliningrad', 'Europe/Kiev', 'Europe/Kirov', 'Europe/Lisbon', 'Europe/Ljubljana', 'Europe/London', 'Europe/Luxembourg', 'Europe/Madrid', 'Europe/Malta', 'Europe/Mariehamn', 'Europe/Minsk', 'Europe/Monaco', 'Europe/Moscow', 'Europe/Nicosia', 'Europe/Oslo', 'Europe/Paris', 'Europe/Podgorica', 'Europe/Prague', 'Europe/Riga', 'Europe/Rome', 'Europe/Samara', 'Europe/San_Marino', 'Europe/Sarajevo', 'Europe/Saratov', 'Europe/Simferopol', 'Europe/Skopje', 'Europe/Sofia', 'Europe/Stockholm', 'Europe/Tallinn', 'Europe/Tirane', 'Europe/Tiraspol', 'Europe/Ulyanovsk', 'Europe/Uzhgorod', 'Europe/Vaduz', 'Europe/Vatican', 'Europe/Vienna', 'Europe/Vilnius', 'Europe/Volgograd', 'Europe/Warsaw', 'Europe/Zagreb', 'Europe/Zaporozhye', 'Europe/Zurich', 'GB', 'GB-Eire', 'GMT', 'GMT0', 'Greenwich', 'Hongkong', 'Iceland', 'Indian/Antananarivo', 'Indian/Chagos', 'Indian/Christmas', 'Indian/Cocos', 'Indian/Comoro', 'Indian/Kerguelen', 'Indian/Mahe', 'Indian/Maldives', 'Indian/Mauritius', 'Indian/Mayotte', 'Indian/Reunion', 'Iran', 'Israel', 'Jamaica', 'Japan', 'Kwajalein', 'Libya', 'MET', 'MST7MDT', 'Mexico/BajaNorte', 'Mexico/BajaSur', 'Mexico/General', 'NZ', 'NZ-CHAT', 'Navajo', 'PRC', 'PST8PDT', 'Pacific/Apia', 'Pacific/Auckland', 'Pacific/Bougainville', 'Pacific/Chatham', 'Pacific/Chuuk', 'Pacific/Easter', 'Pacific/Efate', 'Pacific/Enderbury', 'Pacific/Fakaofo', 'Pacific/Fiji', 'Pacific/Funafuti', 'Pacific/Galapagos', 'Pacific/Gambier', 'Pacific/Guadalcanal', 'Pacific/Guam', 'Pacific/Honolulu', 'Pacific/Johnston', 'Pacific/Kiritimati', 'Pacific/Kosrae', 'Pacific/Kwajalein', 'Pacific/Majuro', 'Pacific/Marquesas', 'Pacific/Midway', 'Pacific/Nauru', 'Pacific/Niue', 'Pacific/Norfolk', 'Pacific/Noumea', 'Pacific/Pago_Pago', 'Pacific/Palau', 'Pacific/Pitcairn', 'Pacific/Pohnpei', 'Pacific/Ponape', 'Pacific/Port_Moresby', 'Pacific/Rarotonga', 'Pacific/Saipan', 'Pacific/Samoa', 'Pacific/Tahiti', 'Pacific/Tarawa', 'Pacific/Tongatapu', 'Pacific/Truk', 'Pacific/Wake', 'Pacific/Wallis', 'Pacific/Yap', 'Poland', 'Portugal', 'ROK', 'Singapore', 'SystemV/AST4', 'SystemV/AST4ADT', 'SystemV/CST6', 'SystemV/CST6CDT', 'SystemV/EST5', 'SystemV/EST5EDT', 'SystemV/HST10', 'SystemV/MST7', 'SystemV/MST7MDT', 'SystemV/PST8', 'SystemV/PST8PDT', 'SystemV/YST9', 'SystemV/YST9YDT', 'Turkey', 'UCT', 'US/Alaska', 'US/Aleutian', 'US/Arizona', 'US/Central', 'US/East-Indiana', 'US/Eastern', 'US/Hawaii', 'US/Indiana-Starke', 'US/Michigan', 'US/Mountain', 'US/Pacific', 'US/Pacific-New', 'US/Samoa', 'UTC', 'Universal', 'W-SU', 'WET', 'Zulu', 'EST', 'HST', 'MST', 'ACT', 'AET', 'AGT', 'ART', 'AST', 'BET', 'BST', 'CAT', 'CNT', 'CST', 'CTT', 'EAT', 'ECT', 'IET', 'IST', 'JST', 'MIT', 'NET', 'NST', 'PLT', 'PNT', 'PRT', 'PST', 'SST', 'VST']","[{'comment': 'You can introduce the JavaScript library like moment-timezone (https://www.npmjs.com/package/moment-timezone) or `timezone` (https://www.npmjs.com/package/timezone). Writing these codes to `util` is not a good job', 'commenter': 'chengshiwen'}, {'comment': 'Done, import `moment-timezone`', 'commenter': 'ruanwenjun'}]"
5572,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/TaskInstanceCacheManagerImpl.java,"@@ -47,6 +58,33 @@
     @Autowired
     private ProcessService processService;
 
+    @PostConstruct
+    public void init() {
+        super.setName(""TaskInstanceCacheRefreshThread"");
+        super.start();
+    }
+
+    /**
+     * issue#5539 add thread to fetch task state from database in a fixed rate
+     */
+    @Override
+    public void run() {
+        while (Stopper.isRunning()) {","[{'comment': 'You should better not implement like this, if you want to close, you can only change the Stop, but Stop is used in many other places.', 'commenter': 'ruanwenjun'}]"
5572,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/TaskInstanceCacheManagerImpl.java,"@@ -47,6 +58,33 @@
     @Autowired
     private ProcessService processService;
 
+    @PostConstruct
+    public void init() {
+        super.setName(""TaskInstanceCacheRefreshThread"");
+        super.start();
+    }
+
+    /**
+     * issue#5539 add thread to fetch task state from database in a fixed rate
+     */
+    @Override
+    public void run() {
+        while (Stopper.isRunning()) {
+            try {
+                for (Entry<Integer, TaskInstance> taskInstanceEntry : taskInstanceCache.entrySet()) {
+                    TaskInstance taskInstance = processService.findTaskInstanceById(taskInstanceEntry.getKey());
+                    if (null != taskInstance && taskInstance.getState() == ExecutionStatus.NEED_FAULT_TOLERANCE) {
+                        logger.debug(""task {} need fault tolerance, update instance cache"", taskInstance.getId());
+                        taskInstanceCache.put(taskInstanceEntry.getKey(), taskInstance);
+                    }
+                }
+                Thread.sleep(CACHE_REFRESH_TIME_MILLIS);","[{'comment': 'You can use Timer to implement, rather than while(true) sleep', 'commenter': 'ruanwenjun'}]"
5572,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterTaskExecThread.java,"@@ -149,7 +143,10 @@ public Boolean waitTaskQuit() {
                     this.checkTimeoutFlag = !alertTimeout();
                 }
                 // updateProcessInstance task instance
-                taskInstance = processService.findTaskInstanceById(taskInstance.getId());
+                //taskInstance = processService.findTaskInstanceById(taskInstance.getId());","[{'comment': 'Remove the unused code.', 'commenter': 'ruanwenjun'}]"
5572,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/TaskInstanceCacheManagerImpl.java,"@@ -47,6 +58,33 @@
     @Autowired
     private ProcessService processService;
 
+    @PostConstruct
+    public void init() {
+        super.setName(""TaskInstanceCacheRefreshThread"");
+        super.start();
+    }
+
+    /**
+     * issue#5539 add thread to fetch task state from database in a fixed rate
+     */
+    @Override
+    public void run() {
+        while (Stopper.isRunning()) {
+            try {
+                for (Entry<Integer, TaskInstance> taskInstanceEntry : taskInstanceCache.entrySet()) {
+                    TaskInstance taskInstance = processService.findTaskInstanceById(taskInstanceEntry.getKey());
+                    if (null != taskInstance && taskInstance.getState() == ExecutionStatus.NEED_FAULT_TOLERANCE) {
+                        logger.debug(""task {} need fault tolerance, update instance cache"", taskInstance.getId());
+                        taskInstanceCache.put(taskInstanceEntry.getKey(), taskInstance);","[{'comment': 'You need to consider the concurrency modification. For example, if there is a thread in `MasterTaskExecThread` remove the instance at the same time, these may cause a memory leak. ', 'commenter': 'ruanwenjun'}, {'comment': 'Hi, @ruanwenjun I don\'t quite get the situation.\r\nAssume that in one loop, we are checking the task instance, and at this time, `MasterTaskExecThread` remove it. At this point, \'remove\' may mean two level, first is database remove, and we will get a null taskInstance. Second is cache remove, which means taskInstance is finished state. In both level, the \'if\' condition is not satisfied.\r\nOr another situation, one task is removed outside the entryset loop, then the task will not enter loop.\r\nI wrote a demo for testing , listed below. In timer thread, the sleep simulate a time wasting opration, and another thread remove the entry while timer thread is doing the opration.\r\n```\r\nimport java.util.Map;\r\nimport java.util.Timer;\r\nimport java.util.TimerTask;\r\nimport java.util.concurrent.ConcurrentHashMap;\r\n\r\npublic class ConcurrentHashMapRemoveIteratorTest {\r\n\r\n    private static ConcurrentHashMap<String, String> map = new ConcurrentHashMap<>();\r\n\r\n    public static void main(String[] args) {\r\n        /*for (int i = 0; i < 10; i++) {\r\n            map.put(i + "","", i + """");\r\n        }*/\r\n        map.put(10 + "","", 10 + """");\r\n\r\n        new Timer().scheduleAtFixedRate(\r\n                new TimerTask() {\r\n                    @Override\r\n                    public void run() {\r\n                        System.out.println(""new loop"");\r\n                        for (Map.Entry<String, String> entry : map.entrySet()) {\r\n                            System.out.println(""begin"" + entry.getKey() + entry.getValue());\r\n                            try {\r\n                                System.out.println(""sleeping"");\r\n                                Thread.sleep(5000);\r\n                            } catch (InterruptedException e) {\r\n                                e.printStackTrace();\r\n                            }\r\n                            System.out.println(""end"" + entry.getKey() + entry.getValue());\r\n                        }\r\n                        System.out.println(""new loop end"");\r\n                        System.out.println();\r\n\r\n                    }\r\n                }, 1000, 10000\r\n        );\r\n\r\n        new Thread(() -> {\r\n            try {\r\n                Thread.sleep(12000);\r\n            } catch (InterruptedException e) {\r\n                e.printStackTrace();\r\n            }\r\n            map.remove(10 + "","");\r\n            //map.put(10 + "","",""?"");\r\n            System.out.println(""removed!"");\r\n\r\n        }).start();\r\n    }\r\n}\r\n\r\n```\r\n\r\nThe output is \r\n```\r\nnew loop\r\nbegin10,10\r\nsleeping\r\nend10,10\r\nnew loop end\r\n\r\nnew loop\r\nbegin10,10\r\nsleeping\r\nremoved!\r\nend10,10\r\nnew loop end\r\n\r\nnew loop\r\nnew loop end\r\n```\r\n\r\nMaybe there are something wrong in my situation. Can you point out? Thanks.', 'commenter': 'blackberrier'}, {'comment': '@blackberrier\r\nThis is not an atomic operation.\r\n![image](https://user-images.githubusercontent.com/22415594/120464902-05a14100-c3d0-11eb-8329-ab4d6be3198e.png)\r\nWhen you remove the task in MasterTaskExecThread, but then at the same time you query from database and add the task to cache.\r\nRight?\r\n', 'commenter': 'ruanwenjun'}, {'comment': ""@ruanwenjun \r\nI know what's wrong. I though NEED_FAULT_TOLERANCE  tasks will not be remove in MasterExecThread. After I check, taskInstance.getState().typeIsFinished() include FAILURE NEED_FAULT_TOLERANCE. So you are right."", 'commenter': 'blackberrier'}, {'comment': '@blackberrier The real process should be that the task might be removed from cache first, then add to cache again, and then it will always exist in cache, this cause memory leak 😄 ', 'commenter': 'ruanwenjun'}]"
5572,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/TaskInstanceCacheManagerImpl.java,"@@ -114,6 +143,23 @@ public void cacheTaskInstance(TaskExecuteResponseCommand taskExecuteResponseComm
      */
     @Override
     public void removeByTaskInstanceId(Integer taskInstanceId) {
-        taskInstanceCache.remove(taskInstanceId);
+        synchronized (lock) {
+            taskInstanceCache.remove(taskInstanceId);
+        }
+    }
+
+    class RefreshTaskInstanceTimerTask extends TimerTask {
+        @Override
+        public void run() {
+            synchronized (lock) {","[{'comment': 'I think you can remove lock, use `computeIfPresent` if present to update the status', 'commenter': 'ruanwenjun'}, {'comment': 'cool', 'commenter': 'blackberrier'}]"
5572,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/TaskInstanceCacheManagerImpl.java,"@@ -57,7 +86,7 @@
     @Override
     public TaskInstance getByTaskInstanceId(Integer taskInstanceId) {
         TaskInstance taskInstance = taskInstanceCache.get(taskInstanceId);","[{'comment': 'It is better to use `computeIfAbsent` here.', 'commenter': 'ruanwenjun'}, {'comment': ""I put database access out of `computeIfAbsent`'s `Function` class `apply` method, is this ok? "", 'commenter': 'blackberrier'}, {'comment': '@blackberrier You can change the entire method to \r\n```\r\nreturn taskInstanceCache.computeIfAbsent(taskInstanceId, k -> processService.findTaskInstanceById(k));\r\n```\r\nAnd you can add some ut.', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun \r\nI think the database may waste time or something, and thus block other thread. So I take the  `processService.findTaskInstanceById(k)` out\r\n', 'commenter': 'blackberrier'}, {'comment': '@blackberrier I mean you can change this method to \r\n```\r\npublic TaskInstance getByTaskInstanceId(Integer taskInstanceId) {\r\nreturn taskInstanceCache.computeIfAbsent(taskInstanceId, k -> processService.findTaskInstanceById(k));\r\n}\r\n```\r\nThis is an atomic operation.', 'commenter': 'ruanwenjun'}, {'comment': 'I know your meaning. I have checked the comment of the `computeIfAbsent`, it says as follows. So I wonder if the database access operation should take out.\r\n\r\n![1622725677097](https://user-images.githubusercontent.com/6926304/120649848-c8ac7b80-c4af-11eb-9513-7805180fb339.jpg)\r\n', 'commenter': 'blackberrier'}, {'comment': '@blackberrier \r\nIf there are two threads execute `getByTaskInstanceId` at the same time, we just want to query from database once, right? The block will only happen on the two thread update on the same key, and the key is not exist, this is expected. \r\n\r\nAnd you should realize that the below way is not an atomic operation, in some situation, it might cause problem.\r\n```java\r\nTaskInstance taskInstance = taskInstanceCache.get(taskInstanceId);\r\nif (taskInstance == null){\r\n    taskInstance = processService.findTaskInstanceById(taskInstanceId);\r\n    taskInstanceCache.put(taskInstanceId,taskInstance);\r\n}\r\nreturn taskInstance;\r\n```', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun \r\nI think the block may happen on two thread on two key, and the two key share the same hashcode, which means they are on the same Linkedlist or Red-black tree, and in `computeIfAbsent` synchronized lock on the head node. \r\nIf we write like this,\r\n```\r\ntaskInstanceCache.computeIfAbsent(taskInstanceId, k -> processService.findTaskInstanceById(k));\r\n```\r\nand if the first key access database and wasting time , then the second key have to wait.\r\n\r\nIf we take database access out, like\r\n```\r\ntaskInstance = processService.findTaskInstanceById(taskInstanceId);\r\nTaskInstance finalTaskInstance = taskInstance;\r\ntaskInstanceCache.computeIfAbsent(taskInstanceId, k -> finalTaskInstance);\r\n```\r\nthe second key need not wait while the first key is accessing database.\r\n\r\nI wonder if my thought is reasonable.', 'commenter': 'blackberrier'}, {'comment': '@blackberrier \r\n\r\n> the block may happen on two thread on two key, and the two key share the same hashcode\r\n\r\nYes, but we can avoid the 1 step.\r\n```\r\n1. taskInstance = processService.findTaskInstanceById(taskInstanceId);\r\n2. TaskInstance finalTaskInstance = taskInstance;\r\n3. taskInstanceCache.computeIfAbsent(taskInstanceId, k -> finalTaskInstance);\r\n```', 'commenter': 'ruanwenjun'}, {'comment': ""@ruanwenjun \r\nI can't quite understand.\r\n```\r\n  public TaskInstance getByTaskInstanceId(Integer taskInstanceId) {\r\n        TaskInstance taskInstance = taskInstanceCache.get(taskInstanceId);\r\n        if (taskInstance == null) {\r\n            1. taskInstance = processService.findTaskInstanceById(taskInstanceId);\r\n            2. TaskInstance finalTaskInstance = taskInstance;\r\n            3. taskInstanceCache.computeIfAbsent(taskInstanceId, k -> finalTaskInstance);\r\n        }\r\n        return taskInstance;\r\n    }\r\n```\r\nIf we remove the 1 step, then where can we get the taskInstance? "", 'commenter': 'blackberrier'}, {'comment': ""@blackberrier I mean you can use below code\r\n```\r\npublic TaskInstance getByTaskInstanceId(Integer taskInstanceId) {\r\nreturn taskInstanceCache.computeIfAbsent(taskInstanceId, k -> processService.findTaskInstanceById(k));\r\n}\r\n```\r\nThe cache is used to reduce database pressure, in your plan, if there are multiple threads query the same taskInstance at the same time, they will all query from database.\r\nYour consideration is that when conflicts occur, multiple thread query will block. I think if conflicts occur, if we don't want to be blocked, we should find a better hash method to reduce conflicts. \r\n\r\nIn additional, we can use one line of code to achieve, why use more complex code?"", 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun \r\nok, I have commit latest code', 'commenter': 'blackberrier'}]"
5572,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/master/cache/impl/TaskInstanceCacheManagerImplTest.java,"@@ -0,0 +1,160 @@
+package org.apache.dolphinscheduler.server.master.cache.impl;","[{'comment': 'You need to add Apache license header here, you can find the license header in other file.\r\nAnd when you add an ut file, you need to add the test class in root pom.xml like below:\r\n```java\r\n<include>**/api/service/MonitorServiceTest.java</include>\r\n<include>**/api/service/ProcessDefinitionServiceTest.java</include>\r\n<include>**/api/service/ProcessTaskRelationServiceImplTest.java</include>\r\n<include>**/api/service/TaskDefinitionServiceImplTest.java</include>\r\n```\r\n', 'commenter': 'ruanwenjun'}, {'comment': ""ok, I've added."", 'commenter': 'blackberrier'}]"
5591,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/RegexUtils.java,"@@ -32,14 +32,15 @@
 
     private static final String LINUX_USERNAME_PATTERN = ""[a-z_][a-z\\d_]{0,30}"";
 
+    private static final String WINDOWS_USERNAME_PATTERN = ""[a-z_][a-z\\d_]{0,30}"";","[{'comment': '`WINDOWS_USERNAME_PATTERN` is just same with `LINUX_USERNAME_PATTERN`, and not for Windows', 'commenter': 'chengshiwen'}]"
5591,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TenantServiceImpl.java,"@@ -95,6 +95,11 @@
             return result;
         }
 
+        if (!RegexUtils.isValidWindowUserName(tenantCode)) {","[{'comment': 'This logic is not correct, because the username that does not satisfy Linux has been returned, and it is no longer possible to check if it satisfies the username of Windows', 'commenter': 'chengshiwen'}]"
5602,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessService.java,"@@ -2240,6 +2303,7 @@ public int saveProcessDefinition(User operator, Project project, String name, St
     /**
      * save processDefinition
      */
+    @Deprecated","[{'comment': 'Is this method unnecessary?', 'commenter': 'wen-hemin'}, {'comment': 'If we upgrate new api, i think this can be deleted', 'commenter': 'brave-lee'}]"
5606,sql/upgrade/1.4.0_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -294,7 +294,7 @@ BEGIN
           WHERE relname='t_ds_datasource'
                             AND indexrelname ='t_ds_datasource_name_UN')
       THEN
-         ALTER TABLE t_ds_process_definition ADD CONSTRAINT t_ds_datasource_name_UN UNIQUE (name, type);
+         ALTER TABLE t_ds_alertgroup ADD CONSTRAINT t_ds_alertgroup_name_UN UNIQUE (name, type);","[{'comment': 'The table `t_ds_process_definition` should change to `t_ds_datasource`.', 'commenter': 'ruanwenjun'}]"
5611,sql/upgrade/1.4.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -168,6 +268,199 @@ delimiter ;
 CALL ct_dolphin_T_t_ds_process_definition_version;
 DROP PROCEDURE ct_dolphin_T_t_ds_process_definition_version;
 
+-- uc_dolphin_T_t_ds_project_instance_A_add_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_project_instance_A_add_code;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_project_instance_A_add_code()
+   BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_project'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='code')
+   THEN
+         ALTER TABLE t_ds_project ADD `code` bigint(20) NOT NULL COMMENT 'encoding';
+       END IF;
+ END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_project_instance_A_add_code();
+DROP PROCEDURE uc_dolphin_T_t_ds_project_instance_A_add_code;
+
+-- uc_dolphin_T_t_ds_process_definition_A_add_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_process_definition_A_add_code;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_process_definition_A_add_code()
+   BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_process_definition'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='code')
+   THEN
+         ALTER TABLE t_ds_process_definition ADD `code` bigint(20) NOT NULL COMMENT 'encoding';
+       END IF;
+ END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_process_definition_A_add_code();
+DROP PROCEDURE uc_dolphin_T_t_ds_process_definition_A_add_code;
+
+-- uc_dolphin_T_t_ds_process_definition_A_add_project_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_process_definition_A_add_project_code;","[{'comment': 'I think there should be remove project_id from t_ds_process_definition', 'commenter': 'brave-lee'}, {'comment': 'Solved it!', 'commenter': 'echohlne'}]"
5611,sql/upgrade/1.4.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -168,6 +268,199 @@ delimiter ;
 CALL ct_dolphin_T_t_ds_process_definition_version;
 DROP PROCEDURE ct_dolphin_T_t_ds_process_definition_version;
 
+-- uc_dolphin_T_t_ds_project_instance_A_add_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_project_instance_A_add_code;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_project_instance_A_add_code()
+   BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_project'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='code')
+   THEN
+         ALTER TABLE t_ds_project ADD `code` bigint(20) NOT NULL COMMENT 'encoding';
+       END IF;
+ END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_project_instance_A_add_code();
+DROP PROCEDURE uc_dolphin_T_t_ds_project_instance_A_add_code;
+
+-- uc_dolphin_T_t_ds_process_definition_A_add_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_process_definition_A_add_code;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_process_definition_A_add_code()
+   BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_process_definition'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='code')
+   THEN
+         ALTER TABLE t_ds_process_definition ADD `code` bigint(20) NOT NULL COMMENT 'encoding';
+       END IF;
+ END;","[{'comment': 'Please add warning_group_id to t_ds_process_definition ', 'commenter': 'brave-lee'}, {'comment': ' @JinyLeeChina https://github.com/apache/dolphinscheduler/blob/0d303a804da0bd663162b2616ed01e8c8d731c6f/sql/upgrade/1.4.0_schema/mysql/dolphinscheduler_ddl.sql#L208  warning_group_id has been added before.', 'commenter': 'echohlne'}, {'comment': 'OK', 'commenter': 'brave-lee'}]"
5611,sql/upgrade/1.4.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -168,6 +268,199 @@ delimiter ;
 CALL ct_dolphin_T_t_ds_process_definition_version;
 DROP PROCEDURE ct_dolphin_T_t_ds_process_definition_version;
 
+-- uc_dolphin_T_t_ds_project_instance_A_add_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_project_instance_A_add_code;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_project_instance_A_add_code()
+   BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_project'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='code')
+   THEN
+         ALTER TABLE t_ds_project ADD `code` bigint(20) NOT NULL COMMENT 'encoding';
+       END IF;
+ END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_project_instance_A_add_code();
+DROP PROCEDURE uc_dolphin_T_t_ds_project_instance_A_add_code;
+
+-- uc_dolphin_T_t_ds_process_definition_A_add_code
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_process_definition_A_add_code;","[{'comment': 'Please update UNIQUE KEY of t_ds_process_definition ', 'commenter': 'brave-lee'}, {'comment': 'thanks @JinyLeeChina , solved it.', 'commenter': 'echohlne'}]"
5611,sql/dolphinscheduler_postgre.sql,"@@ -303,7 +303,7 @@ CREATE TABLE t_ds_process_definition (
   tenant_id int DEFAULT '-1' ,
   create_time timestamp DEFAULT NULL ,
   update_time timestamp DEFAULT NULL ,
-  PRIMARY KEY (id) ,
+  PRIMARY KEY (id, code) ,","[{'comment': 'Is it more appropriate to add a unique index to ""code"".', 'commenter': 'wen-hemin'}, {'comment': ""Thanks for your review.\r\nI made this change by folllowing the same table schema in mysql:https://github.com/apache/dolphinscheduler/blob/5d3b75a0a32da02ad562386a8253727ab0dc6b75/sql/dolphinscheduler_mysql.sql#L411  I've also update the sql upgrade script.\r\nI'm not sure what's the best way to do? 😭 "", 'commenter': 'echohlne'}, {'comment': 'Primary key remove ""code"".\r\nAdd a unique index to ""code"".', 'commenter': 'wen-hemin'}, {'comment': '@wen-hemin  thanks! done this:\r\nmysql:\r\n\r\n![image](https://user-images.githubusercontent.com/52202080/121639637-6c54e780-cabf-11eb-8af8-2abf611e40d7.png)\r\npostgresql:\r\n\r\n![image](https://user-images.githubusercontent.com/52202080/121639704-842c6b80-cabf-11eb-94c0-69f93b85c1bc.png)\r\n', 'commenter': 'echohlne'}, {'comment': 'It\'s the same as it is now.\r\n1.The primary key only keeps the ID.\r\n2.Add a unique index to ""code"", the purpose is to improve the query efficiency, and the uniqueness of the constraint ""code""\r\n@kyoty ', 'commenter': 'wen-hemin'}, {'comment': ""Thanks @wen-hemin \r\nyou mean **the primary key should be `id` instead of `(`id`,`code`)`?**\r\nIf so, the schema defined early by other developers in  `dolphinscheduler_mysql.sql`(https://github.com/apache/dolphinscheduler/blob/5d3b75a0a32da02ad562386a8253727ab0dc6b75/sql/dolphinscheduler_mysql.sql#L411) is wrong. Can you confirm this? I'm not familiar with the relevant background\r\n"", 'commenter': 'echohlne'}, {'comment': 'Yes, no problem. ""code"" adds a unique index.', 'commenter': 'wen-hemin'}, {'comment': 'Thanks @wen-hemin , I have resubmitted it, please review again.', 'commenter': 'echohlne'}]"
5628,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/udp/udp.vue,"@@ -202,38 +202,39 @@
        */
       reloadParam () {
         const dag = _.cloneDeep(this.store.state.dag)
-        let fixedParam = []
-        const tasks = this.store.state.dag.tasks
-        for (const task of tasks) {
-          const localParam = task.params ? task.params.localParams : []
-          localParam.forEach(l => {
-            if (!fixedParam.some(f => { return f.prop === l.prop })) {
-              fixedParam.push(Object.assign({
-                ifFixed: true
-              }, l))
-            }
-          })
-        }
+        // let fixedParam = []
+        // const tasks = this.store.state.dag.tasks
+        // for (const task of tasks) {
+        //   const localParam = task.params ? task.params.localParams : []
+        //   localParam.forEach(l => {
+        //     if (!fixedParam.some(f => { return f.prop === l.prop })) {
+        //       fixedParam.push(Object.assign({
+        //         ifFixed: true
+        //       }, l))
+        //     }
+        //   })
+        // }
 
         let globalParams = _.cloneDeep(dag.globalParams)
+        // globalParams = globalParams.map(g => {
+        //   if (fixedParam.some(f => { return g.prop === f.prop })) {
+        //     fixedParam = fixedParam.filter(f => { return g.prop !== f.prop })
+        //     return Object.assign(g, {
+        //       ifFixed: true
+        //     })
+        //   } else {
+        //     return g
+        //   }
+        // })
 
-        globalParams = globalParams.map(g => {
-          if (fixedParam.some(f => { return g.prop === f.prop })) {
-            fixedParam = fixedParam.filter(f => { return g.prop !== f.prop })
-            return Object.assign(g, {
-              ifFixed: true
-            })
-          } else {
-            return g
-          }
-        })
-        let udpList = [...fixedParam, ...globalParams].sort(s => {
-          if (s.ifFixed) {
-            return -1
-          } else {
-            return 1
-          }
-        })
+        // let udpList = [...globalParams].sort(s => {
+        //   if (s.ifFixed) {
+        //     return -1
+        //   } else {
+        //     return 1
+        //   }
+        // })","[{'comment': 'Please remove the comment code', 'commenter': 'zhuangchong'}]"
5630,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProjectServiceImpl.java,"@@ -268,28 +264,28 @@ public boolean hasProjectAndPerm(User loginUser, Project project, Map<String, Ob
      * updateProcessInstance project
      *
      * @param loginUser login user
-     * @param projectId project id
+     * @param projectCode project code
      * @param projectName project name
      * @param desc description
      * @param userName project owner
      * @return update result code
      */
     @Override
-    public Map<String, Object> update(User loginUser, Integer projectId, String projectName, String desc, String userName) {
+    public Map<String, Object> update(User loginUser, Long projectCode, String projectName, String desc, String userName) {
         Map<String, Object> result = new HashMap<>();
 
         Map<String, Object> descCheck = checkDesc(desc);
         if (descCheck.get(Constants.STATUS) != Status.SUCCESS) {
             return descCheck;
         }
 
-        Project project = projectMapper.selectById(projectId);
+        Project project = projectMapper.queryByCode(projectCode);
         boolean hasProjectAndPerm = hasProjectAndPerm(loginUser, project, result);
         if (!hasProjectAndPerm) {
             return result;
         }
         Project tempProject = projectMapper.queryByName(projectName);
-        if (tempProject != null && tempProject.getId() != projectId) {
+        if (tempProject != null && tempProject.getCode().equals(projectCode)) {","[{'comment': 'not equals', 'commenter': 'wen-hemin'}, {'comment': 'yes, there should be deleted', 'commenter': 'brave-lee'}]"
5630,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.xml,"@@ -29,7 +29,7 @@
         select
         <include refid=""baseSql""/>
         from t_ds_project
-        where code = #{code}
+        where code = #{projectCode}","[{'comment': ""The change of variable name is not seen in mapper class, \r\nAre you sure it doesn't need to be modified."", 'commenter': 'wen-hemin'}, {'comment': 'Project queryByCode(@Param(""projectCode"") Long projectCode);', 'commenter': 'brave-lee'}]"
5632,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/tasks/sql.vue,"@@ -43,6 +43,13 @@
         </div>
       </div>
     </m-list-box>
+    <m-list-box>
+        <div slot=""text""><strong class='requiredIcon'>*</strong>{{$t('Max Numbers Return')}}</div>
+        <div slot=""content"">
+          <el-input type=""input"" :disabled=""isDetails"" size=""medium"" v-model=""limit"" :placeholder=""$t('Max Numbers Return placeholder')"">
+          </el-input>
+        </div>
+    </m-list-box>","[{'comment': 'This limit number of rows only needs to be displayed in the query scenario, and it is recommended that the backend also set the initial value of limit at the same time', 'commenter': 'zhuangchong'}, {'comment': '@zhuangchong Thanks for youre review.\r\nSorry I forget to merge some code. I have updated by add a condition `<m-list-box v-show=""sqlType === \'0\'"">`', 'commenter': 'echohlne'}]"
5782,dolphinscheduler-dao/src/main/resources/datasource.properties,"@@ -14,18 +14,16 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-
 # postgresql
-spring.datasource.driver-class-name=org.postgresql.Driver
-spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
-spring.datasource.username=test
-spring.datasource.password=test
-
+#spring.datasource.driver-class-name=org.postgresql.Driver
+#spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
+#spring.datasource.username=test
+#spring.datasource.password=test
 # mysql
-#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
-#spring.datasource.url=jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8
-#spring.datasource.username=xxxx
-#spring.datasource.password=xxxx
+spring.datasource.driver-class-name=com.mysql.jdbc.Driver
+spring.datasource.url=jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8
+spring.datasource.username=root
+spring.datasource.password=123456","[{'comment': 'hi, thank you very much for your contribution, can you submit a related ISSUE and modify the remote branch？ it should be submitted to dev.\r\nIn addition, do not modify these configurations (you can modify them locally when you test and use them, but do not submit them to the upstream warehouse).', 'commenter': 'CalvinKirs'}, {'comment': '\r\n\r\nIssue has proposed that this modification should be submitted in 1.3.7\r\n', 'commenter': 'Zzm0809'}]"
5782,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -699,8 +699,10 @@ private Constants() {
     /**
      * application regex
      */
-    public static final String APPLICATION_REGEX = ""application_\\d+_\\d+"";
+    /* public static final String APPLICATION_REGEX = ""application_\\d+_\\d+""; */
+    public static final String APPLICATION_REGEX = ""http[s]?://([\\w-]+\\.*)+[\\w-]+(/[\\w-.*/?%&=]*)?:(\\d*)/(\\w*)/application[_]?\\d+[_]?\\d+"";","[{'comment': ""\r\n\r\n\r\nI think the regular expression cannot be modified in this way. The yarn application id matching will involve tasks submitted by calculation engines such as flink, hive, spark, etc., and the printed yarn application id log formats are different. The following is the yarn application id printed by flink submitted tasks. , The modified regularity cannot be matched\r\n```\r\nINFO  org.apache.flink.yarn.YarnClusterDescriptor                   - Found Web Interface xxxx of application 'application_1625147587008_396985'.\r\n\r\n```"", 'commenter': 'zhuangchong'}]"
5814,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/RegistryCenterUtils.java,"@@ -36,21 +36,14 @@
  * fixme Some of the information obtained in the api belongs to the unique information of zk.
  * I am not sure whether there is a good abstraction method. This is related to whether the specific plug-in is provided.
  */
-@Component
-public class RegistryMonitor {
+public class RegistryCenterUtils {
 
-    @Autowired
-    RegistryClient registryClient;
-
-    @PostConstruct
-    public void initRegistry() {
-        registryClient.init();
-    }
+    private static RegistryClient registryClient = RegistryClient.getInstance();
 
     /**
      * @return zookeeper info list
      */
-    public List<ZookeeperRecord> zookeeperInfoList() {
+    public static List<ZookeeperRecord> zookeeperInfoList() {","[{'comment': 'remove this method?', 'commenter': 'gabrywu'}, {'comment': 'After this method is confirmed, it may be deleted together with the frontend in the future.', 'commenter': 'wen-hemin'}]"
5814,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/RegistryCenterUtils.java,"@@ -106,11 +99,23 @@ public void initRegistry() {
         return list;
     }
 
-    public Map<String, String> getServerMaps(NodeType nodeType, boolean hostOnly) {
+    public static Map<String, String> getServerMaps(NodeType nodeType, boolean hostOnly) {
         return registryClient.getServerMaps(nodeType, hostOnly);
     }
 
-    public List<String> getServerNodeList(NodeType nodeType, boolean hostOnly) {
+    public static List<String> getServerNodeList(NodeType nodeType, boolean hostOnly) {
         return registryClient.getServerNodeList(nodeType, hostOnly);
     }
+
+    public static boolean isExisted(String key) {
+        return registryClient.isExisted(key);
+    }
+
+    public static List<String> getChildrenKeys(final String key) {","[{'comment': 'getChildrenKeys & isExistted & getValue is meaningless for RegistryCenterUtils, should use a meaningful method name', 'commenter': 'gabrywu'}, {'comment': 'Thx, I will fix', 'commenter': 'wen-hemin'}]"
5814,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -147,7 +137,7 @@ private boolean checkWorkerGroupNameExists(WorkerGroup workerGroup) {
         }
         // check zookeeper
         String workerGroupPath = Constants.REGISTRY_DOLPHINSCHEDULER_WORKERS + Constants.SLASH + workerGroup.getName();
-        return registryClient.isExisted(workerGroupPath);
+        return RegistryCenterUtils.isExisted(workerGroupPath);","[{'comment': 'use a meaningful method name', 'commenter': 'gabrywu'}, {'comment': 'Thx, I will fix', 'commenter': 'wen-hemin'}]"
5829,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/dag.vue,"@@ -893,4 +893,22 @@
   .operBtn {
     padding: 8px 6px;
   }
+
+  .el-drawer__body {
+    ::selection {
+      background: #409EFF;
+      color: white;
+    }
+
+    ::-moz-selection {","[{'comment': 'Please remove `::-moz-selection` and `::-webkit-selection`, `postcss-loader` and `autoprefixer` will add the prefixes automatically when building the ui', 'commenter': 'chengshiwen'}]"
5829,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/udp/udp.vue,"@@ -251,6 +251,19 @@
       max-height: 600px;
       overflow-y: scroll;
       padding:0 20px;
+
+      ::selection {
+        background: #409EFF ;
+        color: white;
+      }
+      ::-moz-selection {","[{'comment': 'Please remove `::-moz-selection` and `::-webkit-selection`', 'commenter': 'chengshiwen'}, {'comment': 'Thanks @chengshiwen, done.', 'commenter': 'echohlne'}]"
5846,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/FileUtils.java,"@@ -131,6 +131,27 @@ public static String getResourceViewSuffixs() {
         return PropertyUtils.getString(RESOURCE_VIEW_SUFFIXS, RESOURCE_VIEW_SUFFIXS_DEFAULT_VALUE);
     }
 
+    /**
+     * create directory if absent
+     *
+     * @param execLocalPath execute local path
+     * @throws IOException errors
+     */
+    public static void createWorkDirIfAbsent(String execLocalPath) throws IOException {","[{'comment': ""The method name does not match it's behavior."", 'commenter': 'Technoboy-'}]"
5868,dolphinscheduler-ui/src/js/module/i18n/locale/zh_CN.js,"@@ -420,7 +420,7 @@ export default {
   'Process instance details': '流程实例详情',
   'Create Resource': '创建资源',
   'User Center': '用户中心',
-  'Please enter method': '请输入方法',
+  AllStatus: '全部状态',","[{'comment': 'Missing single quote?', 'commenter': 'Technoboy-'}, {'comment': 'Thanks for your review, it seems the single quote is not required. Both the two kinds of writing exist in the project.', 'commenter': 'ruanwenjun'}, {'comment': 'How about keeping the same with others?', 'commenter': 'Technoboy-'}, {'comment': 'Good suggestion', 'commenter': 'ruanwenjun'}]"
5882,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AccessTokenController.java,"@@ -128,13 +128,13 @@ public Result queryAccessTokenList(@ApiIgnore @RequestAttribute(value = Constant
                                        @RequestParam(value = ""searchVal"", required = false) String searchVal,
                                        @RequestParam(""pageSize"") Integer pageSize) {
 
-        Map<String, Object> result = checkPageParams(pageNo, pageSize);
-        if (result.get(Constants.STATUS) != Status.SUCCESS) {
-            return returnDataListPaging(result);
+        Result result = checkPageParams(pageNo, pageSize);
+        if (!result.checkResult()) {
+            return error(result.getCode(),result.getMsg());","[{'comment': 'Return the result directly', 'commenter': 'zhuangchong'}]"
5882,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/AccessTokenService.java,"@@ -35,7 +36,7 @@
      * @param pageSize page size
      * @return token list for page number and page size
      */
-    Map<String, Object> queryAccessTokenList(User loginUser, String searchVal, Integer pageNo, Integer pageSize);
+    PageInfo queryAccessTokenList(User loginUser, String searchVal, Integer pageNo, Integer pageSize);","[{'comment': 'Other interfaces return Result type, please keep the same', 'commenter': 'zhuangchong'}]"
5890,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/os/OSUtilsTest.java,"@@ -37,39 +33,32 @@
 
     @Test
     public void memoryUsage() {
-        logger.info(""memoryUsage : {}"", OSUtils.memoryUsage());// 0.3361799418926239
+        double memoryUsage = OSUtils.memoryUsage();
+        logger.info(""memoryUsage : {}"", memoryUsage);
+        Assert.assertTrue(memoryUsage >= 0.0);
     }
 
     @Test
-    public void availablePhysicalMemorySize() {
-        logger.info(""availablePhysicalMemorySize : {}"", OSUtils.availablePhysicalMemorySize());
-        logger.info(""availablePhysicalMemorySize : {}"", OSUtils.totalMemorySize() / 10);
+    public void physicalMemorySize() {
+        double availablePhysicalMemorySize = OSUtils.availablePhysicalMemorySize();
+        double totalPhysicalMemorySize = OSUtils.totalPhysicalMemorySize();
+        logger.info(""availablePhysicalMemorySize : {}"", availablePhysicalMemorySize);
+        logger.info(""totalPhysicalMemorySize : {}"", totalPhysicalMemorySize);
+        Assert.assertTrue(availablePhysicalMemorySize >= 0.0);
+        Assert.assertTrue(totalPhysicalMemorySize >= 0.0);
     }
 
-
     @Test
     public void loadAverage() {","[{'comment': 'Test method should named testXXX().', 'commenter': 'Technoboy-'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
5890,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/os/OSUtilsTest.java,"@@ -37,39 +33,32 @@
 
     @Test
     public void memoryUsage() {
-        logger.info(""memoryUsage : {}"", OSUtils.memoryUsage());// 0.3361799418926239
+        double memoryUsage = OSUtils.memoryUsage();
+        logger.info(""memoryUsage : {}"", memoryUsage);
+        Assert.assertTrue(memoryUsage >= 0.0);
     }
 
     @Test
-    public void availablePhysicalMemorySize() {
-        logger.info(""availablePhysicalMemorySize : {}"", OSUtils.availablePhysicalMemorySize());
-        logger.info(""availablePhysicalMemorySize : {}"", OSUtils.totalMemorySize() / 10);
+    public void physicalMemorySize() {","[{'comment': 'Could you change the method to testPhysicalMemorySize()?', 'commenter': 'Technoboy-'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
5890,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/os/OSUtilsTest.java,"@@ -37,39 +33,32 @@
 
     @Test
     public void memoryUsage() {","[{'comment': 'Also here', 'commenter': 'Technoboy-'}, {'comment': 'Done', 'commenter': 'chengshiwen'}]"
5895,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/SchedulerServiceImpl.java,"@@ -415,15 +416,18 @@
      * @return schedule list page
      */
     @Override
-    public Map<String, Object> querySchedule(User loginUser, String projectName, Integer processDefineId, String searchVal, Integer pageNo, Integer pageSize) {
+    public Result querySchedule(User loginUser, String projectName, Integer processDefineId, String searchVal, Integer pageNo, Integer pageSize) {
 
-        HashMap<String, Object> result = new HashMap<>();
+        Result result = new Result();
 
         Project project = projectMapper.queryByName(projectName);
 
+        Map<String, Object> checkResult = new HashMap<>();
         // check project auth
-        boolean hasProjectAndPerm = projectService.hasProjectAndPerm(loginUser, project, result);
+        boolean hasProjectAndPerm = projectService.hasProjectAndPerm(loginUser, project, checkResult);
         if (!hasProjectAndPerm) {
+            Status status = (Status) checkResult.get(Constants.STATUS);
+            putMsg(result,status);","[{'comment': 'The exception information is not added to the Result.', 'commenter': 'zhuangchong'}, {'comment': ""ok,i'll fix it "", 'commenter': 'soreak'}]"
5912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -553,14 +555,21 @@ private int createCommand(CommandType commandType, int processDefineId,
                         }
                     }
                     if (!CollectionUtils.isEmpty(listDate)) {
-                        // loop by schedule date
-                        for (Date date : listDate) {
-                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(date));
-                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(date));
+
+                        int effectThreadsCount = expectedParallelismNumber == null ? 1 : Math.min(listDate.size(), expectedParallelismNumber);
+                        logger.info(""In parallel mode, current expectedParallelismNumber:{}"", expectedParallelismNumber);
+
+                        int average = listDate.size() / effectThreadsCount;
+                        int slice = listDate.size() % effectThreadsCount == 0 ? average : average + 1;
+
+                        Lists.partition(listDate, slice).stream().forEach(partition -> {
+                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(partition.get(0)));
+                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(partition.get(partition.size() - 1)));
                             command.setCommandParam(JSONUtils.toJsonString(cmdParam));
                             processService.createCommand(command);
-                        }
-                        return listDate.size();
+                        });
+
+                        return effectThreadsCount;","[{'comment': '@lenboo hi,PTAL,thx', 'commenter': 'CalvinKirs'}]"
5912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -553,14 +555,21 @@ private int createCommand(CommandType commandType, int processDefineId,
                         }
                     }
                     if (!CollectionUtils.isEmpty(listDate)) {
-                        // loop by schedule date
-                        for (Date date : listDate) {
-                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(date));
-                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(date));
+
+                        int effectThreadsCount = expectedParallelismNumber == null ? 1 : Math.min(listDate.size(), expectedParallelismNumber);
+                        logger.info(""In parallel mode, current expectedParallelismNumber:{}"", expectedParallelismNumber);
+
+                        int average = listDate.size() / effectThreadsCount;
+                        int slice = listDate.size() % effectThreadsCount == 0 ? average : average + 1;
+
+                        Lists.partition(listDate, slice).stream().forEach(partition -> {
+                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(partition.get(0)));
+                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(partition.get(partition.size() - 1)));","[{'comment': 'With the current change, I think the last mission cannot be executed.\r\n\r\n```\r\n  List<Schedule> schedules = processService.queryReleaseSchedulerListByProcessDefinitionId(processDefinitionId);\r\n        List<Date> listDate = Lists.newLinkedList();\r\n        if (!CollectionUtils.isEmpty(schedules)) {\r\n            for (Schedule schedule : schedules) {\r\n                listDate.addAll(CronUtils.getSelfFireDateList(startDate, endDate, schedule.getCrontab()));\r\n            }\r\n        }\r\n        // get first fire date\r\n        Iterator<Date> iterator = null;\r\n        Date scheduleDate;\r\n        if (!CollectionUtils.isEmpty(listDate)) {\r\n            iterator = listDate.iterator();\r\n            scheduleDate = iterator.next();\r\n            processInstance.setScheduleTime(scheduleDate);\r\n            processService.updateProcessInstance(processInstance);\r\n        } else {\r\n            scheduleDate = processInstance.getScheduleTime();\r\n            if (scheduleDate == null) {\r\n                scheduleDate = startDate;\r\n            }\r\n        }\r\n```\r\n[executeComplementProcess](https://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterExecThread.java)\r\n```\r\n  public static List<Date> getSelfFireDateList(Date startTime, Date endTime, CronExpression cronExpression) {\r\n    List<Date> dateList = new ArrayList<>();\r\n\r\n    while (Stopper.isRunning()) {\r\n      startTime = cronExpression.getNextValidTimeAfter(startTime);\r\n      if (startTime.after(endTime) || startTime.equals(endTime)) {\r\n        break;\r\n      }\r\n      dateList.add(startTime);\r\n    }\r\n\r\n    return dateList;\r\n  }\r\n```\r\n[getSelfFireDateList](https://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/quartz/cron/CronUtils.java)\r\n\r\nI think the condition judgment of startTime.equals(endTime) should be removed in the getSelfFireDateList method\r\n\r\n\r\n', 'commenter': 'zhuangchong'}, {'comment': 'Thanks @zhuangchong.\r\nIn fact, when startTime is same as endTime, the listDate would be empty, and then the code would run into the  [ExecutorServiceImpl.java#L567](https://github.com/apache/dolphinscheduler/blob/f5675170311ccc3cc8e6f88e74c956220297e8cd/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java#L567) like below:\r\n```java\r\nelse {\r\n                        // loop by day\r\n                        int runCunt = 0;\r\n                        while (!start.after(end)) {\r\n                            runCunt += 1;\r\n                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(start));\r\n                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(start));\r\n                            command.setCommandParam(JSONUtils.toJsonString(cmdParam));\r\n                            processService.createCommand(command);\r\n                            start = DateUtils.getSomeDay(start, 1);\r\n                        }\r\n                        return runCunt;\r\n                    }\r\n```\r\nthe runCunt would be 1.\r\nThe part I updated will not affect this case.', 'commenter': 'echohlne'}, {'comment': '@kyoty \r\n\r\nI feel that we are not talking about a part.\r\n\r\nWhat you describe is the judgment operation of the first complement generation task\r\n\r\nWhat I am expressing is the execution operation after generating the complement task,\r\nIn the complement parallel task, multiple serial tasks are generated according to the custom parallelism. Each serial task has a start time and an end time (the start time of the nth time). In this serial task, when the loop is the nth time If the start time is equal to the end time, it will not be executed this time.\r\n\r\nMy understanding may be wrong ...', 'commenter': 'zhuangchong'}, {'comment': ""@zhuangchong Sorry for the delay.\r\n\r\nThis part of the code is a little Confusing.\r\n\r\nFirst of all, we must know that: **`CronUtils#getSelfFireDateList` will only execute with the time points that satisfy cronExpression in the open time interval (startTime, endTime) .**\r\n\r\nThen there are currently two complements, all needs to be taken into consideration:\r\n\r\n1. Serial complement, `CronUtils#getSelfFireDateList` will only be executed once in `MasterExecThread#executeComplementProcess`.\r\n\r\n2. Parallel complement, `CronUtils#getSelfFireDateList` will be executed twice: `ExecutorServiceImpl#createCommand` and `MasterExecThread#executeComplementProcess`, **executed twice will cause the `startTime` and `endTime` of each prepared-execute timeInterval in custom-parallel mode to be discarded**.\r\n\r\n**I dare not modify `CronUtils.getSelfFireDateList`, because modifying it will also affect the serial complement case.**\r\n\r\n **In order to be compatible with all scenarios at the same time, I modified the time range split in parallel mode, such as the prepared-execute timeInterval is [A,B], but we would split it into  [A-1, B+1].  In this way, after executing `CronUtils.getSelfFireDateList` twice, we would finally got the correct interval.**\r\n\r\nNow I've implemented it as I described above, and the manual test works well.\r\n\r\nDo you have any idea?"", 'commenter': 'echohlne'}]"
5919,dolphinscheduler-service/src/test/java/org/apache/dolphinscheduler/service/zk/ZookeeperCachedOperatorTest.java,"@@ -0,0 +1,48 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.zk;
+
+import org.apache.curator.framework.CuratorFramework;
+import org.apache.curator.framework.recipes.cache.TreeCacheEvent;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+public class ZookeeperCachedOperatorTest {
+
+    private ZookeeperCachedOperator zookeeperCachedOperator = new ZookeeperCachedOperator();
+
+    @Test
+    public void testRegisterListener() {
+        AbstractListener abstractListener1 = new AbstractListener(1) {
+            @Override
+            protected void dataChanged(CuratorFramework client, TreeCacheEvent event, String path) {
+                // ignore
+            }
+        };
+        AbstractListener abstractListener2 = new AbstractListener(2) {
+            @Override
+            protected void dataChanged(CuratorFramework client, TreeCacheEvent event, String path) {
+                // ignore
+            }
+        };
+        zookeeperCachedOperator.registerListener(abstractListener2);
+        zookeeperCachedOperator.registerListener(abstractListener1);
+        Assert.assertTrue(true);","[{'comment': 'I think the test has tested nothing.', 'commenter': 'Technoboy-'}, {'comment': 'Sorry, I did not see your comment. Yes, this assertion has no meaning.', 'commenter': 'CalvinKirs'}, {'comment': 'Yes, you are right, this test just for debug 👍 ', 'commenter': 'ruanwenjun'}]"
5942,sql/dolphinscheduler_mysql.sql,"@@ -471,7 +471,7 @@ CREATE TABLE `t_ds_task_definition` (
   `create_time` datetime NOT NULL COMMENT 'create time',
   `update_time` datetime DEFAULT NULL COMMENT 'update time',
   PRIMARY KEY (`id`,`code`),
-  UNIQUE KEY `task_unique` (`name`,`project_code`) USING BTREE
+  UNIQUE KEY `task_unique` (`code`,`project_code`) USING BTREE","[{'comment': ""It seems the `code` is generated by a snowflake algorithm, we may don't need to add such a unique key."", 'commenter': 'ruanwenjun'}, {'comment': 'In the case of clock rollback, duplication may occur, so it is best to + unique constraint', 'commenter': 'CalvinKirs'}, {'comment': 'OK', 'commenter': 'ruanwenjun'}, {'comment': ""Thanks for your contribution. It can't be modified here. When the master module generates a DAG, it will use the name of the task as the key of the nodeMap (See MasterExecThread|buildFlowDag). Using code as the unique key will lead to the loss of the task. I'm refactoring this part. Please pay attention to json_split_two branch."", 'commenter': 'brave-lee'}, {'comment': 'As discussed in #5875, the design needs to be discussed. You can discuss how to make changes', 'commenter': 'CalvinKirs'}]"
5959,sql/create/release-1.0.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -113,9 +113,9 @@ CREATE TABLE `t_escheduler_master_server` (
   `host` varchar(45) DEFAULT NULL COMMENT 'ip',
   `port` int(11) DEFAULT NULL COMMENT 'port',
   `zk_directory` varchar(64) DEFAULT NULL COMMENT 'the server path in zk directory',
-  `res_info` varchar(256) DEFAULT NULL COMMENT 'json resource information:{""cpu"":xxx,""memroy"":xxx}',
+  `res_info` varchar(256) DEFAULT NULL COMMENT 'json resource information:{""cpu"":xxx,""memory"":xxx}',","[{'comment': 'The length is best to be modified to 255', 'commenter': 'CalvinKirs'}, {'comment': 'I changed it.please review. ', 'commenter': 'yimaixinchen'}]"
5983,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/log/LoggerRequestProcessor.java,"@@ -102,19 +92,16 @@ public void process(Channel channel, Command command) {
             case REMOVE_TAK_LOG_REQUEST:
                 RemoveTaskLogRequestCommand removeTaskLogRequest = JSONUtils.parseObject(
                         command.getBody(), RemoveTaskLogRequestCommand.class);
-
-                String taskLogPath = removeTaskLogRequest.getPath();
-
-                File taskLogFile = new File(taskLogPath);
+                List<String> taskLogPaths = removeTaskLogRequest.getPath();
+                OsSystemNativeCommand os = new LinuxSystem();
+                String cmd = """";
+                for (String path : taskLogPaths){","[{'comment': 'It is better to split when the length of the taskLogPaths is large, you can do the split in the api module.', 'commenter': 'ruanwenjun'}, {'comment': 'ds 系统官方推荐目前只是支持 linux 系统，所以使用rm -rf 的方式下应该师符合场景的。\r\n同时也做了未来的扩展可能，加入了系统类的铺垫。\r\n后期在出现多系统支持的时候增加，个人觉得就足够了。', 'commenter': 'caoyj1991'}, {'comment': 'I mean can we directly use `Files.delete();` to remove the log file instead of use shell command.\r\nWhat you concern is using shell command is faster than using api ?', 'commenter': 'ruanwenjun'}, {'comment': '这种场景下最适合的应该是一次性删除多文件的方式，而不是一个个删除的方案。\r\n目前没发现在 java JDK 中有任何比较适合的 api 可以直接调用，可以一次性批量删除。', 'commenter': 'caoyj1991'}, {'comment': 'OK', 'commenter': 'ruanwenjun'}]"
5983,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/cmd/OsSystemNativeCommand.java,"@@ -0,0 +1,7 @@
+package org.apache.dolphinscheduler.common.cmd;
+
+public interface OsSystemNativeCommand {
+    public static String REPLACE_HOLDER = ""REPLACE_HOLDER"";
+    String deleteCmd();","[{'comment': 'should add license heads', 'commenter': 'CalvinKirs'}]"
5983,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessInstanceService.java,"@@ -131,7 +131,7 @@ Result queryProcessInstanceList(User loginUser, String projectName, Integer proc
      * @param processInstanceId process instance id
      * @return delete result code
      */
-    Map<String, Object> deleteProcessInstanceById(User loginUser, String projectName, Integer processInstanceId);
+    Map<String, Object> deleteProcessInstanceById(User loginUser, String projectName, Integer processInstanceId, Map<String, List<String>> taskFiles);","[{'comment': 'Can we remove the `taskFIles` in params and return this in the result', 'commenter': 'ruanwenjun'}, {'comment': '传入的参数作为引用会不断的累加数据。 有什原因不能传入这个阐述吗？\r\n', 'commenter': 'caoyj1991'}, {'comment': ""No problem, it may be programing habit, sometimes if a method return results, then it shouldn't be side effect."", 'commenter': 'ruanwenjun'}, {'comment': 'thank you for reviewing~ \r\nand thanks for your suggestion', 'commenter': 'caoyj1991'}]"
5983,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/MapUtils.java,"@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+public class MapUtils {
+
+    public static void combineMap(Map<String, List<String>> originMap,","[{'comment': ""It's better to rename this method to putAll, sometimes combine may not a side effect method, if you want to use combineMap, you would better add a return value of the method.\r\nAnd it's better to use generics type here.\r\n```java\r\npublic static <K, V> void putAll(Map<K, V> originMap, Map<K, V> putMap, BiFunction<V, V, V> combineFunction) {\r\n        if (originMap == null) {\r\n            originMap = new HashMap<>();\r\n        }\r\n        if (MapUtils.isEmpty(putMap)) {\r\n            return;\r\n        }\r\n        for (Map.Entry<K, V> entry : putMap.entrySet()) {\r\n            K key = entry.getKey();\r\n            V newValue = combineFunction.apply(originMap.get(key), entry.getValue());\r\n            originMap.put(key, newValue);\r\n        }\r\n    }\r\n```\r\n```"", 'commenter': 'ruanwenjun'}, {'comment': '已修正，putAll', 'commenter': 'caoyj1991'}]"
5983,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/AsyncStreamThread.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.thread;
+
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * StreamGobbler
+ */
+public class AsyncStreamThread extends Thread {
+
+    private static final Logger logger = LoggerFactory.getLogger(AsyncStreamThread.class);
+
+    private final InputStream inputStream;
+
+    public AsyncStreamThread(InputStream inputStream) {
+        this.inputStream = inputStream;
+    }
+
+    @Override
+    public void run() {
+        InputStreamReader inputStreamReader = null;
+        BufferedReader inputBufferReader = null;
+
+        try {
+            inputStreamReader = new InputStreamReader(inputStream);
+            inputBufferReader = new BufferedReader(inputStreamReader);
+            String line;","[{'comment': 'Use `try-with-resources` syntax', 'commenter': 'kezhenxu94'}]"
5983,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/thread/AsyncStreamThread.java,"@@ -0,0 +1,74 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.thread;
+
+import java.io.BufferedReader;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * StreamGobbler
+ */
+public class AsyncStreamThread extends Thread {
+
+    private static final Logger logger = LoggerFactory.getLogger(AsyncStreamThread.class);
+
+    private final InputStream inputStream;
+
+    public AsyncStreamThread(InputStream inputStream) {
+        this.inputStream = inputStream;
+    }
+
+    @Override
+    public void run() {
+        InputStreamReader inputStreamReader = null;
+        BufferedReader inputBufferReader = null;
+
+        try {
+            inputStreamReader = new InputStreamReader(inputStream);
+            inputBufferReader = new BufferedReader(inputStreamReader);
+            String line;
+            StringBuilder output = new StringBuilder();
+            while ((line = inputBufferReader.readLine()) != null) {
+                output.append(line);
+                output.append(System.getProperty(""line.separator""));
+            }
+            if (output.length() > 0) {
+                logger.info(""out put msg is{}"", output);","[{'comment': '```suggestion\r\n                logger.info(""out put msg is {}"", output);\r\n```', 'commenter': 'kezhenxu94'}]"
5983,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/MapUtils.java,"@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+public class MapUtils {
+
+    public static void putAll(Map<String, List<String>> originMap,
+                                  Map<String, List<String>> newMap) {
+        for (String key : newMap.keySet()) {
+            List<String> filePaths = originMap.get(key);
+            if (filePaths == null) {
+                filePaths = new ArrayList<>();
+                originMap.put(key, filePaths);
+            }
+            filePaths.addAll(newMap.get(key));
+        }
+    }
+}","[{'comment': ""This is an overuse of util class in my opinion, it's just a one-line codes and not a common case, I don't know who else will use this util class because it seems that this function is only used in your case.\r\n\r\n```java\r\nnewMap.forEach((key, val) -> originMap.computeIfAbsent(key, __ -> new ArrayList<>()).addAll(val));\r\n```"", 'commenter': 'kezhenxu94'}]"
5983,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/log/LoggerRequestProcessor.java,"@@ -96,26 +99,26 @@ public void process(Channel channel, Command command) {
                 for (String line : lines) {
                     builder.append(line + ""\r\n"");
                 }
-                RollViewLogResponseCommand rollViewLogRequestResponse = new RollViewLogResponseCommand(builder.toString());
-                channel.writeAndFlush(rollViewLogRequestResponse.convert2Command(command.getOpaque()));
+                RollViewLogResponseCommand rollViewLogRequestResponse = new RollViewLogResponseCommand(
+                        builder.toString());
+                channel
+                        .writeAndFlush(rollViewLogRequestResponse.convert2Command(command.getOpaque()));
                 break;
             case REMOVE_TAK_LOG_REQUEST:
                 RemoveTaskLogRequestCommand removeTaskLogRequest = JSONUtils.parseObject(
                         command.getBody(), RemoveTaskLogRequestCommand.class);
-
-                String taskLogPath = removeTaskLogRequest.getPath();
-
-                File taskLogFile = new File(taskLogPath);
+                List<String> taskLogPaths = removeTaskLogRequest.getPath();
+                OsSystemNativeCommand os = new LinuxSystem();
+                String cmd = """";
+                for (String path : taskLogPaths) {
+                    cmd += os.deleteCmd() + path + "";"";
+                }","[{'comment': ""I personally don't think manipulating the command is better than JDK APIs, and you should know manipulating the strings to a system command is dangerous and can be injected malicious codes as well"", 'commenter': 'kezhenxu94'}, {'comment': '\r\n其他的部分我倒是能理解。毕竟是追求比较优质的代码。\r\n\r\n第一，ds 的使用场景并不是对外的，而是对内的。\r\n第二，如果存在安全漏洞，其实基本可以认为是不太可能的。因为删除的文件名是来自数据库内自动生成的文件，如果会有可注入的风险，就是因为数据的库的信息被串改了。完全属于没病呻吟的情况。\r\n第三，作为DS 4个版本的使用者，我要说一句，现在批量删除的逻辑是有可能导致 这个系统异常的。日志本身在运维阶段属于可以被定期清理的部分。如果UI 操作删除批量日志能导致使用者直接面对系统宕机，系统本身的稳定性是需要紧急优化的。\r\n第四，非得强调jdk 提供的API 才是最安全的这个情况。个人不是没有考虑过服用jdk 的API 。 但是在牺牲一次性删除的方案下，找个看着可能对的方法去做，并不是解决问题的方式。当然可以说开启异步线程去清理。。。但是有必要吗？\r\n', 'commenter': 'caoyj1991'}, {'comment': '请不要按照开发人员的方式去思考用户该怎么用，因为官方文档里也没有限制用户可嵌套的层级。\r\n\r\n后期我个人带着团队用的时候都是直接删除数据库的。\r\n\r\n', 'commenter': 'caoyj1991'}, {'comment': ""> 第一，ds 的使用场景并不是对外的，而是对内的。\r\n\r\nCompany employees are totally possible to destroy their servers / databases.\r\n\r\n> 第二，如果存在安全漏洞，其实基本可以认为是不太可能的。因为删除的文件名是来自数据库内自动生成的文件，如果会有可注入的风险，就是因为数据的库的信息被串改了。完全属于没病呻吟的情况。\r\n\r\nDo you mean if the database is hacked, it's reasonable that your servers should be also hacked? You should limit the exploding radius instead of expanding it.\r\n\r\n> 第三，作为DS 4个版本的使用者，我要说一句，现在批量删除的逻辑是有可能导致 这个系统异常的。日志本身在运维阶段属于可以被定期清理的部分。如果UI 操作删除批量日志能导致使用者直接面对系统宕机，系统本身的稳定性是需要紧急优化的。\r\n\r\nYou said the original logic is possible to cause exceptions, but didn't explain what exceptions might be caused and why your changes will resolve it.\r\n\r\n> 第四，非得强调jdk 提供的API 才是最安全的这个情况。个人不是没有考虑过服用jdk 的API 。 但是在牺牲一次性删除的方案下，找个看着可能对的方法去做，并不是解决问题的方式。当然可以说开启异步线程去清理。。。但是有必要吗？\r\n> 请不要按照开发人员的方式去思考用户该怎么用，因为官方文档里也没有限制用户可嵌套的层级。\r\n> 后期我个人带着团队用的时候都是直接删除数据库的。\r\n\r\nPlease don't take it personally and don't be so aggressive, reviewers just give their opinions and raise their concerns, giving your reasons is just enough, that's how open source community works, again, don't take it personally, don't be aggressive."", 'commenter': 'kezhenxu94'}, {'comment': ""I'm OK to just give a +1 if you don't like your codes reviewed "", 'commenter': 'kezhenxu94'}, {'comment': '原因就在最初的介绍里。\r\n![image](https://user-images.githubusercontent.com/10510545/130352211-d9cb7793-e448-43a1-be1b-8aa660639bf5.png)\r\n\r\n有效的建议个人认为是都是比较正向可以接受的。但是如果不清楚整体情况下反复的重复同样的问题，回复同样的解释。貌似并不是很有效的沟通，**这个PR 上已经回复了第二次这个问题的起因和解决方法的设计。**', 'commenter': 'caoyj1991'}, {'comment': '![image](https://user-images.githubusercontent.com/10510545/130352410-700e6173-2e42-4b53-9d50-3496269d60d8.png)\r\n', 'commenter': 'caoyj1991'}]"
5983,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessInstanceServiceImpl.java,"@@ -304,17 +319,20 @@ public Result queryProcessInstanceList(User loginUser, String projectName, Integ
      * @throws IOException io exception
      */
     @Override
-    public Map<String, Object> queryTaskListByProcessId(User loginUser, String projectName, Integer processId) throws IOException {
+    public Map<String, Object> queryTaskListByProcessId(User loginUser, String projectName,
+                                                        Integer processId) throws IOException {
         Map<String, Object> result = new HashMap<>();
         Project project = projectMapper.queryByName(projectName);
 
-        Map<String, Object> checkResult = projectService.checkProjectAndAuth(loginUser, project, projectName);
+        Map<String, Object> checkResult = projectService
+                .checkProjectAndAuth(loginUser, project, projectName);","[{'comment': 'This code style is not better than before', 'commenter': 'kezhenxu94'}]"
6016,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -110,7 +102,7 @@
         @ApiImplicitParam(name = ""locations"", value = ""PROCESS_DEFINITION_LOCATIONS"", required = true, type = ""String""),
         @ApiImplicitParam(name = ""description"", value = ""PROCESS_DEFINITION_DESC"", required = false, type = ""String"")
     })
-    @PostMapping(value = ""/save"")","[{'comment': 'Should this be kept ?', 'commenter': 'brave-lee'}, {'comment': 'In the standard document, we use POST to represent create.', 'commenter': 'marin-man'}]"
6016,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -138,12 +130,12 @@ public Result createProcessDefinition(@ApiIgnore @RequestAttribute(value = Const
      * @param targetProjectCode target project code
      * @return copy result code
      */
-    @ApiOperation(value = ""copy"", notes = ""COPY_PROCESS_DEFINITION_NOTES"")
+    @ApiOperation(value = ""batchCopyProcessDefinitions"", notes = ""COPY_PROCESS_DEFINITION_NOTES"")","[{'comment': 'please check', 'commenter': 'brave-lee'}, {'comment': 'I have put it another way.\r\n`@ApiOperation(value = ""batchMoveByCodes"", notes = ""MOVE_PROCESS_DEFINITION_NOTES"")`', 'commenter': 'marin-man'}]"
6016,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -81,7 +72,7 @@
  */
 @Api(tags = ""PROCESS_DEFINITION_TAG"")
 @RestController
-@RequestMapping(""projects/{projectCode}/process"")
+@RequestMapping(""projects/{projectCode}/process-definitions"")","[{'comment': 'English singular is recommended.\r\nproject/{projectCode}/process-definition', 'commenter': 'wen-hemin'}, {'comment': 'ok', 'commenter': 'marin-man'}]"
6016,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskDefinitionController.java,"@@ -160,14 +153,14 @@ public Result queryTaskDefinitionVersions(@ApiIgnore @RequestAttribute(value = C
         @ApiImplicitParam(name = ""code"", value = ""TASK_DEFINITION_CODE"", required = true, dataType = ""Long"", example = ""1""),
         @ApiImplicitParam(name = ""version"", value = ""VERSION"", required = true, dataType = ""Int"", example = ""100"")
     })
-    @GetMapping(value = ""/version/switch"")
+    @GetMapping(value = ""/{code}/version/switch/{version}"")","[{'comment': 'Get or Post ?\r\n\r\nGet:\r\n/{code}/version/{version}\r\n\r\nPost:\r\n/{code}/version/{version}/switch', 'commenter': 'wen-hemin'}, {'comment': 'I think the first is good', 'commenter': 'marin-man'}, {'comment': '/project/{code}/version/{version}/switch better', 'commenter': 'gabrywu'}]"
6103,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditMessage.java,"@@ -0,0 +1,66 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.Date;
+
+public class AuditMessage {
+    private String messageType;","[{'comment': '\r\n```suggestion\r\n\r\n```\r\nRemove the unused attribute.', 'commenter': 'ruanwenjun'}]"
6103,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,87 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Date;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>(1000);
+
+    /**
+     * subscribers list
+     */
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        Thread thread = new Thread(() -> doPublish());
+        thread.setDaemon(true);
+        thread.start();
+    }
+
+    /**
+     * publish a new audit message
+     *
+     * @param message audit message
+     */
+    public void publish(AuditMessage message) {
+        queue.offer(message);
+    }
+
+    /**
+     *  subscribers execute the message processor method
+     */
+    private void doPublish() {
+        AuditMessage message;
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            while (true) {
+                try {
+                    message = queue.take();
+                    for (AuditSubscriber subscriber : subscribers) {
+                        try {
+                            subscriber.execute(message);
+                        } catch (Exception e) {
+                            logger.error(""subscriber fail to process message {}"", message.getMessageType());
+                        }
+                    }
+                } catch (InterruptedException e) {
+                    Thread.currentThread().interrupt();
+                }
+            }
+        }
+    }
+
+    /**
+     *  generate new Message
+     *
+     */
+    public AuditMessage generateMessage(User user, Date auditDate, AuditModuleType module, AuditOperationType operation) {
+        return new AuditMessage(user, auditDate, module, operation);
+    }","[{'comment': '```suggestion\r\n```\r\nRemove the unused method', 'commenter': 'ruanwenjun'}]"
6103,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,87 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Date;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>(1000);
+
+    /**
+     * subscribers list
+     */
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        Thread thread = new Thread(() -> doPublish());
+        thread.setDaemon(true);
+        thread.start();
+    }
+
+    /**
+     * publish a new audit message
+     *
+     * @param message audit message
+     */
+    public void publish(AuditMessage message) {
+        queue.offer(message);
+    }
+
+    /**
+     *  subscribers execute the message processor method
+     */
+    private void doPublish() {
+        AuditMessage message;
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {","[{'comment': 'There might be a bug, if the switch set to false, the application will still add `AuditMessage` to the queue.\r\n\r\nIt is better to move this switch to `publish` method and `init` method.', 'commenter': 'ruanwenjun'}]"
6103,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,87 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Date;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>(1000);
+
+    /**
+     * subscribers list
+     */
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        Thread thread = new Thread(() -> doPublish());
+        thread.setDaemon(true);","[{'comment': 'Set thread name', 'commenter': 'ruanwenjun'}]"
6103,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditSubscriber.java,"@@ -0,0 +1,11 @@
+package org.apache.dolphinscheduler.api.audit;
+
+public interface AuditSubscriber {
+
+    /**
+     * process the message","[{'comment': '```suggestion\r\nprocess the audit message\r\n```', 'commenter': 'ruanwenjun'}]"
6103,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AuditConfiguration.java,"@@ -0,0 +1,20 @@
+package org.apache.dolphinscheduler.api.configuration;
+
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.context.annotation.Configuration;
+
+@Configuration
+public class AuditConfiguration {
+    @Value(""${audit.control.global.switch:true}"")
+    private boolean auditGlobalControlSwitch;
+
+
+","[{'comment': '```suggestion\r\n```', 'commenter': 'ruanwenjun'}]"
6103,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/AuditLog.java,"@@ -0,0 +1,75 @@
+package org.apache.dolphinscheduler.dao.entity;
+
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
+import com.baomidou.mybatisplus.annotation.TableName;
+import com.fasterxml.jackson.annotation.JsonFormat;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+
+import java.util.Date;
+
+@TableName(""t_ds_audit_log"")
+public class AuditLog {
+
+    /**
+     * id
+     */
+    @TableId(value = ""id"", type = IdType.AUTO)
+    private int id;
+
+    /**
+     * user id
+     */
+    private int userId;
+
+    /**
+     * operation module
+     */
+    private AuditModuleType module;","[{'comment': ""Don't use Enum here, this might make code comples."", 'commenter': 'ruanwenjun'}, {'comment': ""> Don't use Enum here, this might make code comples.\r\n\r\nIf so, user might need to use input boxes instead of drop-down boxes to query audit log. \r\nIn this way, when inserting new audit logs, we need to input modules and operations in String class again."", 'commenter': 'yc322'}]"
6103,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/AuditLog.java,"@@ -0,0 +1,75 @@
+package org.apache.dolphinscheduler.dao.entity;
+
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableId;
+import com.baomidou.mybatisplus.annotation.TableName;
+import com.fasterxml.jackson.annotation.JsonFormat;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+
+import java.util.Date;
+
+@TableName(""t_ds_audit_log"")
+public class AuditLog {
+
+    /**
+     * id
+     */
+    @TableId(value = ""id"", type = IdType.AUTO)
+    private int id;
+
+    /**
+     * user id
+     */
+    private int userId;
+
+    /**
+     * operation module
+     */
+    private AuditModuleType module;
+
+    /**
+     * operation
+     */
+    private AuditOperationType operation;
+
+    /**
+     * operation time
+     */
+    @JsonFormat(pattern = ""yyyy-MM-dd HH:mm:ss"",timezone=""GMT+8"")
+    private Date time;
+
+    // TODO : 添加项目","[{'comment': 'Remove the Chinese.', 'commenter': 'ruanwenjun'}]"
6103,sql/dolphinscheduler_mysql.sql,"@@ -968,3 +968,16 @@ CREATE TABLE `t_ds_alert_plugin_instance` (
   `instance_name` varchar(200) DEFAULT NULL COMMENT 'alert instance name',
   PRIMARY KEY (`id`)
 ) ENGINE=InnoDB DEFAULT CHARSET=utf8;
+
+-- ----------------------------
+-- Table structure for t_ds_alert_plugin_instance
+-- ----------------------------
+DROP TABLE IF EXISTS `t_ds_audit_log`;
+CREATE TABLE `t_ds_audit_log` (
+  `id` int NOT NULL AUTO_INCREMENT,
+  `user_id` int(11) NOT NULL COMMENT 'user id',
+  `module` int DEFAULT NULL COMMENT 'module',
+  `operation` int DEFAULT NULL COMMENT 'operation',
+  `time` datetime DEFAULT NULL COMMENT 'create time',","[{'comment': ""```suggestion\r\n`time` datetime DEFAULT CURRENT_TIMESTAMP COMMENT 'create time',\r\n```\r\n"", 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun  Thanks for your review, I have addressed the comments. PTAL', 'commenter': 'yc322'}]"
6104,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -1083,4 +1083,11 @@ private Constants() {
     public static final String TASK_DEPENDENCE_PROJECT_NAME = ""projectName"";
     public static final String TASK_DEPENDENCE_DEFINITION_ID = ""definitionId"";
     public static final String TASK_DEPENDENCE_DEFINITION_NAME = ""definitionName"";
+
+    /**
+     * dry run state
+     */
+    public static final Integer NORMAL_STATE = 0;
+    public static final Integer DRY_RUN_STATE = 1;","[{'comment': ""DRY_RUN_FLAG_NO and DRY_RUN_FLAG_YES\r\n'state' change to 'flag'\r\nInteger change to int"", 'commenter': 'wen-hemin'}]"
6104,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/Command.java,"@@ -357,6 +373,7 @@ public int hashCode() {
         result = 31 * result + (processInstancePriority != null ? processInstancePriority.hashCode() : 0);
         result = 31 * result + (updateTime != null ? updateTime.hashCode() : 0);
         result = 31 * result + (workerGroup != null ? workerGroup.hashCode() : 0);
+        result = 31 * result + (dryRun != null ? dryRun.hashCode() : 0);
         result = 31 * result + (environmentCode != null ? environmentCode.hashCode() : 0);","[{'comment': 'Adjust the order', 'commenter': 'wen-hemin'}]"
6104,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThread.java,"@@ -191,14 +197,25 @@ public void run() {
             this.task.init();
             //init varPool
             this.task.getParameters().setVarPool(taskExecutionContext.getVarPool());
-            // task handle
-            this.task.handle();
 
-            // task result process
-            if (this.task.getNeedAlert()) {
-                sendAlert(this.task.getTaskAlertInfo());
+            taskInstanceMapper = SpringApplicationContext.getBean(TaskInstanceMapper.class);
+            TaskInstance taskInstance = taskInstanceMapper.selectById(taskExecutionContext.getTaskInstanceId());","[{'comment': 'You can use the method ""ProcessService.findTaskInstanceById()"", no need introduce the TaskInstanceMapper class', 'commenter': 'wen-hemin'}]"
6104,sql/dolphinscheduler_mysql.sql,"@@ -332,6 +332,7 @@ CREATE TABLE `t_ds_command` (
   `process_instance_priority` int(11) DEFAULT NULL COMMENT 'process instance priority: 0 Highest,1 High,2 Medium,3 Low,4 Lowest',
   `worker_group` varchar(64)  COMMENT 'worker group',
   `environment_code` bigint(20) DEFAULT '-1' COMMENT 'environment code',
+  `dry_run` int NULL DEFAULT 0 COMMENT 'dry run state：0 normal, 1 dry run',","[{'comment': ""'state' change to 'flag'"", 'commenter': 'wen-hemin'}, {'comment': 'ok', 'commenter': 'andream7'}]"
6104,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThread.java,"@@ -191,14 +197,25 @@ public void run() {
             this.task.init();
             //init varPool
             this.task.getParameters().setVarPool(taskExecutionContext.getVarPool());","[{'comment': 'Does the previous code need to be executed when dry run?', 'commenter': 'wen-hemin'}]"
6104,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/ErrorCommand.java,"@@ -120,7 +120,12 @@
      */
     private Long environmentCode;
 
-    public ErrorCommand(){}
+    /**
+     * dry run state","[{'comment': 'fix comment', 'commenter': 'wen-hemin'}]"
6104,sql/dolphinscheduler_postgre.sql,"@@ -297,6 +298,7 @@ CREATE TABLE t_ds_error_command (
   worker_group varchar(64),
   environment_code bigint DEFAULT '-1',
   message text ,
+  dry_ru int DEFAULT '0' ,","[{'comment': 'Please also add this field to `sql/dolphinscheduler_h2.sql`', 'commenter': 'kezhenxu94'}]"
6173,dolphinscheduler-ui/src/js/module/i18n/locale/en_US.js,"@@ -187,6 +187,7 @@ export default {
   'Task status statistics': 'Task Status Statistics',
   Number: 'Number',
   State: 'State',
+  'dryRun Flag': 'dryRun Flag',","[{'comment': 'The first letter of the first word is capitalized', 'commenter': 'wen-hemin'}]"
6173,dolphinscheduler-ui/src/js/module/i18n/locale/en_US.js,"@@ -464,6 +465,7 @@ export default {
   'Timeout strategy must be selected': 'Timeout strategy must be selected',
   'Timeout must be a positive integer': 'Timeout must be a positive integer',
   'Add dependency': 'Add dependency',
+  'Whether dryRun': 'Whether dryRun',","[{'comment': 'The first letter of the second word is lowercase', 'commenter': 'wen-hemin'}]"
6190,.github/workflows/ci_k8s.yml,"@@ -0,0 +1,126 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+name: k8s Test
+
+on: 
+  push:
+    paths:
+     - '.github/workflows/ci_k8s.yml'
+     - 'dolphinscheduler/docker/kubernetes/**'
+  pull_request:
+    paths:
+     - '.github/workflows/ci_k8s.yml'
+     - 'dolphinscheduler/docker/kubernetes/**'
+
+env:
+  DOCKER_DIR: ./docker
+  LOG_DIR: /tmp/dolphinscheduler
+
+jobs:
+
+  build:
+    name: Build
+    runs-on: ubuntu-latest # runs-on 是必填字段","[{'comment': '```suggestion\r\n    runs-on: ubuntu-latest\r\n```', 'commenter': 'kezhenxu94'}]"
6190,.github/workflows/ci_k8s.yml,"@@ -0,0 +1,126 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+name: k8s Test
+
+on: 
+  push:
+    paths:
+     - '.github/workflows/ci_k8s.yml'
+     - 'dolphinscheduler/docker/kubernetes/**'
+  pull_request:
+    paths:
+     - '.github/workflows/ci_k8s.yml'
+     - 'dolphinscheduler/docker/kubernetes/**'
+
+env:
+  DOCKER_DIR: ./docker
+  LOG_DIR: /tmp/dolphinscheduler
+
+jobs:
+
+  build:
+    name: Build
+    runs-on: ubuntu-latest # runs-on 是必填字段
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+
+      - name: Check License Header
+        uses: apache/skywalking-eyes@ec88b7d850018c8983f87729ea88549e100c5c82
+
+      - name: Set up Helm
+        uses: azure/setup-helm@v1
+
+      - name: Set up Python","[{'comment': 'Why we need Python?', 'commenter': 'kezhenxu94'}]"
6190,.github/workflows/ci_k8s.yml,"@@ -0,0 +1,126 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+name: k8s Test
+
+on: 
+  push:
+    paths:
+     - '.github/workflows/ci_k8s.yml'
+     - 'dolphinscheduler/docker/kubernetes/**'
+  pull_request:
+    paths:
+     - '.github/workflows/ci_k8s.yml'
+     - 'dolphinscheduler/docker/kubernetes/**'
+
+env:
+  DOCKER_DIR: ./docker
+  LOG_DIR: /tmp/dolphinscheduler
+
+jobs:
+
+  build:
+    name: Build
+    runs-on: ubuntu-latest # runs-on 是必填字段
+    steps:
+      - name: Checkout
+        uses: actions/checkout@v2
+
+      - name: Check License Header
+        uses: apache/skywalking-eyes@ec88b7d850018c8983f87729ea88549e100c5c82
+
+      - name: Set up Helm
+        uses: azure/setup-helm@v1
+
+      - name: Set up Python
+        uses: actions/setup-python@v2
+        with:
+          python-version: 3.7
+
+      - name: Fetch history","[{'comment': 'Why we need the git history?', 'commenter': 'kezhenxu94'}]"
6210,sql/upgrade/1.4.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -355,8 +355,68 @@ CREATE TABLE `t_ds_environment` (
    UNIQUE KEY `environment_code_unique` (`code`)
 ) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;
 
-ALTER TABLE t_ds_task_definition ADD COLUMN `environment_code` bigint(20) default '-1' COMMENT 'environment code' AFTER `worker_group`;
-ALTER TABLE t_ds_task_definition_log ADD COLUMN `environment_code` bigint(20) default '-1' COMMENT 'environment code' AFTER `worker_group`;","[{'comment': 'Why remove this part of sql?', 'commenter': 'zhuangchong'}, {'comment': 'Because it already exists in the added t_ds_task_definition, t_ds_task_definition_log table creation statement.', 'commenter': 'Tandoy'}, {'comment': ""sorry, i didn't notice."", 'commenter': 'zhuangchong'}]"
6222,sql/dolphinscheduler_h2.sql,"@@ -315,6 +315,7 @@ CREATE TABLE t_ds_command
     id                        int(11) NOT NULL AUTO_INCREMENT,
     command_type              tinyint(4) DEFAULT NULL,
     process_definition_id     int(11) DEFAULT NULL,","[{'comment': 'Can we remove this field, it seems `process_definition_id` has not been used?', 'commenter': 'ruanwenjun'}, {'comment': 'Yes, I will do it', 'commenter': 'LiuBodong'}]"
6222,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TenantServiceImpl.java,"@@ -95,7 +95,8 @@
             return result;
         }
 
-        if (checkTenantExists(tenantCode)) {
+        // check if tenant exists in database or named ""default""
+        if (checkTenantExists(tenantCode) || ""default"".equalsIgnoreCase(tenantCode)) {","[{'comment': ""Why not allow tenants to be set to 'default' ?"", 'commenter': 'brave-lee'}, {'comment': '![图片](https://user-images.githubusercontent.com/23203149/133557913-946ed17e-e519-4a5f-8dae-9e9f0525ddc9.png)\r\n\r\nThere\'s already a tenant named ""default"" which is a default tenant if no other tenant could be chosen, if we create a new tenant named ""default"", it hard to figure out which one is the ""real"" tenant we need.', 'commenter': 'LiuBodong'}, {'comment': 'I think the front-end display should be repaired here. When there is already a tenant, the virtual tenant should not be displayed', 'commenter': 'brave-lee'}, {'comment': 'Yes, you are right.\r\nI think the front-end should display noting if no tenant was created.\r\nif the user want to create a workflow when no tenant exists, he should create a new tenant first.', 'commenter': 'LiuBodong'}, {'comment': ""I have different suggestion. if the user want to create a workflow when no tenant exists, in order not to affect workflow creation the tenant id will be -1, and now the tenant code is 'default'. I think that's how default appears."", 'commenter': 'brave-lee'}, {'comment': ""So the question is how to avoid 'default' tenant in front-end and user created tenant named 'default' both appears.\r\nShould we add a mark in the front-end to distinguish? or just remove the 'default' option when tenant list is not empty."", 'commenter': 'LiuBodong'}, {'comment': 'I mean, if the tenant exists, it will be displayed, and the default of this enumeration will not be displayed. If it does not exist, the default of enumeration will be displayed', 'commenter': 'brave-lee'}]"
6226,dolphinscheduler-ui/src/js/conf/home/store/resource/actions.js,"@@ -150,7 +150,7 @@ export default {
    */
   updateContent ({ state }, payload) {
     return new Promise((resolve, reject) => {
-      io.post(`resources/${payload.id}/update-content`, payload, res => {
+      io.post(`resources/${payload.id}`, payload, res => {","[{'comment': 'It seems just need to change this method from post to put?', 'commenter': 'ruanwenjun'}, {'comment': ""It doesn't need to change the http method, but just change the url in the code(in dolphinscheduler-ui) to match the backend."", 'commenter': 'Liiyue'}, {'comment': '@Liiyue Are you sure? it seems this bug is imported by \r\n- #6110\r\nand you can check the payload, I am not sure.\r\nhttps://github.com/apache/dolphinscheduler/blob/c1496d8a74ef69253d1873602a467ca61876bbfb/dolphinscheduler-ui/src/js/conf/home/pages/resource/pages/file/pages/edit/index.vue#L79-L86\r\n\r\nBTW, we use PUT instead of POST, when we want to submit a update request', 'commenter': 'ruanwenjun'}, {'comment': 'You are right, the bug is caused by the confusion between PUT and POST. I have update the code for the bug and the UT in ResourcesControllerTest.', 'commenter': 'Liiyue'}, {'comment': 'Also,I have fix the mismatch of resource download url between frontend and backend.', 'commenter': 'Liiyue'}]"
6226,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/controller/ResourcesControllerTest.java,"@@ -171,7 +172,7 @@ public void testDownloadResource() throws Exception {
         MultiValueMap<String, String> paramsMap = new LinkedMultiValueMap<>();
         paramsMap.add(""id"", ""5"");
 
-        MvcResult mvcResult = mockMvc.perform(get(""/resources/download"")
+        MvcResult mvcResult = mockMvc.perform(get(""/resources/5/download"")","[{'comment': 'please use args， like  get(""/resources/{id}/download"", 5)', 'commenter': 'brave-lee'}, {'comment': 'Update for this unit test.', 'commenter': 'Liiyue'}]"
6240,dolphinscheduler-dao/src/main/resources/datasource.properties,"@@ -16,16 +16,16 @@
 #
 
 # datasource configuration
-spring.datasource.driver-class-name=org.postgresql.Driver
-spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
-spring.datasource.username=root
-spring.datasource.password=root
+#spring.datasource.driver-class-name=org.postgresql.Driver
+#spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
+#spring.datasource.username=root
+#spring.datasource.password=root
 
 # mysql example
-#spring.datasource.driver-class-name=com.mysql.jdbc.Driver
-#spring.datasource.url=jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8
-#spring.datasource.username=ds_user
-#spring.datasource.password=dolphinscheduler
+spring.datasource.driver-class-name=com.mysql.jdbc.Driver
+spring.datasource.url=jdbc:mysql://127.0.0.1:3306/dolphinscheduler?useUnicode=true&characterEncoding=UTF-8
+spring.datasource.username=ds_user
+spring.datasource.password=dolphinscheduler","[{'comment': ""@CalvinKirs we'd better provide Spring profiles to allow developers to specify different profile when developing, instead of modifying these over and over, although I think this should not be submitted in this PR"", 'commenter': 'kezhenxu94'}]"
6240,dolphinscheduler-graphql/mvnw,"@@ -0,0 +1,310 @@
+#!/bin/sh","[{'comment': ""There is no point to add maven wrapper again, in this module, it's already added in the root project"", 'commenter': 'kezhenxu94'}]"
6283,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/model/TaskNode.java,"@@ -393,7 +394,9 @@ public void setPreTaskNodeList(List<PreviousTaskNode> preTaskNodeList) {
     }
 
     public String getTaskParams() {
-        Map<String, Object> taskParams = JSONUtils.toMap(this.params, String.class, Object.class);
+//        Map<String, Object> taskParams = JSONUtils.toMap(this.params, String.class, Object.class);","[{'comment': 'Please remove the unused code', 'commenter': 'ruanwenjun'}, {'comment': 'Oh I forgot to remove this one. Thank you for pointing it out.', 'commenter': 'EricPyZhou'}, {'comment': '@EricPyZhou Please fix the ci error.', 'commenter': 'ruanwenjun'}]"
6283,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/JSONUtilsTest.java,"@@ -199,8 +203,6 @@ public void testToMap() {
 
         Assert.assertNull(JSONUtils.toMap(""3""));","[{'comment': 'It seems you need to remove this test method', 'commenter': 'ruanwenjun'}, {'comment': '> It seems you need to remove this test method\r\n\r\nI removed three unused imports here. Also why do we remove this testToMap() method?', 'commenter': 'EricPyZhou'}, {'comment': '> It seems you need to remove this test method\r\n\r\n\r\n\r\n> It seems you need to remove this test method\r\n\r\nis it because it overlaps with `toMap` test method?', 'commenter': 'EricPyZhou'}, {'comment': 'Since we have remove the `JSONUtils.toMap` method, so this will compile failed.', 'commenter': 'ruanwenjun'}, {'comment': '> Since we have remove the `JSONUtils.toMap` method, so this will compile failed.\r\n\r\nI thought we only remove `public static <K, V> Map<K, V> toMap(String json, Class<K> classK, Class<V> classV) ` not together with the `public static <K, V> Map<K, V> toMap(String json)`', 'commenter': 'EricPyZhou'}, {'comment': ""> Since we have remove the `JSONUtils.toMap` method, so this will compile failed.\r\n\r\noh okay, I do think we can get rid of toMap by looking back to discussions. will do that and commit tomorrow. (It's midnight here in my time zone)"", 'commenter': 'EricPyZhou'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,79 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>();","[{'comment': ""It's better to rename the queue to auditMessageQueue, rather than add a comment."", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,79 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>();
+
+    /**
+     * subscribers list
+     */
+    @Autowired
+    private List<AuditSubscriber> subscribers;","[{'comment': 'Remove this comment.', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,79 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>();
+
+    /**
+     * subscribers list
+     */
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    private AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            Thread thread = new Thread(() -> doPublish());
+            thread.setDaemon(true);
+            thread.setName(""Audit-Log-Consume-Thread"");
+            thread.start();
+        }
+    }
+
+    /**
+     * publish a new audit message
+     *
+     * @param message audit message
+     */
+    public void publish(AuditMessage message) {
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            queue.offer(message);
+        }
+    }
+
+    /**
+     *  subscribers execute the message processor method
+     */
+    private void doPublish() {
+        AuditMessage message;
+        while (true) {
+            try {
+                message = queue.take();
+                for (AuditSubscriber subscriber : subscribers) {
+                    try {
+                        subscriber.execute(message);
+                    } catch (Exception e) {
+                        logger.error(""consume audit message failed {}"", message.toString());
+                        e.printStackTrace();","[{'comment': 'Use logger.error(""consume audit message failed {}"", message.toString(), e);\r\nRemove e.printStackTrace();', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,79 @@
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+@Component
+public class AuditPublishService {
+
+    /**
+     * audit message queue
+     */
+    private BlockingQueue<AuditMessage> queue = new LinkedBlockingQueue<>();
+
+    /**
+     * subscribers list
+     */
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    private AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            Thread thread = new Thread(() -> doPublish());
+            thread.setDaemon(true);
+            thread.setName(""Audit-Log-Consume-Thread"");
+            thread.start();
+        }
+    }
+
+    /**
+     * publish a new audit message
+     *
+     * @param message audit message
+     */
+    public void publish(AuditMessage message) {
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            queue.offer(message);
+        }
+    }
+
+    /**
+     *  subscribers execute the message processor method
+     */
+    private void doPublish() {
+        AuditMessage message;
+        while (true) {
+            try {
+                message = queue.take();
+                for (AuditSubscriber subscriber : subscribers) {
+                    try {
+                        subscriber.execute(message);
+                    } catch (Exception e) {
+                        logger.error(""consume audit message failed {}"", message.toString());
+                        e.printStackTrace();
+                    }
+                }
+            } catch (InterruptedException e) {
+                logger.error(""consume audit message failed"");","[{'comment': 'logger.error(""consume audit message failed"", e);', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditSubscriberImpl.java,"@@ -0,0 +1,26 @@
+package org.apache.dolphinscheduler.api.audit;
+
+
+import org.apache.dolphinscheduler.dao.entity.AuditLog;
+import org.apache.dolphinscheduler.dao.mapper.AuditLogMapper;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+@Component
+public class AuditSubscriberImpl implements AuditSubscriber {
+
+    @Autowired
+    AuditLogMapper logMapper;","[{'comment': 'Add private', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/AuditLogController.java,"@@ -0,0 +1,84 @@
+package org.apache.dolphinscheduler.api.controller;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.AuditService;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.*;
+import springfox.documentation.annotations.ApiIgnore;
+
+import java.util.Map;
+
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_AUDIT_LOG_LIST_PAGING;
+
+@Api(tags = ""AUDIT_LOG_TAG"")
+@RestController
+@RequestMapping(""projects/audit"")
+public class AuditLogController extends BaseController {
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditLogController.class);
+
+    @Autowired
+    AuditService auditService;","[{'comment': 'Add private', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/AuditDto.java,"@@ -0,0 +1,87 @@
+package org.apache.dolphinscheduler.api.dto;
+
+import com.fasterxml.jackson.annotation.JsonFormat;
+
+import java.util.Date;
+
+public class AuditDto {
+
+    /**
+     * operator
+     */
+    private String userName;","[{'comment': 'Use swagger annotion instead of comment.', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -331,8 +331,10 @@
     VERIFY_ENVIRONMENT_ERROR(1200011, ""verify environment error"", ""验证环境信息错误""),
     ENVIRONMENT_WORKER_GROUPS_IS_INVALID(1200012, ""environment worker groups is invalid format"", ""环境关联的工作组参数解析错误""),
     UPDATE_ENVIRONMENT_WORKER_GROUP_RELATION_ERROR(1200013,""You can't modify the worker group, because the worker group [{0}] and this environment [{1}] already be used in the task [{2}]"",
-            ""您不能修改工作组选项，因为该工作组 [{0}] 和 该环境 [{1}] 已经被用在任务 [{2}] 中"");
+            ""您不能修改工作组选项，因为该工作组 [{0}] 和 该环境 [{1}] 已经被用在任务 [{2}] 中""),
 
+    // audit log
+    QUERY_AUDIT_LOG_LIST_PAGING(10057, ""query resources list paging"", ""分页查询资源列表错误"");","[{'comment': '```suggestion\r\nQUERY_AUDIT_LOG_LIST_PAGING(10057, ""query resources list paging"", ""分页查询资源列表错误""),\r\n;\r\n```\r\nIf someone add a enum in the future, this format may help review', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/AuditService.java,"@@ -0,0 +1,46 @@
+package org.apache.dolphinscheduler.api.service;
+
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.Map;
+
+/**
+ * audit information service
+ */
+public interface AuditService {
+
+    /**
+     *
+     * @param user login user
+     * @param module module type
+     * @param operation operation type
+     * @param projectName project name
+     * @param processName process name
+     */
+    void addAudit(User user, AuditModuleType module, AuditOperationType operation,
+                  String projectName, String processName);
+
+    /**
+     * query audit log list
+     *
+     * @param loginUser         login user","[{'comment': 'Why the two formats are not match', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AuditServiceImpl.java,"@@ -0,0 +1,126 @@
+package org.apache.dolphinscheduler.api.service.impl;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
+import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
+import org.apache.dolphinscheduler.api.audit.AuditMessage;
+import org.apache.dolphinscheduler.api.audit.AuditPublishService;
+import org.apache.dolphinscheduler.api.dto.AuditDto;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.service.AuditService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.utils.CollectionUtils;
+import org.apache.dolphinscheduler.dao.entity.AuditLog;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AuditLogMapper;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+import java.util.*;","[{'comment': ""Don't use import *"", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/resources/application-api.properties,"@@ -56,6 +56,9 @@ security.authentication.type=PASSWORD
 #traffic.control.default.tenant.qps.rate=10
 #traffic.control.customize.tenant.qps.rate={'tenant1':11,'tenant2':20}
 
+# Audit log control
+#audit.control.global.switch=false","[{'comment': ""The switch can set true, otherwise the front page will display white. Or you have a better way to let the front end don't show audit tab"", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/configuration/AuditConfigurationTest.java,"@@ -0,0 +1,19 @@
+package org.apache.dolphinscheduler.api.configuration;
+
+import org.apache.dolphinscheduler.api.controller.AbstractControllerTest;
+import org.junit.Assert;
+import org.junit.Test;
+import org.springframework.beans.factory.annotation.Autowired;
+
+import static org.junit.Assert.*;","[{'comment': ""Don't use import *"", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/AuditModuleType.java,"@@ -0,0 +1,44 @@
+package org.apache.dolphinscheduler.common.enums;
+
+import java.util.HashMap;
+
+/**
+ * Audit Module type
+ */
+public enum AuditModuleType {
+    // TODO: add other audit module enums
+    DEFAULT(0, ""default""),
+    USER_MODULE(1, ""user module""),
+    PROJECT_MODULE(2, ""project module"");
+
+    private final int code;
+    private final String enMsg;
+
+    private static HashMap<Integer, AuditModuleType> AUDIT_MODULE_MAP = new HashMap<>();
+
+    static {
+        for (AuditModuleType auditModuleType : AuditModuleType.values()) {
+            AUDIT_MODULE_MAP.put(auditModuleType.code, auditModuleType);
+        }
+    }
+
+    AuditModuleType(int code, String enMsg) {
+        this.code = code;
+        this.enMsg = enMsg;
+    }
+
+    public int getCode() {
+        return this.code;
+    }
+
+    public String getMsg() {
+        return this.enMsg;
+    }
+
+    public static AuditModuleType of(int status) {
+        if (AUDIT_MODULE_MAP.containsKey(status)) {
+            return AUDIT_MODULE_MAP.get(status);
+        }
+        throw new IllegalArgumentException(""invalid audit module type "" + status);","[{'comment': '```suggestion\r\nthrow new IllegalArgumentException(""invalid audit module type code "" + status);\r\n```', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/AuditOperationType.java,"@@ -0,0 +1,45 @@
+package org.apache.dolphinscheduler.common.enums;
+
+import java.util.HashMap;
+
+/**
+ * Audit Operation type
+ */
+public enum AuditOperationType {
+
+    // TODO: add other audit operation enums
+    DEFAULT(0, ""default"" ),
+    CREATE_USER(1, ""create user""),
+    CREATE_PROJECT(2, ""create project"");
+
+    private final int code;
+    private final String enMsg;
+
+    private static HashMap<Integer, AuditOperationType> AUDIT_OPERATION_MAP = new HashMap<>();
+
+    static {
+        for (AuditOperationType operationType : AuditOperationType.values()) {
+            AUDIT_OPERATION_MAP.put(operationType.code, operationType);
+        }
+    }
+
+    AuditOperationType(int code, String enMsg) {
+        this.code = code;
+        this.enMsg = enMsg;
+    }
+
+    public static AuditOperationType of(int status) {
+        if (AUDIT_OPERATION_MAP.containsKey(status)) {
+            return AUDIT_OPERATION_MAP.get(status);
+        }
+        throw new IllegalArgumentException(""invalid audit operation type "" + status);","[{'comment': '```suggestion\r\nthrow new IllegalArgumentException(""invalid audit operation type code "" + status);\r\n```', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/vo/AlertGroupVo.java,"@@ -30,6 +32,18 @@
      * group_name
      */
     private String groupName;
+    /**","[{'comment': 'Remove this file changes', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/AlertGroupMapper.xml,"@@ -33,7 +33,7 @@
         order by update_time desc
     </select>
     <select id=""queryAlertGroupVo"" resultType=""org.apache.dolphinscheduler.dao.vo.AlertGroupVo"">
-        select id, group_name
+        select id, group_name, description, create_time, update_time","[{'comment': 'Remove this file changes', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessService.java,"@@ -2188,23 +2188,23 @@ public int saveTaskDefine(User operator, long projectCode, List<TaskDefinitionLo
             }
             newTaskDefinitionLogs.add(taskDefinitionLog);
         }
+        int insertResult = 0;","[{'comment': 'Remove this file changes', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-service/src/test/java/org/apache/dolphinscheduler/service/process/ProcessServiceTest.java,"@@ -100,6 +103,8 @@
     @Mock
     private TaskDefinitionLogMapper taskDefinitionLogMapper;
     @Mock
+    private TaskDefinitionMapper taskDefinitionMapper;","[{'comment': 'Remove this file changes', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-spi/src/main/java/org/apache/dolphinscheduler/spi/task/TaskConstants.java,"@@ -320,5 +320,8 @@ private TaskConstants() {
      */
     public static final String HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE = ""hadoop.security.authentication.startup.state"";
 
-
+    /**","[{'comment': 'Remove this file changes', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java,"@@ -308,7 +307,7 @@ private void clear() {
      * @param process process
      */
     private void parseProcessOutput(Process process) {
-        String threadLoggerInfoName = String.format(LoggerUtils.TASK_LOGGER_THREAD_NAME + ""-%s"", taskRequest.getTaskAppId());
+        String threadLoggerInfoName = String.format(TaskConstants.TASK_LOGGER_THREAD_NAME + ""-%s"", taskRequest.getTaskAppId());","[{'comment': 'Remove this file changes', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractTaskExecutor.java,"@@ -45,10 +41,7 @@
      */
     protected AbstractTaskExecutor(TaskRequest taskRequest) {
         super(taskRequest);
-        logger = LoggerFactory.getLogger(LoggerUtils.buildTaskId(LoggerUtils.TASK_LOGGER_INFO_PREFIX,
-                taskRequest.getProcessDefineId(),
-                taskRequest.getProcessInstanceId(),
-                taskRequest.getTaskInstanceId()));
+        logger = LoggerFactory.getLogger(taskRequest.getLogPath());","[{'comment': ""It seems the upstream dev is \r\n```java\r\nlogger = LoggerFactory.getLogger(taskRequest.getLogPath());\r\n```\r\nyou didn't do this change, this is strange."", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-ui/src/js/module/i18n/locale/zh_CN.js,"@@ -707,5 +707,11 @@ export default {
   condition: '条件',
   'The condition content cannot be empty': '条件内容不能为空',
   'Reference from': '使用已有任务',
-  'No more...': '没有更多了...'
+  'No more...': '没有更多了...',
+  'Audit Log': '审计日志',
+  'AuditType': '审计类型',
+  'AllTypes': '所有类型',
+  'AllOperations': '所有操作',
+  'UserAudit': '用户管理审计',
+  'ProjectAudit': '项目管理审计'","[{'comment': ""```suggestion\r\n  AuditLog: '审计日志',\r\n  AuditType: '审计类型',\r\n  AllTypes: '所有类型',\r\n  AllOperations: '所有操作',\r\n  UserAudit: '用户管理审计',\r\n  ProjectAudit: '项目管理审计'\r\n```"", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-ui/src/js/module/i18n/locale/en_US.js,"@@ -708,5 +708,11 @@ export default {
   condition: 'condition',
   'The condition content cannot be empty': 'The condition content cannot be empty',
   'Reference from': 'Reference from',
-  'No more...': 'No more...'
+  'No more...': 'No more...',
+  'Audit Log': 'Audit Log',
+  'AuditType': 'audit type',
+  'AllModules': 'all modules',
+  'AllOperations': 'all operations',
+  'UserAudit': 'user management audit',
+  'Project Module': 'project management audit',","[{'comment': ""```suggestion\r\n  AuditLog: 'Audit Log',\r\n  AuditType: 'Audit type',\r\n  AllModules: 'All modules',\r\n  AllOperations: 'All operations',\r\n  UserAudit: 'User management audit',\r\n  ProjectModule: 'Project management audit',\r\n```"", 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/audit/AuditSubscriberTest.java,"@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.AuditLog;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AuditLogMapper;
+
+import java.util.Date;
+
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.InjectMocks;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.mockito.junit.MockitoJUnitRunner;
+
+@RunWith(MockitoJUnitRunner.class)
+public class AuditSubscriberTest {","[{'comment': 'New test class should be added into pom.xml', 'commenter': 'ruanwenjun'}]"
6322,dolphinscheduler-api/src/main/resources/application-api.properties,"@@ -0,0 +1,74 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# server port
+server.port=12345","[{'comment': 'This file is converted to `.yaml` format. Please rebase. ', 'commenter': 'kezhenxu94'}, {'comment': 'Still not rebase correctly', 'commenter': 'kezhenxu94'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditMessage.java,"@@ -0,0 +1,106 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.common.enums.AuditModuleType;
+import org.apache.dolphinscheduler.common.enums.AuditOperationType;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.Date;
+
+public class AuditMessage {
+    private User user;
+
+    private Date auditDate;
+
+    private AuditModuleType module;
+
+    private AuditOperationType operation;
+
+    private String projectName;
+
+    private String processName;","[{'comment': 'The design of audit message looks bad, it includes the resources in it, so if we need to audit 100 kinds of resources (tenants, users, projects, workflows, workflow instances, ...), we have to put their `***Name` here? That would make the class explode and we have to modify the database schema over and over again, also there might be many fields empty (redundant) for many records.\r\n\r\nIn my mind, an audit log should only include an operation (say, CRUD), a resource type (for example, project, workflow), and a resource id (project id, workflow id), with that we can expand the audit logs easily', 'commenter': 'kezhenxu94'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,92 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+@Component
+public class AuditPublishService {
+
+    private BlockingQueue<AuditMessage> auditMessageQueue = new LinkedBlockingQueue<>();
+
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    private AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            Thread thread = new Thread(this::doPublish);
+            thread.setDaemon(true);
+            thread.setName(""Audit-Log-Consume-Thread"");
+            thread.start();
+        }
+    }
+
+    /**
+     * publish a new audit message
+     *
+     * @param message audit message
+     */
+    public void publish(AuditMessage message) {
+        if (auditConfiguration.isAuditGlobalControlSwitch() && !auditMessageQueue.offer(message)) {
+            logger.error(""add audit message failed {}"", message.toString());
+        }
+    }
+
+    /**
+     *  subscribers execute the message processor method
+     */
+    private void doPublish() {
+        AuditMessage message;
+        while (true) {
+            try {
+                message = auditMessageQueue.take();
+                for (AuditSubscriber subscriber : subscribers) {
+                    try {
+                        subscriber.execute(message);
+                    } catch (Exception e) {
+                        logger.error(""consume audit message {} failed, error detail {}"", message, e);
+                    }
+                }
+            } catch (InterruptedException e) {
+                logger.error(""consume audit message failed {}."", e);
+                Thread.currentThread().interrupt();
+            }
+        }","[{'comment': '```suggestion\r\n        AuditMessage message = null;\r\n        while (true) {\r\n            try {\r\n                message = auditMessageQueue.take();\r\n                for (AuditSubscriber subscriber : subscribers) {\r\n                    try {\r\n                        subscriber.execute(message);\r\n                    } catch (Exception e) {\r\n                        logger.error(""consume audit message {} failed, error detail {}"", message, e);\r\n                    }\r\n                }\r\n            } catch (InterruptedException e) {\r\n                logger.error(""consume audit message failed {}."", message, e);\r\n                Thread.currentThread().interrupt();\r\n            }\r\n        }\r\n```', 'commenter': 'kezhenxu94'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/AuditConfiguration.java,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.configuration;
+
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.context.annotation.Configuration;
+
+@Configuration
+public class AuditConfiguration {
+    @Value(""${audit.control.global.switch:true}"")
+    private boolean auditGlobalControlSwitch;","[{'comment': 'Please use Spring Boot properties, take the existing `application-master.yaml` and `application-worker.yaml` as example', 'commenter': 'kezhenxu94'}]"
6322,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/audit/AuditPublishService.java,"@@ -0,0 +1,92 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.audit;
+
+import org.apache.dolphinscheduler.api.configuration.AuditConfiguration;
+
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+@Component
+public class AuditPublishService {
+
+    private BlockingQueue<AuditMessage> auditMessageQueue = new LinkedBlockingQueue<>();
+
+    @Autowired
+    private List<AuditSubscriber> subscribers;
+
+    @Autowired
+    private AuditConfiguration auditConfiguration;
+
+    private static final Logger logger = LoggerFactory.getLogger(AuditPublishService.class);
+
+    /**
+     * create a daemon thread to process the message queue
+     */
+    @PostConstruct
+    private void init() {
+        if (auditConfiguration.isAuditGlobalControlSwitch()) {
+            Thread thread = new Thread(this::doPublish);
+            thread.setDaemon(true);
+            thread.setName(""Audit-Log-Consume-Thread"");
+            thread.start();
+        }
+    }
+
+    /**
+     * publish a new audit message
+     *
+     * @param message audit message
+     */
+    public void publish(AuditMessage message) {
+        if (auditConfiguration.isAuditGlobalControlSwitch() && !auditMessageQueue.offer(message)) {
+            logger.error(""add audit message failed {}"", message.toString());
+        }
+    }
+
+    /**
+     *  subscribers execute the message processor method
+     */
+    private void doPublish() {
+        AuditMessage message;
+        while (true) {
+            try {
+                message = auditMessageQueue.take();
+                for (AuditSubscriber subscriber : subscribers) {
+                    try {
+                        subscriber.execute(message);
+                    } catch (Exception e) {
+                        logger.error(""consume audit message {} failed, error detail {}"", message, e);
+                    }
+                }
+            } catch (InterruptedException e) {
+                logger.error(""consume audit message failed {}."", e);
+                Thread.currentThread().interrupt();","[{'comment': 'You need to `break` here otherwise the process cannot be stopped....', 'commenter': 'kezhenxu94'}]"
6346,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/ApiApplicationServer.java,"@@ -23,11 +23,13 @@
 import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;
 import org.springframework.context.annotation.ComponentScan;
 import org.springframework.context.annotation.FilterType;
+import org.springframework.context.annotation.PropertySource;
 
 @SpringBootApplication
 @ServletComponentScan
 @ComponentScan(value = ""org.apache.dolphinscheduler"",
         excludeFilters = @ComponentScan.Filter(type = FilterType.REGEX, pattern = ""org.apache.dolphinscheduler.server.*""))
+@PropertySource(ignoreResourceNotFound = false, value = ""classpath:application-api.properties"")","[{'comment': 'this file need not change in this feature.', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-api/src/main/resources/logback-api.xml,"@@ -56,6 +56,7 @@
 
     <root level=""INFO"">
         <appender-ref ref=""APILOGFILE""/>
+        <appender-ref ref=""STDOUT""/>","[{'comment': 'this change is unnecessary', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-dao/src/main/resources/datasource.properties,"@@ -16,17 +16,22 @@
 #
 
 # datasource configuration
-spring.datasource.driver-class-name=org.postgresql.Driver
-spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
-spring.datasource.username=root
-spring.datasource.password=root
+#spring.datasource.driver-class-name=org.postgresql.Driver
+#spring.datasource.url=jdbc:postgresql://127.0.0.1:5432/dolphinscheduler
+#spring.datasource.username=root","[{'comment': 'Unnecessary change', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/MasterServer.java,"@@ -59,6 +60,7 @@
                 ""org.apache.dolphinscheduler.server.log.*""
         })
 })
+@PropertySource(ignoreResourceNotFound = false, value = ""classpath:master.properties"")","[{'comment': 'Unnecessary change', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/WorkerServer.java,"@@ -67,6 +68,7 @@
                 ""org.apache.dolphinscheduler.server.log.*""
         })
 })
+@PropertySource(ignoreResourceNotFound = false, value = ""classpath:worker.properties"")","[{'comment': 'unnecessary change', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/worker/config/WorkerConfig.java,"@@ -26,7 +26,7 @@
 import org.springframework.stereotype.Component;
 
 @Component
-@PropertySource(value = ""worker.properties"")
+@PropertySource(value = ""worker.properties"") ","[{'comment': 'unnecessary change', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/resources/logback-master.xml,"@@ -76,6 +76,7 @@
     <root level=""INFO"">
         <appender-ref ref=""TASKLOGFILE""/>
         <appender-ref ref=""MASTERLOGFILE""/>
+        <appender-ref ref=""STDOUT""/>","[{'comment': 'U C', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/resources/logback-worker.xml,"@@ -76,6 +76,7 @@
     <root level=""INFO"">
         <appender-ref ref=""TASKLOGFILE""/>
         <appender-ref ref=""WORKERLOGFILE""/>
+        <appender-ref ref=""STDOUT""/>","[{'comment': 'U C', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/resources/master.properties,"@@ -16,7 +16,7 @@
 #
 
 # master listen port
-#master.listen.port=5678
+master.listen.port=5678","[{'comment': 'U C', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-server/src/main/resources/worker.properties,"@@ -31,7 +31,7 @@
 #worker.tenant.auto.create=false
 
 # worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks. default value -1: the number of cpu cores * 2
-#worker.max.cpuload.avg=-1
+#worker.max.cpuload.avg=100","[{'comment': 'u C', 'commenter': 'lenboo'}]"
6346,dolphinscheduler-service/src/main/resources/registry.properties,"@@ -24,4 +24,4 @@ registry.servers=127.0.0.1:2181
 #maven.local.repository=/usr/local/localRepository
 
 #registry.plugin.binding config the Registry Plugin need be load when development and run in IDE
-#registry.plugin.binding=./dolphinscheduler-registry-plugin/dolphinscheduler-registry-zookeeper/pom.xml
+registry.plugin.binding=./dolphinscheduler-registry-plugin/dolphinscheduler-registry-zookeeper/pom.xml","[{'comment': 'U C', 'commenter': 'lenboo'}]"
6346,pom.xml,"@@ -77,7 +77,7 @@
         <httpclient.version>4.4.1</httpclient.version>
         <httpcore.version>4.4.1</httpcore.version>
         <junit.version>4.12</junit.version>
-        <mysql.connector.version>5.1.34</mysql.connector.version>
+        <mysql.connector.version>8.0.25</mysql.connector.version>","[{'comment': 'U C', 'commenter': 'lenboo'}]"
6427,dolphinscheduler-ui/src/js/module/i18n/locale/zh_CN.js,"@@ -586,7 +586,7 @@ export default {
   TargetDataBase: '目标库',
   TargetTable: '目标表',
   TargetJobName: 'TIS目标任务名',
-  'Please enter TIS DataX job name': '请输入TIS DataX任务名',
+  'Please enter PIGEON DataX job name': '请输入TIS DataX任务名',","[{'comment': 'Maybe we should change the describe here, about the keyword `DataX` and `TIS`, BTW, please change `en_US.js` too', 'commenter': 'zhongjiajie'}, {'comment': ""> 'Please enter DataX job name': '请输入DataX任务名',\r\n\r\nthis shoud be OK"", 'commenter': 'baisui1981'}, {'comment': '> Maybe we should change the describe here, about the keyword `DataX` and `TIS`, BTW, please change `en_US.js` too\r\n\r\ndescription has been improved, and en_US.js lack these description,  now, has added', 'commenter': 'jixiang155'}]"
6427,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/tasks/pigeon.vue,"@@ -23,7 +23,7 @@
           type=""input""
           size=""small""
           v-model=""targetJobName""
-          :placeholder=""$t('Please enter TIS DataX job name')"">
+          :placeholder=""$t('Please enter PIGEON DataX job name')"">","[{'comment': 'Maybe remove the DATAx keyword here too', 'commenter': 'zhongjiajie'}, {'comment': '> Maybe remove the DATAx keyword here too\r\n\r\nhas removed', 'commenter': 'jixiang155'}]"
6427,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/canvas/taskbar.scss,"@@ -174,8 +174,8 @@
             &.icos-switch {
               background-image: url(""../images/task-icos/switch_hover.png"");
             }
-            &.icos-tis {
-              background-image: url(""../images/task-icos/tis_hover.png"");
+            &.icos-pigeon {","[{'comment': 'Why we have two `tis` icos here in L159 and L177', 'commenter': 'zhongjiajie'}, {'comment': 'add duplicate, should be reserved one', 'commenter': 'baisui1981'}, {'comment': '> add duplicate, should be reserved one\r\n\r\ndone', 'commenter': 'jixiang155'}]"
6546,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/ProcessInstanceExecCacheManagerImpl.java,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.cache.impl;
+
+import org.apache.dolphinscheduler.server.master.cache.ProcessInstanceExecCacheManager;
+import org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteThread;
+import org.springframework.stereotype.Component;
+
+import java.util.Collection;
+import java.util.concurrent.ConcurrentHashMap;
+
+/**
+ * cache of process instance id and WorkflowExecuteThread
+ */
+@Component
+public class ProcessInstanceExecCacheManagerImpl implements ProcessInstanceExecCacheManager {
+
+    /**
+     * use a concurrent map cache
+     */
+    private final ConcurrentHashMap<Integer, WorkflowExecuteThread> processInstanceExecMaps = new ConcurrentHashMap<>();
+
+    @Override
+    public WorkflowExecuteThread getByProcessInstanceId(int processInstanceId) {
+        return processInstanceExecMaps.get(processInstanceId);
+    }
+
+    @Override
+    public boolean contains(int processInstanceId) {
+        return processInstanceExecMaps.containsKey(processInstanceId);
+    }
+
+    @Override
+    public void removeByProcessInstanceId(int processInstanceId) {
+        processInstanceExecMaps.remove(processInstanceId);
+    }
+
+    @Override
+    public void cache(int processInstanceId, WorkflowExecuteThread workflowExecuteThread) {
+        if (workflowExecuteThread == null) {
+            return;
+        }
+        processInstanceExecMaps.put(processInstanceId, workflowExecuteThread);
+    }
+
+    @Override
+    public Collection<WorkflowExecuteThread> getAll() {
+        return processInstanceExecMaps.values();","[{'comment': ""It's better to return an Immutable list here. If some modified the result, such remove or add, it will cause problem.\r\nThis method just return a view result, all change need by other interface."", 'commenter': 'ruanwenjun'}]"
6546,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/impl/ProcessInstanceExecCacheManagerImpl.java,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.cache.impl;
+
+import org.apache.dolphinscheduler.server.master.cache.ProcessInstanceExecCacheManager;
+import org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteThread;
+import org.springframework.stereotype.Component;
+
+import java.util.Collection;
+import java.util.concurrent.ConcurrentHashMap;
+
+/**
+ * cache of process instance id and WorkflowExecuteThread
+ */
+@Component
+public class ProcessInstanceExecCacheManagerImpl implements ProcessInstanceExecCacheManager {
+
+    /**
+     * use a concurrent map cache","[{'comment': ""For code clean, remove this comment.\r\n\r\nIf you want to add a comment here, it's better to write why you use concurrent map here rather than just write use a concurrent map, we can easily know this is a concurrent map.\r\n\r\nIt's better to write what is the key of the map."", 'commenter': 'ruanwenjun'}]"
6546,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/registry/MasterRegistryClient.java,"@@ -101,13 +106,16 @@
 
     private String localNodePath;
 
-    public void init(ConcurrentHashMap<Integer, WorkflowExecuteThread> processInstanceExecMaps) {
+    /**
+     * constructor","[{'comment': 'Remove this comment, we can know this is a constructor.', 'commenter': 'ruanwenjun'}]"
6546,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/EventExecuteService.java,"@@ -73,21 +80,21 @@
     private StateEventCallbackService stateEventCallbackService;
 
 
-    private ConcurrentHashMap<Integer, WorkflowExecuteThread> processInstanceExecMaps;
-    private ConcurrentHashMap<String, WorkflowExecuteThread> eventHandlerMap = new ConcurrentHashMap();
+    private ConcurrentHashMap<String, WorkflowExecuteThread> eventHandlerMap = new ConcurrentHashMap<>();
     ListeningExecutorService listeningExecutorService;
 
-    public void init(ConcurrentHashMap<Integer, WorkflowExecuteThread> processInstanceExecMaps) {
-
+    /**
+     * constructor","[{'comment': 'Remove this comment, we can know this is a constructor.', 'commenter': 'ruanwenjun'}]"
6546,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/EventExecuteService.java,"@@ -73,21 +80,21 @@
     private StateEventCallbackService stateEventCallbackService;
 
 
-    private ConcurrentHashMap<Integer, WorkflowExecuteThread> processInstanceExecMaps;
-    private ConcurrentHashMap<String, WorkflowExecuteThread> eventHandlerMap = new ConcurrentHashMap();
+    private ConcurrentHashMap<String, WorkflowExecuteThread> eventHandlerMap = new ConcurrentHashMap<>();
     ListeningExecutorService listeningExecutorService;
 
-    public void init(ConcurrentHashMap<Integer, WorkflowExecuteThread> processInstanceExecMaps) {
-
+    /**
+     * constructor
+     */
+    public EventExecuteService() {
         eventExecService = ThreadUtils.newDaemonFixedThreadExecutor(""MasterEventExecution"", masterConfig.getMasterExecThreads());
 
-        this.processInstanceExecMaps = processInstanceExecMaps;
-
         listeningExecutorService = MoreExecutors.listeningDecorator(eventExecService);
         this.stateEventCallbackService = SpringApplicationContext.getBean(StateEventCallbackService.class);
-
     }
 
+
+","[{'comment': 'Remove extra empty line.', 'commenter': 'ruanwenjun'}]"
6546,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/cache/ProcessInstanceExecCacheManager.java,"@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.cache;
+
+import org.apache.dolphinscheduler.server.master.runner.WorkflowExecuteThread;
+
+import java.util.Collection;
+
+/**
+ * cache of process instance id and WorkflowExecuteThread
+ */
+public interface ProcessInstanceExecCacheManager {
+
+    /**
+     * get WorkflowExecuteThread by process instance id
+     *
+     * @param processInstanceId processInstanceId
+     * @return WorkflowExecuteThread
+     */
+    WorkflowExecuteThread getByProcessInstanceId(int processInstanceId);
+
+    /**
+     * judge the process instance does it exist
+     *
+     * @param processInstanceId processInstanceId
+     * @return true - if process instance id exists in cache
+     */
+    boolean contains(int processInstanceId);
+
+    /**
+     * remove cache by process instance id
+     *
+     * @param processInstanceId processInstanceId
+     */
+    void removeByProcessInstanceId(int processInstanceId);
+
+    /**
+     * cache
+     *
+     * @param processInstanceId     processInstanceId
+     * @param workflowExecuteThread notnull
+     */
+    void cache(int processInstanceId, WorkflowExecuteThread workflowExecuteThread);","[{'comment': ""Do you want to use @Nonnull here? It seems if the workflowExecuteThread is null,  no exception thrown here.\r\n\r\nSo workflowExecuteThread is null is normal? If it's normal, it's better to tell other if the workflowExecuteThread is null, it will not be cached. The first time I saw notnull, I think it will throw an exception."", 'commenter': 'ruanwenjun'}]"
6656,dolphinscheduler-server/src/test/java/org/apache/dolphinscheduler/server/master/dispatch/host/RefreshResourceTaskTest.java,"@@ -0,0 +1,23 @@
+package org.apache.dolphinscheduler.server.master.dispatch.host;
+
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnitRunner;
+
+/**
+ * RefreshResourceTask test
+ */
+@RunWith(MockitoJUnitRunner.class)
+public class RefreshResourceTaskTest {
+
+  @Mock
+  private LowerWeightHostManager.RefreshResourceTask refreshResourceTask;
+
+  @Test
+  public void testGetHostWeightWithResult() {","[{'comment': 'Does this UT test anything :), this will not go inside the method.', 'commenter': 'ruanwenjun'}, {'comment': 'hi @ruanwenjun \r\n   updated!', 'commenter': 'Yao-MR-zz'}, {'comment': '@Yao-MR Please resolve the code style.', 'commenter': 'ruanwenjun'}, {'comment': 'And can the latest code go inside the method? It seems you still use @Mock here', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun\r\nsorry, fix it, can you help with it ?\r\n', 'commenter': 'Yao-MR-zz'}, {'comment': 'Please add RefreshResourceTaskTest in pom.xml like other UT file.', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun  done', 'commenter': 'Yao-MR-zz'}]"
6656,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/dispatch/host/LowerWeightHostManager.java,"@@ -154,6 +155,11 @@ public void run() {
         }
 
         public HostWeight getHostWeight(String addr, String workerGroup, String heartBeatInfo) {
+            if (StringUtils.isEmpty(heartBeatInfo)) {","[{'comment': ""Maybe we can change the return type of `org.apache.dolphinscheduler.server.master.registry.ServerNodeManager#getWorkerNodeInfo(java.lang.String)` to `Optional<String>` and check whether it's `Optional.isPresent()`?"", 'commenter': 'kezhenxu94'}, {'comment': '@kezhenxu94 actually yes, and this pr is for relove this issue \r\n[Bug] [MasterServer] RefreshResourceTask error by NPE #6641\r\n\r\nconsiser the interface interact with many other method, and i will open an new issue for optimize and improve the rubustness of the interface\r\nand pull a sepearte request，\r\n', 'commenter': 'Yao-MR-zz'}, {'comment': ""I agree zhenxu, use optional is better. If you think it is unnecessary to change `ServerNodeManager#getWorkerNodeInfo` in this pr, maybe it's better to change the return type of `LowerWeightHostManager.RefreshResourceTask#getHostWeight` to return  `Optional<HostWeight>`? This is a small change."", 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun @kezhenxu94 yes, it a elegent way to deal the npe with optional,\r\n\r\nand now we are better to fouce the issue releated area code, and later will consider the whole', 'commenter': 'Yao-MR-zz'}]"
6668,dolphinscheduler-python/src/main/java/org/apache/dolphinscheduler/server/PythonGatewayServer.java,"@@ -177,7 +177,7 @@ public Long createOrUpdateProcessDefinition(String userName,
         long projectCode = project.getCode();
         Map<String, Object> verifyProcessDefinitionExists = processDefinitionService.verifyProcessDefinitionName(user, projectCode, name);
 
-        if (verifyProcessDefinitionExists.get(Constants.STATUS) != Status.SUCCESS) {
+        if (verifyProcessDefinitionExists.get(Constants.STATUS) == Status.PROCESS_DEFINITION_NAME_EXIST) {","[{'comment': 'I see the code, it seems the status may also be `PROJECT_NOT_FOUNT` or `USER_NO_OPERATION_PROJECT_PERM` here?', 'commenter': 'ruanwenjun'}, {'comment': 'Hi wenjun, we would create project with assigned user before code running to this line. So I think we nearly zero percent to miss this situation. Unless other process drop project or user object after I create it just now.', 'commenter': 'zhongjiajie'}, {'comment': ""OK, I got you. \r\nI suggest adding a log if the status is neither SUCCESS and PROCESS_DEFINITION_NAME_EXIST.\r\nThis change is not mandatory, It's up to you."", 'commenter': 'ruanwenjun'}, {'comment': 'Good suggestions, I would add it to codebase, thanks', 'commenter': 'zhongjiajie'}]"
6718,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataQualityController.java,"@@ -0,0 +1,192 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.GET_DATASOURCE_OPTIONS_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.GET_RULE_FORM_CREATE_JSON_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_EXECUTE_RESULT_LIST_PAGING_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_RULE_LIST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_RULE_LIST_PAGING_ERROR;
+
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.DqExecuteResultService;
+import org.apache.dolphinscheduler.api.service.DqRuleService;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.Map;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+import springfox.documentation.annotations.ApiIgnore;
+
+/**
+ * data quality controller
+ */","[{'comment': 'This kind of JavaDoc is meaningless, please remove them all or write more useful comments', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/main/java/org/apache/dolphinscheduler/data/quality/utils/ConfigUtils.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.utils;
+
+import org.apache.dolphinscheduler.data.quality.config.Config;
+
+import java.util.LinkedHashMap;
+import java.util.Map;
+
+public class ConfigUtils {
+
+    private ConfigUtils() {
+        throw new IllegalStateException(""Construct ConfigUtils"");
+    }
+
+    /**
+     * Extract sub config with fixed prefix
+     *
+     * @param source config source
+     * @param prefix config prefix
+     * @param keepPrefix true if keep prefix
+     */
+    public static Config extractSubConfig(Config source, String prefix, boolean keepPrefix) {
+        Map<String, Object> values = new LinkedHashMap<>();
+
+        for (Map.Entry<String, Object> entry : source.entrySet()) {
+            final String key = entry.getKey();
+            final String value = String.valueOf(entry.getValue());
+
+            if (key.startsWith(prefix)) {
+                if (keepPrefix) {
+                    values.put(key, value);
+                } else {
+                    values.put(key.substring(prefix.length()), value);
+                }
+            }
+        }
+
+        return new Config(values);
+    }","[{'comment': 'This method is only used in 2 places and the method can be written in a one-line statement, maybe just inline it and not to provide too many util classes?\r\n\r\n```java\r\n               new Config(source.entrySet()\r\n                                .stream()\r\n                                .filter(it -> it.getKey().startsWith(prefix))\r\n                                .collect(toMap(it -> keepPrefix ? it.getKey() : it.getKey().substring(prefix.length()), Entry::getValue)));\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'This utils will be used more frequently with the increase of readers', 'commenter': 'zixi0825'}]"
6718,dolphinscheduler-data-quality/src/main/java/org/apache/dolphinscheduler/data/quality/utils/JsonUtils.java,"@@ -0,0 +1,78 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.utils;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_STRING_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+import static com.fasterxml.jackson.databind.SerializationFeature.FAIL_ON_EMPTY_BEANS;
+
+import java.util.TimeZone;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.fasterxml.jackson.databind.ObjectMapper;
+
+/**
+ * JsonUtil
+ */
+public class JsonUtils {
+
+    private static final Logger logger = LoggerFactory.getLogger(JsonUtils.class);
+
+    /**
+     * can use static singleton, inject: just make sure to reuse!
+     */
+    private static final ObjectMapper MAPPER = new ObjectMapper()
+            .configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(ACCEPT_EMPTY_STRING_AS_NULL_OBJECT,true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .configure(FAIL_ON_EMPTY_BEANS,false)
+            .setTimeZone(TimeZone.getDefault());
+
+    private JsonUtils() {
+        throw new UnsupportedOperationException(""Construct JSONUtils"");
+    }
+
+    public static String toJson(Object object) {","[{'comment': 'This is not used, please remove', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/main/java/org/apache/dolphinscheduler/data/quality/utils/Preconditions.java,"@@ -0,0 +1,42 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.utils;
+
+/**
+ * utility methods for validating input
+ */
+public final class Preconditions {
+
+    private Preconditions() {
+        throw new UnsupportedOperationException(""Construct Preconditions"");
+    }
+
+    /**
+     * if condition is false will throw an IllegalArgumentException with the given message
+     *
+     * @param condition condition
+     * @param errorMsg error message
+     * @throws IllegalArgumentException Thrown, if the condition is violated.
+     */
+    public static void checkArgument(boolean condition, Object errorMsg) {","[{'comment': 'Why do you choose to write again instead of using `com.google.common.base.Preconditions.checkArgument`?', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/main/java/org/apache/dolphinscheduler/data/quality/utils/StringUtils.java,"@@ -0,0 +1,45 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.utils;
+
+/**
+ * StringUtils
+ */
+public class StringUtils {","[{'comment': 'Why do you choose to write again instead of using `com.google.common.base.Strings`?', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/test/java/org/apache/dolphinscheduler/data/quality/configuration/ConfigurationParserTest.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.configuration;
+
+import org.apache.dolphinscheduler.data.quality.config.DataQualityConfiguration;
+import org.apache.dolphinscheduler.data.quality.utils.JsonUtils;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * ConfigurationParserTest
+ */
+public class ConfigurationParserTest {
+
+    @Test","[{'comment': 'You don\'t need to make it so complex, simply use this, if there is exception thrown, the test will fail\r\n\r\n```java\r\n    @Test\r\n    public void testConfigurationValidate() {\r\n        String parameterStr = ""{\\""name\\"":\\""data quality test\\"",\\""env\\"":{\\""type\\"":\\""batch\\"",\\""config\\"":null},""\r\n            + ""\\""readers\\"":[{\\""type\\"":\\""JDBC\\"",\\""config\\"":{\\""database\\"":\\""test\\"",\\""password\\"":\\""Test@123!\\"",""\r\n            + ""\\""driver\\"":\\""com.mysql.jdbc.Driver\\"",\\""user\\"":\\""test\\"",\\""output_table\\"":\\""test1\\"",\\""table\\"":\\""test1\\"",""\r\n            + ""\\""url\\"":\\""jdbc:mysql://172.16.100.199:3306/test\\""} }],\\""transformers\\"":[{\\""type\\"":\\""sql\\"",\\""config\\"":""\r\n            + ""{\\""index\\"":1,\\""output_table\\"":\\""miss_count\\"",\\""sql\\"":\\""SELECT COUNT(*) AS miss FROM test1 WHERE (c1 is null or c1 = \'\') \\""} },""\r\n            + ""{\\""type\\"":\\""sql\\"",\\""config\\"":{\\""index\\"":2,\\""output_table\\"":\\""total_count\\"",\\""sql\\"":\\""SELECT COUNT(*) AS total FROM test1 \\""} }],""\r\n            + ""\\""writers\\"":[{\\""type\\"":\\""JDBC\\"",\\""config\\"":{\\""database\\"":\\""dolphinscheduler\\"",\\""password\\"":\\""test\\"",""\r\n            + ""\\""driver\\"":\\""org.postgresql.Driver\\"",\\""user\\"":\\""test\\"",\\""table\\"":\\""t_ds_dq_execute_result\\"",""\r\n            + ""\\""url\\"":\\""jdbc:postgresql://172.16.100.199:5432/dolphinscheduler?stringtype=unspecified\\"",""\r\n            + ""\\""sql\\"":\\""SELECT 0 as rule_type,\'data quality test\' as rule_name,7 as process_definition_id,80 as process_instance_id,""\r\n            + ""80 as task_instance_id,miss_count.miss AS statistics_value, total_count.total AS comparison_value,2 as check_type,10 as""\r\n            + "" threshold, 3 as operator, 0 as failure_strategy, \'2021-06-29 10:18:59\' as create_time,\'2021-06-29 10:18:59\' as update_time ""\r\n            + ""from miss_count FULL JOIN total_count\\""} }]}"";\r\n\r\n        DataQualityConfiguration dataQualityConfiguration = JsonUtils.fromJson(parameterStr, DataQualityConfiguration.class);\r\n        dataQualityConfiguration.validate();\r\n    }\r\n```', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/test/java/org/apache/dolphinscheduler/data/quality/flow/reader/JdbcReaderTest.java,"@@ -0,0 +1,99 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.flow.reader;
+
+import static org.apache.dolphinscheduler.data.quality.Constants.DATABASE;
+import static org.apache.dolphinscheduler.data.quality.Constants.DRIVER;
+import static org.apache.dolphinscheduler.data.quality.Constants.PASSWORD;
+import static org.apache.dolphinscheduler.data.quality.Constants.TABLE;
+import static org.apache.dolphinscheduler.data.quality.Constants.URL;
+import static org.apache.dolphinscheduler.data.quality.Constants.USER;
+
+import org.apache.dolphinscheduler.data.quality.config.Config;
+import org.apache.dolphinscheduler.data.quality.flow.FlowTestBase;
+import org.apache.dolphinscheduler.data.quality.flow.batch.reader.JdbcReader;
+
+import java.sql.Connection;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+
+/**
+ * JdbcConnectorTest
+ */
+public class JdbcReaderTest extends FlowTestBase {
+
+    @Before
+    public void before() {","[{'comment': ""Missing '@Override' annotation on 'before()' "", 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/test/java/org/apache/dolphinscheduler/data/quality/flow/reader/ReaderFactoryTest.java,"@@ -0,0 +1,72 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.flow.reader;
+
+import static org.apache.dolphinscheduler.data.quality.Constants.DATABASE;
+import static org.apache.dolphinscheduler.data.quality.Constants.DRIVER;
+import static org.apache.dolphinscheduler.data.quality.Constants.PASSWORD;
+import static org.apache.dolphinscheduler.data.quality.Constants.TABLE;
+import static org.apache.dolphinscheduler.data.quality.Constants.URL;
+import static org.apache.dolphinscheduler.data.quality.Constants.USER;
+
+import org.apache.dolphinscheduler.data.quality.config.ReaderConfig;
+import org.apache.dolphinscheduler.data.quality.flow.batch.BatchReader;
+import org.apache.dolphinscheduler.data.quality.flow.batch.reader.ReaderFactory;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * ConnectorFactoryTest
+ */
+public class ReaderFactoryTest {
+
+    @Test
+    public void testConnectorGenerate() {
+
+        List<ReaderConfig> readerConfigs = new ArrayList<>();
+        ReaderConfig readerConfig = new ReaderConfig();
+        readerConfig.setType(""JDBC"");
+        Map<String,Object> config = new HashMap<>();
+        config.put(DATABASE,""test"");
+        config.put(TABLE,""test1"");
+        config.put(URL,""jdbc:mysql://localhost:3306/test"");
+        config.put(USER,""test"");
+        config.put(PASSWORD,""123456"");
+        config.put(DRIVER,""com.mysql.jdbc.Driver"");
+        readerConfig.setConfig(config);
+        readerConfigs.add(readerConfig);
+
+        int flag = 0;
+        try {
+            List<BatchReader> readers = ReaderFactory.getInstance().getReaders(null,readerConfigs);
+            if (readers != null && readers.size() >= 1) {
+                flag = 1;
+            }
+        } catch (Exception e) {
+            e.printStackTrace();
+        }
+
+        Assert.assertEquals(1,flag);","[{'comment': 'No need to write this kind of codes, just remove the `try-catch` and let it throw the exception to make the test fail', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/test/java/org/apache/dolphinscheduler/data/quality/flow/writer/JdbcWriterTest.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.flow.writer;
+
+import static org.apache.dolphinscheduler.data.quality.Constants.DATABASE;
+import static org.apache.dolphinscheduler.data.quality.Constants.DRIVER;
+import static org.apache.dolphinscheduler.data.quality.Constants.PASSWORD;
+import static org.apache.dolphinscheduler.data.quality.Constants.TABLE;
+import static org.apache.dolphinscheduler.data.quality.Constants.URL;
+import static org.apache.dolphinscheduler.data.quality.Constants.USER;
+
+import org.apache.dolphinscheduler.data.quality.config.Config;
+import org.apache.dolphinscheduler.data.quality.flow.FlowTestBase;
+import org.apache.dolphinscheduler.data.quality.flow.batch.reader.JdbcReader;
+import org.apache.dolphinscheduler.data.quality.flow.batch.writer.JdbcWriter;
+
+import java.sql.Connection;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.junit.Before;
+import org.junit.Test;
+
+/**
+ * JdbcWriterTest
+ */
+public class JdbcWriterTest extends FlowTestBase {
+
+    @Before
+    public void before() {","[{'comment': ""Missing `@Override` annotation on 'before()' "", 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/src/test/java/org/apache/dolphinscheduler/data/quality/flow/writer/WriterFactoryTest.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality.flow.writer;
+
+import org.apache.dolphinscheduler.data.quality.config.WriterConfig;
+import org.apache.dolphinscheduler.data.quality.flow.batch.BatchWriter;
+import org.apache.dolphinscheduler.data.quality.flow.batch.writer.WriterFactory;
+
+import java.util.ArrayList;
+import java.util.List;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+/**
+ * WriterFactoryTest
+ */
+public class WriterFactoryTest {
+
+    @Test
+    public void testWriterGenerate() {
+
+        List<WriterConfig> writerConfigs = new ArrayList<>();
+        WriterConfig writerConfig = new WriterConfig();
+        writerConfig.setType(""JDBC"");
+        writerConfig.setConfig(null);
+        writerConfigs.add(writerConfig);
+
+        int flag = 0;
+        try {
+            List<BatchWriter> writers = WriterFactory.getInstance().getWriters(null,writerConfigs);
+            if (writers != null && writers.size() >= 1) {
+                flag = 1;
+            }
+        } catch (Exception e) {
+            e.printStackTrace();
+        }
+
+        Assert.assertEquals(1,flag);","[{'comment': 'Same here, remove the `try-catch` block', 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-data-quality/pom.xml,"@@ -0,0 +1,162 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>2.0.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+    <artifactId>dolphinscheduler-data-quality</artifactId>
+    <name>dolphinscheduler-data-quality</name>
+
+    <packaging>jar</packaging>
+
+    <properties>
+        <jackson.version>2.9.0</jackson.version>
+        <scope>provided</scope>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.spark</groupId>
+            <artifactId>spark-core_${scala.binary.version}</artifactId>
+            <scope>${scope}</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.spark</groupId>
+            <artifactId>spark-sql_${scala.binary.version}</artifactId>
+            <scope>${scope}</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.spark</groupId>
+            <artifactId>spark-hive_${scala.binary.version}</artifactId>
+            <scope>${scope}</scope>
+            <exclusions>
+                <exclusion>
+                    <groupId>commons-httpclient</groupId>
+                    <artifactId>commons-httpclient</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.apache.httpcomponents</groupId>
+                    <artifactId>httpclient</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+        <dependency>
+            <groupId>com.fasterxml.jackson.core</groupId>
+            <artifactId>jackson-databind</artifactId>
+            <version>${jackson.version}</version>
+            <scope>${scope}</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>com.h2database</groupId>
+            <artifactId>h2</artifactId>
+            <scope>test</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>junit</groupId>
+            <artifactId>junit</artifactId>
+            <scope>test</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>mysql</groupId>
+            <artifactId>mysql-connector-java</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.postgresql</groupId>
+            <artifactId>postgresql</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>ru.yandex.clickhouse</groupId>
+            <artifactId>clickhouse-jdbc</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>com.microsoft.sqlserver</groupId>
+            <artifactId>mssql-jdbc</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>com.facebook.presto</groupId>
+            <artifactId>presto-jdbc</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.jacoco</groupId>
+            <artifactId>org.jacoco.agent</artifactId>
+            <classifier>runtime</classifier>
+            <scope>test</scope>
+        </dependency>
+    </dependencies>
+
+    <build>
+        <plugins>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-assembly-plugin</artifactId>
+                <version>2.2</version>
+                <configuration>
+                    <appendAssemblyId>false</appendAssemblyId>
+                    <descriptorRefs>
+                        <descriptorRef>jar-with-dependencies</descriptorRef>
+                    </descriptorRefs>
+                    <archive>
+                        <manifest>
+                            <mainClass>org.apache.dolphinscheduler.data.quality.DataQualityApplication</mainClass>
+                        </manifest>
+                    </archive>
+                </configuration>
+                <executions>
+                    <execution>
+                        <id>make-assembly</id>
+                        <phase>package</phase>
+                        <goals>
+                            <goal>assembly</goal>
+                        </goals>
+                    </execution>
+                </executions>
+            </plugin>
+            <plugin>
+                <artifactId>maven-source-plugin</artifactId>
+                <version>2.1</version>
+                <configuration>
+                    <attach>true</attach>
+                </configuration>
+                <executions>
+                    <execution>
+                        <phase>compile</phase>
+                        <goals>
+                            <goal>jar</goal>
+                        </goals>
+                    </execution>
+                </executions>
+            </plugin>","[{'comment': ""I don't think you need this plugin?"", 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-dist/src/main/provisio/dolphinscheduler.xml,"@@ -131,4 +131,9 @@
             <unpack/>
         </artifact>
     </artifactSet>
+    <artifactSet to=""lib/plugin/task/dataquality"">","[{'comment': ""If this is a task plugin, why don't you move the module to `dolphinscheduler-task-plugin/dolphinscheduler-data-quality`?"", 'commenter': 'kezhenxu94'}, {'comment': 'All plugin artifactset write in this file，no need move to data-quality-plugin module', 'commenter': 'zixi0825'}]"
6718,dolphinscheduler-data-quality/pom.xml,"@@ -0,0 +1,162 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>2.0.0-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+    <artifactId>dolphinscheduler-data-quality</artifactId>
+    <name>dolphinscheduler-data-quality</name>
+
+    <packaging>jar</packaging>
+
+    <properties>
+        <jackson.version>2.9.0</jackson.version>
+        <scope>provided</scope>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.spark</groupId>
+            <artifactId>spark-core_${scala.binary.version}</artifactId>
+            <scope>${scope}</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.spark</groupId>
+            <artifactId>spark-sql_${scala.binary.version}</artifactId>
+            <scope>${scope}</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.spark</groupId>
+            <artifactId>spark-hive_${scala.binary.version}</artifactId>
+            <scope>${scope}</scope>
+            <exclusions>
+                <exclusion>
+                    <groupId>commons-httpclient</groupId>
+                    <artifactId>commons-httpclient</artifactId>
+                </exclusion>
+                <exclusion>
+                    <groupId>org.apache.httpcomponents</groupId>
+                    <artifactId>httpclient</artifactId>
+                </exclusion>
+            </exclusions>
+        </dependency>
+
+        <dependency>
+            <groupId>com.fasterxml.jackson.core</groupId>
+            <artifactId>jackson-databind</artifactId>
+            <version>${jackson.version}</version>
+            <scope>${scope}</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>com.h2database</groupId>
+            <artifactId>h2</artifactId>
+            <scope>test</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>junit</groupId>
+            <artifactId>junit</artifactId>
+            <scope>test</scope>
+        </dependency>
+
+        <dependency>
+            <groupId>mysql</groupId>
+            <artifactId>mysql-connector-java</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.postgresql</groupId>
+            <artifactId>postgresql</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>ru.yandex.clickhouse</groupId>
+            <artifactId>clickhouse-jdbc</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>com.microsoft.sqlserver</groupId>
+            <artifactId>mssql-jdbc</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>com.facebook.presto</groupId>
+            <artifactId>presto-jdbc</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.jacoco</groupId>
+            <artifactId>org.jacoco.agent</artifactId>
+            <classifier>runtime</classifier>
+            <scope>test</scope>
+        </dependency>
+    </dependencies>
+
+    <build>
+        <plugins>
+            <plugin>
+                <groupId>org.apache.maven.plugins</groupId>
+                <artifactId>maven-assembly-plugin</artifactId>
+                <version>2.2</version>
+                <configuration>
+                    <appendAssemblyId>false</appendAssemblyId>
+                    <descriptorRefs>
+                        <descriptorRef>jar-with-dependencies</descriptorRef>","[{'comment': ""Please don't use this kind of package style, you will hide a lot of dependencies that might bring license issues, FYI @CalvinKirs "", 'commenter': 'kezhenxu94'}, {'comment': 'After testing, this packaging method does not hide the license problem; For example, I added mssql-jdbc to POM, but did not exclude azure-keyvault, and the license check will report an error.', 'commenter': 'zixi0825'}, {'comment': ""That's not the only reason not to use jar with dependencies, why should this module use this package style? My question is this kind of package will duplicate the dependencies in the dist tar"", 'commenter': 'kezhenxu94'}]"
6718,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/dag.scss,"@@ -15,6 +15,542 @@
  * limitations under the License.
  */
 
+.dag-model {
+  background: url(""../img/dag_bg.png"");
+  height: calc(100vh - 100px);
+  ::selection {
+    background:transparent;
+  }
+  ::-moz-selection {
+    background:transparent;
+  }
+  ::-webkit-selection {
+    background:transparent;
+  }
+  .jsplumb-connector {
+    z-index: 1;
+  }
+  .endpoint-tasks {
+    margin-top:22px;
+  }
+  .draggable {
+    > span {
+      text-align: center;
+      display: block;
+      margin-top: -4px;
+      padding: 0 4px;
+      width: 200px;
+      margin-left: -81px;
+      position: absolute;
+      left: 0;
+      bottom: -12px;
+    }
+    .fa {
+      display: inline-block;
+      position: absolute;
+      right: -8px;
+      top: -8px;
+      z-index: 2;
+      cursor: pointer;
+    }
+    .icos {
+      display: inline-block;
+      cursor: pointer;
+    }
+    &.active-tasks {
+      span {
+        color: #0296DF;
+      }
+    }
+  }
+  .icos {
+    width: 32px;
+    height: 32px;
+    margin: 2px;
+    border-radius: 3px;
+    position: relative;
+    z-index: 9;
+  }
+  .icos-SHELL {
+    background: url(""../img/toolbar_SHELL.png"") no-repeat 50% 50%;
+  }
+  .icos-WATERDROP {
+    background: url(""../img/toolbar_WATERDROP.png"") no-repeat 50% 50%;","[{'comment': 'This icon cannot be found locally.', 'commenter': 'songjianet'}]"
6718,pom.xml,"@@ -111,6 +111,8 @@
         <springfox.version>2.9.2</springfox.version>
         <swagger-models.version>1.5.24</swagger-models.version>
         <guava-retry.version>2.0.0</guava-retry.version>
+        <scala.binary.version>2.11</scala.binary.version>
+        <spark.version>2.4.0</spark.version>","[{'comment': 'Can Spark and scala jar move to dataquality module?', 'commenter': 'davidzollo'}]"
6718,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/TaskType.java,"@@ -55,7 +57,8 @@
     SQOOP(12, ""SQOOP""),
     SEATUNNEL(13, ""SEATUNNEL""),
     SWITCH(14, ""SWITCH""),
-    PIGEON(15, ""PIGEON"");
+    PIGEON(15, ""PIGEON""),
+    DATA_QUALITY(16, ""data_quality"");","[{'comment': '```suggestion\r\n    DATA_QUALITY(16, ""DATA_QUALITY"");\r\n```', 'commenter': 'caishunfeng'}]"
6718,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/DqExecuteResultMapper.xml,"@@ -0,0 +1,65 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+
+<!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd"" >
+<mapper namespace=""org.apache.dolphinscheduler.dao.mapper.DqExecuteResultMapper"">
+    <select id=""queryResultListPaging"" resultType=""org.apache.dolphinscheduler.dao.entity.DqExecuteResult"">
+        SELECT a.id, a.process_definition_id, b.name as process_definition_name, b.code as process_definition_code, a.process_instance_id, e.name as process_instance_name,a.task_instance_id, c.name as task_name, a.rule_type, a.rule_name, a.statistics_value, a.comparison_value, a.check_type,
+        a.threshold , cp.type as comparison_type_name,
+        a.operator, a.failure_strategy, a.state, a.user_id, d.user_name, a.create_time, a.update_time
+        FROM t_ds_dq_execute_result a
+        left join (select id,name,code from t_ds_process_definition) b on a.process_definition_id = b.id","[{'comment': 'why to use sub query like `(select id,name,code from t_ds_process_definition) b` but not left join `t_ds_process_definition` directly?', 'commenter': 'caishunfeng'}, {'comment': 'and I think maybe you can check the processDefinition early in code, which can reduce the sql join.', 'commenter': 'caishunfeng'}]"
6718,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/DqExecuteResultMapper.xml,"@@ -0,0 +1,65 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+
+<!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd"" >
+<mapper namespace=""org.apache.dolphinscheduler.dao.mapper.DqExecuteResultMapper"">
+    <select id=""queryResultListPaging"" resultType=""org.apache.dolphinscheduler.dao.entity.DqExecuteResult"">
+        SELECT a.id, a.process_definition_id, b.name as process_definition_name, b.code as process_definition_code, a.process_instance_id, e.name as process_instance_name,a.task_instance_id, c.name as task_name, a.rule_type, a.rule_name, a.statistics_value, a.comparison_value, a.check_type,
+        a.threshold , cp.type as comparison_type_name,
+        a.operator, a.failure_strategy, a.state, a.user_id, d.user_name, a.create_time, a.update_time
+        FROM t_ds_dq_execute_result a
+        left join (select id,name,code from t_ds_process_definition) b on a.process_definition_id = b.id
+        left join (select id,name from t_ds_task_instance) c on a.task_instance_id = c.id
+        left join t_ds_process_instance e on a.process_instance_id = e.id
+        left join t_ds_user d on d.id = a.user_id
+        left join t_ds_dq_comparison_type cp on cp.id = a.comparison_type
+        <where>
+            <if test="" searchVal != null and searchVal != ''"">
+                and c.name like concat('%', #{searchVal}, '%')
+            </if>
+            <if test=""startTime != null "">
+                and a.update_time > #{startTime} and a.update_time <![CDATA[ <=]]> #{endTime}
+            </if>
+            <if test=""states != null and states != ''"">
+                and a.state in
+                <foreach collection=""states"" index=""index"" item=""i"" open=""("" separator="","" close="")"">
+                    #{i}
+                </foreach>
+            </if>
+            <if test="" userId != 1"">
+                and a.user_id = #{userId}
+            </if>
+            <if test="" ruleType != -1"">
+                and a.rule_type = #{ruleType}
+            </if>
+        </where>
+        order by a.update_time desc
+    </select>
+
+    <select id=""getExecuteResultById"" resultType=""org.apache.dolphinscheduler.dao.entity.DqExecuteResult"">
+        SELECT a.*, b.name as process_definition_name, e.name as process_instance_name, c.name as task_name,
+        cp.type as comparison_type_name, d.user_name
+        FROM t_ds_dq_execute_result a
+        left join (select id,name from t_ds_process_definition) b on a.process_definition_id = b.id","[{'comment': 'the same question', 'commenter': 'caishunfeng'}]"
6718,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/DqRuleInputEntryMapper.xml,"@@ -0,0 +1,27 @@
+<?xml version=""1.0"" encoding=""UTF-8"" ?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+
+<!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd"" >
+<mapper namespace=""org.apache.dolphinscheduler.dao.mapper.DqRuleInputEntryMapper"">
+
+    <select id=""getRuleInputEntryList"" resultType=""org.apache.dolphinscheduler.dao.entity.DqRuleInputEntry"">
+        SELECT * , b.values_map, b.index FROM t_ds_dq_rule_input_entry a join ( SELECT *","[{'comment': 'avoid to use `*`', 'commenter': 'caishunfeng'}]"
6718,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -994,6 +994,784 @@ CREATE TABLE `t_ds_alert_plugin_instance` (
   PRIMARY KEY (`id`)
 ) ENGINE=InnoDB DEFAULT CHARSET=utf8;
 
+--
+-- Table structure for table `t_ds_dq_comparison_type`
+--
+DROP TABLE IF EXISTS `t_ds_dq_comparison_type`;
+CREATE TABLE `t_ds_dq_comparison_type` (
+    `id` int(11) NOT NULL AUTO_INCREMENT,
+    `type` varchar(100) NOT NULL,
+    `execute_sql` text DEFAULT NULL,
+    `output_table` varchar(100) DEFAULT NULL,
+    `name` varchar(100) DEFAULT NULL,
+    `create_time` datetime DEFAULT NULL,
+    `update_time` datetime DEFAULT NULL,
+    `is_inner_source` tinyint(1) DEFAULT '0',
+    PRIMARY KEY (`id`)
+)ENGINE=InnoDB DEFAULT CHARSET=utf8;
+
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(1, 'FixValue', NULL, NULL, NULL, '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', false);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(2, 'DailyFluctuation', 'select round(avg(statistics_value),2) as day_avg from t_ds_dq_task_statistics_value where data_time >=date_trunc(''DAY'', ${data_time}) and data_time < date_add(date_trunc(''day'', ${data_time}),1) and unique_code = ${unique_code} and statistics_name = ''${statistics_name}''', 'day_range', 'day_range.day_avg', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', true);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(3, 'WeeklyFluctuation', 'select round(avg(statistics_value),2) as week_avg from t_ds_dq_task_statistics_value where  data_time >= date_trunc(''WEEK'', ${data_time}) and data_time <date_trunc(''day'', ${data_time}) and unique_code = ${unique_code} and statistics_name = ''${statistics_name}''', 'week_range', 'week_range.week_avg', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', true);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(4, 'MonthlyFluctuation', 'select round(avg(statistics_value),2) as month_avg from t_ds_dq_task_statistics_value where  data_time >= date_trunc(''MONTH'', ${data_time}) and data_time <date_trunc(''day'', ${data_time}) and unique_code = ${unique_code} and statistics_name = ''${statistics_name}''', 'month_range', 'month_range.month_avg', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', true);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(5, 'Last7DayFluctuation', 'select round(avg(statistics_value),2) as last_7_avg from t_ds_dq_task_statistics_value where  data_time >= date_add(date_trunc(''day'', ${data_time}),-7) and  data_time <date_trunc(''day'', ${data_time}) and unique_code = ${unique_code} and statistics_name = ''${statistics_name}''', 'last_seven_days', 'last_seven_days.last_7_avg', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', true);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(6, 'Last30DayFluctuation', 'select round(avg(statistics_value),2) as last_30_avg from t_ds_dq_task_statistics_value where  data_time >= date_add(date_trunc(''day'', ${data_time}),-30) and  data_time < date_trunc(''day'', ${data_time}) and unique_code = ${unique_code} and statistics_name = ''${statistics_name}''', 'last_thirty_days', 'last_thirty_days.last_30_avg', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', true);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(7, 'SrcTableTotalRows', 'SELECT COUNT(*) AS total FROM ${src_table} WHERE (${src_filter})', 'total_count', 'total_count.total', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', false);
+INSERT INTO `t_ds_dq_comparison_type`
+(`id`, `type`, `execute_sql`, `output_table`, `name`, `create_time`, `update_time`, `is_inner_source`)
+VALUES(8, 'TargetTableTotalRows', 'SELECT COUNT(*) AS total FROM ${target_table} WHERE (${target_filter})', 'total_count', 'total_count.total', '2021-06-30 00:00:00.000', '2021-06-30 00:00:00.000', false);
+
+--
+-- Table structure for table `t_ds_dq_execute_result`
+--
+DROP TABLE IF EXISTS `t_ds_dq_execute_result`;
+CREATE TABLE `t_ds_dq_execute_result` (
+    `id` int(11) NOT NULL AUTO_INCREMENT,
+    `process_definition_id` int(11) DEFAULT NULL,
+    `process_instance_id` int(11) DEFAULT NULL,
+    `task_instance_id` int(11) DEFAULT NULL,
+    `rule_type` int(11) DEFAULT NULL,
+    `rule_name` varchar(255) DEFAULT NULL,
+    `statistics_value` double DEFAULT NULL,
+    `comparison_value` double DEFAULT NULL,
+    `check_type` int(11) DEFAULT NULL,
+    `threshold` double DEFAULT NULL,
+    `operator` int(11) DEFAULT NULL,
+    `failure_strategy` int(11) DEFAULT NULL,
+    `state` int(11) DEFAULT NULL,
+    `user_id` int(11) DEFAULT NULL,
+    `comparison_type` int(11) DEFAULT NULL,
+    `error_output_path` text DEFAULT NULL,
+    `create_time` datetime DEFAULT NULL,
+    `update_time` datetime DEFAULT NULL,
+    PRIMARY KEY (`id`)
+) ENGINE=InnoDB DEFAULT CHARSET=utf8;
+
+--
+-- Table structure for table t_ds_dq_rule
+--
+DROP TABLE IF EXISTS `t_ds_dq_rule`;
+CREATE TABLE `t_ds_dq_rule` (
+    `id` int(11) NOT NULL AUTO_INCREMENT,
+    `name` varchar(100) DEFAULT NULL,
+    `type` int(11) DEFAULT NULL,
+    `user_id` int(11) DEFAULT NULL,
+    `create_time` datetime DEFAULT NULL,
+    `update_time` datetime DEFAULT NULL,
+    PRIMARY KEY (`id`)
+) ENGINE=InnoDB DEFAULT CHARSET=utf8;
+
+INSERT INTO `t_ds_dq_rule`
+(`id`, `name`, `type`, `user_id`, `create_time`, `update_time`)
+VALUES(1, '$t(null_check)', 0, 1, '2020-01-12 00:00:00.000', '2020-01-12 00:00:00.000');","[{'comment': 'is it necessary to assign id?', 'commenter': 'caishunfeng'}, {'comment': 'Yes, because this id needs to be used to associate rules_ input_ entry and rule_ execute_ sql', 'commenter': 'zixi0825'}]"
6718,dolphinscheduler-data-quality/src/main/java/org/apache/dolphinscheduler/data/quality/DataQualityApplication.java,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.data.quality;
+
+import static org.apache.dolphinscheduler.data.quality.Constants.SPARK_APP_NAME;
+
+import org.apache.dolphinscheduler.data.quality.config.Config;
+import org.apache.dolphinscheduler.data.quality.config.DataQualityConfiguration;
+import org.apache.dolphinscheduler.data.quality.config.EnvConfig;
+import org.apache.dolphinscheduler.data.quality.context.DataQualityContext;
+import org.apache.dolphinscheduler.data.quality.execution.SparkRuntimeEnvironment;
+import org.apache.dolphinscheduler.data.quality.utils.JsonUtils;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.base.Strings;
+
+/**
+ * DataQualityApplication
+ */
+public class DataQualityApplication {","[{'comment': 'can you add some detail comments for `DataQualityApplication`?', 'commenter': 'caishunfeng'}]"
6731,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -258,6 +258,14 @@ private Constants() {
     public static final String YYYY_MM_DD_HH_MM_SS = ""yyyy-MM-dd HH:mm:ss"";
 
 
+
+    /**
+     * date format of yyyyMMdd
+     */
+    public static final String YYYYMMDD = ""yyyyMMdd"";
+
+
+","[{'comment': 'Remove the extra blank lines and only keep one blank line', 'commenter': 'kezhenxu94'}]"
6731,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -258,6 +258,14 @@ private Constants() {
     public static final String YYYY_MM_DD_HH_MM_SS = ""yyyy-MM-dd HH:mm:ss"";
 
 
+","[{'comment': 'Remove the extra blank lines and only keep one blank line.\r\n\r\nBTW, @zhongjiajie can you please set up a code style rule to only allow at most one blank line between member fields / methods?', 'commenter': 'kezhenxu94'}, {'comment': '👌 , would try today', 'commenter': 'zhongjiajie'}]"
6731,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/DateUtils.java,"@@ -506,6 +506,16 @@ public static TimeZone getTimezone(String timezoneId) {
         return TimeZone.getTimeZone(timezoneId);
     }
 
+    /**
+     * get specify date
+     */
+    public static Date getSpecifyDate(int year, int month, int date) {","[{'comment': ""Please, this method is only for test, it's not necessary to add this method to increase maintainers' burden, please just move it into the test."", 'commenter': 'kezhenxu94'}]"
6731,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/LoggerUtils.java,"@@ -71,12 +72,14 @@ private LoggerUtils() {
      * @return task id format
      */
     public static String buildTaskId(String affix,
+                                     Date firstSubmitTime,
                                      Long processDefineCode,
                                      int processDefineVersion,
                                      int processInstId,
                                      int taskId) {
-        // - [taskAppId=TASK-798_1-4084-15210]
-        return String.format("" - %s%s-%s_%s-%s-%s]"", TASK_APPID_LOG_FORMAT, affix, processDefineCode, processDefineVersion, processInstId, taskId);
+        // - [taskAppId=TASK-20211107-798_1-4084-15210]
+        String firstSubmitTimeStr = DateUtils.format(firstSubmitTime, Constants.YYYYMMDD);
+        return String.format("" - %s%s-%s-%s_%s-%s-%s]"", TASK_APPID_LOG_FORMAT, affix, firstSubmitTimeStr, processDefineCode, processDefineVersion, processInstId, taskId);","[{'comment': 'LGTM, \r\nbut why not use all `-` here? Use `_` here is just want to split?', 'commenter': 'ruanwenjun'}, {'comment': 'Maybe we could found it git history to check out why', 'commenter': 'zhongjiajie'}, {'comment': 'Before org.apache.dolphinscheduler.server.log.TaskLogDiscriminator#getDiscriminatingValue replace `-` with `/`', 'commenter': 'choucmei'}, {'comment': ""I mean why not use a consistent separator?  The current log looks like `453920594116992_1-1-1.log`, I prefer `453920594116992-1-1-1.log`. This maybe a history issue.\r\nAnyway, it is not a big deal, maybe I like to use consistent separator.\r\n\r\nIt's better to extract code from `LogUtils` and `LoggerUtils`, otherwise it may easy to generate bug if someone change the path.\r\nIt can be a future job."", 'commenter': 'ruanwenjun'}, {'comment': ""> I mean why not use a consistent separator? The current log looks like `453920594116992_1-1-1.log`, I prefer `453920594116992-1-1-1.log`. This maybe a history issue. Anyway, it is not a big deal, maybe I like to use consistent separator.\r\n> \r\n> It's better to extract code from `LogUtils` and `LoggerUtils`, otherwise it may easy to generate bug if someone change the path. It can be a future job.\r\n\r\nI agree,i am confused about `LogUtils` and `LoggerUtils`  when i do this feature."", 'commenter': 'choucmei'}, {'comment': ' > I agree,i am confused about `LogUtils` and `LoggerUtils` when i do this feature.\r\n\r\n@choucmei Do you want to submit a PR to fix this confused thinks?', 'commenter': 'zhongjiajie'}]"
6805,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProjectController.java,"@@ -265,7 +265,7 @@ public Result queryProjectCreatedAndAuthorizedByUser(@ApiIgnore @RequestAttribut
     @ApiException(LOGIN_USER_QUERY_PROJECT_LIST_PAGING_ERROR)
     @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
     public Result queryAllProjectList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {
-        Map<String, Object> result = projectService.queryAllProjectList();
+        Map<String, Object> result = projectService.queryAllProjectList(loginUser);","[{'comment': 'there are some situations that we need the all projects without login user.\r\nso i think this is no necessary.', 'commenter': 'lenboo'}, {'comment': 'If this interface has no permission control, then you are right and this is no necessary, I have removed it in the new commit', 'commenter': 'xianweiY'}]"
6805,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/mapper/ProjectMapper.java,"@@ -114,7 +114,7 @@
     ProjectUser queryProjectWithUserByProcessInstanceId(@Param(""processInstanceId"") int processInstanceId);
 
     /**
-     * query all project
+     * query all project,only admin user can use this method, Other users query all projects use {@link ProjectMapper#queryProjectCreatedAndAuthorizedByUserId(int)}","[{'comment': 'not only admin can use this api.', 'commenter': 'lenboo'}, {'comment': 'if now anyone can use this method to query all projects , this comment is wrong, i have remove', 'commenter': 'xianweiY'}]"
6806,dolphinscheduler-dao/src/main/resources/sql/upgrade/2.0.0_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -210,7 +210,7 @@ BEGIN
 	)';
 
 	EXECUTE 'CREATE TABLE IF NOT EXISTS '|| quote_ident(v_schema) ||'.""t_ds_task_definition"" (
-	  id int NOT NULL  ,
+	  id serial int NOT NULL  ,","[{'comment': 'id serial not null or id serial', 'commenter': 'GaoTianDuo'}, {'comment': '> id serial not null or id serial\r\n\r\nthanks for reminding!', 'commenter': 'lenboo'}]"
6806,dolphinscheduler-dao/src/main/resources/sql/upgrade/2.0.0_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -298,6 +298,17 @@ BEGIN
 	  update_time timestamp DEFAULT NULL ,
 	  PRIMARY KEY (id)
 	)';
+
+	EXECUTE 'CREATE TABLE IF NOT EXISTS '|| quote_ident(v_schema) ||'.""t_ds_worker_group"" (
+      id serial int(11) NOT NULL,","[{'comment': 'in postgres please use int or bigint  exp: id  int not null', 'commenter': 'GaoTianDuo'}]"
6972,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/future/ResponseFuture.java,"@@ -105,6 +105,10 @@ public static ResponseFuture getFuture(long opaque) {
         return FUTURE_TABLE.get(opaque);
     }
 
+    public void removeFuture(){","[{'comment': 'Please solve Code Style\r\n```\r\nhttps://dolphinscheduler.apache.org/zh-cn/community/development/pull-request.html\r\n```', 'commenter': 'zhuangchong'}]"
7111,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -590,6 +590,60 @@ public Result queryUserList(User loginUser, String searchVal, Integer pageNo, In
         return result;
     }
 
+    /**
+     * grant project by code
+     *
+     * @param loginUser login user
+     * @param userId user id
+     * @param projectCodes project code array
+     * @return grant result code
+     */
+    @Override
+    @Transactional(rollbackFor = RuntimeException.class)
+    public Map<String, Object> grantProjectByCode(final User loginUser, final int userId, final String projectCodes) {
+        Map<String, Object> result = new HashMap<>();
+        result.put(Constants.STATUS, false);
+
+        // 1. only admin can operate
+        if (this.check(result, !this.isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)) {
+            return result;
+        }
+
+        // 2. check if user is existed
+        User tempUser = this.userMapper.selectById(userId);
+        if (tempUser == null) {
+            putMsg(result, Status.USER_NOT_EXIST, userId);
+            return result;
+        }
+
+        // 3. if the selected projectCodes are empty, delete all items associated with the user
+        if (this.check(result, StringUtils.isEmpty(projectCodes), Status.SUCCESS)) {
+            this.projectUserMapper.deleteProjectRelation(0, userId);
+            return result;
+        }
+
+        // 4. maintain the relationship between project and user
+        String[] projectCodeArr = projectCodes.split("","");
+        for (String projectCode : projectCodeArr) {","[{'comment': 'I think there should be elegant writing here', 'commenter': 'brave-lee'}, {'comment': 'changed to `for (String projectCode : projectCodes.split("",""))`', 'commenter': 'ouyangyewei429'}]"
7111,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -590,6 +590,60 @@ public Result queryUserList(User loginUser, String searchVal, Integer pageNo, In
         return result;
     }
 
+    /**
+     * grant project by code
+     *
+     * @param loginUser login user
+     * @param userId user id
+     * @param projectCodes project code array
+     * @return grant result code
+     */
+    @Override
+    @Transactional(rollbackFor = RuntimeException.class)","[{'comment': 'There should be exceptions displayed in the code, otherwise `Transactional` will not work', 'commenter': 'brave-lee'}]"
7111,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -590,6 +590,58 @@ public Result queryUserList(User loginUser, String searchVal, Integer pageNo, In
         return result;
     }
 
+    /**
+     * grant project by code
+     *
+     * @param loginUser login user
+     * @param userId user id
+     * @param projectCodes project code array
+     * @return grant result code
+     */
+    @Override
+    public Map<String, Object> grantProjectByCode(final User loginUser, final int userId, final String projectCodes) {
+        Map<String, Object> result = new HashMap<>();
+        result.put(Constants.STATUS, false);
+
+        // 1. only admin can operate
+        if (this.check(result, !this.isAdmin(loginUser), Status.USER_NO_OPERATION_PERM)) {
+            return result;
+        }
+
+        // 2. check if user is existed
+        User tempUser = this.userMapper.selectById(userId);
+        if (tempUser == null) {
+            putMsg(result, Status.USER_NOT_EXIST, userId);
+            return result;
+        }
+
+        // 3. if the selected projectCodes are empty, delete all items associated with the user
+        if (this.check(result, StringUtils.isEmpty(projectCodes), Status.SUCCESS)) {
+            this.projectUserMapper.deleteProjectRelation(0, userId);
+            return result;
+        }
+
+        // 4. maintain the relationship between project and user
+        for (String projectCode : projectCodes.split("","")) {","[{'comment': 'I recommend to use `Constants.COMMA` here\r\nhttps://github.com/apache/dolphinscheduler/blob/0dcff1425a28da0ce0004fc3e594b97d080c5fd9/dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java#L160', 'commenter': 'zhongjiajie'}]"
7221,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskDefinitionLogMapper.xml,"@@ -47,6 +47,9 @@
                 and version = #{item.version})
             </foreach>
         </if>
+        <if test=""taskDefinitions == null or taskDefinitions.size == 0"">","[{'comment': 'Judge taskDefinitions as a required parameter, please add it to the business layer.', 'commenter': 'zhuangchong'}, {'comment': 'OK', 'commenter': 'brave-lee'}]"
7226,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/formModel.vue,"@@ -550,7 +554,18 @@
         backfillRefresh: true,
         // whether this is a new Task
         isNewCreate: true,
-        tasksTypeList: Object.keys(tasksType)
+        tasksTypeList: Object.keys(tasksType),
+        helpUrlEnable: function (typeKey) {","[{'comment': 'typekey => {}', 'commenter': 'songjianet'}, {'comment': 'Functions should be written in methods. [methods](https://cn.vuejs.org/v2/api/#methods)', 'commenter': 'wangyizhi1'}, {'comment': 'ok', 'commenter': 'baisui1981'}, {'comment': 'then when i add  **methods** ,vue module throw an exception as blow, is there something invalid for me ?\r\n```\r\nvue.runtime.esm.js?2b0e:1897 TypeError: _vm.helpUrlEnable is not a function\r\n    at Proxy.render (formModel.vue?d1b5:22)\r\n    at VueComponent.Vue._render (vue.runtime.esm.js?2b0e:3569)\r\n    at VueComponent.updateComponent (vue.runtime.esm.js?2b0e:4081)\r\n    at Watcher.get (vue.runtime.esm.js?2b0e:4495)\r\n    at new Watcher (vue.runtime.esm.js?2b0e:4484)\r\n    at mountComponent (vue.runtime.esm.js?2b0e:4088)\r\n    at VueComponent.Vue.$mount (vue.runtime.esm.js?2b0e:8459)\r\n    at init (vue.runtime.esm.js?2b0e:3137)\r\n    at createComponent (vue.runtime.esm.js?2b0e:6022)\r\n    at createElm (vue.runtime.esm.js?2b0e:5969)\r\n```', 'commenter': 'baisui1981'}, {'comment': 'ok, i have catch your idea, and have modified it', 'commenter': 'baisui1981'}]"
7226,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/formModel.vue,"@@ -550,7 +554,18 @@
         backfillRefresh: true,
         // whether this is a new Task
         isNewCreate: true,
-        tasksTypeList: Object.keys(tasksType)
+        tasksTypeList: Object.keys(tasksType),
+        helpUrlEnable: function (typeKey) {
+          let type = tasksType[typeKey]","[{'comment': 'const type = tasksType[typeKey]', 'commenter': 'songjianet'}, {'comment': 'ok', 'commenter': 'baisui1981'}]"
7226,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/formModel.vue,"@@ -550,7 +554,18 @@
         backfillRefresh: true,
         // whether this is a new Task
         isNewCreate: true,
-        tasksTypeList: Object.keys(tasksType)
+        tasksTypeList: Object.keys(tasksType),
+        helpUrlEnable: function (typeKey) {
+          let type = tasksType[typeKey]
+          if (type) {
+            let disabled = !!type.helperLinkDisable
+            return !disabled
+          }
+          return false","[{'comment': ""if (!type) return false\r\n\r\nconst disabled = !! type.helperLinkDisable\r\nreturn !disabled\r\n\r\nThere are three inversion operations here, can't it be simplified?"", 'commenter': 'songjianet'}, {'comment': 'ok , has been modified\r\n``` javascript\r\nhelpUrlEnable: function (typeKey) {\r\n          const type = tasksType[typeKey]\r\n          if (type) {\r\n            if (!type.helperLinkDisable) return true\r\n            return !type.helperLinkDisable\r\n          }\r\n          return false\r\n        },\r\n```', 'commenter': 'baisui1981'}]"
7226,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/formModel.vue,"@@ -550,7 +554,18 @@
         backfillRefresh: true,
         // whether this is a new Task
         isNewCreate: true,
-        tasksTypeList: Object.keys(tasksType)
+        tasksTypeList: Object.keys(tasksType),
+        helpUrlEnable: function (typeKey) {
+          let type = tasksType[typeKey]
+          if (type) {
+            let disabled = !!type.helperLinkDisable
+            return !disabled
+          }
+          return false
+        },
+        helpUrl: function (tskType) {","[{'comment': 'tasktype => {}\r\n\r\nHere `tsktype` should be replaced with `tasktype`.', 'commenter': 'songjianet'}, {'comment': 'ok', 'commenter': 'baisui1981'}]"
7226,dolphinscheduler-ui/src/js/conf/home/pages/dag/_source/formModel/formModel.vue,"@@ -17,7 +17,10 @@
 <template>
   <div class=""form-model-wrapper"" v-clickoutside=""_handleClose"">
     <div class=""title-box"">
-      <span class=""name"">{{ $t(""Current node settings"") }}</span>
+      <span class=""name"">{{ $t(""Current node settings"") }}
+        <a v-if=""helpUrlEnable(nodeData.taskType)"" class=""helper-link"" target=""_blank""
+           :href=""helpUrl(nodeData.taskType)"">?{{nodeData.taskType}} {{ $t('Instructions') }}</a>","[{'comment': 'It is recommended to change the question mark to an icon. The icon can be set in the same style as the text.\r\n``` vue\r\n<a v-if=""helpUrlEnable(nodeData.taskType)"" class=""helper-link"" target=""_blank"" :href=""helpUrl(nodeData.taskType)"">\r\n  <i class=""el-icon-question"" />\r\n  {{nodeData.taskType}} {{ $t(\'Instructions\') }}\r\n</a>\r\n```', 'commenter': 'songjianet'}, {'comment': 'tks, you have provided so beautify icon', 'commenter': 'baisui1981'}]"
7258,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/MasterServer.java,"@@ -56,6 +56,7 @@
 })
 @EnableTransactionManagement
 @EnableCaching
+@EnableScheduling","[{'comment': 'remove', 'commenter': 'caishunfeng'}]"
7258,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -0,0 +1,136 @@
+package org.apache.dolphinscheduler.server.master.runner;
+
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.common.enums.StateEvent;
+import org.apache.dolphinscheduler.common.enums.StateEventType;
+import org.apache.dolphinscheduler.common.utils.NetUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.remote.command.StateEventChangeCommand;
+import org.apache.dolphinscheduler.remote.processor.StateEventCallbackService;
+import org.apache.dolphinscheduler.server.master.cache.ProcessInstanceExecCacheManager;
+import org.apache.dolphinscheduler.server.master.config.MasterConfig;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+
+import org.apache.commons.lang.StringUtils;
+
+import java.util.Map;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
+import org.springframework.stereotype.Component;
+import org.springframework.util.concurrent.ListenableFuture;
+import org.springframework.util.concurrent.ListenableFutureCallback;
+
+@Component
+public class WorkflowExecuteThreadPool extends ThreadPoolTaskExecutor {
+
+    private static final Logger logger = LoggerFactory.getLogger(WorkflowExecuteThreadPool.class);
+
+    @Autowired
+    private MasterConfig masterConfig;
+
+    @Autowired
+    private ProcessService processService;
+
+    @Autowired
+    private ProcessInstanceExecCacheManager processInstanceExecCacheManager;
+
+    @Autowired
+    private StateEventCallbackService stateEventCallbackService;
+
+    @PostConstruct
+    private void init() {
+        this.setDaemon(true);
+        this.setThreadNamePrefix(""Master-Exec-Thread-"");
+        this.setMaxPoolSize(masterConfig.getExecThreads());
+        this.setCorePoolSize(masterConfig.getExecThreads());
+    }
+
+    /**
+     * submit state event
+     */
+    public void submitStateEvent(StateEvent stateEvent) {
+        WorkflowExecuteThread workflowExecuteThread = processInstanceExecCacheManager.getByProcessInstanceId(stateEvent.getProcessInstanceId());
+        if (workflowExecuteThread != null) {","[{'comment': 'add warn log if workflowExecuteThread is null', 'commenter': 'caishunfeng'}]"
7258,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.runner;
+
+import org.apache.dolphinscheduler.common.enums.ExecutionStatus;
+import org.apache.dolphinscheduler.common.enums.Flag;
+import org.apache.dolphinscheduler.common.enums.StateEvent;
+import org.apache.dolphinscheduler.common.enums.StateEventType;
+import org.apache.dolphinscheduler.common.utils.NetUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.remote.command.StateEventChangeCommand;
+import org.apache.dolphinscheduler.remote.processor.StateEventCallbackService;
+import org.apache.dolphinscheduler.server.master.cache.ProcessInstanceExecCacheManager;
+import org.apache.dolphinscheduler.server.master.config.MasterConfig;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+
+import org.apache.commons.lang.StringUtils;
+
+import java.util.Map;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor;
+import org.springframework.stereotype.Component;
+import org.springframework.util.concurrent.ListenableFuture;
+import org.springframework.util.concurrent.ListenableFutureCallback;
+
+@Component
+public class WorkflowExecuteThreadPool extends ThreadPoolTaskExecutor {
+
+    private static final Logger logger = LoggerFactory.getLogger(WorkflowExecuteThreadPool.class);
+
+    @Autowired
+    private MasterConfig masterConfig;
+
+    @Autowired
+    private ProcessService processService;
+
+    @Autowired
+    private ProcessInstanceExecCacheManager processInstanceExecCacheManager;
+
+    @Autowired
+    private StateEventCallbackService stateEventCallbackService;
+
+    @PostConstruct
+    private void init() {
+        this.setDaemon(true);
+        this.setThreadNamePrefix(""Master-Exec-Thread-"");","[{'comment': 'Is thread name need to be more closer to the expression of this class?', 'commenter': 'lenboo'}]"
7258,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/processor/queue/StateEventResponseService.java,"@@ -142,18 +146,14 @@ private void persist(StateEvent stateEvent) {
                     break;
                 default:
             }
-            workflowExecuteThread.addStateEvent(stateEvent);
+            workflowExecuteThreadPool.submitStateEvent(stateEvent);","[{'comment': 'events in one workflow need to be handled in one thread.', 'commenter': 'lenboo'}, {'comment': 'I keep the event loop logic for it. Please review again.', 'commenter': 'caishunfeng'}]"
7258,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/StateWheelExecuteThread.java,"@@ -74,30 +84,83 @@ public void run() {
             } catch (Exception e) {
                 logger.error(""state wheel thread check error:"", e);
             }
-            ThreadUtil.sleepAtLeastIgnoreInterrupts(stateCheckIntervalSecs);
+            ThreadUtil.sleepAtLeastIgnoreInterrupts((long) masterConfig.getStateWheelInterval() * Constants.SLEEP_TIME_MILLIS);
         }
     }
 
     public void addProcess4TimeoutCheck(ProcessInstance processInstance) {
-        this.processInstanceTimeoutCheckList.put(processInstance.getId(), processInstance);
+        processInstanceTimeoutCheckList.add(processInstance.getId());
+    }
+
+    public void removeProcess4TimeoutCheck(ProcessInstance processInstance) {
+        processInstanceTimeoutCheckList.remove(processInstance.getId());
     }
 
     public void addTask4TimeoutCheck(TaskInstance taskInstance) {
-        this.taskInstanceTimeoutCheckList.put(taskInstance.getId(), taskInstance);
+        if (taskInstanceTimeoutCheckList.containsKey(taskInstance.getId())) {
+            return;
+        }
+        TaskDefinition taskDefinition = taskInstance.getTaskDefine();
+        if (taskDefinition == null) {
+            logger.error(""taskDefinition is null, taskId:{}"", taskInstance.getId());
+            return;
+        }
+        if (TimeoutFlag.OPEN == taskDefinition.getTimeoutFlag()) {
+            taskInstanceTimeoutCheckList.put(taskInstance.getId(), taskInstance.getProcessInstanceId());
+        }
+        if (taskInstance.isDependTask() || taskInstance.isSubProcess()) {
+            taskInstanceTimeoutCheckList.put(taskInstance.getId(), taskInstance.getProcessInstanceId());
+        }
+    }
+
+    public void removeTask4TimeoutCheck(TaskInstance taskInstance) {
+        taskInstanceTimeoutCheckList.remove(taskInstance.getId());
     }
 
     public void addTask4RetryCheck(TaskInstance taskInstance) {
-        this.taskInstanceRetryCheckList.put(taskInstance.getId(), taskInstance);
+        if (taskInstanceRetryCheckList.containsKey(taskInstance.getId())) {
+            return;
+        }
+        TaskDefinition taskDefinition = taskInstance.getTaskDefine();
+        if (taskDefinition == null) {
+            logger.error(""taskDefinition is null, taskId:{}"", taskInstance.getId());
+            return;
+        }
+        if (taskInstance.taskCanRetry()) {
+            taskInstanceRetryCheckList.put(taskInstance.getId(), taskInstance.getProcessInstanceId());
+        }
+
+        if (taskInstance.isDependTask() || taskInstance.isSubProcess()) {
+            taskInstanceRetryCheckList.put(taskInstance.getId(), taskInstance.getProcessInstanceId());
+        }
     }
 
-    public void checkTask4Timeout() {
+    public void removeTask4RetryCheck(TaskInstance taskInstance) {
+        taskInstanceRetryCheckList.remove(taskInstance.getId());
+    }
+
+    private void checkTask4Timeout() {
         if (taskInstanceTimeoutCheckList.isEmpty()) {
             return;
         }
-        for (TaskInstance taskInstance : taskInstanceTimeoutCheckList.values()) {
+        for (Entry<Integer, Integer> entry : taskInstanceTimeoutCheckList.entrySet()) {
+            int processInstanceId = entry.getValue();
+            int taskInstanceId = entry.getKey();
+
+            WorkflowExecuteThread workflowExecuteThread = processInstanceExecCacheManager.getByProcessInstanceId(processInstanceId);","[{'comment': ""'workflow execute' is a high real-time polling and cannot be affected by other services.\r\nso i prefer to put this polling in the 'WorkflowExecuteThreadPool'  "", 'commenter': 'lenboo'}, {'comment': ""> 'workflow execute' is a high real-time polling and cannot be affected by other services. so i prefer to put this polling in the 'WorkflowExecuteThreadPool'\r\n\r\nGood idea. But I think the `processInstanceExecCacheManager` and `WorkflowExecuteThreadPool` is deffierent. It may get `workflowExecuteThread` from cacheManager and handle by some logic, like check timeout. And the `WorkflowExecuteThreadPool` manages `workflowExecThread` executing."", 'commenter': 'caishunfeng'}]"
7506,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/AlertPluginInstanceMapper.xml,"@@ -19,15 +19,21 @@
 <!DOCTYPE mapper PUBLIC ""-//mybatis.org//DTD Mapper 3.0//EN"" ""http://mybatis.org/dtd/mybatis-3-mapper.dtd"" >
 <mapper namespace=""org.apache.dolphinscheduler.dao.mapper.AlertPluginInstanceMapper"">
 
+    <sql id=""baseSql"">
+        id, plugin_define_id, plugin_instance_params, create_time, update_time, instance_name
+    </sql>
+    a","[{'comment': 'check it out here.', 'commenter': 'zhuangchong'}]"
7526,dolphinscheduler-ui-next/src/layouts/basic/components/header/index.tsx,"@@ -0,0 +1,93 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, ref } from 'vue'
+
+import styles from './index.module.scss'
+import { NDropdown, NIcon, NLayoutHeader, NMenu } from 'naive-ui'
+import { Logo } from '@/layouts/basic/components/logo'
+import { IosArrowDown } from ""@vicons/ionicons4""
+import { UserAlt } from '@vicons/fa'
+
+const Header = defineComponent({
+  name: 'Header',
+  props:{
+    inverted: {
+      type:Boolean,
+      default: true
+    },
+    menuOptions: {
+      type: Array,
+      default: []
+    },
+    languageOptions: {
+      type: Array,
+      default: []
+    },
+    profileOptions: {
+      type: Array,
+      default: []
+    },
+    currentMenu: {
+      type: Object
+    },
+    defaultMenuKey: {
+      type: String
+    }
+  },
+  setup(props, context) {
+    const currentMenu = ref({})","[{'comment': 'currentMenuRef', 'commenter': 'songjianet'}]"
7526,dolphinscheduler-ui-next/src/layouts/basic/components/sider/index.tsx,"@@ -0,0 +1,79 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, ref } from 'vue'
+import { NLayoutSider, NMenu } from 'naive-ui'
+
+const Sider = defineComponent({
+  name: 'Sider',
+  props:{
+    visible: {
+      type:Boolean,
+      default: true
+    },
+    inverted: {
+      type:Boolean,
+      default: true
+    },
+    menuOptions: {
+      type: Array,
+      default: []
+    },
+    currentMenu: {
+      type: Object
+    },
+    defaultMenuKey: {
+      type: String
+    }
+  },
+  setup(props) {
+    const currentMenu = ref({})
+
+    function handleMenuClick(key, data) {","[{'comment': 'const handleMenuClick = (key, data) => {}', 'commenter': 'songjianet'}]"
7530,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/datasource/CreateDolphinScheduler.java,"@@ -42,10 +42,14 @@ public static void main(String[] args) {
 
         @Override
         public void run(String... args) throws Exception {
+            if (dolphinSchedulerManager.schemaIsInitialized()) {
+                dolphinSchedulerManager.upgradeDolphinScheduler();
+                logger.info(""upgrade DolphinScheduler finished"");
+            } else {
+                dolphinSchedulerManager.initDolphinScheduler();
+            }
             dolphinSchedulerManager.initDolphinScheduler();","[{'comment': ""it's initialized twice\r\n\r\n```suggestion\r\n```"", 'commenter': 'kezhenxu94'}, {'comment': 'Thanks,you are right,I will remove it.', 'commenter': 'lgcareer'}, {'comment': 'Hi,I have done. please recheck it ,thx', 'commenter': 'lgcareer'}]"
7530,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/datasource/CreateDolphinScheduler.java,"@@ -42,10 +42,14 @@ public static void main(String[] args) {
 
         @Override
         public void run(String... args) throws Exception {
+            if (dolphinSchedulerManager.schemaIsInitialized()) {
+                dolphinSchedulerManager.upgradeDolphinScheduler();
+                logger.info(""upgrade DolphinScheduler finished"");
+            } else {
+                dolphinSchedulerManager.initDolphinScheduler();
+            }
             dolphinSchedulerManager.initDolphinScheduler();
             logger.info(""init DolphinScheduler finished"");","[{'comment': 'What about also moving this into the `else` block?', 'commenter': 'kezhenxu94'}, {'comment': 'Great.Done.', 'commenter': 'lgcareer'}]"
7533,dolphinscheduler-ui-next/src/layouts/basic/components/sider/index.tsx,"@@ -41,20 +41,20 @@ const Sider = defineComponent({
     },
   },
   setup(props) {
-    const currentMenuRef = ref({});
+    const currentMenuRef = ref({})
 
     const handleMenuClick = (key, data) => {
-      currentMenuRef.value = data;
-    };
+      currentMenuRef.value = data
+    }
 
-    return { handleMenuClick };
+    return { handleMenuClick }
   },
   render() {
     if (this.visible) {","[{'comment': '&&', 'commenter': 'songjianet'}]"
7613,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -1083,34 +1083,51 @@ private DependResult isTaskDepsComplete(String taskCode) {
             return DependResult.SUCCESS;
         }
         TaskNode taskNode = dag.getNode(taskCode);
-        List<String> depCodeList = taskNode.getDepList();
-        for (String depsNode : depCodeList) {
-            if (!dag.containsNode(depsNode)
-                    || forbiddenTaskMap.containsKey(depsNode)
-                    || skipTaskNodeMap.containsKey(depsNode)) {
-                continue;
-            }
-            // dependencies must be fully completed
-            if (!completeTaskMap.containsKey(depsNode)) {
-                return DependResult.WAITING;
-            }
-            Integer depsTaskId = completeTaskMap.get(depsNode);
-            ExecutionStatus depTaskState = taskInstanceMap.get(depsTaskId).getState();
-            if (depTaskState.typeIsPause() || depTaskState.typeIsCancel()) {
-                return DependResult.NON_EXEC;
-            }
-            // ignore task state if current task is condition
-            if (taskNode.isConditionsTask()) {
-                continue;
-            }
-            if (!dependTaskSuccess(depsNode, taskCode)) {
-                return DependResult.FAILED;
+        List<String> indirectDepCodeList = new ArrayList<>();
+        getIndirectDepList(taskCode, indirectDepCodeList);
+        for (String depsNode : indirectDepCodeList) {
+            if (dag.containsNode(depsNode) && !skipTaskNodeMap.containsKey(depsNode)) {
+                // dependencies must be fully completed
+                if (!completeTaskMap.containsKey(depsNode)) {
+                    return DependResult.WAITING;
+                }
+                Integer depsTaskId = completeTaskMap.get(depsNode);
+                ExecutionStatus depTaskState = taskInstanceMap.get(depsTaskId).getState();
+                if (depTaskState.typeIsPause() || depTaskState.typeIsCancel()) {
+                    return DependResult.NON_EXEC;
+                }
+                // ignore task state if current task is condition
+                if (taskNode.isConditionsTask()) {
+                    continue;
+                }
+                if (!dependTaskSuccess(depsNode, taskCode)) {
+                    return DependResult.FAILED;
+                }
             }
         }
         logger.info(""taskCode: {} completeDependTaskList: {}"", taskCode, Arrays.toString(completeTaskMap.keySet().toArray()));
         return DependResult.SUCCESS;
     }
 
+    /**
+     * This function is specially used to handle the dependency situation where the parent node is a prohibited node.
+     * When the parent node is a forbidden node, the dependency relationship should continue to be traced
+     *
+     * @param taskCode            taskCode
+     * @param indirectDepCodeList All indirectly dependent nodes
+     */
+    private void getIndirectDepList(String taskCode, List<String> indirectDepCodeList) {","[{'comment': '```suggestion\r\n    private List<String> getIndirectDepList(String taskCode) {\r\n\r\n}\r\n``` ', 'commenter': 'ruanwenjun'}, {'comment': 'Suggest add a return result here, get method should not carry side effects.', 'commenter': 'ruanwenjun'}, {'comment': 'Yes, this is my mistake. I modified the method name.', 'commenter': 'vinnielhj'}]"
7613,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -1083,34 +1083,51 @@ private DependResult isTaskDepsComplete(String taskCode) {
             return DependResult.SUCCESS;
         }
         TaskNode taskNode = dag.getNode(taskCode);
-        List<String> depCodeList = taskNode.getDepList();
-        for (String depsNode : depCodeList) {
-            if (!dag.containsNode(depsNode)
-                    || forbiddenTaskMap.containsKey(depsNode)
-                    || skipTaskNodeMap.containsKey(depsNode)) {
-                continue;
-            }
-            // dependencies must be fully completed
-            if (!completeTaskMap.containsKey(depsNode)) {
-                return DependResult.WAITING;
-            }
-            Integer depsTaskId = completeTaskMap.get(depsNode);
-            ExecutionStatus depTaskState = taskInstanceMap.get(depsTaskId).getState();
-            if (depTaskState.typeIsPause() || depTaskState.typeIsCancel()) {
-                return DependResult.NON_EXEC;
-            }
-            // ignore task state if current task is condition
-            if (taskNode.isConditionsTask()) {
-                continue;
-            }
-            if (!dependTaskSuccess(depsNode, taskCode)) {
-                return DependResult.FAILED;
+        List<String> indirectDepCodeList = new ArrayList<>();
+        getIndirectDepList(taskCode, indirectDepCodeList);
+        for (String depsNode : indirectDepCodeList) {
+            if (dag.containsNode(depsNode) && !skipTaskNodeMap.containsKey(depsNode)) {
+                // dependencies must be fully completed
+                if (!completeTaskMap.containsKey(depsNode)) {
+                    return DependResult.WAITING;
+                }
+                Integer depsTaskId = completeTaskMap.get(depsNode);
+                ExecutionStatus depTaskState = taskInstanceMap.get(depsTaskId).getState();
+                if (depTaskState.typeIsPause() || depTaskState.typeIsCancel()) {
+                    return DependResult.NON_EXEC;
+                }
+                // ignore task state if current task is condition
+                if (taskNode.isConditionsTask()) {
+                    continue;
+                }
+                if (!dependTaskSuccess(depsNode, taskCode)) {
+                    return DependResult.FAILED;
+                }
             }
         }
         logger.info(""taskCode: {} completeDependTaskList: {}"", taskCode, Arrays.toString(completeTaskMap.keySet().toArray()));
         return DependResult.SUCCESS;
     }
 
+    /**
+     * This function is specially used to handle the dependency situation where the parent node is a prohibited node.
+     * When the parent node is a forbidden node, the dependency relationship should continue to be traced
+     *
+     * @param taskCode            taskCode
+     * @param indirectDepCodeList All indirectly dependent nodes
+     */
+    private void getIndirectDepList(String taskCode, List<String> indirectDepCodeList) {
+        TaskNode taskNode = dag.getNode(taskCode);
+        List<String> depCodeList = taskNode.getDepList();
+        for (String depsNode : depCodeList) {
+            if (forbiddenTaskMap.containsKey(depsNode)) {","[{'comment': 'Does the `skip node` also has this bug? Can we return all the parent of the current node? I think this may not cause  a performance loss.', 'commenter': 'ruanwenjun'}, {'comment': 'I think there is no problem with the processing of skip nodes. The skip node is unique to the condition node and the switch node. If a node depends on a skip node, then it must also is a skip node. It will not check dependent tasks.', 'commenter': 'vinnielhj'}]"
7798,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/HttpUtilsTest.java,"@@ -39,40 +39,41 @@
 
     @Test
     public void testGetTest() {
-	// success
-	String result = HttpUtils.get(""https://github.com/manifest.json"");
-	Assert.assertNotNull(result);
-	ObjectNode jsonObject = JSONUtils.parseObject(result);
-	Assert.assertEquals(""GitHub"", jsonObject.path(""name"").asText());
-	result = HttpUtils.get(""https://123.333.111.33/ccc"");
-	Assert.assertNull(result);
+		// success
+		String result = HttpUtils.get(""https://github.com/manifest.json"");
+		Assert.assertNotNull(result);
+		ObjectNode jsonObject = JSONUtils.parseObject(result);
+		Assert.assertEquals(""GitHub"", jsonObject.path(""name"").asText());
+		result = HttpUtils.get(""https://123.333.111.33/ccc"");
+		Assert.assertNull(result);","[{'comment': 'The code indentation format is wrong.', 'commenter': 'zhuangchong'}, {'comment': 'Hi @zhuangchong ，updated，please check again.\r\nThanks for your suggestion.', 'commenter': 'springmonster'}]"
7798,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/HttpUtilsTest.java,"@@ -39,40 +39,41 @@
 
     @Test
     public void testGetTest() {
-	// success
-	String result = HttpUtils.get(""https://github.com/manifest.json"");
-	Assert.assertNotNull(result);
-	ObjectNode jsonObject = JSONUtils.parseObject(result);
-	Assert.assertEquals(""GitHub"", jsonObject.path(""name"").asText());
-	result = HttpUtils.get(""https://123.333.111.33/ccc"");
-	Assert.assertNull(result);
+		// success
+		String result = HttpUtils.get(""https://github.com/manifest.json"");
+		Assert.assertNotNull(result);
+		ObjectNode jsonObject = JSONUtils.parseObject(result);
+		Assert.assertEquals(""GitHub"", jsonObject.path(""name"").asText());
+		result = HttpUtils.get(""https://123.333.111.33/ccc"");
+		Assert.assertNull(result);
     }
 
     @Test
     public void testGetByKerberos() {
-	try {
-	    String applicationUrl = hadoopUtils.getApplicationUrl(""application_1542010131334_0029"");
-	    String responseContent;
-	    responseContent = HttpUtils.get(applicationUrl);
-	    Assert.assertNull(responseContent);
-
-	} catch (Exception e) {
-	    logger.error(e.getMessage(), e);
-	}
-
+		try {
+			String applicationUrl = hadoopUtils.getApplicationUrl(""application_1542010131334_0029"");
+			String responseContent;
+			responseContent = HttpUtils.get(applicationUrl);
+			Assert.assertNull(responseContent);
+		} catch (Exception e) {
+			logger.error(e.getMessage(), e);
+		}","[{'comment': 'The code indentation format is wrong.', 'commenter': 'zhuangchong'}, {'comment': 'Hi @zhuangchong ，updated，please check again.\r\nThanks for your suggestion.', 'commenter': 'springmonster'}]"
7798,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/HttpUtilsTest.java,"@@ -39,40 +39,41 @@
 
     @Test
     public void testGetTest() {
-	// success
-	String result = HttpUtils.get(""https://github.com/manifest.json"");
-	Assert.assertNotNull(result);
-	ObjectNode jsonObject = JSONUtils.parseObject(result);
-	Assert.assertEquals(""GitHub"", jsonObject.path(""name"").asText());
-	result = HttpUtils.get(""https://123.333.111.33/ccc"");
-	Assert.assertNull(result);
+		// success
+		String result = HttpUtils.get(""https://github.com/manifest.json"");
+		Assert.assertNotNull(result);
+		ObjectNode jsonObject = JSONUtils.parseObject(result);
+		Assert.assertEquals(""GitHub"", jsonObject.path(""name"").asText());
+		result = HttpUtils.get(""https://123.333.111.33/ccc"");
+		Assert.assertNull(result);
     }
 
     @Test
     public void testGetByKerberos() {
-	try {
-	    String applicationUrl = hadoopUtils.getApplicationUrl(""application_1542010131334_0029"");
-	    String responseContent;
-	    responseContent = HttpUtils.get(applicationUrl);
-	    Assert.assertNull(responseContent);
-
-	} catch (Exception e) {
-	    logger.error(e.getMessage(), e);
-	}
-
+		try {
+			String applicationUrl = hadoopUtils.getApplicationUrl(""application_1542010131334_0029"");
+			String responseContent;
+			responseContent = HttpUtils.get(applicationUrl);
+			Assert.assertNull(responseContent);
+		} catch (Exception e) {
+			logger.error(e.getMessage(), e);
+		}
     }
 
     @Test
     public void testGetResponseContentString() {
-	CloseableHttpClient httpclient = HttpClients.createDefault();
-	HttpGet httpget = new HttpGet(""https://github.com/manifest.json"");
-	/** set timeout、request time、socket timeout */
-	RequestConfig requestConfig = RequestConfig.custom().setConnectTimeout(Constants.HTTP_CONNECT_TIMEOUT)
-		.setConnectionRequestTimeout(Constants.HTTP_CONNECTION_REQUEST_TIMEOUT)
-		.setSocketTimeout(Constants.SOCKET_TIMEOUT).setRedirectsEnabled(true).build();
-	httpget.setConfig(requestConfig);
-	String responseContent = HttpUtils.getResponseContentString(httpget, httpclient);
-	Assert.assertNotNull(responseContent);
+		CloseableHttpClient httpclient = HttpClients.createDefault();
+		HttpGet httpget = new HttpGet(""https://github.com/manifest.json"");
+		/** set timeout、request time、socket timeout */
+		RequestConfig requestConfig = RequestConfig.custom().setConnectTimeout(Constants.HTTP_CONNECT_TIMEOUT)
+			.setConnectionRequestTimeout(Constants.HTTP_CONNECTION_REQUEST_TIMEOUT)
+			.setSocketTimeout(Constants.SOCKET_TIMEOUT).setRedirectsEnabled(true).build();
+		httpget.setConfig(requestConfig);
+		String responseContent = HttpUtils.getResponseContentString(httpget, httpclient);
+		Assert.assertNotNull(responseContent);
+	
+		responseContent = HttpUtils.getResponseContentString(null, null);
+		Assert.assertNull(responseContent);","[{'comment': 'The code indentation format is wrong.', 'commenter': 'zhuangchong'}, {'comment': 'Hi @zhuangchong ，updated，please check again.\r\nThanks for your suggestion.', 'commenter': 'springmonster'}]"
7798,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HttpUtils.java,"@@ -154,10 +154,10 @@ public static String getResponseContentString(HttpGet httpget, CloseableHttpClie
                     logger.warn(""http entity is null"");
                 }
             } else {
-                logger.error(""http get:{} response status code is not 200!"", response.getStatusLine().getStatusCode());
+                logger.error(""http get: {} response status code is not 200!"", response.getStatusLine().getStatusCode());
             }
-        } catch (IOException ioe) {
-            logger.error(ioe.getMessage(), ioe);
+        } catch (NullPointerException | IOException exception) {
+            logger.error(exception.getMessage(), exception);","[{'comment': 'I would recommend to verify the parameters before the method is processed.', 'commenter': 'zhuangchong'}, {'comment': 'Hi @zhuangchong ，updated，please check again.\r\nThanks for your suggestion.', 'commenter': 'springmonster'}]"
7830,dolphinscheduler-ui-next/src/layouts/content/index.tsx,"@@ -3,67 +3,80 @@
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.
  * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
+ * (the 'License') you may not use this file except in compliance with","[{'comment': '```suggestion\r\n * (the ""License""); you may not use this file except in compliance with\r\n```', 'commenter': 'zhongjiajie'}]"
7830,dolphinscheduler-ui-next/src/layouts/content/use-dataList.ts,"@@ -3,7 +3,7 @@
  * contributor license agreements.  See the NOTICE file distributed with
  * this work for additional information regarding copyright ownership.
  * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the 'License'); you may not use this file except in compliance with
+ * (the 'License') you may not use this file except in compliance with","[{'comment': ""```suggestion\r\n * (the 'License'); you may not use this file except in compliance with\r\n```"", 'commenter': 'zhongjiajie'}, {'comment': ""I've fixed it"", 'commenter': 'labbomb'}]"
7875,pom.xml,"@@ -60,7 +60,7 @@
         <hadoop.version>2.7.3</hadoop.version>
         <quartz.version>2.3.2</quartz.version>
         <jackson.version>2.10.5</jackson.version>
-        <mybatis-plus.version>3.2.0</mybatis-plus.version>
+        <mybatis-plus.version>3.4.0</mybatis-plus.version>","[{'comment': ""It's better not upgrade `mybatis-plus` in this PR, If you hope to do this, it's necessary to create a new issue and discuss with community first."", 'commenter': 'ruanwenjun'}, {'comment': "" \r\n   sorry about that, i choose the way of adding a typeHandler to fix issue #7732 . but due to the mybatis-plus [BUG](https://github.com/baomidou/mybatis-plus/issues/2550), it failed in the maven test. so i update a oldest version that works.\r\n  \r\n  but if there is anthor way to fix this bug, i think i won't change the version"", 'commenter': 'jim-parsons'}, {'comment': 'We can discuss in #7732 .', 'commenter': 'ruanwenjun'}]"
7877,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java,"@@ -116,13 +116,13 @@
     public Result startProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                                        @ApiParam(name = ""projectCode"", value = ""PROJECT_CODE"", required = true) @PathVariable long projectCode,
                                        @RequestParam(value = ""processDefinitionCode"") long processDefinitionCode,
-                                       @RequestParam(value = ""scheduleTime"", required = false) String scheduleTime,
-                                       @RequestParam(value = ""failureStrategy"", required = true) FailureStrategy failureStrategy,
+                                       @RequestParam(value = ""scheduleTime"") String scheduleTime,","[{'comment': 'Why remove `required = false`?', 'commenter': 'zhuangchong'}, {'comment': 'Because It\'s required according to ""@ApiImplicitParam(name = ""scheduleTime"", value = ""SCHEDULE_TIME"", required = true, dataType = ""String""),"" ', 'commenter': 'JiangTChen'}, {'comment': 'It is recommended to modify ApiImplicitParam `required = false`, because the scheduleTime parameter is not required for a single execution.', 'commenter': 'zhuangchong'}, {'comment': '```\r\n@RequestParam(value = ""scheduleTime"") String scheduleTime\r\n```\r\nThis part is not restored.', 'commenter': 'zhuangchong'}, {'comment': ""@zhuangchong If it's not required, we better set a default value, Could you offer a value?"", 'commenter': 'JiangTChen'}, {'comment': '```\r\n@ApiImplicitParam(name = ""scheduleTime"", value = ""SCHEDULE_TIME"", dataType = ""String""),\r\n@RequestParam(value = ""scheduleTime"", required = false) String scheduleTime\r\n```\r\nI understand that modifying like this does not require a default value, the default value can be empty.', 'commenter': 'zhuangchong'}]"
7877,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java,"@@ -116,13 +116,13 @@
     public Result startProcessInstance(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
                                        @ApiParam(name = ""projectCode"", value = ""PROJECT_CODE"", required = true) @PathVariable long projectCode,
                                        @RequestParam(value = ""processDefinitionCode"") long processDefinitionCode,
-                                       @RequestParam(value = ""scheduleTime"", required = false) String scheduleTime,
-                                       @RequestParam(value = ""failureStrategy"", required = true) FailureStrategy failureStrategy,
+                                       @RequestParam(value = ""scheduleTime"") String scheduleTime,
+                                       @RequestParam(value = ""failureStrategy"") FailureStrategy failureStrategy,
                                        @RequestParam(value = ""startNodeList"", required = false) String startNodeList,
                                        @RequestParam(value = ""taskDependType"", required = false) TaskDependType taskDependType,
                                        @RequestParam(value = ""execType"", required = false) CommandType execType,
-                                       @RequestParam(value = ""warningType"", required = true) WarningType warningType,
-                                       @RequestParam(value = ""warningGroupId"", required = false) int warningGroupId,
+                                       @RequestParam(value = ""warningType"") WarningType warningType,
+                                       @RequestParam(value = ""warningGroupId"") int warningGroupId,","[{'comment': 'Why remove `required = false`?', 'commenter': 'zhuangchong'}, {'comment': 'Because It\'s required according to""@ApiImplicitParam(name = ""warningGroupId"", value = ""WARNING_GROUP_ID"", required = true, dataType = ""Int"", example = ""100""),""', 'commenter': 'JiangTChen'}, {'comment': 'It is recommended to modify ApiImplicitParam `required = false`, because RequestParam is a strong verification, ApiImplicitParam is only used for swagger display.', 'commenter': 'zhuangchong'}, {'comment': '```\r\n@RequestParam(value = ""warningGroupId"") int warningGroupId,\r\n```\r\nThis part is not restored.', 'commenter': 'zhuangchong'}, {'comment': '> ```\r\n> @RequestParam(value = ""warningGroupId"") int warningGroupId,\r\n> ```\r\n> \r\n> This part is not restored.\r\n\r\n@zhuangchong If it\'s not required, we better set a default value, Could you offer a value?', 'commenter': 'JiangTChen'}, {'comment': '@zhuangchong Do you know what the default value of int, I need it to finish testStartProcessInstanceWithRequiredParams test. I try 0, the test still fail.\r\nThanks', 'commenter': 'JiangTChen'}, {'comment': '@zhuangchong, null cannot be assigned to int. Please provide a default value.\r\nThanks', 'commenter': 'JiangTChen'}, {'comment': '@zhuangchong I used default as 0 for warningGroupId', 'commenter': 'JiangTChen'}]"
7883,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/src/main/java/org/apache/dolphinscheduler/plugin/datasource/api/datasource/oracle/OracleDataSourceProcessor.java,"@@ -65,14 +65,16 @@ public BaseDataSourceParamDTO createDatasourceParamDTO(String connectionJson) {
     public BaseConnectionParam createConnectionParams(BaseDataSourceParamDTO datasourceParam) {
         OracleDataSourceParamDTO oracleParam = (OracleDataSourceParamDTO) datasourceParam;
         String address;
+        String jdbcUrl;
         if (DbConnectType.ORACLE_SID.equals(oracleParam.getConnectType())) {
             address = String.format(""%s%s:%s"",
                     Constants.JDBC_ORACLE_SID, oracleParam.getHost(), oracleParam.getPort());
+            jdbcUrl = address + ""/"" + oracleParam.getDatabase();
         } else {
             address = String.format(""%s%s:%s"",
                     Constants.JDBC_ORACLE_SERVICE_NAME, oracleParam.getHost(), oracleParam.getPort());
+            jdbcUrl = address + ""/"" + oracleParam.getDatabase();","[{'comment': ""I'm sorry, I didn't find the difference between the code you changed and before the change."", 'commenter': 'zhuangchong'}, {'comment': ""Aha,It didn't change successfully"", 'commenter': 'jxeditor'}]"
7883,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/src/main/java/org/apache/dolphinscheduler/plugin/datasource/api/datasource/oracle/OracleDataSourceProcessor.java,"@@ -65,14 +65,16 @@ public BaseDataSourceParamDTO createDatasourceParamDTO(String connectionJson) {
     public BaseConnectionParam createConnectionParams(BaseDataSourceParamDTO datasourceParam) {
         OracleDataSourceParamDTO oracleParam = (OracleDataSourceParamDTO) datasourceParam;
         String address;
+        String jdbcUrl;
         if (DbConnectType.ORACLE_SID.equals(oracleParam.getConnectType())) {
             address = String.format(""%s%s:%s"",
                     Constants.JDBC_ORACLE_SID, oracleParam.getHost(), oracleParam.getPort());
+            jdbcUrl = address + ""/"" + oracleParam.getDatabase();","[{'comment': 'I understand what you might want to modify is this part.\r\n\r\nSID:\r\n```\r\njdbc:oracle:thin:@<host>:<port>:<SID> \r\n```\r\nservice_name:\r\n```\r\njdbc:oracle:thin:@//<host>:<port>/<service_name> \r\n\r\n```\r\n', 'commenter': 'zhuangchong'}, {'comment': 'yes,The previous code only supported servicename', 'commenter': 'jxeditor'}]"
7899,.github/ISSUE_TEMPLATE/bug-report.yml,"@@ -98,6 +98,8 @@ body:
         Which version of Apache DolphinScheduler are you running? We only accept bugs report from the LTS projects.
       options:
         - dev
+        - 2.0.3","[{'comment': 'it seem we do not release version 2.0.3. it there any reason you want to add it?', 'commenter': 'zhongjiajie'}, {'comment': 'It is a bug test requirement before 2.0.3 release.', 'commenter': 'zhuangchong'}]"
7943,dolphinscheduler-ui-next/src/locales/modules/en_US.ts,"@@ -151,6 +151,42 @@ const monitor = {
   },
 }
 
+const resource = {","[{'comment': ""resource = {\r\n  file: {\r\n    file_manage: 'File Manage',\r\n    ....\r\n  }\r\n}"", 'commenter': 'songjianet'}]"
7943,dolphinscheduler-ui-next/src/service/service.ts,"@@ -22,6 +22,8 @@ import axios, {
   AxiosRequestHeaders,
 } from 'axios'
 import qs from 'qs'
+import _ from 'lodash'
+import $ from 'jquery'","[{'comment': 'To download a file, you can get the corresponding `url` from the corresponding interception in `axios`, and then create a form for downloading. It is not recommended to use `jquery` for this.', 'commenter': 'songjianet'}]"
7943,dolphinscheduler-ui-next/src/views/resource/file/edit/resource-file-edit.tsx,"@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { useRouter } from 'vue-router'
+import { defineComponent, onMounted, ref, toRefs } from 'vue'
+import { NButton, NForm, NFormItem, NSpace } from 'naive-ui'
+import { useI18n } from 'vue-i18n'
+import Card from '@/components/card'
+import MonacoEditor from '@/components/monaco-editor'
+import { useForm } from './use-form'
+import { useEdit } from './use-edit'
+
+import styles from '../index.module.scss'
+import type { Router } from 'vue-router'
+
+export default defineComponent({
+  name: 'ResourceFileEdit',
+  setup() {
+    const router: Router = useRouter()
+
+    const resourceViewRef = ref()
+    const codeEditorRef = ref()
+    const routeNameRef = ref(router.currentRoute.value.name)
+    const idRef = ref(Number(router.currentRoute.value.params.id))
+
+    const { state } = useForm()
+    const { getResourceView, handleUpdateContent } = useEdit(state)
+
+    const handleFileContent = () => {
+      state.fileForm.content = codeEditorRef.value?.getValue()
+      handleUpdateContent(idRef.value)
+    }
+
+    const handleReturn = () => {
+      router.go(-1)
+    }
+
+    onMounted(() => {
+      resourceViewRef.value = getResourceView(idRef.value)
+    })
+
+    return {
+      idRef,
+      routeNameRef,
+      codeEditorRef,
+      resourceViewRef,
+      handleReturn,
+      handleFileContent,
+      ...toRefs(state),
+    }
+  },
+  render() {
+    const { t } = useI18n()
+    return (
+      <Card title={t('resource.file_details')}>
+        <div class={styles['file-edit-content']}>
+          <h2>
+            <span>{this.resourceViewRef?.value.alias}</span>
+          </h2>
+          <NForm
+            rules={this.rules}
+            ref='fileFormRef'
+            class={styles['form-content']}
+          >
+            <NFormItem path='content'>
+              <div
+                class={styles.cont}
+                style={{
+                  width: '90%',
+                }}
+              >
+                <MonacoEditor
+                  ref='codeEditorRef'
+                  modelValue={this.resourceViewRef?.value.content}
+                />
+              </div>
+            </NFormItem>
+            {this.routeNameRef === 'resource-file-edit' ? (","[{'comment': ""this.routeNameRef === 'resource-file-edit' && \r\nThis is fine. It seems that there is no need to use ternary operations in this place."", 'commenter': 'songjianet'}]"
7943,dolphinscheduler-ui-next/src/views/resource/file/table/table-action.tsx,"@@ -0,0 +1,192 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { useRouter } from 'vue-router'
+import { defineComponent, PropType } from 'vue'
+import { NSpace, NTooltip, NButton, NIcon, NPopconfirm } from 'naive-ui'
+import {
+  DeleteOutlined,
+  DownloadOutlined,
+  FormOutlined,
+  EditOutlined,
+  InfoCircleFilled,
+} from '@vicons/antd'
+import _ from 'lodash'
+import { useI18n } from 'vue-i18n'
+import { ResourceFileTableData } from '../types'
+import { fileTypeArr } from '@/utils/common'
+import { downloadResource, deleteResource } from '@/service/modules/resources'
+import { IRenameFile, IRtDisb } from '../types'
+import type { Router } from 'vue-router'
+
+const props = {
+  show: {
+    type: Boolean as PropType<boolean>,
+    default: false,
+  },
+  row: {
+    type: Object as PropType<ResourceFileTableData>,
+    default: {
+      id: -1,
+      name: '',
+      description: '',
+    },
+  },
+}
+
+export default defineComponent({
+  name: 'TableAction',
+  props,
+  emits: ['updateList', 'renameResource'],
+  setup(props, { emit }) {
+    const { t } = useI18n()
+    const router: Router = useRouter()
+
+    const rtDisb: IRtDisb = (name, size) => {
+      const i = name.lastIndexOf('.')
+      const a = name.substring(i, name.length)
+      let flag = _.includes(fileTypeArr, _.trimStart(a, '.'))
+      if (flag && size < 1000000) {","[{'comment': 'return !flag && size < 1000000', 'commenter': 'songjianet'}, {'comment': 'This should be `return !(flag && size < 1000000)`', 'commenter': 'devosend'}]"
7943,dolphinscheduler-ui-next/src/views/resource/file/table/use-table.ts,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { h } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { useRouter } from 'vue-router'
+","[{'comment': 'delete entry', 'commenter': 'songjianet'}]"
7943,dolphinscheduler-ui-next/src/views/resource/file/use-file.ts,"@@ -0,0 +1,83 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { useAsyncState } from '@vueuse/core'
+import {
+  queryResourceListPaging,
+  viewResource,
+} from '@/service/modules/resources'
+import type { ResourceListRes } from '@/service/modules/resources/types'
+import { IResourceListState, ISetPagination } from './types'
+
+export function useFileState(
+  setPagination: ISetPagination = {} as ISetPagination,
+) {
+  const getResourceListState: IResourceListState = (
+    id = -1,
+    searchVal = '',
+    pageNo = 1,
+    pageSize = 10,
+  ) => {
+    const { state } = useAsyncState(
+      queryResourceListPaging({
+        id,
+        type: 'FILE',
+        searchVal,
+        pageNo,
+        pageSize,
+      }).then((res: ResourceListRes): any => {
+        const { total } = res
+        setPagination(total)
+        const table = res.totalList.map((item) => {
+          return {
+            id: item.id,
+            name: item.alias,
+            alias: item.alias,
+            fullName: item.fullName,
+            type: item.type,
+            directory: item.directory,
+            file_name: item.fileName,
+            description: item.description,
+            size: item.size,
+            update_time: item.updateTime,
+          }
+        })
+
+        return { total, table }
+      }),
+      { total: 0, table: [] },
+    )
+
+    return state
+  }
+
+  const getResourceView = (id: number) => {
+    const params = {
+      skipLineNum: 0,
+      limit: 3000,
+    }
+    const { state } = useAsyncState(
+      viewResource(params, id).then((res: any) => {","[{'comment': 'viewResource(params, id)', 'commenter': 'songjianet'}, {'comment': ""If you don't need to process the success data, you can omit `then`."", 'commenter': 'songjianet'}]"
7943,dolphinscheduler-ui-next/src/views/resource/file/edit/use-edit.ts,"@@ -0,0 +1,69 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { useI18n } from 'vue-i18n'
+import { useRouter } from 'vue-router'
+import type { Router } from 'vue-router'
+import { useAsyncState } from '@vueuse/core'
+import {
+  viewResource,
+  updateResourceContent,
+} from '@/service/modules/resources'
+
+export function useEdit(state: any) {
+  const { t } = useI18n()
+  const router: Router = useRouter()
+
+  const getResourceView = (id: number) => {
+    const params = {
+      skipLineNum: 0,
+      limit: 3000,
+    }
+    const { state } = useAsyncState(
+      viewResource(params, id).then((res: any) => {","[{'comment': 'viewResource(params, id)', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/components/user-modal.tsx,"@@ -0,0 +1,117 @@
+import { defineComponent, inject } from 'vue'","[{'comment': 'inject is deprecated.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/components/use-modal.tsx,"@@ -0,0 +1,236 @@
+import { ref, watch, computed } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { useMessage } from 'naive-ui'
+import { queryTenantList } from '@/service/modules/tenants'
+import { queryList } from '@/service/modules/queues'
+import {
+  createUser,
+  updateUser,
+  delUserById,
+  verifyUserName
+} from '@/service/modules/users'
+export type Mode = 'add' | 'edit' | 'delete'
+
+export function useModal() {
+  const message = useMessage()
+  const { t } = useI18n()
+  const show = ref(false)
+  const mode = ref<Mode>('add')
+  const user = ref()
+  const formRef = ref()
+  const formValues = ref({
+    userName: '',
+    userPassword: '',
+    tenantId: 0,
+    email: '',
+    queue: '',
+    phone: '',
+    state: 1
+  })
+  const tenants = ref<any[]>([])
+  const queues = ref<any[]>([])
+  const optionsLoading = ref(false)
+  const confirmLoading = ref(false)
+
+  const formRules = computed(() => {
+    return {
+      userName: {
+        required: true,
+        message: t('security.user.username_rule_msg'),
+        trigger: 'blur'
+      },
+      userPassword: {
+        required: mode.value === 'add',
+        validator(rule: any, value?: string) {
+          if (mode.value !== 'add' && !value) {
+            return true
+          }
+          const msg = t('security.user.user_password_rule_msg')
+          if (
+            !value ||
+            !/^(?![0-9]+$)(?![a-zA-Z]+$)[0-9A-Za-z]{6,20}$/.test(value)
+          ) {
+            return new Error(msg)
+          }
+          return true
+        },
+        trigger: ['blur', 'input']
+      },
+      tenantId: {
+        required: true,
+        validator(rule: any, value?: number) {
+          const msg = t('security.user.tenant_id_rule_msg')
+          if (typeof value === 'number') {
+            return true
+          }
+          return new Error(msg)
+        },
+        trigger: 'blur'
+      },
+      email: {
+        required: true,
+        validator(rule: any, value?: string) {
+          const msg = t('security.user.email_rule_msg')
+          if (
+            !value ||
+            !/^(([^<>()[\]\\.,;:\s@""]+(\.[^<>()[\]\\.,;:\s@""]+)*)|("".+""))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/.test(","[{'comment': 'Regular can be put in utils/regex.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/components/use-modal.tsx,"@@ -0,0 +1,236 @@
+import { ref, watch, computed } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { useMessage } from 'naive-ui'
+import { queryTenantList } from '@/service/modules/tenants'
+import { queryList } from '@/service/modules/queues'
+import {
+  createUser,
+  updateUser,
+  delUserById,
+  verifyUserName
+} from '@/service/modules/users'
+export type Mode = 'add' | 'edit' | 'delete'
+
+export function useModal() {
+  const message = useMessage()
+  const { t } = useI18n()
+  const show = ref(false)
+  const mode = ref<Mode>('add')
+  const user = ref()
+  const formRef = ref()
+  const formValues = ref({
+    userName: '',
+    userPassword: '',
+    tenantId: 0,
+    email: '',
+    queue: '',
+    phone: '',
+    state: 1
+  })
+  const tenants = ref<any[]>([])
+  const queues = ref<any[]>([])
+  const optionsLoading = ref(false)
+  const confirmLoading = ref(false)
+
+  const formRules = computed(() => {
+    return {
+      userName: {
+        required: true,
+        message: t('security.user.username_rule_msg'),
+        trigger: 'blur'
+      },
+      userPassword: {
+        required: mode.value === 'add',
+        validator(rule: any, value?: string) {
+          if (mode.value !== 'add' && !value) {
+            return true
+          }
+          const msg = t('security.user.user_password_rule_msg')
+          if (
+            !value ||
+            !/^(?![0-9]+$)(?![a-zA-Z]+$)[0-9A-Za-z]{6,20}$/.test(value)
+          ) {
+            return new Error(msg)
+          }
+          return true
+        },
+        trigger: ['blur', 'input']
+      },
+      tenantId: {
+        required: true,
+        validator(rule: any, value?: number) {
+          const msg = t('security.user.tenant_id_rule_msg')
+          if (typeof value === 'number') {
+            return true
+          }
+          return new Error(msg)
+        },
+        trigger: 'blur'
+      },
+      email: {
+        required: true,
+        validator(rule: any, value?: string) {
+          const msg = t('security.user.email_rule_msg')
+          if (
+            !value ||
+            !/^(([^<>()[\]\\.,;:\s@""]+(\.[^<>()[\]\\.,;:\s@""]+)*)|("".+""))@((\[[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\.[0-9]{1,3}\])|(([a-zA-Z\-0-9]+\.)+[a-zA-Z]{2,}))$/.test(
+              value
+            )
+          ) {
+            return new Error(msg)
+          }
+          return true
+        },
+        trigger: ['blur', 'input']
+      },
+      phone: {
+        validator(rule: any, value?: string) {
+          const msg = t('security.user.phone_rule_msg')
+          if (value && !/^1\d{10}$/.test(value)) {","[{'comment': 'Regular can be put in utils/regex.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/index.tsx,"@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, provide } from 'vue'
+import {
+  NCard,
+  NButton,
+  NInputGroup,
+  NInput,
+  NIcon,
+  NSpace,
+  NGrid,
+  NGridItem,
+  NDataTable,
+  NPagination,
+  NSkeleton
+} from 'naive-ui'
+import { useI18n } from 'vue-i18n'
+import { SearchOutlined } from '@vicons/antd'
+import { useTable } from './use-table'
+import UserModal from './components/user-modal'
+import { useModal, Mode } from './components/use-modal'
+
+const UsersManage = defineComponent({
+  name: 'user-manage',
+  setup() {
+    const { t } = useI18n()
+    const modalState = useModal()
+    const tableState = useTable({
+      onEdit: (u) => {
+        modalState.onEditUser(u)
+      },
+      onDelete: (u) => {
+        modalState.onDeleteUser(u)
+      }
+    })
+    const onSuccess = (mode: Mode) => {
+      if (mode === 'add') {
+        tableState.resetPage()
+      } else {
+        tableState.getUserList()
+      }
+    }
+
+    provide('modal-state', modalState)
+
+    return {
+      t,
+      onAddUser: modalState.onAddUser,
+      onSuccess,
+      ...tableState
+    }
+  },
+  render() {
+    const { t, onSearchValOk, onSearchValClear, userListLoading } = this
+    return (
+      <>
+        <NGrid cols={1} yGap={16}>
+          <NGridItem>
+            <NCard>
+              <NSpace justify='space-between'>
+                <NButton onClick={this.onAddUser} type='primary'>
+                  {t('security.user.create_user')}
+                </NButton>
+                <NInputGroup>
+                  <NInput
+                    v-model:value={this.searchInputVal}
+                    clearable
+                    onClear={onSearchValClear}
+                    onKeyup={(e) => {
+                      if (e.key === 'Enter') {
+                        onSearchValOk()
+                      }","[{'comment': ""e.key === 'Enter' && onSearchValOk()"", 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/index.tsx,"@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, provide } from 'vue'","[{'comment': 'provide is deprecated.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/components/use-modal.tsx,"@@ -0,0 +1,236 @@
+import { ref, watch, computed } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { useMessage } from 'naive-ui'
+import { queryTenantList } from '@/service/modules/tenants'
+import { queryList } from '@/service/modules/queues'
+import {
+  createUser,
+  updateUser,
+  delUserById,
+  verifyUserName
+} from '@/service/modules/users'
+export type Mode = 'add' | 'edit' | 'delete'
+
+export function useModal() {
+  const message = useMessage()
+  const { t } = useI18n()
+  const show = ref(false)
+  const mode = ref<Mode>('add')
+  const user = ref()
+  const formRef = ref()
+  const formValues = ref({
+    userName: '',
+    userPassword: '',
+    tenantId: 0,
+    email: '',
+    queue: '',
+    phone: '',
+    state: 1
+  })
+  const tenants = ref<any[]>([])
+  const queues = ref<any[]>([])
+  const optionsLoading = ref(false)
+  const confirmLoading = ref(false)
+
+  const formRules = computed(() => {
+    return {
+      userName: {
+        required: true,
+        message: t('security.user.username_rule_msg'),
+        trigger: 'blur'
+      },
+      userPassword: {
+        required: mode.value === 'add',
+        validator(rule: any, value?: string) {
+          if (mode.value !== 'add' && !value) {
+            return true
+          }
+          const msg = t('security.user.user_password_rule_msg')
+          if (
+            !value ||
+            !/^(?![0-9]+$)(?![a-zA-Z]+$)[0-9A-Za-z]{6,20}$/.test(value)","[{'comment': 'Regular can be put in utils/regex.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/components/use-modal.tsx,"@@ -0,0 +1,236 @@
+import { ref, watch, computed } from 'vue'","[{'comment': 'If there is no file returned by dom, you do not need to use tsx, it is recommended to change it to ts.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/locales/modules/zh_CN.ts,"@@ -26,7 +26,9 @@ const login = {
 
 const modal = {
   cancel: '取消',
-  confirm: '确定'
+  confirm: '确定',
+  save_error_msg: '保存失败，请重试',","[{'comment': 'This message information should not be presented in the modal. This is a business function, and the meaning of the button in the place where the pop-up window is used will be different.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/locales/modules/zh_CN.ts,"@@ -26,7 +26,9 @@ const login = {
 
 const modal = {
   cancel: '取消',
-  confirm: '确定'
+  confirm: '确定',
+  save_error_msg: '保存失败，请重试',
+  delete_error_msg: '删除失败，请重试',","[{'comment': 'This message information should not be presented in the modal. This is a business function, and the meaning of the button in the place where the pop-up window is used will be different.', 'commenter': 'songjianet'}]"
8133,dolphinscheduler-ui-next/src/views/security/user-manage/components/use-modal.tsx,"@@ -0,0 +1,236 @@
+import { ref, watch, computed } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { useMessage } from 'naive-ui'
+import { queryTenantList } from '@/service/modules/tenants'
+import { queryList } from '@/service/modules/queues'
+import {
+  createUser,
+  updateUser,
+  delUserById,
+  verifyUserName
+} from '@/service/modules/users'
+export type Mode = 'add' | 'edit' | 'delete'
+
+export function useModal() {
+  const message = useMessage()
+  const { t } = useI18n()
+  const show = ref(false)
+  const mode = ref<Mode>('add')
+  const user = ref()
+  const formRef = ref()
+  const formValues = ref({","[{'comment': 'please use reactive', 'commenter': 'labbomb'}]"
8174,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/k8s/K8sManager.java,"@@ -0,0 +1,67 @@
+package org.apache.dolphinscheduler.service.k8s;
+
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import io.fabric8.kubernetes.client.Config;
+import io.fabric8.kubernetes.client.DefaultKubernetesClient;
+import io.fabric8.kubernetes.client.KubernetesClient;
+import org.apache.dolphinscheduler.dao.entity.K8s;
+import org.apache.dolphinscheduler.dao.mapper.K8sMapper;
+import org.apache.dolphinscheduler.remote.exceptions.RemotingException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Hashtable;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * A separate class, because then wait for multiple environment feature, currently using db configuration, later unified
+ */
+@Component
+public class K8sManager {
+    /**
+     * logger of K8sManager
+     */","[{'comment': 'This kind of comment is meaningless', 'commenter': 'kezhenxu94'}]"
8174,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/k8s/K8sManager.java,"@@ -0,0 +1,67 @@
+package org.apache.dolphinscheduler.service.k8s;
+
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import io.fabric8.kubernetes.client.Config;
+import io.fabric8.kubernetes.client.DefaultKubernetesClient;
+import io.fabric8.kubernetes.client.KubernetesClient;
+import org.apache.dolphinscheduler.dao.entity.K8s;
+import org.apache.dolphinscheduler.dao.mapper.K8sMapper;
+import org.apache.dolphinscheduler.remote.exceptions.RemotingException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Hashtable;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * A separate class, because then wait for multiple environment feature, currently using db configuration, later unified
+ */
+@Component
+public class K8sManager {
+    /**
+     * logger of K8sManager
+     */
+    private static final Logger logger = LoggerFactory.getLogger(K8sManager.class);
+    /**
+     * cache k8s client
+     */
+    private static Map<String, KubernetesClient> clientMap = new Hashtable<>();
+
+    @Autowired
+    private K8sMapper k8sMapper;
+
+    public KubernetesClient getK8sClient(String k8sName) {
+        if(null == k8sName)
+        {
+            return null;
+        }","[{'comment': 'Please keep the code style consistent...', 'commenter': 'kezhenxu94'}]"
8174,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/k8s/K8sManager.java,"@@ -0,0 +1,67 @@
+package org.apache.dolphinscheduler.service.k8s;
+
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import io.fabric8.kubernetes.client.Config;
+import io.fabric8.kubernetes.client.DefaultKubernetesClient;
+import io.fabric8.kubernetes.client.KubernetesClient;
+import org.apache.dolphinscheduler.dao.entity.K8s;
+import org.apache.dolphinscheduler.dao.mapper.K8sMapper;
+import org.apache.dolphinscheduler.remote.exceptions.RemotingException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Hashtable;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * A separate class, because then wait for multiple environment feature, currently using db configuration, later unified
+ */
+@Component
+public class K8sManager {
+    /**
+     * logger of K8sManager
+     */
+    private static final Logger logger = LoggerFactory.getLogger(K8sManager.class);
+    /**
+     * cache k8s client
+     */
+    private static Map<String, KubernetesClient> clientMap = new Hashtable<>();
+
+    @Autowired
+    private K8sMapper k8sMapper;
+
+    public KubernetesClient getK8sClient(String k8sName) {
+        if(null == k8sName)
+        {
+            return null;
+        }
+        return clientMap.get(k8sName);
+    }
+
+    @PostConstruct
+    public void buildApiClientAll() throws RemotingException {
+        QueryWrapper<K8s> nodeWrapper = new QueryWrapper<>();
+        List<K8s> k8sList = k8sMapper.selectList(nodeWrapper);
+
+        if(k8sList!=null) {","[{'comment': 'Format the codes please...\r\n\r\n```suggestion\r\n        if (k8sList!=null) {\r\n```', 'commenter': 'kezhenxu94'}]"
8174,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/k8s/K8sManager.java,"@@ -0,0 +1,67 @@
+package org.apache.dolphinscheduler.service.k8s;
+
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import io.fabric8.kubernetes.client.Config;
+import io.fabric8.kubernetes.client.DefaultKubernetesClient;
+import io.fabric8.kubernetes.client.KubernetesClient;
+import org.apache.dolphinscheduler.dao.entity.K8s;
+import org.apache.dolphinscheduler.dao.mapper.K8sMapper;
+import org.apache.dolphinscheduler.remote.exceptions.RemotingException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Hashtable;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * A separate class, because then wait for multiple environment feature, currently using db configuration, later unified
+ */
+@Component
+public class K8sManager {
+    /**
+     * logger of K8sManager
+     */
+    private static final Logger logger = LoggerFactory.getLogger(K8sManager.class);
+    /**
+     * cache k8s client
+     */
+    private static Map<String, KubernetesClient> clientMap = new Hashtable<>();
+
+    @Autowired
+    private K8sMapper k8sMapper;
+
+    public KubernetesClient getK8sClient(String k8sName) {
+        if(null == k8sName)
+        {
+            return null;
+        }
+        return clientMap.get(k8sName);
+    }
+
+    @PostConstruct
+    public void buildApiClientAll() throws RemotingException {
+        QueryWrapper<K8s> nodeWrapper = new QueryWrapper<>();
+        List<K8s> k8sList = k8sMapper.selectList(nodeWrapper);
+
+        if(k8sList!=null) {
+            for(K8s k8s : k8sList) {","[{'comment': '```suggestion\r\n            for (K8s k8s : k8sList) {\r\n```', 'commenter': 'kezhenxu94'}]"
8174,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/k8s/K8sManager.java,"@@ -0,0 +1,67 @@
+package org.apache.dolphinscheduler.service.k8s;
+
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import io.fabric8.kubernetes.client.Config;
+import io.fabric8.kubernetes.client.DefaultKubernetesClient;
+import io.fabric8.kubernetes.client.KubernetesClient;
+import org.apache.dolphinscheduler.dao.entity.K8s;
+import org.apache.dolphinscheduler.dao.mapper.K8sMapper;
+import org.apache.dolphinscheduler.remote.exceptions.RemotingException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.util.Hashtable;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * A separate class, because then wait for multiple environment feature, currently using db configuration, later unified
+ */
+@Component
+public class K8sManager {
+    /**
+     * logger of K8sManager
+     */
+    private static final Logger logger = LoggerFactory.getLogger(K8sManager.class);
+    /**
+     * cache k8s client
+     */
+    private static Map<String, KubernetesClient> clientMap = new Hashtable<>();
+
+    @Autowired
+    private K8sMapper k8sMapper;
+
+    public KubernetesClient getK8sClient(String k8sName) {
+        if(null == k8sName)
+        {
+            return null;
+        }
+        return clientMap.get(k8sName);
+    }
+
+    @PostConstruct
+    public void buildApiClientAll() throws RemotingException {
+        QueryWrapper<K8s> nodeWrapper = new QueryWrapper<>();
+        List<K8s> k8sList = k8sMapper.selectList(nodeWrapper);
+
+        if(k8sList!=null) {
+            for(K8s k8s : k8sList) {
+                DefaultKubernetesClient client =  getClient(k8s.getK8sConfig());","[{'comment': '```suggestion\r\n                DefaultKubernetesClient client = getClient(k8s.getK8sConfig());\r\n```', 'commenter': 'kezhenxu94'}]"
8174,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/K8s.java,"@@ -0,0 +1,83 @@
+package org.apache.dolphinscheduler.dao.entity;","[{'comment': 'License header', 'commenter': 'kezhenxu94'}]"
8174,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/K8s.java,"@@ -0,0 +1,103 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.dao.entity;
+
+import java.util.Date;
+
+import com.baomidou.mybatisplus.annotation.IdType;
+import com.baomidou.mybatisplus.annotation.TableField;
+import com.baomidou.mybatisplus.annotation.TableId;
+import com.baomidou.mybatisplus.annotation.TableName;
+
+/**
+ * multi-data centre k8s temporary structure, waiting for new feature to complete will switch
+ */
+@TableName(""t_ds_k8s"")","[{'comment': ""Sorry, I can't get your point to add the `t_ds_k8s` table, and what features do you want to implement?"", 'commenter': 'caishunfeng'}, {'comment': 'Hi，you have a multi-environment feature being worked on https://github.com/apache/dolphinscheduler/issues/7623, I consulted Klein and  told me i could support multiple k8s first by db store and wait for that multi-environment to be finished,or I re-implement the transition solution along the lines of your idea, as long as it supports different k8s clusters', 'commenter': 'qianli2022'}]"
8558,dolphinscheduler-e2e/dolphinscheduler-e2e-case/src/test/java/org/apache/dolphinscheduler/e2e/pages/project/ProjectPage.java,"@@ -65,36 +69,50 @@ public ProjectPage create(String project) {
         createProjectForm().buttonSubmit().click();
 
         new WebDriverWait(driver(), 10)
-            .until(ExpectedConditions.textToBePresentInElementLocated(By.className(""project-name""), project));
+                .until(ExpectedConditions.textToBePresentInElementLocated(By.className(""project-name""), project));
+
+        return this;
+    }
+
+    public ProjectPage create(String project, String describe) {","[{'comment': ""Project description is not that important and we don't want to cover every aspect of the ui so I think we don't need the test of creating project with description. It costs resources without bringing too many benefits. "", 'commenter': 'kezhenxu94'}, {'comment': ""> Project description is not that important and we don't want to cover every aspect of the ui so I think we don't need the test of creating project with description. It costs resources without bringing too many benefits.\r\n\r\nE2E task has this item, so is there any E2E task that can be done, please give it?"", 'commenter': 'yangyunxi'}]"
8839,dolphinscheduler-ui-next/src/views/security/user-manage/types.ts,"@@ -0,0 +1,47 @@
+import type {","[{'comment': 'Lack license header.', 'commenter': 'songjianet'}]"
8991,dolphinscheduler-ui-next/src/views/datasource/list/detail.tsx,"@@ -141,7 +141,6 @@ const DetailModal = defineComponent({
                 rules={rules}
                 ref='detailFormRef'
                 require-mark-placement='left'
-                label-placement='left'
                 label-width={180}","[{'comment': '`label-width` is not required in top-down forms.', 'commenter': 'songjianet'}, {'comment': 'ok，i will fix it\r\n', 'commenter': 'labbomb'}]"
9062,dolphinscheduler-ui-next/src/utils/column-config.ts,"@@ -0,0 +1,94 @@
+/*","[{'comment': 'This file should be update to be column-width-config.ts', 'commenter': 'songjianet'}, {'comment': 'Got it,I will change the file name to column-width-config and the COLUMN_CONFIG to COLUMN_WIDTH_CONFIG.', 'commenter': 'Amy0104'}]"
9246,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/AlertPluginManager.java,"@@ -53,25 +52,22 @@
 public final class AlertPluginManager {
     private static final Logger logger = LoggerFactory.getLogger(AlertPluginManager.class);
 
-    private final PluginDao pluginDao;
+    @Autowired
+    private PluginDao pluginDao;
 
     private final Map<Integer, AlertChannel> channelKeyedById = new HashMap<>();
 
     private final PluginParams warningTypeParams = getWarningTypeParams();
 
-    public AlertPluginManager(PluginDao pluginDao) {
-        this.pluginDao = pluginDao;
-    }
-","[{'comment': 'This part is a different spring injection method, it is not recommended to modify.', 'commenter': 'zhuangchong'}, {'comment': '> This part is a different spring injection method, it is not recommended to modify.\r\n\r\nyes, I know, first, this is constructor injection, and has the same effect as @Autowired, both are byType, secondly, keep the style consistent, such as master/worker. What do you think?', 'commenter': 'guoshupei'}, {'comment': 'I recommend keeping the original constructor injection and see what other small partners have suggestions.', 'commenter': 'zhuangchong'}, {'comment': '\r\n> I recommend keeping the original constructor injection and see what other small partners have suggestions.\r\n\r\nOkay,  i agree with you.\r\n', 'commenter': 'guoshupei'}]"
9246,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/AlertRequestProcessor.java,"@@ -36,11 +37,8 @@
 public final class AlertRequestProcessor implements NettyRequestProcessor {
     private static final Logger logger = LoggerFactory.getLogger(AlertRequestProcessor.class);
 
-    private final AlertSender alertSender;
-
-    public AlertRequestProcessor(AlertSender alertSender) {
-        this.alertSender = alertSender;
-    }","[{'comment': 'same as previous question.', 'commenter': 'zhuangchong'}, {'comment': 'same as previous answer', 'commenter': 'guoshupei'}]"
9246,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/AlertSenderService.java,"@@ -17,43 +17,60 @@
 
 package org.apache.dolphinscheduler.alert;
 
-import org.apache.dolphinscheduler.alert.api.AlertChannel;
-import org.apache.dolphinscheduler.alert.api.AlertConstants;
-import org.apache.dolphinscheduler.alert.api.AlertData;
-import org.apache.dolphinscheduler.alert.api.AlertInfo;
-import org.apache.dolphinscheduler.alert.api.AlertResult;
+import org.apache.commons.collections.CollectionUtils;
+import org.apache.dolphinscheduler.alert.api.*;","[{'comment': 'code style', 'commenter': 'zhuangchong'}, {'comment': 'okay, thanks', 'commenter': 'guoshupei'}]"
9246,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/AlertSenderService.java,"@@ -17,43 +17,60 @@
 
 package org.apache.dolphinscheduler.alert;
 
-import org.apache.dolphinscheduler.alert.api.AlertChannel;
-import org.apache.dolphinscheduler.alert.api.AlertConstants;
-import org.apache.dolphinscheduler.alert.api.AlertData;
-import org.apache.dolphinscheduler.alert.api.AlertInfo;
-import org.apache.dolphinscheduler.alert.api.AlertResult;
+import org.apache.commons.collections.CollectionUtils;
+import org.apache.dolphinscheduler.alert.api.*;
+import org.apache.dolphinscheduler.common.Constants;
 import org.apache.dolphinscheduler.common.enums.AlertStatus;
 import org.apache.dolphinscheduler.common.enums.WarningType;
+import org.apache.dolphinscheduler.common.thread.Stopper;
 import org.apache.dolphinscheduler.common.utils.JSONUtils;
 import org.apache.dolphinscheduler.dao.AlertDao;
 import org.apache.dolphinscheduler.dao.entity.Alert;
 import org.apache.dolphinscheduler.dao.entity.AlertPluginInstance;
 import org.apache.dolphinscheduler.remote.command.alert.AlertSendResponseCommand;
 import org.apache.dolphinscheduler.remote.command.alert.AlertSendResponseResult;
-
-import org.apache.commons.collections.CollectionUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
 
 import java.util.ArrayList;
 import java.util.List;
 import java.util.Map;
 import java.util.Optional;
+import java.util.concurrent.TimeUnit;
 
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.springframework.stereotype.Component;
+@Service
+public final class AlertSenderService extends Thread {
+    private static final Logger logger = LoggerFactory.getLogger(AlertSenderService.class);
 
-@Component
-public final class AlertSender {
-    private static final Logger logger = LoggerFactory.getLogger(AlertSender.class);
+    @Autowired
+    private AlertDao alertDao;
 
-    private final AlertDao alertDao;
-    private final AlertPluginManager alertPluginManager;
+    @Autowired
+    private AlertPluginManager alertPluginManager;
 
-    public AlertSender(AlertDao alertDao, AlertPluginManager alertPluginManager) {
-        this.alertDao = alertDao;
-        this.alertPluginManager = alertPluginManager;","[{'comment': 'same as previous question.', 'commenter': 'zhuangchong'}, {'comment': 'same as previous answer', 'commenter': 'guoshupei'}]"
9246,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java,"@@ -17,73 +17,104 @@
 
 package org.apache.dolphinscheduler.alert;
 
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.IStoppable;
 import org.apache.dolphinscheduler.common.thread.Stopper;
-import org.apache.dolphinscheduler.dao.AlertDao;
 import org.apache.dolphinscheduler.dao.PluginDao;
-import org.apache.dolphinscheduler.dao.entity.Alert;
 import org.apache.dolphinscheduler.remote.NettyRemotingServer;
 import org.apache.dolphinscheduler.remote.command.CommandType;
 import org.apache.dolphinscheduler.remote.config.NettyServerConfig;
-
-import java.io.Closeable;
-import java.util.List;
-import java.util.concurrent.Executors;
-import java.util.concurrent.TimeUnit;
-
-import javax.annotation.PreDestroy;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.springframework.beans.factory.annotation.Autowired;
-import org.springframework.boot.SpringApplication;
+import org.springframework.boot.WebApplicationType;
 import org.springframework.boot.autoconfigure.SpringBootApplication;
+import org.springframework.boot.builder.SpringApplicationBuilder;
 import org.springframework.boot.context.event.ApplicationReadyEvent;
 import org.springframework.context.annotation.ComponentScan;
 import org.springframework.context.event.EventListener;
 
+import javax.annotation.PostConstruct;
+
 @SpringBootApplication
 @ComponentScan(""org.apache.dolphinscheduler"")
-public class AlertServer implements Closeable {
+public class AlertServer implements IStoppable {","[{'comment': 'The stop method of IStoppable is called by a special check method, but it is not available in AlertServer.', 'commenter': 'zhuangchong'}, {'comment': 'yes, you are right. The action of interface of `IStoppable`  is to stop by external trigger. such as `RegistryClient`, we can refer to master or worker. At present, `AlertServer` is  not distributed, and stop is not be used, but I think it should be reserved for distributed considerations.', 'commenter': 'guoshupei'}, {'comment': ""You are right, I suggest that the `IStoppable` code and the AlertServer's distributed code are in one PR. If only `IStoppable` code was committed, then `stop` would be an issue during this period."", 'commenter': 'zhuangchong'}, {'comment': ""> You are right, I suggest that the `IStoppable` code and the AlertServer's distributed code are in one PR. If only `IStoppable` code was committed, then `stop` would be an issue during this period.\r\n\r\nYes, i agree with you. I will remove `IStoppable` , at persent, I have no idea to complete the distribution of `AlertServer` , mainly because `WorkerServer` is directly connected to `AlertServer`"", 'commenter': 'guoshupei'}]"
9325,.github/workflows/e2e.yml,"@@ -17,9 +17,13 @@
 
 on:
   pull_request:
+    paths-ignore:
+      - 'docs/**'
   push:
     branches:
       - dev
+    paths-ignore:
+      - 'docs/**'","[{'comment': 'I remember I told you that this can not be added because if the workflow is skipped, the PRs cannot be merged', 'commenter': 'kezhenxu94'}, {'comment': ""Sorry,I forgot this. I'll see if i can fix it. If not i will remove it. @kezhenxu94 "", 'commenter': 'SbloodyS'}, {'comment': 'I try to modify ```e2e-test```  with ```https://github.com/dorny/paths-filter#examples``` and ```https://github.com/dorny/paths-filter/issues/97```. Please check if this is correct. If not i will remove it. Thanks. @kezhenxu94 ', 'commenter': 'SbloodyS'}, {'comment': 'It seems like ```dorny/paths-filter@v2 is not allowed to be used in apache/dolphinscheduler```. Sad...', 'commenter': 'SbloodyS'}, {'comment': 'I have submitted a request to apache infra to see if this plugin can be enable. ```https://issues.apache.org/jira/browse/INFRA-23069```\r\n\r\nIn the mean time, I will mark this pr as draft until this plugin is enable or i can find another way to solve this problem.\r\n\r\n', 'commenter': 'SbloodyS'}, {'comment': '@SbloodyS you can use this getsentry/paths-filter@v2 instead, seems they have the same functionalities and this is approved already by infra team as I know', 'commenter': 'kezhenxu94'}, {'comment': '> @SbloodyS you can use this getsentry/paths-filter@v2 instead, seems they have the same functionalities and this is approved already by infra team as I know\r\n\r\nWow, It seems working. I will do more tests to verify it. Thanks.', 'commenter': 'SbloodyS'}]"
9325,.github/workflows/backend.yml,"@@ -63,3 +77,17 @@ jobs:
                  -Dmaven.wagon.httpconnectionManager.ttlSeconds=120
       - name: Check dependency license
         run: tools/dependencies/check-LICENSE.sh
+  result:
+    name: Build
+    runs-on: ubuntu-latest
+    timeout-minutes: 30
+    needs: [ build ]","[{'comment': 'Did we miss job `paths-filter` dependent here?', 'commenter': 'zhongjiajie'}, {'comment': 'It does not need to. It already exists in steps.run.', 'commenter': 'SbloodyS'}, {'comment': ""@zhongjiajie we don't need explicit dependent here, `result` depends on `build`, `build` depends on `paths-filter`, so `result` depends on `paths-filter` implicitly "", 'commenter': 'kezhenxu94'}, {'comment': 'Thanks for the clarification.', 'commenter': 'zhongjiajie'}]"
9327,dolphinscheduler-task-plugin/dolphinscheduler-task-zeppelin/src/test/java/org/apache/dolphinscheduler/plugin/task/zeppelin/ZeppelinParametersTest.java,"@@ -0,0 +1,61 @@
+///*
+// * Licensed to the Apache Software Foundation (ASF) under one or more
+// * contributor license agreements.  See the NOTICE file distributed with
+// * this work for additional information regarding copyright ownership.
+// * The ASF licenses this file to You under the Apache License, Version 2.0
+// * (the ""License""); you may not use this file except in compliance with
+// * the License.  You may obtain a copy of the License at
+// *
+// *    http://www.apache.org/licenses/LICENSE-2.0
+// *
+// * Unless required by applicable law or agreed to in writing, software
+// * distributed under the License is distributed on an ""AS IS"" BASIS,
+// * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+// * See the License for the specific language governing permissions and
+// * limitations under the License.
+// */
+//
+//package org.apache.dolphinscheduler.plugin.task.spark;
+//
+//import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+//
+//import org.apache.commons.collections.CollectionUtils;
+//
+//import java.util.LinkedList;
+//import java.util.List;
+//
+//import org.junit.Assert;
+//import org.junit.Test;
+//
+//public class SparkParametersTest {
+//
+//    @Test","[{'comment': 'Why do you comment the unittest?', 'commenter': 'zhongjiajie'}, {'comment': ""> Why do you comment the unittest?\r\n\r\nBecause I haven't written it yet, just copied from SparkTest, lol. I'm working on it. "", 'commenter': 'EricGao888'}]"
9327,dolphinscheduler-task-plugin/dolphinscheduler-task-zeppelin/src/main/java/org/apache/dolphinscheduler/plugin/task/zeppelin/ZeppelinTask.java,"@@ -0,0 +1,148 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.zeppelin;
+
+import org.apache.zeppelin.client.*;","[{'comment': 'Please avoid import ```*```.', 'commenter': 'SbloodyS'}, {'comment': '> Please avoid import `*`.\r\n\r\nThx for the suggestion, will fix it.', 'commenter': 'EricGao888'}, {'comment': 'Already fixed in the latest commit. ', 'commenter': 'EricGao888'}]"
9327,dolphinscheduler-task-plugin/dolphinscheduler-task-zeppelin/src/main/java/org/apache/dolphinscheduler/plugin/task/zeppelin/ZeppelinTask.java,"@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.zeppelin;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.PropertyUtils;
+import org.apache.zeppelin.client.ClientConfig;
+import org.apache.zeppelin.client.ParagraphResult;
+import org.apache.zeppelin.client.Status;
+import org.apache.zeppelin.client.ZeppelinClient;
+
+
+public class ZeppelinTask extends AbstractTaskExecutor {
+
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+
+    /**
+     * zeppelin parameters
+     */
+    private ZeppelinParameters zeppelinParameters;
+
+    /**
+     * zeppelin api client
+     */
+    private ZeppelinClient zClient;
+
+
+    /**
+     * constructor
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    protected ZeppelinTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+    }
+
+    @Override
+    public void init() {
+        final String taskParams = taskExecutionContext.getTaskParams();
+        logger.info(""zeppelin task params:{}"", taskParams);
+        this.zeppelinParameters = JSONUtils.parseObject(taskParams, ZeppelinParameters.class);
+        if (this.zeppelinParameters == null || !this.zeppelinParameters.checkParameters()) {
+            throw new ZeppelinTaskException(""zeppelin task params is not valid"");
+        }
+        this.zClient = getZeppelinClient();
+    }
+
+    @Override
+    public void handle() throws Exception {
+        try {
+            String noteId = this.zeppelinParameters.getNoteId();
+            String paragraphId = this.zeppelinParameters.getParagraphId();","[{'comment': 'If the Zeppelin task plugin only has two parameters, paragraphId and noteId, is it better to use the Http task node to call it?', 'commenter': 'zhuangchong'}, {'comment': ""@zhuangchong Actually we could use http task node for most kinds of tasks using restful api, such as EMR task, etc. However, \r\nIMHO there are four main reasons we could use zeppelin task plugin for zeppelin tasks:\r\n1. There are several different RESTful APIs we need to call during the process of executing / scheduling zeppelin tasks. It seems we cannot achieve this goal using http task plugin.\r\n2. We could gain better control in the process of submitting / executing zeppelin tasks by using zeppelin task plugin. In the future PRs, I will improve the method of submitting zeppelin tasks in a non-blocking fashion. In this way, we could query the task execution progress (in percentile) through zeppelin client, which will give our users a better experience.\r\n3. We could manage authentication easily with zeppelin task plugin, although authentication feature hasn't been implemented in this PR. It seems not very practical or convenient for users to use http task plugin to manage this.\r\n4. We could control the result output from zeppelin task plugin. The raw output from zeppelin execution could contain a lot of information users do not really need to see. We filter useless output and only log key information through zeppelin task plugin."", 'commenter': 'EricGao888'}, {'comment': 'OK, I hope to support writing sql statements on the Dolphin page.', 'commenter': 'zhuangchong'}]"
9327,dolphinscheduler-common/src/main/resources/common.properties,"@@ -91,3 +91,5 @@ development.state=false
 # rpc port
 alert.rpc.port=50052
 
+# Url endpoint for zeppelin RESTful API
+zeppelin.rest.url=""http://localhost:8080""","[{'comment': 'zeppelin is a task plugin for dolphin, I recommend this parameter as a parameter of the zeppelin plugin instead of a public parameter.', 'commenter': 'zhuangchong'}, {'comment': '@zhuangchong May I ask where can I add parameter for zeppelin plugin instead of public parameter? Is there anything like task-plugin level `properties` file? ', 'commenter': 'EricGao888'}, {'comment': 'If only one zepplin server is connected, there is no problem with this configuration at present.', 'commenter': 'zhuangchong'}, {'comment': '> @zhuangchong May I ask where can I add parameter for zeppelin plugin instead of public parameter? Is there anything like task-plugin level properties file?\r\n\r\nWhy we should have separate configurations for a single task? I think we should get all config in one single config file. It is easy to maintain and also easy for uses. For ex, when we change our task structure(like add provider) we have to move our code from one side to another, if config file alone with task code, maybe they should change the position too. And this will make user confuse for the position change.', 'commenter': 'zhongjiajie'}, {'comment': 'Maybe we should add a new component named `connection`, like Airflow, for the dynamic config task plugin. And in this way, we could not only have task config but also can change config without restart our server', 'commenter': 'zhongjiajie'}, {'comment': '> Maybe we should add a new component named `connection`, like Airflow, for the dynamic config task plugin. And in this way, we could not only have task config but also can change config without restart our server\r\n\r\nThe `connection` idea sounds cool. It will be more convenient for users to change their credentials.', 'commenter': 'EricGao888'}, {'comment': 'Yeah, but we need more discussion about it on our mailing list or other places. And config like your patch it is good for this PR for now', 'commenter': 'zhongjiajie'}]"
9327,tools/dependencies/known-dependencies.txt,"@@ -273,3 +273,14 @@ aws-java-sdk-s3-1.12.160.jar
 aws-java-sdk-kms-1.12.160.jar
 aws-java-sdk-emr-1.12.160.jar
 aws-java-sdk-core-1.12.160.jar
+commons-text-1.8.jar","[{'comment': 'You should add those packages to the right place in `dolphinscheduler-dist/release-docs/LICENSE` too', 'commenter': 'zhongjiajie'}, {'comment': ""> You should add those packages to the right place in `dolphinscheduler-dist/release-docs/LICENSE` too\r\n\r\n@zhongjiajie I think I've already added them. Is there anything wrong with the LICENSEs? \r\n![image](https://user-images.githubusercontent.com/34905992/162354641-b6e667c6-90af-499b-991c-1592a274cd59.png)\r\n"", 'commenter': 'EricGao888'}, {'comment': 'You should also add them to file https://github.com/apache/dolphinscheduler/blob/81f9b876f9f5865a7e65b668008af0cde580b326/dolphinscheduler-dist/release-docs/LICENSE', 'commenter': 'zhongjiajie'}, {'comment': '> You should also add them to file https://github.com/apache/dolphinscheduler/blob/81f9b876f9f5865a7e65b668008af0cde580b326/dolphinscheduler-dist/release-docs/LICENSE\r\n\r\nGot it. Thx!', 'commenter': 'EricGao888'}, {'comment': '> You should also add them to file https://github.com/apache/dolphinscheduler/blob/81f9b876f9f5865a7e65b668008af0cde580b326/dolphinscheduler-dist/release-docs/LICENSE\r\n\r\nFixed in the latest commit.', 'commenter': 'EricGao888'}]"
9327,dolphinscheduler-task-plugin/dolphinscheduler-task-zeppelin/src/main/java/org/apache/dolphinscheduler/plugin/task/zeppelin/ZeppelinParameters.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.zeppelin;
+
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+public class ZeppelinParameters extends AbstractParameters {
+
+    /**
+     * job flow define in json format
+     * @see <a href=""https://docs.aws.amazon.com/emr/latest/APIReference/API_RunJobFlow.html#API_RunJobFlow_Examples"">API_RunJobFlow_Examples</a>
+     */","[{'comment': 'The documentation link address is wrong.', 'commenter': 'zhuangchong'}, {'comment': 'Thx for the reminder. I will fix it.', 'commenter': 'EricGao888'}, {'comment': '> The documentation link address is wrong.\r\n\r\n@zhuangchong Fixed in the latest commit. PTAL when you have time. Thx!\r\n', 'commenter': 'EricGao888'}]"
9371,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -81,13 +77,27 @@ public int addAlert(Alert alert) {
      * @return update alert result
      */
     public int updateAlert(AlertStatus alertStatus, String log, int id) {
-        Alert alert = alertMapper.selectById(id);
+        Alert alert = new Alert();
+        alert.setId(id);
         alert.setAlertStatus(alertStatus);
         alert.setUpdateTime(new Date());
         alert.setLog(log);
         return alertMapper.updateById(alert);
     }
 
+    /**
+     * 生成通知签名信息
+     * @param alert 通知实体
+     * @return 签名文本","[{'comment': '@czeming English comments is recommended.', 'commenter': 'lenboo'}, {'comment': 'Done', 'commenter': 'czeming'}]"
9371,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -17,39 +17,35 @@
 
 package org.apache.dolphinscheduler.dao;
 
+import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import com.google.common.collect.Lists;
+import org.apache.commons.codec.digest.DigestUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.apache.dolphinscheduler.common.enums.AlertEvent;
 import org.apache.dolphinscheduler.common.enums.AlertStatus;
 import org.apache.dolphinscheduler.common.enums.AlertWarnLevel;
 import org.apache.dolphinscheduler.common.enums.WarningType;
 import org.apache.dolphinscheduler.common.utils.JSONUtils;
-import org.apache.dolphinscheduler.dao.entity.Alert;
-import org.apache.dolphinscheduler.dao.entity.AlertPluginInstance;
-import org.apache.dolphinscheduler.dao.entity.AlertSendStatus;
-import org.apache.dolphinscheduler.dao.entity.ProcessAlertContent;
-import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
-import org.apache.dolphinscheduler.dao.entity.ProjectUser;
-import org.apache.dolphinscheduler.dao.entity.ServerAlertContent;
-import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.dao.entity.*;","[{'comment': 'Please avoid import ```*```', 'commenter': 'SbloodyS'}]"
9371,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -17,39 +17,35 @@
 
 package org.apache.dolphinscheduler.dao;
 
+import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;
+import com.baomidou.mybatisplus.core.conditions.query.QueryWrapper;
+import com.google.common.collect.Lists;
+import org.apache.commons.codec.digest.DigestUtils;
+import org.apache.commons.lang3.StringUtils;
 import org.apache.dolphinscheduler.common.enums.AlertEvent;
 import org.apache.dolphinscheduler.common.enums.AlertStatus;
 import org.apache.dolphinscheduler.common.enums.AlertWarnLevel;
 import org.apache.dolphinscheduler.common.enums.WarningType;
 import org.apache.dolphinscheduler.common.utils.JSONUtils;
-import org.apache.dolphinscheduler.dao.entity.Alert;
-import org.apache.dolphinscheduler.dao.entity.AlertPluginInstance;
-import org.apache.dolphinscheduler.dao.entity.AlertSendStatus;
-import org.apache.dolphinscheduler.dao.entity.ProcessAlertContent;
-import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
-import org.apache.dolphinscheduler.dao.entity.ProjectUser;
-import org.apache.dolphinscheduler.dao.entity.ServerAlertContent;
-import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.dao.entity.*;
 import org.apache.dolphinscheduler.dao.mapper.AlertGroupMapper;
 import org.apache.dolphinscheduler.dao.mapper.AlertMapper;
 import org.apache.dolphinscheduler.dao.mapper.AlertPluginInstanceMapper;
 import org.apache.dolphinscheduler.dao.mapper.AlertSendStatusMapper;
-
-import org.apache.commons.lang.StringUtils;
-
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Date;
-import java.util.List;
-import java.util.stream.Collectors;
-
+import org.joda.time.DateTime;
 import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
 import org.springframework.stereotype.Component;
 
-import com.google.common.collect.Lists;
+import java.util.*;","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}, {'comment': 'done, please review again, thanks.', 'commenter': 'czeming'}]"
9371,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -131,8 +156,11 @@ public void sendServerStopedAlert(int alertGroupId, String host, String serverTy
         alert.setAlertGroupId(alertGroupId);
         alert.setCreateTime(new Date());
         alert.setUpdateTime(new Date());
+        alert.setSign(generateSign(alert));
         // we use this method to avoid insert duplicate alert(issue #5525)
-        alertMapper.insertAlertWhenServerCrash(alert);
+        // we modified this method to optimize performance(issue #9174)
+        Date crashAlarmSuppressionStartTime = DateTime.now().plusMinutes(-crashAlarmSuppression).toDate();
+        alertMapper.insertAlertWhenServerCrash(alert, crashAlarmSuppressionStartTime);","[{'comment': ""This method is triggered when the master server or worker server stops, which is not a lot, I suggest that you don't need to add. Can be added to the alert server."", 'commenter': 'zhuangchong'}, {'comment': 'I resolved the conflict.\r\n\r\nAdd reason for _crashAlarmSuppressionStartTime_: \r\n1. The addition of this parameter is a key condition for the initial screening of data, which can reduce the performance problems caused by the increase of data.\r\n2. **If this parameter is not added, according to the current logic, the warning after the first time of the same host will not be added.** ', 'commenter': 'czeming'}, {'comment': ""You are right, it's me who didn't understand the requirement. Using `content` to determine is the problem."", 'commenter': 'zhuangchong'}]"
9371,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -52,13 +54,8 @@
 import java.util.concurrent.locks.Lock;
 import java.util.concurrent.locks.ReentrantLock;
 
-import javax.annotation.PreDestroy;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.springframework.beans.factory.InitializingBean;
-import org.springframework.beans.factory.annotation.Autowired;
-import org.springframework.stereotype.Service;
+import static org.apache.dolphinscheduler.common.Constants.REGISTRY_DOLPHINSCHEDULER_MASTERS;
+import static org.apache.dolphinscheduler.common.Constants.REGISTRY_DOLPHINSCHEDULER_WORKERS;","[{'comment': 'This part of checkstyle is wrong. It is not clear that CI has not detected it, but it can be detected locally. It is recommended to modify it.', 'commenter': 'zhuangchong'}, {'comment': 'Is my mistake. I didn\'t import the style check configuration `style/checkstyle.xml`.\r\n\r\nI have solved all the files related to my changes. In addition, I see many codes with the same problems.\r\n\r\n\r\nI think we can improve the documentation provided to developers, which is expected to improve the quality of subsequent code.\r\n\r\nFrom this configuration `style/checkstyle.xml` > `ImportOrder`:\r\n\r\n```\r\n        <module name=""ImportOrder"">\r\n            <property name=""staticGroups"" value=""org.apache.dolphinscheduler,org.apache,java,javax,org,com""/>\r\n            <property name=""separatedStaticGroups"" value=""true""/>\r\n\r\n            <property name=""groups"" value=""org.apache.dolphinscheduler,org.apache,java,javax,org,com""/>\r\n            <property name=""ordered"" value=""true""/>\r\n            <property name=""separated"" value=""true""/>\r\n            <property name=""option"" value=""top""/>\r\n            <property name=""sortStaticImportsAlphabetically"" value=""true""/>\r\n        </module>\r\n```', 'commenter': 'czeming'}]"
9393,docs/img_utils.py,"@@ -32,16 +32,6 @@
 img_dir: Path = root_dir.joinpath(""img"")
 doc_dir: Path = root_dir.joinpath(""docs"")
 
-expect_img_types: Set = {
-    ""jpg"",
-    ""png"",
-}","[{'comment': 'Good job.', 'commenter': 'zhongjiajie'}]"
9393,docs/img_utils.py,"@@ -68,14 +58,14 @@ def get_paths_rel_path(paths: Set[Path], rel: Path) -> Set:
     return {f""/{path.relative_to(rel)}"" for path in paths}
 
 
-def get_docs_img_path(paths: Set[Path], pattern: re.Pattern) -> Set:
+def get_docs_img_path(paths: Set[Path]) -> Set:
     """"""Get all img syntax from given :param:`paths` using the regexp from :param:`pattern`.""""""
     res = set()
     for path in paths:
         content = path.read_text()
-        find = pattern.findall(content)
+        find = re.findall(r""/img[\w./-]*"", content)","[{'comment': 'I think we should move this regexp pattern to L102 or L64 for higher performance. And the best practices for regexp is using `re.compile` to create one compile and then use it in the feature saving memory. you could see example in function `build_pattern`', 'commenter': 'zhongjiajie'}, {'comment': '> I think we should move this regexp pattern to L102 or L64 for higher performance. And the best practices for regexp is using `re.compile` to create one compile and then use it in the feature saving memory. you could see example in function `build_pattern`\r\n\r\nSure, I will change it to use `re.compile`.', 'commenter': 'EricGao888'}, {'comment': '> I think we should move this regexp pattern to L102 or L64 for higher performance. And the best practices for regexp is using `re.compile` to create one compile and then use it in the feature saving memory. you could see example in function `build_pattern`\r\n\r\n@zhongjiajie Fixed in the latest commit. PTAL. ', 'commenter': 'EricGao888'}]"
9614,script/scp-hosts.sh,"@@ -28,6 +28,7 @@ if [[ ""$OSTYPE"" == ""darwin""* ]]; then
 fi
 
 workersGroup=(${workers//,/ })
+declare -A workersGroupMap","[{'comment': '```declare -A``` is not working in ```mac``` system.\r\n\r\nI think a new implementation is needed.', 'commenter': 'SbloodyS'}, {'comment': 'Hi @SbloodyS ,\r\nBash version on Mac is 3.x while on Linux its verion is usually 4.x +. Bash 3.x does not support `declare -A`.\r\n\r\nIf we have to support Bash 3.x, we need to avoid declaring a variable as map.', 'commenter': 'paul8263'}, {'comment': 'We can replace the map with two arrays, with assigning the key value pair the same index. However it seems that the worker groups are not needed in those scripts. Can I just remove worker groups and add them back if they were required in future versions?', 'commenter': 'paul8263'}, {'comment': 'Sorry for late reply. Yes. You can remove worker groups since it is not currently used. @paul8263 ', 'commenter': 'SbloodyS'}]"
9614,script/scp-hosts.sh,"@@ -47,11 +42,17 @@ do
   echo ""scp dirs to $host/$installPath starting""
 	ssh -p $sshPort $host  ""cd $installPath/; rm -rf bin/ conf/ lib/ script/ sql/ ui/""
 
+  for i in ${!workerNames[@]}; do
+    if [[ ${workerNames[$i]} == $host ]]; then
+      workerIndex=$i
+      break
+    fi
+  done
+
   for dsDir in bin master-server worker-server alert-server api-server ui
   do
-    # if worker in workersGroupMap
-    if [[ ""${workersGroupMap[${host}]}"" ]]; then
-      echo ""export WORKER_GROUPS_0=${workersGroupMap[${host}]}"" >> worker-server/bin/dolphinscheduler_env.sh
+    if [[ ! -z ${workerIndex+x} ]]; then
+      echo ""export WORKER_GROUPS_0=${groupNames[$workerIndex]}"" >> worker-server/bin/dolphinscheduler_env.sh","[{'comment': 'This path has change to ```worker-server/conf/application.yaml```. And the variables ```WORKER_GROUPS_0``` is no longer exists.\r\nhttps://github.com/apache/dolphinscheduler/blob/a6c14fb23369ae37a1f5f0232ace90fa7a39435f/dolphinscheduler-worker/src/main/resources/application.yaml#L72-L73', 'commenter': 'SbloodyS'}, {'comment': ""So can I simply remove line 53 and 54 as it has already been defined in each worker's application.yaml?\r\n"", 'commenter': 'paul8263'}, {'comment': 'No. we should adapt this logic to ```application.yaml```', 'commenter': 'SbloodyS'}]"
9614,script/scp-hosts.sh,"@@ -47,11 +42,17 @@ do
   echo ""scp dirs to $host/$installPath starting""
 	ssh -p $sshPort $host  ""cd $installPath/; rm -rf bin/ conf/ lib/ script/ sql/ ui/""
 
+  for i in ${!workerNames[@]}; do
+    if [[ ${workerNames[$i]} == $host ]]; then
+      workerIndex=$i
+      break
+    fi
+  done
+
   for dsDir in bin master-server worker-server alert-server api-server ui
   do
-    # if worker in workersGroupMap
-    if [[ ""${workersGroupMap[${host}]}"" ]]; then
-      echo ""export WORKER_GROUPS_0=${workersGroupMap[${host}]}"" >> worker-server/bin/dolphinscheduler_env.sh
+    if [[ ! -z ${workerIndex+x} ]]; then","[{'comment': 'Why do I need a default value of ```x``` here?', 'commenter': 'SbloodyS'}, {'comment': ""It is a way to test whether workerIndex has been defined (The IP were included in workers or not ). If we don't need this I will remove it."", 'commenter': 'paul8263'}, {'comment': 'Would it be better to use ```if [[ -n ${workerIndex} ]]```?', 'commenter': 'SbloodyS'}, {'comment': 'Yes. I wrongly used two negative conditions (`! -z`). I will replace it.', 'commenter': 'paul8263'}]"
9625,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProjectServiceImpl.java,"@@ -38,6 +38,7 @@
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.stereotype.Service;
 
+import javax.annotation.PostConstruct;
 import java.util.*;","[{'comment': 'Please avoid ```import *```', 'commenter': 'SbloodyS'}, {'comment': 'Thank you, I will pay more attention to the code smell of commits.', 'commenter': 'WangJPLeo'}]"
9671,docs/docs/en/guide/parameter/context.md,"@@ -55,7 +55,15 @@ There is only the ""id"" value. Although the user-defined SQL query both ""id"" and
 ### SHELL
 
 `prop` is user-specified and the direction is `OUT`. The output is defined as an export parameter only when the direction is `OUT`. Choose data structures for data type according to the scenario, and leave the value part blank.
-The user needs to pass the parameter when creating the shell script, the output statement format is `${setValue(key=value)}`, the key is the `prop` of the corresponding parameter, and value is the value of the parameter.
+
+The user needs to pass the parameter when creating the shell script, the output statement format is `${setValue(key=value)}` or `#{setValue(key=value)}`, the key is the `prop` of the corresponding parameter, and value is the value of the parameter.","[{'comment': '```suggestion\r\nIf the user needs to pass the parameter when creating the shell script. The output statement format is `${setValue(key=value)}` or `#{setValue(key=value)}`. the key is the `prop` of the corresponding parameter. And value is the value of the parameter.\r\n```', 'commenter': 'SbloodyS'}, {'comment': 'Maybe we can change it to this: \r\n\r\n""If the user wants to pass parameters, you need to output statements in the form of `${setValue(key=value)}` or `#{setValue(key=value)}` when defining the shell script, where the key is the `prop` of the corresponding parameter, and value is the value of the parameter.\r\n\r\n如果用户想要传递参数，那么在定义 shell 脚本时，需要输出格式为 `${setValue(key=value)}` 或者 `#{setValue(key=value)}` 的语句，其中 key 为对应参数的 prop，value 为该参数的值。""\r\n\r\nWhat do you think?\r\n', 'commenter': 'exmy'}, {'comment': 'The chinese part LGTM. But I think the English part of ```suggestion change``` is better. @exmy ', 'commenter': 'SbloodyS'}]"
9671,docs/docs/zh/guide/parameter/context.md,"@@ -57,13 +57,19 @@ prop 为用户指定；方向选择为 OUT，只有当方向为 OUT 时才会被
 prop 为用户指定；方向选择为 OUT，只有当方向为 OUT 时才会被定义为变量输出；数据类型可以根据需要选择不同数据结构；value 部分不需要填写。
 
 
-用户需要传递参数，在定义 shell 脚本时，需要输出格式为 ${setValue(key=value)} 的语句，key 为对应参数的 prop，value 为该参数的值。
+用户需要传递参数，在定义 shell 脚本时，需要输出格式为 `${setValue(key=value)}` 或者 `#{setValue(key=value)}` 的语句，key 为对应参数的 prop，value 为该参数的值。","[{'comment': '```suggestion\r\n如果用户需要传递参数，在定义 shell 脚本时，需要输出格式为 `${setValue(key=value)}` 或者 `#{setValue(key=value)}` 的语句，key 为对应参数的 prop，value 为该参数的值。\r\n```', 'commenter': 'SbloodyS'}]"
9718,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/DagHelper.java,"@@ -565,20 +554,40 @@ public static boolean haveConditionsAfterNode(String parentNodeCode, List<TaskNo
         return false;
     }
 
+
     /**
      * is there have blocking node after the parent node
      */
     public static boolean haveBlockingAfterNode(String parentNodeCode,
                                                 DAG<String,TaskNode,TaskNodeRelation> dag) {
+        return haveSubAfterNode(parentNodeCode, dag, true, TaskConstants.TASK_TYPE_BLOCKING);
+    }
+
+    /**
+     * is there have all node after the parent node
+     */
+    public static boolean haveAllNodeAfterNode(String parentNodeCode,
+                                               DAG<String,TaskNode,TaskNodeRelation> dag) {
+        return haveSubAfterNode(parentNodeCode, dag, false, null);
+    }
+
+    /**
+     * Whether there is a specified type of child node after the parent node
+     */
+    public static boolean haveSubAfterNode(String parentNodeCode,
+                                           DAG<String,TaskNode,TaskNodeRelation> dag, boolean typeCheck, String checkType) {
         Set<String> subsequentNodes = dag.getSubsequentNodes(parentNodeCode);
         if (CollectionUtils.isEmpty(subsequentNodes)) {
             return false;
         }
         for (String nodeName : subsequentNodes) {
             TaskNode taskNode = dag.getNode(nodeName);
             List<String> preTaskList = JSONUtils.toList(taskNode.getPreTasks(),String.class);
-            if (preTaskList.contains(parentNodeCode) && taskNode.isBlockingTask()) {
-                return true;
+            boolean contains = preTaskList.contains(parentNodeCode);
+            if (typeCheck){
+                return contains && taskNode.getType().equalsIgnoreCase(checkType);
+            } else {
+                return contains;","[{'comment': 'The logic is not a match to the method name. ', 'commenter': 'ruanwenjun'}, {'comment': 'ok, i will fix it.', 'commenter': 'WangJPLeo'}]"
9718,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -456,9 +456,9 @@ private void taskFinished(TaskInstance taskInstance) {
             retryTaskInstance(taskInstance);
         } else if (taskInstance.getState().typeIsFailure()) {
             completeTaskMap.put(taskInstance.getTaskCode(), taskInstance.getId());
-            if (taskInstance.isConditionsTask()","[{'comment': 'Is it OK if remove the task type check?', 'commenter': 'caishunfeng'}]"
9718,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/DagHelper.java,"@@ -565,20 +554,40 @@ public static boolean haveConditionsAfterNode(String parentNodeCode, List<TaskNo
         return false;
     }
 
+
     /**
      * is there have blocking node after the parent node
      */
     public static boolean haveBlockingAfterNode(String parentNodeCode,
                                                 DAG<String,TaskNode,TaskNodeRelation> dag) {
+        return haveSubAfterNode(parentNodeCode, dag, true, TaskConstants.TASK_TYPE_BLOCKING);
+    }
+
+    /**
+     * is there have all node after the parent node
+     */
+    public static boolean haveAllNodeAfterNode(String parentNodeCode,","[{'comment': 'Do you want to mean have any node?', 'commenter': 'ruanwenjun'}, {'comment': 'A node with child nodes in the process. The conditions for submitting child nodes when the current node fails are: there are child nodes and the failure strategy is continue. @ruanwenjun ', 'commenter': 'WangJPLeo'}, {'comment': '@WangJPLeo I mean that it better to rename this method name to `haveAnyNodeAfterNode`, since I find you just want to check if there exist any node after the parentNodeCode.', 'commenter': 'ruanwenjun'}, {'comment': 'ok thanks, i see what you mean.', 'commenter': 'WangJPLeo'}]"
9718,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/utils/DagHelper.java,"@@ -565,20 +554,40 @@ public static boolean haveConditionsAfterNode(String parentNodeCode, List<TaskNo
         return false;
     }
 
+
     /**
      * is there have blocking node after the parent node
      */
     public static boolean haveBlockingAfterNode(String parentNodeCode,
                                                 DAG<String,TaskNode,TaskNodeRelation> dag) {
+        return haveSubAfterNode(parentNodeCode, dag, true, TaskConstants.TASK_TYPE_BLOCKING);
+    }
+
+    /**
+     * is there have all node after the parent node
+     */
+    public static boolean haveAllNodeAfterNode(String parentNodeCode,
+                                               DAG<String,TaskNode,TaskNodeRelation> dag) {
+        return haveSubAfterNode(parentNodeCode, dag, false, null);
+    }
+
+    /**
+     * Whether there is a specified type of child node after the parent node
+     */
+    public static boolean haveSubAfterNode(String parentNodeCode,
+                                           DAG<String,TaskNode,TaskNodeRelation> dag, boolean additionalNodeTypeFiltering, String filterNodeType) {
         Set<String> subsequentNodes = dag.getSubsequentNodes(parentNodeCode);
         if (CollectionUtils.isEmpty(subsequentNodes)) {
             return false;
         }
         for (String nodeName : subsequentNodes) {
             TaskNode taskNode = dag.getNode(nodeName);
             List<String> preTaskList = JSONUtils.toList(taskNode.getPreTasks(),String.class);
-            if (preTaskList.contains(parentNodeCode) && taskNode.isBlockingTask()) {
-                return true;
+            boolean containsParentNodeCode = preTaskList.contains(parentNodeCode);
+            if (additionalNodeTypeFiltering){
+                return containsParentNodeCode && taskNode.getType().equalsIgnoreCase(filterNodeType);
+            } else {
+                return containsParentNodeCode;
             }
         }
         return false;","[{'comment': 'The logic is wrong in your change. In my knowledge, this method is used to check if there exist any subNode(filter by type) of the given parentNode.\r\nSee the below case, the input is `parentNodeA` and `Type2 `, the return result might be false, but the expect result is true.\r\n<img width=""465"" alt=""image"" src=""https://user-images.githubusercontent.com/22415594/164983262-d3b2232a-f4c1-4376-8a2a-3bdcd9b81e5f.png"">\r\n\r\nBTY, the parameter `additionalNodeTypeFiltering` `filterNodeType` is duplicate, you can just hold `filterNodeType` is enough.\r\n', 'commenter': 'ruanwenjun'}, {'comment': 'Yes, an error may occur in the case of multiple child nodes, a revision has been committed.', 'commenter': 'WangJPLeo'}]"
9792,docs/docs/en/guide/alert/http.md,"@@ -0,0 +1,35 @@
+# HTTP
+
+If you need to use `Http script` for alerting, create an alert instance in the alert instance management and select the `Http` plugin.
+
+## Parameter Configuration
+
+* URL
+  > The `Http` request URL needs to contain protocol, host, path and parameters if the method is `GET`
+* Request Type
+  > Select the request type from `POST` or `GET`
+* Headers
+  > The headers of the `Http` request in JSON format
+* Body
+  > The request body of the `Http` request in JSON format, when using `POST` method to alert
+* Content Field
+  > The field name to place the alert information
+
+## Send Type
+
+Using `POST` and `GET` method to send `Http` request in the `Request Type`.
+
+### GET Http
+
+Send alert information by `Http` GET method.
+GET `Http`告警指将告警结果作为参数通过`Http` GET方法进行请求。","[{'comment': 'please handle', 'commenter': 'zhuangchong'}]"
9800,dolphinscheduler-ui-next/src/views/datasource/list/detail.tsx,"@@ -264,9 +264,10 @@ const DetailModal = defineComponent({
                 <NFormItem
                   label={t('datasource.user_password')}
                   path='password'
+                  show-require-mark
                 >
                   <NInput
-                    class='input-password'
+                    class='input-pessword'","[{'comment': 'Why did you modify this class? It may affect e2e', 'commenter': 'devosend'}, {'comment': 'If you make changes here, please modify e2e synchronously.', 'commenter': 'songjianet'}, {'comment': 'misoperation, my problem, I will fix it', 'commenter': 'SnowMoon-Dev'}]"
9800,dolphinscheduler-ui-next/src/views/datasource/list/use-form.ts,"@@ -138,9 +146,15 @@ export function useForm(id?: number) {
   const resetFieldsValue = () => {
     state.detailForm = { ...initialValues }
   }
-  const setFieldsValue = (values: object) => {
-    state.detailForm = { ...state.detailForm, ...values }
+
+  const setFieldsValue = (values: IDataSourceDetail) => {
+    state.detailForm = {
+      ...state.detailForm,
+      ...values,
+      password: values.password ? values.password : '******'","[{'comment': 'Password will be hidden by the password type input.', 'commenter': 'devosend'}]"
9800,dolphinscheduler-ui-next/src/views/resource/task-group/queue/use-table.ts,"@@ -149,14 +148,8 @@ export function useTable(
           }
 
           item.taskGroupName = taskGroupName
-          item.createTime = format(
-            parseTime(item.createTime),
-            'yyyy-MM-dd HH:mm:ss'
-          )
-          item.updateTime = format(
-            parseTime(item.updateTime),
-            'yyyy-MM-dd HH:mm:ss'
-          )
+          item.createTime = renderFormat(item.createTime)","[{'comment': ""CreateTime doesn't need to be formatted here, it will be formatted when the table is rendered."", 'commenter': 'devosend'}]"
9800,dolphinscheduler-ui-next/src/views/datasource/list/index.tsx,"@@ -120,7 +120,7 @@ const list = defineComponent({
                   <div class={styles['conditions-search-input']}>
                     <NInput
                       v-model={[this.searchVal, 'value']}
-                      placeholder={`${t('datasource.search_input_tips')}`}
+                      placeholder={`${t('datasource.datasource_name_tips')}`}","[{'comment': 'It is not recommended to change here, and will be optimized in the future.', 'commenter': 'songjianet'}]"
9800,dolphinscheduler-ui-next/src/views/datasource/list/use-detail.ts,"@@ -25,6 +25,7 @@ import {
 } from '@/service/modules/data-source'
 import { useI18n } from 'vue-i18n'
 import type { IDataSource } from './types'
+import { IDataSourceDetail } from './types'","[{'comment': 'To import types please use `import type` .', 'commenter': 'songjianet'}]"
9851,docs/docs/zh/guide/task/spark.md,"@@ -2,7 +2,11 @@
 
 ## 综述
 
-Spark  任务类型，用于执行 Spark 程序。对于 Spark 节点，worker 会通过使用 spark 命令 `spark submit` 方式提交任务。更多详情查看 [spark-submit](https://spark.apache.org/docs/3.2.1/submitting-applications.html#launching-applications-with-spark-submit)。
+Spark  任务类型，用于执行 Spark 程序。对于 Spark 节点，worker 会通过使用 spark 命令：","[{'comment': '```suggestion\r\nSpark 任务类型用于执行 Spark 应用。对于 Spark 节点，worker 支持两个不同类型的 spark 命令提交任务：\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/zh/guide/task/spark.md,"@@ -22,11 +26,13 @@ Spark  任务类型，用于执行 Spark 程序。对于 Spark 节点，worker 
 - 失败重试间隔：任务失败重新提交任务的时间间隔，以分为单位。
 - 延迟执行时间：任务延迟执行的时间，以分为单位。
 - 超时警告：勾选超时警告、超时失败，当任务超过“超时时长”后，会发送告警邮件并且任务执行失败。
-- 程序类型：支持 Java、Scala 和 Python 三种语言。
+- 程序类型：支持 Java、Scala、Python 和 Sql 四种语言。","[{'comment': '```suggestion\r\n- 程序类型：支持 Java、Scala、Python 和 SQL 四种语言。\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/zh/guide/task/spark.md,"@@ -40,30 +46,44 @@ Spark  任务类型，用于执行 Spark 程序。对于 Spark 节点，worker 
 
 ## 任务样例
 
-### 执行 WordCount 程序
+### (1) spark submit","[{'comment': '```suggestion\r\n### spark submit\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/zh/guide/task/spark.md,"@@ -40,30 +46,44 @@ Spark  任务类型，用于执行 Spark 程序。对于 Spark 节点，worker 
 
 ## 任务样例
 
-### 执行 WordCount 程序
+### (1) spark submit
+
+#### 执行 WordCount 程序
 
 本案例为大数据生态中常见的入门案例，常应用于 MapReduce、Flink、Spark 等计算框架。主要为统计输入的文本中，相同的单词的数量有多少。
 
-#### 在 DolphinScheduler 中配置 Spark 环境
+##### 在 DolphinScheduler 中配置 Spark 环境
 
 若生产环境中要是使用到 Spark 任务类型，则需要先配置好所需的环境。配置文件如下：`bin/env/dolphinscheduler_env.sh`。
 
 ![spark_configure](/img/tasks/demo/spark_task01.png)
 
-####  上传主程序包
+#####  上传主程序包
 
 在使用 Spark 任务节点时，需要利用资源中心上传执行程序的 jar 包，可参考[资源中心](../resource.md)。
 
 当配置完成资源中心之后，直接使用拖拽的方式，即可上传所需目标文件。
 
 ![resource_upload](/img/tasks/demo/upload_jar.png)
 
-#### 配置 Spark 节点
+##### 配置 Spark 节点
 
 根据上述参数说明，配置所需的内容即可。
 
 ![demo-spark-simple](/img/tasks/demo/spark_task02.png)
 
+### (2) spark sql","[{'comment': '```suggestion\r\n### spark sql\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/en/guide/task/spark.md,"@@ -2,7 +2,11 @@
 
 ## Overview
 
-Spark task type used to execute Spark program. For Spark nodes, the worker submits the task by using the spark command `spark submit`. See [spark-submit](https://spark.apache.org/docs/3.2.1/submitting-applications.html#launching-applications-with-spark-submit) for more details.
+Spark task type for executing Spark programs. For Spark nodes, the worker will do this by using the spark command:","[{'comment': '```suggestion\r\nSpark task type for executing Spark application. When executing the Spark task, the worker will submits a job to the Spark cluster by following commands:\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/en/guide/task/spark.md,"@@ -21,11 +25,13 @@ Spark task type used to execute Spark program. For Spark nodes, the worker submi
 - **Failed retry interval**: The time interval (unit minute) for resubmitting the task after a failed task.
 - **Delayed execution time**: The time (unit minute) that a task delays in execution.
 - **Timeout alarm**: Check the timeout alarm and timeout failure. When the task runs exceed the ""timeout"", an alarm email will send and the task execution will fail.
-- **Program type**: Supports Java, Scala and Python.
+- **Program type**: Supports Java, Scala, Python and Sql.","[{'comment': '```suggestion\r\n- **Program type**: Supports Java, Scala, Python and SQL.\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/en/guide/task/spark.md,"@@ -39,30 +45,42 @@ Spark task type used to execute Spark program. For Spark nodes, the worker submi
 
 ## Task Example
 
-### Execute the WordCount Program
+### (1) spark submit","[{'comment': '```suggestion\r\n### spark submit\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/en/guide/task/spark.md,"@@ -39,30 +45,42 @@ Spark task type used to execute Spark program. For Spark nodes, the worker submi
 
 ## Task Example
 
-### Execute the WordCount Program
+### (1) spark submit
+
+#### Execute the WordCount Program
 
 This is a common introductory case in the big data ecosystem, which often apply to computational frameworks such as MapReduce, Flink and Spark. The main purpose is to count the number of identical words in the input text. (Flink's releases attach this example job)
 
-#### Configure the Spark Environment in DolphinScheduler
+##### Configure the Spark Environment in DolphinScheduler
 
 If you are using the Spark task type in a production environment, it is necessary to configure the required environment first. The following is the configuration file: `bin/env/dolphinscheduler_env.sh`.
 
 ![spark_configure](/img/tasks/demo/spark_task01.png)
 
-#### Upload the Main Package
+##### Upload the Main Package
 
 When using the Spark task node, you need to upload the jar package to the Resource Centre for the execution, refer to the [resource center](../resource.md).
 
 After finish the Resource Centre configuration, upload the required target files directly by dragging and dropping.
 
 ![resource_upload](/img/tasks/demo/upload_jar.png)
 
-#### Configure Spark Nodes
+##### Configure Spark Nodes
 
 Configure the required content according to the parameter descriptions above.
 
 ![demo-spark-simple](/img/tasks/demo/spark_task02.png)
 
+### (2) spark sql","[{'comment': '```suggestion\r\n### spark sql\r\n```', 'commenter': 'zhongjiajie'}]"
9851,docs/docs/en/guide/task/spark.md,"@@ -39,30 +45,42 @@ Spark task type used to execute Spark program. For Spark nodes, the worker submi
 
 ## Task Example
 
-### Execute the WordCount Program
+### (1) spark submit
+
+#### Execute the WordCount Program
 
 This is a common introductory case in the big data ecosystem, which often apply to computational frameworks such as MapReduce, Flink and Spark. The main purpose is to count the number of identical words in the input text. (Flink's releases attach this example job)
 
-#### Configure the Spark Environment in DolphinScheduler
+##### Configure the Spark Environment in DolphinScheduler
 
 If you are using the Spark task type in a production environment, it is necessary to configure the required environment first. The following is the configuration file: `bin/env/dolphinscheduler_env.sh`.
 
 ![spark_configure](/img/tasks/demo/spark_task01.png)
 
-#### Upload the Main Package
+##### Upload the Main Package
 
 When using the Spark task node, you need to upload the jar package to the Resource Centre for the execution, refer to the [resource center](../resource.md).
 
 After finish the Resource Centre configuration, upload the required target files directly by dragging and dropping.
 
 ![resource_upload](/img/tasks/demo/upload_jar.png)
 
-#### Configure Spark Nodes
+##### Configure Spark Nodes
 
 Configure the required content according to the parameter descriptions above.
 
 ![demo-spark-simple](/img/tasks/demo/spark_task02.png)
 
+### (2) spark sql
+
+#### Execute DDL and DML statements
+
+This case is to create a view table terms and write three rows of data and a table wc in parquet format and determine whether the table exists. The program type is SQL. Insert the data of the view table terms into the table wc in parquet format.
+
+![spark_sql](/img/tasks/demo/spark_sql.png)
+
 ## Notice
 
-JAVA and Scala only used for identification, there is no difference. If you use Python to develop Spark application, there is no class of the main function and the rest is the same.
+JAVA and Scala are only used for identification, and there is no difference. If it is Spark developed by Python, there is no class for the main function. Others are the same. JAVA, Scala and Python do not have SQL scripts.","[{'comment': '```suggestion\r\nJAVA and Scala are only used for identification, and there is no difference when you use the Spark task. If your application is developed by Python, you could just ignore the parameter **Main Class** in the form. Parameter **SQL scripts** is only for SQL type and could be ignored in JAVA, Scala and Python.\r\n```', 'commenter': 'zhongjiajie'}, {'comment': '```suggestion\r\nJAVA and Scala are only used for identification, and there is no difference when you use the Spark task. If your application is developed by Python, you could just ignore the parameter **Main Class** in the form. Parameter **SQL scripts** is only for SQL type and could be ignored in JAVA, Scala and Python.\r\n```', 'commenter': 'zhongjiajie'}, {'comment': ""OK, I'll revise it now."", 'commenter': 'sq-q'}]"
9887,et --soft,"@@ -0,0 +1,242 @@
+[33mcommit 404f7c8b06c19a3db3b25e161f495f795cdef81b[m[33m ([m[1;36mHEAD -> [m[1;32mdev[m[33m, [m[1;31morigin/dev[m[33m, [m[1;31morigin/HEAD[m[33m)[m","[{'comment': 'This file should not be included in this PR.', 'commenter': 'SbloodyS'}]"
9955,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -417,8 +417,12 @@ private boolean taskStateChangeHandler(StateEvent stateEvent) {
         }
         if (activeTaskProcessorMaps.containsKey(task.getTaskCode())) {
             ITaskProcessor iTaskProcessor = activeTaskProcessorMaps.get(task.getTaskCode());
-            iTaskProcessor.action(TaskAction.RUN);
-
+            // pending task needs to be dispatched
+            if (task.getState().typeIsPending()){","[{'comment': 'hello, in dispatchFailedTaskInstanceState2Pending() method, you just save the pending status to db but not in WorkflowExecuteThread.taskInstanceMap, i am not sure if the task here that get from taskInstanceMap can be pending, or the taskInstanceMap may update taskInstance other place ?', 'commenter': 'genuinner'}, {'comment': 'Thanks, the consideration here is that the task instance in the Pending state needs to be dispatched when a failover occurs, I reconfirmed the test and found that this is not the case. But the interesting thing is that a historical problem was discovered during the period, the selected task instance was recreated when the Master service failed over. The executed task instance is re-created, causing the execution of the new task instance to resume successfully, The old task instance will not change anything and generate garbage data. This problem will be written in Issues and will be resolved in the next PR. Finally thank you again for your review.', 'commenter': 'WangJPLeo'}]"
9955,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -120,12 +140,13 @@ public void run() {
 
                 if (!failedDispatchTasks.isEmpty()) {
                     for (TaskPriority dispatchFailedTask : failedDispatchTasks) {
-                        taskPriorityQueue.put(dispatchFailedTask);
-                    }
-                    // If there are tasks in a cycle that cannot find the worker group,
-                    // sleep for 1 second
-                    if (taskPriorityQueue.size() <= failedDispatchTasks.size()) {
-                        TimeUnit.MILLISECONDS.sleep(Constants.SLEEP_TIME_MILLIS);
+                        if (dispatchFailedTask.getDispatchFailedRetryTimes() >= Constants.DEFAULT_MAX_RETRY_COUNT){
+                            logger.error(""the number of retries for dispatch failure has exceeded the maximum limit, taskId: {} processInstanceId: {}"", dispatchFailedTask.getTaskId(), dispatchFailedTask.getProcessInstanceId());
+                            // business alarm
+                            continue;","[{'comment': 'These tasks need to continue to be submitted.', 'commenter': 'lenboo'}, {'comment': 'Yes, Thanks.  After retries 100 times, the business alarm, and then continue to retry according to each 100s delay.', 'commenter': 'WangJPLeo'}]"
9955,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -129,11 +149,13 @@ public void run() {
                 if (CollectionUtils.isNotEmpty(failedDispatchTasks)) {
                     TaskMetrics.incTaskDispatchFailed(failedDispatchTasks.size());
                     for (TaskPriority dispatchFailedTask : failedDispatchTasks) {
-                        taskPriorityQueue.put(dispatchFailedTask);
-                    }
-                    // If the all task dispatch failed, will sleep for 1s to avoid the master cpu higher.
-                    if (fetchTaskNum == failedDispatchTasks.size()) {
-                        TimeUnit.MILLISECONDS.sleep(Constants.SLEEP_TIME_MILLIS);
+                        // service alarm when retries 100 times
+                        if (dispatchFailedTask.getDispatchFailedRetryTimes() == Constants.DEFAULT_MAX_RETRY_COUNT){
+                            logger.error(""the number of retries for dispatch failure has exceeded the maximum limit, taskId: {} processInstanceId: {}"", dispatchFailedTask.getTaskId(), dispatchFailedTask.getProcessInstanceId());
+                            // business alarm
+                        }
+                        // differentiate the queue to prevent high priority from affecting the execution of other tasks
+                        taskPriorityDispatchFailedQueue.put(dispatchFailedTask);","[{'comment': 'So if one task exceeds the max retry times, will it still retry in your plan? I guess you set the maxRetryTimes is want to stop retry?', 'commenter': 'ruanwenjun'}, {'comment': 'Instead of stopping the retry, the retry interval is increased according to the number of retries. When the maximum number of retries is reached, each time interval is 100s. This is described in the comment on line 222 (retry more than 100 times with 100 seconds delay each time).', 'commenter': 'WangJPLeo'}]"
9955,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -150,6 +172,20 @@ public List<TaskPriority> batchDispatch(int fetchTaskNum) throws TaskPriorityQue
         List<TaskPriority> failedDispatchTasks = Collections.synchronizedList(new ArrayList<>());
         CountDownLatch latch = new CountDownLatch(fetchTaskNum);
 
+        // put the failed dispatch task into the dispatch queue again
+        for (int i = 0; i < fetchTaskNum; i++) {
+            TaskPriority dispatchFailedTaskPriority = taskPriorityDispatchFailedQueue.poll(Constants.SLEEP_TIME_MILLIS, TimeUnit.MILLISECONDS);
+            if (Objects.isNull(dispatchFailedTaskPriority)){
+                continue;
+            }
+            if (canRetry(dispatchFailedTaskPriority)){
+                dispatchFailedTaskPriority.setDispatchFailedRetryTimes(dispatchFailedTaskPriority.getDispatchFailedRetryTimes() + 1);
+                taskPriorityQueue.put(dispatchFailedTaskPriority);
+            } else {
+                taskPriorityDispatchFailedQueue.put(dispatchFailedTaskPriority);
+            }
+        }","[{'comment': ""It's not a good idea to deal with the dispatchFailedQueue in the normal process. \r\nMost of the time, the failedDispatchQueue is empty, so if you use the default dispatchTaskNum -> 3, you will extra wait for 3s in each dispatch, since you need to poll the failedDispatchQueue."", 'commenter': 'ruanwenjun'}, {'comment': 'This situation may occur, and it is determined whether to traverse by judging the size of the Queue that fails to dispatch.', 'commenter': 'WangJPLeo'}]"
10096,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ClusterController.java,"@@ -0,0 +1,237 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_CLUSTER_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_CLUSTER_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_CLUSTER_BY_CODE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_CLUSTER_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_CLUSTER_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.VERIFY_CLUSTER_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.ClusterService;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.Map;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+import springfox.documentation.annotations.ApiIgnore;
+
+/**
+ * cluster controller
+ * todo 这是新增的 集群环境
+ */","[{'comment': 'Remove this kind of comments, they are meaningless ', 'commenter': 'kezhenxu94'}, {'comment': 'Just remove the chinese comments , or all of them? I find that all other classes are commented with xx controller?', 'commenter': 'qianli2022'}]"
10096,dolphinscheduler-e2e/dolphinscheduler-e2e-case/src/test/java/org/apache/dolphinscheduler/e2e/cases/ClusterE2ETest.java,"@@ -0,0 +1,123 @@
+/*
+ * Licensed to Apache Software Foundation (ASF) under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Apache Software Foundation (ASF) licenses this file to you under
+ * the Apache License, Version 2.0 (the ""License""); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.dolphinscheduler.e2e.cases;
+
+
+import static org.assertj.core.api.Assertions.assertThat;
+import static org.awaitility.Awaitility.await;
+
+import org.apache.dolphinscheduler.e2e.core.DolphinScheduler;
+import org.apache.dolphinscheduler.e2e.pages.LoginPage;
+import org.apache.dolphinscheduler.e2e.pages.security.ClusterPage;
+import org.apache.dolphinscheduler.e2e.pages.security.SecurityPage;
+
+import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Order;
+import org.junit.jupiter.api.Test;
+import org.openqa.selenium.By;
+import org.openqa.selenium.WebElement;
+import org.openqa.selenium.remote.RemoteWebDriver;
+
+@DolphinScheduler(composeFiles = ""docker/basic/docker-compose.yaml"")
+class ClusterE2ETest {","[{'comment': 'You should add this e2e case into `.github/workflows/e2e.yml`', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'qianli2022'}]"
10096,dolphinscheduler-ui/src/views/security/cluster-manage/components/cluster-modal.tsx,"@@ -0,0 +1,191 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, PropType, toRefs, watch } from 'vue'
+import Modal from '@/components/modal'
+import { NForm, NFormItem, NInput } from 'naive-ui'
+import { useModal } from './use-modal'
+import { useI18n } from 'vue-i18n'
+
+const envK8sConfigPlaceholder = `apiVersion: v1
+clusters:
+- cluster:
+    certificate-authority-data: LS0tLS1CZJQ0FURS0tLS0tCg==
+    server: https://127.0.0.1:6443
+  name: kubernetes
+contexts:
+- context:
+    cluster: kubernetes
+    user: kubernetes-admin
+  name: kubernetes-admin@kubernetes
+current-context: kubernetes-admin@kubernetes
+kind: Config
+preferences: {}
+users:
+- name: kubernetes-admin
+  user:
+    client-certificate-data: LS0tLS1CZJQ0FURS0tLS0tCg= 
+`
+
+const envYarnConfigPlaceholder = 'In development...'
+
+const ClusterModal = defineComponent({
+  name: 'ClusterModal',
+  props: {
+    showModalRef: {
+      type: Boolean as PropType<boolean>,
+      default: false
+    },
+    statusRef: {
+      type: Number as PropType<number>,
+      default: 0
+    },
+    row: {
+      type: Object as PropType<any>,
+      default: {}
+    }
+  },
+  emits: ['cancelModal', 'confirmModal'],
+  setup(props, ctx) {
+    const { variables, handleValidate } = useModal(props, ctx)
+    const { t } = useI18n()
+
+    const cancelModal = () => {
+      if (props.statusRef === 0) {
+        variables.model.name = ''
+        variables.model.k8s_config = ''
+        variables.model.yarn_config = ''
+        variables.model.description = ''
+      }
+      ctx.emit('cancelModal', props.showModalRef)
+    }
+
+    const confirmModal = () => {
+      handleValidate(props.statusRef)
+    }
+
+    const setModal = (row: any) => {
+      variables.model.code = row.code
+      variables.model.name = row.name
+      if (row.config) {
+        const config = JSON.parse(row.config)
+        variables.model.k8s_config = config.k8s || ''
+        variables.model.yarn_config = config.yarn || ''
+      } else {
+        variables.model.k8s_config = ''
+        variables.model.yarn_config = ''
+      }
+      variables.model.description = row.description
+    }
+
+    watch(
+      () => props.statusRef,
+      () => {
+        if (props.statusRef === 0) {
+          variables.model.name = ''
+          variables.model.k8s_config = ''
+          variables.model.yarn_config = ''
+          variables.model.description = ''
+        } else {
+          setModal(props.row)
+        }
+      }
+    )
+
+    watch(
+      () => props.row,
+      () => {
+        setModal(props.row)
+      }
+    )
+
+    return { t, ...toRefs(variables), cancelModal, confirmModal }
+  },
+  render() {
+    const { t } = this
+    return (
+      <div>
+        <Modal
+          title={
+            this.statusRef === 0
+              ? t('security.cluster.create_cluster')
+              : t('security.cluster.edit_cluster')","[{'comment': 'Have you committed the language packs codes?', 'commenter': 'Amy0104'}, {'comment': 'Thank you for your comments, code changed.  @Amy0104 ', 'commenter': 'tongwl'}]"
10096,dolphinscheduler-ui/src/views/security/cluster-manage/components/use-modal.ts,"@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { reactive, ref, SetupContext } from 'vue'
+import { useI18n } from 'vue-i18n'
+import {
+  verifyCluster,
+  createCluster,
+  updateCluster
+} from '@/service/modules/cluster'
+
+export function useModal(
+  props: any,
+  ctx: SetupContext<('cancelModal' | 'confirmModal')[]>
+) {
+  const { t } = useI18n()
+
+  const variables = reactive({
+    clusterFormRef: ref(),
+    model: {
+      code: ref<number>(-1),
+      name: ref(''),
+      k8s_config: ref(''),
+      yarn_config: ref(''),
+      description: ref('')
+    },
+    saving: false,
+    rules: {
+      name: {
+        required: true,
+        trigger: ['input', 'blur'],
+        validator() {
+          if (variables.model.name === '') {
+            return new Error(t('security.cluster.cluster_name_tips'))
+          }
+        }
+      },
+      description: {
+        required: true,
+        trigger: ['input', 'blur'],
+        validator() {
+          if (variables.model.description === '') {
+            return new Error(t('security.cluster.cluster_description_tips'))
+          }
+        }
+      }
+    }
+  })
+
+  const handleValidate = async (statusRef: number) => {
+    await variables.clusterFormRef.validate()
+
+    if (variables.saving) return
+    variables.saving = true
+
+    try {
+      statusRef === 0 ? await submitClusterModal() : await updateClusterModal()
+      variables.saving = false
+    } catch (err) {
+      variables.saving = false
+    }","[{'comment': 'It is better to use finally here than setting saving to false twice.', 'commenter': 'Amy0104'}, {'comment': 'Yes, you are right, code changed, I found other modules also has this issue, other modules can also be optimized:)', 'commenter': 'tongwl'}, {'comment': 'Yes, other modules also be optimized.', 'commenter': 'Amy0104'}]"
10096,dolphinscheduler-ui/src/views/security/cluster-manage/index.tsx,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, onMounted, toRefs, watch } from 'vue'
+import {
+  NButton,
+  NCard,
+  NDataTable,
+  NIcon,
+  NInput,
+  NPagination
+} from 'naive-ui'
+import { SearchOutlined } from '@vicons/antd'
+import { useI18n } from 'vue-i18n'
+import { useTable } from './use-table'
+import Card from '@/components/card'
+import ClusterModal from './components/cluster-modal'
+import styles from './index.module.scss'
+
+const clusterManage = defineComponent({
+  name: 'cluster-manage',
+  setup() {
+    const { t } = useI18n()
+    const { variables, getTableData, createColumns } = useTable()
+
+    const requestData = () => {
+      getTableData({
+        pageSize: variables.pageSize,
+        pageNo: variables.page,
+        searchVal: variables.searchVal
+      })
+    }
+
+    const onUpdatePageSize = () => {
+      variables.page = 1
+      requestData()
+    }
+
+    const onSearch = () => {
+      variables.page = 1
+      requestData()
+    }
+
+    const handleModalChange = () => {
+      variables.showModalRef = true
+      variables.statusRef = 0
+    }
+
+    const onCancelModal = () => {
+      variables.showModalRef = false
+    }
+
+    const onConfirmModal = () => {
+      variables.showModalRef = false
+      requestData()
+    }
+
+    onMounted(() => {
+      createColumns(variables)
+      requestData()
+    })
+
+    watch(useI18n().locale, () => {
+      createColumns(variables)
+    })
+
+    return {
+      t,
+      ...toRefs(variables),
+      requestData,
+      onCancelModal,
+      onConfirmModal,
+      onUpdatePageSize,
+      handleModalChange,
+      onSearch
+    }
+  },
+  render() {
+    const {
+      t,
+      requestData,
+      onUpdatePageSize,
+      onCancelModal,
+      onConfirmModal,
+      handleModalChange,
+      onSearch,
+      loadingRef
+    } = this
+
+    return (
+      <div>
+        <NCard>
+          <div class={styles['search-card']}>
+            <div>
+              <NButton
+                size='small'
+                type='primary'
+                onClick={handleModalChange}
+                class='btn-create-cluster'
+              >
+                {t('security.cluster.create_cluster')}
+              </NButton>","[{'comment': 'It  is unnecessary to wrap a div for the NButton.', 'commenter': 'Amy0104'}, {'comment': 'Yes, you are right, code changed, I found other modules also has this issue, other modules can also be optimized:)', 'commenter': 'tongwl'}]"
10096,dolphinscheduler-ui/src/views/security/cluster-manage/index.tsx,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, onMounted, toRefs, watch } from 'vue'
+import {
+  NButton,
+  NCard,
+  NDataTable,
+  NIcon,
+  NInput,
+  NPagination
+} from 'naive-ui'
+import { SearchOutlined } from '@vicons/antd'
+import { useI18n } from 'vue-i18n'
+import { useTable } from './use-table'
+import Card from '@/components/card'
+import ClusterModal from './components/cluster-modal'
+import styles from './index.module.scss'
+
+const clusterManage = defineComponent({
+  name: 'cluster-manage',
+  setup() {
+    const { t } = useI18n()
+    const { variables, getTableData, createColumns } = useTable()
+
+    const requestData = () => {
+      getTableData({
+        pageSize: variables.pageSize,
+        pageNo: variables.page,
+        searchVal: variables.searchVal
+      })
+    }
+
+    const onUpdatePageSize = () => {
+      variables.page = 1
+      requestData()
+    }
+
+    const onSearch = () => {
+      variables.page = 1
+      requestData()
+    }
+
+    const handleModalChange = () => {
+      variables.showModalRef = true
+      variables.statusRef = 0
+    }
+
+    const onCancelModal = () => {
+      variables.showModalRef = false
+    }
+
+    const onConfirmModal = () => {
+      variables.showModalRef = false
+      requestData()
+    }
+
+    onMounted(() => {
+      createColumns(variables)
+      requestData()
+    })
+
+    watch(useI18n().locale, () => {
+      createColumns(variables)
+    })
+
+    return {
+      t,
+      ...toRefs(variables),
+      requestData,
+      onCancelModal,
+      onConfirmModal,
+      onUpdatePageSize,
+      handleModalChange,
+      onSearch
+    }
+  },
+  render() {
+    const {
+      t,
+      requestData,
+      onUpdatePageSize,
+      onCancelModal,
+      onConfirmModal,
+      handleModalChange,
+      onSearch,
+      loadingRef
+    } = this
+
+    return (
+      <div>
+        <NCard>
+          <div class={styles['search-card']}>
+            <div>
+              <NButton
+                size='small'
+                type='primary'
+                onClick={handleModalChange}
+                class='btn-create-cluster'
+              >
+                {t('security.cluster.create_cluster')}
+              </NButton>
+            </div>
+            <div class={styles.box}>
+              <NInput
+                size='small'
+                clearable
+                v-model={[this.searchVal, 'value']}
+                placeholder={t('security.cluster.search_tips')}
+              />
+              <NButton size='small' type='primary' onClick={onSearch}>
+                {{
+                  icon: () => (
+                    <NIcon>
+                      <SearchOutlined />
+                    </NIcon>
+                  )
+                }}
+              </NButton>
+            </div>
+          </div>","[{'comment': ""It is better to use 'NSpace' component here."", 'commenter': 'Amy0104'}, {'comment': 'Code changed, thank you.', 'commenter': 'tongwl'}, {'comment': ""Sorry, maybe I didn't express clearly. I mean that using NSpace instead of the div with 'search-card' class. And then you don't need write css."", 'commenter': 'Amy0104'}, {'comment': ""Hi  @Amy0104,  yes, you are right, for this part, I have changed the code with NSpace(without css), it's better use NSpace.\r\nAnd about the next comments, lines near 155, as the parent div also has margin-top, not only keep NPagination center, so I kept the same code(\\<div class={styles.pagination}\\>) with other pages, because they have implemented the css margin-top in css file, so I copied and used the same way to keep them similar."", 'commenter': 'tongwl'}, {'comment': '<img width=""1101"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173729266-f3235138-c58a-43d2-9c54-afeea1d680d1.png"">\r\n<img width=""580"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173729291-6a97a9ad-f4c6-498c-90e4-f0e3f79334ac.png"">\r\n', 'commenter': 'tongwl'}, {'comment': '@Amy0104 \r\n', 'commenter': 'tongwl'}, {'comment': 'I have changed it. Pls, check.', 'commenter': 'Amy0104'}, {'comment': 'Sure, thank you for your update. BTW, the style between pages is best to be uniform, I found that there is a small place that is not the same as other pages.', 'commenter': 'tongwl'}, {'comment': '<img width=""1755"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173732007-b98e3edf-ca77-4c8a-93ca-320e8276b617.png"">\r\n<img width=""1751"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173732091-7e2694f5-e207-43cb-a9d4-886b65988f23.png"">\r\n', 'commenter': 'tongwl'}, {'comment': 'There are a few small differences between pages, probably written by different developers.\r\n<img width=""1757"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173732529-fa261600-37d2-4259-9bc4-eeca120414de.png"">\r\n<img width=""1756"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173732566-8c862585-f4e1-47c0-af0d-56aee234a58f.png"">\r\n<img width=""1778"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173732703-96c0f0cc-4ade-477e-bf4b-7ca08c4462de.png"">\r\n<img width=""1734"" alt=""image"" src=""https://user-images.githubusercontent.com/13530192/173732750-dfd955a6-4dd9-4790-898c-0635161e9103.png"">\r\n\r\n\r\n', 'commenter': 'tongwl'}, {'comment': ""That's true. So it's better to use Nspace when we need a space in a page."", 'commenter': 'Amy0104'}]"
10096,dolphinscheduler-ui/src/views/security/cluster-manage/index.tsx,"@@ -0,0 +1,170 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { defineComponent, onMounted, toRefs, watch } from 'vue'
+import {
+  NButton,
+  NCard,
+  NDataTable,
+  NIcon,
+  NInput,
+  NPagination
+} from 'naive-ui'
+import { SearchOutlined } from '@vicons/antd'
+import { useI18n } from 'vue-i18n'
+import { useTable } from './use-table'
+import Card from '@/components/card'
+import ClusterModal from './components/cluster-modal'
+import styles from './index.module.scss'
+
+const clusterManage = defineComponent({
+  name: 'cluster-manage',
+  setup() {
+    const { t } = useI18n()
+    const { variables, getTableData, createColumns } = useTable()
+
+    const requestData = () => {
+      getTableData({
+        pageSize: variables.pageSize,
+        pageNo: variables.page,
+        searchVal: variables.searchVal
+      })
+    }
+
+    const onUpdatePageSize = () => {
+      variables.page = 1
+      requestData()
+    }
+
+    const onSearch = () => {
+      variables.page = 1
+      requestData()
+    }
+
+    const handleModalChange = () => {
+      variables.showModalRef = true
+      variables.statusRef = 0
+    }
+
+    const onCancelModal = () => {
+      variables.showModalRef = false
+    }
+
+    const onConfirmModal = () => {
+      variables.showModalRef = false
+      requestData()
+    }
+
+    onMounted(() => {
+      createColumns(variables)
+      requestData()
+    })
+
+    watch(useI18n().locale, () => {
+      createColumns(variables)
+    })
+
+    return {
+      t,
+      ...toRefs(variables),
+      requestData,
+      onCancelModal,
+      onConfirmModal,
+      onUpdatePageSize,
+      handleModalChange,
+      onSearch
+    }
+  },
+  render() {
+    const {
+      t,
+      requestData,
+      onUpdatePageSize,
+      onCancelModal,
+      onConfirmModal,
+      handleModalChange,
+      onSearch,
+      loadingRef
+    } = this
+
+    return (
+      <div>
+        <NCard>
+          <div class={styles['search-card']}>
+            <div>
+              <NButton
+                size='small'
+                type='primary'
+                onClick={handleModalChange}
+                class='btn-create-cluster'
+              >
+                {t('security.cluster.create_cluster')}
+              </NButton>
+            </div>
+            <div class={styles.box}>
+              <NInput
+                size='small'
+                clearable
+                v-model={[this.searchVal, 'value']}
+                placeholder={t('security.cluster.search_tips')}
+              />
+              <NButton size='small' type='primary' onClick={onSearch}>
+                {{
+                  icon: () => (
+                    <NIcon>
+                      <SearchOutlined />
+                    </NIcon>
+                  )
+                }}
+              </NButton>
+            </div>
+          </div>
+        </NCard>
+        <Card class={styles['table-card']}>
+          <NDataTable
+            loading={loadingRef}
+            row-class-name='items'
+            columns={this.columns}
+            data={this.tableData}
+            scrollX={this.tableWidth}
+          />
+          <div class={styles.pagination}>
+            <NPagination
+              v-model:page={this.page}
+              v-model:page-size={this.pageSize}
+              page-count={this.totalPage}
+              show-size-picker
+              page-sizes={[10, 30, 50]}
+              show-quick-jumper
+              onUpdatePage={requestData}
+              onUpdatePageSize={onUpdatePageSize}
+            />
+          </div>","[{'comment': 'Same as above.', 'commenter': 'Amy0104'}, {'comment': 'Hi @Amy0104, this NPagination parent div here has other styles. In order to keep the page style and code style consistent with other modules, I have not modified this code, please help check again, thank you.', 'commenter': 'tongwl'}]"
10184,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-http.ts,"@@ -192,7 +192,7 @@ export function useHttp(model: { [field: string]: any }): IJsonItem[] {
     ...useCustomParams({
       model,
       field: 'localParams',
-      isSimple: true
+      isSimple: false","[{'comment': 'Are you sure you need the direct and the type here?', 'commenter': 'Amy0104'}, {'comment': '+1', 'commenter': 'labbomb'}, {'comment': 'Yes, because the front end displays drop-down selections for in/out and VARCHAR', 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-http/src/main/java/org/apache/dolphinscheduler/plugin/task/http/HttpParameters.java,"@@ -130,4 +136,44 @@ public int getSocketTimeout() {
     public void setSocketTimeout(int socketTimeout) {
         this.socketTimeout = socketTimeout;
     }
+    @Override
+    public void dealOutParam(String result) {
+        if (CollectionUtils.isEmpty(localParams)) {
+            return;
+        }
+        List<Property> outProperty = getOutProperty(localParams);
+        if (CollectionUtils.isEmpty(outProperty)) {
+            return;
+        }
+        if (StringUtils.isEmpty(result)) {
+            varPool.addAll(outProperty);
+            return;
+        }
+        Map<String, String> httpMapByString = getHttpMapByString(result);
+        //判断是否为空","[{'comment': 'Please use english instead of chinese', 'commenter': 'SbloodyS'}, {'comment': 'Already processed, code already committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-http/src/main/java/org/apache/dolphinscheduler/plugin/task/http/HttpParameters.java,"@@ -130,4 +136,44 @@ public int getSocketTimeout() {
     public void setSocketTimeout(int socketTimeout) {
         this.socketTimeout = socketTimeout;
     }
+    @Override
+    public void dealOutParam(String result) {
+        if (CollectionUtils.isEmpty(localParams)) {
+            return;
+        }
+        List<Property> outProperty = getOutProperty(localParams);
+        if (CollectionUtils.isEmpty(outProperty)) {
+            return;
+        }
+        if (StringUtils.isEmpty(result)) {
+            varPool.addAll(outProperty);
+            return;
+        }
+        Map<String, String> httpMapByString = getHttpMapByString(result);
+        //判断是否为空
+        if (httpMapByString == null || httpMapByString.size() == 0) {
+            return;
+        }
+
+        for (Property info : outProperty) {
+            info.setValue(httpMapByString.get(info.getProp()));
+            varPool.add(info);
+        }
+    }
+
+    protected String setBodyReturn(String updateResult, List<Property> properties) {
+        String result = null;
+        List<Map<String, String>> updateRL = new ArrayList<>();
+        Map<String, String> updateRM = new HashMap<>();
+        for (Property info : properties) {
+            if (Direct.OUT == info.getDirect()) {
+                updateRM.put(info.getProp(), updateResult);
+                updateRL.add(updateRM);
+                result = JSONUtils.toJsonString(updateRL);
+                // break;","[{'comment': 'We should remove this.', 'commenter': 'SbloodyS'}, {'comment': 'This part of code cannot be deleted because updateResult gets the body value, info.getProp() gets the output key from localParm, {""body"":{""userName"":""testName""}}', 'commenter': 'ITBOX-ITBOY'}, {'comment': 'What i mean is remove ```// break;```', 'commenter': 'SbloodyS'}, {'comment': 'Break has been removed and the code has been committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parameters/AbstractParameters.java,"@@ -201,4 +202,27 @@ private void addPropertyToValPool(Property property) {
         varPool.removeIf(p -> p.getProp().equals(property.getProp()));
         varPool.add(property);
     }
+    /**
+     * Convert the body result returned from HTTP to a map
+     * @param result
+     * @return
+     */
+    public static Map<String, String> getHttpMapByString(String result) {","[{'comment': 'I think this method ```getHttpMapByString``` should be included in ```HttpTask``` instead of Abstract class.', 'commenter': 'SbloodyS'}, {'comment': ""GetHttpMapByString is moved to HttpParameters because it's used in this"", 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parameters/AbstractParameters.java,"@@ -17,6 +17,7 @@
 
 package org.apache.dolphinscheduler.plugin.task.api.parameters;
 
+import com.fasterxml.jackson.core.type.TypeReference;","[{'comment': 'Please remove unnessnary change.', 'commenter': 'SbloodyS'}, {'comment': 'Already processed, code already committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parameters/AbstractParameters.java,"@@ -201,4 +202,5 @@ private void addPropertyToValPool(Property property) {
         varPool.removeIf(p -> p.getProp().equals(property.getProp()));
         varPool.add(property);
     }
+","[{'comment': 'same here.', 'commenter': 'SbloodyS'}, {'comment': 'Already processed, code already committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parameters/AbstractParameters.java,"@@ -17,23 +17,17 @@
 
 package org.apache.dolphinscheduler.plugin.task.api.parameters;
 
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.node.ArrayNode;
+import org.apache.commons.collections4.CollectionUtils;
 import org.apache.dolphinscheduler.plugin.task.api.enums.Direct;
 import org.apache.dolphinscheduler.plugin.task.api.model.Property;
 import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
 import org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper;
 import org.apache.dolphinscheduler.spi.utils.JSONUtils;
 import org.apache.dolphinscheduler.spi.utils.StringUtils;
 
-import org.apache.commons.collections4.CollectionUtils;
-
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.LinkedHashMap;
-import java.util.List;
-import java.util.Map;
-
-import com.fasterxml.jackson.databind.JsonNode;
-import com.fasterxml.jackson.databind.node.ArrayNode;
+import java.util.*;","[{'comment': 'Please avoid import ```*```', 'commenter': 'SbloodyS'}, {'comment': 'Already processed, code already committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parameters/AbstractParameters.java,"@@ -17,23 +17,22 @@
 
 package org.apache.dolphinscheduler.plugin.task.api.parameters;
 
+import com.fasterxml.jackson.databind.JsonNode;","[{'comment': 'Please remove unnessnary change in this file.', 'commenter': 'SbloodyS'}, {'comment': 'Already processed, code already committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,docs/docs/en/guide/parameter/context.md,"@@ -64,3 +64,25 @@ For example, in the figure below:
 When the log detects the `${setValue(key=value1)}` format in the shell node definition, it will assign value1 to the key, and downstream nodes can use the variable key directly. Similarly, you can find the corresponding node instance on the [Workflow Instance] page to see the value of the variable.
 
 ![png10](/img/globalParam/image-20210723102522383.png)
+
+### HTTP
+
+Step 1: Drag an HTTP task, fill IN body for KEY, select OUT for IN/OUT, select VARCHAR for output data type, always select VARCHAR, nothing else.
+
+<img src=""/img/httpParam/1-1.png"" alt=""1-1"" style=""zoom:50%;"" />","[{'comment': '* use markdown syntax when img using, ex `[httpParam1](/img/httpParam1-1.png)`. same as other imgs\r\n* please use the English version of screenshot\r\n* change the img file to more meaningful name instead of `1-1.png` and `1-2.png`, maybe you could directly using `/img/httpparam-1.png` and so on', 'commenter': 'zhongjiajie'}, {'comment': 'It has been resolved and the code has been committed', 'commenter': 'ITBOX-ITBOY'}]"
10184,docs/docs/en/guide/parameter/context.md,"@@ -76,3 +76,21 @@ The result of Node_mysql is as follows:
 Even though output is assigned a value of 1 in Node_A's script, the log still shows a value of 100. But according to the principle from [parameter priority](priority.md): `Local Parameter > Parameter Context > Global Parameter`, the output value in Node_B is 1. It proves that the output parameter is passed in the workflow with reference to the expected value, and the query operation is completed using this value in Node_mysql.
 
 But the output value 66 only shows in the Node_A, the reason is that the direction of value is selected as IN, and only when the direction is OUT will it be defined as a variable output.
+
+### HTTP
+
+Step 1: Drag an HTTP task, fill IN body for KEY, select OUT for IN/OUT, select VARCHAR for output data type, always select VARCHAR, nothing else.
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-1](../../../../img/httpParam/httpParam-1.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/en/guide/parameter/context.md,"@@ -76,3 +76,21 @@ The result of Node_mysql is as follows:
 Even though output is assigned a value of 1 in Node_A's script, the log still shows a value of 100. But according to the principle from [parameter priority](priority.md): `Local Parameter > Parameter Context > Global Parameter`, the output value in Node_B is 1. It proves that the output parameter is passed in the workflow with reference to the expected value, and the query operation is completed using this value in Node_mysql.
 
 But the output value 66 only shows in the Node_A, the reason is that the direction of value is selected as IN, and only when the direction is OUT will it be defined as a variable output.
+
+### HTTP
+
+Step 1: Drag an HTTP task, fill IN body for KEY, select OUT for IN/OUT, select VARCHAR for output data type, always select VARCHAR, nothing else.
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />
+
+Step 2: After adding an HTTP task type node, accept the parameters passed upstream. This time just add it in the Request Parameters section,
+
+<img src=""../../../../img/httpParam/httpParam-2.png"" alt=""httpParam-2.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-2](../../../../img/httpParam/httpParam-2.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/en/guide/parameter/context.md,"@@ -76,3 +76,21 @@ The result of Node_mysql is as follows:
 Even though output is assigned a value of 1 in Node_A's script, the log still shows a value of 100. But according to the principle from [parameter priority](priority.md): `Local Parameter > Parameter Context > Global Parameter`, the output value in Node_B is 1. It proves that the output parameter is passed in the workflow with reference to the expected value, and the query operation is completed using this value in Node_mysql.
 
 But the output value 66 only shows in the Node_A, the reason is that the direction of value is selected as IN, and only when the direction is OUT will it be defined as a variable output.
+
+### HTTP
+
+Step 1: Drag an HTTP task, fill IN body for KEY, select OUT for IN/OUT, select VARCHAR for output data type, always select VARCHAR, nothing else.
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />
+
+Step 2: After adding an HTTP task type node, accept the parameters passed upstream. This time just add it in the Request Parameters section,
+
+<img src=""../../../../img/httpParam/httpParam-2.png"" alt=""httpParam-2.png"" style=""zoom:50%;"" />
+
+It can be anything, it can be body, it can be anything, parameter,value, it must be the key that you pass upstream. In this case, the key that you pass upstream is body, so we use ${body}
+
+The configuration is complete
+<img src=""../../../../img/httpParam/httpParam-3.png"" alt=""httpParam-3.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-3](../../../../img/httpParam/httpParam-3.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/en/guide/parameter/context.md,"@@ -76,3 +76,21 @@ The result of Node_mysql is as follows:
 Even though output is assigned a value of 1 in Node_A's script, the log still shows a value of 100. But according to the principle from [parameter priority](priority.md): `Local Parameter > Parameter Context > Global Parameter`, the output value in Node_B is 1. It proves that the output parameter is passed in the workflow with reference to the expected value, and the query operation is completed using this value in Node_mysql.
 
 But the output value 66 only shows in the Node_A, the reason is that the direction of value is selected as IN, and only when the direction is OUT will it be defined as a variable output.
+
+### HTTP
+
+Step 1: Drag an HTTP task, fill IN body for KEY, select OUT for IN/OUT, select VARCHAR for output data type, always select VARCHAR, nothing else.
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />
+
+Step 2: After adding an HTTP task type node, accept the parameters passed upstream. This time just add it in the Request Parameters section,
+
+<img src=""../../../../img/httpParam/httpParam-2.png"" alt=""httpParam-2.png"" style=""zoom:50%;"" />
+
+It can be anything, it can be body, it can be anything, parameter,value, it must be the key that you pass upstream. In this case, the key that you pass upstream is body, so we use ${body}
+
+The configuration is complete
+<img src=""../../../../img/httpParam/httpParam-3.png"" alt=""httpParam-3.png"" style=""zoom:50%;"" />
+
+Step 3: You can write a test interface to test whether our parameters are passed successfully.
+<img src=""../../../../img/httpParam/httpParam-4.png"" alt=""httpParam-4.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-4](../../../../img/httpParam/httpParam-4.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/zh/guide/parameter/context.md,"@@ -76,3 +77,22 @@ Node_mysql 运行结果如下：
 虽然在 Node_A 的脚本中为 output 赋值为 1，但日志中显示的值仍然为 100。但根据[参数优先级](priority.md)的原则：`本地参数 > 上游任务传递的参数 > 全局参数`，在 Node_B 中输出的值为 1。则证明 output 参数参照预期的值在该工作流中传递，并在 Node_mysql 中使用该值完成查询操作。
 
 但是 value 的值却只有在 Node_A 中输出为 66，其原因为 value 的方向选择为 IN，只有当方向为 OUT 时才会被定义为变量输出。
+
+
+### HTTP
+
+第一步:拖一个http类型的任务，在自定义参数中KEY的位置填写body ,在IN/OUT的部分选择OUT,在输出数据类型部分选择VARCHAR，一定要选择VARCHAR，不要选择别的哈。
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-1](../../../../img/httpParam/httpParam-1.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/zh/guide/parameter/context.md,"@@ -76,3 +77,22 @@ Node_mysql 运行结果如下：
 虽然在 Node_A 的脚本中为 output 赋值为 1，但日志中显示的值仍然为 100。但根据[参数优先级](priority.md)的原则：`本地参数 > 上游任务传递的参数 > 全局参数`，在 Node_B 中输出的值为 1。则证明 output 参数参照预期的值在该工作流中传递，并在 Node_mysql 中使用该值完成查询操作。
 
 但是 value 的值却只有在 Node_A 中输出为 66，其原因为 value 的方向选择为 IN，只有当方向为 OUT 时才会被定义为变量输出。
+
+
+### HTTP
+
+第一步:拖一个http类型的任务，在自定义参数中KEY的位置填写body ,在IN/OUT的部分选择OUT,在输出数据类型部分选择VARCHAR，一定要选择VARCHAR，不要选择别的哈。
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />
+
+第二步:在添加一个http任务类型的节点，接收上游传递来的参数。这一次只需要在【请求参数】部分进行添加就可以了，
+
+<img src=""../../../../img/httpParam/httpParam-2.png"" alt=""httpParam-2.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-2](../../../../img/httpParam/httpParam-2.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/zh/guide/parameter/context.md,"@@ -76,3 +77,22 @@ Node_mysql 运行结果如下：
 虽然在 Node_A 的脚本中为 output 赋值为 1，但日志中显示的值仍然为 100。但根据[参数优先级](priority.md)的原则：`本地参数 > 上游任务传递的参数 > 全局参数`，在 Node_B 中输出的值为 1。则证明 output 参数参照预期的值在该工作流中传递，并在 Node_mysql 中使用该值完成查询操作。
 
 但是 value 的值却只有在 Node_A 中输出为 66，其原因为 value 的方向选择为 IN，只有当方向为 OUT 时才会被定义为变量输出。
+
+
+### HTTP
+
+第一步:拖一个http类型的任务，在自定义参数中KEY的位置填写body ,在IN/OUT的部分选择OUT,在输出数据类型部分选择VARCHAR，一定要选择VARCHAR，不要选择别的哈。
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />
+
+第二步:在添加一个http任务类型的节点，接收上游传递来的参数。这一次只需要在【请求参数】部分进行添加就可以了，
+
+<img src=""../../../../img/httpParam/httpParam-2.png"" alt=""httpParam-2.png"" style=""zoom:50%;"" />
+
+参数名可以写任意，可以body也可以是别的，类型选择parameter,value的取值一定是你上一个节点设置输出的key,如:我上一个节点设置的输出key是body，那我下一个节点就要这样取值${body}
+
+配置好后的效果
+<img src=""../../../../img/httpParam/httpParam-3.png"" alt=""httpParam-3.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-3](../../../../img/httpParam/httpParam-3.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,docs/docs/zh/guide/parameter/context.md,"@@ -76,3 +77,22 @@ Node_mysql 运行结果如下：
 虽然在 Node_A 的脚本中为 output 赋值为 1，但日志中显示的值仍然为 100。但根据[参数优先级](priority.md)的原则：`本地参数 > 上游任务传递的参数 > 全局参数`，在 Node_B 中输出的值为 1。则证明 output 参数参照预期的值在该工作流中传递，并在 Node_mysql 中使用该值完成查询操作。
 
 但是 value 的值却只有在 Node_A 中输出为 66，其原因为 value 的方向选择为 IN，只有当方向为 OUT 时才会被定义为变量输出。
+
+
+### HTTP
+
+第一步:拖一个http类型的任务，在自定义参数中KEY的位置填写body ,在IN/OUT的部分选择OUT,在输出数据类型部分选择VARCHAR，一定要选择VARCHAR，不要选择别的哈。
+
+<img src=""../../../../img/httpParam/httpParam-1.png"" alt=""httpParam-1.png"" style=""zoom:50%;"" />
+
+第二步:在添加一个http任务类型的节点，接收上游传递来的参数。这一次只需要在【请求参数】部分进行添加就可以了，
+
+<img src=""../../../../img/httpParam/httpParam-2.png"" alt=""httpParam-2.png"" style=""zoom:50%;"" />
+
+参数名可以写任意，可以body也可以是别的，类型选择parameter,value的取值一定是你上一个节点设置输出的key,如:我上一个节点设置的输出key是body，那我下一个节点就要这样取值${body}
+
+配置好后的效果
+<img src=""../../../../img/httpParam/httpParam-3.png"" alt=""httpParam-3.png"" style=""zoom:50%;"" />
+
+第三步:你可以写一个测试接口,来测试咱们的参数是否传递成功。
+<img src=""../../../../img/httpParam/httpParam-4.png"" alt=""httpParam-4.png"" style=""zoom:50%;"" />","[{'comment': '```suggestion\r\n![httpParam-4](../../../../img/httpParam/httpParam-4.png)\r\n```', 'commenter': 'zhongjiajie'}]"
10184,dolphinscheduler-task-plugin/dolphinscheduler-task-http/src/main/java/org/apache/dolphinscheduler/plugin/task/http/HttpParameters.java,"@@ -130,4 +138,69 @@ public int getSocketTimeout() {
     public void setSocketTimeout(int socketTimeout) {
         this.socketTimeout = socketTimeout;
     }
+
+    @Override
+    public void dealOutParam(String result) {
+        if (CollectionUtils.isEmpty(localParams)) {
+            return;
+        }
+        List<Property> outProperty = getOutProperty(localParams);
+        if (CollectionUtils.isEmpty(outProperty)) {
+            return;
+        }
+        if (StringUtils.isEmpty(result)) {
+            varPool.addAll(outProperty);
+            return;
+        }
+        List<Map<String, String>> httpMapByString = getHttpMapByString(result);
+        if (httpMapByString == null || httpMapByString.size() == 0) {
+            return;
+        }
+
+        for (Property info : outProperty) {
+            for (int i = 0; i < httpMapByString.size() ; i++) {
+                Map<String, String> stringStringMap=httpMapByString.get(i);","[{'comment': '```suggestion\r\n                Map<String, String> stringStringMap = httpMapByString.get(i);\r\n```', 'commenter': 'SbloodyS'}]"
10247,docs/docs/zh/guide/task/switch.md,"@@ -13,25 +15,34 @@ Switch是一个条件判断节点，依据[全局变量](../parameter/global.md)
 - 描述信息：描述该节点的功能。
 - 任务优先级：worker线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。","[{'comment': '```suggestion\r\n- 任务优先级：worker 线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。\r\n```\r\nIt is recommended to add spaces between Chinese characters, numbers, and English. The same goes for the content behind it.', 'commenter': 'QuakeWang'}]"
10247,docs/docs/zh/guide/task/switch.md,"@@ -1,10 +1,12 @@
 # Switch
 
-Switch是一个条件判断节点，依据[全局变量](../parameter/global.md)的值和用户所编写的表达式判断结果执行对应分支。","[{'comment': 'It is recommended to use the original expression, which is more complete.', 'commenter': 'QuakeWang'}]"
10247,docs/docs/zh/guide/task/switch.md,"@@ -13,25 +15,34 @@ Switch是一个条件判断节点，依据[全局变量](../parameter/global.md)
 - 描述信息：描述该节点的功能。
 - 任务优先级：worker线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
 - Worker分组：任务分配给worker组的机器机执行，选择Default，会随机选择一台worker机执行。
+- 环境名称：安全中心中配置的环境，不配置则不使用。
+- 任务组名称：资源中心中配置的任务组，不配置则不使用。
 - 失败重试次数：任务失败重新提交的次数，支持下拉和手填。
 - 失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填。
-- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败.
-- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务
-- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支
+- 延时执行时间：任务延迟执行的时间。
+- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败。
+- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务，使用字符串判断时需要使用""""。
+- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支。
 
 ## 详细流程
+这里使用1个 switch 任务以及3个 shell 任务来演示。
 
-假设我们三个任务，其依赖关系是 `A -> B -> [C, D]` 其中task_a是shell任务，task_b是switch任务
+### 1、创建工作流
+新建 switch 任务，以及下游的3个 shell 任务。shell 任务没有要求。
+switch 任务需要和下游任务连线配置关系后，才可以进行下游任务的选择。
 
-- 任务A中通过[全局变量](../parameter/global.md)定义了名为`id`的全局变量，声明方式为`${setValue(id=1)}`
-- 任务B增加条件，使用上游声明的全局变量实现条件判断（注意：只要直接、非直接上游在switch运行前对全局变量赋值，switch运行时就可以获取该全局变量）。下面我们想要实现当id为1时，运行任务C，其他运行任务D
-  - 配置当全局变量`id=1`时，运行任务C。则在任务B的条件中编辑`${id} == 1`，分支流转选择`C`
-  - 对于其他任务，在分支流转中选择`D`
+![switch_01](/img/tasks/demo/switch_01.png)
 
-最终switch任务的配置如下
+### 2、设置条件
+配置条件和默认分支，满足条件会走指定分支，都不满足则走默认分支。
+条件使用了全局变量，请参考[全局变量](../parameter/global.md)。","[{'comment': 'Some details can be added here. For example, explain the value of the global variable set in this example, and the branch corresponding to the execution task.', 'commenter': 'QuakeWang'}]"
10247,docs/docs/zh/guide/task/switch.md,"@@ -13,25 +15,34 @@ Switch是一个条件判断节点，依据[全局变量](../parameter/global.md)
 - 描述信息：描述该节点的功能。
 - 任务优先级：worker线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
 - Worker分组：任务分配给worker组的机器机执行，选择Default，会随机选择一台worker机执行。
+- 环境名称：安全中心中配置的环境，不配置则不使用。
+- 任务组名称：资源中心中配置的任务组，不配置则不使用。
 - 失败重试次数：任务失败重新提交的次数，支持下拉和手填。
 - 失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填。
-- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败.
-- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务
-- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支
+- 延时执行时间：任务延迟执行的时间。
+- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败。
+- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务，使用字符串判断时需要使用""""。
+- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支。
 
 ## 详细流程
+这里使用1个 switch 任务以及3个 shell 任务来演示。
 
-假设我们三个任务，其依赖关系是 `A -> B -> [C, D]` 其中task_a是shell任务，task_b是switch任务
+### 1、创建工作流","[{'comment': '```suggestion\r\n### 1、创建工作流\r\n\r\n```\r\nIt is recommended to add a line break between the title and body statement. The format will be more standardized. The same as following.', 'commenter': 'QuakeWang'}]"
10247,docs/docs/en/guide/task/switch.md,"@@ -1,6 +1,7 @@
 # Switch
 
 The switch is a conditional judgment node, decide the branch executes according to the value of [global variable](../parameter/global.md) and the expression result written by the user.
+**Note** Execute expressions using javax.script.ScriptEngine.eval.
 
 ## Create","[{'comment': '```suggestion\r\n## Create Task\r\n```', 'commenter': 'QuakeWang'}, {'comment': '- Click `Project -> Management-Project -> Name-Workflow Definition`, and click the Create Workflow button to enter the DAG editing page.\r\n- Drag from the toolbar <img src=""/img/switch.png"" width=""20""/> to the canvas.', 'commenter': 'QuakeWang'}]"
10247,docs/docs/en/guide/task/switch.md,"@@ -14,26 +15,33 @@ Drag from the toolbar <img src=""/img/switch.png"" width=""20""/>  task node to canv
 - Descriptive information: Describe the function of the node.
 - Task priority: When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order.
 - Worker grouping: Assign tasks to the machines of the worker group to execute. If `Default` is selected, randomly select a worker machine for execution.
+- Environment name: The environment in Security, if not configured, it will not be used.
+- Task group name: The group in Resources, if not configured, it will not be used.
 - Times of failed retry attempts: The number of times the task failed to resubmit. You can select from drop-down or fill-in a number.
 - Failed retry interval: The time interval for resubmitting the task after a failed task. You can select from drop-down or fill-in a number.
+- Delay execution time: Task delay execution time.
 - Timeout alarm: Check the timeout alarm and timeout failure. When the task runs exceed the ""timeout"", an alarm email will send and the task execution will fail.
 - Condition: You can configure multiple conditions for the switch task. When the conditions are satisfied, execute the configured branch. You can configure multiple different conditions to satisfy different businesses.
 - Branch flow: The default branch flow, when all the conditions are not satisfied, execute this branch flow.
 
 ## Detail","[{'comment': '```suggestion\r\n## Task Example\r\n```', 'commenter': 'QuakeWang'}]"
10247,docs/docs/en/guide/task/switch.md,"@@ -14,26 +15,33 @@ Drag from the toolbar <img src=""/img/switch.png"" width=""20""/>  task node to canv
 - Descriptive information: Describe the function of the node.","[{'comment': 'Remove extra indent spaces', 'commenter': 'QuakeWang'}]"
10247,docs/docs/en/guide/task/switch.md,"@@ -14,26 +15,42 @@ Drag from the toolbar <img src=""/img/switch.png"" width=""20""/>  task node to canv
 - Descriptive information: Describe the function of the node.
 - Task priority: When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order.
 - Worker grouping: Assign tasks to the machines of the worker group to execute. If `Default` is selected, randomly select a worker machine for execution.
+- Environment name: The environment in Security, if not configured, it will not be used.
+- Task group name: The group in Resources, if not configured, it will not be used.
 - Times of failed retry attempts: The number of times the task failed to resubmit. You can select from drop-down or fill-in a number.
 - Failed retry interval: The time interval for resubmitting the task after a failed task. You can select from drop-down or fill-in a number.
+- Delay execution time: Task delay execution time.
 - Timeout alarm: Check the timeout alarm and timeout failure. When the task runs exceed the ""timeout"", an alarm email will send and the task execution will fail.
 - Condition: You can configure multiple conditions for the switch task. When the conditions are satisfied, execute the configured branch. You can configure multiple different conditions to satisfy different businesses.
 - Branch flow: The default branch flow, when all the conditions are not satisfied, execute this branch flow.
 
-## Detail
+## Task Example
+
+This is demonstrated using one switch task and three shell tasks.
+
+![switch_01](/img/tasks/demo/switch_01.png)
+
+### 1. Create a workflow","[{'comment': 'We should avoid using number in markdown title, the prefix `###` is for the same function @huangchenguang123  and cc @QuakeWang \r\n```suggestion\r\n### Create a workflow\r\n```', 'commenter': 'zhongjiajie'}, {'comment': 'same as others places', 'commenter': 'zhongjiajie'}]"
10247,docs/docs/zh/guide/task/switch.md,"@@ -1,37 +1,57 @@
 # Switch
 
-Switch是一个条件判断节点，依据[全局变量](../parameter/global.md)的值和用户所编写的表达式判断结果执行对应分支。
+Switch 是一个条件判断节点，依据[全局变量](../parameter/global.md)的值和用户所编写的表达式判断结果执行对应分支。
+**注意**使用 javax.script.ScriptEngine.eval 执行表达式。
 
 ## 创建任务
-
-拖动工具栏中的<img src=""/img/switch.png"" width=""20""/>任务节点到画板中即能完成任务创建，**注意**switch任务创建后，要先配置上下游，才能配置任务分支的参数
+点击项目管理 -> 项目名称 -> 工作流定义，点击""创建工作流""按钮，进入 DAG 编辑页面。
+拖动工具栏中的<img src=""/img/switch.png"" width=""20""/>任务节点到画板中即能完成任务创建。
+**注意** switch 任务创建后，要先配置上下游，才能配置任务分支的参数。
 
 ## 任务参数
 
 - 节点名称：一个工作流定义中的节点名称是唯一的。
 - 运行标志：标识这个节点是否能正常调度,如果不需要执行，可以打开禁止执行开关。
 - 描述信息：描述该节点的功能。
-- 任务优先级：worker线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
-- Worker分组：任务分配给worker组的机器机执行，选择Default，会随机选择一台worker机执行。
+- 任务优先级：worker 线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
+- Worker 分组：任务分配给 worker 组的机器机执行，选择 Default，会随机选择一台 worker 机执行。
+- 环境名称：安全中心中配置的环境，不配置则不使用。
+- 任务组名称：资源中心中配置的任务组，不配置则不使用。
 - 失败重试次数：任务失败重新提交的次数，支持下拉和手填。
 - 失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填。
-- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败.
-- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务
-- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支
+- 延时执行时间：任务延迟执行的时间。
+- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败。
+- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务，使用字符串判断时需要使用""""。
+- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支。
+
+## 任务样例
+
+这里使用一个 switch 任务以及三个 shell 任务来演示。
+
+### 1、创建工作流
+
+新建 switch 任务，以及下游的三个 shell 任务。shell 任务没有要求。
+switch 任务需要和下游任务连线配置关系后，才可以进行下游任务的选择。
+
+![switch_01](/img/tasks/demo/switch_01.png)
+
+### 2、设置条件
+
+配置条件和默认分支，满足条件会走指定分支，都不满足则走默认分支。
+图中如果变量的值为 ""A"" 则执行分支 taskA，如果变量的值为 ""B"" 则执行分支 taskB ，都不满足则执行 default。
+
+![switch_02](/img/tasks/demo/switch_02.png)
 
-## 详细流程
+条件使用了全局变量，请参考[全局变量](../parameter/global.md)。
+这里配置全局变量的值为 A。
 
-假设我们三个任务，其依赖关系是 `A -> B -> [C, D]` 其中task_a是shell任务，task_b是switch任务
+![switch_03](/img/tasks/demo/switch_03.png)
 
-- 任务A中通过[全局变量](../parameter/global.md)定义了名为`id`的全局变量，声明方式为`${setValue(id=1)}`
-- 任务B增加条件，使用上游声明的全局变量实现条件判断（注意：只要直接、非直接上游在switch运行前对全局变量赋值，switch运行时就可以获取该全局变量）。下面我们想要实现当id为1时，运行任务C，其他运行任务D
-  - 配置当全局变量`id=1`时，运行任务C。则在任务B的条件中编辑`${id} == 1`，分支流转选择`C`
-  - 对于其他任务，在分支流转中选择`D`
+如果执行正确，那么 taskA 会被正确执行。
 
-最终switch任务的配置如下
+### 3、执行
 
-![task-switch-configure](/img/switch_configure.jpg)
+执行，并且查看是否符合预期。可以看到符合预期，执行了指定的下游任务 taskA。
 
-## 相关任务
+![switch_04](../../../../img/tasks/demo/switch_04.png)","[{'comment': 'Maybe we should still using the old style start with `/img` until we merge https://github.com/apache/dolphinscheduler-website/pull/789 WDYT @huangchenguang123 \r\n```suggestion\r\n![switch_04](/img/tasks/demo/switch_04.png)\r\n```', 'commenter': 'zhongjiajie'}, {'comment': 'This is my problem.I forgot to delete it after testing.', 'commenter': 'huangchenguang123'}]"
10247,docs/docs/zh/guide/task/switch.md,"@@ -1,37 +1,57 @@
 # Switch
 
-Switch是一个条件判断节点，依据[全局变量](../parameter/global.md)的值和用户所编写的表达式判断结果执行对应分支。
+Switch 是一个条件判断节点，依据[全局变量](../parameter/global.md)的值和用户所编写的表达式判断结果执行对应分支。
+**注意**使用 javax.script.ScriptEngine.eval 执行表达式。
 
 ## 创建任务
-
-拖动工具栏中的<img src=""/img/switch.png"" width=""20""/>任务节点到画板中即能完成任务创建，**注意**switch任务创建后，要先配置上下游，才能配置任务分支的参数
+点击项目管理 -> 项目名称 -> 工作流定义，点击""创建工作流""按钮，进入 DAG 编辑页面。
+拖动工具栏中的<img src=""/img/switch.png"" width=""20""/>任务节点到画板中即能完成任务创建。
+**注意** switch 任务创建后，要先配置上下游，才能配置任务分支的参数。
 
 ## 任务参数
 
 - 节点名称：一个工作流定义中的节点名称是唯一的。
 - 运行标志：标识这个节点是否能正常调度,如果不需要执行，可以打开禁止执行开关。
 - 描述信息：描述该节点的功能。
-- 任务优先级：worker线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
-- Worker分组：任务分配给worker组的机器机执行，选择Default，会随机选择一台worker机执行。
+- 任务优先级：worker 线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
+- Worker 分组：任务分配给 worker 组的机器机执行，选择 Default，会随机选择一台 worker 机执行。
+- 环境名称：安全中心中配置的环境，不配置则不使用。
+- 任务组名称：资源中心中配置的任务组，不配置则不使用。
 - 失败重试次数：任务失败重新提交的次数，支持下拉和手填。
 - 失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填。
-- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败.
-- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务
-- 分支流转：默认的流转内容，当**条件**中的内容为全部不符合要求时，则运行**分支流转**中指定的分支
+- 延时执行时间：任务延迟执行的时间。
+- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败。
+- 条件：可以为switch任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务，使用字符串判断时需要使用""""。","[{'comment': '```suggestion\r\n- 条件：可以为 switch 任务配置多个条件，当条件满足时，就会执行指定的分支，可以配置多个不同的条件来满足不同的业务，使用字符串判断时需要使用""""。\r\n```\r\nAdd a space between Chinese and English.\r\n\r\n', 'commenter': 'QuakeWang'}]"
10247,docs/docs/en/guide/task/switch.md,"@@ -14,26 +16,42 @@ Drag from the toolbar <img src=""../../../../img/switch.png"" width=""20""/>  task n
 - Descriptive information: Describe the function of the node.
 - Task priority: When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order.
 - Worker grouping: Assign tasks to the machines of the worker group to execute. If `Default` is selected, randomly select a worker machine for execution.
+- Environment name: The environment in Security, if not configured, it will not be used.
+- Task group name: The group in Resources, if not configured, it will not be used.
 - Times of failed retry attempts: The number of times the task failed to resubmit. You can select from drop-down or fill-in a number.
 - Failed retry interval: The time interval for resubmitting the task after a failed task. You can select from drop-down or fill-in a number.
+- Delay execution time: Task delay execution time.
 - Timeout alarm: Check the timeout alarm and timeout failure. When the task runs exceed the ""timeout"", an alarm email will send and the task execution will fail.
 - Condition: You can configure multiple conditions for the switch task. When the conditions are satisfied, execute the configured branch. You can configure multiple different conditions to satisfy different businesses.
 - Branch flow: The default branch flow, when all the conditions are not satisfied, execute this branch flow.
 
-## Detail
+## Task Example
 
-Here we have three tasks, the dependencies are `A -> B -> [C, D]`, and `task_a` is a shell task and `task_b` is a switch task
+This is demonstrated using one switch task and three shell tasks.
 
-- In task A, a global variable named `id` is defined through [global variable](../parameter/global.md), and the declaration method is `${setValue(id=1)}`
-- Task B adds conditions and uses global variables declared upstream to achieve conditional judgment (Note: switch can get the global variables value, as long as its direct or indirect upstream have already assigned the global variables before switch acquires). We want to execute task C when `id = 1`, otherwise run task D
-  - Configure task C to run when the global variable `id=1`. Then edit `${id} == 1` in the condition of task B, and select `C` as branch flow
-  - For other tasks, select `D` as branch flow
+![switch_01](/img/tasks/demo/switch_01.png)
 
-The following shows the switch task configuration:
+### Create a workflow
 
-![task-switch-configure](../../../../img/switch_configure.jpg)
+Create a new switch task, and three shell tasks downstream. The shell task is not required.
+The switch task needs to be connected with the downstream task to configure the relationship before the downstream task can be selected.
 
-## Related Task
+![switch_01](/img/tasks/demo/switch_01.png)","[{'comment': 'You should use related path instead of absolute path after #10325 merged', 'commenter': 'zhongjiajie'}, {'comment': 'I had change the img path.', 'commenter': 'huangchenguang123'}]"
10269,dolphinscheduler-ui/src/views/projects/task/components/node/format-data.ts,"@@ -315,6 +315,7 @@ export function formatParams(data: INodeData): {
   if (data.taskType === 'ZEPPELIN') {
     taskParams.noteId = data.zeppelinNoteId
     taskParams.paragraphId = data.zeppelinParagraphId
+    taskParams.parameters = data.parameters","[{'comment': 'Have you checked the tsc locally？', 'commenter': 'Amy0104'}, {'comment': ""@Amy0104 I've tested locally and it looks fine. Not sure what `tsc` mean?"", 'commenter': 'EricGao888'}, {'comment': 'I have checked the code, and this is ok for the tsc. Sorry, I have confused you.\r\n<img width=""649"" alt=""image"" src=""https://user-images.githubusercontent.com/97265214/171085817-6e1d3b6c-dc9b-421e-8f86-050326b675ff.png"">\r\n', 'commenter': 'Amy0104'}, {'comment': 'No worries, thx for help me with the review! : )', 'commenter': 'EricGao888'}]"
10294,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/HttpUtilsTest.java,"@@ -40,10 +40,10 @@ public class HttpUtilsTest {
     @Test
     public void testGetTest() {
 	// success
-	String result = HttpUtils.get(""https://github.com/manifest.json"");
+	String result = HttpUtils.get(""https://www.baidu.com/sugrec?prod=pc_his&from=pc_web&json=1&sid=36427_36454_31253_36422_36165_36487_36055_36376_36234_26350_36469_36316&hisdata=&_t=1653904731156&req=2&csor=0"");","[{'comment': ""I don't think this is a good idea. Due to the instability of Baidu. This url may cause unstable in unit test. \r\n\r\nAnd If GitHub cannot be accessed, the DS code can not be pulled."", 'commenter': 'SbloodyS'}, {'comment': 'Perhaps because of the github anti-ddos attack, different policies are used for different URLs, but multiple tries always work.', 'commenter': '106umao'}, {'comment': '> Perhaps because of the github anti-ddos attack, different policies are used for different URLs, but multiple tries always work.\r\n\r\nMaybe your network is in poor condition.', 'commenter': 'SbloodyS'}, {'comment': 'You can consider changing to some high-performance ```Airports```', 'commenter': 'SbloodyS'}, {'comment': ""Actually I'd just remove this test case or set up an http server before the tests. Unit tests should not rely on external third party services. No matter what links you use there must be someone with poor connections and will timeout. "", 'commenter': 'kezhenxu94'}, {'comment': ""> Actually I'd just remove this test case or set up an http server before the tests. Unit tests should not rely on external third party services. No matter what links you use there must be someone with poor connections and will timeout.\r\n\r\nSo do you need to merge this pr now, or do I hide these two test cases in this pr because they will cause the test to be unstable"", 'commenter': '106umao'}, {'comment': ""> > Actually I'd just remove this test case or set up an http server before the tests. Unit tests should not rely on external third party services. No matter what links you use there must be someone with poor connections and will timeout.\n> \n> \n> \n> So do you need to merge this pr now, or do I hide these two test cases in this pr because they will cause the test to be unstable\n\nCan you just modify the test to set up an http server with Jetty, and use localhost:port to test this http util? That would be stable and no timeout. "", 'commenter': 'kezhenxu94'}]"
10294,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/LocalJettyHttpServer.java,"@@ -0,0 +1,56 @@
+package org.apache.dolphinscheduler.common.utils;
+
+import java.io.IOException;
+import java.io.OutputStream;
+
+import junit.extensions.TestSetup;
+import junit.framework.Test;
+
+
+import org.mortbay.jetty.*;
+import org.mortbay.jetty.handler.AbstractHandler;
+import org.mortbay.jetty.handler.ContextHandler;
+import org.mortbay.util.ByteArrayISO8859Writer;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+public class LocalJettyHttpServer extends TestSetup {
+    protected static Server server;
+    private static Logger logger = LoggerFactory.getLogger(LocalJettyHttpServer.class);
+
+    public LocalJettyHttpServer(Test suite) {
+        super(suite);
+    }
+
+    protected void setUp() throws Exception {
+        logger.info(""server si starting..."");
+        server = new Server(8888);","[{'comment': ""Do not hardcode this port, it will also fail when users' machine has service running at port 8888,\r\n\r\n```java\r\n\r\n    Server server = new Server();\r\n    Connector connector = new SelectChannelConnector();\r\n\r\n    connector.setPort(0);\r\n    server.addConnector(connector);\r\n    server.start();\r\n\r\n//... and use this to get the dynamic port\r\n    connector.getLocalPort();\r\n```"", 'commenter': 'kezhenxu94'}]"
10294,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/LocalJettyHttpServer.java,"@@ -0,0 +1,88 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import java.io.IOException;
+import java.io.OutputStream;
+import java.net.BindException;
+
+import junit.extensions.TestSetup;
+import junit.framework.Test;
+
+
+import org.mortbay.jetty.*;
+import org.mortbay.jetty.handler.AbstractHandler;
+import org.mortbay.jetty.handler.ContextHandler;
+import org.mortbay.util.ByteArrayISO8859Writer;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+public class LocalJettyHttpServer extends TestSetup {
+    protected static Server server;
+    private static Logger logger = LoggerFactory.getLogger(LocalJettyHttpServer.class);
+    private Integer serverPort = 8888;
+
+    public Integer getServerPort() {
+        return serverPort;
+    }
+
+    public LocalJettyHttpServer(Test suite) {
+        super(suite);
+    }
+
+    protected void setUp() throws Exception {
+        while (true) {
+            try {
+                server = new Server(serverPort);
+                ContextHandler context = new ContextHandler(""/test.json"");
+                context.setHandler(new AbstractHandler() {
+                    @Override
+                    public void handle(String s, HttpServletRequest request, HttpServletResponse response, int i) throws IOException {
+                        ByteArrayISO8859Writer writer = new ByteArrayISO8859Writer();
+                        writer.write(""{\""name\"":\""Github\""}"");
+                        writer.flush();
+                        response.setContentLength(writer.size());
+                        OutputStream out = response.getOutputStream();
+                        writer.writeTo(out);
+                        out.flush();
+                        Request baseRequest = request instanceof Request ? (Request) request : HttpConnection.getCurrentConnection().getRequest();
+                        baseRequest.setHandled(true);
+                    }
+                });
+                server.setHandler(context);
+                logger.info(""server for "" + context.getBaseResource());
+                server.start();
+                logger.info(""server is starting in port: ""+serverPort);
+            } catch (BindException e) {
+                server.stop();
+                logger.info(""port: ""+serverPort + "" has been bind"");
+                serverPort++;
+                continue;
+            }
+            break;
+        }","[{'comment': ""Please don't do this kind of ugly workarounds, do things in a right way instead of using all kinds of workarounds. see https://stackoverflow.com/questions/8884865/how-to-discover-embedded-jetty-port-after-requesting-random-available-port"", 'commenter': 'kezhenxu94'}, {'comment': 'Thanks for the reminder, but I think this loop can not be saved, you think about it, before the server.start (), the randomly obtained port does not belong to this server, it is likely to be occupied, when occupied will lead to an exception exit.', 'commenter': '106umao'}, {'comment': '> Thanks for the reminder, but I think this loop can not be saved, you think about it, before the server.start (), the randomly obtained port does not belong to this server, it is likely to be occupied, when occupied will lead to an exception exit.\n\nWhy do you think so? When you set port to 0 jetty will find an available port and use it.The key point is ""available"" not ""random"".', 'commenter': 'kezhenxu94'}, {'comment': '@kezhenxu94 \r\nI should have misunderstood before, I thought he would assign the port when constructing the object, but in fact it is assigned in start.', 'commenter': '106umao'}]"
10294,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/LocalServerHttpUtilsTest.java,"@@ -0,0 +1,94 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import com.fasterxml.jackson.databind.node.ObjectNode;
+import junit.framework.Test;
+import junit.framework.TestCase;
+import junit.framework.TestSuite;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.http.client.config.RequestConfig;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.impl.client.CloseableHttpClient;
+import org.apache.http.impl.client.HttpClients;
+import org.junit.Assert;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class LocalServerHttpUtilsTest extends TestCase{
+
+    private HadoopUtils hadoopUtils = HadoopUtils.getInstance();","[{'comment': 'Can we remove Hadoop-related things in this pure http test?', 'commenter': 'kezhenxu94'}, {'comment': 'I think it should be removed, but I have asked questions about it in the WeChat group and no one has answered my questions', 'commenter': '106umao'}, {'comment': '> I think it should be removed, but I have asked questions about it in the WeChat group and no one has answered my questions\n\nOh sorry to hear no one answered but please ask in issues/PR next time so it should be addressed. ', 'commenter': 'kezhenxu94'}, {'comment': ""Can you remove that and I think it's ready to merge"", 'commenter': 'kezhenxu94'}]"
10364,.github/workflows/backend.yml,"@@ -103,7 +106,8 @@ jobs:
       - uses: actions/download-artifact@v2
         name: Download Binary Package
         with:
-          name: binary-package
+          # Only run cluster test on jdk8","[{'comment': 'Add an `if` condition to this step otherwise the job will be run twice on jdk 8', 'commenter': 'kezhenxu94'}, {'comment': 'I find this part is not under `build` so it will not run twice?', 'commenter': 'ruanwenjun'}, {'comment': '> I find this part is not under `build` so it will not run twice?\r\n\r\nOh right, my fault, the matrix part was collapsed in GitHub website', 'commenter': 'kezhenxu94'}]"
10364,.github/workflows/backend.yml,"@@ -56,6 +56,9 @@ jobs:
     needs: paths-filter
     if: ${{ (needs.paths-filter.outputs.not-ignore == 'true') || (github.event_name == 'push') }}
     runs-on: ubuntu-latest
+    strategy:
+      matrix:
+        java: [ '8', '11' ]","[{'comment': 'Add `setup-java` to this job otherwise this matrix does nothing but only build the package twice on default jdk ', 'commenter': 'kezhenxu94'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
10376,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -361,6 +361,11 @@ private Constants() {
      */
     public static final String CMDPARAM_COMPLEMENT_DATA_END_DATE = ""complementEndDate"";
 
+    /**
+     * complement data Schedule date
+     */
+    public static final String CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE = ""complementScheduleDate"";","[{'comment': 'It would be a list string.', 'commenter': 'lenboo'}, {'comment': 'Modified\r\n\r\n', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/corn/CronUtils.java,"@@ -35,13 +34,9 @@
 import org.apache.commons.collections.CollectionUtils;
 
 import java.text.ParseException;
-import java.util.ArrayList;
-import java.util.Calendar;
-import java.util.Collections;
-import java.util.Date;
-import java.util.GregorianCalendar;
-import java.util.List;
+import java.util.*;","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}, {'comment': 'Modified\r\n\r\n', 'commenter': 'hstdream'}, {'comment': 'This has not been addressed.', 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -18,13 +18,9 @@
 package org.apache.dolphinscheduler.api.service.impl;
 
 import static org.apache.dolphinscheduler.api.constants.ApiFuncIdentificationConstant.WORKFLOW_START;
-import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_END_DATE;
-import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_START_DATE;
-import static org.apache.dolphinscheduler.common.Constants.CMD_PARAM_RECOVER_PROCESS_ID_STRING;
-import static org.apache.dolphinscheduler.common.Constants.CMD_PARAM_START_NODES;
-import static org.apache.dolphinscheduler.common.Constants.CMD_PARAM_START_PARAMS;
-import static org.apache.dolphinscheduler.common.Constants.MAX_TASK_TIMEOUT;
+import static org.apache.dolphinscheduler.common.Constants.*;","[{'comment': 'Please avoid import *', 'commenter': 'SbloodyS'}, {'comment': 'OK，Modified', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -75,13 +71,7 @@
 import org.apache.commons.collections.MapUtils;
 import org.apache.commons.lang3.StringUtils;
 
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Map;
-import java.util.Set;
+import java.util.*;","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}, {'comment': 'This has not been addressed.', 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -17,12 +17,7 @@
 
 package org.apache.dolphinscheduler.server.master.runner;
 
-import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_END_DATE;
-import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_START_DATE;
-import static org.apache.dolphinscheduler.common.Constants.CMD_PARAM_RECOVERY_START_NODE_STRING;
-import static org.apache.dolphinscheduler.common.Constants.CMD_PARAM_RECOVER_PROCESS_ID_STRING;
-import static org.apache.dolphinscheduler.common.Constants.CMD_PARAM_START_NODES;
-import static org.apache.dolphinscheduler.common.Constants.DEFAULT_WORKER_GROUP;
+import static org.apache.dolphinscheduler.common.Constants.*;","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -740,45 +729,24 @@ protected int createComplementCommandList(Date start, Date end, RunMode runMode,
                         }
                     }
                     logger.info(""In parallel mode, current expectedParallelismNumber:{}"", createCount);
-
                     // Distribute the number of tasks equally to each command.
                     // The last command with insufficient quantity will be assigned to the remaining tasks.
-                    int itemsPerCommand = (listDateSize / createCount);
-                    int remainingItems = (listDateSize % createCount);
-                    int startDateIndex = 0;
-                    int endDateIndex = 0;
-
-                    for (int i = 1; i <= createCount; i++) {
-                        int extra = (i <= remainingItems) ? 1 : 0;
-                        int singleCommandItems = (itemsPerCommand + extra);
-
-                        if (i == 1) {
-                            endDateIndex += singleCommandItems - 1;
-                        } else {
-                            startDateIndex = endDateIndex + 1;
-                            endDateIndex += singleCommandItems;
+                    for(List<String> stringDate : Lists.partition(listDate,createCount)){
+                        String tempDate = """";
+                        for(String date : stringDate){
+                            tempDate  += date +"","";
                         }
-
-                        cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(listDate.get(startDateIndex)));
-                        cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(listDate.get(endDateIndex)));
+                        cmdParam.put(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE, tempDate.substring(0,tempDate.length() - 1));
                         command.setCommandParam(JSONUtils.toJsonString(cmdParam));
                         processService.createCommand(command);
-
-                        if (schedules.isEmpty() || complementDependentMode == ComplementDependentMode.OFF_MODE) {
-                            logger.info(""process code: {} complement dependent in off mode or schedule's size is 0, skip ""
-                                    + ""dependent complement data"", command.getProcessDefinitionCode());
-                        } else {
-                            dependentProcessDefinitionCreateCount += createComplementDependentCommand(schedules, command);
-                        }","[{'comment': 'Why did you remove this? It may cause complement dependent process error.', 'commenter': 'SbloodyS'}, {'comment': '+1, I had the same question here.', 'commenter': 'caishunfeng'}, {'comment': 'OK，Modified\r\n\r\n\r\n', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -740,45 +729,24 @@ protected int createComplementCommandList(Date start, Date end, RunMode runMode,
                         }
                     }
                     logger.info(""In parallel mode, current expectedParallelismNumber:{}"", createCount);
-
                     // Distribute the number of tasks equally to each command.
                     // The last command with insufficient quantity will be assigned to the remaining tasks.
-                    int itemsPerCommand = (listDateSize / createCount);
-                    int remainingItems = (listDateSize % createCount);
-                    int startDateIndex = 0;
-                    int endDateIndex = 0;
-
-                    for (int i = 1; i <= createCount; i++) {
-                        int extra = (i <= remainingItems) ? 1 : 0;
-                        int singleCommandItems = (itemsPerCommand + extra);
-
-                        if (i == 1) {
-                            endDateIndex += singleCommandItems - 1;
-                        } else {
-                            startDateIndex = endDateIndex + 1;
-                            endDateIndex += singleCommandItems;
+                    for(List<String> stringDate : Lists.partition(listDate,createCount)){
+                        String tempDate = """";
+                        for(String date : stringDate){
+                            tempDate  += date +"","";","[{'comment': ""It's recommanded to format this line."", 'commenter': 'SbloodyS'}, {'comment': '1', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -740,45 +729,24 @@ protected int createComplementCommandList(Date start, Date end, RunMode runMode,
                         }
                     }
                     logger.info(""In parallel mode, current expectedParallelismNumber:{}"", createCount);
-
                     // Distribute the number of tasks equally to each command.
                     // The last command with insufficient quantity will be assigned to the remaining tasks.
-                    int itemsPerCommand = (listDateSize / createCount);
-                    int remainingItems = (listDateSize % createCount);
-                    int startDateIndex = 0;
-                    int endDateIndex = 0;
-
-                    for (int i = 1; i <= createCount; i++) {
-                        int extra = (i <= remainingItems) ? 1 : 0;
-                        int singleCommandItems = (itemsPerCommand + extra);
-
-                        if (i == 1) {
-                            endDateIndex += singleCommandItems - 1;
-                        } else {
-                            startDateIndex = endDateIndex + 1;
-                            endDateIndex += singleCommandItems;
+                    for(List<String> stringDate : Lists.partition(listDate,createCount)){
+                        String tempDate = """";
+                        for(String date : stringDate){
+                            tempDate  += date +"","";
                         }
-
-                        cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(listDate.get(startDateIndex)));
-                        cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(listDate.get(endDateIndex)));
+                        cmdParam.put(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE, tempDate.substring(0,tempDate.length() - 1));","[{'comment': 'I think using it\'s a little confusing using ```substring``` to remove the last comma. Is it more elegant to use ```String.join("","", tmpDateList)``` ?', 'commenter': 'SbloodyS'}, {'comment': 'OK，Modified', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -943,15 +938,12 @@ private void initTaskQueue() {
 
         if (processInstance.isComplementData() && complementListDate.size() == 0) {
             Map<String, String> cmdParam = JSONUtils.toMap(processInstance.getCommandParam());
-            if (cmdParam != null && cmdParam.containsKey(CMDPARAM_COMPLEMENT_DATA_START_DATE)) {
+            if (cmdParam != null && cmdParam.containsKey(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE)) {
                 // reset global params while there are start parameters
                 setGlobalParamIfCommanded(processDefinition, cmdParam);
 
-                Date start = DateUtils.stringToDate(cmdParam.get(CMDPARAM_COMPLEMENT_DATA_START_DATE));
-                Date end = DateUtils.stringToDate(cmdParam.get(CMDPARAM_COMPLEMENT_DATA_END_DATE));
-                List<Schedule> schedules = processService.queryReleaseSchedulerListByProcessDefinitionCode(processInstance.getProcessDefinitionCode());
                 if (complementListDate.size() == 0 && needComplementProcess()) {
-                    complementListDate = CronUtils.getSelfFireDateList(start, end, schedules);","[{'comment': 'As we discuss in wechat. I do not think this is a good idea to remove such a big feature of complement data.', 'commenter': 'SbloodyS'}, {'comment': 'At present, it has been modified to manual input and automatic selection', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -407,6 +407,8 @@ public enum Status {
 
     NO_CURRENT_OPERATING_PERMISSION(1400001, ""The current user does not have this permission."", ""当前用户无此权限""),
     FUNCTION_DISABLED(1400002, ""The current feature is disabled."", ""当前功能已被禁用""),
+    SCHEDULE_TIME_NUMBER(1400003, ""The number of complement dates exceed 100."", ""补数日期个数超过100""),","[{'comment': 'I think we should not limit the date range of user complement. In the actual production environment, it is very common to supplement the time range within one or two years.', 'commenter': 'SbloodyS'}, {'comment': 'The current solution is to manually enter and use the selected date. Manual input requires limiting the number and length of the entire set', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-e2e/dolphinscheduler-e2e-case/src/test/java/org/apache/dolphinscheduler/e2e/cases/WorkflowE2ETest.java,"@@ -162,56 +162,56 @@ void testCreateSubWorkflow() {
         workflowDefinitionPage.publish(workflow);
     }
 
-    @Test
-    @Order(30)
-    void testRunWorkflow() {
-        final String workflow = ""test-workflow-1"";
-        final ProjectDetailPage projectPage =
-                new ProjectPage(browser)
-                        .goToNav(ProjectPage.class)
-                        .goTo(project);
-
-        projectPage
-                .goToTab(WorkflowInstanceTab.class)
-                .deleteAll();
-        projectPage
-                .goToTab(WorkflowDefinitionTab.class)
-                .run(workflow)
-                .submit();
-
-        await().untilAsserted(() -> {
-            browser.navigate().refresh();
-
-            final Row row = projectPage
-                    .goToTab(WorkflowInstanceTab.class)
-                    .instances()
-                    .iterator()
-                    .next();
-
-            assertThat(row.isSuccess()).isTrue();
-            assertThat(row.executionTime()).isEqualTo(1);
-        });
-        // Test rerun
-        projectPage
-                .goToTab(WorkflowInstanceTab.class)
-                .instances()
-                .stream()
-                .filter(it -> it.rerunButton().isDisplayed())
-                .iterator()
-                .next()
-                .rerun();
-
-        await().untilAsserted(() -> {
-            browser.navigate().refresh();
-
-            final Row row = projectPage
-                    .goToTab(WorkflowInstanceTab.class)
-                    .instances()
-                    .iterator()
-                    .next();
-
-            assertThat(row.isSuccess()).isTrue();
-            assertThat(row.executionTime()).isEqualTo(2);
-        });
-    }
+//    @Test
+//    @Order(30)
+//    void testRunWorkflow() {
+//        final String workflow = ""test-workflow-1"";
+//        final ProjectDetailPage projectPage =
+//                new ProjectPage(browser)
+//                        .goToNav(ProjectPage.class)
+//                        .goTo(project);
+//
+//        projectPage
+//                .goToTab(WorkflowInstanceTab.class)
+//                .deleteAll();
+//        projectPage
+//                .goToTab(WorkflowDefinitionTab.class)
+//                .run(workflow)
+//                .submit();
+//
+//        await().untilAsserted(() -> {
+//            browser.navigate().refresh();
+//
+//            final Row row = projectPage
+//                    .goToTab(WorkflowInstanceTab.class)
+//                    .instances()
+//                    .iterator()
+//                    .next();
+//
+//            assertThat(row.isSuccess()).isTrue();
+//            assertThat(row.executionTime()).isEqualTo(1);
+//        });
+//        // Test rerun
+//        projectPage
+//                .goToTab(WorkflowInstanceTab.class)
+//                .instances()
+//                .stream()
+//                .filter(it -> it.rerunButton().isDisplayed())
+//                .iterator()
+//                .next()
+//                .rerun();
+//
+//        await().untilAsserted(() -> {
+//            browser.navigate().refresh();
+//
+//            final Row row = projectPage
+//                    .goToTab(WorkflowInstanceTab.class)
+//                    .instances()
+//                    .iterator()
+//                    .next();
+//
+//            assertThat(row.isSuccess()).isTrue();
+//            assertThat(row.executionTime()).isEqualTo(2);
+//        });
+//    }","[{'comment': 'Why did you comment out this?', 'commenter': 'SbloodyS'}, {'comment': 'Because the input parameters of runworkflow are modified, the E2E is shielded for the time being. After the front-end code is merged, it is opened again.', 'commenter': 'hstdream'}, {'comment': 'Currently our E2E test does not cover the timing module and the complement module. I think we should not change it.', 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/corn/CronUtils.java,"@@ -16,14 +16,13 @@
  */
 
 package org.apache.dolphinscheduler.service.corn;
-
+import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST;","[{'comment': 'There needs to be a blank line in front of this according to checkstyle.', 'commenter': 'SbloodyS'}, {'comment': 'ok', 'commenter': 'hstdream'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -187,11 +183,20 @@ public Map<String, Object> execProcessInstance(User loginUser, long projectCode,
             return result;
         }
 
+        if(!checkScheduleTimeNum(commandType,cronTime)){
+            putMsg(result, Status.SCHEDULE_TIME_NUMBER);
+            return result;
+        }
+
+        if(!checkScheduleTimeRepeat(commandType,cronTime)){","[{'comment': 'I think we should delete duplicate data here instead of return error. This will improve the user experience.', 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -686,89 +728,116 @@ private int createCommand(CommandType commandType, long processDefineCode,
      * create complement command
      * close left and close right
      *
-     * @param start
-     * @param end
+     * @param scheduleTimeParam
      * @param runMode
      * @return
      */
-    protected int createComplementCommandList(Date start, Date end, RunMode runMode, Command command,
+    protected int createComplementCommandList(String scheduleTimeParam, RunMode runMode, Command command,
                                             Integer expectedParallelismNumber, ComplementDependentMode complementDependentMode) {
         int createCount = 0;
+        String startDate = null;
+        String endDate = null;
+        String dateList = null;
         int dependentProcessDefinitionCreateCount = 0;
-
         runMode = (runMode == null) ? RunMode.RUN_MODE_SERIAL : runMode;
         Map<String, String> cmdParam = JSONUtils.toMap(command.getCommandParam());
+        Map<String, String> scheduleParam = JSONUtils.toMap(scheduleTimeParam);
+        if(scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST)){
+            dateList = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST);
+        }
+        if(scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_START_DATE) && scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_END_DATE)){
+            startDate = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_START_DATE);
+            endDate = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_END_DATE);
+        }
         switch (runMode) {
             case RUN_MODE_SERIAL: {
-                if (start.after(end)) {
-                    logger.warn(""The startDate {} is later than the endDate {}"", start, end);
-                    break;
+                if(StringUtils.isNotEmpty(dateList) || dateList != null){","[{'comment': ""I think ```StringUtils.isNotEmpty(null)``` would return false. So it's duplicated."", 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -686,89 +728,116 @@ private int createCommand(CommandType commandType, long processDefineCode,
      * create complement command
      * close left and close right
      *
-     * @param start
-     * @param end
+     * @param scheduleTimeParam
      * @param runMode
      * @return
      */
-    protected int createComplementCommandList(Date start, Date end, RunMode runMode, Command command,
+    protected int createComplementCommandList(String scheduleTimeParam, RunMode runMode, Command command,
                                             Integer expectedParallelismNumber, ComplementDependentMode complementDependentMode) {
         int createCount = 0;
+        String startDate = null;
+        String endDate = null;
+        String dateList = null;
         int dependentProcessDefinitionCreateCount = 0;
-
         runMode = (runMode == null) ? RunMode.RUN_MODE_SERIAL : runMode;
         Map<String, String> cmdParam = JSONUtils.toMap(command.getCommandParam());
+        Map<String, String> scheduleParam = JSONUtils.toMap(scheduleTimeParam);
+        if(scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST)){
+            dateList = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST);
+        }
+        if(scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_START_DATE) && scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_END_DATE)){
+            startDate = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_START_DATE);
+            endDate = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_END_DATE);
+        }
         switch (runMode) {
             case RUN_MODE_SERIAL: {
-                if (start.after(end)) {
-                    logger.warn(""The startDate {} is later than the endDate {}"", start, end);
-                    break;
+                if(StringUtils.isNotEmpty(dateList) || dateList != null){
+                    cmdParam.put(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST,dateList);","[{'comment': 'This line should be formated.', 'commenter': 'SbloodyS'}]"
10376,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -686,89 +728,116 @@ private int createCommand(CommandType commandType, long processDefineCode,
      * create complement command
      * close left and close right
      *
-     * @param start
-     * @param end
+     * @param scheduleTimeParam
      * @param runMode
      * @return
      */
-    protected int createComplementCommandList(Date start, Date end, RunMode runMode, Command command,
+    protected int createComplementCommandList(String scheduleTimeParam, RunMode runMode, Command command,
                                             Integer expectedParallelismNumber, ComplementDependentMode complementDependentMode) {
         int createCount = 0;
+        String startDate = null;
+        String endDate = null;
+        String dateList = null;
         int dependentProcessDefinitionCreateCount = 0;
-
         runMode = (runMode == null) ? RunMode.RUN_MODE_SERIAL : runMode;
         Map<String, String> cmdParam = JSONUtils.toMap(command.getCommandParam());
+        Map<String, String> scheduleParam = JSONUtils.toMap(scheduleTimeParam);
+        if(scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST)){
+            dateList = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST);
+        }
+        if(scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_START_DATE) && scheduleParam.containsKey(CMDPARAM_COMPLEMENT_DATA_END_DATE)){
+            startDate = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_START_DATE);
+            endDate = scheduleParam.get(CMDPARAM_COMPLEMENT_DATA_END_DATE);
+        }
         switch (runMode) {
             case RUN_MODE_SERIAL: {
-                if (start.after(end)) {
-                    logger.warn(""The startDate {} is later than the endDate {}"", start, end);
-                    break;
+                if(StringUtils.isNotEmpty(dateList) || dateList != null){
+                    cmdParam.put(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST,dateList);
+                    command.setCommandParam(JSONUtils.toJsonString(cmdParam));
+                    createCount = processService.createCommand(command);
                 }
-                cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(start));
-                cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(end));
-                command.setCommandParam(JSONUtils.toJsonString(cmdParam));
-                createCount = processService.createCommand(command);
-
-                // dependent process definition
-                List<Schedule> schedules = processService.queryReleaseSchedulerListByProcessDefinitionCode(command.getProcessDefinitionCode());
-
-                if (schedules.isEmpty() || complementDependentMode == ComplementDependentMode.OFF_MODE) {
-                    logger.info(""process code: {} complement dependent in off mode or schedule's size is 0, skip ""
-                            + ""dependent complement data"", command.getProcessDefinitionCode());
-                } else {
-                    dependentProcessDefinitionCreateCount += createComplementDependentCommand(schedules, command);
+                if(startDate != null && endDate != null){
+                    cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, startDate);
+                    cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, endDate);
+                    command.setCommandParam(JSONUtils.toJsonString(cmdParam));
+                    createCount = processService.createCommand(command);
+
+                    // dependent process definition
+                    List<Schedule> schedules = processService.queryReleaseSchedulerListByProcessDefinitionCode(command.getProcessDefinitionCode());
+
+                    if (schedules.isEmpty() || complementDependentMode == ComplementDependentMode.OFF_MODE) {
+                        logger.info(""process code: {} complement dependent in off mode or schedule's size is 0, skip ""
+                                + ""dependent complement data"", command.getProcessDefinitionCode());
+                    } else {
+                        dependentProcessDefinitionCreateCount += createComplementDependentCommand(schedules, command);
+                    }
                 }
-
                 break;
             }
             case RUN_MODE_PARALLEL: {
-                if (start.after(end)) {
-                    logger.warn(""The startDate {} is later than the endDate {}"", start, end);
-                    break;
-                }
-
-                List<Date> listDate = new ArrayList<>();
-                List<Schedule> schedules = processService.queryReleaseSchedulerListByProcessDefinitionCode(command.getProcessDefinitionCode());
-                listDate.addAll(CronUtils.getSelfFireDateList(start, end, schedules));
-                int listDateSize = listDate.size();
-                createCount = listDate.size();
-                if (!CollectionUtils.isEmpty(listDate)) {
-                    if (expectedParallelismNumber != null && expectedParallelismNumber != 0) {
-                        createCount = Math.min(listDate.size(), expectedParallelismNumber);
-                        if (listDateSize < createCount) {
-                            createCount = listDateSize;
+                if(startDate != null && endDate != null){
+                    List<Date> listDate = new ArrayList<>();
+                    List<Schedule> schedules = processService.queryReleaseSchedulerListByProcessDefinitionCode(command.getProcessDefinitionCode());
+                    listDate.addAll(CronUtils.getSelfFireDateList(DateUtils.getScheduleDate(startDate), DateUtils.getScheduleDate(endDate), schedules));
+                    int listDateSize = listDate.size();
+                    createCount = listDate.size();
+                    if (!CollectionUtils.isEmpty(listDate)) {
+                        if (expectedParallelismNumber != null && expectedParallelismNumber != 0) {
+                            createCount = Math.min(listDate.size(), expectedParallelismNumber);
+                            if (listDateSize < createCount) {
+                                createCount = listDateSize;
+                            }
+                        }
+                        logger.info(""In parallel mode, current expectedParallelismNumber:{}"", createCount);
+
+                        // Distribute the number of tasks equally to each command.
+                        // The last command with insufficient quantity will be assigned to the remaining tasks.
+                        int itemsPerCommand = (listDateSize / createCount);
+                        int remainingItems = (listDateSize % createCount);
+                        int startDateIndex = 0;
+                        int endDateIndex = 0;
+
+                        for (int i = 1; i <= createCount; i++) {
+                            int extra = (i <= remainingItems) ? 1 : 0;
+                            int singleCommandItems = (itemsPerCommand + extra);
+
+                            if (i == 1) {
+                                endDateIndex += singleCommandItems - 1;
+                            } else {
+                                startDateIndex = endDateIndex + 1;
+                                endDateIndex += singleCommandItems;
+                            }
+
+                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, DateUtils.dateToString(listDate.get(startDateIndex)));
+                            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, DateUtils.dateToString(listDate.get(endDateIndex)));
+                            command.setCommandParam(JSONUtils.toJsonString(cmdParam));
+                            processService.createCommand(command);
+
+                            if (schedules.isEmpty() || complementDependentMode == ComplementDependentMode.OFF_MODE) {
+                                logger.info(""process code: {} complement dependent in off mode or schedule's size is 0, skip ""
+                                        + ""dependent complement data"", command.getProcessDefinitionCode());
+                            } else {
+                                dependentProcessDefinitionCreateCount += createComplementDependentCommand(schedules, command);
+                            }
                         }
                     }
-                    logger.info(""In parallel mode, current expectedParallelismNumber:{}"", createCount);
-
-                    // Distribute the number of tasks equally to each command.
-                    // The last command with insufficient quantity will be assigned to the remaining tasks.
-                    int itemsPerCommand = (listDateSize / createCount);
-                    int remainingItems = (listDateSize % createCount);
-                    int startDateIndex = 0;
-                    int endDateIndex = 0;
-
-                    for (int i = 1; i <= createCount; i++) {
-                        int extra = (i <= remainingItems) ? 1 : 0;
-                        int singleCommandItems = (itemsPerCommand + extra);
-
-                        if (i == 1) {
-                            endDateIndex += singleCommandItems - 1;
-                        } else {
-                            startDateIndex = endDateIndex + 1;
-                            endDateIndex += singleCommandItems;
+                }
+                if(StringUtils.isNotEmpty(dateList) || dateList != null){","[{'comment': 'Same as 754 line.', 'commenter': 'SbloodyS'}]"
10401,docs/docs/zh/faq.md,"@@ -24,7 +24,10 @@ A：DolphinScheduler 由 5 个服务组成，MasterServer、WorkerServer、ApiSe
 
 ## Q：系统支持哪些邮箱？
 
-A：支持绝大多数邮箱，qq、163、126、139、outlook、aliyun 等皆支持。支持 **TLS 和 SSL** 协议，可以在 alert.properties 中选择性配置
+A：支持绝大多数邮箱，qq、163、126、139、outlook、aliyun 等皆支持。支持 **TLS 和 SSL** 协议，可以在dolphinscheduler的ui中进行配置：","[{'comment': 'Please also modify the english docs.\r\n```docs/docs/en/faq.md```', 'commenter': 'SbloodyS'}, {'comment': 'ok', 'commenter': 'liubo1990'}]"
10401,docs/docs/zh/faq.md,"@@ -24,7 +24,10 @@ A：DolphinScheduler 由 5 个服务组成，MasterServer、WorkerServer、ApiSe
 
 ## Q：系统支持哪些邮箱？
 
-A：支持绝大多数邮箱，qq、163、126、139、outlook、aliyun 等皆支持。支持 **TLS 和 SSL** 协议，可以在 alert.properties 中选择性配置
+A：支持绝大多数邮箱，qq、163、126、139、outlook、aliyun 等皆支持。支持 **TLS 和 SSL** 协议，可以在dolphinscheduler的ui中进行配置：
+![faq](../../img/faq_alter1.png)","[{'comment': 'I think we should put all this into ```docs/docs/en/guide/alert/email.md``` like any other alert channel. And refer the link to the faq.', 'commenter': 'SbloodyS'}, {'comment': 'It is a good idea', 'commenter': 'liubo1990'}, {'comment': 'reslove', 'commenter': 'zhongjiajie'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/README.md,"@@ -0,0 +1,23 @@
+# Introduction
+
+This module is the mysql registry plugin module, this plugin will use mysql as the registry center.
+
+# How to use
+
+If you want to set the registry center as mysql, you need to do the below two steps:
+
+1. Initialize the mysql table
+
+You can directly execute the sql script `src/main/resources/mysql_registry_init.sql`.
+
+2. Open the config
+
+You need to set the registry type to mysql in master/worker/api's appplication.yml
+
+```yaml
+registry:
+  type: zookeeper","[{'comment': '```suggestion\n  type: mysql\n```\n', 'commenter': 'kezhenxu94'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/pom.xml,"@@ -0,0 +1,56 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to Apache Software Foundation (ASF) under one or more contributor
+  ~ license agreements. See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright
+  ~ ownership. Apache Software Foundation (ASF) licenses this file to you under
+  ~ the Apache License, Version 2.0 (the ""License""); you may
+  ~ not use this file except in compliance with the License.
+  ~ You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing,
+  ~ software distributed under the License is distributed on an
+  ~ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+  ~ KIND, either express or implied.  See the License for the
+  ~ specific language governing permissions and limitations
+  ~ under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <artifactId>dolphinscheduler-registry-plugins</artifactId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-registry-mysql</artifactId>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-registry-api</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-common</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-dao</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.slf4j</groupId>
+            <artifactId>slf4j-api</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>org.projectlombok</groupId>","[{'comment': ""If you want to use this. Add this to the root module (not in `<dependencyManagement>`, but in `<dependencies>`). We don't want to add it again and again in every module"", 'commenter': 'kezhenxu94'}, {'comment': 'So glad to see ```lombok``` module is introduced. ^_^', 'commenter': 'SbloodyS'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-api/pom.xml,"@@ -64,6 +64,10 @@
             <groupId>org.apache.dolphinscheduler</groupId>
             <artifactId>dolphinscheduler-registry-zookeeper</artifactId>
         </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-registry-mysql</artifactId>
+        </dependency>","[{'comment': 'Can you do in the same way as how we did in the task plugins? Create a new module `dolphinscheduler-registry-all` to contain all these registry plugin, and we can only add `dolphinscheduler-registry-all` to these starter module, in the future when we add new registry module we can only add them in `dolphinscheduler-registry-all` once', 'commenter': 'kezhenxu94'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/README.md,"@@ -0,0 +1,23 @@
+# Introduction
+
+This module is the mysql registry plugin module, this plugin will use mysql as the registry center.
+
+# How to use
+
+If you want to set the registry center as mysql, you need to do the below two steps:
+
+1. Initialize the mysql table","[{'comment': 'I think users need to add MySQL driver manually, configure the connection string, etc., if they are not already using MySQL as database.', 'commenter': 'kezhenxu94'}, {'comment': 'Yes, agree with you, I have added the datasource config, and remove the rely on dao module.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/MysqlOperator.java,"@@ -0,0 +1,294 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql;
+
+import org.apache.dolphinscheduler.common.utils.NetUtils;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.DataType;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryData;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryLock;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.SQLIntegrityConstraintViolationException;
+import java.sql.Statement;
+import java.sql.Timestamp;
+import java.util.ArrayList;
+import java.util.List;
+
+import javax.sql.DataSource;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Used to CRUD from mysql
+ */
+public class MysqlOperator {
+
+    private static final Logger logger = LoggerFactory.getLogger(MysqlOperator.class);
+
+    private final DataSource dataSource;
+
+    public MysqlOperator(DataSource dataSource) {
+        this.dataSource = dataSource;
+    }
+
+    public void healthCheck() throws SQLException {
+        String sql = ""select 1 from t_ds_mysql_registry_data"";
+        try (Connection connection = dataSource.getConnection();
+             PreparedStatement preparedStatement = connection.prepareStatement(sql)) {
+            // if no exception, the healthCheck success
+            preparedStatement.executeQuery();
+        }
+    }
+
+    public List<MysqlRegistryData> queryAllMysqlRegistryData() throws SQLException {
+        String sql = ""select id, `key`, data, type, createTime, lastUpdateTime from t_ds_mysql_registry_data"";
+        try (Connection connection = dataSource.getConnection();
+             PreparedStatement preparedStatement = connection.prepareStatement(sql)) {
+            ResultSet resultSet = preparedStatement.executeQuery();
+            List<MysqlRegistryData> result = new ArrayList<>(resultSet.getFetchSize());
+            while (resultSet.next()) {
+                MysqlRegistryData mysqlRegistryData = MysqlRegistryData.builder()
+                        .id(resultSet.getLong(1))
+                        .key(resultSet.getString(2))
+                        .data(resultSet.getString(3))
+                        .type(resultSet.getInt(4))
+                        .createTime(resultSet.getTimestamp(5))
+                        .lastUpdateTime(resultSet.getTimestamp(6))","[{'comment': 'What about getting by column label instead of the column index?', 'commenter': 'kezhenxu94'}, {'comment': 'Good suggestion, done.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/MysqlRegistryConstant.java,"@@ -0,0 +1,28 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql;
+
+import lombok.NoArgsConstructor;
+
+@NoArgsConstructor","[{'comment': 'I think you need `@UtilityClass`. `@NoArgsConstructor` means it will generate a constructor with no argument.', 'commenter': 'kezhenxu94'}]"
10406,pom.xml,"@@ -850,6 +856,13 @@
                 <version>${aws.sdk.version}</version>
             </dependency>
 
+            <dependency>
+                <groupId>org.projectlombok</groupId>
+                <artifactId>lombok</artifactId>
+                <version>${lombok.version}</version>
+                <scope>provided</scope>
+            </dependency>","[{'comment': 'Move this out from `<dependencyManagement` and move it into `<dependencies>`', 'commenter': 'kezhenxu94'}, {'comment': 'Done.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-zookeeper/src/main/java/org/apache/dolphinscheduler/plugin/registry/zookeeper/ZookeeperRegistryProperties.java,"@@ -1,33 +1,32 @@
 /*
- * Licensed to the Apache Software Foundation (ASF) under one
- * or more contributor license agreements.  See the NOTICE file
- * distributed with this work for additional information
- * regarding copyright ownership.  The ASF licenses this file
- * to you under the Apache License, Version 2.0 (the
- * ""License""); you may not use this file except in compliance
- * with the License.  You may obtain a copy of the License at
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
  *
- *   http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing,
- * software distributed under the License is distributed on an
- * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
- * KIND, either express or implied.  See the License for the
- * specific language governing permissions and limitations
- * under the License.
+ *    http://www.apache.org/licenses/LICENSE-2.0
  *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
  */
 
-package org.apache.dolphinscheduler.registry.api;
+package org.apache.dolphinscheduler.plugin.registry.zookeeper;
 
 import java.time.Duration;
 
+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
 import org.springframework.boot.context.properties.ConfigurationProperties;
 import org.springframework.context.annotation.Configuration;
 
 @Configuration
+@ConditionalOnProperty(prefix = ""registry"", name = ""type"", havingValue = ""zookeeper"")","[{'comment': 'I think you can remove the `type` field in this class then', 'commenter': 'kezhenxu94'}, {'comment': 'Done.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/task/RegistryLockManager.java,"@@ -0,0 +1,133 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql.task;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlOperator;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlRegistryConstant;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryLock;
+import org.apache.dolphinscheduler.registry.api.RegistryException;
+
+import java.sql.SQLException;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+public class RegistryLockManager implements AutoCloseable {
+
+    private static final Logger logger = LoggerFactory.getLogger(RegistryLockManager.class);
+
+    private final MysqlOperator mysqlOperator;
+    private final Map<String, MysqlRegistryLock> lockHoldMap;
+    private final ScheduledExecutorService lockTermUpdateThreadPool;
+
+    public RegistryLockManager(MysqlOperator mysqlOperator) {
+        this.mysqlOperator = mysqlOperator;
+        mysqlOperator.clearExpireLock();
+        this.lockHoldMap = new ConcurrentHashMap<>();
+        this.lockTermUpdateThreadPool = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""MysqlRegistryLockTermRefreshThread"").setDaemon(true).build());
+    }
+
+    public void start() {
+        lockTermUpdateThreadPool.scheduleWithFixedDelay(
+                new LockTermRefreshTask(lockHoldMap, mysqlOperator),
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                TimeUnit.MILLISECONDS);
+    }
+
+    /**
+     * Acquire the lock, if cannot get the lock will await.
+     */
+    public void acquireLock(String lockKey) throws RegistryException {
+        // maybe we can use the computeIf absent
+        lockHoldMap.computeIfAbsent(lockKey, key -> {
+            MysqlRegistryLock mysqlRegistryLock;
+            try {
+                while ((mysqlRegistryLock = mysqlOperator.tryToAcquireLock(lockKey)) == null) {
+                    logger.debug(""Acquire the lock {} failed try again"", key);
+                    // acquire failed, wait and try again
+                    ThreadUtils.sleep(1_000L);
+                }
+            } catch (SQLException e) {
+                throw new RegistryException(""Acquire the lock error"", e);
+            }
+            return mysqlRegistryLock;
+        });
+    }
+
+    public void releaseLock(String lockKey) {
+        MysqlRegistryLock mysqlRegistryLock = lockHoldMap.get(lockKey);
+        if (mysqlRegistryLock != null) {
+            try {
+                // the lock is unExit
+                mysqlOperator.releaseLock(mysqlRegistryLock.getId());
+                lockHoldMap.remove(lockKey);
+            } catch (SQLException e) {
+                throw new RegistryException(String.format(""Release lock: %s error"", lockKey), e);
+            }
+        }
+    }
+
+    @Override
+    public void close() {
+        lockTermUpdateThreadPool.shutdownNow();
+        for (Map.Entry<String, MysqlRegistryLock> lockEntry : lockHoldMap.entrySet()) {
+            releaseLock(lockEntry.getKey());
+        }
+    }
+
+    /**
+     * This task is used to refresh the lock held by the current server.
+     */
+    static class LockTermRefreshTask implements Runnable {
+        private final Map<String, MysqlRegistryLock> lockHoldMap;
+        private final MysqlOperator mysqlOperator;
+
+        private LockTermRefreshTask(Map<String, MysqlRegistryLock> lockHoldMap, MysqlOperator mysqlOperator) {
+            this.lockHoldMap = checkNotNull(lockHoldMap);
+            this.mysqlOperator = checkNotNull(mysqlOperator);
+        }
+","[{'comment': 'Replace these with `@RequiredArgsConstructor(access = AccessLevel.PRIVATE)` in the class', 'commenter': 'kezhenxu94'}, {'comment': 'Done.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/resources/mysql_registry_init.sql,"@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+
+SET FOREIGN_KEY_CHECKS = 0;
+
+DROP TABLE IF EXISTS `t_ds_mysql_registry_data`;
+CREATE TABLE `t_ds_mysql_registry_data`
+(
+    `id`             bigint(11)   NOT NULL AUTO_INCREMENT COMMENT 'primary key',
+    `key`            varchar(200) NOT NULL COMMENT 'key, like zookeeper node path',
+    `data`           varchar(200) NOT NULL COMMENT 'data, like zookeeper node value',
+    `type`           tinyint(4)   NOT NULL COMMENT '1: ephemeral node, 2: persistent node',
+    `lastUpdateTime` timestamp    NULL COMMENT 'last update time',
+    `createTime`     timestamp    NULL COMMENT 'create time',","[{'comment': 'column names are usually snake_case ', 'commenter': 'kezhenxu94'}, {'comment': 'Done.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/task/SubscribeDataManager.java,"@@ -0,0 +1,163 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql.task;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlOperator;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlRegistryConstant;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryData;
+import org.apache.dolphinscheduler.registry.api.Event;
+import org.apache.dolphinscheduler.registry.api.SubscribeListener;
+
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.function.Function;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+/**
+ * Used to refresh if the subscribe path has been changed.
+ */
+public class SubscribeDataManager implements AutoCloseable {
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(SubscribeDataManager.class);
+
+    private final MysqlOperator mysqlOperator;
+    private final Map<String, List<SubscribeListener>> dataSubScribeMap = new ConcurrentHashMap<>();
+    private final ScheduledExecutorService dataSubscribeCheckThreadPool;
+    private final Map<String, MysqlRegistryData> mysqlRegistryDataMap = new ConcurrentHashMap<>();
+
+    public SubscribeDataManager(MysqlOperator mysqlOperator) {
+        this.mysqlOperator = mysqlOperator;
+        this.dataSubscribeCheckThreadPool = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""MysqlRegistrySubscribeDataCheckThread"").setDaemon(true).build());
+    }
+
+    public void start() {
+        dataSubscribeCheckThreadPool.scheduleWithFixedDelay(
+                new RegistrySubscribeDataCheckTask(mysqlRegistryDataMap, dataSubScribeMap, mysqlOperator),
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                TimeUnit.MILLISECONDS);
+    }
+
+    public void addListener(String path, SubscribeListener subscribeListener) {
+        dataSubScribeMap.computeIfAbsent(path, k -> new ArrayList<>()).add(subscribeListener);
+    }
+
+    public void removeListener(String path) {
+        dataSubScribeMap.remove(path);
+    }
+
+    public String getData(String path) throws SQLException {
+        MysqlRegistryData mysqlRegistryData = mysqlRegistryDataMap.get(path);
+        if (mysqlRegistryData == null) {
+            return null;
+        }
+        return mysqlRegistryData.getData();
+    }
+
+    @Override
+    public void close() {
+        dataSubscribeCheckThreadPool.shutdownNow();
+        dataSubScribeMap.clear();
+    }
+
+    static class RegistrySubscribeDataCheckTask implements Runnable {
+
+        private final Map<String, List<SubscribeListener>> dataSubScribeMap;
+        private final MysqlOperator mysqlOperator;
+        private final Map<String, MysqlRegistryData> mysqlRegistryDataMap;
+
+        public RegistrySubscribeDataCheckTask(
+                Map<String, MysqlRegistryData> mysqlRegistryDataMap,
+                Map<String, List<SubscribeListener>> dataSubScribeMap,
+                MysqlOperator mysqlOperator) {
+            this.mysqlRegistryDataMap = checkNotNull(mysqlRegistryDataMap);
+            this.dataSubScribeMap = checkNotNull(dataSubScribeMap);
+            this.mysqlOperator = checkNotNull(mysqlOperator);
+        }","[{'comment': 'Replace this with `@RequiredArgsConstructor`', 'commenter': 'kezhenxu94'}, {'comment': 'Done.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/MysqlOperator.java,"@@ -0,0 +1,294 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql;
+
+import org.apache.dolphinscheduler.common.utils.NetUtils;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.DataType;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryData;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryLock;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.sql.Connection;
+import java.sql.PreparedStatement;
+import java.sql.ResultSet;
+import java.sql.SQLException;
+import java.sql.SQLIntegrityConstraintViolationException;
+import java.sql.Statement;
+import java.sql.Timestamp;
+import java.util.ArrayList;
+import java.util.List;
+
+import javax.sql.DataSource;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * Used to CRUD from mysql
+ */
+public class MysqlOperator {
+
+    private static final Logger logger = LoggerFactory.getLogger(MysqlOperator.class);
+
+    private final DataSource dataSource;
+
+    public MysqlOperator(DataSource dataSource) {
+        this.dataSource = dataSource;
+    }
+
+    public void healthCheck() throws SQLException {
+        String sql = ""select 1 from t_ds_mysql_registry_data"";
+        try (Connection connection = dataSource.getConnection();
+             PreparedStatement preparedStatement = connection.prepareStatement(sql)) {
+            // if no exception, the healthCheck success
+            preparedStatement.executeQuery();
+        }
+    }
+
+    public List<MysqlRegistryData> queryAllMysqlRegistryData() throws SQLException {
+        String sql = ""select id, `key`, data, type, createTime, lastUpdateTime from t_ds_mysql_registry_data"";","[{'comment': 'Can the style of mapper be used uniformly here?', 'commenter': 'caishunfeng'}, {'comment': 'This module will not rely on dao module, if we hope to use mybatis here may need to do other config like mapper scan. \r\n This can be optimized latter.', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/task/EphemeralDateManager.java,"@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql.task;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlOperator;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlRegistryConstant;
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+/**
+ * This thread is used to check the connect state to mysql.
+ */
+public class EphemeralDateManager implements AutoCloseable {
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(EphemeralDateManager.class);
+
+    private final MysqlOperator mysqlOperator;
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    private final Set<Long> ephemeralDateIds = Collections.synchronizedSet(new HashSet<>());
+    private final ScheduledExecutorService scheduledExecutorService;
+
+    public EphemeralDateManager(MysqlOperator mysqlOperator) {
+        this.mysqlOperator = checkNotNull(mysqlOperator);
+        this.scheduledExecutorService = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""EphemeralDateTermRefreshThread"").setDaemon(true).build());
+        mysqlOperator.clearExpireEphemeralDate();
+    }
+
+    public void start() {
+        this.scheduledExecutorService.scheduleWithFixedDelay(
+                new EphemeralDateTermRefreshTask(mysqlOperator, connectionListeners, ephemeralDateIds),
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                TimeUnit.MILLISECONDS);
+    }
+
+    public void addConnectionListener(ConnectionListener connectionListener) {
+        connectionListeners.add(connectionListener);
+    }
+
+    public void addEphemeralDateId(Long ephemeralDateId) {
+        ephemeralDateIds.add(ephemeralDateId);
+    }
+
+    @Override
+    public void close() throws SQLException {
+        ephemeralDateIds.clear();
+        connectionListeners.clear();
+        scheduledExecutorService.shutdownNow();
+        for (Long ephemeralDateId : ephemeralDateIds) {
+            mysqlOperator.deleteEphemeralData(ephemeralDateId);
+        }
+    }
+
+    // Use this task to refresh ephemeral term and check the connect state.
+    private static class EphemeralDateTermRefreshTask implements Runnable {
+        private final List<ConnectionListener> connectionListeners;
+        private final Set<Long> ephemeralDateIds;
+        private final MysqlOperator mysqlOperator;
+        private ConnectionState connectionState;
+
+        public EphemeralDateTermRefreshTask(MysqlOperator mysqlOperator,
+                                            List<ConnectionListener> connectionListeners,
+                                            Set<Long> ephemeralDateIds) {
+            this.mysqlOperator = checkNotNull(mysqlOperator);
+            this.connectionListeners = checkNotNull(connectionListeners);
+            this.ephemeralDateIds = checkNotNull(ephemeralDateIds);
+        }
+
+        @Override
+        public void run() {
+            try {
+                ConnectionState currentConnectionState = getConnectionState();
+                if (currentConnectionState == connectionState) {
+                    // no state change
+                    return;
+                }
+                if (connectionState == null) {
+                    // first time connect
+                    if (currentConnectionState == ConnectionState.CONNECTED) {
+                        connectionState = ConnectionState.CONNECTED;
+                        triggerListener(ConnectionState.CONNECTED);
+                    }","[{'comment': 'Should it add some else logic if `currentConnectState != ConnectionState.CONNECTED`?', 'commenter': 'caishunfeng'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/task/EphemeralDateManager.java,"@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql.task;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlOperator;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlRegistryConstant;
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+/**
+ * This thread is used to check the connect state to mysql.
+ */
+public class EphemeralDateManager implements AutoCloseable {
+
+    private static final Logger LOGGER = LoggerFactory.getLogger(EphemeralDateManager.class);
+
+    private final MysqlOperator mysqlOperator;
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    private final Set<Long> ephemeralDateIds = Collections.synchronizedSet(new HashSet<>());
+    private final ScheduledExecutorService scheduledExecutorService;
+
+    public EphemeralDateManager(MysqlOperator mysqlOperator) {
+        this.mysqlOperator = checkNotNull(mysqlOperator);
+        this.scheduledExecutorService = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""EphemeralDateTermRefreshThread"").setDaemon(true).build());
+        mysqlOperator.clearExpireEphemeralDate();
+    }
+
+    public void start() {
+        this.scheduledExecutorService.scheduleWithFixedDelay(
+                new EphemeralDateTermRefreshTask(mysqlOperator, connectionListeners, ephemeralDateIds),
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                TimeUnit.MILLISECONDS);
+    }
+
+    public void addConnectionListener(ConnectionListener connectionListener) {
+        connectionListeners.add(connectionListener);
+    }
+
+    public void addEphemeralDateId(Long ephemeralDateId) {
+        ephemeralDateIds.add(ephemeralDateId);
+    }
+
+    @Override
+    public void close() throws SQLException {
+        ephemeralDateIds.clear();
+        connectionListeners.clear();
+        scheduledExecutorService.shutdownNow();
+        for (Long ephemeralDateId : ephemeralDateIds) {
+            mysqlOperator.deleteEphemeralData(ephemeralDateId);
+        }
+    }
+
+    // Use this task to refresh ephemeral term and check the connect state.
+    private static class EphemeralDateTermRefreshTask implements Runnable {
+        private final List<ConnectionListener> connectionListeners;
+        private final Set<Long> ephemeralDateIds;
+        private final MysqlOperator mysqlOperator;
+        private ConnectionState connectionState;
+
+        public EphemeralDateTermRefreshTask(MysqlOperator mysqlOperator,
+                                            List<ConnectionListener> connectionListeners,
+                                            Set<Long> ephemeralDateIds) {
+            this.mysqlOperator = checkNotNull(mysqlOperator);
+            this.connectionListeners = checkNotNull(connectionListeners);
+            this.ephemeralDateIds = checkNotNull(ephemeralDateIds);
+        }
+
+        @Override
+        public void run() {
+            try {
+                ConnectionState currentConnectionState = getConnectionState();
+                if (currentConnectionState == connectionState) {
+                    // no state change
+                    return;
+                }
+                if (connectionState == null) {
+                    // first time connect
+                    if (currentConnectionState == ConnectionState.CONNECTED) {
+                        connectionState = ConnectionState.CONNECTED;
+                        triggerListener(ConnectionState.CONNECTED);
+                    }
+                } else {
+                    // already connect before
+                    if (connectionState == ConnectionState.CONNECTED && currentConnectionState == ConnectionState.DISCONNECTED) {
+                        connectionState = ConnectionState.DISCONNECTED;
+                        triggerListener(ConnectionState.DISCONNECTED);
+                    } else if (connectionState == ConnectionState.DISCONNECTED && currentConnectionState == ConnectionState.CONNECTED) {
+                        connectionState = ConnectionState.CONNECTED;
+                        triggerListener(ConnectionState.RECONNECTED);
+                    }","[{'comment': 'same here', 'commenter': 'caishunfeng'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/java/org/apache/dolphinscheduler/plugin/registry/mysql/task/RegistryLockManager.java,"@@ -0,0 +1,133 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.mysql.task;
+
+import static com.google.common.base.Preconditions.checkNotNull;
+
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlOperator;
+import org.apache.dolphinscheduler.plugin.registry.mysql.MysqlRegistryConstant;
+import org.apache.dolphinscheduler.plugin.registry.mysql.model.MysqlRegistryLock;
+import org.apache.dolphinscheduler.registry.api.RegistryException;
+
+import java.sql.SQLException;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+public class RegistryLockManager implements AutoCloseable {
+
+    private static final Logger logger = LoggerFactory.getLogger(RegistryLockManager.class);
+
+    private final MysqlOperator mysqlOperator;
+    private final Map<String, MysqlRegistryLock> lockHoldMap;
+    private final ScheduledExecutorService lockTermUpdateThreadPool;
+
+    public RegistryLockManager(MysqlOperator mysqlOperator) {
+        this.mysqlOperator = mysqlOperator;
+        mysqlOperator.clearExpireLock();
+        this.lockHoldMap = new ConcurrentHashMap<>();
+        this.lockTermUpdateThreadPool = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""MysqlRegistryLockTermRefreshThread"").setDaemon(true).build());
+    }
+
+    public void start() {
+        lockTermUpdateThreadPool.scheduleWithFixedDelay(
+                new LockTermRefreshTask(lockHoldMap, mysqlOperator),
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                MysqlRegistryConstant.TERM_REFRESH_INTERVAL,
+                TimeUnit.MILLISECONDS);
+    }
+
+    /**
+     * Acquire the lock, if cannot get the lock will await.
+     */
+    public void acquireLock(String lockKey) throws RegistryException {
+        // maybe we can use the computeIf absent
+        lockHoldMap.computeIfAbsent(lockKey, key -> {
+            MysqlRegistryLock mysqlRegistryLock;
+            try {
+                while ((mysqlRegistryLock = mysqlOperator.tryToAcquireLock(lockKey)) == null) {
+                    logger.debug(""Acquire the lock {} failed try again"", key);
+                    // acquire failed, wait and try again
+                    ThreadUtils.sleep(1_000L);","[{'comment': ""It's better to use the constant."", 'commenter': 'caishunfeng'}]"
10406,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-mysql/src/main/resources/mysql_registry_init.sql,"@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+
+SET FOREIGN_KEY_CHECKS = 0;
+
+DROP TABLE IF EXISTS `t_ds_mysql_registry_data`;
+CREATE TABLE `t_ds_mysql_registry_data`
+(
+    `id`             bigint(11)   NOT NULL AUTO_INCREMENT COMMENT 'primary key',
+    `key`            varchar(200) NOT NULL COMMENT 'key, like zookeeper node path',
+    `data`           varchar(200) NOT NULL COMMENT 'data, like zookeeper node value',
+    `type`           tinyint(4)   NOT NULL COMMENT '1: ephemeral node, 2: persistent node',
+    `lastUpdateTime` timestamp    NULL COMMENT 'last update time',
+    `createTime`     timestamp    NULL COMMENT 'create time',
+    PRIMARY KEY (`id`),
+    unique (`key`)
+) ENGINE = InnoDB
+  DEFAULT CHARSET = utf8;
+
+
+DROP TABLE IF EXISTS `t_ds_mysql_registry_lock`;
+CREATE TABLE `t_ds_mysql_registry_lock`","[{'comment': 'should we add the lock owner to avoid deleting lock by mistake?', 'commenter': 'caishunfeng'}, {'comment': 'The host can represent the lock owner.', 'commenter': 'ruanwenjun'}, {'comment': '> The host can represent the lock owner.\r\n\r\nThis is dangerous when users deploy multiple components in a single machine/host, like pseudo cluster mode, you at least need to add process id to the owner key?', 'commenter': 'kezhenxu94'}]"
10437,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -414,7 +414,7 @@ public Map<String, Object> updateUser(User loginUser, int userId,
 
         if (StringUtils.isNotEmpty(userPassword)) {
             if (!CheckUtils.checkPassword(userPassword)) {
-                putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, userPassword);
+                putMsg(result, Status.USER_PASSWORD_NOT_VALID_OR_TOO_LONG_ERROR, userPassword);","[{'comment': 'please check separately and return different tips.', 'commenter': 'caishunfeng'}]"
10437,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -413,10 +414,15 @@ public Map<String, Object> updateUser(User loginUser, int userId,
         }
 
         if (StringUtils.isNotEmpty(userPassword)) {
-            if (!CheckUtils.checkPassword(userPassword)) {
+
+            if (!StringUtils.isEmpty(userPassword)) {
                 putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, userPassword);
                 return result;
             }
+            if (CheckUtils.checkPasswordLength(userPassword)) {
+                putMsg(result, Status.USER_PASSWORD_LENGTH_ERROR);
+                return result;
+            }","[{'comment': '```suggestion\r\n            if (StringUtils.isEmpty(userPassword)) {\r\n                putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, userPassword);\r\n                return result;\r\n            }\r\n            if (CheckUtils.checkPasswordLength(userPassword)) {\r\n                putMsg(result, Status.USER_PASSWORD_LENGTH_ERROR);\r\n                return result;\r\n            }\r\n```', 'commenter': 'caishunfeng'}]"
10437,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -413,10 +414,15 @@ public Map<String, Object> updateUser(User loginUser, int userId,
         }
 
         if (StringUtils.isNotEmpty(userPassword)) {","[{'comment': 'remove the outer not empty validate', 'commenter': 'caishunfeng'}, {'comment': ""> remove the outer not empty validate\r\n\r\nI found that my conditional judgment was wrong. I was very confused about the other judgment. I didn't rule out null values, but I didn't modify it to maintain consistency"", 'commenter': 'syyangs799'}, {'comment': ""> > remove the outer not empty validate\r\n> \r\n> I found that my conditional judgment was wrong. I was very confused about the other judgment. I didn't rule out null values, but I didn't modify it to maintain consistency\r\n\r\nSorry @syyangs799 , I found that my original comment is wrong, the outer non-null judgment needs to be retained, and will only be replaced when the new password is not null.\r\nIn this way, it's enough to keep the `checkPasswordLength` validate when password not empty, what do you think?\r\n"", 'commenter': 'caishunfeng'}, {'comment': ""> > > remove the outer not empty validate\r\n> > \r\n> > \r\n> > I found that my conditional judgment was wrong. I was very confused about the other judgment. I didn't rule out null values, but I didn't modify it to maintain consistency\r\n> \r\n> Sorry @syyangs799 , I found that my original comment is wrong, the outer non-null judgment needs to be retained, and will only be replaced when the new password is not null. In this way, it's enough to keep the `checkPasswordLength` validate when password not empty, what do you think?\r\n\r\nok，I understand that this is to modify the user's other non password information"", 'commenter': 'syyangs799'}]"
10563,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/HeartBeat.java,"@@ -26,22 +26,22 @@ public class HeartBeat {
 
     private static final Logger logger = LoggerFactory.getLogger(HeartBeat.class);
 
-    private long startupTime;
-    private long reportTime;
-    private double cpuUsage;
-    private double memoryUsage;
-    private double loadAverage;
-    private double availablePhysicalMemorySize;
-    private double maxCpuloadAvg;
-    private double reservedMemory;
-    private int serverStatus;
-    private int processId;
-
-    private int workerHostWeight; // worker host weight
-    private int workerWaitingTaskCount; // worker waiting task count
-    private int workerExecThreadCount; // worker thread pool thread count
-
-    private double diskAvailable;
+    protected long startupTime;
+    protected long reportTime;
+    protected double cpuUsage;
+    protected double memoryUsage;
+    protected double loadAverage;
+    protected double availablePhysicalMemorySize;
+    protected double maxCpuloadAvg;
+    protected double reservedMemory;
+    protected int serverStatus;
+    protected int processId;
+
+    protected int workerHostWeight; // worker host weight
+    protected int workerWaitingTaskCount; // worker waiting task count
+    protected int workerExecThreadCount; // worker thread pool thread count","[{'comment': 'These fields need to move to `WorkerHeartBeat`?', 'commenter': 'ruanwenjun'}, {'comment': 'I think these attributes should be a part of  `HeartBeat`, but only apply to `WorkerHeartBeat`. \r\nThe advantage is that the processing of `HeartBeat` is consistent， like `decodeHeartBeat`', 'commenter': 'guoshupei'}, {'comment': ""It's better to move these field to subclass, and maybe we can use directly use Json to serialize/deserialize the heartbeat? cc @caishunfeng WDYT"", 'commenter': 'ruanwenjun'}, {'comment': 'there are pros and cons, anything will do', 'commenter': 'guoshupei'}]"
10563,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/registry/RegistryClient.java,"@@ -97,7 +98,7 @@ public List<Server> getServerList(NodeType nodeType) {
 
         List<Server> serverList = new ArrayList<>();
         for (Map.Entry<String, String> entry : serverMaps.entrySet()) {
-            HeartBeat heartBeat = HeartBeat.decodeHeartBeat(entry.getValue());
+            HeartBeatModel heartBeat = HeartBeatUtils.decodeHeartBeat(entry.getValue(), nodeType);","[{'comment': 'You can make `HeartBeatUtil.decodeHeartBeat` return `AbstractHeartBeat` , then the `HeartBeatModel` can be removed.', 'commenter': 'ruanwenjun'}, {'comment': 'Worker fields are needed in some places. like host manager, Of course, it can also be obtained by split string of heartbeat ,but it is not graceful.', 'commenter': 'guoshupei'}, {'comment': ""> You can make `HeartBeatUtil.decodeHeartBeat` return `AbstractHeartBeat` , then the `HeartBeatModel` can be removed.\r\n\r\nWhen I designed `WorkerHeartBeat` and `MasterHeartBeat`, I have a dependency cycle problem, so I defined `HeartBeatModel` in module `dolphinscheduler-common` that contains all heartbeatInfo, which also avoids the need to hard code the worker's Heartbeat in the master, For example, the workWaitingTaskCount attribute is used in HostManager.\r\n\r\ncurrent design: \r\n`MasterHeartBeat` in `dolphinscheduler-master`\r\n`WorkerHeartBeat `in `dolphinscheduler-worker`\r\n`AbstractHeartBeat `in `dolphinscheduler-server` (move into `dolphinscheduler-common` is also ok)\r\n`HeartBeatModel `in `dolphinscheduler-common`\r\n\r\nps:\r\n`WorkerHeartBeat `dependency injection `WorkerManagerThread `of dolphinscheduler-worker\r\n`HostWeight `of dolphinscheduler-master use `workWaitingTaskCount `of WorkerHeartBeat \r\n\r\nI don't have any good ideas right now. I need your help.\r\n"", 'commenter': 'guoshupei'}, {'comment': 'Is there any problem if you remove the `HeartBeatModel` and only keep AbstractHeart/MasterHeartBeat/WorkHeartBeat ?', 'commenter': 'ruanwenjun'}, {'comment': ""When we get a HeartBeatInfo, we need to know this HeartBeatInfo is represent to worker or master, rather than use a big pojo to contains all fields. If we use a big pojo to represent the HeartBeatInfo, it's hard to know which field is available."", 'commenter': 'ruanwenjun'}, {'comment': 'First , thank you very much for your patient explanation And I really agree with you.  If `HeartBeatModel ` is deleted, there may be some hard coding in the master, which I cannot accept at present. Therefore, I am ready to give up this PR. I hope that if someone changes it, you can tell me. I want to learn it', 'commenter': 'guoshupei'}, {'comment': ""You don't need to give up this PR, this PR is meaningful. Could you please describe `hard coding in the master`? If you mean the master need to judge the HeartBeatInfo type I think this is needed."", 'commenter': 'ruanwenjun'}, {'comment': ""At present, I think it's hard coding.\r\n\r\n![image](https://user-images.githubusercontent.com/29919212/176172028-a7263ddc-a82f-4d29-ad11-67fd791b1858.png)\r\n"", 'commenter': 'guoshupei'}, {'comment': 'You can decode the heartBeatInfo in line 140 and return a WorkerHeartBeat, I think this is OK?', 'commenter': 'ruanwenjun'}, {'comment': 'WorkerHeartBeat in dolphinscheduler-worker. \r\n\r\nPS:WorkerHeartBeat dependency injection WorkerManagerThread of dolphinscheduler-worker', 'commenter': 'guoshupei'}, {'comment': 'OK, I got you....... If so, I suggest we can move the `WorkerHeartBeat` and `MasterHeartBeat` into a `common` module which can be used in api/master/worker.', 'commenter': 'ruanwenjun'}, {'comment': 'First, we need to reach a consensus that `WorkerHeartBeat` must autowared `WorkerManagerThread` in order to get `WorkerWaitingTaskCount`.\r\n\r\nAs you said，`WorkerHeartBeat` in `common` module, but `worker` module depend` common` module and `WorkerManagerThread` in `worker` module.\r\n![image](https://user-images.githubusercontent.com/29919212/176203192-8b57a207-1a94-4f05-b94b-0724f7914b71.png)\r\n\r\n', 'commenter': 'guoshupei'}, {'comment': 'WorkHeartBeat is just a pojo, it should not depend anything, if I have any misunderstand, please let me know.', 'commenter': 'ruanwenjun'}, {'comment': 'The worker needs to update `workWaitingTaskCount `to report the heartbeat information. ', 'commenter': 'guoshupei'}, {'comment': 'Yes, the worker will schedule a WorkerHeartbeatTask to update the info in WorkHeartBeat, there seems no problem.', 'commenter': 'ruanwenjun'}, {'comment': 'I have some questions to confirm.\r\n-  1. Do we need to define a `WorkerHeartbeatTask` ?\r\n- 2. What do you mean `WorkerHeartbeatTask`  autowared `WorkerManagerThread` ?\r\n- 3. Which module is `WorkerHeartbeatTask` in ?', 'commenter': 'guoshupei'}]"
10624,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/expand/ExternalFunctionExtensionCenter.java,"@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.expand;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+
+@Component
+public class ExternalFunctionExtensionCenter {
+
+    @Autowired
+    private TimePlaceholderResolverExpandService expandService;
+
+    private static ExternalFunctionExtensionCenter expandCenter;
+
+    @PostConstruct
+    public void init() {
+        expandCenter = this;
+        expandCenter.expandService = this.expandService;
+    }
+
+    public static boolean timeFunctionNeedExpand(String placeholderName) {
+        return expandCenter.expandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    public static String timeFunctionExtension(Integer processInstanceId, String timeZone, String placeholderName) {
+        return expandCenter.expandService.timeFunctionExtension(processInstanceId, timeZone, placeholderName);
+    }
+}","[{'comment': 'Please remove `static`, this is not safe.', 'commenter': 'ruanwenjun'}, {'comment': 'whether a static method causes thread safety depends on whether a static field is used in the static method. If the static method does not operate a static field, only the instance field is used inside the method, which will not cause security problems.', 'commenter': 'WangJPLeo'}, {'comment': 'When someone execute `ExternalFunctionExtensionCenter.timeFunctionNeedExpand`, he will get unknown result, since he cannot sure if this class has been initialized. This is not a good practice, we need to avoid operating a non-static variable in a static method.', 'commenter': 'ruanwenjun'}, {'comment': 'And if someone use this method in not spring object, he will get error.', 'commenter': 'ruanwenjun'}, {'comment': 'yes, this is indeed a matter of principle. At first, I thought that although the method call is inappropriate, it is thread-safe. I will make a suitable extension optimization for this, thank you for your review.', 'commenter': 'WangJPLeo'}]"
10624,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/expand/TimePlaceholderResolverExpandServiceImpl.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.expand;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Component;
+
+@Component
+public class TimePlaceholderResolverExpandServiceImpl implements TimePlaceholderResolverExpandService {
+
+    private static final Logger logger = LoggerFactory.getLogger(TimePlaceholderResolverExpandServiceImpl.class);
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return false;
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timeZone, String placeholderName) {
+        logger.warn(""time function external expansion"");","[{'comment': 'remove if not use, and I think the log level is `debug` or `info`, not `warn`.', 'commenter': 'caishunfeng'}, {'comment': 'ok thank you.', 'commenter': 'WangJPLeo'}]"
10624,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/ParameterUtils.java,"@@ -86,7 +89,7 @@ public static String convertParameterPlaceholders(String parameterString, Map<St
      * @param scheduleTime    schedule time
      * @return curing user define parameters
      */
-    public static String curingGlobalParams(Map<String, String> globalParamMap, List<Property> globalParamList,
+    public static String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList,","[{'comment': 'Please update the notes too.', 'commenter': 'caishunfeng'}, {'comment': 'ok.', 'commenter': 'WangJPLeo'}]"
10640,dolphinscheduler-task-plugin/dolphinscheduler-task-dinky/src/main/java/org/apache/dolphinscheduler/plugin/task/dinky/DinkyTask.java,"@@ -0,0 +1,272 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dinky;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.http.HttpResponse;
+import org.apache.http.HttpStatus;
+import org.apache.http.client.HttpClient;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.client.utils.URIBuilder;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.impl.client.HttpClientBuilder;
+import org.apache.http.util.EntityUtils;
+
+import java.net.URI;
+import java.nio.charset.StandardCharsets;
+import java.util.HashMap;
+import java.util.Map;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.node.MissingNode;
+
+public class DinkyTask extends AbstractTaskExecutor {
+
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+
+    /**
+     * dinky parameters
+     */
+    private DinkyParameters dinkyParameters;
+
+    /**
+     * constructor
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    protected DinkyTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+    }
+
+    @Override
+    public void init() {
+        final String taskParams = taskExecutionContext.getTaskParams();
+        logger.info(""dinky task params:{}"", taskParams);
+        this.dinkyParameters = JSONUtils.parseObject(taskParams, DinkyParameters.class);
+        if (this.dinkyParameters == null || !this.dinkyParameters.checkParameters()) {
+            throw new DinkyTaskException(""dinky task params is not valid"");
+        }
+    }
+
+    @Override
+    public void handle() throws Exception {
+        try {
+            String address = this.dinkyParameters.getAddress();
+            String taskId = this.dinkyParameters.getTaskId();
+            boolean isOnline = this.dinkyParameters.isOnline();
+            JsonNode result;
+            if (isOnline) {
+                // Online dinky task, and only one job is allowed to execute
+                result = onlineTask(address, taskId);
+            } else {
+                // Submit dinky task
+                result = submitTask(address, taskId);
+            }
+            if (checkResult(result)) {
+                boolean status = result.get(DinkyTaskConstants.API_RESULT_DATAS).get(""success"").asBoolean();
+                String jobInstanceId = result.get(DinkyTaskConstants.API_RESULT_DATAS).get(""jobInstanceId"").asText();
+                boolean finishFlag = false;
+                while (!finishFlag) {
+                    JsonNode jobInstanceInfoResult = getJobInstanceInfo(address, jobInstanceId);
+                    if (!checkResult(jobInstanceInfoResult)) {
+                        break;
+                    }
+                    String jobInstanceStatus = jobInstanceInfoResult.get(DinkyTaskConstants.API_RESULT_DATAS).get(""status"").asText();
+                    switch (jobInstanceStatus) {
+                        case DinkyTaskConstants.STATUS_FINISHED:
+                            final int exitStatusCode = mapStatusToExitCode(status);
+                            // Use address-taskId as app id
+                            setAppIds(String.format(""%s-%s"", address, taskId));
+                            setExitStatusCode(exitStatusCode);
+                            logger.info(""dinky task finished with results: {}"", result.get(DinkyTaskConstants.API_RESULT_DATAS));
+                            finishFlag = true;
+                            break;
+                        case DinkyTaskConstants.STATUS_FAILED:
+                        case DinkyTaskConstants.STATUS_CANCELED:
+                        case DinkyTaskConstants.STATUS_UNKNOWN:
+                            errorHandle(jobInstanceInfoResult.get(DinkyTaskConstants.API_RESULT_DATAS).get(""error"").asText());
+                            finishFlag = true;
+                            break;
+                        default:
+                            Thread.sleep(DinkyTaskConstants.SLEEP_MILLIS);","[{'comment': 'Why to sleep here? What state does default represent?', 'commenter': 'caishunfeng'}, {'comment': 'Hi. Need to poll for task status.', 'commenter': 'aiwenmo'}]"
10640,dolphinscheduler-task-plugin/dolphinscheduler-task-dinky/src/main/java/org/apache/dolphinscheduler/plugin/task/dinky/DinkyTask.java,"@@ -0,0 +1,272 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dinky;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.http.HttpResponse;
+import org.apache.http.HttpStatus;
+import org.apache.http.client.HttpClient;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.client.utils.URIBuilder;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.impl.client.HttpClientBuilder;
+import org.apache.http.util.EntityUtils;
+
+import java.net.URI;
+import java.nio.charset.StandardCharsets;
+import java.util.HashMap;
+import java.util.Map;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.node.MissingNode;
+
+public class DinkyTask extends AbstractTaskExecutor {
+
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+
+    /**
+     * dinky parameters
+     */
+    private DinkyParameters dinkyParameters;
+
+    /**
+     * constructor
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    protected DinkyTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+    }
+
+    @Override
+    public void init() {
+        final String taskParams = taskExecutionContext.getTaskParams();
+        logger.info(""dinky task params:{}"", taskParams);
+        this.dinkyParameters = JSONUtils.parseObject(taskParams, DinkyParameters.class);
+        if (this.dinkyParameters == null || !this.dinkyParameters.checkParameters()) {
+            throw new DinkyTaskException(""dinky task params is not valid"");
+        }
+    }
+
+    @Override
+    public void handle() throws Exception {
+        try {
+            String address = this.dinkyParameters.getAddress();
+            String taskId = this.dinkyParameters.getTaskId();
+            boolean isOnline = this.dinkyParameters.isOnline();
+            JsonNode result;
+            if (isOnline) {
+                // Online dinky task, and only one job is allowed to execute
+                result = onlineTask(address, taskId);
+            } else {
+                // Submit dinky task
+                result = submitTask(address, taskId);
+            }
+            if (checkResult(result)) {
+                boolean status = result.get(DinkyTaskConstants.API_RESULT_DATAS).get(""success"").asBoolean();
+                String jobInstanceId = result.get(DinkyTaskConstants.API_RESULT_DATAS).get(""jobInstanceId"").asText();
+                boolean finishFlag = false;
+                while (!finishFlag) {
+                    JsonNode jobInstanceInfoResult = getJobInstanceInfo(address, jobInstanceId);
+                    if (!checkResult(jobInstanceInfoResult)) {
+                        break;
+                    }
+                    String jobInstanceStatus = jobInstanceInfoResult.get(DinkyTaskConstants.API_RESULT_DATAS).get(""status"").asText();
+                    switch (jobInstanceStatus) {
+                        case DinkyTaskConstants.STATUS_FINISHED:
+                            final int exitStatusCode = mapStatusToExitCode(status);
+                            // Use address-taskId as app id
+                            setAppIds(String.format(""%s-%s"", address, taskId));
+                            setExitStatusCode(exitStatusCode);
+                            logger.info(""dinky task finished with results: {}"", result.get(DinkyTaskConstants.API_RESULT_DATAS));
+                            finishFlag = true;
+                            break;
+                        case DinkyTaskConstants.STATUS_FAILED:
+                        case DinkyTaskConstants.STATUS_CANCELED:
+                        case DinkyTaskConstants.STATUS_UNKNOWN:
+                            errorHandle(jobInstanceInfoResult.get(DinkyTaskConstants.API_RESULT_DATAS).get(""error"").asText());
+                            finishFlag = true;
+                            break;
+                        default:
+                            Thread.sleep(DinkyTaskConstants.SLEEP_MILLIS);
+                    }
+                }
+            }
+        } catch (Exception e) {
+            errorHandle(e);","[{'comment': 'It seems unnecessary to package error handle. You can handle error directly.', 'commenter': 'caishunfeng'}, {'comment': ""Hi. Do you mean to remove 'try catch' ?"", 'commenter': 'aiwenmo'}, {'comment': ""> Hi. Do you mean to remove 'try catch' ?\r\n\r\nNo, I mean remove the `errorHandle` method and handle error directly.  Just a suggestion, nip."", 'commenter': 'caishunfeng'}]"
10640,dolphinscheduler-task-plugin/dolphinscheduler-task-dinky/src/main/java/org/apache/dolphinscheduler/plugin/task/dinky/DinkyTask.java,"@@ -0,0 +1,272 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dinky;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.http.HttpResponse;
+import org.apache.http.HttpStatus;
+import org.apache.http.client.HttpClient;
+import org.apache.http.client.methods.HttpGet;
+import org.apache.http.client.methods.HttpPost;
+import org.apache.http.client.utils.URIBuilder;
+import org.apache.http.entity.StringEntity;
+import org.apache.http.impl.client.HttpClientBuilder;
+import org.apache.http.util.EntityUtils;
+
+import java.net.URI;
+import java.nio.charset.StandardCharsets;
+import java.util.HashMap;
+import java.util.Map;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonNode;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.node.MissingNode;
+
+public class DinkyTask extends AbstractTaskExecutor {
+
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+
+    /**
+     * dinky parameters
+     */
+    private DinkyParameters dinkyParameters;
+
+    /**
+     * constructor
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    protected DinkyTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+    }
+
+    @Override
+    public void init() {
+        final String taskParams = taskExecutionContext.getTaskParams();
+        logger.info(""dinky task params:{}"", taskParams);
+        this.dinkyParameters = JSONUtils.parseObject(taskParams, DinkyParameters.class);
+        if (this.dinkyParameters == null || !this.dinkyParameters.checkParameters()) {
+            throw new DinkyTaskException(""dinky task params is not valid"");
+        }
+    }
+
+    @Override
+    public void handle() throws Exception {
+        try {
+            String address = this.dinkyParameters.getAddress();
+            String taskId = this.dinkyParameters.getTaskId();
+            boolean isOnline = this.dinkyParameters.isOnline();
+            JsonNode result;
+            if (isOnline) {
+                // Online dinky task, and only one job is allowed to execute
+                result = onlineTask(address, taskId);
+            } else {
+                // Submit dinky task
+                result = submitTask(address, taskId);
+            }
+            if (checkResult(result)) {
+                boolean status = result.get(DinkyTaskConstants.API_RESULT_DATAS).get(""success"").asBoolean();
+                String jobInstanceId = result.get(DinkyTaskConstants.API_RESULT_DATAS).get(""jobInstanceId"").asText();
+                boolean finishFlag = false;
+                while (!finishFlag) {
+                    JsonNode jobInstanceInfoResult = getJobInstanceInfo(address, jobInstanceId);
+                    if (!checkResult(jobInstanceInfoResult)) {
+                        break;
+                    }
+                    String jobInstanceStatus = jobInstanceInfoResult.get(DinkyTaskConstants.API_RESULT_DATAS).get(""status"").asText();
+                    switch (jobInstanceStatus) {
+                        case DinkyTaskConstants.STATUS_FINISHED:
+                            final int exitStatusCode = mapStatusToExitCode(status);
+                            // Use address-taskId as app id
+                            setAppIds(String.format(""%s-%s"", address, taskId));
+                            setExitStatusCode(exitStatusCode);
+                            logger.info(""dinky task finished with results: {}"", result.get(DinkyTaskConstants.API_RESULT_DATAS));
+                            finishFlag = true;
+                            break;
+                        case DinkyTaskConstants.STATUS_FAILED:
+                        case DinkyTaskConstants.STATUS_CANCELED:
+                        case DinkyTaskConstants.STATUS_UNKNOWN:
+                            errorHandle(jobInstanceInfoResult.get(DinkyTaskConstants.API_RESULT_DATAS).get(""error"").asText());
+                            finishFlag = true;
+                            break;
+                        default:
+                            Thread.sleep(DinkyTaskConstants.SLEEP_MILLIS);
+                    }
+                }
+            }
+        } catch (Exception e) {
+            errorHandle(e);
+        }
+    }
+
+    /**
+     * map dinky task status to exitStatusCode
+     *
+     * @param status dinky job status
+     * @return exitStatusCode
+     */
+    private int mapStatusToExitCode(boolean status) {
+        if (status) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+    }
+
+    private boolean checkResult(JsonNode result) {
+        if (result instanceof MissingNode || result == null) {
+            errorHandle(DinkyTaskConstants.API_VERSION_ERROR_TIPS);
+            return false;
+        } else if (result.get(""code"").asInt() == DinkyTaskConstants.API_ERROR) {
+            errorHandle(result.get(""msg""));
+            return false;
+        }
+        return true;
+    }
+
+    private void errorHandle(Object msg) {
+        setExitStatusCode(TaskConstants.EXIT_CODE_FAILURE);
+        logger.error(""dinky task submit failed with error: {}"", msg);
+    }
+
+    @Override
+    public AbstractParameters getParameters() {
+        return dinkyParameters;
+    }
+
+    @Override
+    public void cancelApplication(boolean status) throws Exception {
+        super.cancelApplication(status);
+        String address = this.dinkyParameters.getAddress();
+        String taskId = this.dinkyParameters.getTaskId();
+        logger.info(""trying terminate dinky task, taskId: {}, address: {}, taskId: {}"",
+            this.taskExecutionContext.getTaskInstanceId(),
+            address,
+            taskId);
+        cancelTask(address, taskId);
+        logger.info(""dinky task terminated, taskId: {}, address: {}, taskId: {}"",
+            this.taskExecutionContext.getTaskInstanceId(),
+            address,
+            taskId);
+    }
+
+    private JsonNode submitTask(String address, String taskId) {
+        Map<String, String> params = new HashMap<>();
+        params.put(DinkyTaskConstants.PARAM_TASK_ID, taskId);
+        return parse(doGet(address + DinkyTaskConstants.SUBMIT_TASK, params));
+    }
+
+    private JsonNode onlineTask(String address, String taskId) {
+        Map<String, String> params = new HashMap<>();
+        params.put(DinkyTaskConstants.PARAM_TASK_ID, taskId);
+        return parse(doGet(address + DinkyTaskConstants.ONLINE_TASK, params));
+    }
+
+    private JsonNode cancelTask(String address, String taskId) {
+        Map<String, String> params = new HashMap<>();
+        params.put(DinkyTaskConstants.PARAM_JSON_TASK_ID, taskId);
+        params.put(DinkyTaskConstants.PARAM_SAVEPOINT_TYPE, DinkyTaskConstants.SAVEPOINT_CANCEL);
+        return parse(sendJsonStr(address + DinkyTaskConstants.SAVEPOINT_TASK, JSONUtils.toJsonString(params)));
+    }
+
+    private JsonNode getJobInstanceInfo(String address, String taskId) {
+        Map<String, String> params = new HashMap<>();
+        params.put(DinkyTaskConstants.PARAM_JOB_INSTANCE_ID, taskId);
+        return parse(doGet(address + DinkyTaskConstants.GET_JOB_INFO, params));
+    }
+
+    private JsonNode parse(String res) {
+        ObjectMapper mapper = new ObjectMapper();
+        JsonNode result = null;
+        try {
+            result = mapper.readTree(res);
+        } catch (JsonProcessingException e) {
+            logger.error(""dinky task submit failed with error"", e);
+        }
+        return result;
+    }
+
+    private String doGet(String url, Map<String, String> params) {
+        String result = """";
+        HttpClient httpClient = HttpClientBuilder.create().build();
+        HttpGet httpGet = null;
+        try {
+            URIBuilder uriBuilder = new URIBuilder(url);
+            if (null != params && !params.isEmpty()) {
+                for (Map.Entry<String, String> entry : params.entrySet()) {
+                    uriBuilder.addParameter(entry.getKey(), entry.getValue());
+                }
+            }
+            URI uri = uriBuilder.build();
+            httpGet = new HttpGet(uri);
+            logger.info(""access url: {}"", uri);
+            HttpResponse response = httpClient.execute(httpGet);
+            if (response.getStatusLine().getStatusCode() == HttpStatus.SC_OK) {
+                result = EntityUtils.toString(response.getEntity());
+                logger.info(""dinky task succeed with results: {}"", result);
+            } else {
+                logger.info(""dinky task terminated,response: {}"", response);","[{'comment': 'Change the log level to `warn` or `error` is better, WDYT?', 'commenter': 'caishunfeng'}, {'comment': ""It's a good advice. thx"", 'commenter': 'aiwenmo'}]"
10640,dolphinscheduler-task-plugin/dolphinscheduler-task-dinky/src/main/java/org/apache/dolphinscheduler/plugin/task/dinky/DinkyTaskChannel.java,"@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dinky;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskChannel;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.ParametersNode;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+public class DinkyTaskChannel implements TaskChannel {
+
+    @Override
+    public void cancelApplication(boolean status) {
+        // nothing to do","[{'comment': 'Why not implement this?', 'commenter': 'SbloodyS'}]"
10640,dolphinscheduler-ui/src/views/projects/task/components/node/tasks/use-dinky.ts,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import {reactive} from 'vue'
+import * as Fields from '../fields/index'
+import type {IJsonItem, INodeData, ITaskData} from '../types'
+
+export function useDinky({
+                             projectCode,
+                             from = 0,
+                             readonly,
+                             data
+                         }: {","[{'comment': ""It's better to format the codes by running 'npm run prettier'."", 'commenter': 'Amy0104'}]"
10640,dolphinscheduler-ui/src/views/projects/task/components/node/tasks/use-dinky.ts,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import {reactive} from 'vue'
+import * as Fields from '../fields/index'
+import type {IJsonItem, INodeData, ITaskData} from '../types'
+
+export function useDinky({
+                             projectCode,
+                             from = 0,
+                             readonly,
+                             data
+                         }: {
+    projectCode: number
+    from?: number
+    readonly?: boolean
+    data?: ITaskData
+}) {
+    const model = reactive({
+        name: '',
+        taskType: 'DINKY',
+        flag: 'YES',
+        description: '',
+        timeoutFlag: false,
+        localParams: [],
+        environmentCode: null,
+        failRetryInterval: 1,
+        failRetryTimes: 0,
+        workerGroup: 'default',
+        delayTime: 0,
+        timeout: 30","[{'comment': ""Here should set the timeoutNotifyStrategy default value to ['WARN'].\r\nplx check this #10259 ."", 'commenter': 'Amy0104'}, {'comment': 'Hi. I have changed the code.', 'commenter': 'aiwenmo'}]"
10640,docs/docs/en/guide/task/dinky.md,"@@ -0,0 +1,36 @@
+# Dinky
+
+## Overview
+
+Use `Dinky Task` to create a dinky-type task and support one-stop development, debugging, operation and maintenance of FlinkSql, Flink jar and SQL. When the worker executes `Dinky Task`,
+it will call `Dinky API` to trigger dinky task. Click [here](http://www.dlink.top/) for details about `Dinky`.
+
+## Create Task
+
+- Click Project Management-Project Name-Workflow Definition, and click the ""Create Workflow"" button to enter the DAG editing page.
+- Drag <img src=""../../../../img/tasks/icons/dinky.png"" width=""15""/> from the toolbar to the canvas.
+
+## Task Parameter
+
+- Node name: The node name in a workflow definition is unique.
+- Run flag: Identifies whether this node can be scheduled normally, if it does not need to be executed, you can turn on the prohibition switch.
+- Descriptive information: Describe the function of the node.
+- Task priority: When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order.
+- Worker grouping: Assign tasks to the machines of the worker group to execute. If `Default` is selected, randomly select a worker machine for execution.
+- Number of failed retry attempts: The failure task resubmitting times. It supports drop-down and hand-filling.
+- Failed retry interval: The time interval for resubmitting the task after a failed task. It supports drop-down and hand-filling.
+- Timeout alarm: Check the timeout alarm and timeout failure. When the task exceeds the ""timeout period"", an alarm email will send and the task execution will fail.
+- Dinky Address: The url for a dinky server.
+- Dinky Task ID: The unique task id for a dinky task.
+- Online Task: Specify whether the current dinky job is online. If yes, the submitted job can only be submitted successfully when it is published and there is no corresponding Flink job instance running.","[{'comment': 'currently, all our English version tasks parameters convert from list style to table format style, which you can see example in https://github.com/apache/dolphinscheduler/blob/dev/docs/docs/en/guide/task/shell.md.  So please change to a table format in English version of docs. And it is up to you whether change Chinese version of docs', 'commenter': 'zhongjiajie'}]"
10653,deploy/kubernetes/dolphinscheduler/templates/deployment-dolphinscheduler-api.yaml,"@@ -62,6 +62,8 @@ spec:
           ports:
             - containerPort: 12345
               name: ""api-port""
+            - containerPort: 25333
+                name: ""python-api-port""","[{'comment': '```suggestion\r\n              name: ""python-api-port""\r\n```', 'commenter': 'zhongjiajie'}]"
10653,deploy/kubernetes/dolphinscheduler/templates/svc-dolphinscheduler-api.yaml,"@@ -40,6 +40,13 @@ spec:
       {{- end }}
       protocol: TCP
       name: api-port
+    - port: 25333
+      targetPort: python-api-port
+      { { - if and (eq .Values.api.service.type ""NodePort"") .Values.api.service.nodePort } }","[{'comment': '`{ {` is wrong in Helm Chart syntax, please remove the space between the 2 `{`', 'commenter': 'kezhenxu94'}, {'comment': '> `{ {` is wrong in Helm Chart syntax, please remove the space between the 2 `{`\r\n\r\nDone', 'commenter': 'lyleshaw'}]"
10653,deploy/kubernetes/dolphinscheduler/templates/svc-dolphinscheduler-api.yaml,"@@ -42,9 +42,9 @@ spec:
       name: api-port
     - port: 25333
       targetPort: python-api-port
-      { { - if and (eq .Values.api.service.type ""NodePort"") .Values.api.service.nodePort } }
-      nodePort: { { .Values.api.service.nodePort } }
-      { { - end } }
+      {{ - if and (eq .Values.api.service.type ""NodePort"") .Values.api.service.nodePort }}","[{'comment': 'Sorry I missed this, the space between `{{` and `-` should be removed too', 'commenter': 'kezhenxu94'}, {'comment': '> Sorry I missed this, the space between `{{` and `-` should be removed too\r\n\r\nDone~', 'commenter': 'lyleshaw'}]"
10677,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -1800,6 +1802,17 @@ protected void doBatchOperateProcessDefinition(User loginUser,
                     }
                     processDefinition.setLocations(JSONUtils.toJsonString(jsonNodes));
                 }
+                //copy timing configuration
+                Schedule scheduleObj = scheduleMapper.queryByProcessDefinitionCode(oldProcessDefinitionCode);
+                if (scheduleObj != null) {
+                    scheduleObj.setProcessDefinitionCode(processDefinition.getCode());
+                    scheduleObj.setReleaseState(ReleaseState.OFFLINE);
+                    int insertResult = scheduleMapper.insert(scheduleObj);","[{'comment': 'I think you should set id to 0 before insert', 'commenter': 'caishunfeng'}, {'comment': 'Not necessarily, id will auto increment', 'commenter': 'zhuxt2015'}]"
10677,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -1788,6 +1788,7 @@ private Map<String, Object> checkParams(User loginUser,
         return result;
     }
 
+    @Transactional(rollbackFor = RuntimeException.class)","[{'comment': '`this.doBatchOperateProcessDefinition`  will make the `@Transactional` invalidated, you can hold a reference of ProcessDefinitionServiceImpl and use the reference to call doBatchOperateProcessDefinition.', 'commenter': 'ruanwenjun'}]"
10677,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -1856,6 +1858,19 @@ protected void doBatchOperateProcessDefinition(User loginUser,
                     }
                     processDefinition.setLocations(JSONUtils.toJsonString(jsonNodes));
                 }
+                //copy timing configuration
+                Schedule scheduleObj = scheduleMapper.queryByProcessDefinitionCode(oldProcessDefinitionCode);
+                if (scheduleObj != null) {
+                    scheduleObj.setProcessDefinitionCode(processDefinition.getCode());","[{'comment': 'Please set the processDefinitionName to the new Name.', 'commenter': 'ruanwenjun'}, {'comment': 'Ignore this, I find processDefinitionName is not a column in `t_ds_schedules`.', 'commenter': 'ruanwenjun'}]"
10689,docs/docs/en/guide/task/java.md,"@@ -0,0 +1,67 @@
+# Overview
+
+This node is used to perform java-type tasks and supports the use of single files and jar packages as program entries.
+
+# Create Tasks
+
+- Click on project management-> Project name-> workflow definition, click on the“Create workflow” button, go to the DAG edit page:
+
+- Drag the toolbar's Java task node to the palette.
+
+# Task Parameters
+
+- Node Name: the name of the set task. The node name in a workflow definition is unique.
+","[{'comment': 'please remove the redundant blank line here', 'commenter': 'zhongjiajie'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,docs/docs/en/guide/task/java.md,"@@ -0,0 +1,67 @@
+# Overview
+
+This node is used to perform java-type tasks and supports the use of single files and jar packages as program entries.
+
+# Create Tasks
+
+- Click on project management-> Project name-> workflow definition, click on the“Create workflow” button, go to the DAG edit page:
+
+- Drag the toolbar's Java task node to the palette.
+
+# Task Parameters
+
+- Node Name: the name of the set task. The node name in a workflow definition is unique.
+
+- Run Flag: indicates whether the node is scheduled properly and, if it is not needed, turns on the kill switch.
+
+- Description: describes the functionality of the node.
+
+- Task Priority: when the number of worker threads is insufficient, the worker is executed according to the priority from high to low. When the priority is the same, the worker is executed according to the first in, first out principle.
+
+- Worker Group: The machine whose task is assigned to the Worker group executes, and selecting Default will randomly select a Worker machine to execute.
+
+- Environment Name: configure the environment in which the task runs.
+
+- Number Of Failed Retries: number of resubmitted tasks that failed, supported drop-down and hand-fill.
+
+- Failed Retry Interval: the interval between tasks that fail and are resubmitted, supported by drop-down and hand-fill.
+
+- Delayed Execution Time: the amount of time a task is delayed, in units.
+
+- Timeout Alarm: Check timeout warning, timeout failure, when the task exceeds the“Timeout length”, send a warning message and the task execution fails.
+
+- Module Path: turn on the use of Java 9 + 's modularity feature, put all resources into-module-path, and require that the JDK version in your worker support modularity.
+
+- Main Parameter: as a normal Java program main method entry parameter.
+
+- Java VM Parameters: configure startup virtual machine parameters.
+
+- Script: you need to write Java code if you use the Java run type. The public class must exist in the code without writing a package statement.
+
+- Resources: these can be external JAR packages or other resource files that are added to the Classpath or module path and can be easily retrieved in your JAVA script.
+
+- Custom parameter: a user-defined parameter that is part of HTTP and replaces the contents of the script with the ${ variable } .
+
+- Pre Tasks: selecting a pre-task for the current task sets the selected pre-task upstream of the current task.
+
+## Example
+
+HTTP defines the different methods of interacting with the server, and the four most basic methods are GET, POST, PUT, and DELETE. Here we use the HTTP task node to demonstrate the use of POST to send a request to the system's login page and submit data.
+
+The main configuration parameters are as follows:
+
+- Run Type
+","[{'comment': 'redundant blank line too', 'commenter': 'zhongjiajie'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,docs/docs/zh/guide/task/java.md,"@@ -0,0 +1,50 @@
+# JAVA 节点
+
+## 综述
+
+该节点用于执行 java 类型的任务，支持使用单文件和jar包作为程序入口。
+
+## 创建任务
+
+- 点击项目管理 -> 项目名称 -> 工作流定义，点击”创建工作流”按钮，进入 DAG 编辑页面：
+
+- 拖动工具栏的JAVA任务节点到画板中。
+
+## 任务参数
+
+- 节点名称：设置任务的名称。一个工作流定义中的节点名称是唯一的。
+- 运行标志：标识这个节点是否能正常调度,如果不需要执行，可以打开禁止执行开关。
+- 描述：描述该节点的功能。
+- 任务优先级：worker 线程数不足时，根据优先级从高到低依次执行，优先级一样时根据先进先出原则执行。
+- Worker 分组：任务分配给 worker 组的机器机执行，选择 Default，会随机选择一台 worker 机执行。
+- 环境名称：配置运行任务的环境。
+- 失败重试次数：任务失败重新提交的次数，支持下拉和手填。
+- 失败重试间隔：任务失败重新提交任务的时间间隔，支持下拉和手填。
+- 延迟执行时间：任务延迟执行的时间，以分为单位。
+- 超时告警：勾选超时告警、超时失败，当任务超过""超时时长""后，会发送告警邮件并且任务执行失败。
+- 模块路劲：开启使用JAVA9+的模块化特性，把所有资源放入--module-path中，要求您的worker中的JDK版本支持模块化。
+- 主程序参数：作为普通Java程序main方法入口参数。
+- 虚拟机参数：配置启动虚拟机参数。
+- 脚本：若使用JAVA运行类型则需要编写JAVA代码。代码中必须存在public类，不用写package语句。
+- 资源：可以是外部JAR包也可以是其他资源文件，它们都会被加入到类路径或模块路径中，您可以在自己的JAVA脚本中轻松获取。
+- 自定义参数：是 http 局部的用户自定义参数，会替换脚本中以 ${变量} 的内容。
+- 前置任务：选择当前任务的前置任务，会将被选择的前置任务设置为当前任务的上游。
+
+## 任务样例
+
+HTTP 定义了与服务器交互的不同方法，最基本的方法有4种，分别是GET，POST，PUT，DELETE。这里我们使用 http 任务节点，演示使用 POST 向系统的登录页面发送请求，提交数据。
+
+主要配置参数如下：
+
+- 运行类型
+- 模块路径
+- 主程序参数
+- 虚拟机参数
+- 脚本文件
+
+![java_task](../../../../img/tasks/demo/java_task01.png)","[{'comment': 'both English and Chinese documents should use the English version screenshot', 'commenter': 'zhongjiajie'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,docs/docs/en/guide/task/java.md,"@@ -0,0 +1,67 @@
+# Overview
+
+This node is used to perform java-type tasks and supports the use of single files and jar packages as program entries.
+
+# Create Tasks
+
+- Click on project management-> Project name-> workflow definition, click on the“Create workflow” button, go to the DAG edit page:
+
+- Drag the toolbar's Java task node to the palette.
+
+# Task Parameters
+
+- Node Name: the name of the set task. The node name in a workflow definition is unique.
+
+- Run Flag: indicates whether the node is scheduled properly and, if it is not needed, turns on the kill switch.
+
+- Description: describes the functionality of the node.
+
+- Task Priority: when the number of worker threads is insufficient, the worker is executed according to the priority from high to low. When the priority is the same, the worker is executed according to the first in, first out principle.
+
+- Worker Group: The machine whose task is assigned to the Worker group executes, and selecting Default will randomly select a Worker machine to execute.
+
+- Environment Name: configure the environment in which the task runs.
+
+- Number Of Failed Retries: number of resubmitted tasks that failed, supported drop-down and hand-fill.
+
+- Failed Retry Interval: the interval between tasks that fail and are resubmitted, supported by drop-down and hand-fill.
+
+- Delayed Execution Time: the amount of time a task is delayed, in units.
+
+- Timeout Alarm: Check timeout warning, timeout failure, when the task exceeds the“Timeout length”, send a warning message and the task execution fails.
+
+- Module Path: turn on the use of Java 9 + 's modularity feature, put all resources into-module-path, and require that the JDK version in your worker support modularity.
+
+- Main Parameter: as a normal Java program main method entry parameter.
+
+- Java VM Parameters: configure startup virtual machine parameters.
+
+- Script: you need to write Java code if you use the Java run type. The public class must exist in the code without writing a package statement.
+
+- Resources: these can be external JAR packages or other resource files that are added to the Classpath or module path and can be easily retrieved in your JAVA script.
+
+- Custom parameter: a user-defined parameter that is part of HTTP and replaces the contents of the script with the ${ variable } .
+
+- Pre Tasks: selecting a pre-task for the current task sets the selected pre-task upstream of the current task.
+
+## Example
+
+HTTP defines the different methods of interacting with the server, and the four most basic methods are GET, POST, PUT, and DELETE. Here we use the HTTP task node to demonstrate the use of POST to send a request to the system's login page and submit data.
+
+The main configuration parameters are as follows:
+
+- Run Type
+
+- Module Path
+
+- Main Parameters
+
+- Java VM Parameters
+
+- Script 
+
+![java_task](../../../../img/tasks/demo/java_task02.png)
+
+## Notice","[{'comment': '```suggestion\r\n## Note\r\n```', 'commenter': 'zhongjiajie'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-ui/src/locales/en_US/project.ts,"@@ -126,7 +126,6 @@ export default {
     switch_version: 'Switch To This Version',
     confirm_switch_version: 'Confirm Switch To This Version?',
     current_version: 'Current Version',
-    run_type: 'Run Type',","[{'comment': ""The 'run_type' can not be removed, because it is used in workflow instance column."", 'commenter': 'Amy0104'}, {'comment': ""> The 'run_type' can not be removed, because it is used in workflow instance column.\r\n\r\nthank you. maybe I deleted it by mistake."", 'commenter': '106umao'}]"
10689,dolphinscheduler-ui/src/locales/zh_CN/project.ts,"@@ -284,6 +284,10 @@ export default {
     online: '已上线'
   },
   node: {
+    is_module_path: '模块路劲',
+    run_type: '运行类型',
+    jvm_args: '虚拟机参数',
+    jvm_args_tips: '请输入虚拟机参数',","[{'comment': 'It is better to keep these keys the same position as en_US.', 'commenter': 'Amy0104'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/model/TaskResponse.java,"@@ -123,4 +123,18 @@ public TaskRunStatus getStatus() {
     public void setStatus(TaskRunStatus status) {
         this.status = status;
     }
+
+    @Override
+    public String toString() {
+        return ""TaskResponse{"" +
+                ""varPool='"" + varPool + '\'' +
+                "", processId="" + processId +
+                "", resultString='"" + resultString + '\'' +
+                "", appIds='"" + appIds + '\'' +
+                "", process="" + process +
+                "", cancel="" + cancel +
+                "", exitStatusCode="" + exitStatusCode +
+                "", status="" + status +
+                '}';
+    }","[{'comment': 'Please use `@ToString` annotation (or even `@Data` annotation and remove the `getter/setter`) from lombok ', 'commenter': 'kezhenxu94'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-task-plugin/dolphinscheduler-task-java/src/main/java/org/apache/dolphinscheduler/plugin/task/java/JavaConstants.java,"@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.java;
+
+public class JavaConstants {
+
+    private JavaConstants() {
+        throw new IllegalStateException(""Utility class"");
+    }
+
+    public static final String JAVA_HOME = ""JAVA_HOME"";
+
+
+    public static final String RUN_TYPE_JAVA = ""JAVA"";
+    public static final String RUN_TYPE_JAR = ""JAR"";
+
+//    to be extended.
+//    public static final String RUN_TYPE_JSHELL = ""JSHELL"";
+//    public static final String RUN_TYPE_INJVM = ""INJVM"";
+
+
+","[{'comment': ""Do put these commented codes here if you don't plan to implement in this PR, create an issue to track the todo tasks"", 'commenter': 'kezhenxu94'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-task-plugin/dolphinscheduler-task-java/src/main/java/org/apache/dolphinscheduler/plugin/task/java/JavaParameters.java,"@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.java;
+
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+
+import java.util.List;
+
+public class JavaParameters extends AbstractParameters {
+    /**
+     * origin java script
+     */
+    private String rawScript;
+
+    private ResourceInfo mainJar;
+
+    private String runType;
+
+    private String mainArgs;
+
+    private String jvmArgs;
+    private boolean isModulePath;
+
+
+    public boolean isModulePath() {
+        return isModulePath;
+    }
+
+    public void setModulePath(boolean modulePath) {
+        isModulePath = modulePath;
+    }
+
+
+
+    /**
+     * resource list
+     */
+    private List<ResourceInfo> resourceList;
+
+    public String getRawScript() {","[{'comment': 'Use `@Getter/@Setter` annotations from lombok', 'commenter': 'kezhenxu94'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-java-task-main-jar.ts,"@@ -0,0 +1,80 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import { computed, ref, onMounted, watch } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { queryResourceByProgramType } from '@/service/modules/resources'
+import { useTaskNodeStore } from '@/store/project/task-node'
+import utils from '@/utils'
+import type { IJsonItem, ProgramType, IMainJar } from '../types'
+
+export function useJavaTaskMainJar(model: { [field: string]: any }): IJsonItem {
+  const { t } = useI18n()
+  const mainJarOptions = ref([] as IMainJar[])
+  const taskStore = useTaskNodeStore()
+
+  const mainJarSpan = computed(() => (model.runType === 'JAVA' ? 0 : 24))
+  const getMainJars = async (programType: ProgramType) => {
+    const storeMainJar = taskStore.getMainJar(programType)
+    if (storeMainJar) {
+      mainJarOptions.value = storeMainJar
+      return
+    }
+    const res = await queryResourceByProgramType({
+      type: 'FILE',
+      programType
+    })
+    utils.removeUselessChildren(res)
+    mainJarOptions.value = res || []
+    taskStore.updateMainJar(programType, res)
+  }
+
+  onMounted(() => {
+    getMainJars(model.programType)
+  })
+
+  watch(
+    () => model.programType,
+    (value) => {
+        getMainJars(value)
+    }
+  )
+
+  return {
+    type: 'tree-select',
+    field: 'mainJar',
+    name: t('project.node.main_package'),
+    span: mainJarSpan,
+    props: {
+      cascade: true,
+      showPath: true,
+      checkStrategy: 'child',
+      placeholder: t('project.node.main_package_tips'),
+      keyField: 'id',
+      labelField: 'fullName'
+    },
+    validate: {
+      trigger: ['input', 'blur'],
+      required: true,
+      validator(validate: any, value: string) {
+        if (!value) {
+          return new Error(t('project.node.main_package_tips'))
+        }
+      }
+    },
+    options: mainJarOptions
+  }
+}","[{'comment': 'It seems that this hook is not used at all.', 'commenter': 'Amy0104'}, {'comment': 'thx, changes have been made to make Java tasks better code-isolated from other tasks', 'commenter': '106umao'}]"
10689,dolphinscheduler-ui/src/views/projects/task/components/node/format-data.ts,"@@ -35,6 +35,19 @@ export function formatParams(data: INodeData): {
   if (data.taskType === 'SUB_PROCESS') {
     taskParams.processDefinitionCode = data.processDefinitionCode
   }
+
+  if(data.taskType === 'JAVA'){
+    taskParams.runType = data.runType
+    taskParams.mainArgs = data.mainArgs
+    taskParams.jvmArgs = data.jvmArgs
+    taskParams.isModulePath = data.isModulePath
+    if(data.runType === 'JAR'){
+      if (data.mainJar) {
+        taskParams.mainJar = { id: data.mainJar }
+      }
+    }","[{'comment': 'it is better to change the two conditions into one parallel condition.', 'commenter': 'Amy0104'}, {'comment': 'thx, it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-java.ts,"@@ -0,0 +1,98 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+import { computed } from 'vue'
+import { useI18n } from 'vue-i18n'
+import { useCustomParams, useResources ,useMainJar} from '.'
+import type { IJsonItem } from '../types'
+
+export function useJava(model: { [field: string]: any }): IJsonItem[] {
+  const { t } = useI18n()
+  const rawScriptSpan = computed(() => (model.runType === 'JAR' ? 0 : 24))
+  return [
+    {
+        type: 'select',
+        field: 'runType',
+        span: 12,
+        name: t('project.node.run_type'),
+        options: RUN_TYPES,
+        props: {
+          'on-update:value': () => {
+            // if(model.runType=='JAR'){
+            //     model.rawScript=''
+            // }else{
+            //     model.mainJar = null
+            //     model.rawScript=''
+            // }
+          }","[{'comment': 'It is better to remove the comment code.', 'commenter': 'Amy0104'}, {'comment': 'thx,it is done', 'commenter': '106umao'}]"
10689,dolphinscheduler-task-plugin/dolphinscheduler-task-java/src/main/test/org/apache/dolphinscheduler/plugin/task/java/JavaTaskTest.java,"@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.java;
+
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.junit.Assert;
+import org.junit.Test;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.ArrayList;
+import static org.apache.dolphinscheduler.plugin.task.api.enums.DataType.VARCHAR;
+import static org.apache.dolphinscheduler.plugin.task.api.enums.Direct.IN;
+import static org.apache.dolphinscheduler.plugin.task.java.JavaConstants.RUN_TYPE_JAR;
+import static org.apache.dolphinscheduler.plugin.task.java.JavaConstants.RUN_TYPE_JAVA;
+import java.io.IOException;
+public class JavaTaskTest {
+    @Test
+    public void testJavaHome() {
+        Assert.assertNotNull(System.getenv().get(""JAVA_HOME""));
+    }
+
+
+    @Test
+    public void buildJarCommand() {
+        String homePath = System.getenv(JavaConstants.JAVA_HOME);
+        Assert.assertNotNull(homePath);
+        String homeBinPath =  homePath+ System.getProperty(""file.separator"") + ""bin"" + System.getProperty(""file.separator"");
+        JavaTask javaTask = runJarType();
+        Assert.assertEquals(javaTask.buildJarCommand(), homeBinPath
+                +""java --class-path .:/tmp/dolphinscheduler/test/executepath:/tmp/dolphinscheduler/test/executepath/opt/share/jar/resource2.jar -jar /tmp/dolphinscheduler/test/executepath/opt/share/jar/main.jar -host 127.0.0.1 -port 8080 -xms:50m"");
+    }
+
+    @Test
+    public void buildJavaCompileCommand() throws IOException {
+        JavaTask javaTask = runJavaType();
+        String sourceCode = javaTask.buildJavaSourceContent();
+        String publicClassName = javaTask.getPublicClassName(sourceCode);
+        Assert.assertEquals(""JavaTaskTest"", publicClassName);
+        String fileName = javaTask.buildJavaSourceCodeFileFullName(publicClassName);
+        try {
+            String homePath = System.getenv(JavaConstants.JAVA_HOME);
+            Assert.assertNotNull(homePath);
+            String homeBinPath = homePath + System.getProperty(""file.separator"") + ""bin"" + System.getProperty(""file.separator"");
+            Path path = Paths.get(fileName);
+            if (Files.exists(path)) {
+                Files.delete(path);
+            }
+            javaTask.createJavaSourceFileIfNotExists(sourceCode, fileName);
+            Assert.assertEquals(homeBinPath
+                    +""javac --class-path .:/tmp/dolphinscheduler/test/executepath:/tmp/dolphinscheduler/test/executepath/opt/share/jar/resource2.jar /tmp/dolphinscheduler/test/executepath/JavaTaskTest.java"", javaTask.buildJavaCompileCommand(fileName, sourceCode));
+
+        } finally {
+            Path path = Paths.get(fileName);
+            if (Files.exists(path)) {
+                Files.delete(path);
+            }
+        }
+
+    }
+
+
+    @Test
+    public void buildJavaCommand() throws Exception {
+        String homePath = System.getenv(JavaConstants.JAVA_HOME);
+        Assert.assertNotNull(homePath);
+        String homeBinPath =  homePath+ System.getProperty(""file.separator"") + ""bin"" + System.getProperty(""file.separator"");
+        JavaTask javaTask = runJavaType();
+        String sourceCode = javaTask.buildJavaSourceContent();
+        String publicClassName = javaTask.getPublicClassName(sourceCode);
+        Assert.assertEquals(""JavaTaskTest"", publicClassName);
+        String fileName = javaTask.buildJavaSourceCodeFileFullName(publicClassName);
+        Path path = Paths.get(fileName);
+        if (Files.exists(path)) {
+            Files.delete(path);
+        }
+        Assert.assertEquals(javaTask.buildJavaCommand(), homeBinPath + ""java --class-path .:/tmp/dolphinscheduler/test/executepath:/tmp/dolphinscheduler/test/executepath/opt/share/jar/resource2.jar JavaTaskTest -host 127.0.0.1 -port 8080 -xms:50m"");
+    }
+
+    public JavaParameters createJavaParametersObject(String runType) {
+        JavaParameters javaParameters = new JavaParameters();
+        javaParameters.setRunType(runType);
+        javaParameters.setModulePath(false);
+        javaParameters.setJvmArgs(""-xms:50m"");
+        javaParameters.setMainArgs(""-host 127.0.0.1 -port 8080"");
+        ResourceInfo resourceJar = new ResourceInfo();
+        resourceJar.setId(2);
+        resourceJar.setResourceName(""/opt/share/jar/resource2.jar"");
+        resourceJar.setRes(""I'm resource2.jar"");
+        ArrayList<ResourceInfo> resourceInfoArrayList = new ArrayList<>();
+        resourceInfoArrayList.add(resourceJar);
+        javaParameters.setResourceList(resourceInfoArrayList);
+        javaParameters.setRawScript(
+                        ""import java.io.IOException;\n"" +
+                        ""public class JavaTaskTest {\n"" +
+                        ""    public static void main(String[] args) throws IOException {\n"" +
+                        ""        StringBuilder builder = new StringBuilder(\""Hello: \"");\n"" +
+                        ""        for (String arg : args) {\n"" +
+                        ""            builder.append(arg).append(\"" \"");\n"" +
+                        ""        }\n"" +
+                        ""        System.out.println(builder);\n"" +
+                        ""    }\n"" +
+                        ""}\n"");
+        ArrayList<Property> localParams = new ArrayList<>();
+        Property property = new Property();
+        property.setProp(""name"");
+        property.setValue(""zhangsan"");
+        property.setDirect(IN);
+        property.setType(VARCHAR);
+        javaParameters.setLocalParams(localParams);
+//        javaParameters.setVarPool("""");","[{'comment': 'We should remove meaningless code.', 'commenter': 'SbloodyS'}, {'comment': 'thx, it is done .', 'commenter': '106umao'}]"
10689,dolphinscheduler-task-plugin/dolphinscheduler-task-java/src/main/java/org/apache/dolphinscheduler/plugin/task/java/JavaTask.java,"@@ -0,0 +1,343 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.java;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.ShellCommandExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.plugin.task.api.model.TaskResponse;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.plugin.task.java.exception.JavaSourceFileExistException;
+import org.apache.dolphinscheduler.plugin.task.java.exception.PublicClassNotFoundException;
+import org.apache.dolphinscheduler.plugin.task.java.exception.RunTypeNotFoundException;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.commons.lang3.SystemUtils;
+
+import java.io.File;
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.Paths;
+import java.util.HashMap;
+import java.util.Map;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import com.google.common.base.Preconditions;
+
+/**
+ * java task
+ */
+public class JavaTask extends AbstractTaskExecutor {
+
+    /**
+     * java parameters
+     */
+    private JavaParameters javaParameters;
+
+    /**
+     * shell command executor
+     */
+    private ShellCommandExecutor shellCommandExecutor;
+
+    private TaskExecutionContext taskRequest;
+
+    /**
+     * constructor
+     *
+     * @param taskRequest taskRequest
+     */
+    public JavaTask(TaskExecutionContext taskRequest) {
+        super(taskRequest);
+        this.taskRequest = taskRequest;
+        this.shellCommandExecutor = new ShellCommandExecutor(this::logHandle,
+                taskRequest,
+                logger);
+    }
+
+    @Override
+    public void init() {
+        logger.info(""java task params {}"", taskRequest.getTaskParams());
+        javaParameters = JSONUtils.parseObject(taskRequest.getTaskParams(), JavaParameters.class);
+        if (javaParameters == null || !javaParameters.checkParameters()) {
+            throw new TaskException(""java task params is not valid"");
+        }
+        if (javaParameters.getRunType().equals(JavaConstants.RUN_TYPE_JAR)) {
+            setMainJarName();
+        }
+    }
+
+    @Override
+    public String getPreScript() {
+        String rawJavaScript = javaParameters.getRawScript().replaceAll(""\\r\\n"", ""\n"");
+        try {
+            rawJavaScript = convertJavaSourceCodePlaceholders(rawJavaScript);
+        } catch (StringIndexOutOfBoundsException e) {
+            logger.error(""setShareVar field format error, raw java script : {}"", rawJavaScript);
+        }
+        return rawJavaScript;
+    }
+
+    @Override
+    public void handle() throws Exception {
+        try {
+            // Step 1 judge if is java or jar run type.
+            // The  jar run type builds the command directly, adding resource to the java -jar class when building the command
+            // The java run type, first replace the custom parameters, then compile the code, and then build the command will add resource
+            // To run the coma
+            String command = null;
+            switch (javaParameters.getRunType()) {
+                case JavaConstants.RUN_TYPE_JAVA:
+                    command = buildJavaCommand();
+                    break;
+                case JavaConstants.RUN_TYPE_JAR:
+                    command = buildJarCommand();
+                    break;
+                default:
+                    throw new RunTypeNotFoundException(""run type is required, but it is null now."");
+            }
+            Preconditions.checkNotNull(command, ""command not be null."");
+            TaskResponse taskResponse = shellCommandExecutor.run(command);
+            logger.info(""java task run result : "" + taskResponse);
+            setExitStatusCode(taskResponse.getExitStatusCode());
+            setAppIds(taskResponse.getAppIds());
+            setProcessId(taskResponse.getProcessId());
+            setVarPool(shellCommandExecutor.getVarPool());
+        } catch (InterruptedException e) {
+            logger.error(""java task interrupted "", e);
+            setExitStatusCode(TaskConstants.EXIT_CODE_FAILURE);
+            Thread.currentThread().interrupt();
+        } catch (Exception e) {
+            logger.error(""java task failed "", e);
+            setExitStatusCode(TaskConstants.EXIT_CODE_FAILURE);
+            throw new TaskException(""run java task error"", e);
+        }
+    }
+
+    protected String buildJavaCommand() throws Exception {
+        String sourceCode = buildJavaSourceContent();
+        String className = compilerRawScript(sourceCode);
+        StringBuilder builder = new StringBuilder();
+        builder.append(getJavaHomeBinAbsolutePath())
+                .append(""java"").append("" "")
+                .append(buildResourcePath())
+                .append("" "")
+                .append(className).append("" "")
+                .append(javaParameters.getMainArgs().trim()).append("" "")
+                .append(javaParameters.getJvmArgs().trim());
+        return builder.toString();
+    }
+
+    private void setMainJarName() {
+        ResourceInfo mainJar = javaParameters.getMainJar();
+        String resourceName = getResourceNameOfMainJar(mainJar);
+        mainJar.setRes(resourceName);
+        javaParameters.setMainJar(mainJar);
+    }
+
+    private String getResourceNameOfMainJar(ResourceInfo mainJar) {
+        if (null == mainJar) {
+            throw new RuntimeException(""The jar for the task is required."");
+        }
+
+        return mainJar.getId() == 0
+                ? mainJar.getRes()
+                // when update resource maybe has error
+                : mainJar.getResourceName().replaceFirst(""/"", """");
+    }
+
+    protected String buildJarCommand() {
+        String fullName = javaParameters.getMainJar().getResourceName();
+        String mainJarName = fullName.substring(0, fullName.lastIndexOf('.'));
+        mainJarName = mainJarName.substring(mainJarName.lastIndexOf('.') + 1) + "".jar"";
+        StringBuilder builder = new StringBuilder();
+        builder.append(getJavaHomeBinAbsolutePath())
+                .append(""java"").append("" "")
+                .append(buildResourcePath()).append("" "")
+                .append(""-jar"").append("" "")
+                .append(taskRequest.getExecutePath())
+                .append(mainJarName).append("" "")
+                .append(javaParameters.getMainArgs().trim()).append("" "")
+                .append(javaParameters.getJvmArgs().trim());
+        return builder.toString();
+    }
+    
+    @Override
+    public void cancelApplication(boolean cancelApplication) throws Exception {
+        // cancel process
+        shellCommandExecutor.cancelApplication();
+    }
+
+    @Override
+    public AbstractParameters getParameters() {
+        return javaParameters;
+    }
+
+    /**
+     * convertJavaScriptPlaceholders
+     *
+     * @param rawScript rawScript
+     * @return String
+     * @throws StringIndexOutOfBoundsException StringIndexOutOfBoundsException
+     */
+    protected static String convertJavaSourceCodePlaceholders(String rawScript) throws StringIndexOutOfBoundsException {
+        int len = ""${setShareVar(${"".length();
+        int scriptStart = 0;
+        while ((scriptStart = rawScript.indexOf(""${setShareVar(${"", scriptStart)) != -1) {
+            int start = -1;
+            int end = rawScript.indexOf('}', scriptStart + len);
+            String prop = rawScript.substring(scriptStart + len, end);
+
+            start = rawScript.indexOf(',', end);
+            end = rawScript.indexOf(')', start);
+
+            String value = rawScript.substring(start + 1, end);
+
+            start = rawScript.indexOf('}', start) + 1;
+            end = rawScript.length();
+
+            String replaceScript = String.format(""print(\""${{setValue({},{})}}\"".format(\""%s\"",%s))"", prop, value);
+
+            rawScript = rawScript.substring(0, scriptStart) + replaceScript + rawScript.substring(start, end);
+
+            scriptStart += replaceScript.length();
+        }
+        return rawScript;
+    }
+
+    protected void createJavaSourceFileIfNotExists(String sourceCode, String fileName) throws IOException {
+        logger.info(""tenantCode :{}, task dir:{}"", taskRequest.getTenantCode(), taskRequest.getExecutePath());
+
+        if (!Files.exists(Paths.get(fileName))) {
+            logger.info(""generate java source file:{}"", fileName);
+
+            StringBuilder sb = new StringBuilder();
+            sb.append(sourceCode);
+            logger.info(sb.toString());
+
+            // write data to file
+            FileUtils.writeStringToFile(new File(fileName),
+                    sb.toString(),
+                    StandardCharsets.UTF_8);
+        } else {
+            throw new JavaSourceFileExistException(""java source file exists, please report an issue on official."");
+        }
+    }
+
+    protected String buildJavaSourceCodeFileFullName(String publicClassName) {
+        return String.format(JavaConstants.JAVA_SOURCE_CODE_NAME_TEMPLATE, taskRequest.getExecutePath(), publicClassName);
+    }
+
+    protected String buildResourcePath() {
+        StringBuilder builder = new StringBuilder();
+        if (javaParameters.isModulePath()) {
+            builder.append(""--module-path"");
+        } else {
+            builder.append(""--class-path"");
+        }
+        builder.append("" "").append(JavaConstants.CLASSPATH_CURRENT_DIR)
+                .append(JavaConstants.PATH_SEPARATOR)
+                .append(taskRequest.getExecutePath());
+        for (ResourceInfo info : javaParameters.getResourceFilesList()) {
+            builder.append(JavaConstants.PATH_SEPARATOR);
+            builder.append(taskRequest.getExecutePath())
+                    .append(info.getResourceName());
+        }
+        return builder.toString();
+    }
+
+    protected String compilerRawScript(String sourceCode) throws IOException, InterruptedException {
+        String publicClassName = getPublicClassName(sourceCode);
+        String fileName =  buildJavaSourceCodeFileFullName(publicClassName);
+        createJavaSourceFileIfNotExists(sourceCode, fileName);
+        String compileCommand = buildJavaCompileCommand(fileName, sourceCode);
+        Preconditions.checkNotNull(compileCommand, ""command not be null."");
+        TaskResponse compileResponse = shellCommandExecutor.run(compileCommand);
+        // must drop the command file ,if do not ,the next command will not run. because be limited the ShellCommandExecutor's create file rules
+        dropShellCommandFile();
+        shellCommandExecutor = new ShellCommandExecutor(this::logHandle,
+                taskRequest,
+                logger);
+        logger.info(""java task code compile result : "" + compileResponse);
+        return publicClassName;
+    }
+
+    private void dropShellCommandFile() throws IOException {
+        String commandFilePath = String.format(""%s/%s.%s""
+                , taskRequest.getExecutePath()
+                , taskRequest.getTaskAppId()
+                , SystemUtils.IS_OS_WINDOWS ? ""bat"" : ""command"");
+        Path path = Paths.get(commandFilePath);
+        if (Files.exists(path)) {
+            Files.delete(path);
+        }
+    }
+
+    protected String buildJavaCompileCommand(String fileName, String sourceCode) throws IOException {
+
+        StringBuilder compilerCommand = new StringBuilder()
+                .append(getJavaHomeBinAbsolutePath())
+                .append(""javac"").append("" "")
+                .append(buildResourcePath()).append("" "")
+                .append(fileName);
+        return compilerCommand.toString();
+    }
+
+    protected String buildJavaSourceContent() {
+        String rawJavaScript = javaParameters.getRawScript().replaceAll(""\\r\\n"", ""\n"");
+        // replace placeholder
+
+        Map<String, Property> paramsMap = taskRequest.getPrepareParamsMap();
+        if (MapUtils.isEmpty(paramsMap)) {
+            paramsMap = new HashMap<>();
+        }
+        if (MapUtils.isNotEmpty(taskRequest.getParamsMap())) {
+            paramsMap.putAll(taskRequest.getParamsMap());
+        }
+        rawJavaScript = ParameterUtils.convertParameterPlaceholders(rawJavaScript, ParamUtils.convert(paramsMap));
+        logger.info(""raw java script : {}"", javaParameters.getRawScript());
+        return rawJavaScript;
+    }
+
+    private String getJavaHomeBinAbsolutePath() {
+        String javaHomeAbsolutePath = System.getenv(JavaConstants.JAVA_HOME);
+        Preconditions.checkNotNull(javaHomeAbsolutePath, ""not find the java home in the version. "");
+        return javaHomeAbsolutePath + System.getProperty(""file.separator"") + ""bin"" + System.getProperty(""file.separator"");
+    }
+
+    public String getPublicClassName(String sourceCode) {
+        String pattern = ""(.*\\s+public\\s+class\\s+)([a-zA-Z_]+[//w_]*)([.\\s\\S]*)"";
+        Pattern compile = Pattern.compile(pattern);","[{'comment': 'I think should cache regex pattern to improve performance, its performance matters.', 'commenter': 'pinkhello'}, {'comment': 'good idea, have done.', 'commenter': '106umao'}]"
10689,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-main-jar.ts,"@@ -26,7 +26,7 @@ export function useMainJar(model: { [field: string]: any }): IJsonItem {
   const mainJarOptions = ref([] as IMainJar[])
   const taskStore = useTaskNodeStore()
 
-  const mainJarSpan = computed(() => (model.programType === 'SQL' ? 0 : 24))
+  const mainJarSpan = computed(() => (model.programType === 'SQL' ? 0 : 24));","[{'comment': 'No need to modify here.', 'commenter': 'zhuangchong'}, {'comment': 'it is done', 'commenter': '106umao'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {","[{'comment': '```suggestion\r\npublic class CuringGlobalParams implements CuringParamsService {\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'ok.', 'commenter': 'WangJPLeo'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {","[{'comment': 'use constant', 'commenter': 'caishunfeng'}, {'comment': 'ok.', 'commenter': 'WangJPLeo'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);
+        setGlobalParamsMap(taskExecutionContext);
+        Map<String, Property> globalParams = ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams());
+        Map<String,String> globalParamsMap = taskExecutionContext.getDefinedParams();
+        org.apache.dolphinscheduler.spi.enums.CommandType commandType = org.apache.dolphinscheduler.spi.enums.CommandType.of(taskExecutionContext.getCmdTypeIfComplement());","[{'comment': '```suggestion\r\n        CommandType commandType = CommandType.of(taskExecutionContext.getCmdTypeIfComplement());\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'Proven to be replaceable.', 'commenter': 'WangJPLeo'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);
+        setGlobalParamsMap(taskExecutionContext);
+        Map<String, Property> globalParams = ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams());
+        Map<String,String> globalParamsMap = taskExecutionContext.getDefinedParams();
+        org.apache.dolphinscheduler.spi.enums.CommandType commandType = org.apache.dolphinscheduler.spi.enums.CommandType.of(taskExecutionContext.getCmdTypeIfComplement());
+        Date scheduleTime = taskExecutionContext.getScheduleTime();
+
+        // combining local and global parameters
+        Map<String, Property> localParams = parameters.getInputLocalParametersMap();
+
+        //stream pass params
+        Map<String, Property> varParams = parameters.getVarPoolMap();
+
+        if (globalParams.size() == 0 && localParams.size() == 0 && varParams.size() == 0) {
+            return null;
+        }
+        // if it is a complement,
+        // you need to pass in the task instance id to locate the time
+        // of the process instance complement
+        Map<String,String> params = org.apache.dolphinscheduler.plugin.task.api.parser.BusinessTimeUtils
+                .getBusinessTime(commandType,
+                        scheduleTime);
+
+        if (globalParamsMap != null) {
+            params.putAll(globalParamsMap);
+        }
+
+        if (StringUtils.isNotBlank(taskExecutionContext.getExecutePath())) {
+            params.put(PARAMETER_TASK_EXECUTE_PATH, taskExecutionContext.getExecutePath());
+        }
+        params.put(PARAMETER_TASK_INSTANCE_ID, Integer.toString(taskExecutionContext.getTaskInstanceId()));
+
+        if (varParams.size() != 0) {
+            globalParams.putAll(varParams);
+        }
+        if (localParams.size() != 0) {
+            globalParams.putAll(localParams);
+        }
+
+        Iterator<Map.Entry<String, Property>> iter = globalParams.entrySet().iterator();
+        while (iter.hasNext()) {
+            Map.Entry<String, Property> en = iter.next();
+            Property property = en.getValue();
+
+            if (StringUtils.isNotEmpty(property.getValue()) && property.getValue().startsWith(""$"")) {","[{'comment': 'same here', 'commenter': 'caishunfeng'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);
+        setGlobalParamsMap(taskExecutionContext);
+        Map<String, Property> globalParams = ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams());
+        Map<String,String> globalParamsMap = taskExecutionContext.getDefinedParams();
+        org.apache.dolphinscheduler.spi.enums.CommandType commandType = org.apache.dolphinscheduler.spi.enums.CommandType.of(taskExecutionContext.getCmdTypeIfComplement());
+        Date scheduleTime = taskExecutionContext.getScheduleTime();
+
+        // combining local and global parameters
+        Map<String, Property> localParams = parameters.getInputLocalParametersMap();
+
+        //stream pass params
+        Map<String, Property> varParams = parameters.getVarPoolMap();
+
+        if (globalParams.size() == 0 && localParams.size() == 0 && varParams.size() == 0) {
+            return null;
+        }
+        // if it is a complement,
+        // you need to pass in the task instance id to locate the time
+        // of the process instance complement
+        Map<String,String> params = org.apache.dolphinscheduler.plugin.task.api.parser.BusinessTimeUtils
+                .getBusinessTime(commandType,
+                        scheduleTime);
+
+        if (globalParamsMap != null) {
+            params.putAll(globalParamsMap);
+        }
+
+        if (StringUtils.isNotBlank(taskExecutionContext.getExecutePath())) {
+            params.put(PARAMETER_TASK_EXECUTE_PATH, taskExecutionContext.getExecutePath());
+        }
+        params.put(PARAMETER_TASK_INSTANCE_ID, Integer.toString(taskExecutionContext.getTaskInstanceId()));
+
+        if (varParams.size() != 0) {
+            globalParams.putAll(varParams);
+        }
+        if (localParams.size() != 0) {
+            globalParams.putAll(localParams);
+        }
+
+        Iterator<Map.Entry<String, Property>> iter = globalParams.entrySet().iterator();
+        while (iter.hasNext()) {
+            Map.Entry<String, Property> en = iter.next();
+            Property property = en.getValue();
+
+            if (StringUtils.isNotEmpty(property.getValue()) && property.getValue().startsWith(""$"")) {
+                /**
+                 *  local parameter refers to global parameter with the same name
+                 *  note: the global parameters of the process instance here are solidified parameters,
+                 *  and there are no variables in them.
+                 */
+                String val = property.getValue();
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    Map<String, String> cmdParam = JSONUtils.toMap(processInstance.getCommandParam());
+                    val = timeFunctionExtension(taskExecutionContext.getProcessInstanceId(), cmdParam.get(Constants.SCHEDULE_TIMEZONE), val);
+                } else {
+                    val  = org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils.convertParameterPlaceholders(val, params);","[{'comment': '```suggestion\r\n                    val  = ParameterUtils.convertParameterPlaceholders(val, params);\r\n```', 'commenter': 'caishunfeng'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);
+        setGlobalParamsMap(taskExecutionContext);
+        Map<String, Property> globalParams = ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams());
+        Map<String,String> globalParamsMap = taskExecutionContext.getDefinedParams();
+        org.apache.dolphinscheduler.spi.enums.CommandType commandType = org.apache.dolphinscheduler.spi.enums.CommandType.of(taskExecutionContext.getCmdTypeIfComplement());
+        Date scheduleTime = taskExecutionContext.getScheduleTime();
+
+        // combining local and global parameters
+        Map<String, Property> localParams = parameters.getInputLocalParametersMap();
+
+        //stream pass params
+        Map<String, Property> varParams = parameters.getVarPoolMap();
+
+        if (globalParams.size() == 0 && localParams.size() == 0 && varParams.size() == 0) {
+            return null;
+        }
+        // if it is a complement,
+        // you need to pass in the task instance id to locate the time
+        // of the process instance complement
+        Map<String,String> params = org.apache.dolphinscheduler.plugin.task.api.parser.BusinessTimeUtils
+                .getBusinessTime(commandType,
+                        scheduleTime);
+
+        if (globalParamsMap != null) {
+            params.putAll(globalParamsMap);
+        }
+
+        if (StringUtils.isNotBlank(taskExecutionContext.getExecutePath())) {
+            params.put(PARAMETER_TASK_EXECUTE_PATH, taskExecutionContext.getExecutePath());
+        }
+        params.put(PARAMETER_TASK_INSTANCE_ID, Integer.toString(taskExecutionContext.getTaskInstanceId()));
+
+        if (varParams.size() != 0) {
+            globalParams.putAll(varParams);
+        }
+        if (localParams.size() != 0) {
+            globalParams.putAll(localParams);
+        }
+
+        Iterator<Map.Entry<String, Property>> iter = globalParams.entrySet().iterator();
+        while (iter.hasNext()) {
+            Map.Entry<String, Property> en = iter.next();
+            Property property = en.getValue();
+
+            if (StringUtils.isNotEmpty(property.getValue()) && property.getValue().startsWith(""$"")) {
+                /**
+                 *  local parameter refers to global parameter with the same name
+                 *  note: the global parameters of the process instance here are solidified parameters,
+                 *  and there are no variables in them.
+                 */
+                String val = property.getValue();
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    Map<String, String> cmdParam = JSONUtils.toMap(processInstance.getCommandParam());
+                    val = timeFunctionExtension(taskExecutionContext.getProcessInstanceId(), cmdParam.get(Constants.SCHEDULE_TIMEZONE), val);
+                } else {
+                    val  = org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils.convertParameterPlaceholders(val, params);
+                }
+                property.setValue(val);
+            }
+        }
+        if (org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils.isEmpty(globalParams)) {","[{'comment': '```suggestion\r\n        if (MapUtils.isEmpty(globalParams)) {\r\n```', 'commenter': 'caishunfeng'}]"
10704,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parser/ParamUtils.java,"@@ -43,77 +33,81 @@ public class ParamUtils {
     /**
      * parameter conversion
      * Warning:
-     *  When you first invoke the function of convert, the variables of localParams and varPool in the ShellParameters will be modified.
+     *  1.When you first invoke the function of convert, the variables of localParams and varPool in the ShellParameters will be modified.
      *  But in the whole system the variables of localParams and varPool have been used in other functions. I'm not sure if this current
      *  situation is wrong. So I cannot modify the original logic.
      *
+     *  2.Change time: 2022-06-30
+     *  The purpose is for external expansion of local parameters.
+     *  now the method is replaced by the paramParsingPreparation() method of DolphinSchedulerCuringGlobalParams.
+     *
      * @param taskExecutionContext the context of this task instance
      * @param parameters the parameters
      * @return global params
      *
      */
-    public static Map<String, Property> convert(TaskExecutionContext taskExecutionContext, AbstractParameters parameters) {
-        Preconditions.checkNotNull(taskExecutionContext);
-        Preconditions.checkNotNull(parameters);
-        Map<String, Property> globalParams = getUserDefParamsMap(taskExecutionContext.getDefinedParams());
-        Map<String,String> globalParamsMap = taskExecutionContext.getDefinedParams();
-        CommandType commandType = CommandType.of(taskExecutionContext.getCmdTypeIfComplement());
-        Date scheduleTime = taskExecutionContext.getScheduleTime();
-
-        // combining local and global parameters
-        Map<String, Property> localParams = parameters.getInputLocalParametersMap();
-
-        //stream pass params
-        Map<String, Property> varParams = parameters.getVarPoolMap();
-
-        if (globalParams.size() == 0 && localParams.size() == 0 && varParams.size() == 0) {
-            return null;
-        }
-        // if it is a complement,
-        // you need to pass in the task instance id to locate the time
-        // of the process instance complement
-        Map<String,String> params = BusinessTimeUtils
-                .getBusinessTime(commandType,
-                        scheduleTime);
-
-        if (globalParamsMap != null) {
-
-            params.putAll(globalParamsMap);
-        }
-
-        if (StringUtils.isNotBlank(taskExecutionContext.getExecutePath())) {
-            params.put(PARAMETER_TASK_EXECUTE_PATH, taskExecutionContext.getExecutePath());
-        }
-        params.put(PARAMETER_TASK_INSTANCE_ID, Integer.toString(taskExecutionContext.getTaskInstanceId()));
-
-        if (varParams.size() != 0) {
-            globalParams.putAll(varParams);
-        }
-        if (localParams.size() != 0) {
-            globalParams.putAll(localParams);
-        }
-
-        Iterator<Map.Entry<String, Property>> iter = globalParams.entrySet().iterator();
-        while (iter.hasNext()) {
-            Map.Entry<String, Property> en = iter.next();
-            Property property = en.getValue();
-
-            if (StringUtils.isNotEmpty(property.getValue())
-                    && property.getValue().startsWith(""$"")) {
-                /**
-                 *  local parameter refers to global parameter with the same name
-                 *  note: the global parameters of the process instance here are solidified parameters,
-                 *  and there are no variables in them.
-                 */
-                String val = property.getValue();
-
-                val  = ParameterUtils.convertParameterPlaceholders(val, params);
-                property.setValue(val);
-            }
-        }
-
-        return globalParams;
-    }
+//    public static Map<String, Property> convert(TaskExecutionContext taskExecutionContext, AbstractParameters parameters) {","[{'comment': 'remove if no use.', 'commenter': 'caishunfeng'}, {'comment': 'You can delete unused code.', 'commenter': 'lenboo'}]"
10704,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parser/ParameterUtils.java,"@@ -155,54 +151,59 @@ public static void setInParameter(int index, PreparedStatement stmt, DataType da
     /**
      * curing user define parameters
      *
+     * Warning:
+     *      Change time: 2022-06-30
+     *      The purpose is for external expansion of local parameters.
+     *      now the method is replaced by the curingGlobalParams() method of DolphinSchedulerCuringGlobalParams.
+     *
      * @param globalParamMap  global param map
      * @param globalParamList global param list
      * @param commandType     command type
      * @param scheduleTime    schedule time
      * @return curing user define parameters
      */
-    public static String curingGlobalParams(Map<String, String> globalParamMap, List<Property> globalParamList,
-                                            CommandType commandType, Date scheduleTime) {
-
-        if (globalParamList == null || globalParamList.isEmpty()) {
-            return null;
-        }
-
-        Map<String, String> globalMap = new HashMap<>();
-        if (globalParamMap != null) {
-            globalMap.putAll(globalParamMap);
-        }
-        Map<String, String> allParamMap = new HashMap<>();
-        //If it is a complement, a complement time needs to be passed in, according to the task type
-        Map<String, String> timeParams = BusinessTimeUtils
-            .getBusinessTime(commandType, scheduleTime);
-
-        if (timeParams != null) {
-            allParamMap.putAll(timeParams);
-        }
-
-        allParamMap.putAll(globalMap);
-
-        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
-
-        Map<String, String> resolveMap = new HashMap<>();
-        for (Map.Entry<String, String> entry : entries) {
-            String val = entry.getValue();
-            if (val.startsWith(""$"")) {
-                String str = ParameterUtils.convertParameterPlaceholders(val, allParamMap);
-                resolveMap.put(entry.getKey(), str);
-            }
-        }
-        globalMap.putAll(resolveMap);
-
-        for (Property property : globalParamList) {
-            String val = globalMap.get(property.getProp());
-            if (val != null) {
-                property.setValue(val);
-            }
-        }
-        return JSONUtils.toJsonString(globalParamList);
-    }
+//    public static String curingGlobalParams(Map<String, String> globalParamMap, List<Property> globalParamList,","[{'comment': 'same here.', 'commenter': 'caishunfeng'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {","[{'comment': 'please add some comments.', 'commenter': 'caishunfeng'}, {'comment': 'I hope we can add comments and example in the interface, unless the interface is easy to know.', 'commenter': 'ruanwenjun'}]"
10704,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/builder/TaskExecutionContextBuilder.java,"@@ -131,6 +136,13 @@ public TaskExecutionContextBuilder buildK8sTaskRelatedInfo(K8sTaskExecutionConte
         taskExecutionContext.setK8sTaskExecutionContext(k8sTaskExecutionContext);
         return this;
     }
+
+    public TaskExecutionContextBuilder buildParamInfo(CuringParamsService curingParamsService, AbstractParameters baseParam, ProcessInstance processInstance) {
+        Map<String, Property> propertyMap = curingParamsService.paramParsingPreparation(taskExecutionContext, baseParam, processInstance);
+        taskExecutionContext.setPrepareParamsMap(propertyMap);
+        return this;
+    }","[{'comment': ""It's better to calculate the param in the upper layer.\r\n```suggestion\r\n    public TaskExecutionContextBuilder buildParamInfo(Map<String, Property> propertyMap) {\r\n        taskExecutionContext.setPrepareParamsMap(propertyMap);\r\n        return this;\r\n    }\r\n```"", 'commenter': 'ruanwenjun'}]"
10704,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -255,7 +254,7 @@ public WorkflowExecuteRunnable(ProcessInstance processInstance
             , ProcessAlertManager processAlertManager
             , MasterConfig masterConfig
             , StateWheelExecuteThread stateWheelExecuteThread
-            , CuringGlobalParamsService curingGlobalParamsService) {
+            , CuringParamsService curingGlobalParamsService) {","[{'comment': '```suggestion\r\n            , CuringParamsService curingParamsService) {\r\n```', 'commenter': 'ruanwenjun'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);","[{'comment': ""It's better to use `@NonNull` in the method to replace Preconditions.checkNotNull."", 'commenter': 'ruanwenjun'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);
+        setGlobalParamsMap(taskExecutionContext);","[{'comment': 'So this method will affect `taskExecutionContext`, I think this should be note in the comment.', 'commenter': 'ruanwenjun'}]"
10704,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/DolphinSchedulerCuringGlobalParams.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.service.expand;
+
+import com.google.common.base.Preconditions;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CommandType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.ParameterUtils;
+import org.apache.dolphinscheduler.common.utils.placeholder.BusinessTimeUtils;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.utils.MapUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+import java.util.Date;
+import java.util.HashMap;
+import java.util.Iterator;
+import java.util.List;
+import java.util.Map;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_EXECUTE_PATH;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_TASK_INSTANCE_ID;
+
+@Component
+public class DolphinSchedulerCuringGlobalParams implements CuringParamsService {
+
+    private static final Logger logger = LoggerFactory.getLogger(DolphinSchedulerCuringGlobalParams.class);
+
+    @Autowired
+    private TimePlaceholderResolverExpandService timePlaceholderResolverExpandService;
+
+    @Override
+    public String convertParameterPlaceholders(String val, Map<String, String> allParamMap) {
+        return ParameterUtils.convertParameterPlaceholders(val, allParamMap);
+    }
+
+    @Override
+    public boolean timeFunctionNeedExpand(String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionNeedExpand(placeholderName);
+    }
+
+    @Override
+    public String timeFunctionExtension(Integer processInstanceId, String timezone, String placeholderName) {
+        return timePlaceholderResolverExpandService.timeFunctionExtension(processInstanceId, timezone, placeholderName);
+    }
+
+    @Override
+    public String curingGlobalParams(Integer processInstanceId, Map<String, String> globalParamMap, List<Property> globalParamList, CommandType commandType, Date scheduleTime, String timezone) {
+        if (globalParamList == null || globalParamList.isEmpty()) {
+            return null;
+        }
+        Map<String, String> globalMap = new HashMap<>();
+        if (globalParamMap != null) {
+            globalMap.putAll(globalParamMap);
+        }
+        Map<String, String> allParamMap = new HashMap<>();
+        //If it is a complement, a complement time needs to be passed in, according to the task type
+        Map<String, String> timeParams = BusinessTimeUtils.
+                getBusinessTime(commandType, scheduleTime, timezone);
+
+        if (timeParams != null) {
+            allParamMap.putAll(timeParams);
+        }
+        allParamMap.putAll(globalMap);
+        Set<Map.Entry<String, String>> entries = allParamMap.entrySet();
+        Map<String, String> resolveMap = new HashMap<>();
+        for (Map.Entry<String, String> entry : entries) {
+            String val = entry.getValue();
+            if (val.startsWith(""$"")) {
+                String str = """";
+                // whether external scaling calculation is required
+                if (timeFunctionNeedExpand(val)) {
+                    str = timeFunctionExtension(processInstanceId, timezone, val);
+                } else {
+                    str = convertParameterPlaceholders(val, allParamMap);
+                }
+                resolveMap.put(entry.getKey(), str);
+            }
+        }
+        globalMap.putAll(resolveMap);
+        for (Property property : globalParamList) {
+            String val = globalMap.get(property.getProp());
+            if (val != null) {
+                property.setValue(val);
+            }
+        }
+        return JSONUtils.toJsonString(globalParamList);
+    }
+
+    @Override
+    public Map<String, Property> paramParsingPreparation(TaskExecutionContext taskExecutionContext, AbstractParameters parameters, ProcessInstance processInstance) {
+        Preconditions.checkNotNull(taskExecutionContext);
+        Preconditions.checkNotNull(parameters);
+        setGlobalParamsMap(taskExecutionContext);
+        Map<String, Property> globalParams = ParamUtils.getUserDefParamsMap(taskExecutionContext.getDefinedParams());
+        Map<String,String> globalParamsMap = taskExecutionContext.getDefinedParams();
+        org.apache.dolphinscheduler.spi.enums.CommandType commandType = org.apache.dolphinscheduler.spi.enums.CommandType.of(taskExecutionContext.getCmdTypeIfComplement());
+        Date scheduleTime = taskExecutionContext.getScheduleTime();
+
+        // combining local and global parameters
+        Map<String, Property> localParams = parameters.getInputLocalParametersMap();
+
+        //stream pass params
+        Map<String, Property> varParams = parameters.getVarPoolMap();
+
+        if (globalParams.size() == 0 && localParams.size() == 0 && varParams.size() == 0) {","[{'comment': 'Use `isEmpty()` is better than `.size() == 0`', 'commenter': 'ruanwenjun'}]"
10718,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/QueueServiceImpl.java,"@@ -160,7 +160,7 @@ public Map<String, Object> createQueue(User loginUser, String queue, String queu
         queueMapper.insert(queueObj);
         result.put(Constants.DATA_LIST, queueObj);
         putMsg(result, Status.SUCCESS);
-
+        resourcePermissionCheckService.postHandle(AuthorizationType.QUEUE, loginUser.getId(), Collections.singletonList(queueObj.getId()), logger);","[{'comment': 'I have some question:\r\n\r\n1. Why to check resource permission of the new created queue here? \r\n2. If check fail, should the db transaction rollback?', 'commenter': 'caishunfeng'}, {'comment': 'This is a post action,  saving the data permission relationship in the external extension.\r\nWhen an exception occurs, a Runtime exception will be thrown and rolled back.', 'commenter': 'WangJPLeo'}, {'comment': ""But I don't see the @Transactional of this method, is it right?"", 'commenter': 'caishunfeng'}, {'comment': 'Yes I still have this question, do we need to rollback here?', 'commenter': 'ruanwenjun'}, {'comment': 'I think it is needed, including other methods involving data manipulation. This can be used as an optimization item to do an overall transaction investigation later.', 'commenter': 'WangJPLeo'}, {'comment': 'updated checkList. @caishunfeng @ruanwenjun ', 'commenter': 'WangJPLeo'}]"
10718,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -833,4 +833,6 @@ private Constants() {
     public static final int USER_PASSWORD_MIN_LENGTH = 2;
 
     public static final String FUNCTION_START_WITH = ""$"";
+
+    public static final Integer DEFAULT_TENANT_ID = 1;","[{'comment': 'This is a tenant id or user id?', 'commenter': 'ruanwenjun'}, {'comment': 'the default tenant id, which is stored when the database is initialized.', 'commenter': 'WangJPLeo'}, {'comment': ""Ok, but I don't see we have inserted a default tenant into the database."", 'commenter': 'ruanwenjun'}, {'comment': ""Sorry, after I confirm again, the 'DEFAULT_TENANT_ID' constant here is the default queue ID, I will change the variable name."", 'commenter': 'WangJPLeo'}]"
10718,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataSourceServiceImpl.java,"@@ -139,6 +140,8 @@ public Result<Object> createDataSource(User loginUser, BaseDataSourceParamDTO da
         } catch (DuplicateKeyException ex) {
             logger.error(""Create datasource error."", ex);
             putMsg(result, Status.DATASOURCE_EXIST);
+        } catch (RuntimeException e) {
+            throw new RuntimeException(e.getMessage());
         }","[{'comment': ""Please don't hide the exception stack.\r\n```suggestion\r\n        }\r\n```"", 'commenter': 'ruanwenjun'}]"
10718,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -84,6 +84,7 @@ public class WorkerGroupServiceImpl extends BaseServiceImpl implements WorkerGro
      * @return create or update result code
      */
     @Override
+    @Transactional(rollbackFor = Exception.class)","[{'comment': ""Please don't set the rollbackFor, if you set this then this method will only rollback a checked Exception, but you can know this method will not throw a checked Exception, if you want to rollback in all case, you can set rollbackFor = Throwable.class, but in this case ,you need to use rollbackFor = RuntimeException.class, the defailt rollback strategy is RuntimeException and Error, so you don't need to set.\r\n```suggestion\r\n    @Transactional\r\n```"", 'commenter': 'ruanwenjun'}, {'comment': ""yeah, thx for this, 'If no rules are relevant to the exception, it will be treated like DefaultTransactionAttribute (rolling back on runtime exceptions)', without adding properties such as rollbackFor, Spring will roll back when Unchecked Exceptions are encountered, not only RuntimeException, but also Error. I will optimize it later."", 'commenter': 'WangJPLeo'}, {'comment': 'Created an improvement [https://github.com/apache/dolphinscheduler/issues/10791] \r\nTransaction checking and optimization will be handled uniformly in the new pr.  @ruanwenjun ', 'commenter': 'WangJPLeo'}, {'comment': 'Please fix this soon.', 'commenter': 'ruanwenjun'}]"
10727,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessServiceImpl.java,"@@ -1409,8 +1412,14 @@ protected String getSubWorkFlowParam(ProcessInstanceMap instanceMap, ProcessInst
             Map<String, String> parentParam = JSONUtils.toMap(parentProcessInstance.getCommandParam());
             String endTime = parentParam.get(CMDPARAM_COMPLEMENT_DATA_END_DATE);
             String startTime = parentParam.get(CMDPARAM_COMPLEMENT_DATA_START_DATE);
-            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_END_DATE, endTime);
-            cmdParam.put(CMDPARAM_COMPLEMENT_DATA_START_DATE, startTime);
+            String scheduleTime = parentParam.get(CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST);
+            if (StringUtils.isNotEmpty(startTime) && StringUtils.isNotEmpty(startTime)) {","[{'comment': 'Duplicated usage.', 'commenter': 'SbloodyS'}, {'comment': 'ok', 'commenter': 'hstdream'}]"
10727,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -77,33 +84,23 @@
 import org.apache.dolphinscheduler.server.master.runner.task.TaskProcessorFactory;
 import org.apache.dolphinscheduler.service.alert.ProcessAlertManager;
 import org.apache.dolphinscheduler.service.corn.CronUtils;
+import org.apache.dolphinscheduler.service.expand.CuringParamsService;
 import org.apache.dolphinscheduler.service.process.ProcessService;
 import org.apache.dolphinscheduler.service.queue.PeerTaskInstancePriorityQueue;
-
-import org.apache.commons.collections.CollectionUtils;
-import org.apache.commons.lang3.StringUtils;
-import org.apache.commons.lang3.math.NumberUtils;
-
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.Collection;
-import java.util.Date;
-import java.util.HashMap;
-import java.util.HashSet;
-import java.util.Iterator;
-import java.util.List;
-import java.util.Map;
-import java.util.Objects;
-import java.util.Optional;
-import java.util.Set;
-import java.util.concurrent.ConcurrentHashMap;
-import java.util.concurrent.ConcurrentLinkedQueue;
-import java.util.concurrent.atomic.AtomicBoolean;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
-
-import com.google.common.collect.Lists;
+import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_END_DATE;","[{'comment': ""Due to some history problem, we didn't check the code style in ci, You need to revert this import change, your code is breaking the import rule defined in checkstyle.xml."", 'commenter': 'ruanwenjun'}, {'comment': 'ok,reverted.', 'commenter': 'hstdream'}]"
10727,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/corn/CronUtils.java,"@@ -46,14 +26,30 @@
 import java.util.List;
 import java.util.Map;
 
-import org.quartz.CronExpression;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
 import com.cronutils.model.Cron;
 import com.cronutils.model.definition.CronDefinitionBuilder;
 import com.cronutils.parser.CronParser;
 
+import org.apache.commons.collections.CollectionUtils;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.CycleEnum;
+import org.apache.dolphinscheduler.common.thread.Stopper;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.dao.entity.Schedule;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.quartz.CronExpression;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import static com.cronutils.model.CronType.QUARTZ;
+import static org.apache.dolphinscheduler.common.Constants.CMDPARAM_COMPLEMENT_DATA_SCHEDULE_DATE_LIST;
+import static org.apache.dolphinscheduler.common.Constants.COMMA;","[{'comment': 'Please use the correct import order.', 'commenter': 'ruanwenjun'}, {'comment': 'ok,reverted.', 'commenter': 'hstdream'}]"
10731,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-environment-name.ts,"@@ -54,23 +53,20 @@ export function useEnvironmentName(
     return option.workerGroups.indexOf(model.workerGroup) !== -1
   }
 
-  watch(
-    () => options.value.length,
-    () => {
-      if (isCreate && options.value.length === 1 && !value.value) {
-        model.environmentCode = options.value[0].value
-      }
-      if (options.value.length === 0) model.environmentCode = null
-    }
-  )
-
   watch(
     () => model.workerGroup,
     () => {
       if (!model.workerGroup) return
       options.value = environmentList.filter((option: IEnvironmentNameOption) =>
         filterByWorkerGroup(option)
       )
+      // default environmentCode changing when workerGroup changed.
+      // if options only one. set the one as default.
+      if (options.value.length === 1) {
+        model.environmentCode = options.value[0].value
+      } else {
+        model.environmentCode = null
+      }","[{'comment': 'Data playback will get a problem. Such as you have two workerGroups A and B. And then set the workerGroup to B and set the environment to B-2.  Save the task, and reopen you will get the environment to B-1.', 'commenter': 'Amy0104'}, {'comment': 'got it. I will try to fix it later.', 'commenter': 'rockfang'}]"
10731,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-worker-group.ts,"@@ -43,7 +42,8 @@ export function useWorkerGroup(): IJsonItem {
     span: 12,
     name: t('project.node.worker_group'),
     props: {
-      loading: loading
+      loading: loading,
+      'on-update:value': () => (model.environmentCode = null)","[{'comment': 'Setting to null, the environmentCode will not has default value after changing workgroup.', 'commenter': 'Amy0104'}]"
10749,dolphinscheduler-meter/src/main/resources/grafana/DolphinSchedulerWorker.json,"@@ -764,13 +764,398 @@
         ""align"": false
       }
     },
+    {
+      ""datasource"": {
+        ""type"": ""prometheus"",
+        ""uid"": ""PBFA97CFB590B2093""
+      },
+      ""fieldConfig"": {
+        ""defaults"": {
+          ""color"": {
+            ""mode"": ""palette-classic""
+          },
+          ""custom"": {
+            ""axisLabel"": """",
+            ""axisPlacement"": ""auto"",
+            ""barAlignment"": 0,
+            ""drawStyle"": ""line"",
+            ""fillOpacity"": 0,
+            ""gradientMode"": ""none"",
+            ""hideFrom"": {
+              ""legend"": false,
+              ""tooltip"": false,
+              ""viz"": false
+            },
+            ""lineInterpolation"": ""linear"",
+            ""lineWidth"": 1,
+            ""pointSize"": 5,
+            ""scaleDistribution"": {
+              ""type"": ""linear""
+            },
+            ""showPoints"": ""auto"",
+            ""spanNulls"": false,
+            ""stacking"": {
+              ""group"": ""A"",
+              ""mode"": ""none""
+            },
+            ""thresholdsStyle"": {
+              ""mode"": ""off""
+            }
+          },
+          ""mappings"": [],
+          ""thresholds"": {
+            ""mode"": ""absolute"",
+            ""steps"": [
+              {
+                ""color"": ""green"",
+                ""value"": null
+              },
+              {
+                ""color"": ""red"",
+                ""value"": 80
+              }
+            ]
+          }
+        },
+        ""overrides"": []
+      },
+      ""gridPos"": {
+        ""h"": 8,
+        ""w"": 24,
+        ""x"": 0,
+        ""y"": 33
+      },
+      ""id"": 47,
+      ""options"": {
+        ""legend"": {
+          ""calcs"": [],
+          ""displayMode"": ""list"",
+          ""placement"": ""bottom""
+        },
+        ""tooltip"": {
+          ""mode"": ""single"",
+          ""sort"": ""none""
+        }
+      },
+      ""targets"": [
+        {
+          ""datasource"": {
+            ""type"": ""prometheus"",
+            ""uid"": ""PBFA97CFB590B2093""
+          },
+          ""expr"": ""sum(increase(ds_worker_resource_download_count_total{}[5m]))"",
+          ""refId"": ""A""
+        },
+        {
+          ""datasource"": {
+            ""type"": ""prometheus"",
+            ""uid"": ""PBFA97CFB590B2093""
+          },
+          ""expr"": ""sum(increase(ds_worker_resource_download_success_count_total{}[5m]))"",
+          ""hide"": false,
+          ""refId"": ""B""
+        },
+        {
+          ""datasource"": {
+            ""type"": ""prometheus"",
+            ""uid"": ""PBFA97CFB590B2093""
+          },
+          ""expr"": ""sum(increase(ds_worker_resource_download_failure_count_total{}[5m]))"",
+          ""hide"": false,
+          ""refId"": ""C""
+        }
+      ],
+      ""title"": ""Worker Resource Download Count/5m"",
+      ""type"": ""timeseries""
+    },
+    {
+      ""datasource"": {
+        ""type"": ""prometheus"",
+        ""uid"": ""PBFA97CFB590B2093""
+      },
+      ""fieldConfig"": {
+        ""defaults"": {
+          ""color"": {
+            ""mode"": ""palette-classic""
+          },
+          ""custom"": {
+            ""axisLabel"": """",
+            ""axisPlacement"": ""auto"",
+            ""barAlignment"": 0,
+            ""drawStyle"": ""line"",
+            ""fillOpacity"": 0,
+            ""gradientMode"": ""none"",
+            ""hideFrom"": {
+              ""legend"": false,
+              ""tooltip"": false,
+              ""viz"": false
+            },
+            ""lineInterpolation"": ""linear"",
+            ""lineWidth"": 1,
+            ""pointSize"": 5,
+            ""scaleDistribution"": {
+              ""type"": ""linear""
+            },
+            ""showPoints"": ""auto"",
+            ""spanNulls"": false,
+            ""stacking"": {
+              ""group"": ""A"",
+              ""mode"": ""none""
+            },
+            ""thresholdsStyle"": {
+              ""mode"": ""off""
+            }
+          },
+          ""mappings"": [],
+          ""thresholds"": {
+            ""mode"": ""absolute"",
+            ""steps"": [
+              {
+                ""color"": ""green"",
+                ""value"": null
+              },
+              {
+                ""color"": ""red"",
+                ""value"": 80
+              }
+            ]
+          }
+        },
+        ""overrides"": []
+      },
+      ""gridPos"": {
+        ""h"": 8,
+        ""w"": 12,
+        ""x"": 0,
+        ""y"": 41
+      },
+      ""id"": 44,
+      ""options"": {
+        ""legend"": {
+          ""calcs"": [],
+          ""displayMode"": ""list"",
+          ""placement"": ""bottom""
+        },
+        ""tooltip"": {
+          ""mode"": ""single"",
+          ""sort"": ""none""
+        }
+      },
+      ""targets"": [
+        {
+          ""datasource"": {
+            ""type"": ""prometheus"",
+            ""uid"": ""PBFA97CFB590B2093""
+          },
+          ""expr"": ""increase(ds_worker_resource_download_duration_seconds{}[5m])"",
+          ""refId"": ""A""
+        }
+      ],
+      ""title"": ""Worker Resource Download Time/5m"",
+      ""type"": ""timeseries""
+    },
+    {
+      ""datasource"": {
+        ""type"": ""prometheus"",
+        ""uid"": ""PBFA97CFB590B2093""
+      },
+      ""fieldConfig"": {
+        ""defaults"": {
+          ""color"": {
+            ""mode"": ""palette-classic""
+          },
+          ""custom"": {
+            ""axisLabel"": """",
+            ""axisPlacement"": ""auto"",
+            ""barAlignment"": 0,
+            ""drawStyle"": ""line"",
+            ""fillOpacity"": 0,
+            ""gradientMode"": ""none"",
+            ""hideFrom"": {
+              ""legend"": false,
+              ""tooltip"": false,
+              ""viz"": false
+            },
+            ""lineInterpolation"": ""linear"",
+            ""lineWidth"": 1,
+            ""pointSize"": 5,
+            ""scaleDistribution"": {
+              ""type"": ""linear""
+            },
+            ""showPoints"": ""auto"",
+            ""spanNulls"": false,
+            ""stacking"": {
+              ""group"": ""A"",
+              ""mode"": ""none""
+            },
+            ""thresholdsStyle"": {
+              ""mode"": ""off""
+            }
+          },
+          ""mappings"": [],
+          ""thresholds"": {
+            ""mode"": ""absolute"",
+            ""steps"": [
+              {
+                ""color"": ""green"",
+                ""value"": null
+              },
+              {
+                ""color"": ""red"",
+                ""value"": 80
+              }
+            ]
+          }
+        },
+        ""overrides"": []
+      },
+      ""gridPos"": {
+        ""h"": 8,
+        ""w"": 12,
+        ""x"": 12,
+        ""y"": 41
+      },
+      ""id"": 45,
+      ""options"": {
+        ""legend"": {
+          ""calcs"": [],
+          ""displayMode"": ""list"",
+          ""placement"": ""bottom""
+        },
+        ""tooltip"": {
+          ""mode"": ""single"",
+          ""sort"": ""none""
+        }
+      },
+      ""targets"": [
+        {
+          ""datasource"": {
+            ""type"": ""prometheus"",
+            ""uid"": ""PBFA97CFB590B2093""
+          },
+          ""expr"": ""increase(ds_worker_resource_download_size_KB[5m])"",
+          ""refId"": ""A""
+        }
+      ],
+      ""title"": ""Worker Resource Download Size/5m"",
+      ""type"": ""timeseries""
+    },
+    {
+      ""cards"": {},
+      ""color"": {
+        ""cardColor"": ""#b4ff00"",
+        ""colorScale"": ""sqrt"",
+        ""colorScheme"": ""interpolateOranges"",
+        ""exponent"": 0.5,
+        ""mode"": ""spectrum""
+      },
+      ""dataFormat"": ""timeseries"",
+      ""datasource"": {
+        ""type"": ""prometheus"",
+        ""uid"": ""PBFA97CFB590B2093""
+      },
+      ""gridPos"": {
+        ""h"": 8,
+        ""w"": 12,
+        ""x"": 0,
+        ""y"": 49
+      },
+      ""heatmap"": {},
+      ""hideZeroBuckets"": false,
+      ""highlightCards"": true,
+      ""id"": 46,
+      ""legend"": {
+        ""show"": false
+      },
+      ""reverseYBuckets"": false,
+      ""targets"": [
+        {
+          ""datasource"": {
+            ""type"": ""prometheus"",
+            ""uid"": ""PBFA97CFB590B2093""
+          },
+          ""expr"": ""histogram_quantile(0.75, sum(increase(ds_worker_resource_download_size_KB_bucket[5m])) by (le))"",","[{'comment': ""I'm not confident with this one."", 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/FileUtils.java,"@@ -244,4 +244,15 @@ public static boolean directoryTraversal(String filename){
         }
     }
 
+    /**
+     * Get file size in KB
+     *
+     * @param filename String type of filename
+     * @return file size in KB
+     */
+    public static double getFileSizeInKB(String filename){
+        File file = new File(filename);
+        return ((double) file.length()) / 1024;","[{'comment': 'how about add 1024 to constants?', 'commenter': 'zhongjiajie'}, {'comment': 'Sure, thx. Will fix it.', 'commenter': 'EricGao888'}, {'comment': 'You can directly use org.apache.commons.io.FileUtils.ONE_KB', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun `org.apache.commons.io.FileUtils.ONE_KB` is cool! Thx. I will fix it in the next commit.', 'commenter': 'EricGao888'}, {'comment': 'Fixed by the latest commit.', 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/metrics/WorkerServerMetrics.java,"@@ -17,11 +17,10 @@
 
 package org.apache.dolphinscheduler.server.worker.metrics;
 
+import java.util.concurrent.TimeUnit;
 import java.util.function.Supplier;
 
-import io.micrometer.core.instrument.Counter;
-import io.micrometer.core.instrument.Gauge;
-import io.micrometer.core.instrument.Metrics;
+import io.micrometer.core.instrument.*;","[{'comment': 'should avoid add `import *` to our code base', 'commenter': 'zhongjiajie'}, {'comment': 'Sure, will fix it in the next commit.', 'commenter': 'EricGao888'}, {'comment': 'Fixed by the latest commit.', 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThread.java,"@@ -273,13 +275,20 @@ public void kill() {
     public void downloadResource(String execLocalPath, Logger logger, List<Pair<String, String>> fileDownloads) {
         for (Pair<String, String> fileDownload : fileDownloads) {
             try {
+                WorkerServerMetrics.incWorkerResourceDownloadCount();
                 // query the tenant code of the resource according to the name of the resource
                 String fullName = fileDownload.getLeft();
                 String tenantCode = fileDownload.getRight();
                 String resHdfsPath = storageOperate.getResourceFileName(tenantCode, fullName);
                 logger.info(""get resource file from hdfs :{}"", resHdfsPath);
+                Long resourceDownloadStartTime = System.currentTimeMillis();","[{'comment': 'There is no need to do an extra pack\r\n```suggestion\r\n                long resourceDownloadStartTime = System.currentTimeMillis();\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Sure, will fix it. Thx', 'commenter': 'EricGao888'}, {'comment': 'Fixed by the latest commit.', 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-meter/src/main/resources/grafana/DolphinSchedulerWorker.json,"@@ -172,7 +172,7 @@
         ""showThresholdLabels"": false,
         ""showThresholdMarkers"": false
       },
-      ""pluginVersion"": ""8.5.3"",
+      ""pluginVersion"": ""9.0.0-beta2"",","[{'comment': ""I don't recommend using a beta version of plugin"", 'commenter': 'kezhenxu94'}, {'comment': 'Sure, will fix it.', 'commenter': 'EricGao888'}, {'comment': 'Fixed by the latest commit.', 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/metrics/WorkerServerMetrics.java,"@@ -37,6 +36,36 @@ public class WorkerServerMetrics {
             .description(""full worker submit queues count"")
             .register(Metrics.globalRegistry);
 
+    private static final Counter WORKER_RESOURCE_DOWNLOAD_COUNTER =
+            Counter.builder(""ds.worker.resource.download.count"")
+                    .description(""worker resource download count"")
+                    .register(Metrics.globalRegistry);
+
+    private static final Counter WORKER_RESOURCE_DOWNLOAD_SUCCESS_COUNTER =
+            Counter.builder(""ds.worker.resource.download.success.count"")
+                    .description(""worker resource download success count"")
+                    .register(Metrics.globalRegistry);
+
+    private static final Counter WORKER_RESOURCE_DOWNLOAD_FAILURE_COUNTER =
+            Counter.builder(""ds.worker.resource.download.failure.count"")
+                    .description(""worker resource download failure count"")
+                    .register(Metrics.globalRegistry);
+
+    private static final Timer WORKER_RESOURCE_DOWNLOAD_DURATION_TIMER =
+            Timer.builder(""ds.worker.resource.download.duration"")
+                    .publishPercentiles(0.5, 0.75, 0.95, 0.99)
+                    .publishPercentileHistogram()
+                    .description(""time cost of resource download on workers"")
+                    .register(Metrics.globalRegistry);
+","[{'comment': ""Hi, I didn't notice this, but for `counter`, `successful counter` and `failure counter`, we usually use only one `counter` and add `status=success`/`status=failure` tags so we don't have 3 counters for only one metrics"", 'commenter': 'kezhenxu94'}, {'comment': 'Sure, thx for pointing this out. I will fix it and the related issues in the previous commits in this PR.', 'commenter': 'EricGao888'}, {'comment': 'Fixed by the latest commit.', 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/metrics/WorkerServerMetrics.java,"@@ -37,6 +40,33 @@ public class WorkerServerMetrics {
             .description(""full worker submit queues count"")
             .register(Metrics.globalRegistry);
 
+    private static final Counter WORKER_RESOURCE_DOWNLOAD_SUCCESS_COUNTER =
+            Counter.builder(""ds.worker.resource.download.count"")
+                    .tag(""status"", ""success"")
+                    .description(""worker resource download success count"")
+                    .register(Metrics.globalRegistry);
+
+    private static final Counter WORKER_RESOURCE_DOWNLOAD_FAILURE_COUNTER =
+            Counter.builder(""ds.worker.resource.download.count"")
+                    .tag(""status"", ""fail"")
+                    .description(""worker resource download failure count"")
+                    .register(Metrics.globalRegistry);
+
+    private static final Timer WORKER_RESOURCE_DOWNLOAD_DURATION_TIMER =
+            Timer.builder(""ds.worker.resource.download.duration"")
+                    .publishPercentiles(0.5, 0.75, 0.95, 0.99)
+                    .publishPercentileHistogram()
+                    .description(""time cost of resource download on workers"")
+                    .register(Metrics.globalRegistry);
+
+    private static final DistributionSummary WORKER_RESOURCE_DOWNLOAD_SIZE_DISTRIBUTION =
+            DistributionSummary.builder(""ds.worker.resource.download.size"")
+            .baseUnit(""KB"")","[{'comment': ""I'd just use `bytes` as the unit so users can get more detailed size, and they can just convert it to `kb`/`mb` if they want, in Grafana.\r\n\r\nConsider if users have many small files, `<1KB`, this would only display `0`."", 'commenter': 'kezhenxu94'}, {'comment': ""That's a good point. Will change it to use `byte` as unit. Thx for the suggestions~ "", 'commenter': 'EricGao888'}]"
10749,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/FileUtils.java,"@@ -244,4 +244,15 @@ public static boolean directoryTraversal(String filename){
         }
     }
 
+    /**
+     * Get file size in Byte
+     *
+     * @param filename String type of filename
+     * @return file size in Byte
+     */
+    public static long getFileSizeInByte(String filename) {
+        File file = new File(filename);
+        return file.length();
+    }","[{'comment': 'This is one-line code, just inline this util method and remove this method?\r\n\r\n```java\r\nnew File(filename).length()\r\n```', 'commenter': 'kezhenxu94'}]"
10749,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/runner/TaskExecuteThread.java,"@@ -278,8 +280,14 @@ public void downloadResource(String execLocalPath, Logger logger, List<Pair<Stri
                 String tenantCode = fileDownload.getRight();
                 String resHdfsPath = storageOperate.getResourceFileName(tenantCode, fullName);
                 logger.info(""get resource file from hdfs :{}"", resHdfsPath);
+                long resourceDownloadStartTime = System.currentTimeMillis();
                 storageOperate.download(tenantCode, resHdfsPath, execLocalPath + File.separator + fullName, false, true);
+                WorkerServerMetrics.recordWorkerResourceDownloadTime(System.currentTimeMillis() - resourceDownloadStartTime);
+                WorkerServerMetrics.recordWorkerResourceDownloadSize(
+                        FileUtils.getFileSizeInByte(execLocalPath + File.separator + fullName));","[{'comment': '```suggestion\r\n                WorkerServerMetrics.recordWorkerResourceDownloadSize(\r\n                        Files.size(Paths.get(execLocalPath, fullName)));\r\n```', 'commenter': 'kezhenxu94'}, {'comment': 'Pretty and neat! Have fixed it in the latest commit. Thx', 'commenter': 'EricGao888'}]"
10776,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/generator/sources/MySQLSourceGenerator.java,"@@ -89,9 +90,11 @@ public String generate(SqoopParameters sqoopParameters, SqoopTaskExecutionContex
                                 .append(SPACE).append(sourceMysqlParameter.getSrcTable());
                         }
 
-                        if (StringUtils.isNotEmpty(sourceMysqlParameter.getSrcColumns())) {
-                            mysqlSourceSb.append(SPACE).append(COLUMNS)
-                                .append(SPACE).append(sourceMysqlParameter.getSrcColumns());
+                        if(sourceMysqlParameter.getSrcColumnType() == SqoopColumnType.SOME_COLUMNS.getCode()){
+                            if (StringUtils.isNotEmpty(sourceMysqlParameter.getSrcColumns())) {","[{'comment': 'Please merge two if statement', 'commenter': 'zhuxt2015'}, {'comment': 'ok, done 😀@zhuxt2015 ', 'commenter': 'CallMeKingsley97'}]"
10776,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -784,6 +785,16 @@ public void checkSerialProcess(ProcessDefinition processDefinition) {
             return;
         }
         Map<String, Object> cmdParam = new HashMap<>();
+        //write the parameters of the nextProcessInstance to command
+        if (StringUtils.isNotEmpty(nextProcessInstance.getCommandParam())) {
+            Map<String, String> commandStartParamsMap = JSONUtils.toMap(nextProcessInstance.getCommandParam());
+            if (MapUtils.isNotEmpty(commandStartParamsMap)) {
+                Map<String, String> paramsMap = JSONUtils.toMap(commandStartParamsMap.get(CMD_PARAM_START_PARAMS));
+                if (MapUtils.isNotEmpty(paramsMap)) {
+                    cmdParam.put(CMD_PARAM_START_PARAMS, JSONUtils.toJsonString(paramsMap));
+                }
+            }
+        }","[{'comment': 'Please revert this.', 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'CallMeKingsley97'}]"
10776,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessServiceImpl.java,"@@ -774,7 +775,8 @@ private Boolean checkCmdParam(Command command, Map<String, String> cmdParam) {
         CommandType commandTypeIfComplement = getCommandTypeIfComplement(processInstance, command);
         // reset global params while repeat running and recover tolerance fault process is needed by cmdParam
         if (commandTypeIfComplement == CommandType.REPEAT_RUNNING ||
-                commandTypeIfComplement == CommandType.RECOVER_TOLERANCE_FAULT_PROCESS) {
+                commandTypeIfComplement == CommandType.RECOVER_TOLERANCE_FAULT_PROCESS ||
+                commandTypeIfComplement == CommandType.RECOVER_SERIAL_WAIT) {","[{'comment': 'Please revert this.', 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'CallMeKingsley97'}]"
10776,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopColumnType.java,"@@ -0,0 +1,41 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.sqoop;
+
+public enum SqoopColumnType {
+
+    ALL_COLUMNS(0, ""GET_ALL_COLUMNS""),
+    SOME_COLUMNS(1, ""CUSTOMIZE_COLUMNS"");","[{'comment': '```suggestion\r\n    CUSTOMIZE_COLUMNS(1, ""CUSTOMIZE_COLUMNS"");\r\n```', 'commenter': 'ruanwenjun'}]"
10776,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/generator/sources/MySQLSourceGenerator.java,"@@ -89,7 +90,8 @@ public String generate(SqoopParameters sqoopParameters, SqoopTaskExecutionContex
                                     .append(SPACE).append(sourceMysqlParameter.getSrcTable());
                         }
 
-                        if (StringUtils.isNotEmpty(sourceMysqlParameter.getSrcColumns())) {
+                        if (sourceMysqlParameter.getSrcColumnType() == SqoopColumnType.SOME_COLUMNS.getCode()","[{'comment': '```suggestion\r\n                        if (sourceMysqlParameter.getSrcColumnType() == SqoopColumnType. CUSTOMIZE_COLUMNS.getCode()\r\n```', 'commenter': 'ruanwenjun'}]"
10821,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -1300,6 +1301,10 @@ public void getPreVarPool(TaskInstance taskInstance, Set<String> preTask) {
             }
             if (allProperty.size() > 0) {
                 taskInstance.setVarPool(JSONUtils.toJsonString(allProperty.values()));
+                Map<String, Object> taskParams = JSONUtils.parseObject(taskInstance.getTaskParams(), new TypeReference<Map<String, Object>>() {
+                });
+                taskParams.put(""varPool"", JSONUtils.toJsonString(allProperty.values()));","[{'comment': ""TaskParams and VarPool is different fields, so you can't add varpool into taskParams."", 'commenter': 'caishunfeng'}, {'comment': 'org.apache.dolphinscheduler.service.expand.CuringGlobalParams#paramParsingPreparation use taskInstance.varParams to build prepareParamsMap, and prepareParamsMap  was used to replace sql param.But taskInstance.varParams is always null, so I put it.This is why I did it, maybe you have a better idea？', 'commenter': 'huangchenguang123'}, {'comment': 'I think this is a unified process for all task, so after you fix the spark ui, the custome params can pass to worker.\r\nBTW, the custome params for the current task is localParams.\r\nThis is a shell task example, hope it can help you. \r\n![image](https://user-images.githubusercontent.com/11962619/178404246-ad166c76-1ebf-44e5-9b69-ac5c3be41a1c.png)', 'commenter': 'caishunfeng'}, {'comment': 'BTW, I found the flink task also has the same issue in ui.', 'commenter': 'caishunfeng'}, {'comment': ""localParams is currently useful, but this is limited to [in] parameters, but for upstream [out] parameters, spark sql currently doesn't work, which is why I use varPool."", 'commenter': 'huangchenguang123'}, {'comment': ""Now ds just support three task types for parameter transfer, see https://dolphinscheduler.apache.org/en-us/docs/dev/user_doc/guide/parameter/context.html\r\nSo it's a feature, not a bug, you would better to create another feature issue to do it. WDYT?"", 'commenter': 'caishunfeng'}, {'comment': 'I will create a feature, but do I need to resubmit a mr about parameter transfer?', 'commenter': 'huangchenguang123'}, {'comment': '> I will create a feature, but do I need to resubmit a mr about parameter transfer?\r\n\r\nYou can submit other pr to the feature issue if you are interested in.', 'commenter': 'caishunfeng'}]"
10850,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -988,8 +988,7 @@ private String removeDuplicates(String scheduleTimeList) {
         HashSet<String> removeDate = new HashSet<String>();
         List<String> resultList = new ArrayList<String>();
         if (StringUtils.isNotEmpty(scheduleTimeList)) {
-            String[] dateArrays = scheduleTimeList.split(COMMA);
-            List<String> dateList = Arrays.asList(dateArrays);
+            List<String> dateList  = Arrays.stream(scheduleTimeList.split(COMMA)).map(String::trim).collect(Collectors.toList());","[{'comment': 'I think we should distinct dataList.', 'commenter': 'SbloodyS'}, {'comment': 'ok,changed.', 'commenter': 'hstdream'}]"
10850,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -984,15 +984,12 @@ private boolean isValidateScheduleTime(String schedule) {
      * @param scheduleTimeList
      * @return remove duplicate date list
      */
-    private String removeDuplicates(String scheduleTimeList) {
+    private static String removeDuplicates(String scheduleTimeList) {
         HashSet<String> removeDate = new HashSet<String>();
-        List<String> resultList = new ArrayList<String>();
         if (StringUtils.isNotEmpty(scheduleTimeList)) {
-            String[] dateArrays = scheduleTimeList.split(COMMA);
-            List<String> dateList = Arrays.asList(dateArrays);
-            removeDate.addAll(dateList);
-            resultList.addAll(removeDate);
-            return String.join(COMMA, resultList);
+            List<String> inputDateList  = Arrays.stream(scheduleTimeList.split(COMMA)).map(String::trim).collect(Collectors.toList());","[{'comment': 'I understand that the problem you fixed is to delete the space before and after, not the repetition. Am I right?', 'commenter': 'SbloodyS'}, {'comment': 'no, here is the problem of repeated scheduling time.', 'commenter': 'hstdream'}, {'comment': '\r\nSpace will cause the problem of repeated scheduling time.', 'commenter': 'hstdream'}, {'comment': '```suggestion\r\n            Set<String> dateSet  = Arrays.stream(scheduleTimeList.split(COMMA)).map(String::trim).collect(Collectors.toSet());\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'And the name `removeDate` seems ambiguous, suggestion: dateSet.', 'commenter': 'caishunfeng'}, {'comment': 'ok', 'commenter': 'hstdream'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/pom.xml,"@@ -0,0 +1,57 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-task-plugin</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-task-chunjun</artifactId>
+    <packaging>jar</packaging>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-datasource-all</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-spi</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-task-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-datasource-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>","[{'comment': 'Can we remove this? since we already import `dolphinscheduler-datasource-all`', 'commenter': 'ruanwenjun'}, {'comment': 'dolphinscheduler-datasource-all and dolphinscheduler-datasource-api  are separate module', 'commenter': 'tracehh'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/main/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunTaskExecutionContext.java,"@@ -0,0 +1,118 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+import org.apache.dolphinscheduler.spi.enums.DbType;
+
+import java.io.Serializable;
+
+/**
+ * chunjun  taskExecutionContext
+ */
+public class ChunJunTaskExecutionContext implements Serializable {","[{'comment': 'Please use lombok to generate get/set/toString\r\n```suggestion\r\n@Data\r\npublic class ChunJunTaskExecutionContext implements Serializable {\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'ok update it', 'commenter': 'tracehh'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/main/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunTask.java,"@@ -0,0 +1,261 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.EXIT_CODE_FAILURE;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.RWXR_XR_X;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.ShellCommandExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.model.TaskResponse;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.enums.Flag;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.commons.lang.SystemUtils;
+
+import java.io.File;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardOpenOption;
+import java.nio.file.attribute.FileAttribute;
+import java.nio.file.attribute.PosixFilePermission;
+import java.nio.file.attribute.PosixFilePermissions;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ * chunjun task
+ */
+public class ChunJunTask extends AbstractTaskExecutor {
+    /**
+     * chunjun path
+     */
+    private static final String CHUNJUN_PATH = ""${CHUNJUN_HOME}/bin/start-chunjun"";
+
+    /**
+     * chunjun dist
+     */
+    private static final String CHUNJUN_DIST_DIR = ""${CHUNJUN_HOME}/chunjun-dist"";
+
+    /**
+     * chunJun parameters
+     */
+    private ChunJunParameters chunJunParameters;
+
+    /**
+     * shell command executor
+     */
+    private ShellCommandExecutor shellCommandExecutor;
+
+    /**
+     * taskExecutionContext
+     */
+    private TaskExecutionContext taskExecutionContext;
+
+    public ChunJunTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+        this.shellCommandExecutor = new ShellCommandExecutor(this::logHandle,
+            taskExecutionContext, logger);
+    }
+
+    /**
+     * init chunjun config
+     */
+    @Override
+    public void init() {
+        logger.info(""chunjun task params {}"", taskExecutionContext.getTaskParams());
+        chunJunParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), ChunJunParameters.class);
+
+        if (!chunJunParameters.checkParameters()) {
+            throw new RuntimeException(""chunjun task params is not valid"");
+        }
+    }
+
+    /**
+     * run chunjun process
+     *
+     * @throws Exception exception
+     */
+    @Override
+    public void handle() throws Exception {
+        try {
+            Map<String, Property> paramsMap = taskExecutionContext.getPrepareParamsMap();
+
+            String jsonFilePath = buildChunJunJsonFile(paramsMap);
+            String shellCommandFilePath = buildShellCommandFile(jsonFilePath, paramsMap);
+            TaskResponse commandExecuteResult = shellCommandExecutor.run(shellCommandFilePath);
+
+            setExitStatusCode(commandExecuteResult.getExitStatusCode());
+            setAppIds(commandExecuteResult.getAppIds());
+            setProcessId(commandExecuteResult.getProcessId());
+        } catch (Exception e) {
+            logger.error(""chunjun task failed."", e);
+            setExitStatusCode(EXIT_CODE_FAILURE);
+            throw e;
+        }
+    }
+
+    /**
+     * build chunjun json file
+     *
+     * @param paramsMap
+     * @return
+     * @throws Exception
+     */
+    private String buildChunJunJsonFile(Map<String, Property> paramsMap)
+        throws Exception {
+        // generate json
+        String fileName = String.format(""%s/%s_job.json"",
+            taskExecutionContext.getExecutePath(),
+            taskExecutionContext.getTaskAppId());
+
+        String json = null;
+
+        Path path = new File(fileName).toPath();
+        if (Files.exists(path)) {
+            return fileName;
+        }
+
+        if (chunJunParameters.getCustomConfig() == Flag.YES.ordinal()) {
+            json = chunJunParameters.getJson().replaceAll(""\\r\\n"", ""\n"");
+        }
+
+        // replace placeholder
+        json = ParameterUtils.convertParameterPlaceholders(json, ParamUtils.convert(paramsMap));
+
+        logger.debug(""chunjun job json : {}"", json);
+
+        // create chunjun json file
+        FileUtils.writeStringToFile(new File(fileName), json, StandardCharsets.UTF_8);
+        return fileName;
+    }
+
+
+    /**
+     * create command
+     *
+     * @return shell command file name
+     * @throws Exception if error throws Exception
+     */
+    private String buildShellCommandFile(String jobConfigFilePath, Map<String, Property> paramsMap)
+        throws Exception {
+        // generate scripts
+        String fileName = String.format(""%s/%s_node.%s"",
+            taskExecutionContext.getExecutePath(),
+            taskExecutionContext.getTaskAppId(),
+            SystemUtils.IS_OS_WINDOWS ? ""bat"" : ""sh"");
+
+        Path path = new File(fileName).toPath();
+
+        if (Files.exists(path)) {
+            return fileName;
+        }
+
+        // chunjun command
+        StringBuilder sbr = new StringBuilder();","[{'comment': 'It\'s better to use Joiner or list to concat the parameters with "" "".', 'commenter': 'ruanwenjun'}, {'comment': 'ok update it', 'commenter': 'tracehh'}, {'comment': ""I don't see you updated this, please don't mark as resolved if it's not resolved actually"", 'commenter': 'kezhenxu94'}, {'comment': 'I understant incorrectly before. update it now', 'commenter': 'tracehh'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/pom.xml,"@@ -0,0 +1,57 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-task-plugin</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-task-chunjun</artifactId>
+    <packaging>jar</packaging>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-datasource-all</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-spi</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-task-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-datasource-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>com.alibaba</groupId>
+            <artifactId>druid</artifactId>
+        </dependency>","[{'comment': ""It seems we don't need to add this?\r\n```suggestion\r\n        \r\n```"", 'commenter': 'ruanwenjun'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/main/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunTask.java,"@@ -0,0 +1,267 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.EXIT_CODE_FAILURE;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.RWXR_XR_X;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractTaskExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.ShellCommandExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.model.TaskResponse;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.enums.Flag;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.commons.lang.SystemUtils;
+
+import java.io.File;
+import java.nio.charset.StandardCharsets;
+import java.nio.file.Files;
+import java.nio.file.Path;
+import java.nio.file.StandardOpenOption;
+import java.nio.file.attribute.FileAttribute;
+import java.nio.file.attribute.PosixFilePermission;
+import java.nio.file.attribute.PosixFilePermissions;
+import java.util.Map;
+import java.util.Set;
+
+/**
+ * chunjun task
+ */
+public class ChunJunTask extends AbstractTaskExecutor {
+    /**
+     * chunjun path
+     */
+    private static final String CHUNJUN_PATH = ""${CHUNJUN_HOME}/bin/start-chunjun"";","[{'comment': 'We should put this environment variable to `script/env/dolphinscheduler_env.sh`.', 'commenter': 'SbloodyS'}, {'comment': 'ok  update it', 'commenter': 'tracehh'}]"
10937,docs/docs/en/guide/task/chunjun.md,"@@ -0,0 +1,73 @@
+# CHUNJUN
+
+## Overview
+
+CHUNJUN task type for executing CHUNJUN programs. For CHUNJUN nodes, the worker will execute `${CHUNJUN_HOME}/bin/start-chunjun` to analyze the input json file.","[{'comment': 'could you add some hyper link for `CHUNJUN`? and I wonder is it have to use uppercase for all characters?', 'commenter': 'zhongjiajie'}, {'comment': 'Add you have to add `ChuJun` to https://github.com/apache/dolphinscheduler/blob/81930e54208f7c0f305c0b9f8846149bfc38f428/docs/configs/docsdev.js#L603 and https://github.com/apache/dolphinscheduler/blob/81930e54208f7c0f305c0b9f8846149bfc38f428/docs/configs/docsdev.js#L183 to display it in the dolphinscheduler website sidebar', 'commenter': 'zhongjiajie'}, {'comment': 'Thanks very much，update it', 'commenter': 'tracehh'}]"
10937,docs/docs/en/guide/task/chunjun.md,"@@ -0,0 +1,73 @@
+# CHUNJUN
+
+## Overview
+
+CHUNJUN task type for executing CHUNJUN programs. For CHUNJUN nodes, the worker will execute `${CHUNJUN_HOME}/bin/start-chunjun` to analyze the input json file.
+
+## Create Task
+
+- Click `Project Management -> Project Name -> Workflow Definition`, and click the `Create Workflow` button to enter the DAG editing page.
+- Drag the <img src=""../../../../img/tasks/icons/chunjun.png"" width=""15""/> from the toolbar to the drawing board.
+
+## Task Parameters
+
+| **Parameter** | **Description** |
+| ------- | ---------- |
+| Node name | The node name in a workflow definition is unique. |
+| Run flag | Identifies whether this node schedules normally, if it does not need to execute, select the prohibition execution. |
+| Task priority | When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order. |
+| Description | Describe the function of the node. |
+| Worker group | Assign tasks to the machines of the worker group to execute. If `Default` is selected, randomly select a worker machine for execution. |
+| Environment Name | Configure the environment name in which run the script. |
+| Number of failed retries | The number of times the task failed to resubmit. |
+| Failed retry interval | The time interval (unit minute) for resubmitting the task after a failed task. |
+| Task group name | The task group name. |
+| Priority | The task priority. |
+| Delayed execution time |  The time, in cents, that a task is delayed in execution. |
+| Timeout alarm | Check the timeout alarm and timeout failure. When the task exceeds the ""timeout period"", an alarm email will be sent and the task execution will fail. |
+| Custom template | Custom the content of the CHUNJUN node's json profile. |
+| json | json configuration file for CHUNJUN synchronization. |
+| Custom parameters | SQL task type, and stored procedure is a custom parameter order to set values for the method. The custom parameter type and data type are the same as the stored procedure task type. The difference is that the SQL task type custom parameter will replace the \${variable} in the SQL statement. |
+| Deploy mode | Execute chunjun task mode, eg local standalone. |
+| Option Parameters | Support such as `-confProp ""{\""flink.checkpoint.interval\"":60000}""` |
+| Predecessor task | Selecting a predecessor task for the current task will set the selected predecessor task as upstream of the current task. |
+
+## Task Example
+
+This example demonstrates importing data from Hive into MySQL.
+
+### Configuring the CHUNJUN environment in DolphinScheduler
+
+If you are using the CHUNJUN task type in a production environment, it is necessary to configure the required environment first. The configuration file is as follows: `/dolphinscheduler/conf/env/dolphinscheduler_env.sh`.
+
+![chunjun_task01](../../../../img/tasks/demo/chunjun_task01.png)
+
+After the environment has been configured, DolphinScheduler needs to be restarted.
+
+### Configuring CHUNJUN Task Node
+
+As the data to be read from Hive, a custom json is required, refer to: the template json in directory chunjun/chunjun-examples/json/hive.
+
+After writing the required json file, you can configure the node content by following the steps in the diagram below.
+
+![chunjun_task02](../../../../img/tasks/demo/chunjun_task02.png)
+
+### View run results
+
+![chunjun_task03](../../../../img/tasks/demo/chunjun_task03.png)
+
+### Note
+
+Before execute ${CHUNJUN_HOME}/bin/start-chunjun, need to change the shell ${CHUNJUN_HOME}/bin/start-chunjun, remove '&' in order to run in front. 
+
+ such as:
+
+```shell
+nohup $JAVA_RUN -cp $JAR_DIR $CLASS_NAME $@ &
+```
+
+update to following:
+
+```shell
+nohup $JAVA_RUN -cp $JAR_DIR $CLASS_NAME $@","[{'comment': 'It is seems you are using the different format in this for English and Chinses docs, could you migrate them to the same format?', 'commenter': 'zhongjiajie'}, {'comment': 'update it', 'commenter': 'tracehh'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/main/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunConstants.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+/**
+ * ChunJun constants
+ */
+public class ChunJunConstants {
+
+    public static final String FLINK_CONF_DIR = ""${FLINK_HOME}/conf"";
+
+    public static final String FLINK_LIB_DIR = ""${FLINK_HOME}/lib"";
+
+    public static final String HADOOP_CONF_DIR = ""${HADOOP_HOME}/etc/hadoop"";","[{'comment': 'Does ChuJun have to run base on flink or hadoop? and have to config both flink and hadoop home? if so please add them to our docs', 'commenter': 'zhongjiajie'}, {'comment': 'yarn-per-job based on flink or hadoop，HADOOP_HOME，FLINK_HOME had added', 'commenter': 'tracehh'}, {'comment': 'I can not see you added related content in docs @tracehh ', 'commenter': 'zhongjiajie'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/main/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunParameters.java,"@@ -0,0 +1,264 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+import org.apache.dolphinscheduler.plugin.task.api.enums.ResourceType;
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.resource.ResourceParametersHelper;
+import org.apache.dolphinscheduler.spi.enums.Flag;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import java.util.ArrayList;
+import java.util.List;
+
+/**
+ * chunjun parameters
+ */
+public class ChunJunParameters extends AbstractParameters {","[{'comment': 'I wonder can we use `@Data` here to getter and setter?', 'commenter': 'zhongjiajie'}, {'comment': 'ok update it', 'commenter': 'tracehh'}, {'comment': 'Hi~ I recommend replacing `@Data` with `@Getter`, `@Setter` and `@ToString` because `@Data` will generate some code we may not need and cause the test coverage to decrease. Thx : )', 'commenter': 'EricGao888'}, {'comment': 'see: https://projectlombok.org/features/Data', 'commenter': 'EricGao888'}, {'comment': 'https://stackoverflow.com/questions/45569085/sonarqube-bad-coverage-because-of-lombok-data', 'commenter': 'EricGao888'}, {'comment': '> SonarCloud Quality Gate failed.\xa0 \xa0 [![Quality Gate failed](https://camo.githubusercontent.com/4ea51c1f64ee3746f631653a02ab678ca6a3efb5f5cb474402faed2e3dcf90b5/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f5175616c6974794761746542616467652f6661696c65642d313670782e706e67)](https://sonarcloud.io/dashboard?id=apache-dolphinscheduler&pullRequest=10937)\r\n> \r\n> [![Bug](https://camo.githubusercontent.com/4c6102327f5a954f9c8acaf2e2714183157a9e41717b371b2cd585cf25057310/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636f6d6d6f6e2f6275672d313670782e706e67)](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=BUG) [![A](https://camo.githubusercontent.com/1cba125a897d7fa47033a3b3b2be2bbee680d34d4f004a215564659b853fb201/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f526174696e6742616467652f412d313670782e706e67)](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=BUG) [0 Bugs](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=BUG) [![Vulnerability](https://camo.githubusercontent.com/3ba1ee49636ffc3427e38649a9f8a65ee392f28e8a662fcf96ce24cefbb520e9/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636f6d6d6f6e2f76756c6e65726162696c6974792d313670782e706e67)](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=VULNERABILITY) [![A](https://camo.githubusercontent.com/1cba125a897d7fa47033a3b3b2be2bbee680d34d4f004a215564659b853fb201/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f526174696e6742616467652f412d313670782e706e67)](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=VULNERABILITY) [0 Vulnerabilities](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=VULNERABILITY) [![Security Hotspot](https://camo.githubusercontent.com/fb735cbe76f8d5e1679c76ce83b740ceb1eaf62de4f7bf88623dc9953261aff7/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636f6d6d6f6e2f73656375726974795f686f7473706f742d313670782e706e67)](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=SECURITY_HOTSPOT) [![E](https://camo.githubusercontent.com/ca3e5c9e7ad5fd04244d2d793976efbe479a024b145a815384556548a9884b5f/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f526174696e6742616467652f452d313670782e706e67)](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=SECURITY_HOTSPOT) [1 Security Hotspot](https://sonarcloud.io/project/security_hotspots?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=SECURITY_HOTSPOT) [![Code Smell](https://camo.githubusercontent.com/8fe18b2dfb6f7d4e44582f281b29f617eb5ae07c248d2002ca586e91da219212/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636f6d6d6f6e2f636f64655f736d656c6c2d313670782e706e67)](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=CODE_SMELL) [![A](https://camo.githubusercontent.com/1cba125a897d7fa47033a3b3b2be2bbee680d34d4f004a215564659b853fb201/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f526174696e6742616467652f412d313670782e706e67)](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=CODE_SMELL) [7 Code Smells](https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&pullRequest=10937&resolved=false&types=CODE_SMELL)\r\n> \r\n> [![10.7%](https://camo.githubusercontent.com/3f04cff3eeef8477afe696ae55c570cbb6ed02f16152497c14251828329a3e91/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f436f76657261676543686172742f302d313670782e706e67)](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=10937&metric=new_coverage&view=list) [10.7% Coverage](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=10937&metric=new_coverage&view=list) [![5.9%](https://camo.githubusercontent.com/6d10b2752bda1e1762d255930f4a4807428112b982706db9e339669f1165f525/68747470733a2f2f736f6e6172736f757263652e6769746875622e696f2f736f6e6172636c6f75642d6769746875622d7374617469632d7265736f75726365732f76322f636865636b732f4475706c69636174696f6e732f31302d313670782e706e67)](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=10937&metric=new_duplicated_lines_density&view=list) [5.9% Duplication](https://sonarcloud.io/component_measures?id=apache-dolphinscheduler&pullRequest=10937&metric=new_duplicated_lines_density&view=list)\r\n\r\n`Sonar` will probably no more fail for low test coverage once you fix this.', 'commenter': 'EricGao888'}, {'comment': 'Replaced @Data with @Getter, @Setter and @ToString', 'commenter': 'tracehh'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/test/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunConstantsTest.java,"@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+
+public class ChunJunConstantsTest {
+
+    private String flinkConfDir;
+
+    private String flinkLibDir;
+
+    private String hadoopConfDir;
+
+    @Before
+    public void setUp() {
+        flinkConfDir = ""${FLINK_HOME}/conf"";
+        flinkLibDir = ""${FLINK_HOME}/lib"";
+        hadoopConfDir = ""${HADOOP_HOME}/etc/hadoop"";
+    }
+
+    @Test
+    public void testEqualsString() {
+        Assert.assertEquals(flinkConfDir, ChunJunConstants.FLINK_CONF_DIR);
+        Assert.assertEquals(flinkLibDir, ChunJunConstants.FLINK_LIB_DIR);
+        Assert.assertEquals(hadoopConfDir, ChunJunConstants.HADOOP_CONF_DIR);","[{'comment': '```suggestion\r\n        Assert.assertEquals(ChunJunConstants.FLINK_CONF_DIR, flinkConfDir);\r\n        Assert.assertEquals(ChunJunConstants.FLINK_LIB_DIR, flinkLibDir);\r\n        Assert.assertEquals(ChunJunConstants.HADOOP_CONF_DIR, hadoopConfDir);\r\n```', 'commenter': 'SbloodyS'}]"
10937,dolphinscheduler-task-plugin/dolphinscheduler-task-chunjun/src/main/java/org/apache/dolphinscheduler/plugin/task/chunjun/ChunJunTaskChannelFactory.java,"@@ -0,0 +1,59 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.chunjun;
+
+import org.apache.dolphinscheduler.plugin.task.api.TaskChannel;
+import org.apache.dolphinscheduler.plugin.task.api.TaskChannelFactory;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+
+import java.util.List;
+
+import com.google.auto.service.AutoService;
+
+/**
+ * chunjun task channelFactory
+ */
+@AutoService(TaskChannelFactory.class)
+public class ChunJunTaskChannelFactory implements TaskChannelFactory {
+
+    @Override
+    public TaskChannel create() {
+        return new ChunJunTaskChannel();
+    }
+
+    /**
+     * plugin name
+     * Must be UNIQUE .
+     *
+     * @return this alert plugin name","[{'comment': ""This is not alert plugin, it's task plugin"", 'commenter': 'kezhenxu94'}, {'comment': 'ok update it', 'commenter': 'tracehh'}]"
10937,docs/docs/en/guide/task/chunjun.md,"@@ -0,0 +1,73 @@
+# ChunJun
+
+## Overview
+
+ChunJun task type for executing ChunJun programs. For ChunJun nodes, the worker will execute `${CHUNJUN_HOME}/bin/start-chunjun` to analyze the input json file.
+
+## Create Task
+
+- Click `Project Management -> Project Name -> Workflow Definition`, and click the `Create Workflow` button to enter the DAG editing page.
+- Drag the <img src=""../../../../img/tasks/icons/chunjun.png"" width=""15""/> from the toolbar to the drawing board.
+
+## Task Parameters
+
+| **Parameter** | **Description** |
+| ------- | ---------- |
+| Node name | The node name in a workflow definition is unique. |
+| Run flag | Identifies whether this node schedules normally, if it does not need to execute, select the prohibition execution. |
+| Task priority | When the number of worker threads is insufficient, execute in the order of priority from high to low, and tasks with the same priority will execute in a first-in first-out order. |
+| Description | Describe the function of the node. |
+| Worker group | Assign tasks to the machines of the worker group to execute. If `Default` is selected, randomly select a worker machine for execution. |
+| Environment Name | Configure the environment name in which run the script. |
+| Number of failed retries | The number of times the task failed to resubmit. |
+| Failed retry interval | The time interval (unit minute) for resubmitting the task after a failed task. |
+| Task group name | The task group name. |
+| Priority | The task priority. |
+| Delayed execution time |  The time, in cents, that a task is delayed in execution. |","[{'comment': '`in cents` typos? ', 'commenter': 'zhuxt2015'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdRegistryProperties.java,"@@ -0,0 +1,31 @@
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import lombok.Data;
+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
+import org.springframework.boot.context.properties.ConfigurationProperties;
+import org.springframework.context.annotation.Configuration;
+
+import java.time.Duration;
+
+@Data
+@Configuration
+@ConditionalOnProperty(prefix = ""registry"", name = ""type"", havingValue = ""etcd"")
+@ConfigurationProperties(prefix = ""registry"")
+public class EtcdRegistryProperties {
+    private String endpoints;
+    private String namespace=""dolphinscheduler"";
+    private Duration connectionTimeout = Duration.ofSeconds(9);
+
+    // auth
+    private String user;
+    private String password;
+    private String authority;
+
+    // RetryPolicy
+    private Long retryDelay=60L;
+    private Long retryMaxDelay=300L;","[{'comment': 'Consider also using `Duration` type, and format the codes please.', 'commenter': 'kezhenxu94'}, {'comment': 'The time unit for these two parameters is set by the ChronUnitRetry in jetcd.  The type of these two parameters is long, but the type of retryMaxDuration is Duration.\r\n\r\nYou can see the reference of these three parameters in EtcdRegistry.java line 51 to 54.', 'commenter': 'wjf222'}, {'comment': ""> The time unit for these two parameters is set by the ChronUnitRetry in jetcd. The type of these two parameters is long, but the type of retryMaxDuration is Duration.\r\n> \r\n> You can see the reference of these three parameters in EtcdRegistry.java line 51 to 54.\r\n\r\nHi, you don't have to just copy the type from JETCD client, using `Duration` as type in our own configurations is for users' convenient, they can just set something like `1s`, `500ms`, without knowing what's the time unit of the config. Also, users don't care what types we pass into `EtcdRegistry.java`, let's provide simplicity to users"", 'commenter': 'kezhenxu94'}, {'comment': ""> > The time unit for these two parameters is set by the ChronUnitRetry in jetcd. The type of these two parameters is long, but the type of retryMaxDuration is Duration.\r\n> > You can see the reference of these three parameters in EtcdRegistry.java line 51 to 54.\r\n> \r\n> Hi, you don't have to just copy the type from JETCD client, using `Duration` as type in our own configurations is for users' convenient, they can just set something like `1s`, `500ms`, without knowing what's the time unit of the config. Also, users don't care what types we pass into `EtcdRegistry.java`, let's provide simplicity to users\r\n\r\nYou are right,I fix this in [Modify the type of delay](https://github.com/apache/dolphinscheduler/pull/10981/commits/ba5f7687f8842427e4fea67b56f7f1125e48b9d4)"", 'commenter': 'wjf222'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdRegistryProperties.java,"@@ -0,0 +1,31 @@
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import lombok.Data;
+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
+import org.springframework.boot.context.properties.ConfigurationProperties;
+import org.springframework.context.annotation.Configuration;
+
+import java.time.Duration;
+
+@Data
+@Configuration
+@ConditionalOnProperty(prefix = ""registry"", name = ""type"", havingValue = ""etcd"")
+@ConfigurationProperties(prefix = ""registry"")
+public class EtcdRegistryProperties {
+    private String endpoints;
+    private String namespace=""dolphinscheduler"";
+    private Duration connectionTimeout = Duration.ofSeconds(9);
+
+    // auth
+    private String user;
+    private String password;
+    private String authority;
+
+    // RetryPolicy
+    private Long retryDelay=60L;
+    private Long retryMaxDelay=300L;
+    private Duration retryMaxDuration=Duration.ofMillis(1500);;","[{'comment': '```suggestion\r\n    private Duration retryMaxDuration=Duration.ofMillis(1500);\r\n```', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/pom.xml,"@@ -0,0 +1,43 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-registry-plugins</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-registry-etcd</artifactId>
+
+    <properties>
+        <maven.compiler.source>8</maven.compiler.source>
+        <maven.compiler.target>8</maven.compiler.target>
+    </properties>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-registry-api</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-common</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>io.etcd</groupId>
+            <artifactId>jetcd-core</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>io.etcd</groupId>
+            <artifactId>jetcd-test</artifactId>
+        </dependency>","[{'comment': 'This should be `test` scope', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/pom.xml,"@@ -0,0 +1,43 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-registry-plugins</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-registry-etcd</artifactId>
+
+    <properties>
+        <maven.compiler.source>8</maven.compiler.source>
+        <maven.compiler.target>8</maven.compiler.target>
+    </properties>","[{'comment': ""Don't set this here"", 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/README.md,"@@ -0,0 +1,28 @@
+# Introduction
+
+This module is the etcd registry plugin module, this plugin will use etcd as the registry center.
+
+# How to use
+
+If you want to set the registry center as mysql,You need to set the registry properties in master/worker/api's appplication.yml","[{'comment': ""```suggestion\r\nIf you want to set the registry center as mysql, you need to set the registry properties in master/worker/api's appplication.yml\r\n```"", 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/pom.xml,"@@ -0,0 +1,39 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>","[{'comment': 'License header', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdRegistry.java,"@@ -0,0 +1,301 @@
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import com.google.common.base.Splitter;
+import com.google.common.base.Strings;
+import io.etcd.jetcd.*;
+import io.etcd.jetcd.options.DeleteOption;
+import io.etcd.jetcd.options.GetOption;
+import io.etcd.jetcd.options.PutOption;
+import io.etcd.jetcd.options.WatchOption;
+import io.etcd.jetcd.support.Observers;
+import io.etcd.jetcd.watch.WatchEvent;
+import org.apache.dolphinscheduler.registry.api.*;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
+import org.springframework.stereotype.Component;
+
+import javax.annotation.PostConstruct;
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.time.temporal.ChronoUnit;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.stream.Collectors;
+
+import static org.apache.dolphinscheduler.common.Constants.FOLDER_SEPARATOR;
+
+
+@Component
+@ConditionalOnProperty(prefix = ""registry"", name = ""type"", havingValue = ""etcd"")
+public class EtcdRegistry implements Registry {
+    private static Logger LOGGER = LoggerFactory.getLogger(EtcdRegistry.class);
+    private final Client client;
+    private EtcdConnectionStateListener etcdConnectionStateListener;
+    // save the lock info for thread
+    // key:lockKey Value:leaseId
+    private static final ThreadLocal<Map<String, Long>> threadLocalLockMap = new ThreadLocal<>();
+
+    private final Map<String, Watch.Watcher> watcherMap = new ConcurrentHashMap<>();
+
+    private static Long TIME_TO_LIVE_SECONDS=30L;
+    public EtcdRegistry(EtcdRegistryProperties registryProperties) {
+        LOGGER.info(""Starting Etcd Registry..."");
+        ClientBuilder clientBuilder = Client.builder()
+                .endpoints(Util.toURIs(Splitter.on("","").trimResults().splitToList(registryProperties.getEndpoints())))
+                .namespace(byteSequence(registryProperties.getNamespace()))
+                .connectTimeout(registryProperties.getConnectionTimeout())
+                .retryChronoUnit(ChronoUnit.MILLIS)
+                .retryDelay(registryProperties.getRetryDelay())
+                .retryMaxDelay(registryProperties.getRetryMaxDelay())
+                .retryMaxDuration(registryProperties.getRetryMaxDuration());
+        if(!Strings.isNullOrEmpty(registryProperties.getUser())&&(!Strings.isNullOrEmpty(registryProperties.getPassword()))){
+            clientBuilder.user(byteSequence(registryProperties.getUser()));
+            clientBuilder.password(byteSequence(registryProperties.getPassword()));
+        }
+        if(!Strings.isNullOrEmpty(registryProperties.getLoadBalancerPolicy())){
+            clientBuilder.loadBalancerPolicy(registryProperties.getLoadBalancerPolicy());
+        }
+        if(!Strings.isNullOrEmpty(registryProperties.getAuthority())){
+            clientBuilder.authority(registryProperties.getAuthority());
+        }
+        client = clientBuilder.build();
+        LOGGER.info(""Started Etcd Registry..."");
+        etcdConnectionStateListener = new EtcdConnectionStateListener(client);
+    }
+
+    /**
+     * Start the etcd Connection stateListeer
+     */
+    @PostConstruct
+    public void start() {
+        LOGGER.info(""Starting Etcd ConnectionListener..."");
+        etcdConnectionStateListener.start();
+        LOGGER.info(""Started Etcd ConnectionListener..."");
+    }
+
+    /**
+     *
+     * @param path The prefix of the key being listened to
+     * @param listener
+     * @return if subcribe Returns true if no exception was thrown
+     */
+    @Override
+    public boolean subscribe(String path, SubscribeListener listener) {
+        try {
+            ByteSequence watchKey = byteSequence(path);
+            WatchOption watchOption = WatchOption.newBuilder().isPrefix(true).build();
+            watcherMap.computeIfAbsent(path, $ -> client.getWatchClient().watch(watchKey, watchOption,watchResponse -> {
+                for (WatchEvent event : watchResponse.getEvents()) {
+                    listener.notify(new EventAdaptor(event, path));
+                }
+            }));
+        } catch (Exception e){
+            throw new RegistryException(""Failed to subscribe listener for key: "" + path, e);
+        }
+        return true;
+    }
+
+    /**
+     * @throws throws an exception if the unsubscribe path does not exist
+     * @param path The prefix of the key being listened to
+     */
+    @Override
+    public void unsubscribe(String path) {
+        try {
+            watcherMap.get(path).close();
+            watcherMap.remove(path);
+        } catch (Exception e) {
+            throw new RegistryException(""Failed to unsubscribe listener for key: "" + path, e);
+        }
+    }
+
+    @Override
+    public void addConnectionStateListener(ConnectionListener listener) {
+        etcdConnectionStateListener.addConnectionListener(listener);
+    }
+
+    /**
+     *
+     * @param key
+     * @return Returns the value corresponding to the key
+     * @throws throws an exception if the key does not exist
+     */
+    @Override
+    public String get(String key) {
+        try {
+            List<KeyValue> keyValues = client.getKVClient().get(byteSequence(key)).get().getKvs();
+            return keyValues.iterator().next().getValue().toString(StandardCharsets.UTF_8);
+        } catch (Exception e) {
+            throw new RegistryException(""etcd get data error"", e);
+        }
+    }
+
+    /**
+     *
+     * @param key
+     * @param value
+     * @param deleteOnDisconnect Does the put data disappear when the client disconnects
+     */
+    @Override
+    public void put(String key, String value, boolean deleteOnDisconnect) {
+        try{
+            if(deleteOnDisconnect) {
+                // keep the key by lease, if disconnected, the lease will ,the key will delete","[{'comment': 'This sentence is not complete...', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdConnectionStateListener.java,"@@ -0,0 +1,133 @@
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+import io.etcd.jetcd.Client;
+import io.grpc.ConnectivityState;
+import io.grpc.ManagedChannel;
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+import org.apache.dolphinscheduler.registry.api.RegistryException;
+
+import java.lang.reflect.Field;
+import java.lang.reflect.Method;
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+/**
+ * Get the connection status by listening to the Client's Channel
+ */
+public class EtcdConnectionStateListener implements AutoCloseable{
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    // A thread pool that periodically obtains connection status
+    private final ScheduledExecutorService scheduledExecutorService;
+    // Client's Channel
+    private AtomicReference<ManagedChannel> channel;
+    // monitored client
+    private Client client;
+    // The state of the last monitor
+    private ConnectionState connectionState;
+    private long initialDelay = 500L;
+    private long delay = 500L;
+    public EtcdConnectionStateListener(Client client) {
+        this.client = client;
+        channel = new AtomicReference<>();
+        this.scheduledExecutorService = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""EtcdConnectionStateListenerThread"").setDaemon(true).build());
+    }
+
+    public void addConnectionListener(ConnectionListener connectionListener) {
+        connectionListeners.add(connectionListener);
+    }
+
+    @Override
+    public void close() throws Exception {
+        connectionListeners.clear();
+        scheduledExecutorService.shutdownNow();
+    }
+
+    /**
+     * try to get jetcd client ManagedChannel
+     * @param client the etcd client
+     * @return current connection channel
+     */
+    private ManagedChannel newChannel(Client client) {
+        try {
+            Field connectField =client.getClass().getDeclaredField(""connectManager"");
+            if(!connectField.isAccessible()){
+                connectField.setAccessible(true);
+            }
+            Object connection = connectField.get(client);
+            Method channel = connection.getClass().getDeclaredMethod(""getChannel"");
+            if (!channel.isAccessible()) {
+                channel.setAccessible(true);
+            }
+            return (ManagedChannel) channel.invoke(connection);
+        } catch (Exception e) {
+            throw new RegistryException(""Failed to get the etcd client channel"", e);
+        }","[{'comment': ""I don't think this is a good way to implement the connectivity state listener, why do you choose to use reflection instead of some native method of jetcd client?"", 'commenter': 'kezhenxu94'}, {'comment': 'Ok, I will try to use keepalive in lease client to listen for connection status.', 'commenter': 'wjf222'}, {'comment': ""> I don't think this is a good way to implement the connectivity state listener, why do you choose to use reflection instead of some native method of jetcd client?\r\n\r\nI made the problem complicated. I only need to periodically try to connect to Etcd, and the connection status can be judged by the connection result.\r\nI have removed the reflection related code. Now, i use the client to apply for a lease to determine whether the connection is successful in [Using the lease to listen connection state](https://github.com/apache/dolphinscheduler/pull/10981/commits/d3ecd2a6eed4af52395d2547ef7486cf435d03a1)"", 'commenter': 'wjf222'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/ConnectionListener.java,"@@ -19,6 +19,10 @@
 
 package org.apache.dolphinscheduler.registry.api;
 
+/**
+ * when the connect state between client and registry center changed,
+ * the onupdate function is triggered","[{'comment': '```suggestion\n * the {@code onUpdate} function is triggered\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/ConnectionState.java,"@@ -19,6 +19,9 @@
 
 package org.apache.dolphinscheduler.registry.api;
 
+/**
+ * Connection State Between client and registry center(Etcd,MySql,Zookeeper)","[{'comment': '```suggestion\n * Connection state between client and registry center(Etcd, MySql, Zookeeper)\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/Event.java,"@@ -20,9 +20,13 @@
 package org.apache.dolphinscheduler.registry.api;
 
 public class Event {
+    // The prefix which is watched
     private String key;
+    // The full path where the event was generated
     private String path;
+    // The value corresponding to the path
     private String data;
+    // The event type {ADD, REMOVE ,UPDATE}","[{'comment': '```suggestion\n    // The event type {ADD, REMOVE, UPDATE}\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/Registry.java,"@@ -20,27 +20,72 @@
 package org.apache.dolphinscheduler.registry.api;
 
 import java.io.Closeable;
-import java.time.Duration;
 import java.util.Collection;
 
+/**
+ * Registry
+ *
+ * <p>
+ * The implementation may throw RegistryException during function call","[{'comment': 'This is verbose as the function signatures already indicate that. \n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/Registry.java,"@@ -20,27 +20,72 @@
 package org.apache.dolphinscheduler.registry.api;
 
 import java.io.Closeable;
-import java.time.Duration;
 import java.util.Collection;
 
+/**
+ * Registry
+ *
+ * <p>
+ * The implementation may throw RegistryException during function call
+ */
 public interface Registry extends Closeable {
+    /**
+     * Watch the change of this path and subpath.
+     * The type of change contains [ADD,DELETE,UPDATE]
+     * @return if there is not a Exception, the result is true.","[{'comment': '```suggestion\n     * @return {@code true} if succeeded.\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/Registry.java,"@@ -20,27 +20,72 @@
 package org.apache.dolphinscheduler.registry.api;
 
 import java.io.Closeable;
-import java.time.Duration;
 import java.util.Collection;
 
+/**
+ * Registry
+ *
+ * <p>
+ * The implementation may throw RegistryException during function call
+ */
 public interface Registry extends Closeable {
+    /**
+     * Watch the change of this path and subpath.
+     * The type of change contains [ADD,DELETE,UPDATE]
+     * @return if there is not a Exception, the result is true.
+     */
     boolean subscribe(String path, SubscribeListener listener);
 
+    /**
+     * remove the SubscribeListener which subscribe this path","[{'comment': '```suggestion\n     * Remove the path from the subscribe list.\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/Registry.java,"@@ -20,27 +20,72 @@
 package org.apache.dolphinscheduler.registry.api;
 
 import java.io.Closeable;
-import java.time.Duration;
 import java.util.Collection;
 
+/**
+ * Registry
+ *
+ * <p>
+ * The implementation may throw RegistryException during function call
+ */
 public interface Registry extends Closeable {
+    /**
+     * Watch the change of this path and subpath.
+     * The type of change contains [ADD,DELETE,UPDATE]
+     * @return if there is not a Exception, the result is true.
+     */
     boolean subscribe(String path, SubscribeListener listener);
 
+    /**
+     * remove the SubscribeListener which subscribe this path
+     */
     void unsubscribe(String path);
 
+    /**
+     * addd a connection listener to collection","[{'comment': '```suggestion\n     * Add a connection listener to collection.\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-api/src/main/java/org/apache/dolphinscheduler/registry/api/Registry.java,"@@ -20,27 +20,72 @@
 package org.apache.dolphinscheduler.registry.api;
 
 import java.io.Closeable;
-import java.time.Duration;
 import java.util.Collection;
 
+/**
+ * Registry
+ *
+ * <p>
+ * The implementation may throw RegistryException during function call
+ */
 public interface Registry extends Closeable {
+    /**
+     * Watch the change of this path and subpath.
+     * The type of change contains [ADD,DELETE,UPDATE]
+     * @return if there is not a Exception, the result is true.
+     */
     boolean subscribe(String path, SubscribeListener listener);
 
+    /**
+     * remove the SubscribeListener which subscribe this path
+     */
     void unsubscribe(String path);
 
+    /**
+     * addd a connection listener to collection
+     */
     void addConnectionStateListener(ConnectionListener listener);
 
+    /**
+     * @return the value
+     */
     String get(String key);
 
+    /**
+     *
+     * @param key
+     * @param value
+     * @param deleteOnDisconnect if true, when the connection state is disconnected, the key will be deleted
+     */
     void put(String key, String value, boolean deleteOnDisconnect);
 
+    /**
+     * This function will delete the keys whose prefix is {@param key}
+     * @param key the prefix of deleted key
+     * @throws if the key not exists, there is a registryException
+     */
     void delete(String key);
 
+    /**
+     * This function will get the subdirectory of {@param key}
+     * E.g: registry contains  the following keys:[/test/test1/test2,]
+     * if the key: /test
+     * Return: test1
+     */
     Collection<String> children(String key);
 
+    /**
+     * @return if key exists,return true","[{'comment': '```suggestion\n     * @return {@code true} if key exists.\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/README.md,"@@ -0,0 +1,28 @@
+# Introduction
+
+This module is the etcd registry plugin module, this plugin will use etcd as the registry center.
+
+# How to use
+
+If you want to set the registry center as mysql,you need to set the registry properties in master/worker/api's appplication.yml","[{'comment': ""```suggestion\nIf you want to set the registry center as etcd, you need to set the registry properties in master/worker/api's appplication.yml\n```\n"", 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdConnectionStateListener.java,"@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+import io.etcd.jetcd.Client;
+import io.grpc.ManagedChannel;
+
+/**
+ * Get the connection status by listening to the Client's Channel
+ */
+public class EtcdConnectionStateListener implements AutoCloseable {
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    // A thread pool that periodically obtains connection status
+    private final ScheduledExecutorService scheduledExecutorService;
+    // Client's Channel
+    private AtomicReference<ManagedChannel> channel;
+    // monitored client
+    private Client client;
+    // The state of the last monitor
+    private ConnectionState connectionState;
+    private long initialDelay = 500L;
+    private long delay = 500L;
+    public EtcdConnectionStateListener(Client client) {
+        this.client = client;
+        channel = new AtomicReference<>();
+        this.scheduledExecutorService = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""EtcdConnectionStateListenerThread"").setDaemon(true).build());
+    }
+
+    public void addConnectionListener(ConnectionListener connectionListener) {
+        connectionListeners.add(connectionListener);
+    }
+
+    @Override
+    public void close() throws Exception {
+        connectionListeners.clear();
+        scheduledExecutorService.shutdownNow();
+    }
+
+    /**
+     * Apply for a lease through the client, if there is no exception, the connection is normal
+     * @return the current connection state
+     * @throws if there is a exception, return is DISCONNECTED
+     */
+    private ConnectionState isConnected() {
+        try {
+            // Use Get() to ensure Future completes","[{'comment': ""Remove this. Don't explain codes if they are already very clear. "", 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdConnectionStateListener.java,"@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+import io.etcd.jetcd.Client;
+import io.grpc.ManagedChannel;
+
+/**
+ * Get the connection status by listening to the Client's Channel
+ */
+public class EtcdConnectionStateListener implements AutoCloseable {
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    // A thread pool that periodically obtains connection status
+    private final ScheduledExecutorService scheduledExecutorService;
+    // Client's Channel
+    private AtomicReference<ManagedChannel> channel;
+    // monitored client
+    private Client client;
+    // The state of the last monitor
+    private ConnectionState connectionState;
+    private long initialDelay = 500L;
+    private long delay = 500L;
+    public EtcdConnectionStateListener(Client client) {
+        this.client = client;
+        channel = new AtomicReference<>();
+        this.scheduledExecutorService = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""EtcdConnectionStateListenerThread"").setDaemon(true).build());
+    }
+
+    public void addConnectionListener(ConnectionListener connectionListener) {
+        connectionListeners.add(connectionListener);
+    }
+
+    @Override
+    public void close() throws Exception {
+        connectionListeners.clear();
+        scheduledExecutorService.shutdownNow();
+    }
+
+    /**
+     * Apply for a lease through the client, if there is no exception, the connection is normal
+     * @return the current connection state
+     * @throws if there is a exception, return is DISCONNECTED
+     */
+    private ConnectionState isConnected() {","[{'comment': '```suggestion\n    private ConnectionState currentConnectivityState() {\n```\n', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdConnectionStateListener.java,"@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+import io.etcd.jetcd.Client;
+import io.grpc.ManagedChannel;
+
+/**
+ * Get the connection status by listening to the Client's Channel
+ */
+public class EtcdConnectionStateListener implements AutoCloseable {
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    // A thread pool that periodically obtains connection status
+    private final ScheduledExecutorService scheduledExecutorService;
+    // Client's Channel
+    private AtomicReference<ManagedChannel> channel;
+    // monitored client
+    private Client client;
+    // The state of the last monitor
+    private ConnectionState connectionState;
+    private long initialDelay = 500L;
+    private long delay = 500L;
+    public EtcdConnectionStateListener(Client client) {
+        this.client = client;
+        channel = new AtomicReference<>();
+        this.scheduledExecutorService = Executors.newScheduledThreadPool(
+                1,
+                new ThreadFactoryBuilder().setNameFormat(""EtcdConnectionStateListenerThread"").setDaemon(true).build());
+    }
+
+    public void addConnectionListener(ConnectionListener connectionListener) {
+        connectionListeners.add(connectionListener);
+    }
+
+    @Override
+    public void close() throws Exception {
+        connectionListeners.clear();
+        scheduledExecutorService.shutdownNow();
+    }
+
+    /**
+     * Apply for a lease through the client, if there is no exception, the connection is normal
+     * @return the current connection state
+     * @throws if there is a exception, return is DISCONNECTED
+     */
+    private ConnectionState isConnected() {
+        try {
+            // Use Get() to ensure Future completes
+            client.getLeaseClient().grant(1).get().getID();
+            return ConnectionState.CONNECTED;
+        } catch (Exception e) {
+            return ConnectionState.DISCONNECTED;
+        }
+    }
+
+    /**
+     * Periodically execute thread to get connection status
+     */
+    public void start() {
+        this.scheduledExecutorService.scheduleWithFixedDelay(() -> {
+            ConnectionState currentConnectionState = isConnected();
+            if (currentConnectionState == connectionState) {
+                return;
+            }
+            if (connectionState == ConnectionState.CONNECTED) {
+                if (currentConnectionState == ConnectionState.DISCONNECTED) {
+                    connectionState = ConnectionState.DISCONNECTED;
+                    triggerListener(ConnectionState.DISCONNECTED);
+                }
+            } else if (connectionState == ConnectionState.DISCONNECTED) {
+                if (currentConnectionState == ConnectionState.CONNECTED) {
+                    connectionState = ConnectionState.CONNECTED;
+                    triggerListener(ConnectionState.RECONNECTED);
+                }
+            } else if (connectionState == null) {
+                connectionState = currentConnectionState;
+                triggerListener(connectionState);
+            }","[{'comment': ""Why can't we just simplify this to\n\n```suggestion\n            if (connectionState != ConnectionState.SUSPENDED) {\n                connectionState = currentConnectionState;\n                triggerListener(connectionState);\n```\n\n@ruanwenjun I think the api should also notify even if the previous state is suspended and if the listener isn't interested in this they can just ignored. "", 'commenter': 'kezhenxu94'}, {'comment': 'Yes, in fact, for all state changes, we need to notify the listener.\r\nI wrote these logic in MysqlRegistry, since we need to generate `ConnectionState.RECONNECTED` state :), but the state we story in memory is just `RECONNECTED` and `RECONNECTED`.', 'commenter': 'ruanwenjun'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdConnectionStateListener.java,"@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+import io.etcd.jetcd.Client;
+import io.grpc.ManagedChannel;
+
+/**
+ * Get the connection status by listening to the Client's Channel","[{'comment': 'Reword this there is no channel anymore', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdConnectionStateListener.java,"@@ -0,0 +1,119 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.ConnectionState;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.concurrent.Executors;
+import java.util.concurrent.ScheduledExecutorService;
+import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicReference;
+
+import com.google.common.util.concurrent.ThreadFactoryBuilder;
+
+import io.etcd.jetcd.Client;
+import io.grpc.ManagedChannel;
+
+/**
+ * Get the connection status by listening to the Client's Channel
+ */
+public class EtcdConnectionStateListener implements AutoCloseable {
+    private final List<ConnectionListener> connectionListeners = Collections.synchronizedList(new ArrayList<>());
+    // A thread pool that periodically obtains connection status
+    private final ScheduledExecutorService scheduledExecutorService;
+    // Client's Channel
+    private AtomicReference<ManagedChannel> channel;","[{'comment': 'This is no needed right?', 'commenter': 'kezhenxu94'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdRegistry.java,"@@ -0,0 +1,344 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.Event;
+import org.apache.dolphinscheduler.registry.api.Registry;
+import org.apache.dolphinscheduler.registry.api.RegistryException;
+import org.apache.dolphinscheduler.registry.api.SubscribeListener;
+
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.time.temporal.ChronoUnit;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutionException;
+import java.util.stream.Collectors;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
+import org.springframework.stereotype.Component;
+
+import com.google.common.base.Splitter;
+import com.google.common.base.Strings;
+
+import io.etcd.jetcd.ByteSequence;
+import io.etcd.jetcd.Client;
+import io.etcd.jetcd.ClientBuilder;
+import io.etcd.jetcd.KeyValue;
+import io.etcd.jetcd.Lease;
+import io.etcd.jetcd.Lock;
+import io.etcd.jetcd.Util;
+import io.etcd.jetcd.Watch;
+import io.etcd.jetcd.options.DeleteOption;
+import io.etcd.jetcd.options.GetOption;
+import io.etcd.jetcd.options.PutOption;
+import io.etcd.jetcd.options.WatchOption;
+import io.etcd.jetcd.support.Observers;
+import io.etcd.jetcd.watch.WatchEvent;
+
+/**
+ * This is one of the implementation of {@link Registry}, with this implementation, you need to rely on Etcd CLuster to
+ * store the DolphinScheduler master/worker's metadata and do the server registry/unRegistry.
+ */
+@Component
+@ConditionalOnProperty(prefix = ""registry"", name = ""type"", havingValue = ""etcd"")
+public class EtcdRegistry implements Registry {
+    private static Logger LOGGER = LoggerFactory.getLogger(EtcdRegistry.class);
+    private final Client client;
+    private EtcdConnectionStateListener etcdConnectionStateListener;
+    public static final String FOLDER_SEPARATOR = ""/"";
+    // save the lock info for thread
+    // key:lockKey Value:leaseId
+    private static final ThreadLocal<Map<String, Long>> threadLocalLockMap = new ThreadLocal<>();
+
+    private final Map<String, Watch.Watcher> watcherMap = new ConcurrentHashMap<>();
+
+    private static Long TIME_TO_LIVE_SECONDS = 30L;
+    public EtcdRegistry(EtcdRegistryProperties registryProperties) {
+        LOGGER.info(""Starting Etcd Registry..."");
+        ClientBuilder clientBuilder = Client.builder()
+                .endpoints(Util.toURIs(Splitter.on("","").trimResults().splitToList(registryProperties.getEndpoints())))
+                .namespace(byteSequence(registryProperties.getNamespace()))
+                .connectTimeout(registryProperties.getConnectionTimeout())
+                .retryChronoUnit(ChronoUnit.MILLIS)
+                .retryDelay(registryProperties.getRetryDelay().toMillis())
+                .retryMaxDelay(registryProperties.getRetryMaxDelay().toMillis())
+                .retryMaxDuration(registryProperties.getRetryMaxDuration());
+        if (!Strings.isNullOrEmpty(registryProperties.getUser()) && (!Strings.isNullOrEmpty(registryProperties.getPassword()))) {","[{'comment': '```suggestion\r\n        if (StringUtils.isNotEmpty(registryProperties.getUser()) && (StringUtils.isNotEmpty(registryProperties.getPassword()))) {\r\n```', 'commenter': 'caishunfeng'}]"
10981,dolphinscheduler-registry/dolphinscheduler-registry-plugins/dolphinscheduler-registry-etcd/src/main/java/org/apache/dolphinscheduler/plugin/registry/etcd/EtcdRegistry.java,"@@ -0,0 +1,344 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.registry.etcd;
+
+import org.apache.dolphinscheduler.registry.api.ConnectionListener;
+import org.apache.dolphinscheduler.registry.api.Event;
+import org.apache.dolphinscheduler.registry.api.Registry;
+import org.apache.dolphinscheduler.registry.api.RegistryException;
+import org.apache.dolphinscheduler.registry.api.SubscribeListener;
+
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.time.temporal.ChronoUnit;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ExecutionException;
+import java.util.stream.Collectors;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;
+import org.springframework.stereotype.Component;
+
+import com.google.common.base.Splitter;
+import com.google.common.base.Strings;
+
+import io.etcd.jetcd.ByteSequence;
+import io.etcd.jetcd.Client;
+import io.etcd.jetcd.ClientBuilder;
+import io.etcd.jetcd.KeyValue;
+import io.etcd.jetcd.Lease;
+import io.etcd.jetcd.Lock;
+import io.etcd.jetcd.Util;
+import io.etcd.jetcd.Watch;
+import io.etcd.jetcd.options.DeleteOption;
+import io.etcd.jetcd.options.GetOption;
+import io.etcd.jetcd.options.PutOption;
+import io.etcd.jetcd.options.WatchOption;
+import io.etcd.jetcd.support.Observers;
+import io.etcd.jetcd.watch.WatchEvent;
+
+/**
+ * This is one of the implementation of {@link Registry}, with this implementation, you need to rely on Etcd CLuster to
+ * store the DolphinScheduler master/worker's metadata and do the server registry/unRegistry.
+ */
+@Component
+@ConditionalOnProperty(prefix = ""registry"", name = ""type"", havingValue = ""etcd"")
+public class EtcdRegistry implements Registry {
+    private static Logger LOGGER = LoggerFactory.getLogger(EtcdRegistry.class);
+    private final Client client;
+    private EtcdConnectionStateListener etcdConnectionStateListener;
+    public static final String FOLDER_SEPARATOR = ""/"";
+    // save the lock info for thread
+    // key:lockKey Value:leaseId
+    private static final ThreadLocal<Map<String, Long>> threadLocalLockMap = new ThreadLocal<>();
+
+    private final Map<String, Watch.Watcher> watcherMap = new ConcurrentHashMap<>();
+
+    private static Long TIME_TO_LIVE_SECONDS = 30L;
+    public EtcdRegistry(EtcdRegistryProperties registryProperties) {
+        LOGGER.info(""Starting Etcd Registry..."");
+        ClientBuilder clientBuilder = Client.builder()
+                .endpoints(Util.toURIs(Splitter.on("","").trimResults().splitToList(registryProperties.getEndpoints())))
+                .namespace(byteSequence(registryProperties.getNamespace()))
+                .connectTimeout(registryProperties.getConnectionTimeout())
+                .retryChronoUnit(ChronoUnit.MILLIS)
+                .retryDelay(registryProperties.getRetryDelay().toMillis())
+                .retryMaxDelay(registryProperties.getRetryMaxDelay().toMillis())
+                .retryMaxDuration(registryProperties.getRetryMaxDuration());
+        if (!Strings.isNullOrEmpty(registryProperties.getUser()) && (!Strings.isNullOrEmpty(registryProperties.getPassword()))) {
+            clientBuilder.user(byteSequence(registryProperties.getUser()));
+            clientBuilder.password(byteSequence(registryProperties.getPassword()));
+        }
+        if (!Strings.isNullOrEmpty(registryProperties.getLoadBalancerPolicy())) {
+            clientBuilder.loadBalancerPolicy(registryProperties.getLoadBalancerPolicy());
+        }
+        if (!Strings.isNullOrEmpty(registryProperties.getAuthority())) {
+            clientBuilder.authority(registryProperties.getAuthority());
+        }
+        client = clientBuilder.build();
+        LOGGER.info(""Started Etcd Registry..."");
+        etcdConnectionStateListener = new EtcdConnectionStateListener(client);
+    }
+
+    /**
+     * Start the etcd Connection stateListeer
+     */
+    @PostConstruct
+    public void start() {
+        LOGGER.info(""Starting Etcd ConnectionListener..."");
+        etcdConnectionStateListener.start();
+        LOGGER.info(""Started Etcd ConnectionListener..."");
+    }
+
+    /**
+     *
+     * @param path The prefix of the key being listened to
+     * @param listener
+     * @return if subcribe Returns true if no exception was thrown
+     */
+    @Override
+    public boolean subscribe(String path, SubscribeListener listener) {
+        try {
+            ByteSequence watchKey = byteSequence(path);
+            WatchOption watchOption = WatchOption.newBuilder().isPrefix(true).build();
+            watcherMap.computeIfAbsent(path, $ -> client.getWatchClient().watch(watchKey, watchOption,watchResponse -> {
+                for (WatchEvent event : watchResponse.getEvents()) {
+                    listener.notify(new EventAdaptor(event, path));
+                }
+            }));
+        } catch (Exception e) {
+            throw new RegistryException(""Failed to subscribe listener for key: "" + path, e);
+        }
+        return true;
+    }
+
+    /**
+     * @throws throws an exception if the unsubscribe path does not exist
+     * @param path The prefix of the key being listened to
+     */
+    @Override
+    public void unsubscribe(String path) {
+        try {
+            watcherMap.get(path).close();
+            watcherMap.remove(path);
+        } catch (Exception e) {
+            throw new RegistryException(""Failed to unsubscribe listener for key: "" + path, e);
+        }
+    }
+
+    @Override
+    public void addConnectionStateListener(ConnectionListener listener) {
+        etcdConnectionStateListener.addConnectionListener(listener);
+    }
+
+    /**
+     *
+     * @param key
+     * @return Returns the value corresponding to the key
+     * @throws throws an exception if the key does not exist
+     */
+    @Override
+    public String get(String key) {
+        try {
+            List<KeyValue> keyValues = client.getKVClient().get(byteSequence(key)).get().getKvs();
+            return keyValues.iterator().next().getValue().toString(StandardCharsets.UTF_8);
+        } catch (InterruptedException | ExecutionException e) {","[{'comment': ""If throw ExecutionException, should we call `Thread.currentThread().interrupt()`? It's better to handle separately, WDYT?"", 'commenter': 'caishunfeng'}]"
11009,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/StateEventResponseCommand.java,"@@ -71,7 +72,7 @@ public Command convert2Command() {
     public String toString() {
         return ""StateEventResponseCommand{""
                 + ""key="" + key
-                + "", status="" + status
+                + "", status="" + status.getDescp()","[{'comment': '```suggestion\r\n                + "", status="" + status\r\n```', 'commenter': 'ruanwenjun'}]"
11009,dolphinscheduler-master/src/test/java/org/apache/dolphinscheduler/server/master/processor/TaskAckProcessorTest.java,"@@ -66,7 +65,7 @@ public void before() {
         taskExecuteRunningMessage = new TaskExecuteRunningCommand(""127.0.0.1:5678"",
                                                                   "" 127.0.0.1:1234"",
                                                                   System.currentTimeMillis());
-        taskExecuteRunningMessage.setStatus(1);
+        taskExecuteRunningMessage.setStatus(ExecutionStatus.SUBMITTED_SUCCESS);","[{'comment': '```suggestion\r\n        taskExecuteRunningMessage.setStatus(ExecutionStatus.RUNNING_EXECUTION);\r\n```', 'commenter': 'ruanwenjun'}]"
11009,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/TaskExecuteRunningAckMessage.java,"@@ -70,6 +71,6 @@ public Command convert2Command() {
 
     @Override
     public String toString() {
-        return ""TaskExecuteRunningAckCommand{"" + ""taskInstanceId="" + taskInstanceId + "", status="" + status + '}';
+        return ""TaskExecuteRunningAckCommand{"" + ""taskInstanceId="" + taskInstanceId + "", status="" + status.getDescp() + '}';","[{'comment': '```suggestion\r\n        return ""TaskExecuteRunningAckCommand{"" + ""taskInstanceId="" + taskInstanceId + "", status="" + status + \'}\';\r\n```', 'commenter': 'ruanwenjun'}]"
11099,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java,"@@ -237,8 +237,8 @@ public TaskResponse run(String execCommand) throws IOException, InterruptedExcep
             result.setExitStatusCode(process.exitValue());
 
         } else {
-            logger.error(""process has failure , exitStatusCode:{}, processExitValue:{}, ready to kill ..."",
-                    result.getExitStatusCode(), process.exitValue());
+            logger.error(""process has failure , the task timeout configuration value is:{}, ready to kill ..."",
+                    result.getExitStatusCode(), taskRequest.getTaskTimeout());","[{'comment': 'What you expected to happen? Only print task timeout?', 'commenter': 'zhuxt2015'}, {'comment': ""When the process.waitFor execution times out and the process process is still alive, an exception will be thrown when the process.exitValue() method is executed. I don't think it is necessary to print process.exitValue here, because this information is already printed later.\r\n\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/a868259c47632c52f808b28c8fe15407514a299e/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java#L228\r\n\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/a868259c47632c52f808b28c8fe15407514a299e/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java#L246"", 'commenter': 'zhuangchong'}, {'comment': '@zhuangchong Do you miss `{}` in your error message string? ', 'commenter': 'zhongjiajie'}, {'comment': '> @zhuangchong Do you miss `{}` in your error message string?\r\n\r\nThanks, it has been changed.', 'commenter': 'zhuangchong'}]"
11157,docs/docs/en/guide/datasource/athena.md,"@@ -0,0 +1,21 @@
+# AWS Athena
+
+![mysql](../../../../img/new_ui/dev/datasource/athena.png)","[{'comment': '```suggestion\r\n![athena](../../../../img/new_ui/dev/datasource/athena.png)\r\n```', 'commenter': 'zhongjiajie'}]"
11157,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-athena/src/main/java/org/apache/dolphinscheduler/plugin/datasource/athena/param/AthenaDataSourceProcessor.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.datasource.athena.param;
+
+import com.google.auto.service.AutoService;
+import org.apache.commons.collections4.MapUtils;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.AbstractDataSourceProcessor;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.BaseDataSourceParamDTO;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.DataSourceProcessor;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.PasswordUtils;
+import org.apache.dolphinscheduler.spi.datasource.BaseConnectionParam;
+import org.apache.dolphinscheduler.spi.datasource.ConnectionParam;
+import org.apache.dolphinscheduler.spi.enums.DbType;
+import org.apache.dolphinscheduler.spi.utils.Constants;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+
+@AutoService(DataSourceProcessor.class)
+public class AthenaDataSourceProcessor extends AbstractDataSourceProcessor {
+
+    @Override
+    public BaseDataSourceParamDTO castDatasourceParamDTO(String paramJson) {
+        return JSONUtils.parseObject(paramJson, AthenaDataSourceParamDTO.class);
+    }
+
+    @Override
+    public BaseDataSourceParamDTO createDatasourceParamDTO(String connectionJson) {
+        AthenaConnectionParam
+            connectionParams = (AthenaConnectionParam) this.createConnectionParams(connectionJson);
+
+        AthenaDataSourceParamDTO
+            athenaDatasourceParamDTO = new AthenaDataSourceParamDTO();
+        athenaDatasourceParamDTO.setAwsRegion(connectionParams.getAwsRegion());
+        athenaDatasourceParamDTO.setDatabase(connectionParams.getDatabase());
+        athenaDatasourceParamDTO.setUserName(connectionParams.getUser());
+        athenaDatasourceParamDTO.setOther(this.parseOther(connectionParams.getOther()));","[{'comment': 'Can we add a new constructor for the class AthenaDataSourceParamDTO? we pass AthenaConnectionParam to it and   it see attribute inside the constructor?\r\nI find out we all data source using the `setAttr` to set attribute, maybe we should discuss it', 'commenter': 'zhongjiajie'}, {'comment': ""I find out we all data source using the `setAttr` to set attribute, so i implemented in the same way,I'm not sure if it needs to be changed uniformly\r\n \r\n "", 'commenter': 'guodongym'}, {'comment': 'get it', 'commenter': 'zhongjiajie'}]"
11157,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-athena/src/main/java/org/apache/dolphinscheduler/plugin/datasource/athena/param/AthenaDataSourceProcessor.java,"@@ -0,0 +1,158 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.datasource.athena.param;
+
+import com.google.auto.service.AutoService;
+import org.apache.commons.collections4.MapUtils;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.AbstractDataSourceProcessor;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.BaseDataSourceParamDTO;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.DataSourceProcessor;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.PasswordUtils;
+import org.apache.dolphinscheduler.spi.datasource.BaseConnectionParam;
+import org.apache.dolphinscheduler.spi.datasource.ConnectionParam;
+import org.apache.dolphinscheduler.spi.enums.DbType;
+import org.apache.dolphinscheduler.spi.utils.Constants;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.LinkedHashMap;
+import java.util.List;
+import java.util.Map;
+
+@AutoService(DataSourceProcessor.class)
+public class AthenaDataSourceProcessor extends AbstractDataSourceProcessor {
+
+    @Override
+    public BaseDataSourceParamDTO castDatasourceParamDTO(String paramJson) {
+        return JSONUtils.parseObject(paramJson, AthenaDataSourceParamDTO.class);
+    }
+
+    @Override
+    public BaseDataSourceParamDTO createDatasourceParamDTO(String connectionJson) {
+        AthenaConnectionParam
+            connectionParams = (AthenaConnectionParam) this.createConnectionParams(connectionJson);
+
+        AthenaDataSourceParamDTO
+            athenaDatasourceParamDTO = new AthenaDataSourceParamDTO();
+        athenaDatasourceParamDTO.setAwsRegion(connectionParams.getAwsRegion());
+        athenaDatasourceParamDTO.setDatabase(connectionParams.getDatabase());
+        athenaDatasourceParamDTO.setUserName(connectionParams.getUser());
+        athenaDatasourceParamDTO.setOther(this.parseOther(connectionParams.getOther()));
+
+        return athenaDatasourceParamDTO;
+    }
+
+    @Override
+    public BaseConnectionParam createConnectionParams(BaseDataSourceParamDTO datasourceParam) {
+        AthenaDataSourceParamDTO athenaParam = (AthenaDataSourceParamDTO) datasourceParam;
+        String address = String.format(""%s%s=%s;"", Constants.JDBC_ATHENA, ""AwsRegion"", athenaParam.getAwsRegion());
+
+        AthenaConnectionParam
+            athenaConnectionParam = new AthenaConnectionParam();
+        athenaConnectionParam.setUser(athenaParam.getUserName());
+        athenaConnectionParam.setPassword(PasswordUtils.encodePassword(athenaParam.getPassword()));
+        athenaConnectionParam.setAwsRegion(athenaParam.getAwsRegion());
+        athenaConnectionParam.setOther(this.transformOther(athenaParam.getOther()));
+        athenaConnectionParam.setAddress(address);
+        athenaConnectionParam.setJdbcUrl(address);
+        athenaConnectionParam.setDatabase(athenaParam.getDatabase());
+        athenaConnectionParam.setDriverClassName(this.getDatasourceDriver());
+        athenaConnectionParam.setValidationQuery(this.getValidationQuery());
+        athenaConnectionParam.setProps(athenaParam.getOther());
+
+        return athenaConnectionParam;
+    }
+
+    @Override
+    public ConnectionParam createConnectionParams(String connectionJson) {
+        return JSONUtils.parseObject(connectionJson, AthenaConnectionParam.class);
+    }
+
+    @Override
+    public String getDatasourceDriver() {
+        return Constants.COM_ATHENA_JDBC_DRIVER;
+    }
+
+    @Override
+    public String getValidationQuery() {
+        return Constants.ATHENA_VALIDATION_QUERY;
+    }
+
+    @Override
+    public String getJdbcUrl(ConnectionParam connectionParam) {
+        AthenaConnectionParam
+            athenaConnectionParam = (AthenaConnectionParam) connectionParam;
+        if (!StringUtils.isEmpty(athenaConnectionParam.getOther())) {
+            return String.format(""%s%s"", athenaConnectionParam.getJdbcUrl(), athenaConnectionParam.getOther());
+        }
+        return athenaConnectionParam.getJdbcUrl();
+    }
+
+    @Override
+    public Connection getConnection(ConnectionParam connectionParam) throws ClassNotFoundException, SQLException {
+        AthenaConnectionParam athenaConnectionParam = (AthenaConnectionParam) connectionParam;
+        Class.forName(this.getDatasourceDriver());
+        return DriverManager.getConnection(this.getJdbcUrl(connectionParam),
+            athenaConnectionParam.getUser(), PasswordUtils.decodePassword(athenaConnectionParam.getPassword()));
+    }
+
+    @Override
+    public DbType getDbType() {
+        return DbType.ATHENA;
+    }
+
+    @Override
+    public DataSourceProcessor create() {
+        return new AthenaDataSourceProcessor();
+    }
+
+    private String transformOther(Map<String, String> otherMap) {
+        if (MapUtils.isNotEmpty(otherMap)) {
+            List<String> list = new ArrayList<>(otherMap.size());
+            otherMap.forEach((key, value) -> list.add(String.format(""%s=%s"", key, value)));
+            return String.join(Constants.SEMICOLON, list);
+        }
+        return null;
+    }
+
+    private Map<String, String> parseOther(String other) {
+        Map<String, String> otherMap = new LinkedHashMap<>();
+        if (StringUtils.isEmpty(other)) {
+            return otherMap;
+        }
+        String[] configs = other.split(Constants.SEMICOLON);
+        for (String config : configs) {
+            otherMap.put(config.split(Constants.EQUAL_SIGN)[0], config.split(Constants.EQUAL_SIGN)[1]);
+        }
+        return otherMap;
+    }
+
+    @Override
+    protected void checkHost(String host) {
+        // Do not need to set the host, nothing to do
+    }
+
+    @Override
+    protected void checkDatabasePatter(String database) {
+        // Do not need to set the database, nothing to do
+    }","[{'comment': 'we can remove those method', 'commenter': 'zhongjiajie'}, {'comment': 'if remove those method, will cause the parent class parameter check error, `org.apache.dolphinscheduler.plugin.datasource.api.datasource.AbstractDataSourceProcessor#checkDatasourceParam` , I find  POSTGRESQL  are also problems with database verification \r\n ', 'commenter': 'guodongym'}, {'comment': '👌 ', 'commenter': 'zhongjiajie'}]"
11157,docs/docs/en/guide/datasource/athena.md,"@@ -0,0 +1,21 @@
+# AWS Athena
+
+![mysql](../../../../img/new_ui/dev/datasource/athena.png)
+
+## Datasource Parameters
+
+| **Datasource** | **Description** |
+| --- | --- |
+| Datasource | Select ATHENA. |
+| Datasource name | Enter the name of the DataSource. |
+| Description | Enter a description of the DataSource. |
+| Username | Set the AWS access key. |
+| Password | Set the AWS secret access key. |
+| AwsRegion | Set the AWS region. |
+| Database name | Enter the database name of the ATHENA connection. |
+| Jdbc connection parameters | Parameter settings for ATHENA connection, in JSON format. |
+
+## Native Supported
+
+No, read section example in [datasource-setting](../howto/datasource-setting.md) `DataSource Center` section to activate this datasource.","[{'comment': 'If not native supported, can we provider the JDBC connection name to download, better add some download link for it', 'commenter': 'zhongjiajie'}]"
11157,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-athena/src/main/java/org/apache/dolphinscheduler/plugin/datasource/athena/param/AthenaDataSourceParamDTO.java,"@@ -0,0 +1,53 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.datasource.athena.param;
+
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.BaseDataSourceParamDTO;
+import org.apache.dolphinscheduler.spi.enums.DbType;
+","[{'comment': 'We could use `lombok` `@Data` here to help the data class look neat.', 'commenter': 'EricGao888'}, {'comment': 'Done', 'commenter': 'guodongym'}, {'comment': 'resolve', 'commenter': 'zhongjiajie'}]"
11157,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-athena/src/test/java/org/apache/dolphinscheduler/plugin/datasource/athena/param/AthenaDataSourceProcessorTest.java,"@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.datasource.athena.param;
+
+import org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.CommonUtils;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.DataSourceUtils;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.PasswordUtils;
+import org.apache.dolphinscheduler.spi.enums.DbType;
+import org.apache.dolphinscheduler.spi.utils.Constants;
+
+import java.sql.DriverManager;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mockito;
+import org.powermock.api.mockito.PowerMockito;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+@RunWith(PowerMockRunner.class)","[{'comment': ""Better avoid using `powermock`, see: https://github.com/apache/dolphinscheduler/issues/11405 . But it's fine to me if you don't want to rewrite it at this moment. I could refactor this later in issue #11405"", 'commenter': 'EricGao888'}, {'comment': 'waiting for you to refactor later \r\n ', 'commenter': 'guodongym'}, {'comment': 'mark resolve', 'commenter': 'zhongjiajie'}]"
11183,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -294,7 +294,7 @@ public Map<String, Object> checkProcessDefinitionValid(long projectCode, Process
     }
 
     /**
-     * check if the current process has subprocesses and all subprocesses are valid
+     * check whether the current process has subprocesses and valid all subprocesses","[{'comment': '```suggestion\r\n     * check whether the current process has subprocesses and validate all subprocesses\r\n```', 'commenter': 'EricGao888'}]"
11183,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -607,7 +607,7 @@ private Map<String, Object> insertCommand(User loginUser, Integer instanceId, lo
     }
 
     /**
-     * check if sub processes are offline before starting process definition
+     * check whether sub processes are offline before starting process definition","[{'comment': '`sub processes` or `subprocesses`? I think either one is ok but just keep it consistent.', 'commenter': 'EricGao888'}, {'comment': 'I think with subprocesses', 'commenter': 'fuchanghai'}]"
11183,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -724,7 +724,7 @@ private int createCommand(CommandType commandType, long processDefineCode, TaskD
                 return createComplementCommandList(schedule, runMode, command, expectedParallelismNumber,
                     complementDependentMode);
             } catch (CronParseException cronParseException) {
-                // this just make compile happy, since we already validate the cron before
+                // this just make compile happen, since we already validate the cron before","[{'comment': 'Not sure what this comment means here. It makes developers confused. If we do not need this, maybe we could just delete it.', 'commenter': 'EricGao888'}, {'comment': ""I just saw a spelling error here, and I was confused at the time, but I don't know if it should be deleted, and I want to see other reviewers' opinions"", 'commenter': 'fuchanghai'}, {'comment': 'I think we can delete it\r\n', 'commenter': 'zhongjiajie'}, {'comment': 'Oh, I think it add this comment for specific case, The init idea is when even `CronParseException ` throw from function `createComplementCommandList ` or not, we should think it pass.\r\n\r\nSo maybe this sentence mean, `we add this catch to pass compiler pass, because we throw exception in function CronParseException`.\r\n\r\nIn this case I think we should remove the error log in L728 but keep this comment, WDYT @EricGao888 ', 'commenter': 'zhongjiajie'}, {'comment': 'I got it. Thx @zhongjiajie  for the explanation. We could remove the error logging and update the comment as `We catch the exception here just to make compiler happy, since we have already validated the schedule cron expression before` for better comprehension. @fuchanghai ', 'commenter': 'EricGao888'}, {'comment': ""Are you sure you don't replace happy with happen @EricGao888\r\n\r\n> I got it. Thx @zhongjiajie for the explanation. We could remove the error logging and update the comment as `We catch the exception here just to make compiler happy, since we have already validated the schedule cron expression before` for better comprehension. @fuchanghai\r\n\r\n"", 'commenter': 'fuchanghai'}]"
11183,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -940,7 +940,7 @@ private List<DependentProcessDefinition> checkDependentProcessDefinitionValid(
 
     /**
      * @param schedule
-     * @return check error return 0 otherwish 1
+     * @return check error return 0 otherwise 1","[{'comment': '```suggestion\r\n     * @return check error return 0, otherwise 1\r\n```', 'commenter': 'EricGao888'}]"
11183,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -724,8 +724,7 @@ private int createCommand(CommandType commandType, long processDefineCode, TaskD
                 return createComplementCommandList(schedule, runMode, command, expectedParallelismNumber,
                     complementDependentMode);
             } catch (CronParseException cronParseException) {
-                // this just make compile happy, since we already validate the cron before
-                logger.error(""Parse cron error"", cronParseException);
+                // We catch the exception here just to make compiler happen, since we have already validated the schedule cron expression before","[{'comment': '```suggestion\r\n                // We catch the exception here just to make compiler happy, since we have already validated the schedule cron expression before\r\n```', 'commenter': 'EricGao888'}, {'comment': '```suggestion\r\n                // We catch the exception here just to make compiler happy, since we have already validated the schedule cron expression before\r\n```', 'commenter': 'EricGao888'}]"
11204,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/utils/DependentExecute.java,"@@ -186,15 +233,12 @@ private DependResult getDependTaskResult(long taskCode, ProcessInstance processI
      * @return ProcessInstance
      */
     private ProcessInstance findLastProcessInterval(Long definitionCode, DateInterval dateInterval) {
-
-        ProcessInstance runningProcess = processService.findLastRunningProcess(definitionCode,
-                dateInterval.getStartTime(), dateInterval.getEndTime());
+        ProcessInstance runningProcess = processService.findLastRunningProcess(definitionCode, dateInterval.getStartTime(), dateInterval.getEndTime());","[{'comment': 'related pr: https://github.com/apache/dolphinscheduler/pull/11424', 'commenter': 'caishunfeng'}]"
11204,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.xml,"@@ -246,4 +246,29 @@
         where instance.process_instance_id = #{processInstanceId}
         and que.status = #{status}
     </select>
+    <select id=""queryLastTaskInstance"" resultType=""org.apache.dolphinscheduler.dao.entity.TaskInstance"">
+        select
+        <include refid=""baseSql""/>
+        from t_ds_task_instance
+        where task_code=#{taskCode}
+        <if test=""startTime!=null and endTime != null"">
+            and start_time <![CDATA[ >= ]]> #{startTime} and start_time <![CDATA[ <= ]]> #{endTime}
+        </if>
+        order by end_time desc limit 1
+    </select>
+    <select id=""queryLastTaskInstanceList"" resultType=""org.apache.dolphinscheduler.dao.entity.TaskInstance"">","[{'comment': '```suggestion\r\n    <select id=""queryTaskInstanceListByTime"" resultType=""org.apache.dolphinscheduler.dao.entity.TaskInstance"">\r\n```', 'commenter': 'caishunfeng'}]"
11204,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/utils/DependentExecute.java,"@@ -129,51 +140,87 @@ private DependResult calculateResultForTasks(DependentItem dependentItem,
 
     /**
      * depend type = depend_all
-     *
-     * @return
      */
-    private DependResult dependResultByProcessInstance(ProcessInstance processInstance) {
-        if (!processInstance.getState().isFinished()) {
-            return DependResult.WAITING;
-        }
+    private DependResult dependResultByProcessInstance(ProcessInstance processInstance, DateInterval dateInterval) {","[{'comment': 'Please add some comments.', 'commenter': 'caishunfeng'}]"
11204,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/utils/DependentExecute.java,"@@ -129,51 +140,87 @@ private DependResult calculateResultForTasks(DependentItem dependentItem,
 
     /**
      * depend type = depend_all
-     *
-     * @return
      */
-    private DependResult dependResultByProcessInstance(ProcessInstance processInstance) {
-        if (!processInstance.getState().isFinished()) {
-            return DependResult.WAITING;
-        }
+    private DependResult dependResultByProcessInstance(ProcessInstance processInstance, DateInterval dateInterval) {
         if (processInstance.getState().isSuccess()) {
+            List<ProcessTaskRelation> taskRelations = processService.findRelationByCode(processInstance.getProcessDefinitionCode(),
+                processInstance.getProcessDefinitionVersion());
+            if (!taskRelations.isEmpty()) {
+                List<TaskDefinitionLog> taskDefinitionLogs = processService.genTaskDefineList(taskRelations);
+                Map<Long, String> definiteTask = taskDefinitionLogs.stream().filter(log -> !log.getTaskType().equals(TaskConstants.TASK_TYPE_SUB_PROCESS)","[{'comment': 'Why filter these logic tasks?', 'commenter': 'caishunfeng'}]"
11204,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/utils/DependentExecute.java,"@@ -129,51 +140,87 @@ private DependResult calculateResultForTasks(DependentItem dependentItem,
 
     /**
      * depend type = depend_all
-     *
-     * @return
      */
-    private DependResult dependResultByProcessInstance(ProcessInstance processInstance) {
-        if (!processInstance.getState().isFinished()) {
-            return DependResult.WAITING;
-        }
+    private DependResult dependResultByProcessInstance(ProcessInstance processInstance, DateInterval dateInterval) {
         if (processInstance.getState().isSuccess()) {
+            List<ProcessTaskRelation> taskRelations = processService.findRelationByCode(processInstance.getProcessDefinitionCode(),
+                processInstance.getProcessDefinitionVersion());
+            if (!taskRelations.isEmpty()) {
+                List<TaskDefinitionLog> taskDefinitionLogs = processService.genTaskDefineList(taskRelations);
+                Map<Long, String> definiteTask = taskDefinitionLogs.stream().filter(log -> !log.getTaskType().equals(TaskConstants.TASK_TYPE_SUB_PROCESS)
+                        || !log.getTaskType().equals(TaskConstants.TASK_TYPE_DEPENDENT)
+                        || !log.getTaskType().equals(TaskConstants.TASK_TYPE_CONDITIONS))
+                    .filter(log -> log.getFlag().equals(Flag.YES))
+                    .collect(Collectors.toMap(TaskDefinition::getCode, TaskDefinitionLog::getName));
+                if (!definiteTask.isEmpty()) {
+                    List<TaskInstance> taskInstanceList = processService.findLastTaskInstanceListInterval(definiteTask.keySet(), dateInterval);
+                    if (taskInstanceList.isEmpty()) {
+                        logger.warn(""Cannot find the task instance: {}"", JSONUtils.toJsonString(definiteTask));
+                        return DependResult.FAILED;
+                    }
+                    Map<Long, TaskInstance> taskInstanceMap = new HashMap<>();
+                    for (TaskInstance instance : taskInstanceList) {
+                        taskInstanceMap.compute(instance.getTaskCode(), (k, v) -> {
+                            if (v == null) {
+                                v = instance;
+                            } else {
+                                if (v.getId() < instance.getId()) {
+                                    v = instance;
+                                }
+                            }
+                            return v;
+                        });
+                        definiteTask.remove(instance.getTaskCode());
+                    }","[{'comment': 'What is the point of this part?', 'commenter': 'caishunfeng'}]"
11204,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/utils/DependentExecute.java,"@@ -129,51 +140,87 @@ private DependResult calculateResultForTasks(DependentItem dependentItem,
 
     /**
      * depend type = depend_all
-     *
-     * @return
      */
-    private DependResult dependResultByProcessInstance(ProcessInstance processInstance) {
-        if (!processInstance.getState().isFinished()) {
-            return DependResult.WAITING;
-        }
+    private DependResult dependResultByProcessInstance(ProcessInstance processInstance, DateInterval dateInterval) {
         if (processInstance.getState().isSuccess()) {
+            List<ProcessTaskRelation> taskRelations = processService.findRelationByCode(processInstance.getProcessDefinitionCode(),","[{'comment': 'The workflow dependent only need check the process instance state.\r\nThere are scenarios in which only some tasks are run, resulting in a successful workflow.', 'commenter': 'lenboo'}]"
11235,dolphinscheduler-ui/src/views/projects/workflow/definition/components/start-modal.tsx,"@@ -255,6 +255,18 @@ export default defineComponent({
               </NSpace>
             </NRadioGroup>
           </NFormItem>
+          <NFormItem
+            label={t('project.workflow.node_execution')}
+            path='taskDependType'
+          >
+            <NRadioGroup v-model:value={this.startForm.taskDependType}>
+              <NSpace>
+                <NRadio value='TASK_POST'>{t('project.workflow.backward_execution')}</NRadio>
+                <NRadio value='TASK_PRE'>{t('project.workflow.forward_execution')}</NRadio>
+                <NRadio value='TASK_ONLY'>{t('project.workflow.current_node_execution')}</NRadio>
+              </NSpace>
+            </NRadioGroup>
+          </NFormItem>","[{'comment': ""It's should set the default value for the taskDependType in startForm."", 'commenter': 'Amy0104'}, {'comment': 'This is my mistake. It has been set before.', 'commenter': 'Amy0104'}]"
11272,style/license-header,"@@ -0,0 +1,17 @@
+/*","[{'comment': 'We already use skywalking-eyes to check the license header, is this needed? this will only check the java code? or all files.', 'commenter': 'ruanwenjun'}, {'comment': ""I'm not sure whether `skywalking-eyes` could add the license header for users or not. `Spotless` could automatically add it if there is no license header."", 'commenter': 'EricGao888'}, {'comment': 'Skywalking-eyes will only check if the file contains license header, does Spotless will add license header in all files?\r\nWe need to filter some `md`, `json` file.', 'commenter': 'ruanwenjun'}, {'comment': 'Sure, I will check it to make sure `md` and `json` excluded.', 'commenter': 'EricGao888'}, {'comment': ""> I'm not sure whether `skywalking-eyes` could add the license header for users or not. `Spotless` could automatically add it if there is no license header.\n\nLicense eye can add license headers and it deals with all files. I think spotless only deals with the files within maven project's files?\n Anyway I don't think we should have two tools to do the same thing"", 'commenter': 'kezhenxu94'}, {'comment': 'Got it, will remove it in the next commit.', 'commenter': 'EricGao888'}]"
11272,style/spotless_dolphinscheduler_formatter.xml,"@@ -0,0 +1,51 @@
+<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>
+<!--
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+-->
+<profiles version=""13"">
+    <profile kind=""CodeFormatterProfile"" name=""'DolphinScheduler Apache Current'"" version=""13"">
+        <setting id=""org.eclipse.jdt.core.compiler.source"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.compiler.compliance"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.compiler.codegen.targetPlatform"" value=""1.8"" />","[{'comment': 'Are these property needed?', 'commenter': 'ruanwenjun'}, {'comment': 'Will double check it. Thx', 'commenter': 'EricGao888'}, {'comment': ""I've found an example here, but I haven't figured out how `org.eclipse.jdt.core.compiler.xxx` affects `spotless`. https://github.com/google/styleguide/blob/gh-pages/eclipse-java-google-style.xml"", 'commenter': 'EricGao888'}]"
11272,style/spotless_dolphinscheduler_formatter.xml,"@@ -0,0 +1,51 @@
+<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>
+<!--
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+-->
+<profiles version=""13"">
+    <profile kind=""CodeFormatterProfile"" name=""'DolphinScheduler Apache Current'"" version=""13"">
+        <setting id=""org.eclipse.jdt.core.compiler.source"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.compiler.compliance"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.compiler.codegen.targetPlatform"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.formatter.indent_empty_lines"" value=""true"" />
+        <setting id=""org.eclipse.jdt.core.formatter.tabulation.size"" value=""4"" />
+        <setting id=""org.eclipse.jdt.core.formatter.lineSplit"" value=""200"" />","[{'comment': '200 is too long', 'commenter': 'ruanwenjun'}, {'comment': 'Sure, will decrease the number.', 'commenter': 'EricGao888'}]"
11272,style/spotless_dolphinscheduler_formatter.xml,"@@ -0,0 +1,51 @@
+<?xml version=""1.0"" encoding=""UTF-8"" standalone=""no""?>
+<!--
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+-->
+<profiles version=""13"">
+    <profile kind=""CodeFormatterProfile"" name=""'DolphinScheduler Apache Current'"" version=""13"">
+        <setting id=""org.eclipse.jdt.core.compiler.source"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.compiler.compliance"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.compiler.codegen.targetPlatform"" value=""1.8"" />
+        <setting id=""org.eclipse.jdt.core.formatter.indent_empty_lines"" value=""true"" />","[{'comment': 'This conflicts with the current style and most IDE settings. Most IDEs trim the blank lines when saving', 'commenter': 'kezhenxu94'}, {'comment': 'Thx, will set it to false.', 'commenter': 'EricGao888'}]"
11272,docs/docs/en/development/development-environment-setup.md,"@@ -19,14 +19,28 @@ cd dolphinscheduler
 git clone git@github.com:apache/dolphinscheduler.git
 ```
 
-### compile source code
+### Compile Source Code
 
 Supporting system:
 * MacOS
 * Liunx
 
 Run `mvn clean install -Prelease -Dmaven.test.skip=true`
 
+### Code Style
+
+DolphinScheduler uses `Spotless` for code style and formatting checks.
+You could run the following command and `Spotless` will automatically fix 
+the code style and formatting errors for you:
+
+```shell
+mvn spotless:apply","[{'comment': 'Prefer `./mvnw`\r\n```suggestion\r\n./mvnw spotless:apply\r\n```', 'commenter': 'kezhenxu94'}]"
11272,style/pre-commit,"@@ -0,0 +1,20 @@
+#!/bin/sh
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+# A hook script to automatically fix code style and formatting errors with spotless
+mvn spotless:apply","[{'comment': ""Prefer `.mvnw`\r\n\r\n```suggestion\r\n./mvnw spotless:apply\r\n```\r\n\r\nThis is not a correct hook. A check hook should prevent the commit if the codes style conflict with the rules but it just fix the codestyle and let the commit succeeds. If the developers think the commit succeeds and then `git push`, the bad style codes are still pushed, leaving the fixed one locally. You can try modify some codes to bad style and try `git add . && git commit -m'Test'`, everything is going to succeed and if you then `git push`, you might don't know the hook script helped you fixed the codes and you might be curious why there are uncommitted codes.\r\n\r\n\r\nTry mine here 👇\r\n\r\n```suggestion\r\nif ./mvnw spotless:check; then\r\n  exit 0\r\nfi\r\n\r\n./mvnw spotless:apply\r\n\r\nexit 1\r\n```"", 'commenter': 'kezhenxu94'}, {'comment': ""Oh thx for pointing this out, it's my first time to write a pre-commit hook. I will try your suggestions : )"", 'commenter': 'EricGao888'}]"
11272,.github/actions/sanity-check/action.yml,"@@ -39,7 +39,7 @@ runs:
         reviewdog_version: v0.10.2
 
     - shell: bash
-      run: ./mvnw -B -q checkstyle:checkstyle-aggregate
+      run: ./mvnw spotless:check","[{'comment': ""Remove the next step and review dog submodule, now we don't have checkstyle result to perform review dog."", 'commenter': 'kezhenxu94'}]"
11329,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/DataSourceUser.java,"@@ -58,4 +58,64 @@ public class DatasourceUser {
      * update time
      */
     private Date updateTime;
+
+    public int getId() {
+        return id;
+    }
+
+    public void setId(int id) {
+        this.id = id;
+    }
+
+    public int getUserId() {
+        return userId;
+    }
+
+    public void setUserId(int userId) {
+        this.userId = userId;
+    }
+
+    public int getDataSourceId() {
+        return datasourceId;
+    }
+
+    public void setDataSourceId(int datasourceId) {
+        this.datasourceId = datasourceId;
+    }
+
+    public int getPerm() {
+        return perm;
+    }
+
+    public void setPerm(int perm) {
+        this.perm = perm;
+    }
+
+    public Date getCreateTime() {
+        return createTime;","[{'comment': ""You don't need to add `get`, `set` and `toString` method. "", 'commenter': 'ruanwenjun'}, {'comment': 'OK', 'commenter': 'ChrisYuan'}]"
11329,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/main/java/org/apache/dolphinscheduler/plugin/task/sqoop/parameter/SqoopParameters.java,"@@ -223,13 +223,13 @@ public ResourceParametersHelper getResources() {
         }
 
         SourceMysqlParameter sourceMysqlParameter = JSONUtils.parseObject(this.getSourceParams(), SourceMysqlParameter.class);
-        if (sourceMysqlParameter.getSrcDatasource() != 0) {
-            resources.put(ResourceType.DATASOURCE, sourceMysqlParameter.getSrcDatasource());
+        if (sourceMysqlParameter.getSrcDataSource() != 0) {
+            resources.put(ResourceType.DATASOURCE, sourceMysqlParameter.getSrcDataSource());
         }
 
         TargetMysqlParameter targetMysqlParameter = JSONUtils.parseObject(this.getTargetParams(), TargetMysqlParameter.class);
-        if (targetMysqlParameter.getTargetDatasource() != 0) {
-            resources.put(ResourceType.DATASOURCE, targetMysqlParameter.getTargetDatasource());
+        if (targetMysqlParameter.getTargetDataSource() != 0) {
+            resources.put(ResourceType.DATASOURCE, targetMysqlParameter.getTargetDataSource());","[{'comment': ""You can't do this change directly, this will bring an upgrade issue, the parameter has been store at database, user need to refresh their history data  in database."", 'commenter': 'ruanwenjun'}]"
11372,dolphinscheduler-ui/src/views/projects/workflow/definition/components/start-modal.tsx,"@@ -144,6 +147,11 @@ export default defineComponent({
       }
     ]
 
+    const showTaskDependType = computed(() =>
+      (route.name === 'workflow-definition-detail' ||
+        route.name === 'workflow-instance-detail')
+    )
+","[{'comment': 'Is this only displayed on page workflow definition detail? because the start action is not supported on workflow instance detail page.', 'commenter': 'Amy0104'}, {'comment': ""> Is this only displayed on page workflow definition detail? because the start action is not supported on workflow instance detail page.\r\n\r\nOk, i'll make some changes"", 'commenter': 'sketchmind'}]"
11393,.github/workflows/cluster-test/mysql/dolphinscheduler_env.sh,"@@ -15,6 +15,9 @@
 # limitations under the License.
 #
 
+# Load system configuration
+source /etc/profile","[{'comment': ""I think it's not a good idea since this may destroy the user's environment variables. cc @EricGao888 @zhongjiajie @ruanwenjun "", 'commenter': 'SbloodyS'}, {'comment': ""I don't like the idea to `source /etc/profile` either. Some users may put their real `profile` files in a different path, in that case, `source /etc/profile` may cause some big trouble."", 'commenter': 'EricGao888'}, {'comment': ""> I think it's not a good idea since this may destroy the user's environment variables. cc @EricGao888 @zhongjiajie @ruanwenjun\r\n\r\nThe user environment variable is configured after this command, and the increment or update configuration operation will still follow the user configuration requirements."", 'commenter': 'insist777'}, {'comment': ""> I don't like the idea to `source /etc/profile` either. Some users may put their real `profile` files in a different path, in that case, `source /etc/profile` may cause some big trouble.\r\n\r\nThe default path is / etc / profile. The user needs to change the corresponding source file address when storing in other places. Therefore, relevant comments are given to load the system environment variable configuration"", 'commenter': 'insist777'}, {'comment': ""> > I think it's not a good idea since this may destroy the user's environment variables. cc @EricGao888 @zhongjiajie @ruanwenjun\r\n> \r\n> The user environment variable is configured after this command, and the increment or update configuration operation will still follow the user configuration requirements.\r\n\r\nIf user want to customize environment variables. they can add them in `dolphinscheduler_env.sh` or in the environment management of the UI interface. However, we do not recommend hardcode the `source /etc/profile`.\r\n\r\n"", 'commenter': 'SbloodyS'}, {'comment': '> \r\n\r\nAfter testing, I found that this did not affect', 'commenter': 'insist777'}, {'comment': 'But there is a bug:\r\n`export JAVA_HOME=${JAVA_HOME:-/usr/local/openjdk-8}`\r\nWe want to use the system environment variables, but it does not work in reality.\r\nHow we can get the system environment without `source /etc/profile` ?\r\n\r\n', 'commenter': 'lenboo'}, {'comment': 'For example. In AWS EMR, if a non root user and a non system installation user such as `ubuntu/hadoop/ec2-user` are used to execute the `source /etc/profile` command. It will directly lead to the `hive/flink/spark` cli no such file exception.', 'commenter': 'SbloodyS'}, {'comment': ""@SbloodyS \r\nSo, what's your suggestions about this issue?"", 'commenter': 'lenboo'}, {'comment': ""> @SbloodyS So, what's your suggestions about this issue?\r\n\r\nI think the current `export JAVA_HOME=${JAVA_HOME:-/usr/local/openjdk-8}` a is a good solution for manual configuration. If the user's image does not contain global `JAVA_HOME`. It should only be configured manually by the user or find the operations engineer to optimize the basic image.\r\n\r\n"", 'commenter': 'SbloodyS'}, {'comment': ""> > @SbloodyS So, what's your suggestions about this issue?\r\n> \r\n> I think the current a is a good solution for manual configuration. If the user's image does not contain global . It should only be configured manually by the user or find the operations engineer to optimize the basic image.`export JAVA_HOME=${JAVA_HOME:-/usr/local/openjdk-8}``JAVA_HOME`\r\n\r\nIn order to obtain system variables, source / etc / profile can solve this problem. Export Java_ Home = ${java_home: - / usr / local / openjdk-8} after source, which means that when Java does not exist in the system variable_ When home, the specified file is used. If the system variable has been configured, the system configured variable is used."", 'commenter': 'insist777'}, {'comment': ""i think so, and the environment variables do not only exist in the /etc/profile file, I think the specificity of the worker host should be ignored, which can enhance the user's autonomy"", 'commenter': 'DarkAssassinator'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -72,6 +75,12 @@ public class TaskPriorityQueueConsumer extends BaseDaemonThread {
     @Autowired
     private TaskPriorityQueue<TaskPriority> taskPriorityQueue;
 
+    /**
+     * task failed queue
+     */
+    @Autowired
+    private TaskPriorityQueue<TaskPriority> taskPriorityDispatchFailedQueue;","[{'comment': 'This bean is the same with `taskPriorityQueue`, you need to create a new block queue here.', 'commenter': 'ruanwenjun'}, {'comment': 'Yes, I will add the implementation of the failure queue under queue.', 'commenter': 'WangJPLeo'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -176,6 +203,41 @@ public List<TaskPriority> batchDispatch(int fetchTaskNum) throws TaskPriorityQue
         return failedDispatchTasks;
     }
 
+    /**
+     * put the failed dispatch task into the dispatch queue again
+     */
+    private void dispatchFailedBackToTaskPriorityQueue(int fetchTaskNum) throws TaskPriorityQueueException, InterruptedException {
+        try {
+            for (int i = 0; i < fetchTaskNum; i++) {
+                TaskPriority dispatchFailedTaskPriority = taskPriorityDispatchFailedQueue.poll(Constants.SLEEP_TIME_MILLIS, TimeUnit.MILLISECONDS);
+                if (Objects.isNull(dispatchFailedTaskPriority)){
+                    continue;
+                }
+                if (canRetry(dispatchFailedTaskPriority)){
+                    dispatchFailedTaskPriority.setDispatchFailedRetryTimes(dispatchFailedTaskPriority.getDispatchFailedRetryTimes() + 1);
+                    taskPriorityQueue.put(dispatchFailedTaskPriority);
+                } else {
+                    taskPriorityDispatchFailedQueue.put(dispatchFailedTaskPriority);","[{'comment': 'If can not retry, I think it should be removed from fail queue, otherwise this fail queue will keep growing and not release.', 'commenter': 'caishunfeng'}, {'comment': '1. When the task is taken out of the failure queue and placed in the dispatch queue, it will not be put into the failure queue again if the execution is successful.\r\n2. We guarantee that tasks can always be retried in case of failure.', 'commenter': 'WangJPLeo'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -176,6 +203,41 @@ public List<TaskPriority> batchDispatch(int fetchTaskNum) throws TaskPriorityQue
         return failedDispatchTasks;
     }
 
+    /**
+     * put the failed dispatch task into the dispatch queue again
+     */
+    private void dispatchFailedBackToTaskPriorityQueue(int fetchTaskNum) throws TaskPriorityQueueException, InterruptedException {
+        try {
+            for (int i = 0; i < fetchTaskNum; i++) {
+                TaskPriority dispatchFailedTaskPriority = taskPriorityDispatchFailedQueue.poll(Constants.SLEEP_TIME_MILLIS, TimeUnit.MILLISECONDS);
+                if (Objects.isNull(dispatchFailedTaskPriority)){
+                    continue;
+                }
+                if (canRetry(dispatchFailedTaskPriority)){
+                    dispatchFailedTaskPriority.setDispatchFailedRetryTimes(dispatchFailedTaskPriority.getDispatchFailedRetryTimes() + 1);
+                    taskPriorityQueue.put(dispatchFailedTaskPriority);
+                } else {
+                    taskPriorityDispatchFailedQueue.put(dispatchFailedTaskPriority);
+                }
+            }
+        } catch (Exception e) {
+            logger.error(""dispatch failed back to task priority queue error"", e);
+        }
+    }
+
+    /**
+     * the time interval is adjusted according to the number of retries
+     */
+    private boolean canRetry (TaskPriority taskPriority){
+        int dispatchFailedRetryTimes = taskPriority.getDispatchFailedRetryTimes();
+        long now = System.currentTimeMillis();
+        // retry more than 100 times with 100 seconds delay each time
+        if (dispatchFailedRetryTimes >= Constants.DEFAULT_MAX_RETRY_COUNT){
+            return now - taskPriority.getLastDispatchTime() >= TIME_DELAY[Constants.DEFAULT_MAX_RETRY_COUNT];","[{'comment': 'will it out of bounds if use `TIME_DELAY[Constants.DEFAULT_MAX_RETRY_COUNT]`?', 'commenter': 'caishunfeng'}, {'comment': 'No, the number of retries will exceed the length of the array, and when it exceeds, the value of the last element of the array will be used as the time interval.', 'commenter': 'WangJPLeo'}, {'comment': 'What I mean is that the last one is `TIME_DELAY[Constants.DEFAULT_MAX_RETRY_COUNT-1]`, not `TIME_DELAY[Constants.DEFAULT_MAX_RETRY_COUNT]`', 'commenter': 'caishunfeng'}, {'comment': 'Forgot to initialize the start value, thanks a lot.', 'commenter': 'WangJPLeo'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -151,6 +173,10 @@ public List<TaskPriority> batchDispatch(int fetchTaskNum) throws TaskPriorityQue
         List<TaskPriority> failedDispatchTasks = Collections.synchronizedList(new ArrayList<>());
         CountDownLatch latch = new CountDownLatch(fetchTaskNum);
 
+        if (taskPriorityDispatchFailedQueue.size() > 0) {
+            dispatchFailedBackToTaskPriorityQueue(fetchTaskNum);","[{'comment': 'Will it take affect to the performance if handle in the same thread? ', 'commenter': 'caishunfeng'}, {'comment': 'It would be better to have a separate thread for the failed queue retry.', 'commenter': 'WangJPLeo'}, {'comment': 'The default task scheduling thread pool size is 2, which ensures that the processing in the failure queue and the scheduling queue do not affect each other.\r\nIn other cases add the default scheduling thread pool size +1.', 'commenter': 'WangJPLeo'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskPriorityQueueConsumer.java,"@@ -151,6 +173,10 @@ public List<TaskPriority> batchDispatch(int fetchTaskNum) throws TaskPriorityQue
         List<TaskPriority> failedDispatchTasks = Collections.synchronizedList(new ArrayList<>());
         CountDownLatch latch = new CountDownLatch(fetchTaskNum);
 
+        if (!taskDispatchFailedQueue.isEmpty()) {
+            consumerThreadPoolExecutor.submit(() -> dispatchFailedBackToTaskPriorityQueue(fetchTaskNum));
+        }","[{'comment': ""It's not good idea to consume the failed queue in the normal process.\r\n\r\nBTW, this will cause the thread busy, or OOM in consumerThreadPoolExecutor, since  you didn't wait the current batch task finished.\r\n"", 'commenter': 'ruanwenjun'}, {'comment': 'Understood, I changed the processing location of the failed queue.', 'commenter': 'WangJPLeo'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskDispatchFailedQueueConsumer.java,"@@ -0,0 +1,149 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.consumer;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.lifecycle.ServerLifeCycleManager;
+import org.apache.dolphinscheduler.common.thread.BaseDaemonThread;
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.server.master.config.MasterConfig;
+import org.apache.dolphinscheduler.server.master.metrics.TaskMetrics;
+import org.apache.dolphinscheduler.service.exceptions.TaskPriorityQueueException;
+import org.apache.dolphinscheduler.service.queue.TaskPriority;
+import org.apache.dolphinscheduler.service.queue.TaskPriorityQueue;
+import org.apache.dolphinscheduler.service.queue.TaskPriorityQueueImpl;
+
+import java.util.Objects;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Qualifier;
+import org.springframework.stereotype.Component;
+
+@Component
+public class TaskDispatchFailedQueueConsumer extends BaseDaemonThread {
+
+    private static final Logger logger = LoggerFactory.getLogger(TaskDispatchFailedQueueConsumer.class);
+
+    /**
+     * taskPriorityQueue
+     */
+    @Autowired
+    @Qualifier(Constants.TASK_PRIORITY_QUEUE)
+    private TaskPriorityQueue<TaskPriority> taskPriorityQueueImpl;
+
+    /**
+     * taskDispatchFailedQueue
+     */
+    @Autowired
+    @Qualifier(Constants.TASK_DISPATCH_FAILED_QUEUE)
+    private TaskPriorityQueue<TaskPriority> taskDispatchFailedQueueImpl;
+
+    @Autowired
+    private MasterConfig masterConfig;
+
+    private ThreadPoolExecutor retryConsumerThreadPoolExecutor;
+
+    /**
+     * delay time for retries
+     */
+    private static final Long[] TIME_DELAY;
+
+    /**
+     * initialization failure retry delay rule
+     */
+    static {
+        TIME_DELAY = new Long[Constants.DEFAULT_MAX_RETRY_COUNT];
+        for (int i = 0; i < Constants.DEFAULT_MAX_RETRY_COUNT; i++) {
+            int delayTime = (i + 1) * 1000;
+            TIME_DELAY[i] = (long) delayTime;
+        }
+    }
+
+    protected TaskDispatchFailedQueueConsumer() {
+        super(""TaskDispatchFailedQueueConsumerThread"");
+    }
+
+    @PostConstruct
+    public void init() {
+        this.retryConsumerThreadPoolExecutor = (ThreadPoolExecutor) ThreadUtils
+                .newDaemonFixedThreadExecutor(""TaskDispatchFailedQueueConsumerThread"", masterConfig.getDispatchTaskNumber());
+        super.start();
+    }
+
+    @Override
+    public void run() {
+        while (!ServerLifeCycleManager.isStopped()) {
+            try {
+                failedRetry();
+            } catch (Exception e) {
+                TaskMetrics.incTaskDispatchError();
+                logger.error(""failed task retry error"", e);
+            }
+        }
+    }
+
+    public void failedRetry() throws TaskPriorityQueueException {
+        if (taskDispatchFailedQueueImpl.size() > 0) {
+            retryConsumerThreadPoolExecutor.submit(() -> dispatchFailedBackToTaskPriorityQueue(masterConfig.getDispatchTaskNumber()));
+        }
+    }","[{'comment': 'This will cause OOM, if the `taskDispatchFailedQueueImpl` is not empty, it will submit a lot of task... until the task be trigger\r\nAnd this is while (true), you need to add sleep, otherwise the CPU will go to 100%\r\n\r\nYou need to wait the before task finished, and then finish the current loop.', 'commenter': 'ruanwenjun'}, {'comment': 'Yes, thx, I will fix this.', 'commenter': 'WangJPLeo'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskDispatchFailedQueueConsumer.java,"@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.consumer;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.lifecycle.ServerLifeCycleManager;
+import org.apache.dolphinscheduler.common.thread.BaseDaemonThread;
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.server.master.config.MasterConfig;
+import org.apache.dolphinscheduler.server.master.metrics.TaskMetrics;
+import org.apache.dolphinscheduler.service.exceptions.TaskPriorityQueueException;
+import org.apache.dolphinscheduler.service.queue.TaskPriority;
+import org.apache.dolphinscheduler.service.queue.TaskPriorityQueue;
+
+import java.util.Objects;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Qualifier;
+import org.springframework.stereotype.Component;
+
+@Component
+public class TaskDispatchFailedQueueConsumer extends BaseDaemonThread {
+
+    private static final Logger logger = LoggerFactory.getLogger(TaskDispatchFailedQueueConsumer.class);
+
+    /**
+     * taskPriorityQueue
+     */
+    @Autowired
+    @Qualifier(Constants.TASK_PRIORITY_QUEUE)
+    private TaskPriorityQueue<TaskPriority> taskPriorityQueueImpl;
+
+    /**
+     * taskDispatchFailedQueue
+     */
+    @Autowired
+    @Qualifier(Constants.TASK_DISPATCH_FAILED_QUEUE)
+    private TaskPriorityQueue<TaskPriority> taskDispatchFailedQueueImpl;
+
+    @Autowired
+    private MasterConfig masterConfig;
+
+    private ThreadPoolExecutor retryConsumerThreadPoolExecutor;
+
+    /**
+     * delay time for retries
+     */
+    private static final Long[] TIME_DELAY;
+
+    /**
+     * initialization failure retry delay rule
+     */
+    static {
+        TIME_DELAY = new Long[Constants.DEFAULT_MAX_RETRY_COUNT];
+        for (int i = 0; i < Constants.DEFAULT_MAX_RETRY_COUNT; i++) {
+            int delayTime = (i + 9) * 1000;
+            TIME_DELAY[i] = (long) delayTime;
+        }
+    }
+
+    protected TaskDispatchFailedQueueConsumer() {
+        super(""TaskDispatchFailedQueueConsumerThread"");
+    }
+
+    @PostConstruct
+    public void init() {
+        this.retryConsumerThreadPoolExecutor = (ThreadPoolExecutor) ThreadUtils
+                .newDaemonFixedThreadExecutor(""TaskDispatchFailedQueueConsumerThread"", masterConfig.getDispatchTaskNumber());
+        super.start();
+    }
+
+    @Override
+    public void run() {
+        while (!ServerLifeCycleManager.isStopped()) {
+            try {
+                failedRetry();
+            } catch (Exception e) {
+                TaskMetrics.incTaskDispatchError();
+                logger.error(""failed task retry error"", e);
+            } finally {
+                ThreadUtils.sleep(Constants.SLEEP_TIME_MILLIS * 10L);","[{'comment': '```suggestion\r\n                ThreadUtils.sleep(Constants.SLEEP_TIME_MILLIS);\r\n```', 'commenter': 'caishunfeng'}]"
11464,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/consumer/TaskDispatchFailedQueueConsumer.java,"@@ -0,0 +1,150 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.server.master.consumer;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.lifecycle.ServerLifeCycleManager;
+import org.apache.dolphinscheduler.common.thread.BaseDaemonThread;
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.server.master.config.MasterConfig;
+import org.apache.dolphinscheduler.server.master.metrics.TaskMetrics;
+import org.apache.dolphinscheduler.service.exceptions.TaskPriorityQueueException;
+import org.apache.dolphinscheduler.service.queue.TaskPriority;
+import org.apache.dolphinscheduler.service.queue.TaskPriorityQueue;
+
+import java.util.Objects;
+import java.util.concurrent.ThreadPoolExecutor;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.PostConstruct;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Qualifier;
+import org.springframework.stereotype.Component;
+
+@Component
+public class TaskDispatchFailedQueueConsumer extends BaseDaemonThread {
+
+    private static final Logger logger = LoggerFactory.getLogger(TaskDispatchFailedQueueConsumer.class);
+
+    /**
+     * taskPriorityQueue
+     */
+    @Autowired
+    @Qualifier(Constants.TASK_PRIORITY_QUEUE)
+    private TaskPriorityQueue<TaskPriority> taskPriorityQueueImpl;
+
+    /**
+     * taskDispatchFailedQueue
+     */
+    @Autowired
+    @Qualifier(Constants.TASK_DISPATCH_FAILED_QUEUE)
+    private TaskPriorityQueue<TaskPriority> taskDispatchFailedQueueImpl;
+
+    @Autowired
+    private MasterConfig masterConfig;
+
+    private ThreadPoolExecutor retryConsumerThreadPoolExecutor;
+
+    /**
+     * delay time for retries
+     */
+    private static final Long[] TIME_DELAY;
+
+    /**
+     * initialization failure retry delay rule
+     */
+    static {
+        TIME_DELAY = new Long[Constants.DEFAULT_MAX_RETRY_COUNT];
+        for (int i = 0; i < Constants.DEFAULT_MAX_RETRY_COUNT; i++) {
+            int delayTime = (i + 9) * 1000;","[{'comment': '```suggestion\r\n            long delayTime = (i + 1) * Constant.SLEEP_TIME_MILLIS;\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'grateful.', 'commenter': 'WangJPLeo'}]"
11470,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/MasterSchedulerBootstrap.java,"@@ -232,6 +247,24 @@ private List<ProcessInstance> command2ProcessInstance(List<Command> commands) th
         return processInstances;
     }
 
+    private void sendRpcCommand(ProcessInstance processInstance) {","[{'comment': 'Suggest move this method in `handleCommand`, otherwise, we need to execute sendRpcCommand in all other place when we  execute handleCommand.\r\n\r\nWe can just split handleCommand into two method: `handleCommandInDB` and `sendRpcCommand`, handleCommandInDb can have transaction.', 'commenter': 'ruanwenjun'}, {'comment': 'Good idea, i will change it.', 'commenter': 'WangJPLeo'}]"
11504,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -973,17 +969,7 @@ public Map<String, Object> queryAllGeneralUsers(User loginUser) {
     public Map<String, Object> queryUserList(User loginUser) {
         Map<String, Object> result = new HashMap<>();
         //only admin can operate
-        if (!canOperatorPermissions(loginUser,null, AuthorizationType.ACCESS_TOKEN, USER_MANAGER)) {
-            putMsg(result, Status.USER_NO_OPERATION_PERM);
-            return result;
-        }
-
-        QueryWrapper<User> queryWrapper = new QueryWrapper<>();
-        queryWrapper.ge(""id"", 0);
-        if (loginUser.getUserType().equals(UserType.GENERAL_USER)) {
-            queryWrapper.eq(""id"", loginUser.getId());
-        }
-        List<User> userList = userMapper.selectList(null);
+        List<User> userList = userMapper.queryEnabledUsers();","[{'comment': 'This is unsafe, all user can query all other user information.', 'commenter': 'ruanwenjun'}, {'comment': 'Yes, restore previous permissions.', 'commenter': 'WangJPLeo'}]"
11509,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/SortEnum.java,"@@ -0,0 +1,26 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+
+package org.apache.dolphinscheduler.api.enums;
+
+public enum SortEnum {","[{'comment': 'no comments', 'commenter': 'lenboo'}]"
11509,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -491,6 +492,7 @@ public Result queryProcessDefinitionListPaging(@ApiIgnore @RequestAttribute(valu
                                                    @RequestParam(value = ""searchVal"", required = false) String searchVal,
                                                    @RequestParam(value = ""otherParamsJson"", required = false) String otherParamsJson,
                                                    @RequestParam(value = ""userId"", required = false, defaultValue = ""0"") Integer userId,
+                                                   @RequestParam(value = ""sortEnum"", required = false) SortEnum sortType,","[{'comment': 'add default value', 'commenter': 'lenboo'}]"
11509,dolphinscheduler-standalone-server/src/main/resources/logback-spring.xml,"@@ -78,6 +78,7 @@
                 <appender-ref ref=""STDOUT""/>
             </then>
         </if>
+        <appender-ref ref=""STDOUT""/>","[{'comment': 'remove this unused code', 'commenter': 'lenboo'}]"
11542,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/WorkerGroup.java,"@@ -92,16 +94,24 @@ public void setSystemDefault(boolean systemDefault) {
         this.systemDefault = systemDefault;
     }
 
+    public String getDescription() {
+        return description;
+    }
+
+    public void setDescription(String description) {
+        this.description = description;
+    }
+
     @Override
     public String toString() {
-        return ""WorkerGroup{""
-                + ""id= "" + id
-                + "", name= "" + name
-                + "", addrList= "" + addrList
-                + "", createTime= "" + createTime
-                + "", updateTime= "" + updateTime
-                + "", systemDefault= "" + systemDefault
-                + ""}"";
+        return ""WorkerGroup{"" +
+                ""id="" + id +
+                "", name='"" + name + '\'' +
+                "", addrList='"" + addrList + '\'' +
+                "", createTime="" + createTime +
+                "", updateTime="" + updateTime +
+                "", description='"" + description + '\'' +
+                "", systemDefault="" + systemDefault +
+                '}';","[{'comment': 'Please remove this and use Lombok.', 'commenter': 'ruanwenjun'}]"
11542,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -122,6 +123,7 @@ public Map<String, Object> saveWorkerGroup(User loginUser, int id, String name,
             return result;
         }
         if (workerGroup.getId() != 0) {
+            handleWorkGroup(workerGroup);","[{'comment': ""This is strange, I don't think we should add a handle method here, what the handle method means?"", 'commenter': 'ruanwenjun'}, {'comment': 'Persistent equal burial point\r\n\r\n', 'commenter': 'insist777'}]"
11542,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkerGroupController.java,"@@ -74,7 +74,8 @@ public class WorkerGroupController extends BaseController {
     @ApiImplicitParams({
         @ApiImplicitParam(name = ""id"", value = ""WORKER_GROUP_ID"", dataType = ""Int"", example = ""10"", defaultValue = ""0""),
         @ApiImplicitParam(name = ""name"", value = ""WORKER_GROUP_NAME"", required = true, dataType = ""String""),
-        @ApiImplicitParam(name = ""addrList"", value = ""WORKER_ADDR_LIST"", required = true, dataType = ""String"")
+        @ApiImplicitParam(name = ""addrList"", value = ""WORKER_ADDR_LIST"", required = true, dataType = ""String""),
+        @ApiImplicitParam(name = ""description"", value = ""WORKER_DESC"", required = true, dataType = ""String"")","[{'comment': 'required=false', 'commenter': 'lenboo'}]"
11542,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -304,6 +310,8 @@ private List<WorkerGroup> getWorkerGroups(boolean isPaging, List<Integer> ids) {
             if (childrenNodes == null || childrenNodes.isEmpty()) {
                 continue;
             }
+            WorkerGroup aDefault = workerGroups.stream().filter(a -> a.getAddrList().equals(""default"")).collect(Collectors.toList()).get(0);","[{'comment': 'This operation is not safe, I am not sure if the below code will return a empty list.\r\n```\r\nworkerGroups.stream().filter(a -> a.getAddrList().equals(""default"")).collect(Collectors.toList())\r\n```', 'commenter': 'ruanwenjun'}, {'comment': '```suggestion\r\n            WorkerGroup aDefault = workerGroups.stream().filter(a -> a.getAddrList().equals(""default"")).collect(Collectors.toList()).get(0);\r\n```\r\nPlease put this out of the for loop', 'commenter': 'ruanwenjun'}]"
11542,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -292,7 +298,10 @@ private List<WorkerGroup> getWorkerGroups(boolean isPaging, List<Integer> ids) {
             }
             return workerGroups;
         }
-
+        Map<String, WorkerGroup> collect = null;
+        if (workerGroups.size() != 0) { 
+            collect = workerGroups.stream().collect(Collectors.toMap(WorkerGroup::getName, a -> a, (k1, k2) -> k1));","[{'comment': 'a  ?  k1 ？ k2?', 'commenter': 'lenboo'}]"
11542,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -292,7 +298,10 @@ private List<WorkerGroup> getWorkerGroups(boolean isPaging, List<Integer> ids) {
             }
             return workerGroups;
         }
-
+        Map<String, WorkerGroup> workerGroupsMap = null;
+        if (workerGroups.size() != 0) {
+            workerGroupsMap = workerGroups.stream().collect(Collectors.toMap(WorkerGroup::getName, item -> item, (key, value) -> key));","[{'comment': 'key ? value ? ', 'commenter': 'lenboo'}]"
11542,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -305,19 +314,27 @@ private List<WorkerGroup> getWorkerGroups(boolean isPaging, List<Integer> ids) {
                 continue;
             }
             WorkerGroup wg = new WorkerGroup();
+            handleAddrList(wg, workerGroup, childrenNodes);
             wg.setName(workerGroup);
             if (isPaging) {
-                wg.setAddrList(String.join(Constants.COMMA, childrenNodes));
                 String registeredValue = registryClient.get(workerGroupPath + Constants.SINGLE_SLASH + childrenNodes.iterator().next());
                 HeartBeat heartBeat = HeartBeat.decodeHeartBeat(registeredValue);
                 wg.setCreateTime(new Date(heartBeat.getStartupTime()));
                 wg.setUpdateTime(new Date(heartBeat.getReportTime()));
                 wg.setSystemDefault(true);
+                if (workerGroupsMap != null && workerGroupsMap.get(workerGroup) != null) {","[{'comment': 'contains', 'commenter': 'lenboo'}]"
11542,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -210,11 +210,7 @@ public void run() {
                         String workerGroup = wg.getName();
                         Set<String> nodes = new HashSet<>();
                         String[] addrs = wg.getAddrList().split(Constants.COMMA);
-                        for (String addr : addrs) {
-                            if (newWorkerNodeInfo.containsKey(addr)) {
-                                nodes.add(addr);
-                            }
-                        }
+                        handleAddr(newWorkerNodeInfo, workerGroup, nodes, addrs);","[{'comment': 'nodes = handleAddr(registerWorkerNodeMap, wg)', 'commenter': 'lenboo'}]"
11542,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -227,6 +221,16 @@ public void run() {
         }
     }
 
+
+    protected void handleAddr(Map<String, String> newWorkerNodeInfo, WorkerGroup wg, Set<String> nodes) {
+        String[] addrs = wg.getAddrList().split(Constants.COMMA);
+        for (String addr : addrs) {
+            if (newWorkerNodeInfo.containsKey(addr)) {
+                nodes.add(addr);
+            }
+        }
+    }","[{'comment': ""it's better to rename this method to `protected Set<String> getNodeAddress(Map<String, String> newWorkerNodeInfo, WorkerGroup workgroup)`"", 'commenter': 'ruanwenjun'}]"
11560,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/test/java/org/apache/dolphinscheduler/plugin/task/sql/HiveSqlLogThreadTest.java,"@@ -0,0 +1,105 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.sql;
+
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.plugin.datasource.api.plugin.DataSourceClientProvider;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.DataSourceUtils;
+import org.apache.dolphinscheduler.plugin.datasource.hive.param.HiveConnectionParam;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.SqlParameters;
+import org.apache.dolphinscheduler.spi.datasource.BaseConnectionParam;
+import org.apache.dolphinscheduler.spi.datasource.ConnectionParam;
+import org.apache.dolphinscheduler.spi.enums.DbType;
+
+import org.apache.hadoop.security.UserGroupInformation;
+
+import java.io.IOException;
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.ResultSet;
+import java.sql.Statement;
+import java.util.concurrent.ExecutionException;
+
+import org.junit.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * hive sql listener test
+ */
+public class HiveSqlLogThreadTest {
+    private static final Logger LOGGER = LoggerFactory.getLogger(HiveSqlLogThreadTest.class);
+    @Test
+    public void testHiveSql() throws IOException, ClassNotFoundException, ExecutionException {
+        String taskJson=""{\""type\"":\""HIVE\"",\""datasource\"":1,\""sql\"":\""select count(*) from tmp.test_doris\"",\""udfs\"":\""\"",\""sqlType\"":\""0\"",\""sendEmail\"":false,\""displayRows\"":10,\""title\"":\""\"",\""groupId\"":null,\""localParams\"":[],\""connParams\"":\""\"",\""preStatements\"":[],\""postStatements\"":[],\""dependence\"":{},\""conditionResult\"":{\""successNode\"":[],\""failedNode\"":[]},\""waitStartTimeout\"":{},\""switchResult\"":{}}"";
+        TaskExecutionContext taskExecutionContext = new TaskExecutionContext();
+        taskExecutionContext.setTaskType(""hive"");
+        taskExecutionContext.setTaskParams(taskJson);
+        SqlParameters sqlParameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), SqlParameters.class);
+        assert sqlParameters != null;
+        String sql = sqlParameters.getSql();
+
+        String krb5FilePath =""/etc/krb5.conf"";
+        String krb5KeyTabPath =""/etc/vulcan.keytab"";
+        System.setProperty(""java.security.krb5.conf"", krb5FilePath);
+        System.setProperty(""sun.security.krb5.debug"", ""true"");
+        org.apache.hadoop.conf.Configuration configuration = new org.apache.hadoop.conf.Configuration();
+        configuration.set(""hadoop.security.authentication"", ""Kerberos"");
+        configuration.set(""keytab.file"", krb5KeyTabPath);
+        configuration.set(""kerberos.principal"", ""vulcan@BJ.BAIDU.COM"");
+
+        UserGroupInformation.setConfiguration(configuration);
+        UserGroupInformation.loginUserFromKeytab(""vulcan"", krb5KeyTabPath);
+
+        // 创建hive连接","[{'comment': 'Could u plz change this line of comment into English? The same for Line#91, thanks.', 'commenter': 'EricGao888'}, {'comment': 'ok ， i will Resubmit', 'commenter': 'fengjian1129'}]"
11589,dolphinscheduler-spi/src/main/java/org/apache/dolphinscheduler/spi/utils/StringUtils.java,"@@ -282,10 +284,17 @@ public static String replaceDoubleBrackets(String mainParameter) {
         mainParameter = mainParameter
                 .replace(Constants.DOUBLE_BRACKETS_LEFT, Constants.DOUBLE_BRACKETS_LEFT_SPACE)
                 .replace(Constants.DOUBLE_BRACKETS_RIGHT, Constants.DOUBLE_BRACKETS_RIGHT_SPACE);
-        if (mainParameter.contains(Constants.DOUBLE_BRACKETS_LEFT) || mainParameter.contains(Constants.DOUBLE_BRACKETS_RIGHT)) {
+        if (mainParameter.contains(Constants.DOUBLE_BRACKETS_LEFT)
+                || mainParameter.contains(Constants.DOUBLE_BRACKETS_RIGHT)) {
             return replaceDoubleBrackets(mainParameter);
         } else {
-            return  mainParameter;
+            return mainParameter;
         }
     }
+
+    public static String maskPassword(String originalString, String passwordRegex, String maskString) {","[{'comment': '```suggestion\r\n    public static String maskPassword(final String originalString, final String passwordRegex, final String maskString) {\r\n```', 'commenter': 'EricGao888'}]"
11589,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ShellCommandExecutor.java,"@@ -112,6 +118,10 @@ protected void createCommandFileIfNotExists(String execCommand, String commandFi
                     }
                 }
             }
+
+            if (execCommand.startsWith(""sqoop"")) {","[{'comment': 'May I ask whether we could do this with some other ways in `sqoop task plugin` instead of add a specific condition here for `sqoop`? ShellCommandExecutor is shared across different task plugins, it might not be a good practice and uneasy to maintain if we need to change it every time we need to mask something for a task plugin. The same for line 55-56.', 'commenter': 'EricGao888'}]"
11589,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/test/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopTaskTest.java,"@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.sqoop;
+
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+public class SqoopTaskTest {
+
+    @Test
+    public void testMaskPassword() {
+        String script =","[{'comment': '```suggestion\r\n        final String script =\r\n```', 'commenter': 'EricGao888'}]"
11589,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/src/test/java/org/apache/dolphinscheduler/plugin/task/sqoop/SqoopTaskTest.java,"@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.sqoop;
+
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+public class SqoopTaskTest {
+
+    @Test
+    public void testMaskPassword() {
+        String script =
+                ""sqoop import -D mapred.job.name=sqoop_task -m 1 --connect \""jdbc:mysql://localhost:3306/defuault\"" --username root --password \""mypassword\"" --table student --target-dir /sqoop_test --as-textfile"";
+        String scriptPasswordMasking =","[{'comment': '```suggestion\r\n        final String scriptPasswordMasking =\r\n```', 'commenter': 'EricGao888'}]"
11589,dolphinscheduler-task-plugin/dolphinscheduler-task-sqoop/pom.xml,"@@ -48,5 +48,10 @@
             <artifactId>dolphinscheduler-datasource-api</artifactId>
             <version>${project.version}</version>
         </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-service</artifactId>
+            <version>${project.version}</version>
+        </dependency>","[{'comment': 'I am not sure wether we should dependent `dolphinscheduler-service` in task plugin or not', 'commenter': 'zhongjiajie'}, {'comment': 'Do you have time to take a look @caishunfeng @ruanwenjun ', 'commenter': 'zhongjiajie'}, {'comment': '> I am not sure wether we should dependent `dolphinscheduler-service` in task plugin or not\r\n\r\nWe should not add the service module in task-plugin, they are independent.', 'commenter': 'caishunfeng'}, {'comment': 'Please remove this module in task-plugin.', 'commenter': 'caishunfeng'}, {'comment': '> Please remove this module in task-plugin.\r\n\r\nHi @caishunfeng , thanks for your comment. \r\n\r\nThis dependent is added in `dolphinscheudler-task-sqoop/pom.xml` since `sqoop` task needs to add its mask pattern through `SensitiveDataConverter.addMaskPattern()`, which is in `dolphinscheduler-service` module.\r\n\r\n<img width=""378"" alt=""截屏2022-11-22 15 32 05"" src=""https://user-images.githubusercontent.com/38122586/203252444-09914e7e-ffe1-4249-a3ed-4f55ab55547b.png"">\r\n\r\nIs your suggestion that we should move `SensitiveDataConverter` to another module? (maybe `dolphinscheduler-task-api`?)\r\n', 'commenter': 'rickchengx'}, {'comment': '>Is your suggestion that we should move SensitiveDataConverter to another module? (maybe dolphinscheduler-task-api?)\r\n\r\nYes, is it better to move it inito common module? WDYT?', 'commenter': 'caishunfeng'}, {'comment': ""> > Is your suggestion that we should move SensitiveDataConverter to another module? (maybe dolphinscheduler-task-api?)\r\n> \r\n> Yes, is it better to move it inito common module? WDYT?\r\n\r\nSure, thanks for your suggestion, I'll look into it."", 'commenter': 'rickchengx'}]"
11619,dolphinscheduler-dao/src/main/resources/sql/upgrade/2.0.0_schema/mysql/dolphinscheduler_ddl_post.sql,"@@ -0,0 +1,26 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+
+alter table t_ds_process_definition drop primary key, ADD PRIMARY KEY (`id`,`code`);","[{'comment': 'We should rename this file to `dolphinscheduler_ddl.sql`.', 'commenter': 'SbloodyS'}, {'comment': 'When upgrading 2.0, the function of this file is to delete the original index and create a new index after splitting the json. The upgrade program has always included this logic.', 'commenter': 'wangfann'}, {'comment': ""I don't quite understand what you mean. What I mean is rename this file."", 'commenter': 'SbloodyS'}, {'comment': ""![image](https://user-images.githubusercontent.com/6930421/190333180-a1c69925-954f-4421-8258-41a14716791d.png)\r\nA dolphinscheduler_ddl.sql file already exists,and they don't work the same way,this file needs to be executed after splitting the JSON."", 'commenter': 'wangfann'}]"
11668,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskKillProcessor.java,"@@ -94,8 +94,14 @@ public void process(Channel channel, Command command) {
         }
 
         int processId = taskExecutionContext.getProcessId();
-        if (processId == 0) {
-            this.cancelApplication(taskInstanceId);
+
+        // if processId > 0, it should call cancelApplication to cancel remote application too.","[{'comment': 'This comment seems no more useful here. We may just remove it.', 'commenter': 'EricGao888'}]"
11668,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskKillProcessor.java,"@@ -94,8 +94,14 @@ public void process(Channel channel, Command command) {
         }
 
         int processId = taskExecutionContext.getProcessId();
-        if (processId == 0) {
-            this.cancelApplication(taskInstanceId);
+
+        this.cancelApplication(taskInstanceId);
+
+        Pair<Boolean, List<String>> result = doKill(taskExecutionContext);","[{'comment': ""I don't think we need to do this change, if the task is execute in worker's thread, the processId is 0."", 'commenter': 'ruanwenjun'}, {'comment': '+1', 'commenter': 'caishunfeng'}]"
11668,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskKillProcessor.java,"@@ -95,8 +95,14 @@ public void process(Channel channel, Command command) {
         }
 
         int processId = taskExecutionContext.getProcessId();
-        if (processId == 0) {
-            this.cancelApplication(taskInstanceId);
+
+        this.cancelApplication(taskInstanceId);
+
+        Pair<Boolean, List<String>> result = doKill(taskExecutionContext);
+
+        // if processId = 0 and yarn application_id list is empty, the task has not been executed and has been cancelled.","[{'comment': ""```suggestion\r\n\r\n```\r\nIf the processId is 0, means the task doen't create a process."", 'commenter': 'ruanwenjun'}]"
11668,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskKillProcessor.java,"@@ -95,8 +95,14 @@ public void process(Channel channel, Command command) {
         }
 
         int processId = taskExecutionContext.getProcessId();
-        if (processId == 0) {
-            this.cancelApplication(taskInstanceId);
+
+        this.cancelApplication(taskInstanceId);
+
+        Pair<Boolean, List<String>> result = doKill(taskExecutionContext);
+
+        // if processId = 0 and yarn application_id list is empty, the task has not been executed and has been cancelled.
+
+        if (processId == 0 && result.getRight().isEmpty()) {","[{'comment': 'Please revert this, this will cause memory leak if the kill yarn failed.', 'commenter': 'ruanwenjun'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-form.ts,"@@ -137,24 +159,47 @@ export function useForm(id?: number) {
     } else {
       state.showPrincipal = false
     }
+    if (!state.detailForm.id) await getSameTypeTestDataSource()
   }
 
   const changePort = async () => {
     if (!state.detailForm.type) return
     const currentDataBaseOption = datasourceType[state.detailForm.type]
     currentDataBaseOption.previousPort = state.detailForm.port
   }
+  const changeTestFlag = async (testFlag: IDataBase) => {
+    if (testFlag) {
+      state.detailForm.bindTestId = undefined
+    }
+    if (state.detailForm.id) await getSameTypeTestDataSource()
+  }
+
+
+  const getSameTypeTestDataSource = async () => {
+    const params = { type: state.detailForm.type,testFlag: 1 } as TypeReq
+    const result = await queryDataSourceList(params)
+    state.bindTestDataSourceExample = result.map(
+        (TestDataSourceExample: { name: string; id: number }) => ({
+          label: TestDataSourceExample.name,
+          value: TestDataSourceExample.id
+        })
+    ).filter((value: { label: string; value: number }) => {
+      if (state.detailForm.id && state.detailForm.id === value.value) return false
+      return true
+    } )
+  }","[{'comment': 'It is better to filter first and then map.', 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-form.ts,"@@ -118,7 +124,23 @@ export function useForm(id?: number) {
             return new Error(t('datasource.jdbc_format_tips'))
           }
         }
+      },
+    testFlag: {
+      trigger: ['input'],
+      validator() {
+        if (state.detailForm.testFlag ===undefined) {","[{'comment': 'The empty value is not only undefined. So  it is better to take the opposite here.', 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-form.ts,"@@ -137,24 +159,47 @@ export function useForm(id?: number) {
     } else {
       state.showPrincipal = false
     }
+    if (!state.detailForm.id) await getSameTypeTestDataSource()
   }
 
   const changePort = async () => {
     if (!state.detailForm.type) return
     const currentDataBaseOption = datasourceType[state.detailForm.type]
     currentDataBaseOption.previousPort = state.detailForm.port
   }
+  const changeTestFlag = async (testFlag: IDataBase) => {
+    if (testFlag) {
+      state.detailForm.bindTestId = undefined
+    }
+    if (state.detailForm.id) await getSameTypeTestDataSource()
+  }
+
+
+  const getSameTypeTestDataSource = async () => {
+    const params = { type: state.detailForm.type,testFlag: 1 } as TypeReq
+    const result = await queryDataSourceList(params)
+    state.bindTestDataSourceExample = result.map(
+        (TestDataSourceExample: { name: string; id: number }) => ({
+          label: TestDataSourceExample.name,
+          value: TestDataSourceExample.id
+        })
+    ).filter((value: { label: string; value: number }) => {
+      if (state.detailForm.id && state.detailForm.id === value.value) return false
+      return true
+    } )
+  }
 
   const resetFieldsValue = () => {
     state.detailForm = { ...initialValues }
   }
 
-  const setFieldsValue = (values: IDataSource) => {
+  const setFieldsValue = async (values: IDataSource) => {
     state.detailForm = {
       ...state.detailForm,
       ...values,
       other: values.other ? JSON.stringify(values.other) : values.other
     }
+    await getSameTypeTestDataSource()","[{'comment': 'It seems to be no need to reload the test options  here.', 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-sqoop-datasource.ts,"@@ -18,8 +18,8 @@
 import { onMounted, ref, Ref } from 'vue'
 import { queryDataSourceList } from '@/service/modules/data-source'
 import { useI18n } from 'vue-i18n'
-import type { IJsonItem, IDataBase } from '../types'
-
+import { IJsonItem, IDataBase } from '../types'","[{'comment': ""If you're going to import a type, it's better to use 'import type'."", 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/projects/task/instance/use-table.ts,"@@ -116,6 +116,32 @@ export function useTable() {
         key: 'executorName',
         ...COLUMN_WIDTH_CONFIG['name']
       },
+      {
+        title: t('project.task.operating_environment'),
+        key: 'testFlag',
+        width: 160,
+        render: (row: IRecord) => {
+          if (row.testFlag===0) {
+            return h(
+                NTag,
+                { type: 'success', size: 'small' },
+                {
+                  default: () => t('project.task.on_line')
+                }
+            )
+          } else if(row.testFlag===1){
+            return h(
+                NTag,
+                { type: 'warning', size: 'small' },
+                {
+                  default: () => t('project.task.test')
+                }
+            )
+          }else {
+            return '-'
+          }
+        }
+      },","[{'comment': ""It's the same as the testFlag  of the datasource list. It is better to wrap it into a common hook."", 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/projects/workflow/instance/use-table.ts,"@@ -109,6 +111,33 @@ export function useTable() {
         className: 'workflow-status',
         render: (_row: IWorkflowInstance) => renderStateCell(_row.state, t)
       },
+      {
+        title: t('project.workflow.operating_environment'),
+        key: 'testFlag',
+        width: 160,
+        className: 'workflow-testFlag',
+        render: (_row: IWorkflowInstance) => {
+          if (_row.testFlag===0) {
+            return h(
+                NTag,
+                { type: 'success', size: 'small' },
+                {
+                  default: () => t('project.workflow.on_line')
+                }
+            )
+          } else if(_row.testFlag===1){
+            return h(
+                NTag,
+                { type: 'warning', size: 'small' },
+                {
+                  default: () => t('project.workflow.test')
+                }
+            )
+          }else {
+            return '-'
+          }","[{'comment': 'Same as above.', 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-columns.ts,"@@ -28,12 +28,13 @@ import {
 import { EditOutlined, DeleteOutlined } from '@vicons/antd'
 import JsonHighlight from './json-highlight'
 import ButtonLink from '@/components/button-link'
+import { IDataSource, TableColumns } from './types'","[{'comment': '`import type` is better than `import` here, and `import type` should be in the last line.', 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-form.ts,"@@ -27,7 +30,7 @@ import type {
   IDataSource
 } from './types'
 import utils from '@/utils'
-
+import { TypeReq } from '@/service/modules/data-source/types'","[{'comment': 'Same as above.', 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-form.ts,"@@ -118,6 +124,22 @@ export function useForm(id?: number) {
             return new Error(t('datasource.jdbc_format_tips'))
           }
         }
+      },
+      testFlag: {
+        trigger: ['input'],
+        validator() {
+          if (undefined === state.detailForm.testFlag) {
+            return new Error(t('datasource.datasource_test_flag_tips'))
+          }
+        }","[{'comment': ""For radios, it's better to set a default value."", 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-ui/src/views/datasource/list/use-form.ts,"@@ -137,24 +159,52 @@ export function useForm(id?: number) {
     } else {
       state.showPrincipal = false
     }
+    if (state.detailForm.id === undefined) {
+      await getSameTypeTestDataSource()","[{'comment': 'It seems to be no need to reload the test options here. The test options need to be reloaded only when the test flag is changed to 0.', 'commenter': 'Amy0104'}, {'comment': 'need', 'commenter': 'insist777'}, {'comment': 'To load when changing type.', 'commenter': 'insist777'}]"
11670,dolphinscheduler-ui/src/common/common.ts,"@@ -49,6 +50,31 @@ export const bytesToSize = (bytes: number) => {
   return parseFloat((bytes / Math.pow(k, i)).toPrecision(3)) + ' ' + sizes[i]
 }
 
+export function renderEnvironmentalDistinctionCell(
+  testFlag: number | undefined,
+  t: Function
+) {
+  if (testFlag === 0) {
+    return h(
+      NTag,
+      { type: 'success', size: 'small' },
+      {
+        default: () => t('datasource.on_line')
+      }
+    )
+  } else if (testFlag === 1) {
+    return h(
+      NTag,
+      { type: 'warning', size: 'small' },
+      {
+        default: () => t('datasource.test')
+      }
+    )
+  } else {
+    return '-'
+  }
+}
+","[{'comment': ""The common folder is used for configuration-related information. It's better to move it to the util folder by a separate file."", 'commenter': 'Amy0104'}]"
11670,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java,"@@ -148,23 +148,25 @@ public Result queryDataSource(@ApiIgnore @RequestAttribute(value = Constants.SES
     }
 
     /**
-     * query datasource by type
+     * query online/testDatasource by type
      *
      * @param loginUser login user
      * @param type data source type
      * @return data source list page
      */
     @ApiOperation(value = ""queryDataSourceList"", notes = ""QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES"")
     @ApiImplicitParams({
-            @ApiImplicitParam(name = ""type"", value = ""DB_TYPE"", required = true, dataType = ""DbType"")
+            @ApiImplicitParam(name = ""type"", value = ""DB_TYPE"", required = true, dataType = ""DbType""),
+            @ApiImplicitParam(name = ""testFlag"", value = ""DB_TEST_FLAG"", required = true, dataType = ""DbTestFlag"")
     })
     @GetMapping(value = ""/list"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(QUERY_DATASOURCE_ERROR)
     @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
     public Result queryDataSourceList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
-                                      @RequestParam(""type"") DbType type) {
-        Map<String, Object> result = dataSourceService.queryDataSourceList(loginUser, type.ordinal());
+                                      @RequestParam(""type"") DbType type,
+                                      @RequestParam(""testFlag"")int testFlag) {","[{'comment': 'missing spaces\r\n@RequestParam(""testFlag"") int testFlag', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/DataSourceController.java,"@@ -148,23 +148,25 @@ public Result queryDataSource(@ApiIgnore @RequestAttribute(value = Constants.SES
     }
 
     /**
-     * query datasource by type
+     * query online/testDatasource by type
      *
      * @param loginUser login user
      * @param type data source type
      * @return data source list page
      */
     @ApiOperation(value = ""queryDataSourceList"", notes = ""QUERY_DATA_SOURCE_LIST_BY_TYPE_NOTES"")
     @ApiImplicitParams({
-            @ApiImplicitParam(name = ""type"", value = ""DB_TYPE"", required = true, dataType = ""DbType"")
+            @ApiImplicitParam(name = ""type"", value = ""DB_TYPE"", required = true, dataType = ""DbType""),
+            @ApiImplicitParam(name = ""testFlag"", value = ""DB_TEST_FLAG"", required = true, dataType = ""DbTestFlag"")
     })
     @GetMapping(value = ""/list"")
     @ResponseStatus(HttpStatus.OK)
     @ApiException(QUERY_DATASOURCE_ERROR)
     @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
     public Result queryDataSourceList(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
-                                      @RequestParam(""type"") DbType type) {
-        Map<String, Object> result = dataSourceService.queryDataSourceList(loginUser, type.ordinal());
+                                      @RequestParam(""type"") DbType type,
+                                      @RequestParam(""testFlag"")int testFlag) {
+        Map<String, Object> result = dataSourceService.queryDataSourceList(loginUser, type.ordinal(),testFlag);","[{'comment': 'missing spaces\r\ntype.ordinal(), testFlag', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ExecutorService.java,"@@ -65,7 +65,7 @@ Map<String, Object> execProcessInstance(User loginUser, long projectCode,
                                             RunMode runMode,
                                             Priority processInstancePriority, String workerGroup, Long environmentCode, Integer timeout,
                                             Map<String, String> startParams, Integer expectedParallelismNumber,
-                                            int dryRun,
+                                            int dryRun,int testFlag,","[{'comment': 'optimized format', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-api/src/main/resources/i18n/messages.properties,"@@ -21,7 +21,7 @@ PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation
 RUN_PROCESS_INSTANCE_NOTES=run process instance
 BATCH_RUN_PROCESS_INSTANCE_NOTES=batch run process instance
 BATCH_EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=batch change execute state for process instance
-START_NODE_LIST=start node list（node name）
+START_NODE_LIST=start node list\uFF08node name\uFF09","[{'comment': 'text encoding error', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-api/src/main/resources/i18n/messages_zh_CN.properties,"@@ -14,347 +14,348 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-QUERY_SCHEDULE_LIST_NOTES=查询定时列表","[{'comment': 'text encoding error', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/DataSource.java,"@@ -75,6 +71,17 @@ public class DataSource {
      */
     private Date updateTime;
 
+    /**
+     * test flag
+     */
+    protected int testFlag;
+
+    /**
+     * bind test data source id
+     */
+    @TableField(fill = FieldFill.INSERT_UPDATE)","[{'comment': 'What is the function of annotation?', 'commenter': 'wen-hemin'}, {'comment': 'When converting the online data source to the test data source, the bind passed to the back end_ test_ ID is null. Since mybatis plus is used for updating, you will find that the update statement will omit the field with null value, which will cause problems. Therefore, the function of this annotation is that even if the value is null, it cannot be omitted.', 'commenter': 'insist777'}]"
11670,dolphinscheduler-dao/src/main/resources/sql/upgrade/3.2.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -0,0 +1,25 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+ALTER TABLE `t_ds_datasource` ADD COLUMN `test_flag` tinyint(4) DEFAULT NULL COMMENT 'test flag：0 normal, 1 testDataSource';","[{'comment': 'Please refer to the 1.3.0_schema directory to upgrade the ddl', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-dao/src/main/resources/sql/upgrade/3.2.0_schema/postgresql/dolphinscheduler_ddl.sql,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+
+delimiter d//
+
+
+
+CREATE OR REPLACE FUNCTION public.dolphin_update_metadata(
+    )
+    RETURNS character varying
+    LANGUAGE 'plpgsql'
+    COST 100
+    VOLATILE PARALLEL UNSAFE
+AS $BODY$
+DECLARE
+v_schema varchar;
+BEGIN
+    ---get schema name
+    v_schema =current_schema();
+
+
+
+--- add column
+EXECUTE 'ALTER TABLE ' || quote_ident(v_schema) ||'.t_ds_datasource ADD COLUMN IF NOT EXISTS test_flag int DEFAULT null  ';","[{'comment': 'Please refer to the 1.3.0_schema directory to upgrade the ddl', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/src/main/java/org/apache/dolphinscheduler/plugin/datasource/api/datasource/BaseDataSourceParamDTO.java,"@@ -117,6 +121,22 @@ public void setOther(Map<String, String> other) {
         this.other = other;
     }
 
+    public int getTestFlag() {
+        return testFlag;
+    }
+
+    public void setTestFlag(Integer testFlag) {","[{'comment': 'Uniform Field Type', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/builder/TaskExecutionContextBuilder.java,"@@ -65,14 +65,15 @@ public TaskExecutionContextBuilder buildTaskInstanceRelatedInfo(TaskInstance tas
         taskExecutionContext.setDelayTime(taskInstance.getDelayTime());
         taskExecutionContext.setVarPool(taskInstance.getVarPool());
         taskExecutionContext.setDryRun(taskInstance.getDryRun());
+        taskExecutionContext.setTestFlag(taskInstance.getTestFlag());
         taskExecutionContext.setCurrentExecutionStatus(TaskExecutionStatus.SUBMITTED_SUCCESS);
         taskExecutionContext.setCpuQuota(taskInstance.getCpuQuota());
         taskExecutionContext.setMemoryMax(taskInstance.getMemoryMax());
         taskExecutionContext.setAppIds(taskInstance.getAppLink());
         return this;
     }
 
-    public TaskExecutionContextBuilder buildTaskDefinitionRelatedInfo(TaskDefinition taskDefinition) {
+    public TaskExecutionContextBuilder buildTaskDefinitionRelatedInfo(TaskDefinition taskDefinition, TaskInstance taskInstance) {","[{'comment': 'Why not use taskDefinition ?', 'commenter': 'wen-hemin'}, {'comment': 'What I need to pass to the worker is the replaced taskparams to judge whether the replacement is successful. In fact, the taskparams defined by the task are not much different from the taskparams of the task instance, so it has little impact on other tasks that do not need to be tested for the time being.\r\n', 'commenter': 'insist777'}]"
11670,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/task/CommonTaskProcessor.java,"@@ -47,6 +52,7 @@ public class CommonTaskProcessor extends BaseTaskProcessor {
 
     @Override
     protected boolean submitTask() {
+        checkAndReplaceTestDataSource();","[{'comment': 'return is not handled', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/runner/WorkerTaskExecuteRunnable.java,"@@ -274,4 +296,9 @@ protected void clearTaskExecPathIfNeeded() {
         return task;
     }
 
+    public boolean checkTaskHaveDataSourceInstance(String taskType) {
+        List<String> testableTaskTypeList = Arrays.asList(""PROCEDURE"", ""SQL"", ""DATAX"", ""SQOOP"", ""DATA_QUALITY"");","[{'comment': 'This time only sql tasks are supported, other tasks are temporarily closed.', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-api/src/main/resources/i18n/messages.properties,"@@ -21,7 +21,7 @@ PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation
 RUN_PROCESS_INSTANCE_NOTES=run process instance
 BATCH_RUN_PROCESS_INSTANCE_NOTES=batch run process instance
 BATCH_EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=batch change execute state for process instance
-START_NODE_LIST=start node list（node name）
+START_NODE_LIST=start node list (node name)","[{'comment': 'There should be no changes here', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-api/src/main/resources/i18n/messages_en_US.properties,"@@ -20,7 +20,7 @@ PROCESS_INSTANCE_EXECUTOR_TAG=process instance executor related operation
 RUN_PROCESS_INSTANCE_NOTES=run process instance
 BATCH_RUN_PROCESS_INSTANCE_NOTES=batch run process instance(If any processDefinitionCode cannot be found, the failure information is returned and the status is set to failed. The successful task will run normally and will not stop)
 BATCH_EXECUTE_ACTION_TO_PROCESS_INSTANCE_NOTES=batch change state for muliple process instances(Will raise error with specific id when any it cannot be found, and will only show detail error message when some instances change state not as expected)
-START_NODE_LIST=start node list（node name）
+START_NODE_LIST=start node list (node name)","[{'comment': 'There should be no changes here', 'commenter': 'wen-hemin'}]"
11670,dolphinscheduler-dao/src/main/resources/sql/upgrade/3.2.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -0,0 +1,118 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+*/
+SET sql_mode=(SELECT REPLACE(@@sql_mode,'ONLY_FULL_GROUP_BY',''));
+
+-- uc_dolphin_T_t_ds_command_R_test_flag
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_command_R_test_flag;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_command_R_test_flag()
+BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_command'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='modify_by')
+   THEN
+ALTER TABLE t_ds_command ADD `test_flag` tinyint(4) DEFAULT null COMMENT 'test flag：0 normal, 1 test run';
+END IF;
+END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_command_R_test_flag;
+DROP PROCEDURE uc_dolphin_T_t_ds_command_R_test_flag;
+
+-- uc_dolphin_T_t_ds_error_command_R_test_flag
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_error_command_R_test_flag;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_error_command_R_test_flag()
+BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_error_command'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='modify_by')
+   THEN
+ALTER TABLE t_ds_error_command ADD `test_flag` tinyint(4) DEFAULT null COMMENT 'test flag：0 normal, 1 test run';
+END IF;
+END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_error_command_R_test_flag;
+DROP PROCEDURE uc_dolphin_T_t_ds_error_command_R_test_flag;
+
+-- uc_dolphin_T_t_ds_datasource_R_test_flag_bind_test_id
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_datasource_R_test_flag_bind_test_id;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_datasource_R_test_flag_bind_test_id()
+BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_datasource'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='modify_by')
+   THEN
+ALTER TABLE t_ds_datasource ADD `test_flag` tinyint(4) DEFAULT null COMMENT 'test flag：0 normal, 1 testDataSource',
+ALTER TABLE t_ds_datasource ADD `bind_test_id` int(11) DEFAULT null COMMENT 'bind testDataSource id';
+END IF;
+END;
+
+d//
+
+delimiter ;
+CALL uc_dolphin_T_t_ds_datasource_R_test_flag_bind_test_id;
+DROP PROCEDURE uc_dolphin_T_t_ds_datasource_R_test_flag_bind_test_id;
+
+-- uc_dolphin_T_t_ds_process_instance_R_test_flag
+drop PROCEDURE if EXISTS uc_dolphin_T_t_ds_process_instance_R_test_flag;
+delimiter d//
+CREATE PROCEDURE uc_dolphin_T_t_ds_process_instance_R_test_flag()
+BEGIN
+       IF NOT EXISTS (SELECT 1 FROM information_schema.COLUMNS
+           WHERE TABLE_NAME='t_ds_process_instance'
+           AND TABLE_SCHEMA=(SELECT DATABASE())
+           AND COLUMN_NAME ='modify_by')","[{'comment': 'COLUMN_NAME is wrong', 'commenter': 'wen-hemin'}]"
11682,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -698,6 +699,43 @@ public Map<String, Object> verifyProcessDefinitionName(User loginUser, long proj
         return result;
     }
 
+    @Override","[{'comment': 'We need to add `@Transaction` to rollback the data.', 'commenter': 'ruanwenjun'}, {'comment': 'Batch deletion, implemented as a loop call `deleteProcessDefinitionByCode` which add `@Transaction`. In my original idea, the delete operation of each workflow does not affect each other.\r\nSo, I would like to ask, it is necessary to add `@Transaction` here?', 'commenter': 'HomminLee'}, {'comment': 'If the operation failed, but some workflow has been deleted, this will make the data incorrect.', 'commenter': 'ruanwenjun'}]"
11682,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -698,6 +699,43 @@ public Map<String, Object> verifyProcessDefinitionName(User loginUser, long proj
         return result;
     }
 
+    @Override
+    public Map<String, Object> batchDeleteProcessDefinitionByCodes(User loginUser,
+                                                                   long projectCode,
+                                                                   String codes){
+        Map<String, Object> result = new HashMap<>();
+        Set<String> deleteFailedCodeSet = new HashSet<>();
+        if (!StringUtils.isEmpty(codes)) {
+            String[] processDefinitionCodeArray = codes.split("","");
+            for (String strProcessDefinitionCode : processDefinitionCodeArray) {
+                long code = Long.parseLong(strProcessDefinitionCode);
+                ProcessDefinition processDefinition = processDefinitionMapper.queryByCode(code);
+                // check workflow exists, avoid null exception
+                if (processDefinition == null || projectCode != processDefinition.getProjectCode()) {
+                    deleteFailedCodeSet.add(MessageFormat.format(Status.PROCESS_DEFINE_NOT_EXIST.getMsg(), String.valueOf(code)));
+                    continue;
+                }
+                try {
+                    Map<String, Object> deleteResult = this.deleteProcessDefinitionByCode(loginUser, projectCode, code);
+                    if (!Status.SUCCESS.equals(deleteResult.get(Constants.STATUS))) {
+                        String errorMsg = MessageFormat.format(Status.DELETE_PROCESS_DEFINE_BY_CODES_ERROR.getMsg(), processDefinition.getName(), deleteResult.get(Constants.MSG));
+                        deleteFailedCodeSet.add(errorMsg);
+                        logger.error(errorMsg);
+                    }
+                } catch (Exception e) {
+                    deleteFailedCodeSet.add(MessageFormat.format(Status.DELETE_PROCESS_DEFINE_BY_CODES_ERROR.getMsg(), processDefinition.getName(), e.getMessage()));
+                }
+            }
+        }
+
+        if (!deleteFailedCodeSet.isEmpty()) {
+            putMsg(result, Status.BATCH_DELETE_PROCESS_DEFINE_BY_CODES_ERROR, ""\n "" + String.join(""\n "", deleteFailedCodeSet));","[{'comment': ""In fact, it's better to return the error process name rather than code, but the interface receive codes... "", 'commenter': 'ruanwenjun'}, {'comment': ""> In fact, it's better to return the error process name rather than code, but the interface receive codes...\r\n\r\nYou mean should write another interface which receive the names, instead of query the name by codes?\r\n\r\n"", 'commenter': 'HomminLee'}, {'comment': ""No, the interface need to receive code. But we need to return process name in UI, since the processCode is not friendly to user, but if someone use openAPI, it's better to return code, since process name is not friendly for openAPI."", 'commenter': 'ruanwenjun'}, {'comment': 'I modified the implementation: if any workflow fails to delete, stop subsequent actions and rollback.', 'commenter': 'HomminLee'}]"
11682,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -796,6 +797,53 @@
         return result;
     }
 
+    @Override
+    @Transactional
+    public Map<String, Object> batchDeleteProcessDefinitionByCodes(User loginUser,
+                                                                   long projectCode,
+                                                                   String codes) {
+        Map<String, Object> result = new HashMap<>();
+        if (StringUtils.isEmpty(codes)) {
+            putMsg(result, Status.SUCCESS);
+            return result;
+        }
+
+        Set<Long> definitionCodes = Arrays.stream(codes.split(Constants.COMMA)).map(Long::parseLong)","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1231)"", 'commenter': 'github-advanced-security[bot]'}]"
11682,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -504,6 +504,76 @@
         Assert.assertEquals(Status.SUCCESS, deleteSuccess.get(Constants.STATUS));
     }
 
+    @Test
+    public void batchDeleteProcessDefinitionByCodeTest() {
+        long projectCode = 1L;
+        Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
+
+        Project project = getProject(projectCode);
+        User loginUser = new User();
+        loginUser.setId(-1);
+        loginUser.setUserType(UserType.GENERAL_USER);
+
+        // process check exists
+        Set<Long> definitionCodes =
+                Arrays.stream(""46,47"".split(Constants.COMMA)).map(Long::parseLong).collect(Collectors.toSet());","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1232)"", 'commenter': 'github-advanced-security[bot]'}]"
11682,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -504,6 +504,76 @@
         Assert.assertEquals(Status.SUCCESS, deleteSuccess.get(Constants.STATUS));
     }
 
+    @Test
+    public void batchDeleteProcessDefinitionByCodeTest() {
+        long projectCode = 1L;
+        Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
+
+        Project project = getProject(projectCode);
+        User loginUser = new User();
+        loginUser.setId(-1);
+        loginUser.setUserType(UserType.GENERAL_USER);
+
+        // process check exists
+        Set<Long> definitionCodes =
+                Arrays.stream(""46,47"".split(Constants.COMMA)).map(Long::parseLong).collect(Collectors.toSet());
+        ProcessDefinition process = getProcessDefinition();
+        List<ProcessDefinition> processDefinitionList = new ArrayList<>();
+        processDefinitionList.add(process);
+        Mockito.when(processDefineMapper.queryByCodes(definitionCodes)).thenReturn(processDefinitionList);
+        Map<String, Object> map = processDefinitionService.batchDeleteProcessDefinitionByCodes(loginUser, projectCode, ""46,47"");
+        Assert.assertEquals(Status.BATCH_DELETE_PROCESS_DEFINE_BY_CODES_ERROR, map.get(Constants.STATUS));
+
+        // project check auth fail
+        Map<String, Object> result = new HashMap<>();
+        putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
+        definitionCodes = Arrays.stream(""46"".split(Constants.COMMA)).map(Long::parseLong).collect(Collectors.toSet());","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1233)"", 'commenter': 'github-advanced-security[bot]'}]"
11682,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -787,6 +788,49 @@
         return result;
     }
 
+    @Override
+    @Transactional
+    public Map<String, Object> batchDeleteProcessDefinitionByCodes(User loginUser, long projectCode, String codes) {
+        Map<String, Object> result = new HashMap<>();
+        if (StringUtils.isEmpty(codes)) {
+            putMsg(result, Status.SUCCESS);
+            return result;
+        }
+
+        Set<Long> definitionCodes = Arrays.stream(codes.split(Constants.COMMA))
+                .map(Long::parseLong)","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1512)"", 'commenter': 'github-advanced-security[bot]'}]"
11682,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -805,6 +805,52 @@
         return result;
     }
 
+    @Override
+    @Transactional
+    public Map<String, Object> batchDeleteProcessDefinitionByCodes(User loginUser, long projectCode, String codes) {
+        Map<String, Object> result = new HashMap<>();
+        if (StringUtils.isEmpty(codes)) {
+            logger.error(""Parameter processDefinitionCodes is empty, projectCode is {}."", projectCode);
+            putMsg(result, Status.PROCESS_DEFINITION_CODES_IS_EMPTY);
+            return result;
+        }
+
+        Set<Long> definitionCodes = Lists.newArrayList(codes.split(Constants.COMMA)).stream().map(Long::parseLong)","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1535)"", 'commenter': 'github-advanced-security[bot]'}]"
11682,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -504,6 +505,76 @@
         Assertions.assertDoesNotThrow(() -> processDefinitionService.deleteProcessDefinitionByCode(user, 46L));
     }
 
+    @Test
+    public void batchDeleteProcessDefinitionByCodeTest() {
+        Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
+
+        Project project = getProject(projectCode);
+
+        // process check exists
+        final String twoCodes = ""11,12"";
+        Set<Long> definitionCodes = Lists.newArrayList(twoCodes.split(Constants.COMMA)).stream()
+                .map(Long::parseLong).collect(Collectors.toSet());","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1540)"", 'commenter': 'github-advanced-security[bot]'}]"
11682,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -504,6 +505,76 @@
         Assertions.assertDoesNotThrow(() -> processDefinitionService.deleteProcessDefinitionByCode(user, 46L));
     }
 
+    @Test
+    public void batchDeleteProcessDefinitionByCodeTest() {
+        Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
+
+        Project project = getProject(projectCode);
+
+        // process check exists
+        final String twoCodes = ""11,12"";
+        Set<Long> definitionCodes = Lists.newArrayList(twoCodes.split(Constants.COMMA)).stream()
+                .map(Long::parseLong).collect(Collectors.toSet());
+        ProcessDefinition process = getProcessDefinition();
+        List<ProcessDefinition> processDefinitionList = new ArrayList<>();
+        processDefinitionList.add(process);
+        Mockito.when(processDefinitionMapper.queryByCodes(definitionCodes)).thenReturn(processDefinitionList);
+        Throwable exception = Assertions.assertThrows(ServiceException.class,
+                () -> processDefinitionService.batchDeleteProcessDefinitionByCodes(user, projectCode, twoCodes));
+        String formatter = MessageFormat.format(Status.BATCH_DELETE_PROCESS_DEFINE_BY_CODES_ERROR.getMsg(),
+                        ""12[process definition not exist]"");
+        Assertions.assertEquals(formatter, exception.getMessage());
+
+        // project check auth fail
+        Map<String, Object> result = new HashMap<>();
+        final String singleCodes = ""11"";
+        putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
+        definitionCodes = Lists.newArrayList(singleCodes.split(Constants.COMMA)).stream().map(Long::parseLong)","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1541)"", 'commenter': 'github-advanced-security[bot]'}]"
11690,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parameters/DependentParameters.java,"@@ -23,13 +23,15 @@
 import org.apache.dolphinscheduler.plugin.task.api.model.DependentTaskModel;
 
 import java.util.List;
+import java.util.Map;
 
 @Data
 @EqualsAndHashCode(callSuper = true)
 public class DependentParameters extends AbstractParameters {
 
     private List<DependentTaskModel> dependTaskList;
     private DependentRelation relation;
+    private Map<String, Object> otherParams;","[{'comment': ""Please don't add this kind of parameters.\r\n\r\nAnd I don't see we have used this in DS."", 'commenter': 'ruanwenjun'}]"
11690,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java,"@@ -308,15 +308,17 @@ public void init(String host, Date startTime, String executePath) {
 
     public DependentParameters getDependency() {
         if (this.dependency == null) {
-            Map<String, Object> taskParamsMap =
-                    JSONUtils.parseObject(this.getTaskParams(), new TypeReference<Map<String, Object>>() {
-                    });
-            this.dependency =
-                    JSONUtils.parseObject((String) taskParamsMap.get(Constants.DEPENDENCE), DependentParameters.class);
+            Map<String, Object> taskParamsMap = JSONUtils.parseObject(this.getTaskParams(), new TypeReference<Map<String, Object>>() {
+            });
+            this.dependency = JSONUtils.parseObject((String) taskParamsMap.get(Constants.DEPENDENCE), DependentParameters.class);
+            if (taskParamsMap.get(Constants.OTHER_PARAMS) != null){
+                this.dependency.setOtherParams((Map<String, Object>) taskParamsMap.get(Constants.OTHER_PARAMS));","[{'comment': 'if the `this.dependency == null` this will throw NPE, and why you transform the dependent params from taskParmas, you can directly set in `Constants.DEPENDENCE`.', 'commenter': 'ruanwenjun'}]"
11693,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/ProcessInstance.java,"@@ -77,6 +74,7 @@ public class ProcessInstance {
     /**
      * end time
      */
+    @TableField(updateStrategy = FieldStrategy.IGNORED)","[{'comment': ""Please don't use this way, because it's a hide way for upper callers, will cause other problems if users don't know."", 'commenter': 'caishunfeng'}, {'comment': ""> Please don't use this way, because it's a hide way for upper callers, will cause other problems if users don't know.\r\n\r\nemm, but also we cannot config the global field-strategy, may we can add a update sql in mapper.xml?\r\nOr just update the date to 1970, but need change many files."", 'commenter': 'DarkAssassinator'}]"
11708,dolphinscheduler-common/pom.xml,"@@ -275,6 +287,12 @@
             <scope>provided</scope>
         </dependency>
 
+        <dependency>
+            <groupId>com.aliyun.oss</groupId>
+            <artifactId>aliyun-sdk-oss</artifactId>
+            <version>3.15.1</version>","[{'comment': 'Please manage the version in bom.\r\n```suggestion\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Sure, thanks for the suggestion.', 'commenter': 'EricGao888'}, {'comment': 'Fixed in the latest commit.', 'commenter': 'EricGao888'}]"
11708,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/config/StoreConfiguration.java,"@@ -41,6 +43,10 @@ public class StoreConfiguration {
     @Bean
     public StorageOperate storageOperate() {
         switch (PropertyUtils.getString(RESOURCE_STORAGE_TYPE)) {
+            case STORAGE_OSS:
+                OssOperator ossOperator = OssOperator.getInstance();
+                ossOperator.init();","[{'comment': ""Since this is a singleton, why you don't put the `init` method into constructor? Can the init method be executed multiple times?"", 'commenter': 'ruanwenjun'}, {'comment': 'This is also for code-decoupling and testing purpose. If we put this in the constructor, `oss client` will get instantiated in the constructor. As a result, we lose control of the instantiation of the external class and could not inject the corresponding mock during testing.', 'commenter': 'EricGao888'}, {'comment': 'I removed singleton implementation of OssOperator in the latest commit and provided a new init method which takes `ossConnection` for `OssClientFactory` to instantiate `OSS Client`. Once `configuration / connection` center supported, I will change to use it.', 'commenter': 'EricGao888'}]"
11708,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/OssOperator.java,"@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import static org.apache.dolphinscheduler.common.Constants.ALIBABA_CLOUD_OSS_END_POINT;
+import static org.apache.dolphinscheduler.common.Constants.FOLDER_SEPARATOR;
+import static org.apache.dolphinscheduler.common.Constants.FORMAT_S_S;
+import static org.apache.dolphinscheduler.common.Constants.RESOURCE_TYPE_FILE;
+import static org.apache.dolphinscheduler.common.Constants.RESOURCE_TYPE_UDF;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.ResUploadType;
+import org.apache.dolphinscheduler.common.storage.StorageOperate;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.enums.ResourceType;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayInputStream;
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.nio.file.Files;
+import java.util.Collections;
+import java.util.List;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.aliyun.oss.OSS;
+import com.aliyun.oss.OSSClientBuilder;
+import com.aliyun.oss.OSSException;
+import com.aliyun.oss.model.Bucket;
+import com.aliyun.oss.model.OSSObject;
+import com.aliyun.oss.model.ObjectMetadata;
+import com.aliyun.oss.model.PutObjectRequest;
+
+public class OssOperator implements Closeable, StorageOperate {
+
+    private static final Logger logger = LoggerFactory.getLogger(OssOperator.class);
+
+    public static String ACCESS_KEY_ID;
+
+    public static String ACCESS_KEY_SECRET;
+
+    public static String REGION;
+
+    public static String BUCKET_NAME;
+
+    public static String BASE_DIR = """";
+
+    private OSS ossClient;
+
+    private PropertyUtilsWrapper propertyUtilsWrapper;
+
+    private OssOperator() {
+    }
+
+    private enum OssOperatorSingleton {
+
+        INSTANCE;
+
+        private final OssOperator instance;
+
+        OssOperatorSingleton() {
+            instance = new OssOperator();
+        }
+
+        private OssOperator getInstance() {
+            return instance;
+        }
+    }
+
+    public static OssOperator getInstance() {
+        return OssOperatorSingleton.INSTANCE.getInstance();
+    }
+
+    public void init() {
+        propertyUtilsWrapper = createPropertyUtilsWrapper();
+        ACCESS_KEY_ID = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_ACCESS_KEY_ID);
+        ACCESS_KEY_SECRET = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_ACCESS_KEY_SECRET);
+        REGION = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_REGION);
+        BUCKET_NAME = propertyUtilsWrapper.getString(Constants.ALIBABA_CLOUD_OSS_BUCKET_NAME);
+
+        ossClient = buildOssClient();
+        ensureBucketSuccessfullyCreated(BUCKET_NAME);
+    }
+
+    @Override
+    public void close() throws IOException {
+        ossClient.shutdown();
+    }
+
+    @Override
+    public void createTenantDirIfNotExists(String tenantCode) throws Exception {
+        mkdir(tenantCode, getOssResDir(tenantCode));
+        mkdir(tenantCode, getOssUdfDir(tenantCode));
+    }
+
+    @Override
+    public String getResDir(String tenantCode) {
+        return getOssResDir(tenantCode) + FOLDER_SEPARATOR;
+    }
+
+    @Override
+    public String getUdfDir(String tenantCode) {
+        return getOssUdfDir(tenantCode) + FOLDER_SEPARATOR;
+    }
+
+    @Override
+    public boolean mkdir(String tenantCode, String path) throws IOException {
+        final String key = path + FOLDER_SEPARATOR;
+        if (!ossClient.doesObjectExist(BUCKET_NAME, key)) {
+            createOssPrefix(BUCKET_NAME, key);
+        }
+        return true;
+    }
+
+    protected void createOssPrefix(final String bucketName, final String key) {
+        ObjectMetadata metadata = new ObjectMetadata();
+        metadata.setContentLength(0);
+        InputStream emptyContent = new ByteArrayInputStream(new byte[0]);
+        PutObjectRequest putObjectRequest = new PutObjectRequest(bucketName, key, emptyContent, metadata);
+        ossClient.putObject(putObjectRequest);
+    }
+
+    @Override
+    public String getResourceFileName(String tenantCode, String fileName) {
+        if (fileName.startsWith(FOLDER_SEPARATOR)) {
+            fileName = fileName.replaceFirst(FOLDER_SEPARATOR, """");
+        }
+        return String.format(FORMAT_S_S, getOssResDir(tenantCode), fileName);
+    }
+
+    @Override
+    public String getFileName(ResourceType resourceType, String tenantCode, String fileName) {
+        if (fileName.startsWith(FOLDER_SEPARATOR)) {
+            fileName = fileName.replaceFirst(FOLDER_SEPARATOR, """");
+        }
+        return getDir(resourceType, tenantCode) + fileName;
+    }
+
+    @Override
+    public void download(String tenantCode, String srcFilePath, String dstFilePath, boolean deleteSource,
+                         boolean overwrite) throws IOException {
+        File dstFile = new File(dstFilePath);
+        if (dstFile.isDirectory()) {
+            Files.delete(dstFile.toPath());
+        } else {
+            Files.createDirectories(dstFile.getParentFile().toPath());
+        }
+        OSSObject ossObject = ossClient.getObject(BUCKET_NAME, srcFilePath);
+        try (
+                InputStream ossInputStream = ossObject.getObjectContent();
+                FileOutputStream fos = new FileOutputStream(dstFilePath)) {
+            byte[] readBuf = new byte[1024];
+            int readLen;
+            while ((readLen = ossInputStream.read(readBuf)) > 0) {
+                fos.write(readBuf, 0, readLen);
+            }
+        } catch (OSSException e) {
+            throw new IOException(e.getMessage());","[{'comment': ""```suggestion\r\n            throw new IOException(e);\r\n```\r\nDon't hide the stack."", 'commenter': 'ruanwenjun'}, {'comment': 'Sure, will fix it.', 'commenter': 'EricGao888'}]"
11708,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/OssOperator.java,"@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import static org.apache.dolphinscheduler.common.Constants.ALIBABA_CLOUD_OSS_END_POINT;
+import static org.apache.dolphinscheduler.common.Constants.FOLDER_SEPARATOR;
+import static org.apache.dolphinscheduler.common.Constants.FORMAT_S_S;
+import static org.apache.dolphinscheduler.common.Constants.RESOURCE_TYPE_FILE;
+import static org.apache.dolphinscheduler.common.Constants.RESOURCE_TYPE_UDF;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.ResUploadType;
+import org.apache.dolphinscheduler.common.storage.StorageOperate;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.enums.ResourceType;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayInputStream;
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.nio.file.Files;
+import java.util.Collections;
+import java.util.List;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.aliyun.oss.OSS;
+import com.aliyun.oss.OSSClientBuilder;
+import com.aliyun.oss.OSSException;
+import com.aliyun.oss.model.Bucket;
+import com.aliyun.oss.model.OSSObject;
+import com.aliyun.oss.model.ObjectMetadata;
+import com.aliyun.oss.model.PutObjectRequest;
+
+public class OssOperator implements Closeable, StorageOperate {
+
+    private static final Logger logger = LoggerFactory.getLogger(OssOperator.class);
+
+    public static String ACCESS_KEY_ID;
+
+    public static String ACCESS_KEY_SECRET;
+
+    public static String REGION;
+
+    public static String BUCKET_NAME;
+
+    public static String BASE_DIR = """";
+
+    private OSS ossClient;
+
+    private PropertyUtilsWrapper propertyUtilsWrapper;
+
+    private OssOperator() {
+    }
+
+    private enum OssOperatorSingleton {
+
+        INSTANCE;
+
+        private final OssOperator instance;
+
+        OssOperatorSingleton() {
+            instance = new OssOperator();
+        }
+
+        private OssOperator getInstance() {
+            return instance;
+        }
+    }
+
+    public static OssOperator getInstance() {
+        return OssOperatorSingleton.INSTANCE.getInstance();
+    }
+
+    public void init() {
+        propertyUtilsWrapper = createPropertyUtilsWrapper();
+        ACCESS_KEY_ID = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_ACCESS_KEY_ID);
+        ACCESS_KEY_SECRET = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_ACCESS_KEY_SECRET);
+        REGION = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_REGION);
+        BUCKET_NAME = propertyUtilsWrapper.getString(Constants.ALIBABA_CLOUD_OSS_BUCKET_NAME);
+
+        ossClient = buildOssClient();
+        ensureBucketSuccessfullyCreated(BUCKET_NAME);
+    }
+
+    @Override
+    public void close() throws IOException {
+        ossClient.shutdown();
+    }
+
+    @Override
+    public void createTenantDirIfNotExists(String tenantCode) throws Exception {
+        mkdir(tenantCode, getOssResDir(tenantCode));
+        mkdir(tenantCode, getOssUdfDir(tenantCode));
+    }
+
+    @Override
+    public String getResDir(String tenantCode) {
+        return getOssResDir(tenantCode) + FOLDER_SEPARATOR;
+    }
+
+    @Override
+    public String getUdfDir(String tenantCode) {
+        return getOssUdfDir(tenantCode) + FOLDER_SEPARATOR;
+    }
+
+    @Override
+    public boolean mkdir(String tenantCode, String path) throws IOException {
+        final String key = path + FOLDER_SEPARATOR;
+        if (!ossClient.doesObjectExist(BUCKET_NAME, key)) {
+            createOssPrefix(BUCKET_NAME, key);
+        }
+        return true;
+    }
+
+    protected void createOssPrefix(final String bucketName, final String key) {
+        ObjectMetadata metadata = new ObjectMetadata();
+        metadata.setContentLength(0);
+        InputStream emptyContent = new ByteArrayInputStream(new byte[0]);
+        PutObjectRequest putObjectRequest = new PutObjectRequest(bucketName, key, emptyContent, metadata);
+        ossClient.putObject(putObjectRequest);
+    }
+
+    @Override
+    public String getResourceFileName(String tenantCode, String fileName) {
+        if (fileName.startsWith(FOLDER_SEPARATOR)) {
+            fileName = fileName.replaceFirst(FOLDER_SEPARATOR, """");
+        }
+        return String.format(FORMAT_S_S, getOssResDir(tenantCode), fileName);
+    }
+
+    @Override
+    public String getFileName(ResourceType resourceType, String tenantCode, String fileName) {
+        if (fileName.startsWith(FOLDER_SEPARATOR)) {
+            fileName = fileName.replaceFirst(FOLDER_SEPARATOR, """");
+        }
+        return getDir(resourceType, tenantCode) + fileName;
+    }
+
+    @Override
+    public void download(String tenantCode, String srcFilePath, String dstFilePath, boolean deleteSource,
+                         boolean overwrite) throws IOException {
+        File dstFile = new File(dstFilePath);
+        if (dstFile.isDirectory()) {
+            Files.delete(dstFile.toPath());
+        } else {
+            Files.createDirectories(dstFile.getParentFile().toPath());
+        }
+        OSSObject ossObject = ossClient.getObject(BUCKET_NAME, srcFilePath);
+        try (
+                InputStream ossInputStream = ossObject.getObjectContent();
+                FileOutputStream fos = new FileOutputStream(dstFilePath)) {
+            byte[] readBuf = new byte[1024];
+            int readLen;
+            while ((readLen = ossInputStream.read(readBuf)) > 0) {
+                fos.write(readBuf, 0, readLen);
+            }
+        } catch (OSSException e) {
+            throw new IOException(e.getMessage());
+        } catch (FileNotFoundException e) {
+            logger.error(""the destination file {} not found"", dstFilePath);
+            throw e;
+        }
+    }
+
+    @Override
+    public boolean exists(String tenantCode, String fileName) throws IOException {
+        return ossClient.doesObjectExist(BUCKET_NAME, fileName);
+    }
+
+    @Override
+    public boolean delete(String tenantCode, String filePath, boolean recursive) throws IOException {
+        try {
+            ossClient.deleteObject(BUCKET_NAME, filePath);
+            return true;
+        } catch (OSSException e) {
+            logger.error(""delete the object error,the resource path is {}"", filePath);","[{'comment': '```suggestion\r\n            logger.error(""delete the object error,the resource path is {}"", filePath, e);\r\n```', 'commenter': 'ruanwenjun'}]"
11708,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/OssOperator.java,"@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import static org.apache.dolphinscheduler.common.Constants.ALIBABA_CLOUD_OSS_END_POINT;
+import static org.apache.dolphinscheduler.common.Constants.FOLDER_SEPARATOR;
+import static org.apache.dolphinscheduler.common.Constants.FORMAT_S_S;
+import static org.apache.dolphinscheduler.common.Constants.RESOURCE_TYPE_FILE;
+import static org.apache.dolphinscheduler.common.Constants.RESOURCE_TYPE_UDF;
+
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.common.enums.ResUploadType;
+import org.apache.dolphinscheduler.common.storage.StorageOperate;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.enums.ResourceType;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayInputStream;
+import java.io.Closeable;
+import java.io.File;
+import java.io.FileNotFoundException;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.nio.file.Files;
+import java.util.Collections;
+import java.util.List;
+import java.util.stream.Collectors;
+import java.util.stream.Stream;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.aliyun.oss.OSS;
+import com.aliyun.oss.OSSClientBuilder;
+import com.aliyun.oss.OSSException;
+import com.aliyun.oss.model.Bucket;
+import com.aliyun.oss.model.OSSObject;
+import com.aliyun.oss.model.ObjectMetadata;
+import com.aliyun.oss.model.PutObjectRequest;
+
+public class OssOperator implements Closeable, StorageOperate {
+
+    private static final Logger logger = LoggerFactory.getLogger(OssOperator.class);
+
+    public static String ACCESS_KEY_ID;
+
+    public static String ACCESS_KEY_SECRET;
+
+    public static String REGION;
+
+    public static String BUCKET_NAME;
+
+    public static String BASE_DIR = """";
+
+    private OSS ossClient;
+
+    private PropertyUtilsWrapper propertyUtilsWrapper;
+
+    private OssOperator() {
+    }
+
+    private enum OssOperatorSingleton {
+
+        INSTANCE;
+
+        private final OssOperator instance;
+
+        OssOperatorSingleton() {
+            instance = new OssOperator();
+        }
+
+        private OssOperator getInstance() {
+            return instance;
+        }
+    }
+
+    public static OssOperator getInstance() {
+        return OssOperatorSingleton.INSTANCE.getInstance();
+    }
+
+    public void init() {
+        propertyUtilsWrapper = createPropertyUtilsWrapper();
+        ACCESS_KEY_ID = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_ACCESS_KEY_ID);
+        ACCESS_KEY_SECRET = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_ACCESS_KEY_SECRET);
+        REGION = propertyUtilsWrapper.getString(TaskConstants.ALIBABA_CLOUD_REGION);
+        BUCKET_NAME = propertyUtilsWrapper.getString(Constants.ALIBABA_CLOUD_OSS_BUCKET_NAME);
+
+        ossClient = buildOssClient();
+        ensureBucketSuccessfullyCreated(BUCKET_NAME);
+    }
+
+    @Override
+    public void close() throws IOException {
+        ossClient.shutdown();
+    }
+
+    @Override
+    public void createTenantDirIfNotExists(String tenantCode) throws Exception {
+        mkdir(tenantCode, getOssResDir(tenantCode));
+        mkdir(tenantCode, getOssUdfDir(tenantCode));
+    }
+
+    @Override
+    public String getResDir(String tenantCode) {
+        return getOssResDir(tenantCode) + FOLDER_SEPARATOR;
+    }
+
+    @Override
+    public String getUdfDir(String tenantCode) {
+        return getOssUdfDir(tenantCode) + FOLDER_SEPARATOR;
+    }
+
+    @Override
+    public boolean mkdir(String tenantCode, String path) throws IOException {
+        final String key = path + FOLDER_SEPARATOR;
+        if (!ossClient.doesObjectExist(BUCKET_NAME, key)) {
+            createOssPrefix(BUCKET_NAME, key);
+        }
+        return true;
+    }
+
+    protected void createOssPrefix(final String bucketName, final String key) {
+        ObjectMetadata metadata = new ObjectMetadata();
+        metadata.setContentLength(0);
+        InputStream emptyContent = new ByteArrayInputStream(new byte[0]);
+        PutObjectRequest putObjectRequest = new PutObjectRequest(bucketName, key, emptyContent, metadata);
+        ossClient.putObject(putObjectRequest);
+    }
+
+    @Override
+    public String getResourceFileName(String tenantCode, String fileName) {
+        if (fileName.startsWith(FOLDER_SEPARATOR)) {
+            fileName = fileName.replaceFirst(FOLDER_SEPARATOR, """");
+        }
+        return String.format(FORMAT_S_S, getOssResDir(tenantCode), fileName);
+    }
+
+    @Override
+    public String getFileName(ResourceType resourceType, String tenantCode, String fileName) {
+        if (fileName.startsWith(FOLDER_SEPARATOR)) {
+            fileName = fileName.replaceFirst(FOLDER_SEPARATOR, """");
+        }
+        return getDir(resourceType, tenantCode) + fileName;
+    }
+
+    @Override
+    public void download(String tenantCode, String srcFilePath, String dstFilePath, boolean deleteSource,
+                         boolean overwrite) throws IOException {
+        File dstFile = new File(dstFilePath);
+        if (dstFile.isDirectory()) {
+            Files.delete(dstFile.toPath());
+        } else {
+            Files.createDirectories(dstFile.getParentFile().toPath());
+        }
+        OSSObject ossObject = ossClient.getObject(BUCKET_NAME, srcFilePath);
+        try (
+                InputStream ossInputStream = ossObject.getObjectContent();
+                FileOutputStream fos = new FileOutputStream(dstFilePath)) {
+            byte[] readBuf = new byte[1024];
+            int readLen;
+            while ((readLen = ossInputStream.read(readBuf)) > 0) {
+                fos.write(readBuf, 0, readLen);
+            }
+        } catch (OSSException e) {
+            throw new IOException(e.getMessage());
+        } catch (FileNotFoundException e) {
+            logger.error(""the destination file {} not found"", dstFilePath);
+            throw e;
+        }
+    }
+
+    @Override
+    public boolean exists(String tenantCode, String fileName) throws IOException {
+        return ossClient.doesObjectExist(BUCKET_NAME, fileName);
+    }
+
+    @Override
+    public boolean delete(String tenantCode, String filePath, boolean recursive) throws IOException {
+        try {
+            ossClient.deleteObject(BUCKET_NAME, filePath);
+            return true;
+        } catch (OSSException e) {
+            logger.error(""delete the object error,the resource path is {}"", filePath);
+            return false;
+        }
+    }
+
+    @Override
+    public boolean copy(String srcPath, String dstPath, boolean deleteSource, boolean overwrite) throws IOException {
+        ossClient.copyObject(BUCKET_NAME, srcPath, BUCKET_NAME, dstPath);
+        ossClient.deleteObject(BUCKET_NAME, srcPath);
+        return true;
+    }
+
+    @Override
+    public String getDir(ResourceType resourceType, String tenantCode) {
+        switch (resourceType) {
+            case UDF:
+                return getUdfDir(tenantCode);
+            case FILE:
+                return getResDir(tenantCode);
+            default:
+                return BASE_DIR;
+        }
+    }
+
+    @Override
+    public boolean upload(String tenantCode, String srcFile, String dstPath, boolean deleteSource,
+                          boolean overwrite) throws IOException {
+        try {
+            ossClient.putObject(BUCKET_NAME, dstPath, new File(srcFile));
+            return true;
+        } catch (OSSException e) {
+            logger.error(""upload failed,the bucketName is {},the filePath is {}"", BUCKET_NAME, dstPath);","[{'comment': '```suggestion\r\n            logger.error(""upload failed,the bucketName is {},the filePath is {}"", BUCKET_NAME, dstPath, e);\r\n```', 'commenter': 'ruanwenjun'}]"
11708,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/PropertyUtilsWrapper.java,"@@ -0,0 +1,28 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import lombok.Data;
+
+@Data
+public class PropertyUtilsWrapper {","[{'comment': ""I don't see this class doing any enhancement, why we don't directly execute `PropertyUtils.getString`"", 'commenter': 'ruanwenjun'}, {'comment': 'This is a class to facilitate unit tests. Currently, there is no way to mock `PropertyUtils` as we choose to remove `Powermock`. `Mockito.mockStatic` does not work for this class because `PropertyUtils` throws some kind of `initialization error` when mocking it. `Powermock` could use some mechanism to suppress the error. Therefore, we could choose either to use a `wrapper class` or refactor `PropertyUtils`.', 'commenter': 'EricGao888'}, {'comment': 'Wrapper class removed in the latest commit.', 'commenter': 'EricGao888'}]"
11708,tools/dependencies/known-dependencies.txt,"@@ -289,3 +289,14 @@ zeppelin-client-0.10.1.jar
 zeppelin-common-0.10.1.jar
 zjsonpatch-0.3.0.jar
 zookeeper-3.4.14.jar
+aliyun-java-sdk-core-4.5.10.jar","[{'comment': 'Please update the LICENSE. ', 'commenter': 'ruanwenjun'}, {'comment': 'Sure, will update `dolphinscheduler-dist/release-docs/LICENSE`', 'commenter': 'EricGao888'}, {'comment': 'Updated in the latest commit.', 'commenter': 'EricGao888'}]"
11708,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/OssOperatorTest.java,"@@ -0,0 +1,253 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import static org.apache.dolphinscheduler.common.Constants.FOLDER_SEPARATOR;
+import static org.apache.dolphinscheduler.common.Constants.FORMAT_S_S;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.fail;
+import static org.mockito.ArgumentMatchers.any;
+import static org.mockito.ArgumentMatchers.anyString;
+import static org.mockito.Mockito.doNothing;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.mockito.Mockito.times;
+import static org.mockito.Mockito.verify;
+
+import org.apache.dolphinscheduler.spi.enums.ResourceType;
+
+import java.io.IOException;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.mockito.junit.MockitoJUnitRunner;
+
+import com.aliyun.oss.OSS;
+
+@RunWith(MockitoJUnitRunner.class)
+public class OssOperatorTest {","[{'comment': ':+1: ', 'commenter': 'caishunfeng'}]"
11708,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/model/OssConnection.java,"@@ -0,0 +1,34 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.model;
+
+import lombok.Data;
+
+@Data
+public class OssConnection {
+
+    public String accessKeyId;
+    public String accessKeySecret;
+    public String endPoint;
+
+    public OssConnection(final String accessKeyId, final String accessKeySecret, final String endPoint) {
+        this.accessKeyId = accessKeyId;
+        this.accessKeySecret = accessKeySecret;
+        this.endPoint = endPoint;
+    }","[{'comment': 'Use `@AllArgsConstructor`', 'commenter': 'ruanwenjun'}, {'comment': 'Fixed, thanks.', 'commenter': 'EricGao888'}]"
11708,tools/dependencies/known-dependencies.txt,"@@ -345,3 +345,14 @@ protobuf-java-util-3.17.2.jar
 zjsonpatch-0.3.0.jar
 zookeeper-3.8.0.jar
 zookeeper-jute-3.8.0.jar
+aliyun-java-sdk-core-4.5.10.jar
+aliyun-java-sdk-kms-2.11.0.jar
+aliyun-java-sdk-ram-3.1.0.jar","[{'comment': 'You forgot announce `aliyun-java-sdk-ram` in LICENSE?', 'commenter': 'ruanwenjun'}, {'comment': 'Fixed in the latest commit. Thanks for pointing this out.', 'commenter': 'EricGao888'}]"
11759,dolphinscheduler-standalone-server/src/main/bin/start.sh,"@@ -36,4 +36,4 @@ done
 
 java $JAVA_OPTS \
   -cp ""$DOLPHINSCHEDULER_HOME/conf"":""$CP"" \
-  org.apache.dolphinscheduler.StandaloneServer
+  org.apache.dolphinscheduler.StandaloneServer","[{'comment': 'Please remove unnessnary change.', 'commenter': 'SbloodyS'}, {'comment': ""ok,I'll delete it"", 'commenter': 'amaoisnb'}]"
11759,dolphinscheduler-server/pom.xml,"@@ -44,6 +45,10 @@
             <artifactId>mockito-core</artifactId>
             <scope>test</scope>
         </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-api</artifactId>","[{'comment': 'The server should not depend on api-server.', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionControllerTest.java,"@@ -1,423 +0,0 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.dolphinscheduler.api.controller;
-
-import org.apache.dolphinscheduler.api.enums.Status;
-import org.apache.dolphinscheduler.api.service.impl.ProcessDefinitionServiceImpl;
-import org.apache.dolphinscheduler.api.utils.PageInfo;
-import org.apache.dolphinscheduler.api.utils.Result;
-import org.apache.dolphinscheduler.common.Constants;
-import org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum;
-import org.apache.dolphinscheduler.common.enums.ReleaseState;
-import org.apache.dolphinscheduler.common.enums.UserType;
-import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
-import org.apache.dolphinscheduler.dao.entity.ProcessDefinitionLog;
-import org.apache.dolphinscheduler.dao.entity.Resource;
-import org.apache.dolphinscheduler.dao.entity.User;
-
-import java.text.MessageFormat;
-import java.util.ArrayList;
-import java.util.HashMap;
-import java.util.List;
-import java.util.Map;
-
-import javax.servlet.http.HttpServletResponse;
-
-import org.junit.Assert;
-import org.junit.Before;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.mockito.InjectMocks;
-import org.mockito.Mock;
-import org.mockito.Mockito;
-import org.mockito.junit.MockitoJUnitRunner;
-import org.springframework.mock.web.MockHttpServletResponse;
-
-/**
- * process definition controller test
- */
-@RunWith(MockitoJUnitRunner.Silent.class)","[{'comment': 'Why remove this UT case?', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/demo/DemoContants.java,"@@ -0,0 +1,121 @@
+package org.apache.dolphinscheduler.server.demo;
+
+public class DemoContants {
+    public static final String [] SHELL_taskDefinitionJson = {""[{\""code\"":"",","[{'comment': 'Replace with Java Object  is better, because users can update it easily, and if someone change the Jave class, such as `TaskDefinition`, then he will update this too.', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/datasource/CreateProcessDemo.java,"@@ -0,0 +1,49 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.tools.datasource;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.boot.CommandLineRunner;
+import org.springframework.boot.SpringApplication;
+import org.springframework.boot.autoconfigure.SpringBootApplication;
+import org.springframework.stereotype.Component;
+
+@SpringBootApplication
+public class CreateProcessDemo {
+    public static void main(String[] args) {
+        SpringApplication.run(CreateProcessDemo.class, args);
+    }
+
+    @Component
+    static class DemoRunner implements CommandLineRunner {
+        private static final Logger logger = LoggerFactory.getLogger(DemoRunner.class);
+
+        private final ProcessDefinitionDemo processDefinitionDemo;
+
+        DemoRunner(ProcessDefinitionDemo processDefinitionDemo) {
+            this.processDefinitionDemo = processDefinitionDemo;
+        }
+
+        @Override
+        public void run(String... args) throws Exception {
+            processDefinitionDemo.createProcessDefinitionDemo();","[{'comment': 'Could you please split this method into `createDemoProject`, `createDemoTenant`, `createDemoWorkflow`?\r\nAnd can we get the current login user as demoTenant?', 'commenter': 'ruanwenjun'}]"
11759,dolphinscheduler-common/pom.xml,"@@ -319,6 +319,19 @@
             <artifactId>netty-all</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.projectlombok</groupId>
+            <artifactId>lombok</artifactId>
+            <version>1.16.22</version>","[{'comment': 'move the version into bom.', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-common/pom.xml,"@@ -319,6 +319,19 @@
             <artifactId>netty-all</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.projectlombok</groupId>
+            <artifactId>lombok</artifactId>
+            <version>1.16.22</version>
+            <scope>compile</scope>
+        </dependency>
+        <dependency>
+            <groupId>com.squareup.okhttp3</groupId>
+            <artifactId>okhttp</artifactId>
+            <version>3.14.9</version>","[{'comment': 'same here', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/DemoContants.java,"@@ -0,0 +1,117 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+public class DemoContants {
+    public static final String [] SHELL_taskDefinitionJson = {""[{\""code\"":"",","[{'comment': 'Json string is hard to maintain, please replace it with `TaskDefinition` Object.\r\n', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProcessDefinitionDemo.java,"@@ -0,0 +1,321 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+
+import static org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum.PARALLEL;
+
+
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.EncryptionUtils;
+import org.apache.dolphinscheduler.dao.entity.AccessToken;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AccessTokenMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.UserMapper;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.LinkedHashMap;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.stereotype.Component;
+
+
+@Component
+public class ProcessDefinitionDemo {
+
+    private static final Logger logger = LoggerFactory.getLogger(ProcessDefinitionDemo.class);
+
+    @Value(""${create-demo.tenant-code}"")
+    private String tenantCode;
+
+    @Autowired
+    private ProjectMapper projectMapper;
+
+    @Autowired
+    private UserMapper userMapper;
+
+    @Autowired
+    private AccessTokenMapper accessTokenMapper;
+
+    @Autowired
+    private ProxyProcessDefinitionController proxyProcessDefinitionController;
+
+    public void createProcessDefinitionDemo(){
+        //get user
+        User loginUser = userMapper.selectById(""1"");
+        Date now = new Date();
+
+        //create demo tenantCode
+        CreateDemoTenant createDemoTenant = new CreateDemoTenant();
+        createDemoTenant.createTenantCode(tenantCode);
+
+        //create and get demo projectCode
+        Project project = projectMapper.queryByName(""demo"");
+        try {
+            project = Project
+                    .newBuilder()
+                    .name(""demo"")
+                    .code(CodeGenerateUtils.getInstance().genCode())
+                    .description("""")
+                    .userId(loginUser.getId())
+                    .userName(loginUser.getUserName())
+                    .createTime(now)
+                    .updateTime(now)
+                    .build();
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.info(""create project error"");","[{'comment': '```suggestion\r\n            logger.error(""create project error"", e);\r\n```', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProcessDefinitionDemo.java,"@@ -0,0 +1,321 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+
+import static org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum.PARALLEL;
+
+
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.EncryptionUtils;
+import org.apache.dolphinscheduler.dao.entity.AccessToken;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AccessTokenMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.UserMapper;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.LinkedHashMap;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.stereotype.Component;
+
+
+@Component
+public class ProcessDefinitionDemo {
+
+    private static final Logger logger = LoggerFactory.getLogger(ProcessDefinitionDemo.class);
+
+    @Value(""${create-demo.tenant-code}"")
+    private String tenantCode;
+
+    @Autowired
+    private ProjectMapper projectMapper;
+
+    @Autowired
+    private UserMapper userMapper;
+
+    @Autowired
+    private AccessTokenMapper accessTokenMapper;
+
+    @Autowired
+    private ProxyProcessDefinitionController proxyProcessDefinitionController;
+
+    public void createProcessDefinitionDemo(){
+        //get user
+        User loginUser = userMapper.selectById(""1"");
+        Date now = new Date();
+
+        //create demo tenantCode
+        CreateDemoTenant createDemoTenant = new CreateDemoTenant();
+        createDemoTenant.createTenantCode(tenantCode);
+
+        //create and get demo projectCode
+        Project project = projectMapper.queryByName(""demo"");
+        try {
+            project = Project
+                    .newBuilder()
+                    .name(""demo"")
+                    .code(CodeGenerateUtils.getInstance().genCode())
+                    .description("""")
+                    .userId(loginUser.getId())
+                    .userName(loginUser.getUserName())
+                    .createTime(now)
+                    .updateTime(now)
+                    .build();
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.info(""create project error"");
+        }
+        if (projectMapper.insert(project) > 0) {
+            logger.info(""create project success"");
+        } else {
+            logger.info(""create project error"");
+        }","[{'comment': 'should throw exception', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProxyProcessDefinitionController.java,"@@ -0,0 +1,56 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+import org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.utils.OkHttpUtils;
+
+import java.io.IOException;
+import java.util.HashMap;
+import java.util.Map;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.stereotype.Service;
+
+@Service
+public class ProxyProcessDefinitionController {
+
+    private static final Logger logger = LoggerFactory.getLogger(ProxyProcessDefinitionController.class);
+    public ProxyResult createProcessDefinition (String token,
+                                                long projectCode,
+                                                String name,
+                                                String description,
+                                                String globalParams,
+                                                String locations,
+                                                int timeout,
+                                                String tenantCode,
+                                                String taskRelationJson,
+                                                String taskDefinitionJson,
+                                                ProcessExecutionTypeEnum executionType){
+        ProxyResult proxyResult = new ProxyResult();
+        String ServerPort = ""3000"";
+        String url = ""http://localhost:"" + ServerPort + ""/dolphinscheduler/projects/"" + projectCode + ""/process-definition"";","[{'comment': 'The ip and port should be config in `application.yaml`', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-common/pom.xml,"@@ -319,6 +319,15 @@
             <artifactId>netty-all</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.projectlombok</groupId>
+            <artifactId>lombok</artifactId>
+        </dependency>","[{'comment': ""You don't need this, please remove them"", 'commenter': 'kezhenxu94'}]"
11759,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/OkHttpUtils.java,"@@ -0,0 +1,130 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.utils;
+
+import org.apache.http.HttpStatus;
+
+import java.io.IOException;
+import java.util.Map;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.Nullable;
+
+import lombok.NonNull;
+import okhttp3.HttpUrl;
+import okhttp3.MediaType;
+import okhttp3.OkHttpClient;
+import okhttp3.Request;
+import okhttp3.RequestBody;
+import okhttp3.Response;
+
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+
+public class OkHttpUtils {","[{'comment': ""Please, don't add everything to common module, move this to the module it needs."", 'commenter': 'kezhenxu94'}, {'comment': ""Ok, I'll make some adjustments"", 'commenter': 'amaoisnb'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/CreateProcessDemo.java,"@@ -0,0 +1,61 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.tools.demo;
+
+
+
+","[{'comment': 'Why so many blank lines?', 'commenter': 'kezhenxu94'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProxyResult.java,"@@ -0,0 +1,87 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+
+public class ProxyResult<T> {
+    /**
+     * status
+     */","[{'comment': 'Remove all these useless JavaDoc', 'commenter': 'kezhenxu94'}]"
11759,dolphinscheduler-common/pom.xml,"@@ -319,6 +319,15 @@
             <artifactId>netty-all</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.projectlombok</groupId>
+            <artifactId>lombok</artifactId>
+        </dependency>
+        <dependency>
+            <groupId>com.squareup.okhttp3</groupId>
+            <artifactId>okhttp</artifactId>
+        </dependency>","[{'comment': 'Why are you adding a duplicate dependency just the same as line 411? Can you please check whether it exists before adding one?', 'commenter': 'kezhenxu94'}]"
11759,dolphinscheduler-tools/src/main/resources/application.yaml,"@@ -34,6 +34,12 @@ spring:
       leak-detection-threshold: 0
       initialization-fail-timeout: 1
 
+create-demo:
+  tenant-code: default
+
+server:
+  port: 5173","[{'comment': '```suggestion\r\ndemo:\r\n  tenant-code: default\r\n  api-server-port: 5173\r\n```', 'commenter': 'caishunfeng'}]"
11759,docs/configs/docsdev.js,"@@ -1013,6 +1017,10 @@ export default {
                         title: '扩/缩容',
                         link: '/zh-cn/docs/dev/user_doc/guide/expansion-reduction.html',
                     },
+                    {
+                        title: '初始化工作流',","[{'comment': ""```suggestion\r\n                        title: 'Demo',\r\n```"", 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/CreateDemoTenant.java,"@@ -0,0 +1,38 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+import org.apache.dolphinscheduler.dao.entity.Tenant;
+import org.apache.dolphinscheduler.dao.mapper.TenantMapper;
+
+import java.util.Date;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+
+public class CreateDemoTenant {
+
+    private static final Logger logger = LoggerFactory.getLogger(CreateDemoTenant.class);
+    @Autowired
+    private TenantMapper tenantMapper;
+
+    public void createTenantCode(String tenantCode){
+        Date now = new Date();
+
+        if( !tenantCode.equals(""default"")){
+            Boolean existTenant = tenantMapper.existTenant(tenantCode);
+            if( !Boolean.TRUE.equals(existTenant) ){
+                Tenant tenant = new Tenant();
+                tenant.setTenantCode(tenantCode);
+                tenant.setQueueId(1);
+                tenant.setDescription("""");
+                tenant.setCreateTime(now);
+                tenant.setUpdateTime(now);
+                // save
+                tenantMapper.insert(tenant);
+                logger.info(""create tenant success"");
+            }else {
+                logger.info(""os tenant code already exists"");","[{'comment': '```suggestion\r\n                logger.warn(""os tenant code already exists"");\r\n```', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/CreateProcessDemo.java,"@@ -0,0 +1,41 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.boot.CommandLineRunner;
+import org.springframework.boot.SpringApplication;
+import org.springframework.boot.autoconfigure.SpringBootApplication;
+import org.springframework.context.annotation.ComponentScan;
+import org.springframework.context.annotation.FilterType;
+import org.springframework.context.annotation.Profile;
+import org.springframework.stereotype.Component;
+
+@SpringBootApplication
+@ComponentScan(value = ""org.apache.dolphinscheduler"", excludeFilters = {
+        @ComponentScan.Filter(type = FilterType.REGEX, pattern = {
+                ""org.apache.dolphinscheduler.tools.datasource.*"",","[{'comment': 'Why need to exclude these?', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProcessDefinitionDemo.java,"@@ -0,0 +1,778 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+import static org.apache.dolphinscheduler.common.enums.ConditionType.NONE;
+import static org.apache.dolphinscheduler.common.enums.Flag.YES;
+import static org.apache.dolphinscheduler.common.enums.Priority.MEDIUM;
+import static org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum.PARALLEL;
+
+import org.apache.dolphinscheduler.common.enums.TimeoutFlag;
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.EncryptionUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.AccessToken;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.ProcessTaskRelationLog;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.TaskDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AccessTokenMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.UserMapper;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.LinkedHashMap;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.stereotype.Component;
+
+@Component
+public class ProcessDefinitionDemo {
+
+    private static final Logger logger = LoggerFactory.getLogger(ProcessDefinitionDemo.class);
+
+    @Value(""${demo.tenant-code}"")
+    private String tenantCode;
+
+    @Autowired
+    private ProjectMapper projectMapper;
+
+    @Autowired
+    private UserMapper userMapper;
+
+    @Autowired
+    private AccessTokenMapper accessTokenMapper;
+
+    @Autowired
+    private ProxyProcessDefinitionController proxyProcessDefinitionController;
+
+    public void createProcessDefinitionDemo() throws Exception {
+        //get user
+        User loginUser = userMapper.selectById(""1"");
+        Date now = new Date();
+
+        //create demo tenantCode
+        CreateDemoTenant createDemoTenant = new CreateDemoTenant();
+        createDemoTenant.createTenantCode(tenantCode);
+
+        //create and get demo projectCode
+        Project project = projectMapper.queryByName(""demo"");
+        if (project != null) {
+            logger.warn(""Project {} already exists."", project.getName());
+        }
+        try {
+            project = Project
+                .builder()
+                .name(""demo"")
+                .code(CodeGenerateUtils.getInstance().genCode())
+                .description("""")
+                .userId(loginUser.getId())
+                .userName(loginUser.getUserName())
+                .createTime(now)
+                .updateTime(now)
+                .build();
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""create project error"", e);
+        }
+        if (projectMapper.insert(project) > 0) {
+            logger.info(""create project success"");
+        } else {
+            throw new Exception(""create project error"");
+        }
+        Long projectCode = project.getCode();
+
+        // generate access token
+        String expireTime = ""2050-09-30 15:59:23"";
+        String token = EncryptionUtils.getMd5(1 + expireTime + System.currentTimeMillis());
+        AccessToken accessToken = new AccessToken();
+        accessToken.setUserId(1);
+        accessToken.setExpireTime(DateUtils.stringToDate(expireTime));
+        accessToken.setToken(token);
+        accessToken.setCreateTime(new Date());
+        accessToken.setUpdateTime(new Date());
+
+        int insert = accessTokenMapper.insert(accessToken);
+
+        if (insert > 0) {
+            logger.info(""create access token success"");
+        } else {
+            logger.info(""create access token error"");
+        }
+
+        //creat process definition demo
+        //shell demo
+        ProxyResult shellResult = shellDemo(token, projectCode, tenantCode);
+        logger.info(""create shell demo "" + shellResult.getMsg());","[{'comment': '```suggestion\r\n        logger.info(""create shell demo {}"", shellResult.getMsg());\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'other same', 'commenter': 'caishunfeng'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProcessDefinitionDemo.java,"@@ -0,0 +1,778 @@
+package org.apache.dolphinscheduler.tools.demo;
+
+import static org.apache.dolphinscheduler.common.enums.ConditionType.NONE;
+import static org.apache.dolphinscheduler.common.enums.Flag.YES;
+import static org.apache.dolphinscheduler.common.enums.Priority.MEDIUM;
+import static org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum.PARALLEL;
+
+import org.apache.dolphinscheduler.common.enums.TimeoutFlag;
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.EncryptionUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.AccessToken;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.ProcessTaskRelationLog;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.TaskDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AccessTokenMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.UserMapper;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.LinkedHashMap;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.stereotype.Component;
+
+@Component
+public class ProcessDefinitionDemo {
+
+    private static final Logger logger = LoggerFactory.getLogger(ProcessDefinitionDemo.class);
+
+    @Value(""${demo.tenant-code}"")
+    private String tenantCode;
+
+    @Autowired
+    private ProjectMapper projectMapper;
+
+    @Autowired
+    private UserMapper userMapper;
+
+    @Autowired
+    private AccessTokenMapper accessTokenMapper;
+
+    @Autowired
+    private ProxyProcessDefinitionController proxyProcessDefinitionController;
+
+    public void createProcessDefinitionDemo() throws Exception {
+        //get user
+        User loginUser = userMapper.selectById(""1"");
+        Date now = new Date();
+
+        //create demo tenantCode
+        CreateDemoTenant createDemoTenant = new CreateDemoTenant();
+        createDemoTenant.createTenantCode(tenantCode);
+
+        //create and get demo projectCode
+        Project project = projectMapper.queryByName(""demo"");
+        if (project != null) {
+            logger.warn(""Project {} already exists."", project.getName());
+        }
+        try {
+            project = Project
+                .builder()
+                .name(""demo"")
+                .code(CodeGenerateUtils.getInstance().genCode())
+                .description("""")
+                .userId(loginUser.getId())
+                .userName(loginUser.getUserName())
+                .createTime(now)
+                .updateTime(now)
+                .build();
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""create project error"", e);
+        }
+        if (projectMapper.insert(project) > 0) {
+            logger.info(""create project success"");
+        } else {
+            throw new Exception(""create project error"");
+        }
+        Long projectCode = project.getCode();
+
+        // generate access token
+        String expireTime = ""2050-09-30 15:59:23"";
+        String token = EncryptionUtils.getMd5(1 + expireTime + System.currentTimeMillis());
+        AccessToken accessToken = new AccessToken();
+        accessToken.setUserId(1);
+        accessToken.setExpireTime(DateUtils.stringToDate(expireTime));
+        accessToken.setToken(token);
+        accessToken.setCreateTime(new Date());
+        accessToken.setUpdateTime(new Date());
+
+        int insert = accessTokenMapper.insert(accessToken);
+
+        if (insert > 0) {
+            logger.info(""create access token success"");
+        } else {
+            logger.info(""create access token error"");
+        }
+
+        //creat process definition demo
+        //shell demo
+        ProxyResult shellResult = shellDemo(token, projectCode, tenantCode);
+        logger.info(""create shell demo "" + shellResult.getMsg());
+
+        //subprocess demo
+        LinkedHashMap<String, Object> subProcess = (LinkedHashMap<String, Object>) shellResult.getData();
+        String subProcessCode = String.valueOf(subProcess.get(""code"")) ;
+        ProxyResult subProcessResult = subProcessDemo (token, projectCode, tenantCode, subProcessCode);
+        logger.info(""create subprocess demo "" + subProcessResult.getMsg());
+
+        //switch demo
+        ProxyResult switchResult = swicthDemo (token, projectCode, tenantCode);
+        logger.info(""create switch demo "" + switchResult.getMsg());
+
+        //condition demo
+        ProxyResult conditionResult = conditionDemo (token, projectCode, tenantCode);
+        logger.info(""create condition demo "" + conditionResult.getMsg());
+
+        //dependent demo
+        LinkedHashMap<String, Object> switchProcess = (LinkedHashMap<String, Object>) switchResult.getData();
+        String switchProcessCode = String.valueOf(switchProcess.get(""code"")) ;
+        ProxyResult dependentResult = dependentProxyResultDemo (token, projectCode, tenantCode, subProcessCode, switchProcessCode);
+        logger.info(""create dependent demo "" + dependentResult.getMsg());
+
+        //parameter context demo
+        ProxyResult parameterContextResult = parameterContextDemo (token, projectCode, tenantCode);
+        logger.info(""create parameter context demo "" + parameterContextResult.getMsg());
+
+        //clear log demo
+        ProxyResult clearLogResult = clearLogDemo (token, projectCode, tenantCode);
+        logger.info(""create clear log demo "" + clearLogResult.getMsg());
+
+    }
+
+    public ProxyResult clearLogDemo(String token, long projectCode, String tenantCode){
+
+        //get demo taskcode
+        List<Long> taskCodes = new ArrayList<>();
+        try {
+            for (int i = 0; i < 1; i++) {
+                taskCodes.add(CodeGenerateUtils.getInstance().genCode());
+            }
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""task code get error, "", e);
+        }
+        String taskCodeFirst = String.valueOf(taskCodes.get(0)).replaceAll(""\\[|\\]"", """");
+        String absolutePath = System.getProperty(""user.dir"");
+
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog();
+        processDefinitionLog.setName(""demo_clear_log"");
+        processDefinitionLog.setDescription(""Clear the DS log files from 30 days ago"");
+        processDefinitionLog.setGlobalParams(""[]"");
+        processDefinitionLog.setLocations(DemoContants.CLEAR_LOG_locations[0] + taskCodeFirst + DemoContants.CLEAR_LOG_locations[1]);
+        processDefinitionLog.setTimeout(0);
+
+        List<ProcessTaskRelationLog> processTaskRelationLogs = new ArrayList<>();
+        for (int i = 0; i < 1; i++) {
+            ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog();
+            processTaskRelationLog.setName("""");
+            processTaskRelationLog.setConditionType(NONE);
+            processTaskRelationLog.setConditionParams(""{}"");
+            processTaskRelationLogs.add(processTaskRelationLog);
+        }
+        ProcessTaskRelationLog processTaskRelationLogFirst = processTaskRelationLogs.get(0);
+        processTaskRelationLogFirst.setPreTaskCode(0);
+        processTaskRelationLogFirst.setPreTaskVersion(0);
+        processTaskRelationLogFirst.setPostTaskCode(taskCodes.get(0));
+        processTaskRelationLogFirst.setPostTaskVersion(1);
+
+        String taskRelationJson = JSONUtils.toJsonString(processTaskRelationLogs);
+
+        List<TaskDefinitionLog> taskDefinitionLogs = new ArrayList<>();
+        for (int i = 0; i < 1; i++) {
+            TaskDefinitionLog taskDefinitionLog = new TaskDefinitionLog();
+            taskDefinitionLog.setFlag(YES);
+            taskDefinitionLog.setDelayTime(0);
+            taskDefinitionLog.setEnvironmentCode(-1);
+            taskDefinitionLog.setFailRetryInterval(1);
+            taskDefinitionLog.setFailRetryTimes(0);
+            taskDefinitionLog.setTaskPriority(MEDIUM);
+            taskDefinitionLog.setTimeout(0);
+            taskDefinitionLog.setTimeoutFlag(TimeoutFlag.CLOSE);
+            taskDefinitionLog.setTimeoutNotifyStrategy(null);
+            taskDefinitionLog.setWorkerGroup(""default"");
+            taskDefinitionLog.setTaskType(""SHELL"");
+            taskDefinitionLogs.add(taskDefinitionLog);
+        }
+        TaskDefinitionLog taskDefinitionLogFirst = taskDefinitionLogs.get(0);
+        taskDefinitionLogFirst.setCode(taskCodes.get(0));
+        taskDefinitionLogFirst.setName(""Clear log node"");
+        taskDefinitionLogFirst.setDescription("""");
+        taskDefinitionLogFirst.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""cd cd "" + absolutePath + ""\\r\\nfind ./logs/ -mtime +30 -name \\\""*.log\\\"" -exec rm -rf {} \\\\;\"",\""resourceList\"":[]}"");
+
+        String taskDefinitionJson = JSONUtils.toJsonString(taskDefinitionLogs);
+
+        ProxyResult ProxyResult = proxyProcessDefinitionController.createProcessDefinition(token, projectCode,
+            processDefinitionLog.getName(),
+            processDefinitionLog.getDescription(),
+            processDefinitionLog.getGlobalParams(),
+            processDefinitionLog.getLocations(),
+            processDefinitionLog.getTimeout(),
+            tenantCode,
+            taskRelationJson,
+            taskDefinitionJson,
+            PARALLEL);
+        return ProxyResult;
+    }
+    public ProxyResult dependentProxyResultDemo(String token, long projectCode, String tenantCode, String shellProcessCode, String switchProcessCode){
+
+        //get demo taskcode
+        List<Long> taskCodes = new ArrayList<>();
+        try {
+            for (int i = 0; i < 2; i++) {
+                taskCodes.add(CodeGenerateUtils.getInstance().genCode());
+            }
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""task code get error, "", e);
+        }
+        String taskCodeFirst = String.valueOf(taskCodes.get(0)).replaceAll(""\\[|\\]"", """");
+        String taskCodeSecond = String.valueOf(taskCodes.get(1)).replaceAll(""\\[|\\]"", """");
+
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog();
+        processDefinitionLog.setName(""demo_dependent"");
+        processDefinitionLog.setDescription(""Check the completion of daily tasks"");
+        processDefinitionLog.setGlobalParams(""[]"");
+        processDefinitionLog.setLocations(DemoContants.DEPENDENT_locations[0] + taskCodeFirst + DemoContants.DEPENDENT_locations[1] + taskCodeSecond + DemoContants.DEPENDENT_locations[2]);
+        processDefinitionLog.setTimeout(0);
+
+        List<ProcessTaskRelationLog> processTaskRelationLogs = new ArrayList<>();
+        for (int i = 0; i < 2; i++) {
+            ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog();
+            processTaskRelationLog.setName("""");
+            processTaskRelationLog.setConditionType(NONE);
+            processTaskRelationLog.setConditionParams(""{}"");
+            processTaskRelationLogs.add(processTaskRelationLog);
+        }
+        ProcessTaskRelationLog processTaskRelationLogFirst = processTaskRelationLogs.get(0);
+        processTaskRelationLogFirst.setPreTaskCode(0);
+        processTaskRelationLogFirst.setPreTaskVersion(0);
+        processTaskRelationLogFirst.setPostTaskCode(taskCodes.get(0));
+        processTaskRelationLogFirst.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogSecond = processTaskRelationLogs.get(1);
+        processTaskRelationLogSecond.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogSecond.setPreTaskVersion(1);
+        processTaskRelationLogSecond.setPostTaskCode(taskCodes.get(1));
+        processTaskRelationLogSecond.setPostTaskVersion(1);
+
+        String taskRelationJson = JSONUtils.toJsonString(processTaskRelationLogs);
+
+        List<TaskDefinitionLog> taskDefinitionLogs = new ArrayList<>();
+        for (int i = 0; i < 2; i++) {
+            TaskDefinitionLog taskDefinitionLog = new TaskDefinitionLog();
+            taskDefinitionLog.setFlag(YES);
+            taskDefinitionLog.setDelayTime(0);
+            taskDefinitionLog.setEnvironmentCode(-1);
+            taskDefinitionLog.setFailRetryInterval(1);
+            taskDefinitionLog.setFailRetryTimes(0);
+            taskDefinitionLog.setTaskPriority(MEDIUM);
+            taskDefinitionLog.setTimeout(0);
+            taskDefinitionLog.setTimeoutFlag(TimeoutFlag.CLOSE);
+            taskDefinitionLog.setTimeoutNotifyStrategy(null);
+            taskDefinitionLog.setWorkerGroup(""default"");
+            taskDefinitionLogs.add(taskDefinitionLog);
+        }
+        TaskDefinitionLog taskDefinitionLogFirst = taskDefinitionLogs.get(0);
+        taskDefinitionLogFirst.setCode(taskCodes.get(0));
+        taskDefinitionLogFirst.setName(""Weekly report task"");
+        taskDefinitionLogFirst.setDescription(""The weekly report task requires the demo_shell and demo_switch tasks to be successfully executed every day of the last week"");
+        taskDefinitionLogFirst.setTaskParams(""{\""localParams\"":[],\""resourceList\"":[],\""dependence\"":{\""relation\"":\""AND\"",\""dependTaskList\"":[{\""relation\"":\""AND\"",\""dependItemList\"":[{\""projectCode\"":""+projectCode+"",\""definitionCode\"":""+shellProcessCode+"",\""depTaskCode\"":0,\""cycle\"":\""day\"",\""dateValue\"":\""last1Days\"",\""state\"":null},{\""projectCode\"":""+projectCode+"",\""definitionCode\"":""+switchProcessCode+"",\""depTaskCode\"":0,\""cycle\"":\""day\"",\""dateValue\"":\""last1Days\"",\""state\"":null}]}]}}"");
+        taskDefinitionLogFirst.setTaskType(""DEPENDENT"");
+
+        TaskDefinitionLog taskDefinitionLogSecond = taskDefinitionLogs.get(1);
+        taskDefinitionLogSecond.setCode(taskCodes.get(1));
+        taskDefinitionLogSecond.setName(""Weekly Report Task Result"");
+        taskDefinitionLogSecond.setDescription(""Result report after the completion of the weekly report task"");
+        taskDefinitionLogSecond.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""end of report\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogSecond.setTaskType(""SHELL"");
+        String taskDefinitionJson = JSONUtils.toJsonString(taskDefinitionLogs);
+
+        ProxyResult ProxyResult = proxyProcessDefinitionController.createProcessDefinition(token, projectCode,
+            processDefinitionLog.getName(),
+            processDefinitionLog.getDescription(),
+            processDefinitionLog.getGlobalParams(),
+            processDefinitionLog.getLocations(),
+            processDefinitionLog.getTimeout(),
+            tenantCode,
+            taskRelationJson,
+            taskDefinitionJson,
+            PARALLEL);
+        return ProxyResult;
+    }
+    public ProxyResult parameterContextDemo(String token, long projectCode, String tenantCode){
+
+        //get demo taskcode
+        List<Long> taskCodes = new ArrayList<>();
+        try {
+            for (int i = 0; i < 2; i++) {
+                taskCodes.add(CodeGenerateUtils.getInstance().genCode());
+            }
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""task code get error, "", e);
+        }
+        String taskCodeFirst = String.valueOf(taskCodes.get(0)).replaceAll(""\\[|\\]"", """");
+        String taskCodeSecond = String.valueOf(taskCodes.get(1)).replaceAll(""\\[|\\]"", """");
+
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog();
+        processDefinitionLog.setName(""demo_parameter_context"");
+        processDefinitionLog.setDescription(""Upstream and downstream task node parameter transfer"");
+        processDefinitionLog.setGlobalParams(DemoContants.PARAMETER_CONTEXT_PARAMS);
+        processDefinitionLog.setLocations(DemoContants.PARAMETER_CONTEXT_locations[0] + taskCodeFirst + DemoContants.PARAMETER_CONTEXT_locations[1] + taskCodeSecond + DemoContants.PARAMETER_CONTEXT_locations[2]);
+        processDefinitionLog.setTimeout(0);
+
+        List<ProcessTaskRelationLog> processTaskRelationLogs = new ArrayList<>();
+        for (int i = 0; i < 2; i++) {
+            ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog();
+            processTaskRelationLog.setName("""");
+            processTaskRelationLog.setConditionType(NONE);
+            processTaskRelationLog.setConditionParams(""{}"");
+            processTaskRelationLogs.add(processTaskRelationLog);
+        }
+        ProcessTaskRelationLog processTaskRelationLogFirst = processTaskRelationLogs.get(0);
+        processTaskRelationLogFirst.setPreTaskCode(0);
+        processTaskRelationLogFirst.setPreTaskVersion(0);
+        processTaskRelationLogFirst.setPostTaskCode(taskCodes.get(0));
+        processTaskRelationLogFirst.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogSecond = processTaskRelationLogs.get(1);
+        processTaskRelationLogSecond.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogSecond.setPreTaskVersion(1);
+        processTaskRelationLogSecond.setPostTaskCode(taskCodes.get(1));
+        processTaskRelationLogSecond.setPostTaskVersion(1);
+
+        String taskRelationJson = JSONUtils.toJsonString(processTaskRelationLogs);
+
+        List<TaskDefinitionLog> taskDefinitionLogs = new ArrayList<>();
+        for (int i = 0; i < 2; i++) {
+            TaskDefinitionLog taskDefinitionLog = new TaskDefinitionLog();
+            taskDefinitionLog.setFlag(YES);
+            taskDefinitionLog.setDelayTime(0);
+            taskDefinitionLog.setEnvironmentCode(-1);
+            taskDefinitionLog.setFailRetryInterval(1);
+            taskDefinitionLog.setFailRetryTimes(0);
+            taskDefinitionLog.setTaskPriority(MEDIUM);
+            taskDefinitionLog.setTimeout(0);
+            taskDefinitionLog.setTimeoutFlag(TimeoutFlag.CLOSE);
+            taskDefinitionLog.setTimeoutNotifyStrategy(null);
+            taskDefinitionLog.setWorkerGroup(""default"");
+            taskDefinitionLog.setTaskType(""SHELL"");
+            taskDefinitionLogs.add(taskDefinitionLog);
+        }
+        TaskDefinitionLog taskDefinitionLogFirst = taskDefinitionLogs.get(0);
+        taskDefinitionLogFirst.setCode(taskCodes.get(0));
+        taskDefinitionLogFirst.setName(""Upstream task node"");
+        taskDefinitionLogFirst.setDescription(""Create a local parameter and pass the assignment to the downstream"");
+        taskDefinitionLogFirst.setTaskParams(""{\""localParams\"":[{\""prop\"":\""value\"",\""direct\"":\""IN\"",\""type\"":\""VARCHAR\"",\""value\"":\""0\""},{\""prop\"":\""output\"",\""direct\"":\""OUT\"",\""type\"":\""VARCHAR\"",\""value\"":\""\""}],\""rawScript\"":\""echo \\\""====Node start====\\\""\\r\\necho '${setValue(output=1)}'\\r\\n\\r\\necho ${output}\\r\\necho ${value}\\r\\n\\r\\necho \\\""====Node end====\\\""\"",\""resourceList\"":[]}"");
+
+        TaskDefinitionLog taskDefinitionLogSecond = taskDefinitionLogs.get(1);
+        taskDefinitionLogSecond.setCode(taskCodes.get(1));
+        taskDefinitionLogSecond.setName(""Downstream task node"");
+        taskDefinitionLogSecond.setDescription(""Test outputs the parameters passed by the upstream task"");
+        taskDefinitionLogSecond.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""====node start====\\\""\\r\\n\\r\\necho ${output}\\r\\n\\r\\necho ${value}\\r\\n\\r\\necho \\\""====Node end====\\\""\"",\""resourceList\"":[]}"");
+        String taskDefinitionJson = JSONUtils.toJsonString(taskDefinitionLogs);
+
+        ProxyResult ProxyResult = proxyProcessDefinitionController.createProcessDefinition(token, projectCode,
+            processDefinitionLog.getName(),
+            processDefinitionLog.getDescription(),
+            processDefinitionLog.getGlobalParams(),
+            processDefinitionLog.getLocations(),
+            processDefinitionLog.getTimeout(),
+            tenantCode,
+            taskRelationJson,
+            taskDefinitionJson,
+            PARALLEL);
+        return ProxyResult;
+    }
+    public ProxyResult conditionDemo(String token, long projectCode, String tenantCode){
+
+        //get demo taskcode
+        List<Long> taskCodes = new ArrayList<>();
+        try {
+            for (int i = 0; i < 4; i++) {
+                taskCodes.add(CodeGenerateUtils.getInstance().genCode());
+            }
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""task code get error, "", e);
+        }
+        String taskCodeFirst = String.valueOf(taskCodes.get(0)).replaceAll(""\\[|\\]"", """");
+        String taskCodeSecond = String.valueOf(taskCodes.get(1)).replaceAll(""\\[|\\]"", """");
+        String taskCodeThird = String.valueOf(taskCodes.get(2)).replaceAll(""\\[|\\]"", """");
+        String taskCodeFourth = String.valueOf(taskCodes.get(3)).replaceAll(""\\[|\\]"", """");
+
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog();
+        processDefinitionLog.setName(""demo_condition"");
+        processDefinitionLog.setDescription(""Coin Toss"");
+        processDefinitionLog.setGlobalParams(""[]"");
+        processDefinitionLog.setLocations(DemoContants.CONDITION_locations[0] + taskCodeFirst + DemoContants.CONDITION_locations[1] + taskCodeSecond + DemoContants.CONDITION_locations[2] + taskCodeThird + DemoContants.CONDITION_locations[3] + taskCodeFourth + DemoContants.CONDITION_locations[4]);
+        processDefinitionLog.setTimeout(0);
+
+        List<ProcessTaskRelationLog> processTaskRelationLogs = new ArrayList<>();
+        for (int i = 0; i < 4; i++) {
+            ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog();
+            processTaskRelationLog.setName("""");
+            processTaskRelationLog.setConditionType(NONE);
+            processTaskRelationLog.setConditionParams(""{}"");
+            processTaskRelationLogs.add(processTaskRelationLog);
+        }
+        ProcessTaskRelationLog processTaskRelationLogFirst = processTaskRelationLogs.get(0);
+        processTaskRelationLogFirst.setPreTaskCode(0);
+        processTaskRelationLogFirst.setPreTaskVersion(0);
+        processTaskRelationLogFirst.setPostTaskCode(taskCodes.get(1));
+        processTaskRelationLogFirst.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogSecond = processTaskRelationLogs.get(1);
+        processTaskRelationLogSecond.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogSecond.setPreTaskVersion(1);
+        processTaskRelationLogSecond.setPostTaskCode(taskCodes.get(2));
+        processTaskRelationLogSecond.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogThird = processTaskRelationLogs.get(2);
+        processTaskRelationLogThird.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogThird.setPreTaskVersion(1);
+        processTaskRelationLogThird.setPostTaskCode(taskCodes.get(3));
+        processTaskRelationLogThird.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogFourth = processTaskRelationLogs.get(3);
+        processTaskRelationLogFourth.setPreTaskCode(taskCodes.get(1));
+        processTaskRelationLogFourth.setPreTaskVersion(1);
+        processTaskRelationLogFourth.setPostTaskCode(taskCodes.get(0));
+        processTaskRelationLogFourth.setPostTaskVersion(1);
+        String taskRelationJson = JSONUtils.toJsonString(processTaskRelationLogs);
+
+        List<TaskDefinitionLog> taskDefinitionLogs = new ArrayList<>();
+        for (int i = 0; i < 4; i++) {
+            TaskDefinitionLog taskDefinitionLog = new TaskDefinitionLog();
+            taskDefinitionLog.setFlag(YES);
+            taskDefinitionLog.setDelayTime(0);
+            taskDefinitionLog.setEnvironmentCode(-1);
+            taskDefinitionLog.setFailRetryInterval(1);
+            taskDefinitionLog.setFailRetryTimes(0);
+            taskDefinitionLog.setTaskPriority(MEDIUM);
+            taskDefinitionLog.setTimeout(0);
+            taskDefinitionLog.setTimeoutFlag(TimeoutFlag.CLOSE);
+            taskDefinitionLog.setTimeoutNotifyStrategy(null);
+            taskDefinitionLog.setWorkerGroup(""default"");
+            taskDefinitionLogs.add(taskDefinitionLog);
+        }
+        TaskDefinitionLog taskDefinitionLogFirst = taskDefinitionLogs.get(0);
+        taskDefinitionLogFirst.setCode(taskCodes.get(0));
+        taskDefinitionLogFirst.setName(""condition"");
+        taskDefinitionLogFirst.setDescription(""head is the status of success, tail is the status of failure"");
+        taskDefinitionLogFirst.setTaskParams(""{\""localParams\"":[],\""resourceList\"":[],\""dependence\"":{\""relation\"":\""AND\"",\""dependTaskList\"":[]},\""conditionResult\"":{\""successNode\"":[""+taskCodeThird+""],\""failedNode\"":[""+taskCodeFourth+""]}}"");
+        taskDefinitionLogFirst.setTaskType(""CONDITIONS"");
+
+        TaskDefinitionLog taskDefinitionLogSecond = taskDefinitionLogs.get(1);
+        taskDefinitionLogSecond.setCode(taskCodes.get(1));
+        taskDefinitionLogSecond.setName(""coin"");
+        taskDefinitionLogSecond.setDescription(""Toss a coin"");
+        taskDefinitionLogSecond.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""Start\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogSecond.setTaskType(""SHELL"");
+
+        TaskDefinitionLog taskDefinitionLogThird = taskDefinitionLogs.get(2);
+        taskDefinitionLogThird.setCode(taskCodes.get(2));
+        taskDefinitionLogThird.setName(""head"");
+        taskDefinitionLogThird.setDescription(""Choose to learn if the result is head"");
+        taskDefinitionLogThird.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""Start learning\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogThird.setTaskType(""SHELL"");
+
+        TaskDefinitionLog taskDefinitionLogFourth = taskDefinitionLogs.get(3);
+        taskDefinitionLogFourth.setCode(taskCodes.get(3));
+        taskDefinitionLogFourth.setName(""tail"");
+        taskDefinitionLogFourth.setDescription(""Choose to play if the result is tail"");
+        taskDefinitionLogFourth.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""Start playing\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogFourth.setTaskType(""SHELL"");
+        String taskDefinitionJson = JSONUtils.toJsonString(taskDefinitionLogs);
+
+        ProxyResult ProxyResult = proxyProcessDefinitionController.createProcessDefinition(token, projectCode,
+            processDefinitionLog.getName(),
+            processDefinitionLog.getDescription(),
+            processDefinitionLog.getGlobalParams(),
+            processDefinitionLog.getLocations(),
+            processDefinitionLog.getTimeout(),
+            tenantCode,
+            taskRelationJson,
+            taskDefinitionJson,
+            PARALLEL);
+        return ProxyResult;
+    }
+    public ProxyResult swicthDemo(String token, long projectCode, String tenantCode){
+
+        //get demo taskcode
+        List<Long> taskCodes = new ArrayList<>();
+        try {
+            for (int i = 0; i < 4; i++) {
+                taskCodes.add(CodeGenerateUtils.getInstance().genCode());
+            }
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""task code get error, "", e);
+        }
+        String taskCodeFirst = String.valueOf(taskCodes.get(0)).replaceAll(""\\[|\\]"", """");
+        String taskCodeSecond = String.valueOf(taskCodes.get(1)).replaceAll(""\\[|\\]"", """");
+        String taskCodeThird = String.valueOf(taskCodes.get(2)).replaceAll(""\\[|\\]"", """");
+        String taskCodeFourth = String.valueOf(taskCodes.get(3)).replaceAll(""\\[|\\]"", """");
+
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog();
+        processDefinitionLog.setName(""demo_switch"");
+        processDefinitionLog.setDescription(""Determine which task to perform based on conditions"");
+        processDefinitionLog.setGlobalParams(DemoContants.SWITCH_GLOBAL_PARAMS);
+        processDefinitionLog.setLocations(DemoContants.SWITCH_locations[0] + taskCodeFirst + DemoContants.SWITCH_locations[1] + taskCodeSecond + DemoContants.SWITCH_locations[2] + taskCodeThird + DemoContants.SWITCH_locations[3] + taskCodeFourth + DemoContants.SWITCH_locations[4]);
+        processDefinitionLog.setTimeout(0);
+
+        List<ProcessTaskRelationLog> processTaskRelationLogs = new ArrayList<>();
+        for (int i = 0; i < 4; i++) {
+            ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog();
+            processTaskRelationLog.setName("""");
+            processTaskRelationLog.setConditionType(NONE);
+            processTaskRelationLog.setConditionParams(""{}"");
+            processTaskRelationLogs.add(processTaskRelationLog);
+        }
+        ProcessTaskRelationLog processTaskRelationLogFirst = processTaskRelationLogs.get(0);
+        processTaskRelationLogFirst.setPreTaskCode(0);
+        processTaskRelationLogFirst.setPreTaskVersion(0);
+        processTaskRelationLogFirst.setPostTaskCode(taskCodes.get(0));
+        processTaskRelationLogFirst.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogSecond = processTaskRelationLogs.get(1);
+        processTaskRelationLogSecond.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogSecond.setPreTaskVersion(1);
+        processTaskRelationLogSecond.setPostTaskCode(taskCodes.get(1));
+        processTaskRelationLogSecond.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogThird = processTaskRelationLogs.get(2);
+        processTaskRelationLogThird.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogThird.setPreTaskVersion(1);
+        processTaskRelationLogThird.setPostTaskCode(taskCodes.get(2));
+        processTaskRelationLogThird.setPostTaskVersion(1);
+
+        ProcessTaskRelationLog processTaskRelationLogFourth = processTaskRelationLogs.get(3);
+        processTaskRelationLogFourth.setPreTaskCode(taskCodes.get(0));
+        processTaskRelationLogFourth.setPreTaskVersion(1);
+        processTaskRelationLogFourth.setPostTaskCode(taskCodes.get(3));
+        processTaskRelationLogFourth.setPostTaskVersion(1);
+        String taskRelationJson = JSONUtils.toJsonString(processTaskRelationLogs);
+
+        List<TaskDefinitionLog> taskDefinitionLogs = new ArrayList<>();
+        for (int i = 0; i < 4; i++) {
+            TaskDefinitionLog taskDefinitionLog = new TaskDefinitionLog();
+            taskDefinitionLog.setFlag(YES);
+            taskDefinitionLog.setDelayTime(0);
+            taskDefinitionLog.setEnvironmentCode(-1);
+            taskDefinitionLog.setFailRetryInterval(1);
+            taskDefinitionLog.setFailRetryTimes(0);
+            taskDefinitionLog.setTaskPriority(MEDIUM);
+            taskDefinitionLog.setTimeout(0);
+            taskDefinitionLog.setTimeoutFlag(TimeoutFlag.CLOSE);
+            taskDefinitionLog.setTimeoutNotifyStrategy(null);
+            taskDefinitionLog.setWorkerGroup(""default"");
+            taskDefinitionLogs.add(taskDefinitionLog);
+        }
+        TaskDefinitionLog taskDefinitionLogFirst = taskDefinitionLogs.get(0);
+        taskDefinitionLogFirst.setCode(taskCodes.get(0));
+        taskDefinitionLogFirst.setName(""switch node"");
+        taskDefinitionLogFirst.setDescription(""The global parameter is to execute TaskA for A, and for B to execute TaskB, otherwise the default task is executed"");
+        taskDefinitionLogFirst.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""\"",\""resourceList\"":[],\""switchResult\"":{\""dependTaskList\"":[{\""condition\"":\""${switchValue} == \\\""A\\\""\"",\""nextNode\"":"" + taskCodeThird + ""},{\""condition\"":\""${switchValue} == \\\""B\\\""\"",\""nextNode\"":""+ taskCodeFourth + ""}],\""nextNode\"":""+taskCodeSecond+""}}"");
+        taskDefinitionLogFirst.setTaskType(""SWITCH"");
+
+        TaskDefinitionLog taskDefinitionLogSecond = taskDefinitionLogs.get(1);
+        taskDefinitionLogSecond.setCode(taskCodes.get(1));
+        taskDefinitionLogSecond.setName(""default"");
+        taskDefinitionLogSecond.setDescription(""executed default task"");
+        taskDefinitionLogSecond.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""default\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogSecond.setTaskType(""SHELL"");
+
+        TaskDefinitionLog taskDefinitionLogThird = taskDefinitionLogs.get(2);
+        taskDefinitionLogThird.setCode(taskCodes.get(2));
+        taskDefinitionLogThird.setName(""TaskA"");
+        taskDefinitionLogThird.setDescription(""execute TaskA"");
+        taskDefinitionLogThird.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""TaskA\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogThird.setTaskType(""SHELL"");
+
+        TaskDefinitionLog taskDefinitionLogFourth = taskDefinitionLogs.get(3);
+        taskDefinitionLogFourth.setCode(taskCodes.get(3));
+        taskDefinitionLogFourth.setName(""TaskB"");
+        taskDefinitionLogFourth.setDescription(""execute TaskB"");
+        taskDefinitionLogFourth.setTaskParams(""{\""localParams\"":[],\""rawScript\"":\""echo \\\""TaskB\\\""\"",\""resourceList\"":[]}"");
+        taskDefinitionLogFourth.setTaskType(""SHELL"");
+        String taskDefinitionJson = JSONUtils.toJsonString(taskDefinitionLogs);
+
+        ProxyResult ProxyResult = proxyProcessDefinitionController.createProcessDefinition(token, projectCode,
+            processDefinitionLog.getName(),
+            processDefinitionLog.getDescription(),
+            processDefinitionLog.getGlobalParams(),
+            processDefinitionLog.getLocations(),
+            processDefinitionLog.getTimeout(),
+            tenantCode,
+            taskRelationJson,
+            taskDefinitionJson,
+            PARALLEL);
+        return ProxyResult;
+    }
+    public ProxyResult shellDemo(String token, long projectCode, String tenantCode){
+
+        //get demo taskcode
+        List<Long> taskCodes = new ArrayList<>();
+        try {
+            for (int i = 0; i < 3; i++) {
+                taskCodes.add(CodeGenerateUtils.getInstance().genCode());
+            }
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""task code get error, "", e);
+        }
+        String taskCodeFirst = String.valueOf(taskCodes.get(0)).replaceAll(""\\[|\\]"", """");
+        String taskCodeSecond = String.valueOf(taskCodes.get(1)).replaceAll(""\\[|\\]"", """");
+        String taskCodeThird = String.valueOf(taskCodes.get(2)).replaceAll(""\\[|\\]"", """");
+
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog();
+        processDefinitionLog.setName(""demo_shell"");
+        processDefinitionLog.setDescription(""Production, processing and sales of a series of processes"");
+        processDefinitionLog.setGlobalParams(DemoContants.SHELL_GLOBAL_PARAMS);
+        processDefinitionLog.setLocations(DemoContants.SHELL_locations[0] + taskCodeFirst + DemoContants.SHELL_locations[1] + taskCodeSecond + DemoContants.SHELL_locations[2] + taskCodeThird + DemoContants.SHELL_locations[3]);","[{'comment': ""When location is null, it will auto format in the UI.\r\nSo we don't need to set location here."", 'commenter': 'caishunfeng'}]"
11759,docs/docs/en/guide/demo.md,"@@ -0,0 +1,37 @@
+# DolphinScheduler Initialize The Workflow Demo
+
+## Prepare
+
+### Backup Previous Version's Files and Database
+
+To prevent data loss by some miss-operation, it is recommended to back up data before initializing the workflow demo. The backup way according to your environment.
+
+### Download the Latest Version Installation Package
+
+Download the latest binary distribute package from [download](/en-us/download/download.html) and then put it in the different
+directory where current service running. And all below command is running in this directory.
+
+## Start
+
+### Start Services of DolphinScheduler
+
+Start all services of dolphinscheduler according to your deployment method. If you deploy your dolphinscheduler according to [cluster deployment](installation/cluster.md), you can start all services by command `sh ./script/start-all.sh`.
+
+### Database Configuration
+
+Initializing the workflow demo needs to store metabase in other database like MySQL or PostgreSQL, they have to change some configuration. Follow the instructions in [datasource-setting](howto/datasource-setting.md) `Standalone Switching Metadata Database Configuration` section to create and initialize database.
+
+### Tenant Configuration
+
+#### Change `dolphinscheduler-tools/resources/application.yaml` Placement Details
+
+        ```
+        demo:
+          tenant-code: default
+          api-server-port: 5173","[{'comment': '```suggestion\r\ndemo:\r\n  tenant-code: default\r\n  api-server-port: 5173\r\n```', 'commenter': 'zhongjiajie'}]"
11759,docs/docs/zh/guide/demo.md,"@@ -0,0 +1,37 @@
+# DolphinScheduler 初始化工作流 demo
+
+## 准备工作
+
+### 备份上一版本文件和数据库
+
+为了防止操作错误导致数据丢失，建议初始化工作流 demo 服务之前备份数据，备份方法请结合你数据库的情况来定
+
+### 下载新版本的安装包
+
+在[下载](/zh-cn/download/download.html)页面下载最新版本的二进制安装包，并将二进制包放到与当前 dolphinscheduler 服务不一样的路径中，以下服务启动操作都需要在新版本的目录进行。
+
+## 服务启动步骤
+
+### 开启 dolphinscheduler 服务
+
+根据你部署方式开启 dolphinscheduler 的所有服务，如果你是通过 [集群部署](installation/cluster.md) 来部署你的 dolphinscheduler 的话，可以通过 `sh ./script/start-all.sh` 开启全部服务。
+
+### 数据库配置
+
+初始化工作流 demo 服务需要使用 MySQL 或 PostgreSQL 等其他数据库作为其元数据存储数据，因此必须更改一些配置。
+请参考[数据源配置](howto/datasource-setting.md) `Standalone 切换元数据库`创建并初始化数据库 ，然后运行 demo 服务启动脚本。
+
+### 租户配置
+
+#### 修改 `dolphinscheduler-tools/resources/application.yaml` 配置内容
+
+        ```
+        demo:
+          tenant-code: default
+          api-server-port: 5173","[{'comment': '```suggestion\r\ndemo:\r\n  tenant-code: default\r\n  api-server-port: 5173\r\n```', 'commenter': 'zhongjiajie'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/CreateDemoTenant.java,"@@ -0,0 +1,55 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.tools.demo;
+
+import org.apache.dolphinscheduler.dao.entity.Tenant;
+import org.apache.dolphinscheduler.dao.mapper.TenantMapper;
+
+import java.util.Date;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+
+public class CreateDemoTenant {
+
+    private static final Logger logger = LoggerFactory.getLogger(CreateDemoTenant.class);
+    @Autowired
+    private TenantMapper tenantMapper;
+
+    public void createTenantCode(String tenantCode) {
+        Date now = new Date();
+
+        if (!tenantCode.equals(""default"")) {
+            Boolean existTenant = tenantMapper.existTenant(tenantCode);
+            if (!Boolean.TRUE.equals(existTenant)) {
+                Tenant tenant = new Tenant();
+                tenant.setTenantCode(tenantCode);
+                tenant.setQueueId(1);","[{'comment': 'can we use a Constant variable here instead of a bare number? also to `userMapper.selectById(""1"")` in processdefinitionDemo.java', 'commenter': 'zhongjiajie'}]"
11759,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProcessDefinitionDemo.java,"@@ -0,0 +1,827 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.tools.demo;
+
+import static org.apache.dolphinscheduler.common.enums.ConditionType.NONE;
+import static org.apache.dolphinscheduler.common.enums.Flag.YES;
+import static org.apache.dolphinscheduler.common.enums.Priority.MEDIUM;
+import static org.apache.dolphinscheduler.common.enums.ProcessExecutionTypeEnum.PARALLEL;
+
+import org.apache.dolphinscheduler.common.enums.TimeoutFlag;
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils;
+import org.apache.dolphinscheduler.common.utils.DateUtils;
+import org.apache.dolphinscheduler.common.utils.EncryptionUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.AccessToken;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.ProcessTaskRelationLog;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.TaskDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.AccessTokenMapper;
+import org.apache.dolphinscheduler.dao.mapper.ProjectMapper;
+import org.apache.dolphinscheduler.dao.mapper.UserMapper;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.LinkedHashMap;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.beans.factory.annotation.Value;
+import org.springframework.stereotype.Component;
+
+@Component
+public class ProcessDefinitionDemo {
+
+    private static final Logger logger = LoggerFactory.getLogger(ProcessDefinitionDemo.class);
+
+    @Value(""${demo.tenant-code}"")
+    private String tenantCode;
+
+    @Autowired
+    private ProjectMapper projectMapper;
+
+    @Autowired
+    private UserMapper userMapper;
+
+    @Autowired
+    private AccessTokenMapper accessTokenMapper;
+
+    @Autowired
+    private ProxyProcessDefinitionController proxyProcessDefinitionController;
+
+    public void createProcessDefinitionDemo() throws Exception {
+        // get user
+        User loginUser = userMapper.selectById(""1"");
+        Date now = new Date();
+
+        // create demo tenantCode
+        CreateDemoTenant createDemoTenant = new CreateDemoTenant();
+        createDemoTenant.createTenantCode(tenantCode);
+
+        // create and get demo projectCode
+        Project project = projectMapper.queryByName(""demo"");
+        if (project != null) {
+            logger.warn(""Project {} already exists."", project.getName());
+        }
+        try {
+            project = Project
+                    .builder()
+                    .name(""demo"")
+                    .code(CodeGenerateUtils.getInstance().genCode())
+                    .description("""")
+                    .userId(loginUser.getId())
+                    .userName(loginUser.getUserName())
+                    .createTime(now)
+                    .updateTime(now)
+                    .build();
+        } catch (CodeGenerateUtils.CodeGenerateException e) {
+            logger.error(""create project error"", e);
+        }
+        if (projectMapper.insert(project) > 0) {
+            logger.info(""create project success"");
+        } else {
+            throw new Exception(""create project error"");
+        }
+        Long projectCode = null;
+        try {
+            projectCode = project.getCode();
+        } catch (NullPointerException e) {
+            logger.error(""project code is null"", e);
+        }
+
+        // generate access token
+        String expireTime = ""2050-09-30 15:59:23"";","[{'comment': 'maybe we should better add those constant values in this file to `DemoContants.java`', 'commenter': 'zhongjiajie'}]"
11759,docs/docs/en/guide/demo.md,"@@ -0,0 +1,37 @@
+# DolphinScheduler Initialize The Workflow Demo","[{'comment': 'I think we should also add a hyperlink to https://dolphinscheduler.apache.org/en-us/docs/latest/user_doc/guide/start/quick-start.html to told user we can create demo, WDYT?', 'commenter': 'zhongjiajie'}]"
11762,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/NetUtils.java,"@@ -42,7 +42,8 @@
  */
 public class NetUtils {
 
-    private static final Pattern IP_PATTERN = Pattern.compile(""\\d{1,3}(\\.\\d{1,3}){3,5}$"");
+    private static final Pattern IP_PATTERN = Pattern","[{'comment': ""It's better to directly use `IPAddressUtil.isIPv4LiteralAddress()`."", 'commenter': 'ruanwenjun'}, {'comment': 'ohh, i agree with u.  I always thought that `IPAddressUtil.isIPv4LiteralAddress()` used the same pattern as DS, but just checked the source code again and found that the maximum value was also judged. i will update it later. thx.\r\n![image](https://user-images.githubusercontent.com/20518339/188320928-8fbfd2c0-0455-4be9-971e-786003faebc7.png)\r\n', 'commenter': 'DarkAssassinator'}, {'comment': 'done.', 'commenter': 'DarkAssassinator'}]"
11762,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/NetUtilsTest.java,"@@ -99,6 +99,21 @@ public void testIsValidAddress() {
         address = mock(InetAddress.class);
         when(address.getHostAddress()).thenReturn(""1.2.3.4"");
         assertTrue(NetUtils.isValidV4Address(address));
+        address = mock(InetAddress.class);
+        when(address.getHostAddress()).thenReturn(""1.2.3.4:80"");
+        assertFalse(NetUtils.isValidV4Address(address));
+        address = mock(InetAddress.class);
+        when(address.getHostAddress()).thenReturn(""256.0.0.1"");
+        assertFalse(NetUtils.isValidV4Address(address));
+        address = mock(InetAddress.class);
+        when(address.getHostAddress()).thenReturn(""127.1"");","[{'comment': ""'127.1' is a validated IpV4 \r\nhttps://superuser.com/questions/614001/why-can-i-ping-127-1"", 'commenter': 'ruanwenjun'}, {'comment': 'do we need to consider these unpopular IP formats? such as 127.1, 127.1.1 ', 'commenter': 'DarkAssassinator'}, {'comment': ""> '127.1' is a validated IpV4 https://superuser.com/questions/614001/why-can-i-ping-127-1\r\n\r\nHi @ruanwenjun , could we use `InetAddress.isReachable()` to define this IP? because Ipv4 has many format"", 'commenter': 'DarkAssassinator'}, {'comment': 'Use `IPAddressUtil.isIPv4LiteralAddress` is enough.', 'commenter': 'ruanwenjun'}, {'comment': '> Use `IPAddressUtil.isIPv4LiteralAddress` is enough.\r\n\r\nOK. done', 'commenter': 'DarkAssassinator'}]"
11762,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/NetUtils.java,"@@ -32,17 +32,16 @@
 import java.util.List;
 import java.util.Objects;
 import java.util.Optional;
-import java.util.regex.Pattern;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
+import sun.net.util.IPAddressUtil;","[{'comment': ""## Access to unsupported JDK-internal API\n\nAccess to unsupported JDK-internal API 'sun.net.util.IPAddressUtil'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1396)"", 'commenter': 'github-advanced-security[bot]'}]"
11762,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/NetUtils.java,"@@ -183,7 +182,7 @@
         }
         String name = address.getHostAddress();
         return (name != null
-                && IP_PATTERN.matcher(name).matches()
+                && IPAddressUtil.isIPv4LiteralAddress(name)","[{'comment': ""## Access to unsupported JDK-internal API\n\nAccess to unsupported JDK-internal API 'sun.net.util.IPAddressUtil'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1397)"", 'commenter': 'github-advanced-security[bot]'}, {'comment': 'may replace it with `httpclient->org.apache.http.conn.util.InetAddressUtils` to support JDK8+', 'commenter': 'DarkAssassinator'}]"
11765,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/datasource/SpringConnectionFactory.java,"@@ -51,8 +53,10 @@ public class SpringConnectionFactory {
     public DataSourceScriptDatabaseInitializer dataSourceScriptDatabaseInitializer;
 
     @Bean
-    public PaginationInterceptor paginationInterceptor() {
-        return new PaginationInterceptor();
+    public MybatisPlusInterceptor paginationInterceptor() {
+        MybatisPlusInterceptor interceptor = new MybatisPlusInterceptor();
+        interceptor.addInnerInterceptor(new PaginationInnerInterceptor(DbType.MYSQL));","[{'comment': ""Don't other databases need to be handled?"", 'commenter': 'caishunfeng'}, {'comment': ""> Don't other databases need to be handled?\r\n\r\nUh... forgot to pass the db type here, now fixed"", 'commenter': 'kezhenxu94'}]"
11765,docs/docs/zh/faq.md,"@@ -504,33 +527,49 @@ A： 1，用户修改了 api server 配置文件中的![apiServerContextPath](ht
 ---
 
 ## Q：上传比较大的文件卡住
+
 <p align=""center"">
    <img src=""https://user-images.githubusercontent.com/21357069/58231400-805b0e80-7d69-11e9-8107-7f37b06a95df.png"" width=""60%"" />
  </p>
 A：1，编辑 ngnix 配置文件 vi /etc/nginx/nginx.conf，更改上传大小 client_max_body_size 1024m。
 
-   ​	2，更新 google chrome 版本到最新版本。
+<<<<<<< HEAD
+​	2，更新 google chrome 版本到最新版本。
+=============================
+
+​	2，更新 google chrome 版本到最新版本。
+
+>>>>>>> 85200811c (Bump up dependencies to fix cves)","[{'comment': '```suggestion\r\n\u200b\t2，更新 google chrome 版本到最新版本。\r\n```', 'commenter': 'ruanwenjun'}]"
11765,docs/docs/zh/faq.md,"@@ -504,33 +527,49 @@ A： 1，用户修改了 api server 配置文件中的![apiServerContextPath](ht
 ---
 
 ## Q：上传比较大的文件卡住
+
 <p align=""center"">
    <img src=""https://user-images.githubusercontent.com/21357069/58231400-805b0e80-7d69-11e9-8107-7f37b06a95df.png"" width=""60%"" />
  </p>
 A：1，编辑 ngnix 配置文件 vi /etc/nginx/nginx.conf，更改上传大小 client_max_body_size 1024m。
 
-   ​	2，更新 google chrome 版本到最新版本。
+<<<<<<< HEAD
+​	2，更新 google chrome 版本到最新版本。
+=============================
+
+​	2，更新 google chrome 版本到最新版本。
+
+>>>>>>> 85200811c (Bump up dependencies to fix cves)
 
 ---
 
 ## Q：创建 spark 数据源，点击“测试连接”，系统回退回到登入页面
+
 A：1，edit /etc/nginx/conf.d/escheduler.conf
+
 ```
-     proxy_connect_timeout 300s;
-     proxy_read_timeout 300s;
-     proxy_send_timeout 300s;
+proxy_connect_timeout 300s;
+proxy_read_timeout 300s;
+proxy_send_timeout 300s;
 ```
 
 ---
 
 ## Q：工作流依赖
+
 A：1，目前是按照自然天来判断，上月末：判断时间是工作流 A start_time/scheduler_time between '2019-05-31 00:00:00' and '2019-05-31 23:59:59'。上月：是判断上个月从 1 号到月末每天都要有完成的A实例。上周： 上周 7 天都要有完成的 A 实例。前两天： 判断昨天和前天，两天都要有完成的 A 实例。
 
 ---
 
 ## Q：DS 后端接口文档
+
+<<<<<<< HEAD
 A：1，http://106.75.43.194:8888/dolphinscheduler/swagger-ui/index.html?language=zh_CN&lang=zh。
+============================================================================================
 
+>>>>>>> 85200811c (Bump up dependencies to fix cves)
+
+A：1，http://106.75.43.194:8888/dolphinscheduler/doc.html?language=zh_CN&lang=zh。","[{'comment': '```suggestion\r\nA：1，http://106.75.43.194:8888/dolphinscheduler/swagger-ui/index.html?language=zh_CN&lang=zh。\r\n```', 'commenter': 'ruanwenjun'}]"
11765,docs/docs/zh/faq.md,"@@ -582,13 +621,26 @@ sed -i 's/Defaults    requirett/#Defaults    requirett/g' /etc/sudoers
 ---
 
 ## Q：Yarn多集群支持
+
 A：将Worker节点分别部署至多个Yarn集群，步骤如下（例如AWS EMR）：
 
-   1. 将 Worker 节点部署至 EMR 集群的 Master 节点
+<<<<<<< HEAD","[{'comment': 'Please resolve the conflicts.', 'commenter': 'ruanwenjun'}]"
11774,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ExecutorController.java,"@@ -137,7 +137,7 @@ public Result startProcessInstance(@ApiIgnore @RequestAttribute(value = Constant
                                        @RequestParam(value = ""taskDependType"", required = false) TaskDependType taskDependType,
                                        @RequestParam(value = ""execType"", required = false) CommandType execType,
                                        @RequestParam(value = ""warningType"") WarningType warningType,
-                                       @RequestParam(value = ""warningGroupId"", required = false, defaultValue = ""0"") Integer warningGroupId,
+                                       @RequestParam(value = ""warningGroupId"", required = false) Integer warningGroupId,","[{'comment': '`batch-start-process-instance` also need to modify.', 'commenter': 'stalary'}, {'comment': 'i agree with u', 'commenter': 'fuchanghai'}]"
11774,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/alert/ProcessAlertManager.java,"@@ -217,13 +216,7 @@ public void sendAlertWorkerToleranceFault(ProcessInstance processInstance, List<
     public void sendAlertProcessInstance(ProcessInstance processInstance,
                                          List<TaskInstance> taskInstances,
                                          ProjectUser projectUser) {
-
-        if (!isNeedToSendWarning(processInstance)) {","[{'comment': 'Why remove this check?', 'commenter': 'caishunfeng'}, {'comment': 'Because it has been judged before calling the method sendAlertProcessInstance', 'commenter': 'fuchanghai'}, {'comment': ""It's better don't remove this, since this method mighe be execute by another where, you can remove this check in `WorkflowExecuteRunnable`"", 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
11774,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -81,9 +89,15 @@ public class AlertDao {
      * @return add alert result
      */
     public int addAlert(Alert alert) {
+        if (null == alert.getAlertGroupId() || NumberUtils.INTEGER_ZERO.equals(alert.getAlertGroupId())) {
+            return 0;","[{'comment': ""It's better to add warn log"", 'commenter': 'caishunfeng'}, {'comment': 'i agree with u ', 'commenter': 'fuchanghai'}]"
11774,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/AlertDao.java,"@@ -81,9 +89,16 @@ public class AlertDao {
      * @return add alert result
      */
     public int addAlert(Alert alert) {
+        if (null == alert.getAlertGroupId() || NumberUtils.INTEGER_ZERO.equals(alert.getAlertGroupId())) {","[{'comment': 'Why use `NumberUtils.INTEGER_ZERO` rather than `0 ==alert.getAlertGroupId()` here?', 'commenter': 'ruanwenjun'}, {'comment': 'because I want to reduce to use magic value', 'commenter': 'fuchanghai'}]"
11774,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/alert/ProcessAlertManager.java,"@@ -238,7 +231,6 @@ public void sendAlertProcessInstance(ProcessInstance processInstance,
         alert.setAlertType(processInstance.getState().isSuccess() ? AlertType.PROCESS_INSTANCE_SUCCESS
                 : AlertType.PROCESS_INSTANCE_FAILURE);
         alertDao.addAlert(alert);
-        logger.info(""add alert to db , alert: {}"", alert);","[{'comment': ""Please don't remove this kind of log, you can change the log level to debug."", 'commenter': 'ruanwenjun'}, {'comment': 'i remove the log to the method of AlertDao#addAlert', 'commenter': 'fuchanghai'}]"
11780,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/dataAnalysis/CommandStateCountResponse.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.dto.dataAnalysis;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.Project;
+
+import java.util.Map;
+
+import lombok.Data;
+import lombok.NoArgsConstructor;
+
+/**
+ * command state count response
+ */
+@Data
+@NoArgsConstructor
+public class CommandStateCountResponse extends Result {
+
+    private Project data;
+
+
+    public CommandStateCountResponse(Map<String, Object> result) {","[{'comment': 'Please replace `Map` to pojo since this is our expectation of reconstruction.', 'commenter': 'SbloodyS'}, {'comment': 'CommandStateCountResponse(Map<String, Object> result) => CommandStateCountResponse(Result result)\r\nIs that so?', 'commenter': 'Zzih'}, {'comment': 'You can take a look at `org.apache.dolphinscheduler.api.controller.AccessTokenV2Controller#createToken`', 'commenter': 'SbloodyS'}]"
11793,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -1808,7 +1812,8 @@ public void submitStandByTask() throws StateEventHandleException {
                 getPreVarPool(task, preTask);
             }
             DependResult dependResult = getDependResultForTask(task);
-            if (DependResult.SUCCESS == dependResult) {
+            if (DependResult.SUCCESS == dependResult
+                    || processInstance.getFailureStrategy() == FailureStrategy.CONTINUE) {","[{'comment': '```suggestion\r\n            if (DependResult.SUCCESS == dependResult || (DependResult.FAILED == dependResult && processInstance.getFailureStrategy() == FailureStrategy.CONTINUE)) {\r\n```', 'commenter': 'ruanwenjun'}]"
11793,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -1808,7 +1812,8 @@ public void submitStandByTask() throws StateEventHandleException {
                 getPreVarPool(task, preTask);
             }
             DependResult dependResult = getDependResultForTask(task);
-            if (DependResult.SUCCESS == dependResult) {
+            if (DependResult.SUCCESS == dependResult || ((DependResult.WAITING != dependResult)","[{'comment': ""Yes, it's ok."", 'commenter': 'ruanwenjun'}]"
11809,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -856,7 +856,6 @@ public Map<String, Object> deleteProcessDefinitionByCode(User loginUser, long pr
             putMsg(result, Status.USER_NO_OPERATION_PERM);
             return result;
         }
-
         processDefinitionUsedInOtherTaskValid(processDefinition);","[{'comment': 'It has already check the online state here.', 'commenter': 'caishunfeng'}]"
11858,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java,"@@ -27,8 +28,8 @@
 import java.util.stream.Collectors;
 
 @Data","[{'comment': 'Can you add the @AllArgsConstructor annotation by the way? ', 'commenter': 'fuchanghai'}]"
11858,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/TaskCountDto.java,"@@ -27,8 +28,8 @@
 import java.util.stream.Collectors;
 
 @Data
+@NoArgsConstructor
 public class TaskCountDto {","[{'comment': 'i thind ```Dto``` need be changed to ```DTO``` WDYT', 'commenter': 'fuchanghai'}]"
11859,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/src/main/java/org/apache/dolphinscheduler/plugin/task/datasync/DatasyncHook.java,"@@ -0,0 +1,217 @@
+package org.apache.dolphinscheduler.plugin.task.datasync;
+
+import lombok.Data;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
+import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider;
+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
+import software.amazon.awssdk.regions.Region;
+import software.amazon.awssdk.services.datasync.DataSyncClient;
+import software.amazon.awssdk.services.datasync.model.CancelTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.CancelTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.CreateTaskRequest;
+import software.amazon.awssdk.services.datasync.model.CreateTaskResponse;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskRequest;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskResponse;
+import software.amazon.awssdk.services.datasync.model.FilterRule;
+import software.amazon.awssdk.services.datasync.model.StartTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.StartTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.TagListEntry;
+import software.amazon.awssdk.services.datasync.model.TaskExecutionStatus;
+import software.amazon.awssdk.services.datasync.model.TaskStatus;
+
+import java.util.Arrays;
+import java.util.List;
+
+@Data
+public class DatasyncHook {
+    protected final Logger logger = LoggerFactory.getLogger(String.format(TaskConstants.TASK_LOG_LOGGER_NAME_FORMAT, getClass()));
+    private DataSyncClient client;
+    private String taskArn;
+    private String taskExecArn;
+
+    public static TaskExecutionStatus[] doneStatus = {TaskExecutionStatus.ERROR,TaskExecutionStatus.SUCCESS,TaskExecutionStatus.UNKNOWN_TO_SDK_VERSION};
+    public static TaskStatus[] taskFinishFlags = {TaskStatus.UNAVAILABLE,TaskStatus.UNKNOWN_TO_SDK_VERSION};
+    public DatasyncHook() {
+        client = createClient();
+    }
+
+    protected DataSyncClient createClient() {
+        //final String awsAccessKeyId = PropertyUtils.getString(TaskConstants.AWS_ACCESS_KEY_ID);
+        //final String awsSecretAccessKey = PropertyUtils.getString(TaskConstants.AWS_SECRET_ACCESS_KEY);
+        final String awsAccessKeyId = ""AKIAXTUKRINYVGPCDOBV"";
+        final String awsSecretAccessKey = ""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"";","[{'comment': 'Please avoid doing that. This is a serious safety accident...', 'commenter': 'SbloodyS'}, {'comment': 'sure, done', 'commenter': 'Tianqi-Dotes'}]"
11864,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -101,7 +101,8 @@ public void submitStateEvent(StateEvent stateEvent) {
      * Handle the events belong to the given workflow.
      */
     public void executeEvent(final WorkflowExecuteRunnable workflowExecuteThread) {
-        if (!workflowExecuteThread.isStart() || workflowExecuteThread.eventSize() == 0) {
+        if (!workflowExecuteThread.isStart() || workflowExecuteThread.isHandingEvent()","[{'comment': 'Why we need to do this change, if the `workflowExecuteThread` is handing event, it should be filter by `if (multiThreadFilterMap.containsKey(workflowExecuteThread.getKey()))`', 'commenter': 'ruanwenjun'}, {'comment': '> Why we need to do this change, if the `workflowExecuteThread` is handing event, it should be filter by `if (multiThreadFilterMap.containsKey(workflowExecuteThread.getKey()))`\r\n\r\nbecause `workflowExecuteThread ` will not remove the event if occured any exception, and the `WorkflowExecuteThreadPool` will keep print log each 100ms', 'commenter': 'DarkAssassinator'}, {'comment': 'When this case occur, means the system may exist bug or meet some error, like database crash.', 'commenter': 'ruanwenjun'}, {'comment': '> When this case occur, means the system may exist bug or meet some error, like database crash.\r\n\r\nemm. u are correct, i has avoid this change.', 'commenter': 'DarkAssassinator'}]"
11864,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/event/TaskTimeoutStateEventHandler.java,"@@ -34,29 +34,34 @@ public class TaskTimeoutStateEventHandler implements StateEventHandler {
 
     @Override
     public boolean handleStateEvent(WorkflowExecuteRunnable workflowExecuteRunnable,
-                                    StateEvent stateEvent) throws StateEventHandleError {
+        StateEvent stateEvent) throws StateEventHandleError {
         TaskStateEvent taskStateEvent = (TaskStateEvent) stateEvent;
 
         TaskMetrics.incTaskInstanceByState(""timeout"");
         workflowExecuteRunnable.checkTaskInstanceByStateEvent(taskStateEvent);
 
         TaskInstance taskInstance =
-                workflowExecuteRunnable.getTaskInstance(taskStateEvent.getTaskInstanceId()).orElseThrow(
-                        () -> new StateEventHandleError(String.format(
-                                ""Cannot find the task instance from workflow execute runnable, taskInstanceId: %s"",
-                                taskStateEvent.getTaskInstanceId())));
+            workflowExecuteRunnable.getTaskInstance(taskStateEvent.getTaskInstanceId()).orElseThrow(
+                () -> new StateEventHandleError(String.format(
+                    ""Cannot find the task instance from workflow execute runnable, taskInstanceId: %s"",
+                    taskStateEvent.getTaskInstanceId())));
 
         if (TimeoutFlag.CLOSE == taskInstance.getTaskDefine().getTimeoutFlag()) {
             return true;
         }
-        TaskTimeoutStrategy taskTimeoutStrategy = taskInstance.getTaskDefine().getTimeoutNotifyStrategy();
-        Map<Long, ITaskProcessor> activeTaskProcessMap = workflowExecuteRunnable.getActiveTaskProcessMap();
-        if (TaskTimeoutStrategy.FAILED == taskTimeoutStrategy
-                || TaskTimeoutStrategy.WARNFAILED == taskTimeoutStrategy) {
-            ITaskProcessor taskProcessor = activeTaskProcessMap.get(taskInstance.getTaskCode());
-            taskProcessor.action(TaskAction.TIMEOUT);
+        TaskTimeoutStrategy taskTimeoutStrategy = taskInstance.getTaskDefine()
+            .getTimeoutNotifyStrategy();
+        Map<Long, ITaskProcessor> activeTaskProcessMap = workflowExecuteRunnable
+            .getActiveTaskProcessMap();
+        if ((TaskTimeoutStrategy.FAILED == taskTimeoutStrategy
+            || TaskTimeoutStrategy.WARNFAILED == taskTimeoutStrategy)) {
+            if (activeTaskProcessMap.containsKey(taskInstance.getTaskCode())) {","[{'comment': ""In which case the `taskProcessor` will be null? if it's null we need to throw error?"", 'commenter': 'ruanwenjun'}, {'comment': 'if task instance failure, it will submit a `StateEventType.TASK_STATE_CHANGE`, `TaskStateEventHandler` will call `workflowExecuteRunnable.taskFinished(task)` and remove this `taskProcessor`', 'commenter': 'DarkAssassinator'}, {'comment': ""Ok, it's better to print a warn log if we cannot find the processor here."", 'commenter': 'ruanwenjun'}, {'comment': ""> Ok, it's better to print a warn log if we cannot find the processor here.\r\n\r\nyes, and i add a warn log print."", 'commenter': 'DarkAssassinator'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/src/main/java/org/apache/dolphinscheduler/plugin/task/datasync/DatasyncTask.java,"@@ -0,0 +1,151 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datasync;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import software.amazon.awssdk.services.datasync.model.TaskExecutionStatus;
+
+import java.util.Collections;
+import java.util.Set;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+public class DatasyncTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+            new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+                    .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+                    .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+                    .configure(REQUIRE_SETTERS_FOR_GETTERS, true)","[{'comment': '## Deprecated method or constructor invocation\n\nInvoking [ObjectMapper.configure](1) should be avoided because it has been deprecated.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1234)', 'commenter': 'github-advanced-security[bot]'}]"
11865,docs/docs/en/guide/task/datasync.md,"@@ -0,0 +1,78 @@
+# DataSync Node
+
+## Overview
+
+[AWS DataSync](https://console.aws.amazon.com/datasync/) is an online data transfer service that simplifies, automates, and accelerates moving data between on-premises storage systems and AWS Storage services, as well as between AWS Storage services.
+
+DataSync can copy data to and from:
+
+- Network File System (NFS) file servers
+- Server Message Block (SMB) file servers
+- Hadoop Distributed File System (HDFS)
+- Object storage systems
+- Amazon Simple Storage Service (Amazon S3) buckets
+- Amazon EFS file systems
+- Amazon FSx for Windows File Server file systems
+- Amazon FSx for Lustre file systems
+- Amazon FSx for OpenZFS file systems
+- Amazon FSx for NetApp ONTAP file systems
+- AWS Snowcone devices
+
+The follow shows the DolphinScheduler DataSync task plugin features:
+
+- Create an AWS DataSync task and execute, continuously get the execution status until the task completes.
+
+## Create Task
+
+- Click `Project -> Management-Project -> Name-Workflow Definition`, and click the ""Create Workflow"" button to enter the
+  DAG editing page.
+- Drag from the toolbar <img src=""../../../../img/tasks/icons/datasync.png"" width=""15""/> task node to canvas.
+
+## Task Example
+
+First, introduce some general parameters of DolphinScheduler:
+
+- **Node name**: The node name in a workflow definition is unique.","[{'comment': 'use base doc, see https://dolphinscheduler.apache.org/en-us/docs/dev/user_doc/guide/task/appendix.html', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/pom.xml,"@@ -0,0 +1,70 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-task-plugin</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-task-datasync</artifactId>
+    <packaging>jar</packaging>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-spi</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-task-api</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <!-- https://mvnrepository.com/artifact/software.amazon.awssdk/datasync -->
+        <dependency>
+            <groupId>software.amazon.awssdk</groupId>
+            <artifactId>datasync</artifactId>
+            <version>2.17.260</version>
+        </dependency>
+        <!-- https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-datasync -->
+        <dependency>
+            <groupId>com.amazonaws</groupId>
+            <artifactId>aws-java-sdk-datasync</artifactId>
+            <version>1.12.289</version>
+        </dependency>
+        <dependency>
+            <groupId>com.amazonaws</groupId>
+            <artifactId>aws-java-sdk-dms</artifactId>
+            <version>1.12.297</version>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-common</artifactId>
+            <scope>provided</scope>","[{'comment': 'Why import the ds common module?', 'commenter': 'caishunfeng'}, {'comment': 'use this method: BeanUtils.copyProperties', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/src/main/java/org/apache/dolphinscheduler/plugin/task/datasync/DatasyncHook.java,"@@ -0,0 +1,256 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datasync;
+
+import lombok.Data;
+import org.apache.commons.beanutils.BeanUtils;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.utils.PropertyUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import software.amazon.awssdk.auth.credentials.AwsBasicCredentials;
+import software.amazon.awssdk.auth.credentials.AwsCredentialsProvider;
+import software.amazon.awssdk.auth.credentials.StaticCredentialsProvider;
+import software.amazon.awssdk.regions.Region;
+import software.amazon.awssdk.services.datasync.DataSyncClient;
+import software.amazon.awssdk.services.datasync.model.CancelTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.CancelTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.CreateTaskRequest;
+import software.amazon.awssdk.services.datasync.model.CreateTaskResponse;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskRequest;
+import software.amazon.awssdk.services.datasync.model.DescribeTaskResponse;
+import software.amazon.awssdk.services.datasync.model.FilterRule;
+import software.amazon.awssdk.services.datasync.model.Options;
+import software.amazon.awssdk.services.datasync.model.StartTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.StartTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.TagListEntry;
+import software.amazon.awssdk.services.datasync.model.TaskExecutionStatus;
+import software.amazon.awssdk.services.datasync.model.TaskSchedule;
+import software.amazon.awssdk.services.datasync.model.TaskStatus;
+
+import java.lang.reflect.InvocationTargetException;
+import java.util.Arrays;
+import java.util.List;
+import java.util.stream.Collectors;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+@Data
+public class DatasyncHook {
+
+    public static TaskExecutionStatus[] doneStatus = {TaskExecutionStatus.ERROR, TaskExecutionStatus.SUCCESS, TaskExecutionStatus.UNKNOWN_TO_SDK_VERSION};
+    public static TaskStatus[] taskFinishFlags = {TaskStatus.UNAVAILABLE, TaskStatus.UNKNOWN_TO_SDK_VERSION};
+    protected final Logger logger = LoggerFactory.getLogger(String.format(TaskConstants.TASK_LOG_LOGGER_NAME_FORMAT, getClass()));
+    private DataSyncClient client;
+    private String taskArn;
+    private String taskExecArn;
+
+    public DatasyncHook() {
+        client = createClient();
+    }
+
+    protected static DataSyncClient createClient() {
+        final String awsAccessKeyId = PropertyUtils.getString(TaskConstants.AWS_ACCESS_KEY_ID);
+        final String awsSecretAccessKey = PropertyUtils.getString(TaskConstants.AWS_SECRET_ACCESS_KEY);
+        final String awsRegion = PropertyUtils.getString(TaskConstants.AWS_REGION);
+
+        final AwsBasicCredentials basicAWSCredentials = AwsBasicCredentials.create(awsAccessKeyId, awsSecretAccessKey);
+        final AwsCredentialsProvider awsCredentialsProvider = StaticCredentialsProvider.create(basicAWSCredentials);
+
+        // create a datasync client
+        return DataSyncClient.builder().region(Region.of(awsRegion)).credentialsProvider(awsCredentialsProvider).build();
+    }
+
+    public Boolean createDatasyncTask(DatasyncParameters parameters) {
+        logger.info(""createDatasyncTask ......"");
+        CreateTaskRequest.Builder builder = CreateTaskRequest.builder()
+                .name(parameters.getName())
+                .sourceLocationArn(parameters.getSourceLocationArn())
+                .destinationLocationArn(parameters.getDestinationLocationArn());
+
+        String cloudWatchLogGroupArn = parameters.getCloudWatchLogGroupArn();
+        if (StringUtils.isNotEmpty(cloudWatchLogGroupArn)) {
+            builder.cloudWatchLogGroupArn(cloudWatchLogGroupArn);
+        }
+        castParamPropertyPackage(parameters, builder);
+
+        CreateTaskResponse task = client.createTask(builder.build());
+        if (task.sdkHttpResponse().isSuccessful()) {
+            taskArn = task.taskArn();
+        }
+        logger.info(""finished createDatasyncTask ......"");
+        return doubleCheckTaskStatus(TaskStatus.AVAILABLE, taskFinishFlags);
+    }
+
+    public Boolean startDatasyncTask() {
+        logger.info(""startDatasyncTask ......"");
+        StartTaskExecutionRequest start = StartTaskExecutionRequest.builder().taskArn(taskArn).build();
+        StartTaskExecutionResponse response = client.startTaskExecution(start);
+        if (response.sdkHttpResponse().isSuccessful()) {
+            taskExecArn = response.taskExecutionArn();
+        }
+        return doubleCheckExecStatus(TaskExecutionStatus.LAUNCHING, doneStatus);
+    }
+
+
+    public Boolean cancelDatasyncTask() {
+        logger.info(""cancelTask ......"");
+        CancelTaskExecutionRequest cancel = CancelTaskExecutionRequest.builder().taskExecutionArn(taskExecArn).build();
+        CancelTaskExecutionResponse response = client.cancelTaskExecution(cancel);
+        if (response.sdkHttpResponse().isSuccessful()) {
+            return true;
+        }
+        return false;
+    }
+
+    public TaskStatus queryDatasyncTaskStatus() {
+        logger.info(""queryDatasyncTaskStatus ......"");
+
+        DescribeTaskRequest request = DescribeTaskRequest.builder().taskArn(taskArn).build();
+        DescribeTaskResponse describe = client.describeTask(request);
+
+        if (describe.sdkHttpResponse().isSuccessful()) {
+            logger.info(""queryDatasyncTaskStatus ......{}"", describe.statusAsString());
+            return describe.status();
+        }
+        return null;
+    }
+
+    public TaskExecutionStatus queryDatasyncTaskExecStatus() {
+        logger.info(""queryDatasyncTaskExecStatus ......"");
+        DescribeTaskExecutionRequest request = DescribeTaskExecutionRequest.builder().taskExecutionArn(taskExecArn).build();
+        DescribeTaskExecutionResponse describe = client.describeTaskExecution(request);
+
+        if (describe.sdkHttpResponse().isSuccessful()) {
+            logger.info(""queryDatasyncTaskExecStatus ......{}"", describe.statusAsString());
+            return describe.status();
+        }
+        return null;
+    }
+
+    public Boolean doubleCheckTaskStatus(TaskStatus exceptStatus, TaskStatus[] stopStatus) {
+
+        List<TaskStatus> stopStatusSet = Arrays.asList(stopStatus);
+        int maxRetry = 5;
+        while (maxRetry > 0) {
+            TaskStatus status = queryDatasyncTaskStatus();
+
+            if (status == null) {
+                maxRetry--;
+                continue;
+            }
+
+            if (exceptStatus.equals(status)) {
+                logger.info(""double check success"");
+                return true;
+            } else if (stopStatusSet.contains(status)) {
+                break;
+            }
+        }
+        logger.warn(""double check error"");
+        return false;
+    }
+
+    public Boolean doubleCheckExecStatus(TaskExecutionStatus exceptStatus, TaskExecutionStatus[] stopStatus) {","[{'comment': ""What's the meaning of `double check`?"", 'commenter': 'caishunfeng'}, {'comment': 'this method double check the object status by calling query status API.\r\neg: when you call createTask method, you expect an `AVAILABLE` status, so you call this method to get the task status and compare the expectation', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/src/main/java/org/apache/dolphinscheduler/plugin/task/datasync/DatasyncTask.java,"@@ -0,0 +1,151 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datasync;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import software.amazon.awssdk.services.datasync.model.TaskExecutionStatus;
+
+import java.util.Collections;
+import java.util.List;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+public class DatasyncTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+            new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+                    .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+                    .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+                    .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+                    .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+
+    private final TaskExecutionContext taskExecutionContext;
+    private DatasyncParameters parameters;
+    private DatasyncHook hook;
+
+    public DatasyncTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void init() {
+        logger.info(""Datasync task params {}"", taskExecutionContext.getTaskParams());
+
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DatasyncParameters.class);
+        initParams();
+
+        hook = new DatasyncHook();
+    }
+
+    /**
+     * init datasync hook
+     */
+    public void initParams() throws TaskException {
+        if (parameters.isJsonFormat() && StringUtils.isNotEmpty(parameters.getJson())) {
+            try {
+                parameters = objectMapper.readValue(parameters.getJson(), DatasyncParameters.class);
+                logger.info(""Datasync convert task params {}"", parameters);
+            } catch (JsonProcessingException e) {
+                throw new RuntimeException(e);
+            }
+        }
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        try {
+            int exitStatusCode = runDatasyncTask();
+            setExitStatusCode(exitStatusCode);
+        } catch (Exception e) {
+            setExitStatusCode(TaskConstants.EXIT_CODE_FAILURE);
+            throw new TaskException(""datasync task error"", e);
+        }
+    }
+
+    @Override
+    public void cancelApplication() throws TaskException {
+        hook.cancelDatasyncTask();
+    }
+
+
+    @Override
+    public void trackApplicationStatus() throws TaskException {
+        Boolean isFinishedSuccessfully = hook.doubleCheckFinishStatus(TaskExecutionStatus.SUCCESS, DatasyncHook.doneStatus);","[{'comment': 'Should check applicationId before check status.', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/src/main/java/org/apache/dolphinscheduler/plugin/task/datasync/DatasyncTask.java,"@@ -0,0 +1,151 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datasync;
+
+import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+import software.amazon.awssdk.services.datasync.model.TaskExecutionStatus;
+
+import java.util.Collections;
+import java.util.List;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+public class DatasyncTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+            new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+                    .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+                    .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+                    .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+                    .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+
+    private final TaskExecutionContext taskExecutionContext;
+    private DatasyncParameters parameters;
+    private DatasyncHook hook;
+
+    public DatasyncTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void init() {
+        logger.info(""Datasync task params {}"", taskExecutionContext.getTaskParams());
+
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DatasyncParameters.class);
+        initParams();
+
+        hook = new DatasyncHook();
+    }
+
+    /**
+     * init datasync hook
+     */
+    public void initParams() throws TaskException {
+        if (parameters.isJsonFormat() && StringUtils.isNotEmpty(parameters.getJson())) {
+            try {
+                parameters = objectMapper.readValue(parameters.getJson(), DatasyncParameters.class);
+                logger.info(""Datasync convert task params {}"", parameters);
+            } catch (JsonProcessingException e) {
+                throw new RuntimeException(e);
+            }
+        }
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        try {
+            int exitStatusCode = runDatasyncTask();
+            setExitStatusCode(exitStatusCode);
+        } catch (Exception e) {
+            setExitStatusCode(TaskConstants.EXIT_CODE_FAILURE);
+            throw new TaskException(""datasync task error"", e);
+        }
+    }
+
+    @Override
+    public void cancelApplication() throws TaskException {
+        hook.cancelDatasyncTask();","[{'comment': 'Should check applicationId before.', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}, {'comment': 'It should try to get application id from taskContext if applicationId is null.', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/src/test/java/org/apache/dolphinscheduler/plugin/task/datasync/DatasyncTaskTest.java,"@@ -0,0 +1,234 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datasync;
+
+import static org.mockito.Mockito.mockStatic;
+import static org.powermock.api.mockito.PowerMockito.doReturn;
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.spy;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.PropertyUtils;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.mockito.MockedStatic;
+import org.mockito.Mockito;
+
+import static org.mockito.Mockito.any;
+
+import org.powermock.api.support.membermodification.MemberModifier;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import software.amazon.awssdk.http.SdkHttpResponse;
+import software.amazon.awssdk.services.datasync.DataSyncClient;
+import software.amazon.awssdk.services.datasync.model.CancelTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.CancelTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.CreateTaskRequest;
+import software.amazon.awssdk.services.datasync.model.CreateTaskResponse;
+import software.amazon.awssdk.services.datasync.model.StartTaskExecutionRequest;
+import software.amazon.awssdk.services.datasync.model.StartTaskExecutionResponse;
+import software.amazon.awssdk.services.datasync.model.TaskExecutionStatus;
+import software.amazon.awssdk.services.datasync.model.TaskStatus;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+        JSONUtils.class,
+        PropertyUtils.class,
+        DatasyncHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DatasyncTaskTest {
+
+    private static final String mockExeArn = ""arn:aws:datasync:ap-northeast-3:523202806641:task/task-017642db08fdf6a55/execution/exec-0ac3607778dfc31f5"";
+
+    private static final String mockTaskArn = ""arn:aws:datasync:ap-northeast-3:523202806641:task/task-071ca64ff4c2f0d4a"";
+
+    DatasyncHook datasyncHook;
+
+    DatasyncTask datasyncTask;
+
+    @Mock
+    DataSyncClient client;
+    MockedStatic<DatasyncHook> datasyncHookMockedStatic;
+    @Before
+    public void before() throws IllegalAccessException {
+        client = mock(DataSyncClient.class);
+        datasyncHookMockedStatic = mockStatic(DatasyncHook.class);
+        when(DatasyncHook.createClient()).thenReturn(client);
+
+        DatasyncParameters DatasyncParameters = new DatasyncParameters();
+        datasyncTask = initTask(DatasyncParameters);
+        MemberModifier.field(DatasyncTask.class, ""hook"").set(datasyncTask, datasyncHook);
+    }
+
+    @Test
+    public void testCreateTaskJson() {","[{'comment': 'What is the purpose of this test case?  If just test the value from json, it seems meanless.', 'commenter': 'caishunfeng'}, {'comment': 'the purpose is to confirm the transformation of  `using JSON data to construct data sync task`, and validate the way to convert JSON data to an entity.', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-task-plugin/dolphinscheduler-task-datasync/pom.xml,"@@ -0,0 +1,70 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0""
+         xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-task-plugin</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-task-datasync</artifactId>
+    <packaging>jar</packaging>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-spi</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-task-api</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <!-- https://mvnrepository.com/artifact/software.amazon.awssdk/datasync -->
+        <dependency>
+            <groupId>software.amazon.awssdk</groupId>
+            <artifactId>datasync</artifactId>
+            <version>2.17.260</version>
+        </dependency>
+        <!-- https://mvnrepository.com/artifact/com.amazonaws/aws-java-sdk-datasync -->
+        <dependency>
+            <groupId>com.amazonaws</groupId>
+            <artifactId>aws-java-sdk-datasync</artifactId>
+            <version>1.12.289</version>
+        </dependency>
+        <dependency>
+            <groupId>com.amazonaws</groupId>
+            <artifactId>aws-java-sdk-dms</artifactId>
+            <version>1.12.297</version>","[{'comment': ""Don't manage the versions here, move them to the bom"", 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
11865,dolphinscheduler-bom/pom.xml,"@@ -748,6 +749,102 @@
                 <artifactId>snakeyaml</artifactId>
                 <version>${snakeyaml.version}</version>
             </dependency>
+            <!-- https://mvnrepository.com/artifact/software.amazon.awssdk/datasync -->
+            <dependency>
+                <groupId>software.amazon.awssdk</groupId>
+                <artifactId>datasync</artifactId>
+                <version>${datasync.version}</version>
+               <!-- <exclusions>","[{'comment': 'remove if no need.', 'commenter': 'caishunfeng'}, {'comment': 'This comment is not addressed', 'commenter': 'kezhenxu94'}, {'comment': 'sorry, the page not refreshed and the comment not show when i merge this. have fixed this in this pr.\r\nhttps://github.com/apache/dolphinscheduler/pull/12273', 'commenter': 'Tianqi-Dotes'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHookTest.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.mockStatic;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+    JSONUtils.class,
+    DmsHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DmsHookTest {
+
+    AWSDatabaseMigrationService client;
+
+    @Before
+    public void before() {
+        mockStatic(DmsHook.class);
+        client = mock(AWSDatabaseMigrationService.class);
+        when(DmsHook.createClient()).thenReturn(client);
+    }
+
+    @Test(timeout = 60000)
+    public void testCreateReplicationTask() throws Exception {
+
+        DmsHook dmsHook = spy(new DmsHook());
+        CreateReplicationTaskResult createReplicationTaskResult = mock(CreateReplicationTaskResult.class);
+        when(client.createReplicationTask(any())).thenReturn(createReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.READY);
+        when(createReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.createReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+        Assert.assertEquals(""task"", dmsHook.getReplicationTaskIdentifier());
+    }
+
+    @Test(timeout = 60000)
+    public void testStartReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+        StartReplicationTaskResult startReplicationTaskResult = mock(StartReplicationTaskResult.class);
+        when(client.startReplicationTask(any())).thenReturn(startReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.RUNNING);
+        when(startReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.startReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+    }
+
+    @Test(timeout = 60000)
+    public void testCheckFinishedReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.STOPPED);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        when(replicationTask.getStopReason()).thenReturn(""*_FINISHED"");
+        Assert.assertTrue(dmsHook.checkFinishedReplicationTask());
+
+        when(replicationTask.getStopReason()).thenReturn(""*_ERROR"");
+        Assert.assertFalse(dmsHook.checkFinishedReplicationTask());
+    }
+
+    @Test(timeout = 60000)
+    public void testDeleteReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.DELETE);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.deleteReplicationTask());
+
+    }
+
+    @Test
+    public void testTestConnectionEndpoint() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        String replicationInstanceArn = ""replicationInstanceArn"";
+        String trueSourceEndpointArn = ""trueSourceEndpointArn"";
+        String trueTargetEndpointArn = ""trueTargetEndpointArn"";
+        String falseSourceEndpointArn = ""falseSourceEndpointArn"";
+        String falseTargetEndpointArn = ""falseTargetEndpointArn"";
+
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueSourceEndpointArn);
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueTargetEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseSourceEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseTargetEndpointArn);
+
+
+        dmsHook.setReplicationInstanceArn(replicationInstanceArn);
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertTrue(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+    }
+
+
+    @Test
+    public void testDescribeReplicationTasks() {
+
+        DmsHook dmsHook = new DmsHook();
+        dmsHook.setReplicationInstanceArn(""arn:aws:dms:ap-southeast-1:123456789012:task:task_exist"");
+
+        DescribeReplicationTasksResult describeReplicationTasksResult = mock(DescribeReplicationTasksResult.class);
+        when(client.describeReplicationTasks(any())).thenReturn(describeReplicationTasksResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getSourceEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"");
+        when(replicationTask.getTargetEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"");
+
+        when(describeReplicationTasksResult.getReplicationTasks()).thenReturn(Arrays.asList(replicationTask));
+
+        ReplicationTask replicationTaskOut = dmsHook.describeReplicationTasks();
+        Assert.assertNotEquals(dmsHook.getReplicationInstanceArn(), replicationTaskOut.getReplicationTaskArn());
+        Assert.assertEquals(""task"", replicationTaskOut.getReplicationTaskIdentifier());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"", replicationTaskOut.getSourceEndpointArn());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"", replicationTaskOut.getTargetEndpointArn());
+
+    }
+
+
+    @Test(timeout = 60000)
+    public void testAwaitReplicationTaskStatus() {
+
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        ReplicationTaskStats taskStats = mock(ReplicationTaskStats.class);
+        when(replicationTask.getReplicationTaskStats()).thenReturn(taskStats);
+        when(taskStats.getFullLoadProgressPercent()).thenReturn(100);
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertFalse(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED, DmsHook.STATUS.RUNNING));
+    }
+
+    @Test
+    public void testReplaceFileParameters() throws IOException {
+        String path = this.getClass().getResource(""table_mapping.json"").getPath();","[{'comment': '## Unsafe use of getResource\n\nThe idiom getClass().getResource() is unsafe for classes that may be extended.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1223)', 'commenter': 'github-advanced-security[bot]'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHookTest.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.mockStatic;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+    JSONUtils.class,
+    DmsHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DmsHookTest {
+
+    AWSDatabaseMigrationService client;
+
+    @Before
+    public void before() {
+        mockStatic(DmsHook.class);
+        client = mock(AWSDatabaseMigrationService.class);
+        when(DmsHook.createClient()).thenReturn(client);
+    }
+
+    @Test(timeout = 60000)
+    public void testCreateReplicationTask() throws Exception {
+
+        DmsHook dmsHook = spy(new DmsHook());
+        CreateReplicationTaskResult createReplicationTaskResult = mock(CreateReplicationTaskResult.class);
+        when(client.createReplicationTask(any())).thenReturn(createReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.READY);
+        when(createReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.createReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+        Assert.assertEquals(""task"", dmsHook.getReplicationTaskIdentifier());
+    }
+
+    @Test(timeout = 60000)
+    public void testStartReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+        StartReplicationTaskResult startReplicationTaskResult = mock(StartReplicationTaskResult.class);
+        when(client.startReplicationTask(any())).thenReturn(startReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.RUNNING);
+        when(startReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.startReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+    }
+
+    @Test(timeout = 60000)
+    public void testCheckFinishedReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.STOPPED);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        when(replicationTask.getStopReason()).thenReturn(""*_FINISHED"");
+        Assert.assertTrue(dmsHook.checkFinishedReplicationTask());
+
+        when(replicationTask.getStopReason()).thenReturn(""*_ERROR"");
+        Assert.assertFalse(dmsHook.checkFinishedReplicationTask());
+    }
+
+    @Test(timeout = 60000)
+    public void testDeleteReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.DELETE);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.deleteReplicationTask());
+
+    }
+
+    @Test
+    public void testTestConnectionEndpoint() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        String replicationInstanceArn = ""replicationInstanceArn"";
+        String trueSourceEndpointArn = ""trueSourceEndpointArn"";
+        String trueTargetEndpointArn = ""trueTargetEndpointArn"";
+        String falseSourceEndpointArn = ""falseSourceEndpointArn"";
+        String falseTargetEndpointArn = ""falseTargetEndpointArn"";
+
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueSourceEndpointArn);
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueTargetEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseSourceEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseTargetEndpointArn);
+
+
+        dmsHook.setReplicationInstanceArn(replicationInstanceArn);
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertTrue(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+    }
+
+
+    @Test
+    public void testDescribeReplicationTasks() {
+
+        DmsHook dmsHook = new DmsHook();
+        dmsHook.setReplicationInstanceArn(""arn:aws:dms:ap-southeast-1:123456789012:task:task_exist"");
+
+        DescribeReplicationTasksResult describeReplicationTasksResult = mock(DescribeReplicationTasksResult.class);
+        when(client.describeReplicationTasks(any())).thenReturn(describeReplicationTasksResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getSourceEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"");
+        when(replicationTask.getTargetEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"");
+
+        when(describeReplicationTasksResult.getReplicationTasks()).thenReturn(Arrays.asList(replicationTask));
+
+        ReplicationTask replicationTaskOut = dmsHook.describeReplicationTasks();
+        Assert.assertNotEquals(dmsHook.getReplicationInstanceArn(), replicationTaskOut.getReplicationTaskArn());
+        Assert.assertEquals(""task"", replicationTaskOut.getReplicationTaskIdentifier());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"", replicationTaskOut.getSourceEndpointArn());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"", replicationTaskOut.getTargetEndpointArn());
+
+    }
+
+
+    @Test(timeout = 60000)
+    public void testAwaitReplicationTaskStatus() {
+
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        ReplicationTaskStats taskStats = mock(ReplicationTaskStats.class);
+        when(replicationTask.getReplicationTaskStats()).thenReturn(taskStats);
+        when(taskStats.getFullLoadProgressPercent()).thenReturn(100);
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertFalse(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED, DmsHook.STATUS.RUNNING));
+    }
+
+    @Test
+    public void testReplaceFileParameters() throws IOException {
+        String path = this.getClass().getResource(""table_mapping.json"").getPath();
+
+        String jsonData = loadJson(""table_mapping.json"");
+
+        DmsHook dmsHook = new DmsHook();
+
+        String pathParameter = ""file://"" + path;
+        Assert.assertEquals(jsonData, dmsHook.replaceFileParameters(pathParameter));
+
+//        String pathParameter2 = ""file://"" + ""not_exist.json"";
+//
+//        try {
+//            Assert.assertEquals(pathParameter2, dmsHook.replaceFileParameters(pathParameter2));
+//        }catch (Exception e) {
+//            Assert.assertTrue(e instanceof IOException);
+//        }
+
+        String pathParameter3 = ""{}"";
+        Assert.assertEquals(pathParameter3, dmsHook.replaceFileParameters(pathParameter3));
+
+    }
+
+//    this.getClass().getResourceAsStream(""SagemakerRequestJson.json""))
+
+    private String loadJson(String fileName) {
+        String jsonData;
+        try (InputStream i = this.getClass().getResourceAsStream(fileName)) {","[{'comment': '## Unsafe use of getResource\n\nThe idiom getClass().getResource() is unsafe for classes that may be extended.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1224)', 'commenter': 'github-advanced-security[bot]'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,239 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.Set;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)","[{'comment': '## Deprecated method or constructor invocation\n\nInvoking [ObjectMapper.configure](1) should be avoided because it has been deprecated.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1222)', 'commenter': 'github-advanced-security[bot]'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/pom.xml,"@@ -0,0 +1,54 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xmlns=""http://maven.apache.org/POM/4.0.0""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <parent>
+        <artifactId>dolphinscheduler-task-plugin</artifactId>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <modelVersion>4.0.0</modelVersion>
+
+    <artifactId>dolphinscheduler-task-dms</artifactId>
+    <packaging>jar</packaging>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-spi</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-task-api</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-common</artifactId>
+            <scope>provided</scope>
+        </dependency>
+        <dependency>
+            <groupId>com.amazonaws</groupId>
+            <artifactId>aws-java-sdk-dms</artifactId>
+            <version>1.12.297</version>
+        </dependency>","[{'comment': 'Move the version to bom.', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHook.java,"@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.utils.PropertyUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+import java.util.Date;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.amazonaws.auth.AWSCredentialsProvider;
+import com.amazonaws.auth.AWSStaticCredentialsProvider;
+import com.amazonaws.auth.BasicAWSCredentials;
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationServiceClientBuilder;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DeleteReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.DescribeConnectionsRequest;
+import com.amazonaws.services.databasemigrationservice.model.DescribeConnectionsResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksRequest;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.Filter;
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.ResourceNotFoundException;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.StopReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.Tag;
+import com.amazonaws.services.databasemigrationservice.model.TestConnectionRequest;
+
+import lombok.AllArgsConstructor;
+import lombok.Data;
+import lombok.NoArgsConstructor;
+
+@Data
+public class DmsHook {
+    protected final Logger logger = LoggerFactory.getLogger(String.format(TaskConstants.TASK_LOG_LOGGER_NAME_FORMAT, getClass()));
+    private AWSDatabaseMigrationService client;
+    private String replicationTaskIdentifier;
+    private String sourceEndpointArn;
+    private String targetEndpointArn;
+    private String replicationInstanceArn;
+    private String migrationType;
+    private String tableMappings;
+    private String replicationTaskSettings;
+    private Date cdcStartTime;
+    private String cdcStartPosition;
+    private String cdcStopPosition;
+    private List<Tag> tags;
+    private String taskData;
+    private String resourceIdentifier;
+    private String replicationTaskArn;
+    private String startReplicationTaskType;
+
+    public DmsHook() {
+        this.client = createClient();
+    }
+
+    public static AWSDatabaseMigrationService createClient() {
+        final String awsAccessKeyId = PropertyUtils.getString(TaskConstants.AWS_ACCESS_KEY_ID);
+        final String awsSecretAccessKey = PropertyUtils.getString(TaskConstants.AWS_SECRET_ACCESS_KEY);
+        final String awsRegion = PropertyUtils.getString(TaskConstants.AWS_REGION);
+        final BasicAWSCredentials basicAWSCredentials = new BasicAWSCredentials(awsAccessKeyId, awsSecretAccessKey);
+        final AWSCredentialsProvider awsCredentialsProvider = new AWSStaticCredentialsProvider(basicAWSCredentials);
+
+        // create a DMS client
+        return AWSDatabaseMigrationServiceClientBuilder.standard()
+            .withCredentials(awsCredentialsProvider)
+            .withRegion(awsRegion)
+            .build();
+    }
+
+    public Boolean createReplicationTask() throws Exception {
+        logger.info(""createReplicationTask ......"");
+        CreateReplicationTaskRequest request = new CreateReplicationTaskRequest()
+            .withReplicationTaskIdentifier(replicationTaskIdentifier)
+            .withSourceEndpointArn(sourceEndpointArn)
+            .withTargetEndpointArn(targetEndpointArn)
+            .withReplicationInstanceArn(replicationInstanceArn)
+            .withMigrationType(migrationType)
+            .withTableMappings(tableMappings)
+            .withReplicationTaskSettings(replicationTaskSettings)
+            .withCdcStartTime(cdcStartTime)
+            .withCdcStartPosition(cdcStartPosition)
+            .withCdcStopPosition(cdcStopPosition)
+            .withTags(tags)
+            .withTaskData(taskData)
+            .withResourceIdentifier(resourceIdentifier);
+
+        request.setTableMappings(replaceFileParameters(request.getTableMappings()));
+        request.setReplicationTaskSettings(replaceFileParameters(request.getReplicationTaskSettings()));
+
+        CreateReplicationTaskResult result = client.createReplicationTask(request);
+        replicationTaskIdentifier = result.getReplicationTask().getReplicationTaskIdentifier();
+        replicationTaskArn = result.getReplicationTask().getReplicationTaskArn();
+        logger.info(""replicationTaskIdentifier: {}, replicationTaskArn: {}"", replicationTaskIdentifier, replicationTaskArn);
+        return awaitReplicationTaskStatus(STATUS.READY);
+    }
+
+
+    public Boolean startReplicationTask() {
+        logger.info(""startReplicationTask ......"");
+        StartReplicationTaskRequest request = new StartReplicationTaskRequest()
+            .withReplicationTaskArn(replicationTaskArn)
+            .withStartReplicationTaskType(startReplicationTaskType)
+            .withCdcStartTime(cdcStartTime)
+            .withCdcStartPosition(cdcStartPosition)
+            .withCdcStopPosition(cdcStopPosition);
+        StartReplicationTaskResult result = client.startReplicationTask(request);
+        replicationTaskArn = result.getReplicationTask().getReplicationTaskArn();
+        return awaitReplicationTaskStatus(STATUS.RUNNING);
+    }
+
+    public Boolean checkFinishedReplicationTask() {
+        logger.info(""checkFinishedReplicationTask ......"");
+        awaitReplicationTaskStatus(STATUS.STOPPED);
+        String stopReason = describeReplicationTasks().getStopReason();
+        return stopReason.endsWith(STATUS.FINISH_END_TOKEN);
+    }
+
+    public void stopReplicationTask() {
+        logger.info(""stopReplicationTask ......"");
+        if (replicationTaskArn == null) {
+            return;
+        }
+        StopReplicationTaskRequest request = new StopReplicationTaskRequest()
+            .withReplicationTaskArn(replicationTaskArn);
+        client.stopReplicationTask(request);
+        awaitReplicationTaskStatus(STATUS.STOPPED);
+    }
+
+    public Boolean deleteReplicationTask() {
+        logger.info(""deleteReplicationTask ......"");
+        DeleteReplicationTaskRequest request = new DeleteReplicationTaskRequest()
+            .withReplicationTaskArn(replicationTaskArn);
+        client.deleteReplicationTask(request);
+        Boolean isDeleteSuccessfully;
+        try {
+            isDeleteSuccessfully = awaitReplicationTaskStatus(STATUS.DELETE);
+        } catch (ResourceNotFoundException e) {
+            isDeleteSuccessfully = true;
+        }
+        return isDeleteSuccessfully;
+    }
+
+    public Boolean testConnectionEndpoint() {
+        return (testConnection(replicationInstanceArn, sourceEndpointArn) && testConnection(replicationInstanceArn, targetEndpointArn));
+    }
+
+    public Boolean testConnection(String replicationInstanceArn, String endpointArn) {
+        logger.info(""Test connect replication instance: {} and endpoint: {}"", replicationInstanceArn, endpointArn);
+        TestConnectionRequest request = new TestConnectionRequest().
+            withReplicationInstanceArn(replicationInstanceArn)
+            .withEndpointArn(endpointArn);
+        try {
+            client.testConnection(request);
+        } catch (InvalidResourceStateException e) {
+            logger.info(e.getErrorMessage());
+        }
+
+        return awaitConnectSuccess(replicationInstanceArn, endpointArn);
+    }
+
+    public Boolean awaitConnectSuccess(String replicationInstanceArn, String endpointArn) {
+        Filter instanceFilters = new Filter().withName(AWS_KEY.REPLICATION_INSTANCE_ARN).withValues(replicationInstanceArn);
+        Filter endpointFilters = new Filter().withName(AWS_KEY.ENDPOINT_ARN).withValues(endpointArn);
+        DescribeConnectionsRequest request = new DescribeConnectionsRequest().withFilters(endpointFilters, instanceFilters)
+            .withMarker("""");
+        while (true) {
+            ThreadUtils.sleep(CONSTANTS.CHECK_INTERVAL);
+            DescribeConnectionsResult response = client.describeConnections(request);
+            String status = response.getConnections().get(0).getStatus();
+            if (status.equals(STATUS.SUCCESSFUL)) {
+                logger.info(""Connect successful"");
+                return true;
+            } else if (!status.equals(STATUS.TESTING)) {
+                break;
+            }
+        }
+        logger.info(""Connect error"");
+        return false;
+    }
+
+    public ReplicationTask describeReplicationTasks() {
+        Filter replicationTaskFilter = new Filter().withName(AWS_KEY.REPLICATION_TASK_ARN).withValues(replicationTaskArn);
+        DescribeReplicationTasksRequest request = new DescribeReplicationTasksRequest().withFilters(replicationTaskFilter).withMaxRecords(20).withMarker("""");
+        DescribeReplicationTasksResult result = client.describeReplicationTasks(request);
+        ReplicationTask replicationTask = result.getReplicationTasks().get(0);
+
+        if (sourceEndpointArn == null) {
+            sourceEndpointArn = replicationTask.getSourceEndpointArn();
+        }
+
+        if (targetEndpointArn == null) {
+            targetEndpointArn = replicationTask.getTargetEndpointArn();
+        }
+
+        if (replicationInstanceArn == null) {
+            replicationInstanceArn = replicationTask.getReplicationInstanceArn();
+        }
+
+        if (replicationTaskArn == null) {
+            replicationTaskArn = replicationTask.getReplicationTaskArn();
+        }
+
+        return replicationTask;
+    }
+
+    public Boolean awaitReplicationTaskStatus(String exceptStatus, String... stopStatus) {
+        List<String> stopStatusSet = Arrays.asList(stopStatus);
+        Integer lastPercent = 0;
+        while (true) {
+            ThreadUtils.sleep(CONSTANTS.CHECK_INTERVAL);
+            ReplicationTask replicationTask = describeReplicationTasks();
+            String status = replicationTask.getStatus();
+
+            if (status.equals(STATUS.RUNNING) || status.equals(STATUS.STOPPED)) {
+                ReplicationTaskStats taskStats = replicationTask.getReplicationTaskStats();
+                Integer percent;
+                if (taskStats != null) {
+                    percent = taskStats.getFullLoadProgressPercent();
+                } else {
+                    percent = 0;
+                }
+                if (!lastPercent.equals(percent)) {
+                    String runningMessage = String.format(""fullLoadProgressPercent: %s "", percent);
+                    logger.info(runningMessage);
+                }
+                lastPercent = percent;
+            }
+
+            if (exceptStatus.equals(status)) {
+                logger.info(""success"");","[{'comment': 'remove it if useless.', 'commenter': 'caishunfeng'}, {'comment': 'I think It is necessary to log messages about the DMS task connect status for every step.', 'commenter': 'jieguangzhou'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHook.java,"@@ -0,0 +1,321 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.spi.utils.PropertyUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.FileInputStream;
+import java.io.IOException;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+import java.util.Date;
+import java.util.List;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.amazonaws.auth.AWSCredentialsProvider;
+import com.amazonaws.auth.AWSStaticCredentialsProvider;
+import com.amazonaws.auth.BasicAWSCredentials;
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationServiceClientBuilder;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DeleteReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.DescribeConnectionsRequest;
+import com.amazonaws.services.databasemigrationservice.model.DescribeConnectionsResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksRequest;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.Filter;
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.ResourceNotFoundException;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.StopReplicationTaskRequest;
+import com.amazonaws.services.databasemigrationservice.model.Tag;
+import com.amazonaws.services.databasemigrationservice.model.TestConnectionRequest;
+
+import lombok.AllArgsConstructor;
+import lombok.Data;
+import lombok.NoArgsConstructor;
+
+@Data
+public class DmsHook {
+    protected final Logger logger = LoggerFactory.getLogger(String.format(TaskConstants.TASK_LOG_LOGGER_NAME_FORMAT, getClass()));
+    private AWSDatabaseMigrationService client;
+    private String replicationTaskIdentifier;
+    private String sourceEndpointArn;
+    private String targetEndpointArn;
+    private String replicationInstanceArn;
+    private String migrationType;
+    private String tableMappings;
+    private String replicationTaskSettings;
+    private Date cdcStartTime;
+    private String cdcStartPosition;
+    private String cdcStopPosition;
+    private List<Tag> tags;
+    private String taskData;
+    private String resourceIdentifier;
+    private String replicationTaskArn;
+    private String startReplicationTaskType;
+
+    public DmsHook() {
+        this.client = createClient();
+    }
+
+    public static AWSDatabaseMigrationService createClient() {
+        final String awsAccessKeyId = PropertyUtils.getString(TaskConstants.AWS_ACCESS_KEY_ID);
+        final String awsSecretAccessKey = PropertyUtils.getString(TaskConstants.AWS_SECRET_ACCESS_KEY);
+        final String awsRegion = PropertyUtils.getString(TaskConstants.AWS_REGION);
+        final BasicAWSCredentials basicAWSCredentials = new BasicAWSCredentials(awsAccessKeyId, awsSecretAccessKey);
+        final AWSCredentialsProvider awsCredentialsProvider = new AWSStaticCredentialsProvider(basicAWSCredentials);
+
+        // create a DMS client
+        return AWSDatabaseMigrationServiceClientBuilder.standard()
+            .withCredentials(awsCredentialsProvider)
+            .withRegion(awsRegion)
+            .build();
+    }
+
+    public Boolean createReplicationTask() throws Exception {
+        logger.info(""createReplicationTask ......"");
+        CreateReplicationTaskRequest request = new CreateReplicationTaskRequest()
+            .withReplicationTaskIdentifier(replicationTaskIdentifier)
+            .withSourceEndpointArn(sourceEndpointArn)
+            .withTargetEndpointArn(targetEndpointArn)
+            .withReplicationInstanceArn(replicationInstanceArn)
+            .withMigrationType(migrationType)
+            .withTableMappings(tableMappings)
+            .withReplicationTaskSettings(replicationTaskSettings)
+            .withCdcStartTime(cdcStartTime)
+            .withCdcStartPosition(cdcStartPosition)
+            .withCdcStopPosition(cdcStopPosition)
+            .withTags(tags)
+            .withTaskData(taskData)
+            .withResourceIdentifier(resourceIdentifier);
+
+        request.setTableMappings(replaceFileParameters(request.getTableMappings()));
+        request.setReplicationTaskSettings(replaceFileParameters(request.getReplicationTaskSettings()));
+
+        CreateReplicationTaskResult result = client.createReplicationTask(request);
+        replicationTaskIdentifier = result.getReplicationTask().getReplicationTaskIdentifier();
+        replicationTaskArn = result.getReplicationTask().getReplicationTaskArn();
+        logger.info(""replicationTaskIdentifier: {}, replicationTaskArn: {}"", replicationTaskIdentifier, replicationTaskArn);
+        return awaitReplicationTaskStatus(STATUS.READY);
+    }
+
+
+    public Boolean startReplicationTask() {
+        logger.info(""startReplicationTask ......"");
+        StartReplicationTaskRequest request = new StartReplicationTaskRequest()
+            .withReplicationTaskArn(replicationTaskArn)
+            .withStartReplicationTaskType(startReplicationTaskType)
+            .withCdcStartTime(cdcStartTime)
+            .withCdcStartPosition(cdcStartPosition)
+            .withCdcStopPosition(cdcStopPosition);
+        StartReplicationTaskResult result = client.startReplicationTask(request);
+        replicationTaskArn = result.getReplicationTask().getReplicationTaskArn();
+        return awaitReplicationTaskStatus(STATUS.RUNNING);
+    }
+
+    public Boolean checkFinishedReplicationTask() {
+        logger.info(""checkFinishedReplicationTask ......"");
+        awaitReplicationTaskStatus(STATUS.STOPPED);
+        String stopReason = describeReplicationTasks().getStopReason();
+        return stopReason.endsWith(STATUS.FINISH_END_TOKEN);
+    }
+
+    public void stopReplicationTask() {
+        logger.info(""stopReplicationTask ......"");
+        if (replicationTaskArn == null) {
+            return;
+        }
+        StopReplicationTaskRequest request = new StopReplicationTaskRequest()
+            .withReplicationTaskArn(replicationTaskArn);
+        client.stopReplicationTask(request);
+        awaitReplicationTaskStatus(STATUS.STOPPED);
+    }
+
+    public Boolean deleteReplicationTask() {
+        logger.info(""deleteReplicationTask ......"");
+        DeleteReplicationTaskRequest request = new DeleteReplicationTaskRequest()
+            .withReplicationTaskArn(replicationTaskArn);
+        client.deleteReplicationTask(request);
+        Boolean isDeleteSuccessfully;
+        try {
+            isDeleteSuccessfully = awaitReplicationTaskStatus(STATUS.DELETE);
+        } catch (ResourceNotFoundException e) {
+            isDeleteSuccessfully = true;
+        }
+        return isDeleteSuccessfully;
+    }
+
+    public Boolean testConnectionEndpoint() {
+        return (testConnection(replicationInstanceArn, sourceEndpointArn) && testConnection(replicationInstanceArn, targetEndpointArn));
+    }
+
+    public Boolean testConnection(String replicationInstanceArn, String endpointArn) {
+        logger.info(""Test connect replication instance: {} and endpoint: {}"", replicationInstanceArn, endpointArn);
+        TestConnectionRequest request = new TestConnectionRequest().
+            withReplicationInstanceArn(replicationInstanceArn)
+            .withEndpointArn(endpointArn);
+        try {
+            client.testConnection(request);
+        } catch (InvalidResourceStateException e) {
+            logger.info(e.getErrorMessage());
+        }
+
+        return awaitConnectSuccess(replicationInstanceArn, endpointArn);
+    }
+
+    public Boolean awaitConnectSuccess(String replicationInstanceArn, String endpointArn) {
+        Filter instanceFilters = new Filter().withName(AWS_KEY.REPLICATION_INSTANCE_ARN).withValues(replicationInstanceArn);
+        Filter endpointFilters = new Filter().withName(AWS_KEY.ENDPOINT_ARN).withValues(endpointArn);
+        DescribeConnectionsRequest request = new DescribeConnectionsRequest().withFilters(endpointFilters, instanceFilters)
+            .withMarker("""");
+        while (true) {
+            ThreadUtils.sleep(CONSTANTS.CHECK_INTERVAL);
+            DescribeConnectionsResult response = client.describeConnections(request);
+            String status = response.getConnections().get(0).getStatus();
+            if (status.equals(STATUS.SUCCESSFUL)) {
+                logger.info(""Connect successful"");
+                return true;
+            } else if (!status.equals(STATUS.TESTING)) {
+                break;
+            }
+        }
+        logger.info(""Connect error"");
+        return false;
+    }
+
+    public ReplicationTask describeReplicationTasks() {
+        Filter replicationTaskFilter = new Filter().withName(AWS_KEY.REPLICATION_TASK_ARN).withValues(replicationTaskArn);
+        DescribeReplicationTasksRequest request = new DescribeReplicationTasksRequest().withFilters(replicationTaskFilter).withMaxRecords(20).withMarker("""");
+        DescribeReplicationTasksResult result = client.describeReplicationTasks(request);
+        ReplicationTask replicationTask = result.getReplicationTasks().get(0);
+
+        if (sourceEndpointArn == null) {
+            sourceEndpointArn = replicationTask.getSourceEndpointArn();
+        }
+
+        if (targetEndpointArn == null) {
+            targetEndpointArn = replicationTask.getTargetEndpointArn();
+        }
+
+        if (replicationInstanceArn == null) {
+            replicationInstanceArn = replicationTask.getReplicationInstanceArn();
+        }
+
+        if (replicationTaskArn == null) {
+            replicationTaskArn = replicationTask.getReplicationTaskArn();
+        }
+
+        return replicationTask;
+    }
+
+    public Boolean awaitReplicationTaskStatus(String exceptStatus, String... stopStatus) {
+        List<String> stopStatusSet = Arrays.asList(stopStatus);
+        Integer lastPercent = 0;
+        while (true) {
+            ThreadUtils.sleep(CONSTANTS.CHECK_INTERVAL);
+            ReplicationTask replicationTask = describeReplicationTasks();
+            String status = replicationTask.getStatus();
+
+            if (status.equals(STATUS.RUNNING) || status.equals(STATUS.STOPPED)) {
+                ReplicationTaskStats taskStats = replicationTask.getReplicationTaskStats();
+                Integer percent;
+                if (taskStats != null) {
+                    percent = taskStats.getFullLoadProgressPercent();
+                } else {
+                    percent = 0;
+                }
+                if (!lastPercent.equals(percent)) {
+                    String runningMessage = String.format(""fullLoadProgressPercent: %s "", percent);
+                    logger.info(runningMessage);
+                }
+                lastPercent = percent;
+            }
+
+            if (exceptStatus.equals(status)) {
+                logger.info(""success"");
+                return true;
+            } else if (stopStatusSet.contains(status)) {
+                break;
+            }
+        }
+        logger.info(""error"");","[{'comment': 'remove it if useless.', 'commenter': 'caishunfeng'}, {'comment': ""I think It is necessary to log messages about the DMS task connect status for every step. Especially when it's wrong."", 'commenter': 'jieguangzhou'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,259 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+    public DmsHook dmsHook;
+    /**
+     * Dms parameters
+     */
+    private DmsParameters parameters;
+    private DmsHook.ApplicationIds appId;
+
+    public DmsTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+    }
+
+    @Override
+    public void init() throws TaskException {
+        logger.info(""Dms task params {}"", taskExecutionContext.getTaskParams());
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DmsParameters.class);
+        initDmsHook();
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        exitStatusCode = checkCreateReplicationTask();
+        if (exitStatusCode == TaskConstants.EXIT_CODE_SUCCESS) {
+            exitStatusCode = startReplicationTask();
+        } else {
+            throw new TaskException(""DMS task failed to start"");
+        }
+
+        // if the task is not running, the task will be deleted
+        if (exitStatusCode == TaskConstants.EXIT_CODE_FAILURE && !parameters.getIsRestartTask()) {
+            dmsHook.deleteReplicationTask();
+        }else {
+            appId = dmsHook.getApplicationIds();
+            setAppIds(JSONUtils.toJsonString(appId));
+        }
+    }
+
+    @Override
+    public void trackApplicationStatus() {
+        initAppId();
+        dmsHook.setReplicationTaskArn(appId.getReplicationTaskArn());
+        // if CdcStopPosition is not set, the task will not continue to check the running status
+        if (isStopTaskWhenCdc()) {
+            logger.info(""This is a cdc task and cdcStopPosition is not set, the task will not continue to check the running status"");
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+            return;
+        }
+
+        Boolean isFinishedSuccessfully = dmsHook.checkFinishedReplicationTask();
+        if (isFinishedSuccessfully) {
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            throw new TaskException(""DMS task failed to track"");
+        }
+    }
+
+    /**
+     * init DMS remote AppId if null
+     */
+    private void initAppId() {
+        if (appId == null) {
+            if (StringUtils.isNotEmpty(getAppIds())) {
+                appId = JSONUtils.parseObject(getAppIds(), DmsHook.ApplicationIds.class);
+            }
+        }
+        if (appId == null) {
+            throw new TaskException(""sagemaker applicationID is null"");
+        }
+    }
+
+    public int checkCreateReplicationTask() throws TaskException {
+
+        // if IsRestartTask, return success, do not create replication task
+        if (parameters.getIsRestartTask()) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        }
+
+        // if not IsRestartTask, create replication task
+        Boolean isCreateSuccessfully;
+        try {
+            isCreateSuccessfully = dmsHook.createReplicationTask();
+        } catch (Exception e) {
+            throw new TaskException(""DMS task create replication task error"", e);
+        }
+
+        // if create replication task successfully, return EXIT_CODE_SUCCESS, else return EXIT_CODE_FAILURE
+        if (isCreateSuccessfully) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+    }
+
+    /**
+     * start replication task
+     *
+     * @return
+     * @throws TaskException
+     */
+    public int startReplicationTask() {
+
+        Boolean isStartSuccessfully = false;
+        try {
+            isStartSuccessfully = dmsHook.startReplicationTask();
+        } catch (InvalidResourceStateException e) {
+            logger.error(""Failed to start a task, error message: {}"", e.getErrorMessage());
+
+            // Only restart task when the error contains ""Test connection"", means instance can not connect to source or target
+            if (!e.getErrorMessage().contains(""Test connection"")) {
+                return TaskConstants.EXIT_CODE_FAILURE;
+            }
+
+            logger.info(""restart replication task"");
+            // if only restart task, run dmsHook.describeReplicationTasks to get replication task arn
+            if (parameters.getIsRestartTask()) {
+                dmsHook.describeReplicationTasks();
+            }
+
+            // test connection endpoint again and restart task if connection is ok
+            if (dmsHook.testConnectionEndpoint()) {
+                isStartSuccessfully = dmsHook.startReplicationTask();
+            }
+        }
+
+        // if start replication task failed, return EXIT_CODE_FAILURE
+        if (!isStartSuccessfully) {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+
+        return TaskConstants.EXIT_CODE_SUCCESS;
+    }
+
+    /**
+     * check if stop task when cdc
+     *
+     * @return true if stop task when cdc type and cdcStopPosition is not set, else return false
+     */
+    public Boolean isStopTaskWhenCdc() {
+        ReplicationTask replicationTask = dmsHook.describeReplicationTasks();
+        String migrationType = replicationTask.getMigrationType();
+        return migrationType.contains(""cdc"") && parameters.getCdcStopPosition() == null;
+    }
+
+    /**
+     * init dms hook
+     */
+    public void initDmsHook() throws TaskException {
+        convertJsonParameters();
+
+        dmsHook = new DmsHook();
+        try {
+            BeanUtils.copyProperties(dmsHook, parameters);
+        } catch (Exception e) {
+            throw new TaskException(""DMS task init error"", e);
+        }
+
+
+        if (!StringUtils.isNotEmpty(parameters.getStartReplicationTaskType())) {
+            if (parameters.getIsRestartTask()) {
+                dmsHook.setStartReplicationTaskType(DmsHook.START_TYPE.RELOAD_TARGET);
+            } else {
+                dmsHook.setStartReplicationTaskType(DmsHook.START_TYPE.START_REPLICATION);
+            }
+        }
+    }
+
+    /**
+     * convert json parameters to dms parameters
+     */
+    public void convertJsonParameters() throws TaskException {
+        // create a new parameter object using the json data if the json data is not empty
+        if (parameters.getIsJsonFormat() && parameters.getJsonData() != null) {
+            // combining local and global parameters
+            String jsonData = ParameterUtils.convertParameterPlaceholders(parameters.getJsonData(), ParamUtils.convert(taskExecutionContext.getPrepareParamsMap()));
+
+            boolean isRestartTask = parameters.getIsRestartTask();
+            try {
+                parameters = objectMapper.readValue(jsonData, DmsParameters.class);
+                parameters.setIsRestartTask(isRestartTask);
+            } catch (Exception e) {
+                logger.error(""Failed to convert json data to DmsParameters object, error message: {}"", e.getMessage());
+                throw new TaskException(e.getMessage());
+            }
+        }
+    }
+
+    @Override
+    public DmsParameters getParameters() {
+        return parameters;
+    }
+
+    @Override
+    public void cancelApplication() {
+        dmsHook.stopReplicationTask();
+//        dmsHook.deleteReplicationTask();","[{'comment': '```suggestion\r\n```', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsParameters.java,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+
+import java.util.Date;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.Tag;
+
+import lombok.Data;
+
+@Data
+public class DmsParameters extends AbstractParameters {
+
+    private Boolean isRestartTask = false;
+    private Boolean isJsonFormat = false;
+    private String jsonData;
+    private String replicationTaskIdentifier;
+    private String sourceEndpointArn;
+    private String targetEndpointArn;
+    private String replicationInstanceArn;
+    private String migrationType;
+    private String tableMappings;
+    private String replicationTaskSettings;
+    private Date cdcStartTime;
+    private String cdcStartPosition;
+    private String cdcStopPosition;
+    private List<Tag> tags;
+    private String taskData;
+    private String resourceIdentifier;
+    private String replicationTaskArn;
+    private String startReplicationTaskType;
+
+    @Override
+    public boolean checkParameters() {
+        boolean flag;
+        if (isJsonFormat) {
+            flag = jsonData != null;
+        } else if (isRestartTask) {
+            flag = (replicationTaskArn != null);","[{'comment': '```suggestion\r\n            flag = replicationTaskArn != null;\r\n```', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,259 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+    public DmsHook dmsHook;
+    /**
+     * Dms parameters
+     */
+    private DmsParameters parameters;
+    private DmsHook.ApplicationIds appId;
+
+    public DmsTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+    }
+
+    @Override
+    public void init() throws TaskException {
+        logger.info(""Dms task params {}"", taskExecutionContext.getTaskParams());
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DmsParameters.class);
+        initDmsHook();
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        exitStatusCode = checkCreateReplicationTask();
+        if (exitStatusCode == TaskConstants.EXIT_CODE_SUCCESS) {
+            exitStatusCode = startReplicationTask();
+        } else {
+            throw new TaskException(""DMS task failed to start"");
+        }
+
+        // if the task is not running, the task will be deleted
+        if (exitStatusCode == TaskConstants.EXIT_CODE_FAILURE && !parameters.getIsRestartTask()) {
+            dmsHook.deleteReplicationTask();
+        }else {
+            appId = dmsHook.getApplicationIds();
+            setAppIds(JSONUtils.toJsonString(appId));
+        }
+    }
+
+    @Override
+    public void trackApplicationStatus() {
+        initAppId();
+        dmsHook.setReplicationTaskArn(appId.getReplicationTaskArn());
+        // if CdcStopPosition is not set, the task will not continue to check the running status
+        if (isStopTaskWhenCdc()) {
+            logger.info(""This is a cdc task and cdcStopPosition is not set, the task will not continue to check the running status"");
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+            return;
+        }
+
+        Boolean isFinishedSuccessfully = dmsHook.checkFinishedReplicationTask();
+        if (isFinishedSuccessfully) {
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            throw new TaskException(""DMS task failed to track"");
+        }
+    }
+
+    /**
+     * init DMS remote AppId if null
+     */
+    private void initAppId() {
+        if (appId == null) {
+            if (StringUtils.isNotEmpty(getAppIds())) {
+                appId = JSONUtils.parseObject(getAppIds(), DmsHook.ApplicationIds.class);
+            }
+        }
+        if (appId == null) {
+            throw new TaskException(""sagemaker applicationID is null"");
+        }
+    }
+
+    public int checkCreateReplicationTask() throws TaskException {
+
+        // if IsRestartTask, return success, do not create replication task
+        if (parameters.getIsRestartTask()) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        }
+
+        // if not IsRestartTask, create replication task
+        Boolean isCreateSuccessfully;
+        try {
+            isCreateSuccessfully = dmsHook.createReplicationTask();
+        } catch (Exception e) {
+            throw new TaskException(""DMS task create replication task error"", e);
+        }
+
+        // if create replication task successfully, return EXIT_CODE_SUCCESS, else return EXIT_CODE_FAILURE
+        if (isCreateSuccessfully) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+    }
+
+    /**
+     * start replication task
+     *
+     * @return
+     * @throws TaskException
+     */
+    public int startReplicationTask() {
+
+        Boolean isStartSuccessfully = false;
+        try {
+            isStartSuccessfully = dmsHook.startReplicationTask();
+        } catch (InvalidResourceStateException e) {
+            logger.error(""Failed to start a task, error message: {}"", e.getErrorMessage());
+
+            // Only restart task when the error contains ""Test connection"", means instance can not connect to source or target
+            if (!e.getErrorMessage().contains(""Test connection"")) {
+                return TaskConstants.EXIT_CODE_FAILURE;
+            }
+
+            logger.info(""restart replication task"");
+            // if only restart task, run dmsHook.describeReplicationTasks to get replication task arn
+            if (parameters.getIsRestartTask()) {
+                dmsHook.describeReplicationTasks();
+            }
+
+            // test connection endpoint again and restart task if connection is ok
+            if (dmsHook.testConnectionEndpoint()) {
+                isStartSuccessfully = dmsHook.startReplicationTask();
+            }
+        }
+
+        // if start replication task failed, return EXIT_CODE_FAILURE
+        if (!isStartSuccessfully) {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+
+        return TaskConstants.EXIT_CODE_SUCCESS;
+    }
+
+    /**
+     * check if stop task when cdc
+     *
+     * @return true if stop task when cdc type and cdcStopPosition is not set, else return false
+     */
+    public Boolean isStopTaskWhenCdc() {
+        ReplicationTask replicationTask = dmsHook.describeReplicationTasks();
+        String migrationType = replicationTask.getMigrationType();
+        return migrationType.contains(""cdc"") && parameters.getCdcStopPosition() == null;
+    }
+
+    /**
+     * init dms hook
+     */
+    public void initDmsHook() throws TaskException {
+        convertJsonParameters();
+
+        dmsHook = new DmsHook();
+        try {
+            BeanUtils.copyProperties(dmsHook, parameters);
+        } catch (Exception e) {
+            throw new TaskException(""DMS task init error"", e);
+        }
+
+
+        if (!StringUtils.isNotEmpty(parameters.getStartReplicationTaskType())) {
+            if (parameters.getIsRestartTask()) {
+                dmsHook.setStartReplicationTaskType(DmsHook.START_TYPE.RELOAD_TARGET);
+            } else {
+                dmsHook.setStartReplicationTaskType(DmsHook.START_TYPE.START_REPLICATION);
+            }
+        }
+    }
+
+    /**
+     * convert json parameters to dms parameters
+     */
+    public void convertJsonParameters() throws TaskException {
+        // create a new parameter object using the json data if the json data is not empty
+        if (parameters.getIsJsonFormat() && parameters.getJsonData() != null) {
+            // combining local and global parameters
+            String jsonData = ParameterUtils.convertParameterPlaceholders(parameters.getJsonData(), ParamUtils.convert(taskExecutionContext.getPrepareParamsMap()));
+
+            boolean isRestartTask = parameters.getIsRestartTask();
+            try {
+                parameters = objectMapper.readValue(jsonData, DmsParameters.class);
+                parameters.setIsRestartTask(isRestartTask);
+            } catch (Exception e) {
+                logger.error(""Failed to convert json data to DmsParameters object, error message: {}"", e.getMessage());","[{'comment': '```suggestion\r\n                logger.error(""Failed to convert json data to DmsParameters object"", e);\r\n```', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHookTest.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.mockStatic;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+    JSONUtils.class,
+    DmsHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DmsHookTest {
+
+    AWSDatabaseMigrationService client;
+
+    @Before
+    public void before() {
+        mockStatic(DmsHook.class);
+        client = mock(AWSDatabaseMigrationService.class);
+        when(DmsHook.createClient()).thenAnswer(invocation -> client);
+    }
+
+    @Test(timeout = 60000)
+    public void testCreateReplicationTask() throws Exception {
+
+        DmsHook dmsHook = spy(new DmsHook());
+        CreateReplicationTaskResult createReplicationTaskResult = mock(CreateReplicationTaskResult.class);
+        when(client.createReplicationTask(any())).thenReturn(createReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");","[{'comment': 'use constant string `arn:aws:dms:ap-southeast-1:123456789012:task:task`', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHookTest.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.mockStatic;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+    JSONUtils.class,
+    DmsHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DmsHookTest {
+
+    AWSDatabaseMigrationService client;
+
+    @Before
+    public void before() {
+        mockStatic(DmsHook.class);
+        client = mock(AWSDatabaseMigrationService.class);
+        when(DmsHook.createClient()).thenAnswer(invocation -> client);
+    }
+
+    @Test(timeout = 60000)
+    public void testCreateReplicationTask() throws Exception {
+
+        DmsHook dmsHook = spy(new DmsHook());
+        CreateReplicationTaskResult createReplicationTaskResult = mock(CreateReplicationTaskResult.class);
+        when(client.createReplicationTask(any())).thenReturn(createReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.READY);
+        when(createReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.createReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+        Assert.assertEquals(""task"", dmsHook.getReplicationTaskIdentifier());
+    }
+
+    @Test(timeout = 60000)
+    public void testStartReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+        StartReplicationTaskResult startReplicationTaskResult = mock(StartReplicationTaskResult.class);
+        when(client.startReplicationTask(any())).thenReturn(startReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.RUNNING);
+        when(startReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.startReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+    }
+
+    @Test(timeout = 60000)
+    public void testCheckFinishedReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.STOPPED);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        when(replicationTask.getStopReason()).thenReturn(""*_FINISHED"");
+        Assert.assertTrue(dmsHook.checkFinishedReplicationTask());
+
+        when(replicationTask.getStopReason()).thenReturn(""*_ERROR"");
+        Assert.assertFalse(dmsHook.checkFinishedReplicationTask());
+    }
+
+    @Test(timeout = 60000)
+    public void testDeleteReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.DELETE);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.deleteReplicationTask());
+
+    }
+
+    @Test
+    public void testTestConnectionEndpoint() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        String replicationInstanceArn = ""replicationInstanceArn"";
+        String trueSourceEndpointArn = ""trueSourceEndpointArn"";
+        String trueTargetEndpointArn = ""trueTargetEndpointArn"";
+        String falseSourceEndpointArn = ""falseSourceEndpointArn"";
+        String falseTargetEndpointArn = ""falseTargetEndpointArn"";
+
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueSourceEndpointArn);
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueTargetEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseSourceEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseTargetEndpointArn);
+
+
+        dmsHook.setReplicationInstanceArn(replicationInstanceArn);
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertTrue(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+    }
+
+
+    @Test
+    public void testDescribeReplicationTasks() {
+
+        DmsHook dmsHook = new DmsHook();
+        dmsHook.setReplicationInstanceArn(""arn:aws:dms:ap-southeast-1:123456789012:task:task_exist"");
+
+        DescribeReplicationTasksResult describeReplicationTasksResult = mock(DescribeReplicationTasksResult.class);
+        when(client.describeReplicationTasks(any())).thenReturn(describeReplicationTasksResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getSourceEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"");
+        when(replicationTask.getTargetEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"");
+
+        when(describeReplicationTasksResult.getReplicationTasks()).thenReturn(Arrays.asList(replicationTask));
+
+        ReplicationTask replicationTaskOut = dmsHook.describeReplicationTasks();
+        Assert.assertNotEquals(dmsHook.getReplicationInstanceArn(), replicationTaskOut.getReplicationTaskArn());
+        Assert.assertEquals(""task"", replicationTaskOut.getReplicationTaskIdentifier());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"", replicationTaskOut.getSourceEndpointArn());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"", replicationTaskOut.getTargetEndpointArn());
+
+    }
+
+
+    @Test(timeout = 60000)
+    public void testAwaitReplicationTaskStatus() {
+
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        ReplicationTaskStats taskStats = mock(ReplicationTaskStats.class);
+        when(replicationTask.getReplicationTaskStats()).thenReturn(taskStats);
+        when(taskStats.getFullLoadProgressPercent()).thenReturn(100);
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertFalse(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED, DmsHook.STATUS.RUNNING));
+    }
+
+    @Test
+    public void testReplaceFileParameters() throws IOException {
+        String path = this.getClass().getResource(""table_mapping.json"").getPath();
+
+        String jsonData = loadJson(""table_mapping.json"");
+
+        DmsHook dmsHook = new DmsHook();
+
+        String pathParameter = ""file://"" + path;
+        Assert.assertEquals(jsonData, dmsHook.replaceFileParameters(pathParameter));
+
+//        String pathParameter2 = ""file://"" + ""not_exist.json"";
+//
+//        try {
+//            Assert.assertEquals(pathParameter2, dmsHook.replaceFileParameters(pathParameter2));
+//        }catch (Exception e) {
+//            Assert.assertTrue(e instanceof IOException);
+//        }","[{'comment': '```suggestion\r\n```', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHookTest.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.mockStatic;
+import static org.powermock.api.mockito.PowerMockito.when;
+
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+
+import org.apache.commons.io.IOUtils;
+
+import java.io.IOException;
+import java.io.InputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.Arrays;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.amazonaws.services.databasemigrationservice.AWSDatabaseMigrationService;
+import com.amazonaws.services.databasemigrationservice.model.CreateReplicationTaskResult;
+import com.amazonaws.services.databasemigrationservice.model.DescribeReplicationTasksResult;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTaskStats;
+import com.amazonaws.services.databasemigrationservice.model.StartReplicationTaskResult;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+    JSONUtils.class,
+    DmsHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DmsHookTest {
+
+    AWSDatabaseMigrationService client;
+
+    @Before
+    public void before() {
+        mockStatic(DmsHook.class);
+        client = mock(AWSDatabaseMigrationService.class);
+        when(DmsHook.createClient()).thenAnswer(invocation -> client);
+    }
+
+    @Test(timeout = 60000)
+    public void testCreateReplicationTask() throws Exception {
+
+        DmsHook dmsHook = spy(new DmsHook());
+        CreateReplicationTaskResult createReplicationTaskResult = mock(CreateReplicationTaskResult.class);
+        when(client.createReplicationTask(any())).thenReturn(createReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.READY);
+        when(createReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.createReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+        Assert.assertEquals(""task"", dmsHook.getReplicationTaskIdentifier());
+    }
+
+    @Test(timeout = 60000)
+    public void testStartReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+        StartReplicationTaskResult startReplicationTaskResult = mock(StartReplicationTaskResult.class);
+        when(client.startReplicationTask(any())).thenReturn(startReplicationTaskResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.RUNNING);
+        when(startReplicationTaskResult.getReplicationTask()).thenReturn(replicationTask);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.startReplicationTask());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:task:task"", dmsHook.getReplicationTaskArn());
+    }
+
+    @Test(timeout = 60000)
+    public void testCheckFinishedReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.STOPPED);
+
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        when(replicationTask.getStopReason()).thenReturn(""*_FINISHED"");
+        Assert.assertTrue(dmsHook.checkFinishedReplicationTask());
+
+        when(replicationTask.getStopReason()).thenReturn(""*_ERROR"");
+        Assert.assertFalse(dmsHook.checkFinishedReplicationTask());
+    }
+
+    @Test(timeout = 60000)
+    public void testDeleteReplicationTask() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getStatus()).thenReturn(DmsHook.STATUS.DELETE);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+        Assert.assertTrue(dmsHook.deleteReplicationTask());
+
+    }
+
+    @Test
+    public void testTestConnectionEndpoint() {
+        DmsHook dmsHook = spy(new DmsHook());
+
+        String replicationInstanceArn = ""replicationInstanceArn"";
+        String trueSourceEndpointArn = ""trueSourceEndpointArn"";
+        String trueTargetEndpointArn = ""trueTargetEndpointArn"";
+        String falseSourceEndpointArn = ""falseSourceEndpointArn"";
+        String falseTargetEndpointArn = ""falseTargetEndpointArn"";
+
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueSourceEndpointArn);
+        doReturn(true).when(dmsHook).testConnection(replicationInstanceArn, trueTargetEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseSourceEndpointArn);
+        doReturn(false).when(dmsHook).testConnection(replicationInstanceArn, falseTargetEndpointArn);
+
+
+        dmsHook.setReplicationInstanceArn(replicationInstanceArn);
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertTrue(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(trueSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(falseTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+        dmsHook.setSourceEndpointArn(falseSourceEndpointArn);
+        dmsHook.setTargetEndpointArn(trueTargetEndpointArn);
+        Assert.assertFalse(dmsHook.testConnectionEndpoint());
+
+    }
+
+
+    @Test
+    public void testDescribeReplicationTasks() {
+
+        DmsHook dmsHook = new DmsHook();
+        dmsHook.setReplicationInstanceArn(""arn:aws:dms:ap-southeast-1:123456789012:task:task_exist"");
+
+        DescribeReplicationTasksResult describeReplicationTasksResult = mock(DescribeReplicationTasksResult.class);
+        when(client.describeReplicationTasks(any())).thenReturn(describeReplicationTasksResult);
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        when(replicationTask.getReplicationTaskArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:task:task"");
+        when(replicationTask.getReplicationTaskIdentifier()).thenReturn(""task"");
+        when(replicationTask.getSourceEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"");
+        when(replicationTask.getTargetEndpointArn()).thenReturn(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"");
+
+        when(describeReplicationTasksResult.getReplicationTasks()).thenReturn(Arrays.asList(replicationTask));
+
+        ReplicationTask replicationTaskOut = dmsHook.describeReplicationTasks();
+        Assert.assertNotEquals(dmsHook.getReplicationInstanceArn(), replicationTaskOut.getReplicationTaskArn());
+        Assert.assertEquals(""task"", replicationTaskOut.getReplicationTaskIdentifier());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:source"", replicationTaskOut.getSourceEndpointArn());
+        Assert.assertEquals(""arn:aws:dms:ap-southeast-1:123456789012:endpoint:target"", replicationTaskOut.getTargetEndpointArn());
+
+    }
+
+
+    @Test(timeout = 60000)
+    public void testAwaitReplicationTaskStatus() {
+
+        DmsHook dmsHook = spy(new DmsHook());
+
+        ReplicationTask replicationTask = mock(ReplicationTask.class);
+        doReturn(replicationTask).when(dmsHook).describeReplicationTasks();
+
+        ReplicationTaskStats taskStats = mock(ReplicationTaskStats.class);
+        when(replicationTask.getReplicationTaskStats()).thenReturn(taskStats);
+        when(taskStats.getFullLoadProgressPercent()).thenReturn(100);
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertTrue(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED));
+
+        when(replicationTask.getStatus()).thenReturn(
+            DmsHook.STATUS.RUNNING,
+            DmsHook.STATUS.STOPPED
+        );
+        Assert.assertFalse(dmsHook.awaitReplicationTaskStatus(DmsHook.STATUS.STOPPED, DmsHook.STATUS.RUNNING));
+    }
+
+    @Test
+    public void testReplaceFileParameters() throws IOException {
+        String path = this.getClass().getResource(""table_mapping.json"").getPath();
+
+        String jsonData = loadJson(""table_mapping.json"");
+
+        DmsHook dmsHook = new DmsHook();
+
+        String pathParameter = ""file://"" + path;
+        Assert.assertEquals(jsonData, dmsHook.replaceFileParameters(pathParameter));
+
+//        String pathParameter2 = ""file://"" + ""not_exist.json"";
+//
+//        try {
+//            Assert.assertEquals(pathParameter2, dmsHook.replaceFileParameters(pathParameter2));
+//        }catch (Exception e) {
+//            Assert.assertTrue(e instanceof IOException);
+//        }
+
+        String pathParameter3 = ""{}"";
+        Assert.assertEquals(pathParameter3, dmsHook.replaceFileParameters(pathParameter3));
+
+    }
+
+//    this.getClass().getResourceAsStream(""SagemakerRequestJson.json""))","[{'comment': '```suggestion\r\n```', 'commenter': 'caishunfeng'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTaskTest.java,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.powermock.api.mockito.PowerMockito.mock;
+import static org.powermock.api.mockito.PowerMockito.when;
+import static org.powermock.api.mockito.PowerMockito.whenNew;
+
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.PropertyUtils;
+
+import org.junit.Assert;
+import org.junit.Before;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.mockito.Mock;
+import org.mockito.Mockito;
+import org.powermock.api.support.membermodification.MemberModifier;
+import org.powermock.core.classloader.annotations.PowerMockIgnore;
+import org.powermock.core.classloader.annotations.PrepareForTest;
+import org.powermock.modules.junit4.PowerMockRunner;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+
+@RunWith(PowerMockRunner.class)
+@PrepareForTest({
+    JSONUtils.class,
+    PropertyUtils.class,
+    DmsHook.class
+})
+@PowerMockIgnore({""javax.*""})
+public class DmsTaskTest {
+
+    @Mock
+    DmsHook dmsHook;
+
+    DmsTask dmsTask;
+
+    @Before
+    public void before() throws Exception {
+        whenNew(DmsHook.class).withAnyArguments().thenReturn(dmsHook);
+        DmsParameters dmsParameters = new DmsParameters();
+        dmsTask = initTask(dmsParameters);
+        dmsTask.initDmsHook();
+        MemberModifier.field(DmsTask.class, ""dmsHook"").set(dmsTask, dmsHook);
+    }
+
+    @Test
+    public void testCreateTaskJson() {","[{'comment': 'It seems a meanless test case.', 'commenter': 'caishunfeng'}, {'comment': 'This case will make sure that the parameter can read value correctly from JSON format data', 'commenter': 'jieguangzhou'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/test/java/org/apache/dolphinscheduler/plugin/task/dms/DmsHookTest.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static org.mockito.Mockito.any;
+import static org.mockito.Mockito.doReturn;
+import static org.mockito.Mockito.spy;
+import static org.powermock.api.mockito.PowerMockito.mock;","[{'comment': 'Could u plz removing the dependency of `powermock` in this PR? We have already had a PR to remove all `powermock` in `dolphinscheduler-task-plugin` module, see: https://github.com/apache/dolphinscheduler/pull/11778\r\nThanks~', 'commenter': 'EricGao888'}, {'comment': 'Yes, I will remove powermock', 'commenter': 'jieguangzhou'}, {'comment': 'done', 'commenter': 'jieguangzhou'}]"
11868,docs/docs/en/guide/task/dms.md,"@@ -0,0 +1,107 @@
+# DMS Node
+
+## Overview
+
+[Pytorch](https://pytorch.org) is a mainstream Python machine learning library.
+
+[AWS Database Migration Service (AWS DMS)](https://aws.amazon.com/cn/dms) helps you migrate databases to AWS quickly and securely. 
+The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. 
+The AWS Database Migration Service can migrate your data to and from the most widely used commercial and open-source databases.
+
+DMS task plugin can help users to create and start DMS tasks in DolphinScheduler more conveniently.
+
+Contains two features:
+- Create DMS task and start DMS task
+- Restart DMS task
+
+We can create DMS task and start DMS task in two ways:
+- Use interface
+- Use json data","[{'comment': 'JSON', 'commenter': 'Tianqi-Dotes'}, {'comment': 'and the following json', 'commenter': 'Tianqi-Dotes'}]"
11868,docs/docs/en/guide/task/dms.md,"@@ -0,0 +1,107 @@
+# DMS Node
+
+## Overview
+
+[Pytorch](https://pytorch.org) is a mainstream Python machine learning library.
+
+[AWS Database Migration Service (AWS DMS)](https://aws.amazon.com/cn/dms) helps you migrate databases to AWS quickly and securely. 
+The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. 
+The AWS Database Migration Service can migrate your data to and from the most widely used commercial and open-source databases.
+
+DMS task plugin can help users to create and start DMS tasks in DolphinScheduler more conveniently.
+
+Contains two features:
+- Create DMS task and start DMS task
+- Restart DMS task
+
+We can create DMS task and start DMS task in two ways:
+- Use interface
+- Use json data
+
+DolphinScheduler will track the status of the DMS task and set the status to successfully completed when the DMS task is completed. Except for the CDC task without end time.
+
+So, if the `migrationType` is `cdc` or `full-load-and-cdc`, `cdcStopPosition` not be set, DolphinScheduler will set the status to successfully after the DMS task start successfully.","[{'comment': 'after the DMS task starts successfully.', 'commenter': 'Tianqi-Dotes'}]"
11868,docs/docs/en/guide/task/dms.md,"@@ -0,0 +1,107 @@
+# DMS Node
+
+## Overview
+
+[Pytorch](https://pytorch.org) is a mainstream Python machine learning library.
+
+[AWS Database Migration Service (AWS DMS)](https://aws.amazon.com/cn/dms) helps you migrate databases to AWS quickly and securely. 
+The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. 
+The AWS Database Migration Service can migrate your data to and from the most widely used commercial and open-source databases.
+
+DMS task plugin can help users to create and start DMS tasks in DolphinScheduler more conveniently.
+
+Contains two features:
+- Create DMS task and start DMS task
+- Restart DMS task
+
+We can create DMS task and start DMS task in two ways:
+- Use interface
+- Use json data
+
+DolphinScheduler will track the status of the DMS task and set the status to successfully completed when the DMS task is completed. Except for the CDC task without end time.
+
+So, if the `migrationType` is `cdc` or `full-load-and-cdc`, `cdcStopPosition` not be set, DolphinScheduler will set the status to successfully after the DMS task start successfully.
+
+## Create Task
+
+- Click `Project Management -> Project Name -> Workflow Definition`, and click the `Create Workflow` button to enter the DAG editing page.
+- Drag <img src=""../../../../img/tasks/icons/dms.png"" width=""15""/> from the toolbar to the canvas.
+
+## Task Example
+
+The task plugin picture is as follows
+
+**Create and start DMS task by interface**
+
+![dms](../../../../img/tasks/demo/dms_create_and_start.png)
+
+
+**Restart DMS task by interface**
+
+![dms](../../../../img/tasks/demo/dms_restart.png)
+
+
+**Create and start DMS task by json data**
+
+![dms](../../../../img/tasks/demo/dms_create_and_start_json.png)
+
+**Restart DMS task by json data**
+
+![dms](../../../../img/tasks/demo/dms_restart_json.png)
+
+
+
+### First, introduce some general parameters of DolphinScheduler
+
+- **Node name**: The node name in a workflow definition is unique.
+- **Run flag**: Identifies whether this node schedules normally, if it does not need to execute, select
+  the `prohibition execution`.
+- **Descriptive information**: Describe the function of the node.
+- **Task priority**: When the number of worker threads is insufficient, execute in the order of priority from high
+  to low, and tasks with the same priority will execute in a first-in first-out order.","[{'comment': 'first-in-first-out', 'commenter': 'Tianqi-Dotes'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,258 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+    public DmsHook dmsHook;
+    /**
+     * Dms parameters
+     */
+    private DmsParameters parameters;
+    private DmsHook.ApplicationIds appId;
+
+    public DmsTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+    }
+
+    @Override
+    public void init() throws TaskException {
+        logger.info(""Dms task params {}"", taskExecutionContext.getTaskParams());
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DmsParameters.class);
+        initDmsHook();
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        exitStatusCode = checkCreateReplicationTask();
+        if (exitStatusCode == TaskConstants.EXIT_CODE_SUCCESS) {
+            exitStatusCode = startReplicationTask();
+        } else {
+            throw new TaskException(""DMS task failed to start"");
+        }
+
+        // if the task is not running, the task will be deleted
+        if (exitStatusCode == TaskConstants.EXIT_CODE_FAILURE && !parameters.getIsRestartTask()) {
+            dmsHook.deleteReplicationTask();
+        }else {
+            appId = dmsHook.getApplicationIds();
+            setAppIds(JSONUtils.toJsonString(appId));
+        }
+    }
+
+    @Override
+    public void trackApplicationStatus() {
+        initAppId();
+        dmsHook.setReplicationTaskArn(appId.getReplicationTaskArn());
+        // if CdcStopPosition is not set, the task will not continue to check the running status
+        if (isStopTaskWhenCdc()) {
+            logger.info(""This is a cdc task and cdcStopPosition is not set, the task will not continue to check the running status"");
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+            return;
+        }
+
+        Boolean isFinishedSuccessfully = dmsHook.checkFinishedReplicationTask();
+        if (isFinishedSuccessfully) {
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            throw new TaskException(""DMS task failed to track"");
+        }
+    }
+
+    /**
+     * init DMS remote AppId if null
+     */
+    private void initAppId() {
+        if (appId == null) {
+            if (StringUtils.isNotEmpty(getAppIds())) {
+                appId = JSONUtils.parseObject(getAppIds(), DmsHook.ApplicationIds.class);
+            }
+        }
+        if (appId == null) {
+            throw new TaskException(""sagemaker applicationID is null"");","[{'comment': 'sagemaker', 'commenter': 'Tianqi-Dotes'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,258 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+    public DmsHook dmsHook;
+    /**
+     * Dms parameters
+     */
+    private DmsParameters parameters;
+    private DmsHook.ApplicationIds appId;
+
+    public DmsTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+    }
+
+    @Override
+    public void init() throws TaskException {
+        logger.info(""Dms task params {}"", taskExecutionContext.getTaskParams());
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DmsParameters.class);
+        initDmsHook();
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        exitStatusCode = checkCreateReplicationTask();
+        if (exitStatusCode == TaskConstants.EXIT_CODE_SUCCESS) {
+            exitStatusCode = startReplicationTask();
+        } else {
+            throw new TaskException(""DMS task failed to start"");","[{'comment': ""this else haven't start task yet"", 'commenter': 'Tianqi-Dotes'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,258 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+    public DmsHook dmsHook;
+    /**
+     * Dms parameters
+     */
+    private DmsParameters parameters;
+    private DmsHook.ApplicationIds appId;
+
+    public DmsTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+    }
+
+    @Override
+    public void init() throws TaskException {
+        logger.info(""Dms task params {}"", taskExecutionContext.getTaskParams());
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DmsParameters.class);
+        initDmsHook();
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        exitStatusCode = checkCreateReplicationTask();
+        if (exitStatusCode == TaskConstants.EXIT_CODE_SUCCESS) {
+            exitStatusCode = startReplicationTask();
+        } else {
+            throw new TaskException(""DMS task failed to start"");
+        }
+
+        // if the task is not running, the task will be deleted
+        if (exitStatusCode == TaskConstants.EXIT_CODE_FAILURE && !parameters.getIsRestartTask()) {
+            dmsHook.deleteReplicationTask();
+        }else {","[{'comment': 'format', 'commenter': 'Tianqi-Dotes'}]"
11868,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -0,0 +1,258 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.dms;
+
+import static com.fasterxml.jackson.databind.DeserializationFeature.ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT;
+import static com.fasterxml.jackson.databind.DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES;
+import static com.fasterxml.jackson.databind.DeserializationFeature.READ_UNKNOWN_ENUM_VALUES_AS_NULL;
+import static com.fasterxml.jackson.databind.MapperFeature.REQUIRE_SETTERS_FOR_GETTERS;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+import org.apache.dolphinscheduler.spi.utils.JSONUtils;
+import org.apache.dolphinscheduler.spi.utils.StringUtils;
+
+import org.apache.commons.beanutils.BeanUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import com.amazonaws.services.databasemigrationservice.model.InvalidResourceStateException;
+import com.amazonaws.services.databasemigrationservice.model.ReplicationTask;
+import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.PropertyNamingStrategy;
+
+public class DmsTask extends AbstractRemoteTask {
+
+    private static final ObjectMapper objectMapper =
+        new ObjectMapper().configure(FAIL_ON_UNKNOWN_PROPERTIES, false)
+            .configure(ACCEPT_EMPTY_ARRAY_AS_NULL_OBJECT, true)
+            .configure(READ_UNKNOWN_ENUM_VALUES_AS_NULL, true)
+            .configure(REQUIRE_SETTERS_FOR_GETTERS, true)
+            .setPropertyNamingStrategy(new PropertyNamingStrategy.UpperCamelCaseStrategy());
+    /**
+     * taskExecutionContext
+     */
+    private final TaskExecutionContext taskExecutionContext;
+    public DmsHook dmsHook;
+    /**
+     * Dms parameters
+     */
+    private DmsParameters parameters;
+    private DmsHook.ApplicationIds appId;
+
+    public DmsTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+        this.taskExecutionContext = taskExecutionContext;
+
+    }
+
+    @Override
+    public void init() throws TaskException {
+        logger.info(""Dms task params {}"", taskExecutionContext.getTaskParams());
+        parameters = JSONUtils.parseObject(taskExecutionContext.getTaskParams(), DmsParameters.class);
+        initDmsHook();
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        exitStatusCode = checkCreateReplicationTask();
+        if (exitStatusCode == TaskConstants.EXIT_CODE_SUCCESS) {
+            exitStatusCode = startReplicationTask();
+        } else {
+            throw new TaskException(""DMS task failed to start"");
+        }
+
+        // if the task is not running, the task will be deleted
+        if (exitStatusCode == TaskConstants.EXIT_CODE_FAILURE && !parameters.getIsRestartTask()) {
+            dmsHook.deleteReplicationTask();
+        }else {
+            appId = dmsHook.getApplicationIds();
+            setAppIds(JSONUtils.toJsonString(appId));
+        }
+    }
+
+    @Override
+    public void trackApplicationStatus() {
+        initAppId();
+        dmsHook.setReplicationTaskArn(appId.getReplicationTaskArn());
+        // if CdcStopPosition is not set, the task will not continue to check the running status
+        if (isStopTaskWhenCdc()) {
+            logger.info(""This is a cdc task and cdcStopPosition is not set, the task will not continue to check the running status"");
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+            return;
+        }
+
+        Boolean isFinishedSuccessfully = dmsHook.checkFinishedReplicationTask();
+        if (isFinishedSuccessfully) {
+            exitStatusCode = TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            throw new TaskException(""DMS task failed to track"");
+        }
+    }
+
+    /**
+     * init DMS remote AppId if null
+     */
+    private void initAppId() {
+        if (appId == null) {
+            if (StringUtils.isNotEmpty(getAppIds())) {
+                appId = JSONUtils.parseObject(getAppIds(), DmsHook.ApplicationIds.class);
+            }
+        }
+        if (appId == null) {
+            throw new TaskException(""sagemaker applicationID is null"");
+        }
+    }
+
+    public int checkCreateReplicationTask() throws TaskException {
+
+        // if IsRestartTask, return success, do not create replication task
+        if (parameters.getIsRestartTask()) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        }
+
+        // if not IsRestartTask, create replication task
+        Boolean isCreateSuccessfully;
+        try {
+            isCreateSuccessfully = dmsHook.createReplicationTask();
+        } catch (Exception e) {
+            throw new TaskException(""DMS task create replication task error"", e);
+        }
+
+        // if create replication task successfully, return EXIT_CODE_SUCCESS, else return EXIT_CODE_FAILURE
+        if (isCreateSuccessfully) {
+            return TaskConstants.EXIT_CODE_SUCCESS;
+        } else {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+    }
+
+    /**
+     * start replication task
+     *
+     * @return
+     * @throws TaskException
+     */
+    public int startReplicationTask() {
+
+        Boolean isStartSuccessfully = false;
+        try {
+            isStartSuccessfully = dmsHook.startReplicationTask();
+        } catch (InvalidResourceStateException e) {
+            logger.error(""Failed to start a task, error message: {}"", e.getErrorMessage());
+
+            // Only restart task when the error contains ""Test connection"", means instance can not connect to source or target
+            if (!e.getErrorMessage().contains(""Test connection"")) {
+                return TaskConstants.EXIT_CODE_FAILURE;
+            }
+
+            logger.info(""restart replication task"");
+            // if only restart task, run dmsHook.describeReplicationTasks to get replication task arn
+            if (parameters.getIsRestartTask()) {
+                dmsHook.describeReplicationTasks();
+            }
+
+            // test connection endpoint again and restart task if connection is ok
+            if (dmsHook.testConnectionEndpoint()) {
+                isStartSuccessfully = dmsHook.startReplicationTask();
+            }
+        }
+
+        // if start replication task failed, return EXIT_CODE_FAILURE
+        if (!isStartSuccessfully) {
+            return TaskConstants.EXIT_CODE_FAILURE;
+        }
+
+        return TaskConstants.EXIT_CODE_SUCCESS;
+    }
+
+    /**
+     * check if stop task when cdc
+     *
+     * @return true if stop task when cdc type and cdcStopPosition is not set, else return false
+     */
+    public Boolean isStopTaskWhenCdc() {
+        ReplicationTask replicationTask = dmsHook.describeReplicationTasks();
+        String migrationType = replicationTask.getMigrationType();
+        return migrationType.contains(""cdc"") && parameters.getCdcStopPosition() == null;
+    }
+
+    /**
+     * init dms hook
+     */
+    public void initDmsHook() throws TaskException {
+        convertJsonParameters();
+
+        dmsHook = new DmsHook();
+        try {
+            BeanUtils.copyProperties(dmsHook, parameters);
+        } catch (Exception e) {
+            throw new TaskException(""DMS task init error"", e);
+        }
+","[{'comment': 'format', 'commenter': 'Tianqi-Dotes'}]"
11868,docs/docs/en/guide/task/dms.md,"@@ -0,0 +1,107 @@
+# DMS Node
+
+## Overview
+
+[Pytorch](https://pytorch.org) is a mainstream Python machine learning library.","[{'comment': 'Why there is a link to `pytorch` here? Maybe we could remove it.', 'commenter': 'EricGao888'}, {'comment': 'done', 'commenter': 'jieguangzhou'}]"
11868,docs/docs/en/guide/task/dms.md,"@@ -0,0 +1,107 @@
+# DMS Node
+
+## Overview
+
+[Pytorch](https://pytorch.org) is a mainstream Python machine learning library.
+
+[AWS Database Migration Service (AWS DMS)](https://aws.amazon.com/cn/dms) helps you migrate databases to AWS quickly and securely. 
+The source database remains fully operational during the migration, minimizing downtime to applications that rely on the database. 
+The AWS Database Migration Service can migrate your data to and from the most widely used commercial and open-source databases.
+
+DMS task plugin can help users to create and start DMS tasks in DolphinScheduler more conveniently.
+
+Contains two features:
+- Create DMS task and start DMS task
+- Restart DMS task
+
+We can create DMS task and start DMS task in two ways:
+- Use interface
+- Use JSON data
+
+DolphinScheduler will track the status of the DMS task and set the status to successfully completed when the DMS task is completed. Except for the CDC task without end time.
+
+So, if the `migrationType` is `cdc` or `full-load-and-cdc`, `cdcStopPosition` not be set, DolphinScheduler will set the status to successfully after the DMS task starts successfully.
+
+## Create Task
+
+- Click `Project Management -> Project Name -> Workflow Definition`, and click the `Create Workflow` button to enter the DAG editing page.
+- Drag <img src=""../../../../img/tasks/icons/dms.png"" width=""15""/> from the toolbar to the canvas.
+
+## Task Example
+
+The task plugin picture is as follows
+
+**Create and start DMS task by interface**
+
+![dms](../../../../img/tasks/demo/dms_create_and_start.png)
+
+
+**Restart DMS task by interface**
+
+![dms](../../../../img/tasks/demo/dms_restart.png)
+
+
+**Create and start DMS task by JSON data**
+
+![dms](../../../../img/tasks/demo/dms_create_and_start_json.png)
+
+**Restart DMS task by JSON data**
+
+![dms](../../../../img/tasks/demo/dms_restart_json.png)
+
+
+
+### First, introduce some general parameters of DolphinScheduler","[{'comment': 'We have put those default parameters in a separate doc for better maintainability. See: https://github.com/apache/dolphinscheduler/pull/11776', 'commenter': 'EricGao888'}]"
11905,docs/docs/en/guide/task/mlflow.md,"@@ -13,19 +13,14 @@ MLflow task plugin used to execute MLflow tasks，Currently contains MLflow Proj
 
 The MLflow plugin currently supports and will support the following:
 
-- [x] MLflow Projects
-    - [x] BasicAlgorithm: contains LogisticRegression, svm, lightgbm, xgboost
-    - [x] AutoML: AutoML tool，contains autosklean, flaml
-    - [x] Custom projects: Support for running your own MLflow projects
-- [ ] MLflow Models
-    - [x] MLFLOW: Use `MLflow models serve` to deploy a model service
-    - [x] Docker: Run the container after packaging the docker image
-    - [x] Docker Compose: Use docker compose to run the container, it will replace the docker run above
-    - [ ] Seldon core: Use Selcon core to deploy model to k8s cluster
-    - [ ] k8s: Deploy containers directly to K8S
-    - [ ] MLflow deployments: Built-in deployment modules, such as built-in deployment to SageMaker, etc
-- [ ] Model Registry
-    - [ ] Register Model: Allows artifacts (Including model and related parameters, indicators) to be registered directly into the model center
+- MLflow Projects
+    - BasicAlgorithm: contains LogisticRegression, svm, lightgbm, xgboost
+    - AutoML: AutoML tool，contains autosklean, flaml","[{'comment': '```suggestion\r\n    - AutoML: AutoML tool, contains autosklean, flaml\r\n```', 'commenter': 'EricGao888'}, {'comment': ""I've fixed it"", 'commenter': 'jieguangzhou'}]"
11905,docs/docs/zh/guide/task/mlflow.md,"@@ -12,19 +12,14 @@ MLflow 组件用于执行 MLflow 任务，目前包含Mlflow Projects, 和MLflow
 
 目前 Mlflow 组件支持的和即将支持的内容如下中：
 
-- [x] MLflow Projects
-  - [x] BasicAlgorithm: 基础算法，包含LogisticRegression, svm, lightgbm, xgboost
-  - [x] AutoML: AutoML工具，包含autosklean, flaml
-  - [x] Custom projects: 支持运行自己的MLflow Projects项目
-- [ ] MLflow Models
-  - [x] MLFLOW: 直接使用 `mlflow models serve` 部署模型。
-  - [x] Docker: 打包 DOCKER 镜像后部署模型。
-  - [x] Docker Compose: 使用Docker Compose 部署模型，将会取代上面的Docker部署。
-  - [ ] Seldon core: 构建完镜像后，使用Seldon Core 部署到k8s集群上, 可以使用Seldon Core的生成模型管理能力。
-  - [ ] k8s: 构建完镜像后， 部署到k8s集群上。
-  - [ ] MLflow deployments: 内置的允许MLflow 部署模块, 如内置的部署到Sagemaker等。
-- [ ] Model Registry
-  - [ ] Register Model: 注册相关工件(模型以及相关的参数，指标)到模型中心
+- MLflow Projects
+  - BasicAlgorithm: 基础算法，包含LogisticRegression, svm, lightgbm, xgboost","[{'comment': '```suggestion\r\n  - BasicAlgorithm: 基础算法，包含LogisticRegression，svm，lightgbm，xgboost\r\n```', 'commenter': 'EricGao888'}]"
11905,docs/docs/zh/guide/task/mlflow.md,"@@ -12,19 +12,14 @@ MLflow 组件用于执行 MLflow 任务，目前包含Mlflow Projects, 和MLflow
 
 目前 Mlflow 组件支持的和即将支持的内容如下中：
 
-- [x] MLflow Projects
-  - [x] BasicAlgorithm: 基础算法，包含LogisticRegression, svm, lightgbm, xgboost
-  - [x] AutoML: AutoML工具，包含autosklean, flaml
-  - [x] Custom projects: 支持运行自己的MLflow Projects项目
-- [ ] MLflow Models
-  - [x] MLFLOW: 直接使用 `mlflow models serve` 部署模型。
-  - [x] Docker: 打包 DOCKER 镜像后部署模型。
-  - [x] Docker Compose: 使用Docker Compose 部署模型，将会取代上面的Docker部署。
-  - [ ] Seldon core: 构建完镜像后，使用Seldon Core 部署到k8s集群上, 可以使用Seldon Core的生成模型管理能力。
-  - [ ] k8s: 构建完镜像后， 部署到k8s集群上。
-  - [ ] MLflow deployments: 内置的允许MLflow 部署模块, 如内置的部署到Sagemaker等。
-- [ ] Model Registry
-  - [ ] Register Model: 注册相关工件(模型以及相关的参数，指标)到模型中心
+- MLflow Projects
+  - BasicAlgorithm: 基础算法，包含LogisticRegression, svm, lightgbm, xgboost
+  - AutoML: AutoML工具，包含autosklean, flaml","[{'comment': '```suggestion\r\n  - AutoML: AutoML工具，包含autosklean，flaml\r\n```', 'commenter': 'EricGao888'}]"
11912,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -226,359 +252,329 @@
                 Mockito.eq(project.getCode()))).thenReturn(pageListingResult);
 
         PageInfo<ProcessDefinition> pageInfo = processDefinitionService.queryProcessDefinitionListPaging(
-                loginUser, project.getCode(), """", """", 1, 0, 10);
+                user, project.getCode(), """", """", 1, 0, 10);
 
         Assert.assertNotNull(pageInfo);
     }
 
     @Test
     public void testQueryProcessDefinitionByCode() {
-        long projectCode = 1L;
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
 
         Project project = getProject(projectCode);
 
-        User loginUser = new User();
-        loginUser.setId(-1);
-        loginUser.setUserType(UserType.GENERAL_USER);
         Tenant tenant = new Tenant();
         tenant.setId(1);
         tenant.setTenantCode(""root"");
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
 
         // project check auth fail
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
-        Map<String, Object> map = processDefinitionService.queryProcessDefinitionByCode(loginUser, 1L, 1L);
+        Map<String, Object> map = processDefinitionService.queryProcessDefinitionByCode(user, 1L, 1L);
         Assert.assertEquals(Status.PROJECT_NOT_FOUND, map.get(Constants.STATUS));
 
         // project check auth success, instance not exist
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         DagData dagData = new DagData(getProcessDefinition(), null, null);
         Mockito.when(processService.genDagData(Mockito.any())).thenReturn(dagData);
 
         Map<String, Object> instanceNotexitRes =
-                processDefinitionService.queryProcessDefinitionByCode(loginUser, projectCode, 1L);
+                processDefinitionService.queryProcessDefinitionByCode(user, projectCode, 1L);
         Assert.assertEquals(Status.PROCESS_DEFINE_NOT_EXIST, instanceNotexitRes.get(Constants.STATUS));
 
         // instance exit
-        Mockito.when(processDefineMapper.queryByCode(46L)).thenReturn(getProcessDefinition());
+        Mockito.when(processDefinitionMapper.queryByCode(46L)).thenReturn(getProcessDefinition());
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         Mockito.when(tenantMapper.queryById(1)).thenReturn(tenant);
         Map<String, Object> successRes =
-                processDefinitionService.queryProcessDefinitionByCode(loginUser, projectCode, 46L);
+                processDefinitionService.queryProcessDefinitionByCode(user, projectCode, 46L);
         Assert.assertEquals(Status.SUCCESS, successRes.get(Constants.STATUS));
     }
 
     @Test
     public void testQueryProcessDefinitionByName() {
-        long projectCode = 1L;
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
 
         Project project = getProject(projectCode);
 
-        User loginUser = new User();
-        loginUser.setId(-1);
-        loginUser.setUserType(UserType.GENERAL_USER);
-
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
 
         // project check auth fail
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         Map<String, Object> map =
-                processDefinitionService.queryProcessDefinitionByName(loginUser, projectCode, ""test_def"");
+                processDefinitionService.queryProcessDefinitionByName(user, projectCode, ""test_def"");
         Assert.assertEquals(Status.PROJECT_NOT_FOUND, map.get(Constants.STATUS));
 
         // project check auth success, instance not exist
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
-        Mockito.when(processDefineMapper.queryByDefineName(project.getCode(), ""test_def"")).thenReturn(null);
+        Mockito.when(processDefinitionMapper.queryByDefineName(project.getCode(), ""test_def"")).thenReturn(null);
 
         Map<String, Object> instanceNotExitRes =
-                processDefinitionService.queryProcessDefinitionByName(loginUser, projectCode, ""test_def"");
+                processDefinitionService.queryProcessDefinitionByName(user, projectCode, ""test_def"");
         Assert.assertEquals(Status.PROCESS_DEFINE_NOT_EXIST, instanceNotExitRes.get(Constants.STATUS));
 
         // instance exit
-        Mockito.when(processDefineMapper.queryByDefineName(project.getCode(), ""test""))
+        Mockito.when(processDefinitionMapper.queryByDefineName(project.getCode(), ""test""))
                 .thenReturn(getProcessDefinition());
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         Map<String, Object> successRes =
-                processDefinitionService.queryProcessDefinitionByName(loginUser, projectCode, ""test"");
+                processDefinitionService.queryProcessDefinitionByName(user, projectCode, ""test"");
         Assert.assertEquals(Status.SUCCESS, successRes.get(Constants.STATUS));
     }
 
     @Test
     public void testBatchCopyProcessDefinition() {
-        long projectCode = 1L;
         Project project = getProject(projectCode);
-        User loginUser = new User();
-        loginUser.setId(1);
-        loginUser.setUserType(UserType.GENERAL_USER);
+
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_BATCH_COPY))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_BATCH_COPY))
                 .thenReturn(result);
 
         // copy project definition ids empty test
         Map<String, Object> map =
-                processDefinitionService.batchCopyProcessDefinition(loginUser, projectCode, StringUtils.EMPTY, 2L);
+                processDefinitionService.batchCopyProcessDefinition(user, projectCode, StringUtils.EMPTY, 2L);
         Assert.assertEquals(Status.PROCESS_DEFINITION_CODES_IS_EMPTY, map.get(Constants.STATUS));
 
         // project check auth fail
         putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_BATCH_COPY))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_BATCH_COPY))
                 .thenReturn(result);
         Map<String, Object> map1 = processDefinitionService.batchCopyProcessDefinition(
-                loginUser, projectCode, String.valueOf(project.getId()), 2L);
+                user, projectCode, String.valueOf(project.getId()), 2L);
         Assert.assertEquals(Status.PROJECT_NOT_FOUND, map1.get(Constants.STATUS));
 
         // project check auth success, target project name not equal project name, check auth target project fail
-        projectCode = 2L;
-        Project project1 = getProject(projectCode);
-        Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(project1);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_BATCH_COPY))
+        Project project1 = getProject(projectCodeOther);
+        Mockito.when(projectMapper.queryByCode(projectCodeOther)).thenReturn(project1);
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCodeOther, WORKFLOW_BATCH_COPY))
                 .thenReturn(result);
 
-        putMsg(result, Status.SUCCESS, projectCode);
+        putMsg(result, Status.SUCCESS, projectCodeOther);
         ProcessDefinition definition = getProcessDefinition();
         List<ProcessDefinition> processDefinitionList = new ArrayList<>();
         processDefinitionList.add(definition);
         Set<Long> definitionCodes =
                 Arrays.stream(""46"".split(Constants.COMMA)).map(Long::parseLong).collect(Collectors.toSet());
-        Mockito.when(processDefineMapper.queryByCodes(definitionCodes)).thenReturn(processDefinitionList);
-        Mockito.when(processService.saveProcessDefine(loginUser, definition, Boolean.TRUE, Boolean.TRUE)).thenReturn(2);
+        Mockito.when(processDefinitionMapper.queryByCodes(definitionCodes)).thenReturn(processDefinitionList);
+        Mockito.when(processService.saveProcessDefine(user, definition, Boolean.TRUE, Boolean.TRUE)).thenReturn(2);
         Map<String, Object> map3 = processDefinitionService.batchCopyProcessDefinition(
-                loginUser, projectCode, ""46"", 1L);
+                user, projectCodeOther, String.valueOf(processDefinitionCode), projectCode);
         Assert.assertEquals(Status.SUCCESS, map3.get(Constants.STATUS));
     }
 
     @Test
     public void testBatchMoveProcessDefinition() {
-        long projectCode = 1L;
         Project project1 = getProject(projectCode);
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(project1);
 
-        long projectCode2 = 2L;
-        Project project2 = getProject(projectCode2);
-        Mockito.when(projectMapper.queryByCode(projectCode2)).thenReturn(project2);
-
-        User loginUser = new User();
-        loginUser.setId(-1);
-        loginUser.setUserType(UserType.GENERAL_USER);
+        Project project2 = getProject(projectCodeOther);
+        Mockito.when(projectMapper.queryByCode(projectCodeOther)).thenReturn(project2);
 
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.SUCCESS, projectCode);
 
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project1, projectCode, TASK_DEFINITION_MOVE))
+        Mockito.when(projectService.checkProjectAndAuth(user, project1, projectCode, TASK_DEFINITION_MOVE))
                 .thenReturn(result);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project2, projectCode2, TASK_DEFINITION_MOVE))
+        Mockito.when(projectService.checkProjectAndAuth(user, project2, projectCodeOther, TASK_DEFINITION_MOVE))
                 .thenReturn(result);
 
         ProcessDefinition definition = getProcessDefinition();
         definition.setVersion(1);
         List<ProcessDefinition> processDefinitionList = new ArrayList<>();
         processDefinitionList.add(definition);
-        Set<Long> definitionCodes =
-                Arrays.stream(""46"".split(Constants.COMMA)).map(Long::parseLong).collect(Collectors.toSet());
-        Mockito.when(processDefineMapper.queryByCodes(definitionCodes)).thenReturn(processDefinitionList);
-        Mockito.when(processService.saveProcessDefine(loginUser, definition, Boolean.TRUE, Boolean.TRUE)).thenReturn(2);
-        Mockito.when(processTaskRelationMapper.queryByProcessCode(projectCode, 46L))
+        Set<Long> definitionCodes = Arrays.stream(String.valueOf(processDefinitionCode).split(Constants.COMMA))
+                .map(Long::parseLong).collect(Collectors.toSet());","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1271)"", 'commenter': 'github-advanced-security[bot]'}]"
11912,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -226,359 +252,321 @@
                 Mockito.eq(project.getCode()))).thenReturn(pageListingResult);
 
         PageInfo<ProcessDefinition> pageInfo = processDefinitionService.queryProcessDefinitionListPaging(
-                loginUser, project.getCode(), """", """", 1, 0, 10);
+                user, project.getCode(), """", """", 1, 0, 10);
 
         Assert.assertNotNull(pageInfo);
     }
 
     @Test
     public void testQueryProcessDefinitionByCode() {
-        long projectCode = 1L;
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
 
         Project project = getProject(projectCode);
 
-        User loginUser = new User();
-        loginUser.setId(-1);
-        loginUser.setUserType(UserType.GENERAL_USER);
         Tenant tenant = new Tenant();
         tenant.setId(1);
         tenant.setTenantCode(""root"");
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
 
         // project check auth fail
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
-        Map<String, Object> map = processDefinitionService.queryProcessDefinitionByCode(loginUser, 1L, 1L);
+        Map<String, Object> map = processDefinitionService.queryProcessDefinitionByCode(user, 1L, 1L);
         Assert.assertEquals(Status.PROJECT_NOT_FOUND, map.get(Constants.STATUS));
 
         // project check auth success, instance not exist
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         DagData dagData = new DagData(getProcessDefinition(), null, null);
         Mockito.when(processService.genDagData(Mockito.any())).thenReturn(dagData);
 
         Map<String, Object> instanceNotexitRes =
-                processDefinitionService.queryProcessDefinitionByCode(loginUser, projectCode, 1L);
+                processDefinitionService.queryProcessDefinitionByCode(user, projectCode, 1L);
         Assert.assertEquals(Status.PROCESS_DEFINE_NOT_EXIST, instanceNotexitRes.get(Constants.STATUS));
 
         // instance exit
-        Mockito.when(processDefineMapper.queryByCode(46L)).thenReturn(getProcessDefinition());
+        Mockito.when(processDefinitionMapper.queryByCode(46L)).thenReturn(getProcessDefinition());
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         Mockito.when(tenantMapper.queryById(1)).thenReturn(tenant);
         Map<String, Object> successRes =
-                processDefinitionService.queryProcessDefinitionByCode(loginUser, projectCode, 46L);
+                processDefinitionService.queryProcessDefinitionByCode(user, projectCode, 46L);
         Assert.assertEquals(Status.SUCCESS, successRes.get(Constants.STATUS));
     }
 
     @Test
     public void testQueryProcessDefinitionByName() {
-        long projectCode = 1L;
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
 
         Project project = getProject(projectCode);
 
-        User loginUser = new User();
-        loginUser.setId(-1);
-        loginUser.setUserType(UserType.GENERAL_USER);
-
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
 
         // project check auth fail
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         Map<String, Object> map =
-                processDefinitionService.queryProcessDefinitionByName(loginUser, projectCode, ""test_def"");
+                processDefinitionService.queryProcessDefinitionByName(user, projectCode, ""test_def"");
         Assert.assertEquals(Status.PROJECT_NOT_FOUND, map.get(Constants.STATUS));
 
         // project check auth success, instance not exist
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
-        Mockito.when(processDefineMapper.queryByDefineName(project.getCode(), ""test_def"")).thenReturn(null);
+        Mockito.when(processDefinitionMapper.queryByDefineName(project.getCode(), ""test_def"")).thenReturn(null);
 
         Map<String, Object> instanceNotExitRes =
-                processDefinitionService.queryProcessDefinitionByName(loginUser, projectCode, ""test_def"");
+                processDefinitionService.queryProcessDefinitionByName(user, projectCode, ""test_def"");
         Assert.assertEquals(Status.PROCESS_DEFINE_NOT_EXIST, instanceNotExitRes.get(Constants.STATUS));
 
         // instance exit
-        Mockito.when(processDefineMapper.queryByDefineName(project.getCode(), ""test""))
+        Mockito.when(processDefinitionMapper.queryByDefineName(project.getCode(), ""test""))
                 .thenReturn(getProcessDefinition());
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_DEFINITION))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_DEFINITION))
                 .thenReturn(result);
         Map<String, Object> successRes =
-                processDefinitionService.queryProcessDefinitionByName(loginUser, projectCode, ""test"");
+                processDefinitionService.queryProcessDefinitionByName(user, projectCode, ""test"");
         Assert.assertEquals(Status.SUCCESS, successRes.get(Constants.STATUS));
     }
 
     @Test
     public void testBatchCopyProcessDefinition() {
-        long projectCode = 1L;
         Project project = getProject(projectCode);
-        User loginUser = new User();
-        loginUser.setId(1);
-        loginUser.setUserType(UserType.GENERAL_USER);
+
         Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(getProject(projectCode));
         Map<String, Object> result = new HashMap<>();
         putMsg(result, Status.SUCCESS, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_BATCH_COPY))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_BATCH_COPY))
                 .thenReturn(result);
 
         // copy project definition ids empty test
         Map<String, Object> map =
-                processDefinitionService.batchCopyProcessDefinition(loginUser, projectCode, StringUtils.EMPTY, 2L);
+                processDefinitionService.batchCopyProcessDefinition(user, projectCode, StringUtils.EMPTY, 2L);
         Assert.assertEquals(Status.PROCESS_DEFINITION_CODES_IS_EMPTY, map.get(Constants.STATUS));
 
         // project check auth fail
         putMsg(result, Status.PROJECT_NOT_FOUND, projectCode);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_BATCH_COPY))
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCode, WORKFLOW_BATCH_COPY))
                 .thenReturn(result);
         Map<String, Object> map1 = processDefinitionService.batchCopyProcessDefinition(
-                loginUser, projectCode, String.valueOf(project.getId()), 2L);
+                user, projectCode, String.valueOf(project.getId()), 2L);
         Assert.assertEquals(Status.PROJECT_NOT_FOUND, map1.get(Constants.STATUS));
 
         // project check auth success, target project name not equal project name, check auth target project fail
-        projectCode = 2L;
-        Project project1 = getProject(projectCode);
-        Mockito.when(projectMapper.queryByCode(projectCode)).thenReturn(project1);
-        Mockito.when(projectService.checkProjectAndAuth(loginUser, project, projectCode, WORKFLOW_BATCH_COPY))
+        Project project1 = getProject(projectCodeOther);
+        Mockito.when(projectMapper.queryByCode(projectCodeOther)).thenReturn(project1);
+        Mockito.when(projectService.checkProjectAndAuth(user, project, projectCodeOther, WORKFLOW_BATCH_COPY))
                 .thenReturn(result);
 
-        putMsg(result, Status.SUCCESS, projectCode);
+        putMsg(result, Status.SUCCESS, projectCodeOther);
         ProcessDefinition definition = getProcessDefinition();
         List<ProcessDefinition> processDefinitionList = new ArrayList<>();
         processDefinitionList.add(definition);
         Set<Long> definitionCodes =
-                Arrays.stream(""46"".split(Constants.COMMA)).map(Long::parseLong).collect(Collectors.toSet());
-        Mockito.when(processDefineMapper.queryByCodes(definitionCodes)).thenReturn(processDefinitionList);
-        Mockito.when(processService.saveProcessDefine(loginUser, definition, Boolean.TRUE, Boolean.TRUE)).thenReturn(2);
+                Arrays.stream(String.valueOf(processDefinitionCode).split(Constants.COMMA)).map(Long::parseLong)","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1296)"", 'commenter': 'github-advanced-security[bot]'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ScheduleV2Controller.java,"@@ -0,0 +1,169 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_SCHEDULE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_SCHEDULE_BY_ID_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_SCHEDULE_LIST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_SCHEDULE_LIST_PAGING_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_SCHEDULE_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.PageResourceResponse;
+import org.apache.dolphinscheduler.api.dto.ResourceResponse;
+import org.apache.dolphinscheduler.api.dto.schedule.ScheduleCreateRequest;
+import org.apache.dolphinscheduler.api.dto.schedule.ScheduleFilterRequest;
+import org.apache.dolphinscheduler.api.dto.schedule.ScheduleUpdateRequest;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.service.SchedulerService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.Schedule;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import springfox.documentation.annotations.ApiIgnore;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.DeleteMapping;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+
+/**
+ * schedule controller
+ */
+@Api(tags = ""SCHEDULER_TAG"")
+@RestController
+@RequestMapping(""/v2/schedules"")
+public class ScheduleV2Controller extends BaseController {
+
+    @Autowired
+    private SchedulerService schedulerService;
+
+    @Autowired
+    private ProcessDefinitionService processDefinitionService;
+
+    /**
+     * Create resource schedule
+     *
+     * @param loginUser             login user
+     * @param scheduleCreateRequest the new schedule object will be created
+     * @return ResourceResponse object created
+     */
+    @ApiOperation(value = ""create"", notes = ""CREATE_SCHEDULE_NOTES"")
+    @PostMapping(consumes = {""application/json""})
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_SCHEDULE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse createSchedules(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @RequestBody ScheduleCreateRequest scheduleCreateRequest) {
+        Schedule schedule = schedulerService.createSchedulesV2(loginUser, scheduleCreateRequest);
+        return new ResourceResponse(schedule);
+    }
+
+    /**
+     * Delete schedule by id
+     *
+     * @param loginUser login user
+     * @param id        schedule object id
+     */
+    @ApiOperation(value = ""delete"", notes = ""DELETE_SCHEDULE_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""id"", value = ""SCHEDULE_ID"", dataTypeClass = long.class, example = ""123456"", required = true)
+    })
+    @DeleteMapping(value = ""/{id}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(DELETE_SCHEDULE_BY_ID_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result deleteSchedules(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                  @PathVariable(""id"") Integer id) {
+        schedulerService.deleteSchedulesById(loginUser, id);
+        return new Result(Status.SUCCESS);
+    }
+
+    /**
+     * Update resource schedule
+     *
+     * @param loginUser        login user
+     * @param id               schedule object id
+     * @param scheduleUpdateRequest the schedule object will be updated
+     * @return result Result
+     */
+    @ApiOperation(value = ""update"", notes = ""UPDATE_SCHEDULE_NOTES"")
+    @PutMapping(value = ""/{id}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_SCHEDULE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse updateSchedules(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @PathVariable(""id"") Integer id,
+                                            @RequestBody ScheduleUpdateRequest scheduleUpdateRequest) {
+        Schedule schedule = schedulerService.updateSchedulesV2(loginUser, id, scheduleUpdateRequest);
+        return new ResourceResponse(schedule);
+    }
+
+    /**
+     * Get resource schedule by id
+     *
+     * @param loginUser        login user
+     * @param id               schedule object id
+     * @return result Result
+     */
+    @ApiOperation(value = ""get"", notes = ""GET_SCHEDULE_BY_ID_NOTES"")
+    @GetMapping(value = ""/{id}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_SCHEDULE_LIST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse getSchedules(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                         @PathVariable(""id"") Integer id) {
+        Schedule schedule = schedulerService.getSchedules(loginUser, id);","[{'comment': '```suggestion\r\n        Schedule schedule = schedulerService.getSchedule(loginUser, id);\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'Or change into multi method.', 'commenter': 'caishunfeng'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/schedule/ScheduleCreateRequest.java,"@@ -0,0 +1,120 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.dto.schedule;
+
+import static org.apache.dolphinscheduler.common.utils.DateUtils.stringToDate;
+
+import org.apache.dolphinscheduler.common.enums.FailureStrategy;
+import org.apache.dolphinscheduler.common.enums.Priority;
+import org.apache.dolphinscheduler.common.enums.ReleaseState;
+import org.apache.dolphinscheduler.common.enums.WarningType;
+import org.apache.dolphinscheduler.dao.entity.Schedule;
+
+import java.util.Date;
+
+import lombok.Data;
+import io.swagger.annotations.ApiModelProperty;
+
+/**
+ * schedule create request
+ */
+@Data
+public class ScheduleCreateRequest {
+
+    @ApiModelProperty(example = ""1234567890123"", required = true)
+    private long processDefinitionCode;
+
+    @ApiModelProperty(example = ""schedule timezone"", required = true)
+    private String crontab;
+
+    @ApiModelProperty(example = ""2021-01-01 10:00:00"", required = true)
+    private String startTime;
+
+    @ApiModelProperty(example = ""2022-01-01 12:00:00"", required = true)
+    private String endTime;
+
+    @ApiModelProperty(example = ""Asia/Shanghai"", required = true)
+    private String timezoneId;
+
+    @ApiModelProperty(allowableValues = ""CONTINUE / END"", example = ""CONTINUE"", notes = ""default CONTINUE if value not provide."")
+    private String failureStrategy;
+
+    @ApiModelProperty(allowableValues = ""ONLINE / OFFLINE"", example = ""OFFLINE"", notes = ""default OFFLINE if value not provide."")
+    private String releaseState;
+
+    @ApiModelProperty(allowableValues = ""NONE / SUCCESS / FAILURE / ALL"", example = ""SUCCESS"", notes = ""default NONE if value not provide."")
+    private String warningType;
+
+    @ApiModelProperty(example = ""2"", notes = ""default 0 if value not provide."")
+    private int warningGroupId;
+
+    @ApiModelProperty(allowableValues = ""HIGHEST / HIGH / MEDIUM / LOW / LOWEST"", example = ""MEDIUM"", notes = ""default MEDIUM if value not provide."")
+    private String processInstancePriority;
+
+    @ApiModelProperty(example = ""worker-group-name"")
+    private String workerGroup;
+
+    @ApiModelProperty(example = ""environment-code"")
+    private long environmentCode;
+
+    public String getScheduleParam() {","[{'comment': 'Why not use json util?', 'commenter': 'caishunfeng'}, {'comment': ""It's better to create a pojo named ScheduleParam with this 4 fields."", 'commenter': 'ruanwenjun'}, {'comment': '> Why not use json util?\r\ncan you give some example about how to use it?', 'commenter': 'zhongjiajie'}, {'comment': '>It\'s better to create a pojo named ScheduleParam with this 4 fields.\r\n@ruanwenjun  I want keep parameter same leve, as it in table `t_ds_scheldule`. If we add pojo, we have to accept one parameter like \r\n\r\n```json\r\n{\r\n    ""releaseState"": ""Online"",\r\n    ""ScheduleParam"": ""{\'startTime\': startTime, \'endTime\': endTime, \'crontab\': contab}""\r\n}\r\n```\r\n\r\nbut we I want it is accept parame like \r\n\r\n```json\r\n{\r\n    ""releaseState"": ""Online"",\r\n    ""startTime"": ""startTime"",\r\n    ""endTime"": ""endTime"",\r\n    ""crontab"": ""contab""\r\n}\r\n```', 'commenter': 'zhongjiajie'}, {'comment': 'Oh I get your point, we can create pojo and then \r\n\r\n```java\r\nScheduleParam scheduleParam = new ScheduleParam(this.startTime, this.endTime, this.crontab, this.timezoneId);\r\nreturn scheduleParam.toString();\r\n```\r\n\r\nright?', 'commenter': 'zhongjiajie'}, {'comment': 'I currently use \r\n\r\n```java\r\nGson gson = new GsonBuilder().serializeNulls().create();\r\nScheduleParam scheduleParam = new ScheduleParam(this.startTime, this.endTime, this.crontab, this.timezoneId);\r\nreturn gson.toJson(scheduleParam);\r\n```\r\n\r\nto covert pojo into json string', 'commenter': 'zhongjiajie'}, {'comment': ""> I currently use\r\n> \r\n> ```java\r\n> Gson gson = new GsonBuilder().serializeNulls().create();\r\n> ScheduleParam scheduleParam = new ScheduleParam(this.startTime, this.endTime, this.crontab, this.timezoneId);\r\n> return gson.toJson(scheduleParam);\r\n> ```\r\n> \r\n> to covert pojo into json string\r\n\r\nI think it's OK, cc @ruanwenjun "", 'commenter': 'caishunfeng'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/schedule/ScheduleUpdateRequest.java,"@@ -0,0 +1,133 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.dto.schedule;
+
+import static org.apache.dolphinscheduler.common.Constants.YYYY_MM_DD_HH_MM_SS;
+import static org.apache.dolphinscheduler.common.utils.DateUtils.format;
+import static org.apache.dolphinscheduler.common.utils.DateUtils.stringToDate;
+
+import org.apache.dolphinscheduler.common.enums.FailureStrategy;
+import org.apache.dolphinscheduler.common.enums.Priority;
+import org.apache.dolphinscheduler.common.enums.ReleaseState;
+import org.apache.dolphinscheduler.common.enums.WarningType;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.Schedule;
+
+import java.util.Date;
+
+import lombok.Data;
+
+import com.fasterxml.jackson.annotation.JsonIgnoreProperties;
+import com.fasterxml.jackson.annotation.JsonInclude;
+import io.swagger.annotations.ApiModelProperty;
+
+/**
+ * schedule update request
+ */
+@JsonIgnoreProperties(ignoreUnknown = true)
+@JsonInclude(JsonInclude.Include.NON_NULL)
+@Data
+public class ScheduleUpdateRequest {
+
+    @ApiModelProperty(example = ""schedule timezone"", required = true)
+    private String crontab;
+
+    @ApiModelProperty(example = ""2021-01-01 10:00:00"", required = true)
+    private String startTime;
+
+    @ApiModelProperty(example = ""2022-01-01 12:00:00"", required = true)
+    private String endTime;
+
+    @ApiModelProperty(example = ""Asia/Shanghai"", required = true)
+    private String timezoneId;
+
+    @ApiModelProperty(allowableValues = ""CONTINUE / END"", example = ""CONTINUE"", notes = ""default CONTINUE if value not provide."")
+    private String failureStrategy;
+
+    @ApiModelProperty(allowableValues = ""ONLINE / OFFLINE"", example = ""OFFLINE"", notes = ""default OFFLINE if value not provide."")
+    private String releaseState;
+
+    @ApiModelProperty(allowableValues = ""NONE / SUCCESS / FAILURE / ALL"", example = ""SUCCESS"", notes = ""default NONE if value not provide."")
+    private String warningType;
+
+    @ApiModelProperty(example = ""2"", notes = ""default 0 if value not provide."")
+    private int warningGroupId;
+
+    @ApiModelProperty(allowableValues = ""HIGHEST / HIGH / MEDIUM / LOW / LOWEST"", example = ""MEDIUM"", notes = ""default MEDIUM if value not provide."")
+    private String processInstancePriority;
+
+    @ApiModelProperty(example = ""worker-group-name"")
+    private String workerGroup;
+
+    @ApiModelProperty(example = ""environment-code"")
+    private long environmentCode;
+
+    public String updateScheduleParam(Schedule schedule) {
+        Schedule scheduleUpdate = this.mergeIntoSchedule(schedule);
+        return ""{\""startTime\"":\"""" +
+                format(scheduleUpdate.getStartTime(), YYYY_MM_DD_HH_MM_SS, schedule.getTimezoneId()) +
+                ""\"",\""endTime\"":\"""" +
+                format(scheduleUpdate.getEndTime(), YYYY_MM_DD_HH_MM_SS, schedule.getTimezoneId()) +
+                ""\"",\""crontab\"":\"""" +
+                scheduleUpdate.getCrontab() +
+                ""\"",\""timezoneId\"":\"""" +
+                scheduleUpdate.getTimezoneId() +
+                ""\""}"";
+    }
+
+    public Schedule mergeIntoSchedule(Schedule schedule) {
+        Schedule scheduleDeepCopy = JSONUtils.parseObject(JSONUtils.toJsonString(schedule), Schedule.class);","[{'comment': 'use BeanUtils.cloneBean', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'zhongjiajie'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -67,6 +70,15 @@ Map<String, Object> createProcessDefinition(User loginUser,
                                                 String otherParamsJson,
                                                 ProcessExecutionTypeEnum executionType);
 
+    /**
+     * create process definition V2
+     *
+     * @param loginUser login user
+     * @param workflowCreateRequest the new workflow object will be created
+     * @return New ProcessDefinition object created just now
+     */
+    ProcessDefinition createProcessDefinitionV2(User loginUser, WorkflowCreateRequest workflowCreateRequest);","[{'comment': ""What's the different between v1 and v2? Maybe v2 it's not a good guide for developers if v1 can not be replaced with v2. "", 'commenter': 'caishunfeng'}, {'comment': 'v1 is for currently API(operate workflow and task and task relation object), and V2 is only operate workflow object. V2 is mainly for RESTful api, which we only change one single object instand of too many object', 'commenter': 'zhongjiajie'}, {'comment': 'Will we use v2 uniformly in the future? including UI or support restful api or pyds?', 'commenter': 'caishunfeng'}, {'comment': 'I hope we can do that, and in that moment, maybe it it the best time to migrate python api into separate repository', 'commenter': 'zhongjiajie'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkflowV2Controller.java,"@@ -0,0 +1,168 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_PROCESS_DEFINITION_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_PROCESS_DEFINE_BY_CODE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_PROCESS_DEFINITION_LIST;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_PROCESS_DEFINITION_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.PageResourceResponse;
+import org.apache.dolphinscheduler.api.dto.ResourceResponse;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowCreateRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowFilterRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowUpdateRequest;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import springfox.documentation.annotations.ApiIgnore;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.DeleteMapping;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+
+/**
+ * workflow controller
+ */
+@Api(tags = ""WORKFLOW_TAG"")
+@RestController
+@RequestMapping(""/v2/workflows"")
+public class WorkflowV2Controller extends BaseController {
+
+    @Autowired
+    private ProcessDefinitionService processDefinitionService;
+
+    /**
+     * Create resource workflow
+     *
+     * @param loginUser             login user
+     * @param workflowCreateRequest the new workflow object will be created
+     * @return ResourceResponse object created
+     */
+    @ApiOperation(value = ""create"", notes = ""CREATE_WORKFLOWS_NOTES"")
+    @PostMapping(consumes = {""application/json""})
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse createWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,","[{'comment': '```suggestion\r\n    public Result<ProcessDefinition> createWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\r\n```', 'commenter': 'ruanwenjun'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkflowV2Controller.java,"@@ -0,0 +1,168 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_PROCESS_DEFINITION_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_PROCESS_DEFINE_BY_CODE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_PROCESS_DEFINITION_LIST;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_PROCESS_DEFINITION_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.PageResourceResponse;
+import org.apache.dolphinscheduler.api.dto.ResourceResponse;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowCreateRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowFilterRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowUpdateRequest;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import springfox.documentation.annotations.ApiIgnore;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.DeleteMapping;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+
+/**
+ * workflow controller
+ */
+@Api(tags = ""WORKFLOW_TAG"")
+@RestController
+@RequestMapping(""/v2/workflows"")
+public class WorkflowV2Controller extends BaseController {
+
+    @Autowired
+    private ProcessDefinitionService processDefinitionService;
+
+    /**
+     * Create resource workflow
+     *
+     * @param loginUser             login user
+     * @param workflowCreateRequest the new workflow object will be created
+     * @return ResourceResponse object created
+     */
+    @ApiOperation(value = ""create"", notes = ""CREATE_WORKFLOWS_NOTES"")
+    @PostMapping(consumes = {""application/json""})
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse createWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @RequestBody WorkflowCreateRequest workflowCreateRequest) {
+        ProcessDefinition processDefinition =
+                processDefinitionService.createProcessDefinitionV2(loginUser, workflowCreateRequest);
+        return new ResourceResponse(processDefinition);
+    }
+
+    /**
+     * Delete workflow by code
+     *
+     * @param loginUser login user
+     * @param code      process definition code
+     * @return Result result object delete
+     */
+    @ApiOperation(value = ""delete"", notes = ""DELETE_WORKFLOWS_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""code"", value = ""WORKFLOW_CODE"", dataTypeClass = long.class, example = ""123456"", required = true)
+    })
+    @DeleteMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(DELETE_PROCESS_DEFINE_BY_CODE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result deleteWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                  @PathVariable(""code"") Long code) {
+        processDefinitionService.deleteProcessDefinitionByCode(loginUser, code);
+        return new Result(Status.SUCCESS);
+    }
+
+    /**
+     * Update resource workflow
+     *
+     * @param loginUser        login user
+     * @param code             workflow resource code you want to update
+     * @param workflowUpdateRequest workflowUpdateRequest
+     * @return ResourceResponse object updated
+     */
+    @ApiOperation(value = ""update"", notes = ""UPDATE_WORKFLOWS_NOTES"")
+    @PutMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse updateWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,","[{'comment': '```suggestion\r\n    public Result<ProcessDefinition> updateWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\r\n```', 'commenter': 'ruanwenjun'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkflowV2Controller.java,"@@ -0,0 +1,168 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_PROCESS_DEFINITION_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_PROCESS_DEFINE_BY_CODE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_PROCESS_DEFINITION_LIST;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_PROCESS_DEFINITION_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.PageResourceResponse;
+import org.apache.dolphinscheduler.api.dto.ResourceResponse;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowCreateRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowFilterRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowUpdateRequest;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import springfox.documentation.annotations.ApiIgnore;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.DeleteMapping;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+
+/**
+ * workflow controller
+ */
+@Api(tags = ""WORKFLOW_TAG"")
+@RestController
+@RequestMapping(""/v2/workflows"")
+public class WorkflowV2Controller extends BaseController {
+
+    @Autowired
+    private ProcessDefinitionService processDefinitionService;
+
+    /**
+     * Create resource workflow
+     *
+     * @param loginUser             login user
+     * @param workflowCreateRequest the new workflow object will be created
+     * @return ResourceResponse object created
+     */
+    @ApiOperation(value = ""create"", notes = ""CREATE_WORKFLOWS_NOTES"")
+    @PostMapping(consumes = {""application/json""})
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse createWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @RequestBody WorkflowCreateRequest workflowCreateRequest) {
+        ProcessDefinition processDefinition =
+                processDefinitionService.createProcessDefinitionV2(loginUser, workflowCreateRequest);
+        return new ResourceResponse(processDefinition);
+    }
+
+    /**
+     * Delete workflow by code
+     *
+     * @param loginUser login user
+     * @param code      process definition code
+     * @return Result result object delete
+     */
+    @ApiOperation(value = ""delete"", notes = ""DELETE_WORKFLOWS_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""code"", value = ""WORKFLOW_CODE"", dataTypeClass = long.class, example = ""123456"", required = true)
+    })
+    @DeleteMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(DELETE_PROCESS_DEFINE_BY_CODE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result deleteWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                  @PathVariable(""code"") Long code) {
+        processDefinitionService.deleteProcessDefinitionByCode(loginUser, code);
+        return new Result(Status.SUCCESS);
+    }
+
+    /**
+     * Update resource workflow
+     *
+     * @param loginUser        login user
+     * @param code             workflow resource code you want to update
+     * @param workflowUpdateRequest workflowUpdateRequest
+     * @return ResourceResponse object updated
+     */
+    @ApiOperation(value = ""update"", notes = ""UPDATE_WORKFLOWS_NOTES"")
+    @PutMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse updateWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @PathVariable(""code"") Long code,
+                                            @RequestBody WorkflowUpdateRequest workflowUpdateRequest) {
+        ProcessDefinition processDefinition =
+                processDefinitionService.updateProcessDefinitionV2(loginUser, code, workflowUpdateRequest);
+        return new ResourceResponse(processDefinition);
+    }
+
+    /**
+     * Get resource workflow
+     *
+     * @param loginUser        login user
+     * @param code             workflow resource code you want to update
+     * @return ResourceResponse object get from condition
+     */
+    @ApiOperation(value = ""get"", notes = ""GET_WORKFLOWS_NOTES"")
+    @GetMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_PROCESS_DEFINITION_LIST)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse getWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,","[{'comment': '```suggestion\r\n    public Result<ProcessDefinition> getWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'zhongjiajie'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/WorkflowV2Controller.java,"@@ -0,0 +1,168 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_PROCESS_DEFINITION_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_PROCESS_DEFINE_BY_CODE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_PROCESS_DEFINITION_LIST;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_PROCESS_DEFINITION_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.PageResourceResponse;
+import org.apache.dolphinscheduler.api.dto.ResourceResponse;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowCreateRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowFilterRequest;
+import org.apache.dolphinscheduler.api.dto.workflow.WorkflowUpdateRequest;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.ProcessDefinitionService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.Constants;
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import springfox.documentation.annotations.ApiIgnore;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.DeleteMapping;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.annotations.Api;
+import io.swagger.annotations.ApiImplicitParam;
+import io.swagger.annotations.ApiImplicitParams;
+import io.swagger.annotations.ApiOperation;
+
+/**
+ * workflow controller
+ */
+@Api(tags = ""WORKFLOW_TAG"")
+@RestController
+@RequestMapping(""/v2/workflows"")
+public class WorkflowV2Controller extends BaseController {
+
+    @Autowired
+    private ProcessDefinitionService processDefinitionService;
+
+    /**
+     * Create resource workflow
+     *
+     * @param loginUser             login user
+     * @param workflowCreateRequest the new workflow object will be created
+     * @return ResourceResponse object created
+     */
+    @ApiOperation(value = ""create"", notes = ""CREATE_WORKFLOWS_NOTES"")
+    @PostMapping(consumes = {""application/json""})
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse createWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @RequestBody WorkflowCreateRequest workflowCreateRequest) {
+        ProcessDefinition processDefinition =
+                processDefinitionService.createProcessDefinitionV2(loginUser, workflowCreateRequest);
+        return new ResourceResponse(processDefinition);
+    }
+
+    /**
+     * Delete workflow by code
+     *
+     * @param loginUser login user
+     * @param code      process definition code
+     * @return Result result object delete
+     */
+    @ApiOperation(value = ""delete"", notes = ""DELETE_WORKFLOWS_NOTES"")
+    @ApiImplicitParams({
+            @ApiImplicitParam(name = ""code"", value = ""WORKFLOW_CODE"", dataTypeClass = long.class, example = ""123456"", required = true)
+    })
+    @DeleteMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(DELETE_PROCESS_DEFINE_BY_CODE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result deleteWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                  @PathVariable(""code"") Long code) {
+        processDefinitionService.deleteProcessDefinitionByCode(loginUser, code);
+        return new Result(Status.SUCCESS);
+    }
+
+    /**
+     * Update resource workflow
+     *
+     * @param loginUser        login user
+     * @param code             workflow resource code you want to update
+     * @param workflowUpdateRequest workflowUpdateRequest
+     * @return ResourceResponse object updated
+     */
+    @ApiOperation(value = ""update"", notes = ""UPDATE_WORKFLOWS_NOTES"")
+    @PutMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_PROCESS_DEFINITION_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse updateWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                            @PathVariable(""code"") Long code,
+                                            @RequestBody WorkflowUpdateRequest workflowUpdateRequest) {
+        ProcessDefinition processDefinition =
+                processDefinitionService.updateProcessDefinitionV2(loginUser, code, workflowUpdateRequest);
+        return new ResourceResponse(processDefinition);
+    }
+
+    /**
+     * Get resource workflow
+     *
+     * @param loginUser        login user
+     * @param code             workflow resource code you want to update
+     * @return ResourceResponse object get from condition
+     */
+    @ApiOperation(value = ""get"", notes = ""GET_WORKFLOWS_NOTES"")
+    @GetMapping(value = ""/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_PROCESS_DEFINITION_LIST)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public ResourceResponse getWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                         @PathVariable(""code"") Long code) {
+        ProcessDefinition processDefinition = processDefinitionService.getProcessDefinition(loginUser, code);
+        return new ResourceResponse(processDefinition);
+    }
+
+    /**
+     * Get resource workflows according to query parameter
+     *
+     * @param loginUser        login user
+     * @param workflowFilterRequest workflowFilterRequest
+     * @return PageResourceResponse from condition
+     */
+    @ApiOperation(value = ""get"", notes = ""FILTER_WORKFLOWS_NOTES"")
+    @GetMapping(consumes = {""application/json""})
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_PROCESS_DEFINITION_LIST)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public PageResourceResponse filterWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,","[{'comment': '```suggestion\r\n    public Result<PageInfo<ProcessDefinition>> filterWorkflows(@ApiIgnore @RequestAttribute(value = Constants.SESSION_USER) User loginUser,\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'zhongjiajie'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/ResourceResponse.java,"@@ -0,0 +1,39 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.dto;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.utils.Result;
+
+import lombok.Data;
+
+/**
+ * workflow response
+ */
+@Data
+public class ResourceResponse<T> extends Result<T> {","[{'comment': 'It seems this pojo is same with Result.', 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'zhongjiajie'}]"
11912,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/SchedulerServiceImpl.java,"@@ -270,6 +350,61 @@ public Map<String, Object> updateSchedule(User loginUser,
         return result;
     }
 
+    /**
+     * update schedule object V2
+     *
+     * @param loginUser login user
+     * @param scheduleId scheduler id
+     * @param scheduleUpdateRequest the schedule object will be updated
+     * @return Schedule object
+     */
+    @Override
+    @Transactional
+    public Schedule updateSchedulesV2(User loginUser,
+                                      Integer scheduleId,
+                                      ScheduleUpdateRequest scheduleUpdateRequest) {
+        Schedule schedule = scheduleMapper.selectById(scheduleId);
+        if (schedule == null) {
+            throw new ServiceException(Status.SCHEDULE_NOT_EXISTS, scheduleId);
+        }
+        Schedule scheduleUpdate = scheduleUpdateRequest.mergeIntoSchedule(schedule);
+
+        // check update params
+        this.projectPermCheckByProcess(loginUser, scheduleUpdate.getProcessDefinitionCode());
+        this.scheduleParamCheck(scheduleUpdateRequest.updateScheduleParam(scheduleUpdate));
+        if (scheduleUpdate.getEnvironmentCode() != null) {
+            Environment environment = environmentMapper.queryByEnvironmentCode(scheduleUpdate.getEnvironmentCode());
+            if (environment == null) {
+                throw new ServiceException(Status.QUERY_ENVIRONMENT_BY_CODE_ERROR, scheduleUpdate.getEnvironmentCode());
+            }
+        }
+
+        int update = scheduleMapper.updateById(scheduleUpdate);
+        if (update <= 0) {
+            throw new ServiceException(Status.UPDATE_SCHEDULE_ERROR);
+        }
+        return scheduleUpdate;
+    }
+
+    /**
+     * get schedule object
+     *
+     * @param loginUser login user
+     * @param scheduleId scheduler id
+     * @return Schedule object
+     */
+    @Override
+    @Transactional
+    public Schedule getSchedules(User loginUser,","[{'comment': '->getSchedule', 'commenter': 'Tianqi-Dotes'}, {'comment': 'done', 'commenter': 'zhongjiajie'}]"
11929,dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/mapper/CommandMapperTest.java,"@@ -179,6 +182,14 @@ public void testQueryCommandPageBySlot() {
         toTestQueryCommandPageBySlot(masterCount, thisMasterSlot);
     }
 
+    @Test
+    public void testClone() throws Exception {
+        Command command1 = createCommand();
+        Command command2 = createCommand();
+        Command cloneBean = (Command) BeanUtils.cloneBean(command1);
+        Assert.assertEquals(cloneBean.getId(), command1.getId());
+    }","[{'comment': ""This is pointless, you are testing a third-party method, this is not our responsibility, instead, you should add a test case that verifies `createComplementDependentCommand` doesn't copy the id to the new dependent command"", 'commenter': 'kezhenxu94'}, {'comment': 'Okay, I will modify it.', 'commenter': 'stalary'}]"
11929,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -903,7 +903,8 @@ protected int createComplementDependentCommand(List<Schedule> schedules, Command
         List<DependentProcessDefinition> dependentProcessDefinitionList =
                 getComplementDependentDefinitionList(dependentCommand.getProcessDefinitionCode(),
                         CronUtils.getMaxCycle(schedules.get(0).getCrontab()), dependentCommand.getWorkerGroup());
-
+        // If the id is Integer, the auto-increment id will be obtained and cloned, causing duplicate writes","[{'comment': 'How did you get this conclusion? From the documentation of `BeanUtils.cloneBean`, it copies all fields regardless of its type', 'commenter': 'kezhenxu94'}, {'comment': 'Before using int, mybtais-plus did not fill in the id field, it default use 0, but after being changed to Integer, it will fill it for auto-increment id.', 'commenter': 'stalary'}, {'comment': '> Before using int, mybtais-plus did not fill in the id field, it default use 0, but after being changed to Integer, it will fill it for auto-increment id.\r\n\r\nOK I see, this is a really strange behavior for mybatis-plus...', 'commenter': 'kezhenxu94'}]"
12051,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/task/CommonTaskProcessor.java,"@@ -126,6 +133,14 @@ public boolean dispatchTask() {
                 return false;
             }
 
+            // check in advance to avoid invalid infinite loops in TaskPriorityQueueConsumer
+            if (CollectionUtils.isEmpty(serverNodeManager.getWorkerGroupNodes(taskExecutionContext.getWorkerGroup()))) {","[{'comment': ""We cannot make this change easily, the workgroup may loss in some cases, and recovery automically.\r\n\r\nAnd this is not safe, the workflow may exist in the processor but loss in dispatch part.\r\n\r\nBTY, it's not suggested to do this validation master, we need to do the validation in api-side."", 'commenter': 'ruanwenjun'}, {'comment': ""> We cannot make this change easily, the workgroup may loss in some cases, and recovery automically.\r\n> \r\n> And this is not safe, the workflow may exist in the processor but loss in dispatch part.\r\n> \r\n> BTY, it's not suggested to do this validation master, we need to do the validation in api-side.\r\n\r\nbut if ds want to worker group recovery automically, we also should not add this validation in api-side,just keep loop waiting. WDYT @ruanwenjun "", 'commenter': 'DarkAssassinator'}, {'comment': ""Add validation in API-Side can stop the process in workflow creation. In fact, we have this check in front-end, but in api-side, we don't validate the workgroup."", 'commenter': 'ruanwenjun'}, {'comment': ""> Add validation in API-Side can stop the process in workflow creation. In fact, we have this check in front-end, but in api-side, we don't validate the workgroup.\r\n\r\nu are correct, i add a validator in api side and remove it in master side"", 'commenter': 'DarkAssassinator'}]"
12051,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -306,11 +311,64 @@ public Map<String, Object> checkProcessDefinitionValid(long projectCode, Process
             logger.warn(""Subprocess definition of process definition is not {}, processDefinitionCode:{}."", ReleaseState.ONLINE.getDescp(), processDefineCode);
             putMsg(result, Status.SUB_PROCESS_DEFINE_NOT_RELEASE);
         } else {
-            result.put(Constants.STATUS, Status.SUCCESS);
+            List<String> workerGroupNames = workerGroupService.getAllWorkerGroupNames();
+            return checkWorkerGroupNameExists(processDefinition, workerGroupNames);
         }
         return result;
     }
 
+    /**
+     * check whether worker group is available
+     *
+     * @param processDefinition process definition
+     * @param workerGroupNames worker group name list
+     * @return check result
+     */
+    public Map<String, Object> checkWorkerGroupNameExists(ProcessDefinition processDefinition,
+        List<String> workerGroupNames) {
+        Map<String, Object> result = new HashMap<>();
+        // get all task definitions in this process definition
+        List<ProcessTaskRelation> processTaskRelations = processService
+            .findRelationByCode(processDefinition.getCode(), processDefinition.getVersion());
+        List<TaskDefinitionLog> taskDefinitionLogList = processService
+            .genTaskDefineList(processTaskRelations);
+        List<TaskDefinition> taskDefinitions = taskDefinitionLogList.stream()
+            .map(t -> (TaskDefinition) t).collect(
+                Collectors.toList());
+
+        for (TaskDefinition taskDefinition : taskDefinitions) {
+            if (!workerGroupNames.contains(taskDefinition.getWorkerGroup())) {
+                logger.error(""Cannot find worker group {} configured on task definition named {} "",
+                    taskDefinition.getWorkerGroup(), taskDefinition.getName());
+                putMsg(result, Status.WORKER_GROUP_NOT_EXISTS, taskDefinition.getName(),
+                    taskDefinition.getWorkerGroup());
+                return result;
+            }
+
+            if (TaskConstants.TASK_TYPE_SUB_PROCESS
+                .equalsIgnoreCase(taskDefinition.getTaskType())) {
+                long subProcessCode = Long
+                    .parseLong(JSONUtils.getNodeString(taskDefinition.getTaskParams(),
+                        Constants.CMD_PARAM_SUB_PROCESS_DEFINE_CODE));
+
+                ProcessDefinition subProcessDefinition = processDefinitionMapper
+                    .queryByCode(subProcessCode);
+                if (subProcessDefinition == null) {
+                    putMsg(result, Status.PROCESS_DEFINE_NOT_EXIST, String.valueOf(subProcessCode));
+                    return result;
+                }
+                // check all sub process recursively
+                Map<String, Object> subResult = checkWorkerGroupNameExists(subProcessDefinition,","[{'comment': 'I am not sure if this will exist a cycle here.', 'commenter': 'ruanwenjun'}, {'comment': '> I am not sure if this will exist a cycle here.\r\n\r\nbecause workflow is a DAG, so this change like a DFS, as i think it will not exist a cycle', 'commenter': 'DarkAssassinator'}]"
12051,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -314,11 +319,64 @@
                     ReleaseState.ONLINE.getDescp(), processDefineCode);
             putMsg(result, Status.SUB_PROCESS_DEFINE_NOT_RELEASE);
         } else {
-            result.put(Constants.STATUS, Status.SUCCESS);
+            List<String> workerGroupNames = workerGroupService.getAllWorkerGroupNames();
+            return checkWorkerGroupNameExists(processDefinition, workerGroupNames);
         }
         return result;
     }
 
+    /**
+     * check whether worker group is available
+     *
+     * @param processDefinition process definition
+     * @param workerGroupNames worker group name list
+     * @return check result
+     */
+    public Map<String, Object> checkWorkerGroupNameExists(ProcessDefinition processDefinition,
+        List<String> workerGroupNames) {
+        Map<String, Object> result = new HashMap<>();
+        // get all task definitions in this process definition
+        List<ProcessTaskRelation> processTaskRelations = processService
+            .findRelationByCode(processDefinition.getCode(), processDefinition.getVersion());
+        List<TaskDefinitionLog> taskDefinitionLogList = processService
+            .genTaskDefineList(processTaskRelations);
+        List<TaskDefinition> taskDefinitions = taskDefinitionLogList.stream()
+            .map(t -> (TaskDefinition) t).collect(
+                Collectors.toList());
+
+        for (TaskDefinition taskDefinition : taskDefinitions) {
+            if (!workerGroupNames.contains(taskDefinition.getWorkerGroup())) {
+                logger.error(""Cannot find worker group {} configured on task definition named {} "",
+                    taskDefinition.getWorkerGroup(), taskDefinition.getName());
+                putMsg(result, Status.WORKER_GROUP_NOT_EXISTS, taskDefinition.getName(),
+                    taskDefinition.getWorkerGroup());
+                return result;
+            }
+
+            if (TaskConstants.TASK_TYPE_SUB_PROCESS
+                .equalsIgnoreCase(taskDefinition.getTaskType())) {
+                long subProcessCode = Long
+                    .parseLong(JSONUtils.getNodeString(taskDefinition.getTaskParams(),
+                        Constants.CMD_PARAM_SUB_PROCESS_DEFINE_CODE));","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1539)"", 'commenter': 'github-advanced-security[bot]'}]"
12051,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -329,37 +371,37 @@
     public boolean checkSubProcessDefinitionValid(ProcessDefinition processDefinition) {
         // query all subprocesses under the current process
         List<ProcessTaskRelation> processTaskRelations =
-                processTaskRelationMapper.queryDownstreamByProcessDefinitionCode(processDefinition.getCode());
+            processTaskRelationMapper.queryDownstreamByProcessDefinitionCode(processDefinition.getCode());
         if (processTaskRelations.isEmpty()) {
             return true;
         }
         Set<Long> relationCodes =
-                processTaskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toSet());
+            processTaskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toSet());
         List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(relationCodes);
 
         // find out the process definition code
         Set<Long> processDefinitionCodeSet = new HashSet<>();
         taskDefinitions.stream()
-                .filter(task -> TaskConstants.TASK_TYPE_SUB_PROCESS.equalsIgnoreCase(task.getTaskType())).forEach(
-                        taskDefinition -> processDefinitionCodeSet.add(Long.valueOf(
-                                JSONUtils.getNodeString(taskDefinition.getTaskParams(),
-                                        Constants.CMD_PARAM_SUB_PROCESS_DEFINE_CODE))));
+            .filter(task -> TaskConstants.TASK_TYPE_SUB_PROCESS.equalsIgnoreCase(task.getTaskType())).forEach(
+            taskDefinition -> processDefinitionCodeSet.add(Long.valueOf(
+                JSONUtils.getNodeString(taskDefinition.getTaskParams(),
+                    Constants.CMD_PARAM_SUB_PROCESS_DEFINE_CODE))));","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1542)"", 'commenter': 'github-advanced-security[bot]'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -255,6 +255,15 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 resultJSONArray.add(mapOfColValues);
                 rowCount++;
             }
+            // result is null,output table metadata
+            if (resultJSONArray.isEmpty()) {","[{'comment': '1. int num = md.getColumnCount(); 如果num为零，怎么办？\r\n2. 如果resultJSONArray的数据里全是填充的， 267行的代码就没有意义了\r\n\r\n', 'commenter': 'githublaohu'}, {'comment': '\r\nHi @githublaohu please use the English comments, which can make more developers understand, thanks.', 'commenter': 'caishunfeng'}, {'comment': ' if (resultSet != null)  。resultSet等于null，那么邮件就不发了。是否应该把发邮件的逻辑移出去或则发送一个异常邮件。', 'commenter': 'githublaohu'}, {'comment': 'If num=0, it is impossible. This ""num"" represents the number of fields. The query result cannot be without fields', 'commenter': 'fengjian1129'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -255,6 +255,15 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 resultJSONArray.add(mapOfColValues);
                 rowCount++;
             }
+            // result is null,output table metadata
+            if (resultJSONArray.isEmpty()) {
+                ObjectNode emptyOfColValues = JSONUtils.createObjectNode();
+                for (int i = 1; i <= num; i++) {","[{'comment': '是否只需要填充一行就行了', 'commenter': 'githublaohu'}, {'comment': 'Each field needs to be written to json', 'commenter': 'fengjian1129'}, {'comment': 'Each field needs to be written to json', 'commenter': 'fengjian1129'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -255,6 +255,15 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 resultJSONArray.add(mapOfColValues);
                 rowCount++;
             }
+            // result is null,output table metadata
+            if (resultJSONArray.isEmpty()) {
+                ObjectNode emptyOfColValues = JSONUtils.createObjectNode();
+                for (int i = 1; i <= num; i++) {
+                    emptyOfColValues.set(md.getColumnLabel(i), JSONUtils.toJsonNode(""""));
+                }
+                resultJSONArray.add(emptyOfColValues);","[{'comment': ""If put the empty row, the display rows is 1, but it's 0 in fact."", 'commenter': 'caishunfeng'}, {'comment': 'If the data is empty, I want to send Excel with header\r\n![image](https://user-images.githubusercontent.com/35831367/191250803-cc7373bc-de01-4dc0-9c5b-35fc14690dec.png)\r\n', 'commenter': 'fengjian1129'}, {'comment': ""Yes, I get your point, but what I mean is that the log will show the incorrect empty result. It's better to set empty value before sendAttachment. see https://github.com/apache/dolphinscheduler/pull/12059/files#diff-f54c9e235dbb7e6ab2bd181aaad09f19330e680b8573840d64386401abb47203R269-R273\r\n\r\nBTW, I think you can split this code as a function, like `generateEmptyRow`, WDYT?"", 'commenter': 'caishunfeng'}, {'comment': 'yes, I got it', 'commenter': 'fengjian1129'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -279,6 +274,30 @@ private String resultProcess(ResultSet resultSet) throws Exception {
         return result;
     }
 
+    /**
+     * Output Query Results as JsonString
+     */
+
+    private void generateRow(ArrayNode resultJSONArray, ResultSetMetaData md, int metaColumnsNum, int rowCount) throws SQLException {
+        if (resultJSONArray.isEmpty()) {
+            logger.info(""sql query results is empty"");
+            ObjectNode emptyOfColValues = JSONUtils.createObjectNode();
+            for (int i = 1; i <= metaColumnsNum; i++) {
+                emptyOfColValues.set(md.getColumnLabel(i), JSONUtils.toJsonNode(""""));
+            }
+            resultJSONArray.add(emptyOfColValues);
+        } else {
+            int displayRows = sqlParameters.getDisplayRows() > 0 ? sqlParameters.getDisplayRows() : TaskConstants.DEFAULT_DISPLAY_ROWS;
+            displayRows = Math.min(displayRows, rowCount);
+            logger.info(""display sql result {} rows as follows:"", displayRows);
+            for (int i = 0; i < displayRows; i++) {
+                String row = JSONUtils.toJsonString(resultJSONArray.get(i));
+                logger.info(""row {} : {}"", i + 1, row);
+            }
+        }
+    }","[{'comment': '```suggestion\r\n    private ArrayNode generateEmptyRow(ResultSetMetaData md, int metaColumnsNum, int rowCount) throws SQLException {\r\n            ArrayNode resultJSONArray = JSONUtils.createArrayNode();\r\n            ObjectNode emptyOfColValues = JSONUtils.createObjectNode();\r\n            for (int i = 1; i <= metaColumnsNum; i++) {\r\n                emptyOfColValues.set(md.getColumnLabel(i), JSONUtils.toJsonNode(""""));\r\n            }\r\n            resultJSONArray.add(emptyOfColValues);\r\n           return resultJSONArray;\r\n    }\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'We should avoid to change the input param in the method.', 'commenter': 'caishunfeng'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -261,13 +261,8 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 resultJSONArray.add(mapOfColValues);
                 rowCount++;
             }
-            int displayRows = sqlParameters.getDisplayRows() > 0 ? sqlParameters.getDisplayRows() : TaskConstants.DEFAULT_DISPLAY_ROWS;
-            displayRows = Math.min(displayRows, rowCount);
-            logger.info(""display sql result {} rows as follows:"", displayRows);
-            for (int i = 0; i < displayRows; i++) {
-                String row = JSONUtils.toJsonString(resultJSONArray.get(i));
-                logger.info(""row {} : {}"", i + 1, row);
-            }","[{'comment': 'This is the normal logic, we should recover it.', 'commenter': 'caishunfeng'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -261,13 +261,8 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 resultJSONArray.add(mapOfColValues);
                 rowCount++;
             }
-            int displayRows = sqlParameters.getDisplayRows() > 0 ? sqlParameters.getDisplayRows() : TaskConstants.DEFAULT_DISPLAY_ROWS;
-            displayRows = Math.min(displayRows, rowCount);
-            logger.info(""display sql result {} rows as follows:"", displayRows);
-            for (int i = 0; i < displayRows; i++) {
-                String row = JSONUtils.toJsonString(resultJSONArray.get(i));
-                logger.info(""row {} : {}"", i + 1, row);
-            }
+            // generate query results
+            generateRow(resultJSONArray, md, num, rowCount);","[{'comment': 'It will not take affect when resultSet == null.', 'commenter': 'caishunfeng'}, {'comment': 'I think  when resultSet == null then resultJSONArray is empty, it will still result in no content when the email is sent, and an error RuntimeException will be reported.I will process the logic that the resultSet is empty, and write the result into the content as the fixed error content', 'commenter': 'fengjian1129'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -261,13 +261,8 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 resultJSONArray.add(mapOfColValues);
                 rowCount++;
             }
-            int displayRows = sqlParameters.getDisplayRows() > 0 ? sqlParameters.getDisplayRows() : TaskConstants.DEFAULT_DISPLAY_ROWS;
-            displayRows = Math.min(displayRows, rowCount);
-            logger.info(""display sql result {} rows as follows:"", displayRows);
-            for (int i = 0; i < displayRows; i++) {
-                String row = JSONUtils.toJsonString(resultJSONArray.get(i));
-                logger.info(""row {} : {}"", i + 1, row);
-            }
+            // generate query results
+            generateRow(resultJSONArray, md, num, rowCount);
         }
         String result = JSONUtils.toJsonString(resultJSONArray);
         if (sqlParameters.getSendEmail() == null || sqlParameters.getSendEmail()) {","[{'comment': 'Avoid changing the return result.\r\n```suggestion\r\n        if (sqlParameters.getSendEmail() == null || sqlParameters.getSendEmail()) {\r\n            String attachmentContent = resultJSONArray.isEmpty()? JSONUtils.toJsonString(generateEmptyRow()):result;\r\n            sendAttachment(sqlParameters.getGroupId(), StringUtils.isNotEmpty(sqlParameters.getTitle())\r\n                    ? sqlParameters.getTitle()\r\n                    : taskExecutionContext.getTaskName() + "" query result sets"", attachmentContent);\r\n```', 'commenter': 'caishunfeng'}]"
12059,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -269,7 +270,10 @@ private String resultProcess(ResultSet resultSet) throws Exception {
                 logger.info(""row {} : {}"", i + 1, row);
             }
         }
-        String result = JSONUtils.toJsonString(resultJSONArray);
+
+        String result = resultJSONArray.isEmpty() ?","[{'comment': 'Is it OK if return the empty row? Because it will deal out param if define the param pass.\r\nsee https://dolphinscheduler.apache.org/zh-cn/docs/dev/user_doc/guide/parameter/context.html', 'commenter': 'caishunfeng'}, {'comment': 'I tested it according to the document, such as\r\n<img width=""536"" alt=""image"" src=""https://user-images.githubusercontent.com/35831367/191460410-f5c84b86-19fa-43cb-af22-3f9751839560.png"">\r\n<img width=""333"" alt=""image"" src=""https://user-images.githubusercontent.com/35831367/191460778-847e19fb-410c-4f8f-be01-b3b31fcfff32.png"">\r\n\r\nI think it is in line with expectations\r\n', 'commenter': 'fengjian1129'}, {'comment': 'This is the normal case with data\r\n<img width=""354"" alt=""image"" src=""https://user-images.githubusercontent.com/35831367/191461966-1e0fb4f4-7ded-4864-bbc5-6b75e65eeae8.png"">\r\n', 'commenter': 'fengjian1129'}]"
12076,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -790,6 +790,22 @@ CREATE TABLE `t_ds_resources` (
 -- Records of t_ds_resources
 -- ----------------------------
 
+-- ----------------------------
+-- Table structure for t_ds_relation_resources_task
+-- ----------------------------
+DROP TABLE IF EXISTS `t_ds_relation_resources_task`;
+CREATE TABLE `t_ds_relation_resources_task` (
+  `id` int NOT NULL AUTO_INCREMENT COMMENT 'key',
+  `full_name` varchar(255) DEFAULT NULL,
+  `type` tinyint DEFAULT NULL COMMENT 'resource type,0:FILE,1:UDF',
+  PRIMARY KEY (`id`),
+  UNIQUE KEY `t_ds_relation_resources_task_un` (`full_name`,`type`)
+) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb3","[{'comment': ""I think this table is about resources, not the relation between task and resources.\r\nWhy not create this table like this, and then we can remove the `resource_ids_new` field in `t_ds_task_definition`\r\n```suggestion\r\nCREATE TABLE `t_ds_relation_resources_task` (\r\n  `id` int NOT NULL AUTO_INCREMENT COMMENT 'key',\r\n  `task_id` int(11) DEFAULT NULL COMMENT 'task id',\r\n  `full_name` varchar(255) DEFAULT NULL,\r\n  `type` tinyint DEFAULT NULL COMMENT 'resource type,0:FILE,1:UDF',\r\n  PRIMARY KEY (`id`),\r\n  UNIQUE KEY `t_ds_relation_resources_task_un` (`task_id`, `full_name`,`type`)\r\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb3\r\n```"", 'commenter': 'caishunfeng'}, {'comment': '> I think this table is about resources, not the relation between task and resources. Why not create this table like this, and then we can remove the `resource_ids_new` field in `t_ds_task_definition`\r\n\r\nIt is a relation between tasks and resources because we store resources into this table only when a task uses them.\r\n\r\nHaving a `task_id` field in table definitely helps a lot! I will make some changes based on this new field.', 'commenter': 'EricPyZhou'}, {'comment': ""@caishunfeng @SbloodyS  In the latest commit, I added the `task_id` field. While testing it, I found there was no logic in updating task definition-related tables in the repo. For example, In the current implementation, the modification to resources (rename, delete) used by a task won't update the task definition log, which it should. Therefore, at the end I used `processDefinitionService.updateProcessDefinition()` to implement the logic."", 'commenter': 'EricPyZhou'}]"
12076,dolphinscheduler-ui/src/views/resource/udf/resource/use-table.ts,"@@ -117,19 +120,19 @@ export function useTable() {
       {
         title: t('resource.udf.file_name'),
         ...COLUMN_WIDTH_CONFIG['name'],
-        key: 'fileName'
+        key: 'fullName'
       },
       {
         title: t('resource.udf.file_size'),
         key: 'size',
         ...COLUMN_WIDTH_CONFIG['size'],
         render: (row) => bytesToSize(row.size)
       },
-      {
-        title: t('resource.udf.description'),
-        key: 'description',
-        ...COLUMN_WIDTH_CONFIG['note']
-      },
+//       {
+//         title: t('resource.udf.description'),
+//         key: 'description',
+//         ...COLUMN_WIDTH_CONFIG['note']
+//       },","[{'comment': 'Please remove unnessnary comment.', 'commenter': 'SbloodyS'}]"
12076,dolphinscheduler-ui/src/views/resource/udf/resource/use-table.ts,"@@ -265,15 +281,18 @@ export function useTable() {
     variables.row = row
   }
 
-  const handleDelete = (id: number) => {
+  const handleDelete = (id: number, fullNameObj: {fullName: string, tenantCode: string}) => {
     /* after deleting data from the current page, you need to jump forward when the page is empty. */
     if (variables.tableData.length === 1 && variables.page > 1) {
       variables.page -= 1
     }
 
-    deleteResource(id).then(() =>
+    deleteResource(id, fullNameObj).then(() =>
       getTableData({
-        id: variables.id,
+        id: -1,
+//         id: variables.id,","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}]"
12076,dolphinscheduler-ui/src/views/resource/file/table/use-table.ts,"@@ -86,13 +85,13 @@ export function useTable(renameResource: IRenameFile, updateList: () => void) {
     {
       title: t('resource.file.file_name'),
       ...COLUMN_WIDTH_CONFIG['name'],
-      key: 'file_name'
-    },
-    {
-      title: t('resource.file.description'),
-      ...COLUMN_WIDTH_CONFIG['note'],
-      key: 'description'
+      key: 'fullName'
     },
+//     {
+//       title: t('resource.file.description'),
+//       ...COLUMN_WIDTH_CONFIG['note'],
+//       key: 'description'
+//     },","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UdfFuncServiceImpl.java,"@@ -112,9 +120,15 @@
             return result;
         }
 
-        Resource resource = resourceMapper.selectById(resourceId);
-        if (resource == null) {
-            logger.error(""Resource does not exist, resourceId:{}."", resourceId);
+        Boolean existResource = false;
+        try {
+            existResource = storageOperate.exists(fullName);
+        } catch (IOException e){
+            logger.error(""AmazonServiceException when checking resource: "" + fullName);
+        }
+
+        if (!existResource){
+            logger.error(""resourceId {} is not exist"", fullName);","[{'comment': '## Logging should not be vulnerable to injection attacks\n\n<!--SONAR_ISSUE_KEY:AYPNYBjwUAsZPIwYbSMr-->Change this code to not log user-controlled data. <p>See more on <a href=""https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&issues=AYPNYBjwUAsZPIwYbSMr&open=AYPNYBjwUAsZPIwYbSMr&pullRequest=12076"">SonarCloud</a></p>\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1786)', 'commenter': 'github-advanced-security[bot]'}]"
12076,dolphinscheduler-ui/src/views/projects/task/components/node/types.ts,"@@ -91,7 +91,9 @@ interface ISwitchResult {
 }
 
 interface ISourceItem {
-  id: number
+  id?: number,
+  resourceName: string,
+  res?: string","[{'comment': ""what's the meaning of `res`? Would it be better to use a full word？"", 'commenter': 'Amy0104'}, {'comment': ""> what's the meaning of `res`? Would it be better to use a full word？\r\n\r\nya I agree that 'res' is not clear. It is kinda hard to change it because 'res' corresponds to 'res' field in the backend. For a temporal fix, I put a comment box there to illustrate what 'resourceName' and 'res' are."", 'commenter': 'EricPyZhou'}]"
12076,dolphinscheduler-ui/src/views/resource/file/create/use-create.ts,"@@ -27,7 +27,7 @@ export function useCreate(state: any) {
   const fileStore = useFileStore()
 
   const handleCreateFile = () => {
-    const pid = router.currentRoute.value.params.id || -1
+    const pid = -1","[{'comment': 'It seems to need to remove `pid`.', 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-ui/src/views/resource/file/edit/index.tsx,"@@ -32,21 +32,22 @@ export default defineComponent({
     const router = useRouter()
 
     const componentName = route.name
-    const fileId = Number(route.params.id)
+    const fileId = String(router.currentRoute.value.query.prefix || """")","[{'comment': 'Here `fullName` seems to be better than `fileId`.', 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-ui/src/views/resource/file/edit/use-edit.ts,"@@ -28,25 +28,29 @@ export function useEdit(state: any) {
   const { t } = useI18n()
   const router: Router = useRouter()
 
-  const getResourceView = (id: number) => {
+  const getResourceView = (fullName: string, tenantCode: string, id: number) => {
     const params = {
       skipLineNum: 0,
-      limit: 3000
+      limit: 3000,
+      fullName: fullName,
+      tenantCode: tenantCode
     }
     return useAsyncState(viewResource(params, id), {
       alias: '',
       content: ''
     })
   }
 
-  const handleUpdateContent = (id: number) => {
+  const handleUpdateContent = (id: string, fullName: string, tenantCode: string) => {","[{'comment': '`id` needs to be removed, it seems to be unused.', 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-ui/src/views/resource/file/index.tsx,"@@ -57,8 +57,8 @@ export default defineComponent({
   name: 'File',
   setup() {
     const router: Router = useRouter()
-    const fileId = ref(Number(router.currentRoute.value.params.id) || -1)
-
+    const fileId = ref(String(router.currentRoute.value.query.prefix || """"))","[{'comment': 'Same as above.', 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-ui/src/views/resource/file/upload/use-upload.ts,"@@ -37,7 +34,7 @@ export function useUpload(state: any) {
     if (state.saving) return
     state.saving = true
     try {
-      const pid = router.currentRoute.value.params.id || -1
+      const pid = -1","[{'comment': ""It's better to remove the `pid`, if it is useless."", 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-ui/src/views/resource/udf/resource/use-table.ts,"@@ -242,13 +240,26 @@ export function useTable() {
     variables.loadingRef = true
     const { state } = useAsyncState(
       queryResourceListPaging({ ...params, type: 'UDF' }).then((res: any) => {
-        const breadList =
-          variables.id === -1
-            ? []
-            : (fileStore.getCurrentDir.split('/') as Array<never>)
-        breadList.shift()
-
-        variables.breadList = breadList
+        if (variables.fileId != """"){","[{'comment': 'It better to use strict inequality here.', 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-ui/src/views/resource/udf/resource/use-table.ts,"@@ -285,18 +298,19 @@ export function useTable() {
     router.push({ name: 'resource-manage' })
   }
 
-  const goBread = (fullName: string) => {
-    const { id } = variables
+  const goBread = (fileName: string) => {
+    const id = -1","[{'comment': 'If `id` is useless, it is better to remove it.', 'commenter': 'Amy0104'}, {'comment': 'ya, the ""id"" is deprecated. Will remove it in another pr with new routes along with all other ""ids"". Right now they are labelled as Deprecated in the backend', 'commenter': 'EricPyZhou'}]"
12076,dolphinscheduler-ui/src/views/resource/udf/resource/use-table.ts,"@@ -242,13 +240,26 @@ export function useTable() {
     variables.loadingRef = true
     const { state } = useAsyncState(
       queryResourceListPaging({ ...params, type: 'UDF' }).then((res: any) => {
-        const breadList =
-          variables.id === -1
-            ? []
-            : (fileStore.getCurrentDir.split('/') as Array<never>)
-        breadList.shift()
-
-        variables.breadList = breadList
+        if (variables.fileId != """"){
+            const id = -1
+            queryCurrentResourceById(
+              {
+                id,
+                type: 'UDF',
+                fullName: variables.fileId,
+                tenantCode: variables.tenantCode,
+              },
+              id
+            ).then((res: ResourceFile) => {
+                if (res.fileName) {
+                  const breadList = res.fileName.split('/') as Array<never>","[{'comment': 'The  type of `breadList` can not to be `Array<never>`.', 'commenter': 'Amy0104'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -1808,4 +1929,44 @@ private List<Resource> queryResourceList(Integer userId, int perm) {
     private AuthorizationType checkResourceType(ResourceType type) {
         return type.equals(ResourceType.FILE) ? AuthorizationType.RESOURCE_FILE_ID : AuthorizationType.UDF_FILE;
     }
+
+    /**
+     * check permission by comparing login user's tenantCode with tenantCode in the request
+     *
+     * @param loginUser user who currently logs in
+     * @param resTenantCode tenantCode in the request field ""resTenantCode"", can be different from the login user in the case of admin users.
+     * @param result  result Object containing different cases
+     * @return tenantCode
+     */
+    private String getTenantCodeIfuserValid(User loginUser, String resTenantCode, Result<Object> result) {","[{'comment': ""Please don't use the `Result<Object> result` as input param, we should avoid to change the input param.\r\nYou can throw the exception like `throw new ServiceException(Status.USER_NOT_EXIST)` when some check error."", 'commenter': 'caishunfeng'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -272,46 +254,34 @@ public Result<Object> createResource(User loginUser,
         }
 
         // check resource name exists
-        String fullName = getFullName(currentDir, name);
-        if (checkResourceExists(fullName, type.ordinal())) {
-            logger.warn(""Resource exists, can not create again, fullName:{}."", RegexUtils.escapeNRT(name));
-            putMsg(result, Status.RESOURCE_EXIST);
-            return result;
-        }
-        if (fullName.length() > Constants.RESOURCE_FULL_NAME_MAX_LENGTH) {
-            logger.warn(""Resource file's name is longer than max full name length, fullName:{}, fullNameSize:{}, maxFullNameSize:{}"",
-                    RegexUtils.escapeNRT(name), fullName.length(), Constants.RESOURCE_FULL_NAME_MAX_LENGTH);
-            putMsg(result, Status.RESOURCE_FULL_NAME_TOO_LONG_ERROR);
-            return result;
-        }
-
-        Date now = new Date();
-        Resource resource = new Resource(pid, name, fullName, false, desc, file.getOriginalFilename(),
-                loginUser.getId(), type, file.getSize(), now, now);
+        String userResRootPath = ResourceType.UDF.equals(type) ? storageOperate.getUdfDir(tenantCode)
+                : storageOperate.getResDir(tenantCode);
+        String currDirNFileName = !currentDir.contains(userResRootPath) ? userResRootPath + name : currentDir + name;
 
         try {
-            resourcesMapper.insert(resource);
-            updateParentResourceSize(resource, resource.getSize());
-            putMsg(result, Status.SUCCESS);
-            permissionPostHandle(resource.getType(), loginUser, resource.getId());
-            Map<String, Object> resultMap = new HashMap<>();
-            for (Map.Entry<Object, Object> entry : new BeanMap(resource).entrySet()) {
-                if (!""class"".equalsIgnoreCase(entry.getKey().toString())) {
-                    resultMap.put(entry.getKey().toString(), entry.getValue());
-                }
+            if (checkResourceExists(currDirNFileName, type.ordinal())) {
+                logger.error(""resource {} has exist, can't recreate"", RegexUtils.escapeNRT(name));
+                putMsg(result, Status.RESOURCE_EXIST);
+                return result;
             }
-            result.setData(resultMap);
         } catch (Exception e) {
-            logger.warn(""Resource exists, can not create again, fullName:{}."", fullName, e);
             throw new ServiceException(""resource already exists, can't recreate"");
         }
+        if (currDirNFileName.length() > Constants.RESOURCE_FULL_NAME_MAX_LENGTH) {
+            logger.warn(","[{'comment': '```suggestion\r\n            logger.error(\r\n```', 'commenter': 'caishunfeng'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -355,7 +326,13 @@ private void updateParentResourceSize(Resource resource, long size) {
      * @return true if resource exists
      */
     private boolean checkResourceExists(String fullName, int type) {
-        Boolean existResource = resourcesMapper.existResource(fullName, type);
+        // Boolean existResource = resourcesMapper.existResource(fullName, type);
+        Boolean existResource = false;
+        try {
+            existResource = storageOperate.exists(fullName);
+        } catch (IOException e) {
+            logger.error(""error occurred when checking resource: "" + fullName);","[{'comment': '```suggestion\r\n            logger.error(""error occurred when checking resource: "" + fullName, e);\r\n```', 'commenter': 'caishunfeng'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -374,38 +351,38 @@ private boolean checkResourceExists(String fullName, int type) {
     @Transactional
     public Result<Object> updateResource(User loginUser,
                                          int resourceId,
+                                         String resourceFullName,
+                                         String resTenantCode,
                                          String name,
                                          String desc,
                                          ResourceType type,
                                          MultipartFile file) {
         Result<Object> result = new Result<>();
-        String funcPermissionKey = type.equals(ResourceType.FILE) ? ApiFuncIdentificationConstant.FILE_UPDATE
-                : ApiFuncIdentificationConstant.UDF_UPDATE;
-        boolean canOperatorPermissions =
-                canOperatorPermissions(loginUser, new Object[]{resourceId}, checkResourceType(type), funcPermissionKey);
-        if (!canOperatorPermissions) {
-            putMsg(result, Status.NO_CURRENT_OPERATING_PERMISSION);
-            return result;
-        }
+
         result = checkResourceUploadStartupState();
         if (!result.getCode().equals(Status.SUCCESS.getCode())) {
             return result;
         }
 
-        Resource resource = resourcesMapper.selectById(resourceId);
-        if (resource == null) {
-            logger.error(""Resource does not exist, resourceId:{}."", resourceId);
-            putMsg(result, Status.RESOURCE_NOT_EXIST);
+        String tenantCode = getTenantCodeIfuserValid(loginUser, resTenantCode, result);
+        if (tenantCode == null) {
             return result;
         }
-        if (checkDescriptionLength(desc)) {
-            logger.warn(""Parameter description is too long."");
-            putMsg(result, Status.DESCRIPTION_TOO_LONG_ERROR);
-            return result;
+
+        String defaultPath = storageOperate.getResDir(tenantCode);
+
+        StorageEntity resource;
+        try {
+            resource = storageOperate.getFileStatus(resourceFullName, defaultPath, resTenantCode, type);
+        } catch (Exception e) {
+            logger.error(e.getMessage() + "" Resource path: {}"", resourceFullName, e);","[{'comment': '```suggestion\r\n            logger.error(""Get file status fail, resource path: {}"", resourceFullName, e);\r\n```', 'commenter': 'caishunfeng'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -374,38 +351,38 @@ private boolean checkResourceExists(String fullName, int type) {
     @Transactional
     public Result<Object> updateResource(User loginUser,
                                          int resourceId,
+                                         String resourceFullName,
+                                         String resTenantCode,
                                          String name,
                                          String desc,
                                          ResourceType type,
                                          MultipartFile file) {
         Result<Object> result = new Result<>();
-        String funcPermissionKey = type.equals(ResourceType.FILE) ? ApiFuncIdentificationConstant.FILE_UPDATE
-                : ApiFuncIdentificationConstant.UDF_UPDATE;
-        boolean canOperatorPermissions =
-                canOperatorPermissions(loginUser, new Object[]{resourceId}, checkResourceType(type), funcPermissionKey);
-        if (!canOperatorPermissions) {
-            putMsg(result, Status.NO_CURRENT_OPERATING_PERMISSION);
-            return result;
-        }
+
         result = checkResourceUploadStartupState();
         if (!result.getCode().equals(Status.SUCCESS.getCode())) {
             return result;
         }
 
-        Resource resource = resourcesMapper.selectById(resourceId);
-        if (resource == null) {
-            logger.error(""Resource does not exist, resourceId:{}."", resourceId);
-            putMsg(result, Status.RESOURCE_NOT_EXIST);
+        String tenantCode = getTenantCodeIfuserValid(loginUser, resTenantCode, result);
+        if (tenantCode == null) {
             return result;
         }
-        if (checkDescriptionLength(desc)) {
-            logger.warn(""Parameter description is too long."");
-            putMsg(result, Status.DESCRIPTION_TOO_LONG_ERROR);
-            return result;
+
+        String defaultPath = storageOperate.getResDir(tenantCode);
+
+        StorageEntity resource;
+        try {
+            resource = storageOperate.getFileStatus(resourceFullName, defaultPath, resTenantCode, type);
+        } catch (Exception e) {
+            logger.error(e.getMessage() + "" Resource path: {}"", resourceFullName, e);
+            putMsg(result, Status.RESOURCE_NOT_EXIST);
+            throw new ServiceException(String.format(e.getMessage() + "" Resource path: %s"", resourceFullName));","[{'comment': '```suggestion\r\n            throw new ServiceException(String.format (""Get file status fail, resource path: %s"", resourceFullName));\r\n```', 'commenter': 'caishunfeng'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -506,63 +441,90 @@ public Result<Object> updateResource(User loginUser,
             resource.setSize(file.getSize());
         }
 
-        try {
-            resourcesMapper.updateById(resource);
-            if (resource.isDirectory()) {
-                List<Integer> childrenResource = listAllChildren(resource, false);
-                if (CollectionUtils.isNotEmpty(childrenResource)) {
-                    String matcherFullName = Matcher.quoteReplacement(fullName);
-                    List<Resource> childResourceList;
-                    Integer[] childResIdArray = childrenResource.toArray(new Integer[childrenResource.size()]);
-                    List<Resource> resourceList = resourcesMapper.listResourceByIds(childResIdArray);
-                    childResourceList = resourceList.stream().map(t -> {
-                        t.setFullName(t.getFullName().replaceFirst(originFullName, matcherFullName));
-                        t.setUpdateTime(now);
-                        return t;
-                    }).collect(Collectors.toList());
-                    resourcesMapper.batchUpdateResource(childResourceList);
-
-                    if (ResourceType.UDF.equals(resource.getType())) {
-                        List<UdfFunc> udfFuncs = udfFunctionMapper.listUdfByResourceId(childResIdArray);
-                        if (CollectionUtils.isNotEmpty(udfFuncs)) {
-                            udfFuncs = udfFuncs.stream().map(t -> {
-                                t.setResourceName(t.getResourceName().replaceFirst(originFullName, matcherFullName));
-                                t.setUpdateTime(now);
-                                return t;
-                            }).collect(Collectors.toList());
-                            udfFunctionMapper.batchUpdateUdfFunc(udfFuncs);
-                        }
-                    }
-                }
-            } else if (ResourceType.UDF.equals(resource.getType())) {
-                List<UdfFunc> udfFuncs = udfFunctionMapper.listUdfByResourceId(new Integer[]{resourceId});
-                if (CollectionUtils.isNotEmpty(udfFuncs)) {
-                    udfFuncs = udfFuncs.stream().map(t -> {
-                        t.setResourceName(fullName);
-                        t.setUpdateTime(now);
-                        return t;
-                    }).collect(Collectors.toList());
-                    udfFunctionMapper.batchUpdateUdfFunc(udfFuncs);
-                }
+        // if name unchanged, return directly without moving on HDFS
+        if (originResourceName.equals(name) && file == null) {
+            return result;
+        }
 
+        List<ResourcesTask> existResourcesList;
+        if (resource.isDirectory()) {
+            existResourcesList = resourceTaskMapper.selectSubfoldersFullNames(originFullName + FOLDER_SEPARATOR);
+        } else {
+            existResourcesList = resourceTaskMapper.selectByMap(
+                    Collections.singletonMap(""full_name"", originFullName));
+        }
+
+        if (existResourcesList.size() > 0 && !fullName.equals(originFullName)) {
+            // check if any related task is online. If it is, it can not be updated.
+            for (ResourcesTask existResource : existResourcesList) {
+                int taskId = existResource.getTaskId();
+                if (processService.isTaskOnline(taskDefinitionMapper.selectById(taskId).getCode())) {
+                    logger.error(""can't be updated,because it is used of process definition that's online"");
+                    logger.error(""resource task relation id:{} is used of task code {}"", existResource.getId(),
+                            taskDefinitionMapper.selectById(taskId).getCode());
+                    putMsg(result, Status.RESOURCE_IS_USED);
+                    return result;
+                }
             }
 
-            putMsg(result, Status.SUCCESS);
-            Map<String, Object> resultMap = new HashMap<>();
-            for (Map.Entry<Object, Object> entry : new BeanMap(resource).entrySet()) {
-                if (!Constants.CLASS.equalsIgnoreCase(entry.getKey().toString())) {
-                    resultMap.put(entry.getKey().toString(), entry.getValue());
+            for (ResourcesTask existResource : existResourcesList) {
+                int taskId = existResource.getTaskId();
+                long taskCode = taskDefinitionMapper.selectById(taskId).getCode();
+
+                List<ProcessTaskRelation> processTaskRelation = processTaskRelationMapper.selectByMap(
+                        Collections.singletonMap(""post_task_code"", taskCode));
+                if (processTaskRelation.size() > 0) {
+                    long processDefinitionCode = processTaskRelation.get(0).getProcessDefinitionCode();
+                    int processDefinitionVersion = processTaskRelation.get(0).getProcessDefinitionVersion();
+                    List<ProcessTaskRelation> taskRelationList = processTaskRelationMapper.queryByProcessCode(
+                            processTaskRelation.get(0).getProjectCode(),
+                            processDefinitionCode);
+
+                    List<TaskDefinition> taskDefinitionLogList = new ArrayList<>();
+
+                    if (taskRelationList.size() > 0) {
+                        ProcessDefinitionLog processDefinition =
+                                processDefinitionLogMapper.queryByDefinitionCodeAndVersion(
+                                        processDefinitionCode, processDefinitionVersion);
+                        for (ProcessTaskRelation taskRelation : taskRelationList) {
+                            long taskCodeInProcess = taskRelation.getPostTaskCode();
+                            TaskDefinition taskDefinition = taskDefinitionMapper.queryByCode(taskCodeInProcess);
+                            if (taskCodeInProcess == taskCode) {
+                                // originFullName is a prefix if isDirectory is true
+                                taskDefinition.setTaskParams(RemoveResourceFromResourceList(originFullName,
+                                        taskDefinition.getTaskParams(),
+                                        resource.isDirectory()));
+                                // if isDirectory is true, fullName is the new prefix. we replace old prefix
+                                // of resource fullname with the new prefix.
+                                // if isDirectory is false, fullName is the new path.
+                                taskDefinition.setTaskParams(AddResourceToResourceList(originFullName,
+                                        fullName,
+                                        existResource.getFullName(),
+                                        taskDefinition.getTaskParams(),
+                                        resource.isDirectory()));","[{'comment': 'Why call `taskDefinition.setTaskParams` twice?', 'commenter': 'caishunfeng'}, {'comment': '> Why call `taskDefinition.setTaskParams` twice?\r\n\r\nThe first setTaskParams removes resources deselected by users. (it was selected as first, and then get deselected)\r\nThe second setTaskParams add resources get selected by users.\r\n\r\nI used two setTaskParams to add code readability.', 'commenter': 'EricPyZhou'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UdfFuncServiceImpl.java,"@@ -112,14 +120,20 @@
             return result;
         }
 
-        Resource resource = resourceMapper.selectById(resourceId);
-        if (resource == null) {
-            logger.error(""Resource does not exist, resourceId:{}."", resourceId);
+        Boolean existResource = false;
+        try {
+            existResource = storageOperate.exists(fullName);
+        } catch (IOException e) {
+            logger.error(""AmazonServiceException when checking resource: "" + fullName);
+        }
+
+        if (!existResource) {
+            logger.error(""resource full name {} is not exist"", fullName);","[{'comment': '## Logging should not be vulnerable to injection attacks\n\n<!--SONAR_ISSUE_KEY:AYPkb5rB3zqccheRFO5r-->Change this code to not log user-controlled data. <p>See more on <a href=""https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&issues=AYPkb5rB3zqccheRFO5r&open=AYPkb5rB3zqccheRFO5r&pullRequest=12076"">SonarCloud</a></p>\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1887)', 'commenter': 'github-advanced-security[bot]'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UdfFuncServiceImpl.java,"@@ -243,13 +261,24 @@
             }
         }
 
-        Resource resource = resourceMapper.selectById(resourceId);
-        if (resource == null) {
-            logger.error(""Resource does not exist, resourceId:{}."", resourceId);
+        // Resource resource = resourceMapper.selectById(resourceId);
+        Boolean doesResExist = false;
+        try {
+            doesResExist = storageOperate.exists(fullName);
+        } catch (Exception e) {
+            logger.error(""udf resource checking error"", fullName);
             result.setCode(Status.RESOURCE_NOT_EXIST.getCode());
             result.setMsg(Status.RESOURCE_NOT_EXIST.getMsg());
             return result;
         }
+
+        if (!doesResExist) {
+            logger.error(""resource full name {} is not exist"", fullName);","[{'comment': '## Logging should not be vulnerable to injection attacks\n\n<!--SONAR_ISSUE_KEY:AYPkb5rB3zqccheRFO5q-->Change this code to not log user-controlled data. <p>See more on <a href=""https://sonarcloud.io/project/issues?id=apache-dolphinscheduler&issues=AYPkb5rB3zqccheRFO5q&open=AYPkb5rB3zqccheRFO5q&pullRequest=12076"">SonarCloud</a></p>\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1888)', 'commenter': 'github-advanced-security[bot]'}]"
12076,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UdfFuncServiceImpl.java,"@@ -243,13 +261,24 @@ public Result<Object> updateUdfFunc(User loginUser,
             }
         }
 
-        Resource resource = resourceMapper.selectById(resourceId);
-        if (resource == null) {
-            logger.error(""Resource does not exist, resourceId:{}."", resourceId);
+        // Resource resource = resourceMapper.selectById(resourceId);","[{'comment': 'Please remove unused comment.', 'commenter': 'SbloodyS'}]"
12076,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_h2.sql,"@@ -792,6 +792,24 @@ CREATE TABLE t_ds_resources
 -- Records of t_ds_resources
 -- ----------------------------
 
+-- ----------------------------
+-- Table structure for t_ds_relation_resources_task
+-- ----------------------------
+DROP TABLE IF EXISTS t_ds_relation_resources_task CASCADE;
+CREATE TABLE t_ds_relation_resources_task
+(
+  id                        int(11) NOT NULL AUTO_INCREMENT,
+  task_id                   int(11) DEFAULT NULL,
+  full_name                 varchar(255) DEFAULT NULL,
+  type                      tinyint(4) DEFAULT NULL,
+  PRIMARY KEY (id),
+  UNIQUE KEY t_ds_relation_resources_task_un (task_id, full_name)
+) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb3;","[{'comment': '```suggestion\r\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET= utf8;\r\n```', 'commenter': 'SbloodyS'}]"
12076,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -790,6 +790,23 @@ CREATE TABLE `t_ds_resources` (
 -- Records of t_ds_resources
 -- ----------------------------
 
+-- ----------------------------
+-- Table structure for t_ds_relation_resources_task
+-- ----------------------------
+DROP TABLE IF EXISTS `t_ds_relation_resources_task`;
+CREATE TABLE `t_ds_relation_resources_task` (
+  `id` int NOT NULL AUTO_INCREMENT COMMENT 'key',
+  `task_id` int(11) DEFAULT NULL COMMENT 'task id',
+  `full_name` varchar(255) DEFAULT NULL,
+  `type` tinyint DEFAULT NULL COMMENT 'resource type,0:FILE,1:UDF',
+  PRIMARY KEY (`id`),
+  UNIQUE KEY `t_ds_relation_resources_task_un` (`task_id`, `full_name`)
+) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8mb3;","[{'comment': '```suggestion\r\n) ENGINE=InnoDB AUTO_INCREMENT=1 DEFAULT CHARSET=utf8;\r\n```', 'commenter': 'SbloodyS'}]"
12096,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -1315,7 +1315,6 @@ protected boolean checkAndImport(User loginUser, long projectCode, Map<String, O
             return false;
         }
         processDefinition.setName(importProcessDefinitionName);
-        processDefinition.setId(0);","[{'comment': ""When import workflow, it should create a new id, so it's better to setId(null), but not use the origin id."", 'commenter': 'caishunfeng'}]"
12126,dolphinscheduler-api/pom.xml,"@@ -190,11 +190,23 @@
             <artifactId>spring-cloud-starter-kubernetes-fabric8-config</artifactId>
         </dependency>
 
+        <dependency>","[{'comment': 'Please replace this with \n\n```xml\n             <dependency>\n                 <groupId>org.apache.hbase.thirdparty</groupId>\n                 <artifactId>hbase-noop-htrace</artifactId>\n             </dependency>\n```', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-api/pom.xml,"@@ -190,11 +190,23 @@
             <artifactId>spring-cloud-starter-kubernetes-fabric8-config</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.htrace</groupId>
+            <artifactId>htrace-core4</artifactId>
+            <version>${htrace.version}</version>
+            <scope>runtime</scope>
+        </dependency>
+
         <dependency>
             <groupId>com.h2database</groupId>
             <artifactId>h2</artifactId>
             <scope>test</scope>
         </dependency>
+        <dependency>","[{'comment': 'This should be removed. ', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,pom.xml,"@@ -92,6 +92,7 @@
         <docker.tag>${project.version}</docker.tag>
         <docker.build.skip>true</docker.build.skip>
         <docker.push.skip>true</docker.push.skip>
+        <htrace.version>4.2.0-incubating</htrace.version>","[{'comment': 'Should manage in bom.', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-api/pom.xml,"@@ -190,6 +190,13 @@
             <artifactId>spring-cloud-starter-kubernetes-fabric8-config</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.hbase.thirdparty</groupId>
+            <artifactId>hbase-noop-htrace</artifactId>
+            <version>${htrace.version}</version>
+            <scope>runtime</scope>","[{'comment': 'These are unnecessary. Please remove\n\n```suggestion\n```\n', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-common/pom.xml,"@@ -188,6 +188,11 @@
                 </exclusion>
             </exclusions>
         </dependency>
+        <dependency>
+            <groupId>org.apache.hbase.thirdparty</groupId>
+            <artifactId>hbase-noop-htrace</artifactId>
+            <version>${htrace.version}</version>","[{'comment': 'Same here', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/pom.xml,"@@ -78,6 +78,12 @@
             <artifactId>spring-jdbc</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.hbase.thirdparty</groupId>
+            <artifactId>hbase-noop-htrace</artifactId>
+            <version>${htrace.version}</version>","[{'comment': 'Here', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-api/pom.xml,"@@ -127,6 +133,10 @@
                     <artifactId>log4j</artifactId>
                     <groupId>log4j</groupId>
                 </exclusion>
+                <exclusion>
+                    <groupId>org.apache.htrace</groupId>
+                    <artifactId>htrace-core4</artifactId>
+                </exclusion>","[{'comment': 'These are unnecessary ', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-hive/pom.xml,"@@ -42,6 +42,12 @@
             <scope>provided</scope>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.hbase.thirdparty</groupId>
+            <artifactId>hbase-noop-htrace</artifactId>
+            <version>${htrace.version}</version>","[{'comment': 'Remove', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-hive/pom.xml,"@@ -91,6 +97,10 @@
                     <artifactId>log4j</artifactId>
                     <groupId>log4j</groupId>
                 </exclusion>
+                <exclusion>","[{'comment': 'Remove', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-master/pom.xml,"@@ -95,6 +95,12 @@
             <artifactId>caffeine</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.hbase.thirdparty</groupId>
+            <artifactId>hbase-noop-htrace</artifactId>
+            <version>${htrace.version}</version>","[{'comment': 'Remove', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,dolphinscheduler-master/pom.xml,"@@ -148,6 +154,10 @@
                     <groupId>org.slf4j</groupId>
                     <artifactId>slf4j-reload4j</artifactId>
                 </exclusion>
+                <exclusion>","[{'comment': 'Remove', 'commenter': 'kezhenxu94'}]"
12126,dolphinscheduler-server/pom.xml,"@@ -140,6 +140,11 @@
                 </exclusion>
             </exclusions>
         </dependency>
+        <dependency>
+            <groupId>org.apache.hbase.thirdparty</groupId>
+            <artifactId>hbase-noop-htrace</artifactId>
+            <version>${htrace.version}</version>","[{'comment': 'Remove', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12126,pom.xml,"@@ -92,6 +92,7 @@
         <docker.tag>${project.version}</docker.tag>
         <docker.build.skip>true</docker.build.skip>
         <docker.push.skip>true</docker.push.skip>
+        <htrace.version>4.1.1</htrace.version>","[{'comment': 'Remove this', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'Tianqi-Dotes'}]"
12136,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -344,6 +354,50 @@
                 .isEmpty();
     }
 
+    /**
+     * check whether worker group is available
+     *
+     * @param processDefinition process definition
+     * @param workerGroupNames worker group name list
+     * @return result
+     */
+    public boolean checkWorkerGroupNameExists(ProcessDefinition processDefinition,
+        List<String> workerGroupNames) {
+        // get all task definitions in this process definition
+        List<ProcessTaskRelation> processTaskRelations = processService
+            .findRelationByCode(processDefinition.getCode(), processDefinition.getVersion());
+        List<TaskDefinitionLog> taskDefinitionLogList = processService
+            .genTaskDefineList(processTaskRelations);
+        List<TaskDefinition> taskDefinitions = taskDefinitionLogList.stream()
+            .map(TaskDefinition.class::cast).collect(
+                Collectors.toList());
+
+        for (TaskDefinition taskDefinition : taskDefinitions) {
+            if (!workerGroupNames.contains(taskDefinition.getWorkerGroup())) {
+                logger.error(""Cannot find worker group {} configured on task definition named {} "",
+                    taskDefinition.getWorkerGroup(), taskDefinition.getName());
+                return false;
+            }
+
+            if (TaskConstants.TASK_TYPE_SUB_PROCESS
+                .equalsIgnoreCase(taskDefinition.getTaskType())) {
+                long subProcessCode = Long
+                    .parseLong(JSONUtils.getNodeString(taskDefinition.getTaskParams(),
+                        Constants.CMD_PARAM_SUB_PROCESS_DEFINE_CODE));","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1539)"", 'commenter': 'github-advanced-security[bot]'}]"
12136,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -400,4 +400,22 @@ public Map<String, Object> getWorkerAddressList() {
         return result;
     }
 
+    /**
+     * get all worker group names
+     *
+     * @return worker group name list
+     */
+    @Override
+    public List<String> getAllWorkerGroupNames() {
+        List<WorkerGroup> workerGroups = getWorkerGroups(false, null);
+        List<String> availableWorkerGroupList = workerGroups.stream()
+            .map(WorkerGroup::getName)
+            .collect(Collectors.toList());
+        if (!availableWorkerGroupList.contains(Constants.DEFAULT_WORKER_GROUP)) {","[{'comment': 'availableWorkerGroupList maybe null.', 'commenter': 'hstdream'}, {'comment': '> availableWorkerGroupList maybe null.\r\n\r\nIt will not be null, because mybatis mapper will return a empty list, not null. Mybatis just will return null if return type is a DTO. thx', 'commenter': 'DarkAssassinator'}]"
12142,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskDefinitionServiceImpl.java,"@@ -506,28 +516,43 @@ public Map<String, Object> updateTaskWithUpstream(User loginUser, long projectCo
             ProcessTaskRelation taskRelation = upstreamTaskRelations.get(0);
             List<ProcessTaskRelation> processTaskRelations = processTaskRelationMapper.queryByProcessCode(projectCode, taskRelation.getProcessDefinitionCode());
             List<ProcessTaskRelation> processTaskRelationList = Lists.newArrayList(processTaskRelations);
-            List<ProcessTaskRelation> relationList = Lists.newArrayList();
             for (ProcessTaskRelation processTaskRelation : processTaskRelationList) {
                 if (processTaskRelation.getPostTaskCode() == taskCode) {
                     if (queryUpStreamTaskCodeMap.containsKey(processTaskRelation.getPreTaskCode()) && processTaskRelation.getPreTaskCode() != 0L) {
                         queryUpStreamTaskCodeMap.remove(processTaskRelation.getPreTaskCode());
                     } else {
                         processTaskRelation.setPreTaskCode(0L);
                         processTaskRelation.setPreTaskVersion(0);
-                        relationList.add(processTaskRelation);
                     }
                 }
             }
-            processTaskRelationList.removeAll(relationList);
             for (Map.Entry<Long, TaskDefinition> queryUpStreamTask : queryUpStreamTaskCodeMap.entrySet()) {
-                taskRelation.setPreTaskCode(queryUpStreamTask.getKey());
-                taskRelation.setPreTaskVersion(queryUpStreamTask.getValue().getVersion());
-                processTaskRelationList.add(taskRelation);
+                ProcessTaskRelation processTaskRelation = new ProcessTaskRelation();
+                processTaskRelation.setPreTaskCode(queryUpStreamTask.getKey());
+                processTaskRelation.setPreTaskVersion(queryUpStreamTask.getValue().getVersion());
+                processTaskRelation.setPostTaskCode(taskCode);
+                processTaskRelation.setPostTaskVersion(taskDefinitionToUpdate.getVersion());
+                processTaskRelation.setConditionType(ConditionType.NONE);
+                processTaskRelation.setConditionParams(""{}"");
+                processTaskRelationList.add(processTaskRelation);
             }
             if (queryUpStreamTaskCodeMap.isEmpty() && !processTaskRelationList.isEmpty()) {
                 processTaskRelationList.add(processTaskRelationList.get(0));
             }
-            updateDag(loginUser, result, taskRelation.getProcessDefinitionCode(), processTaskRelations, Lists.newArrayList(taskDefinitionToUpdate));
+            processTaskRelationList.sort((p1, p2) -> Long.compare(p2.getPreTaskCode(), p1.getPreTaskCode()));
+            boolean sign = false;
+            for (int i = 0; i < processTaskRelationList.size(); i++) {
+                ProcessTaskRelation processTaskRelation = processTaskRelationList.get(i);
+                if (processTaskRelation.getPostTaskCode() == taskCode) {
+                    if (processTaskRelation.getPreTaskCode() != 0) {
+                        sign = true;
+                    } else if (sign) {
+                        processTaskRelationList.remove(processTaskRelation);
+                    }
+                }
+            }","[{'comment': ""I think it's better to deal by `Map<PostTaskCode, ProcessTaskRelation>`, due to the sign after sort is not clear. WDYT?"", 'commenter': 'caishunfeng'}, {'comment': 'In the workflow and task definition relation table, the number of the predecessor task is 0. At this time, if a new predecessor task is defined for a task, the old predecessor task with ID 0 is not cleared, resulting in redundant data.\r\n\r\n', 'commenter': 'jinyanhui2008'}]"
12142,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessServiceImpl.java,"@@ -2565,7 +2563,7 @@ public int saveProcessDefine(User operator, ProcessDefinition processDefinition,
     @Override
     public int saveTaskRelation(User operator, long projectCode, long processDefinitionCode, int processDefinitionVersion,
                                 List<ProcessTaskRelationLog> taskRelationList, List<TaskDefinitionLog> taskDefinitionLogs,
-                                Boolean syncDefine) {
+                                Boolean syncDefine, boolean isDelete) {","[{'comment': 'We should avoid this way, because `saveTaskRelation` is already a complex function, expanding the `isDelete` model will exponentially increase the maintenance cost.', 'commenter': 'caishunfeng'}, {'comment': ""I think it will defaultly delete the old relation list and insert the new ones. \r\nWhat's the case will it not be deleted?"", 'commenter': 'caishunfeng'}, {'comment': 'When adding a task definition, the association of all workflow task definitions will be cleared. This is wrong\r\n\r\n', 'commenter': 'jinyanhui2008'}]"
12152,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/task/CommonTaskProcessor.java,"@@ -122,17 +122,17 @@ public boolean dispatchTask() {
 
             TaskExecutionContext taskExecutionContext = getTaskExecutionContext(taskInstance);
             if (taskExecutionContext == null) {
-                logger.error(""task get taskExecutionContext fail: {}"", taskInstance);
+                logger.error(""Get taskExecutionContext fail, task: {}"", taskInstance);
                 return false;
             }
 
             taskPriority.setTaskExecutionContext(taskExecutionContext);
 
             taskUpdateQueue.put(taskPriority);
-            logger.info(""Master submit task to priority queue success, taskInstanceId : {}"", taskInstance.getId());
+            logger.info(""Task {} is submitted to priority queue success by master"", taskInstance.getName());
             return true;
         } catch (Exception e) {
-            logger.error(""submit task error"", e);
+            logger.info(""Task {} is submitted to priority queue error"", taskInstance.getName(), e);","[{'comment': '```suggestion\r\n            logger.error(""Task {} is submitted to priority queue error"", taskInstance.getName(), e);\r\n```', 'commenter': 'caishunfeng'}]"
12152,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -159,8 +159,10 @@ private void notifyProcessChanged(ProcessInstance finishProcessInstance) {
             TaskInstance taskInstance = entry.getValue();
             String address = NetUtils.getAddr(masterConfig.getListenPort());
             if (processInstance.getHost().equalsIgnoreCase(address)) {
+                logger.info(""Process host is local master, will notify it"");","[{'comment': 'add taskInstanceId and workflowId', 'commenter': 'caishunfeng'}]"
12152,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -159,8 +159,10 @@ private void notifyProcessChanged(ProcessInstance finishProcessInstance) {
             TaskInstance taskInstance = entry.getValue();
             String address = NetUtils.getAddr(masterConfig.getListenPort());
             if (processInstance.getHost().equalsIgnoreCase(address)) {
+                logger.info(""Process host is local master, will notify it"");
                 this.notifyMyself(processInstance, taskInstance);
             } else {
+                logger.info(""Process host is remote master, will notify it"");","[{'comment': 'same here', 'commenter': 'caishunfeng'}]"
12158,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/EnvironmentService.java,"@@ -50,7 +50,7 @@ public interface EnvironmentService {
      *
      * @param code environment code
      */
-    Map<String, Object> queryEnvironmentByCode(Long code);
+    Result queryEnvironmentByCode(Long code);","[{'comment': '```suggestion\r\n    Environment queryEnvironmentByCode(Long code);\r\n```\r\n\r\nPlease remove the Result in service.', 'commenter': 'ruanwenjun'}]"
12158,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/EnvironmentServiceImpl.java,"@@ -106,8 +106,8 @@ public Map<String, Object> createEnvironment(User loginUser, String name, String
             putMsg(result, Status.DESCRIPTION_TOO_LONG_ERROR);
             return result;
         }
-        Map<String, Object> checkResult = checkParams(name, config, workerGroups);
-        if (checkResult.get(Constants.STATUS) != Status.SUCCESS) {
+        Result checkResult = checkParams(name, config, workerGroups);
+        if (checkResult.getCode() != Status.SUCCESS.getCode()) {","[{'comment': 'We can directly throw ServiceException in service, use Result is not convenient.', 'commenter': 'ruanwenjun'}]"
12177,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -681,6 +682,7 @@ public Result deleteProcessDefinitionByCode(@ApiIgnore @RequestAttribute(value =
     @ResponseStatus(HttpStatus.OK)
     @ApiException(BATCH_DELETE_PROCESS_DEFINE_BY_CODES_ERROR)
     @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    @Transactional","[{'comment': 'I think we should not add this annotation in controller layer.\r\nIt would better to create a batch delete method in service if we want to do that.', 'commenter': 'caishunfeng'}, {'comment': ""BTW, I don't think this batch delete action should be transactional, because different workflows are independent of each other, not an atomic relationship.\r\nWDYT? @zhongjiajie @ruanwenjun @SbloodyS "", 'commenter': 'caishunfeng'}, {'comment': ""> BTW, I don't think this batch delete action should be transactional, because different workflows are independent of each other, not an atomic relationship. WDYT? @zhongjiajie @ruanwenjun @SbloodyS\r\n\r\n+1"", 'commenter': 'SbloodyS'}]"
12183,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskDispatchProcessor.java,"@@ -95,7 +95,7 @@ public void process(Channel channel, Command command) {
             return;
         }
         final String workflowMasterAddress = taskDispatchCommand.getMessageSenderAddress();
-        logger.info(""task execute request message: {}"", taskDispatchCommand);
+        logger.info(""Receive task execute request message: {}"", taskDispatchCommand);","[{'comment': '```suggestion\r\n        logger.info(""Receive task dispatch request, command: {}"", taskDispatchCommand);\r\n```', 'commenter': 'ruanwenjun'}]"
12183,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskExecuteResultAckProcessor.java,"@@ -54,7 +54,7 @@ public void process(Channel channel, Command command) {
             logger.error(""task execute response ack command is null"");
             return;
         }
-        logger.info(""task execute response ack command : {}"", taskExecuteAckMessage);
+        logger.info(""Receive task execute response ack command : {}"", taskExecuteAckMessage);","[{'comment': 'Please move this log after `LoggerUtils.setTaskInstanceIdMDC(taskExecuteAckMessage.getTaskInstanceId());`\r\nThis will add traceId in log header.', 'commenter': 'ruanwenjun'}]"
12183,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskRejectAckProcessor.java,"@@ -47,8 +47,11 @@ public void process(Channel channel, Command command) {
         TaskRejectAckCommand taskRejectAckMessage = JSONUtils.parseObject(command.getBody(),
                 TaskRejectAckCommand.class);
         if (taskRejectAckMessage == null) {
+            logger.warn(""Task reject response ack command is null"");
             return;
         }
+
+        logger.info(""Receive task reject response ack command: {}"", taskRejectAckMessage);","[{'comment': 'Move this log after\r\n```\r\nLoggerUtils.setTaskInstanceIdMDC(taskRejectAckMessage.getTaskInstanceId());\r\n```', 'commenter': 'ruanwenjun'}]"
12183,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskSavePointProcessor.java,"@@ -76,9 +77,14 @@ public void process(Channel channel, Command command) {
             return;
         }
 
-        doSavePoint(taskInstanceId);
+        try {
+            LoggerUtils.setTaskInstanceIdMDC(taskSavePointRequestCommand.getTaskInstanceId());","[{'comment': '```suggestion\r\n            LoggerUtils.setTaskInstanceIdMDC(taskInstanceId);\r\n```', 'commenter': 'ruanwenjun'}]"
12183,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/processor/TaskRejectAckProcessor.java,"@@ -47,8 +47,11 @@ public void process(Channel channel, Command command) {
         TaskRejectAckCommand taskRejectAckMessage = JSONUtils.parseObject(command.getBody(),
                 TaskRejectAckCommand.class);
         if (taskRejectAckMessage == null) {
+            logger.warn(""Task reject response ack command is null"");","[{'comment': '```suggestion\r\n            logger.error(""Receive task reject response, the response message is null"");\r\n```', 'commenter': 'ruanwenjun'}]"
12183,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/runner/WorkerManagerThread.java,"@@ -93,6 +93,7 @@ public void killTaskBeforeExecuteByInstanceId(Integer taskInstanceId) {
 
     public boolean offer(WorkerDelayTaskExecuteRunnable workerDelayTaskExecuteRunnable) {
         if (waitSubmitQueue.size() > workerExecThreads) {
+            logger.info(""Wait submit queue is full, will retry submit task later"");","[{'comment': '```suggestion\r\n            logger.warn(""Wait submit queue is full, will retry submit task later"");\r\n```', 'commenter': 'ruanwenjun'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    /**
+     * flag to indicate whether print debug logs
+     */
+    private static final String PARA_NAME_ASPECTJ_DEBUG = ""PARA_NAME_ASPECTJ_DEBUG"";
+
+    /**
+     * The current application report when application submitted successfully
+     */
+    private ApplicationReport currentApplicationReport = null;
+
+    private String appInfoFilePath;
+    private boolean debug;
+
+    public YarnClientAspect() {
+        appInfoFilePath = System.getProperty(""user.dir"") + ""/appInfo.log"";
+        debug = Boolean.parseBoolean(System.getenv(PARA_NAME_ASPECTJ_DEBUG));","[{'comment': 'should we put this variable ```PARA_NAME_ASPECTJ_DEBUG``` into common.properties?', 'commenter': 'fuchanghai'}, {'comment': '> should we put this variable `PARA_NAME_ASPECTJ_DEBUG` into common.properties?\r\n\r\nAFAIK, `PARA_NAME_ASPECTJ_DEBUG` can not be read if put in common.properties, because task and aop code runs in another JVM and different JVM can not share properties in normal way.', 'commenter': 'Radeity'}, {'comment': ""if he depends on the common module, it can be solved. I think this variable must be configurable and cannot be configured by modifying the code. if above cann't fits your needs.We should prioritize using the configuration file in this module. Welcome to give your feedback any comments"", 'commenter': 'fuchanghai'}, {'comment': ""`PARA_NAME_ASPECTJ_DEBUG` is now configured in `dolphinscheduler_env.sh`. Actually, i'm considering about the configuration `appId.file.path` which i've already added into common.properties(default value is '/appInfo.log'), however, it's hard coded now in the above aop code. I'll try to optimize this part of code."", 'commenter': 'Radeity'}]"
12197,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/FileUtils.java,"@@ -17,12 +17,7 @@
 
 package org.apache.dolphinscheduler.common.utils;
 
-import static org.apache.dolphinscheduler.common.Constants.DATA_BASEDIR_PATH;
-import static org.apache.dolphinscheduler.common.Constants.FOLDER_SEPARATOR;
-import static org.apache.dolphinscheduler.common.Constants.RESOURCE_VIEW_SUFFIXES;
-import static org.apache.dolphinscheduler.common.Constants.RESOURCE_VIEW_SUFFIXES_DEFAULT_VALUE;
-import static org.apache.dolphinscheduler.common.Constants.UTF_8;
-import static org.apache.dolphinscheduler.common.Constants.YYYYMMDDHHMMSS;
+import static org.apache.dolphinscheduler.common.Constants.*;","[{'comment': 'should we avoid to use ```.*```?', 'commenter': 'fuchanghai'}, {'comment': ""> should we avoid to use `.*`?\r\n\r\nThanks, i'll modify them later!"", 'commenter': 'Radeity'}]"
12197,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/FileUtils.java,"@@ -119,7 +126,7 @@ public static String getResourceViewSuffixes() {
      * @throws IOException errors
      */
     public static void createWorkDirIfAbsent(String execLocalPath) throws IOException {
-        //if work dir exists, first delete
+        // if work dir exists, first delete","[{'comment': '```work dir``` is puzzling ，maybe we can replace that with ```work catalog``` or ```work directory```? @EricGao888 PTAL', 'commenter': 'fuchanghai'}, {'comment': ""I'd rather we just remove this line of comment. The code has indicated what it is doing here. BTW, this comment has already been away from the code, which also shows it is hard to maintain such kind of comment.\r\n\r\n```java\r\n if (execLocalPathFile.exists()) {\r\n            try {\r\n                org.apache.commons.io.FileUtils.forceDelete(execLocalPathFile);\r\n......\r\n```"", 'commenter': 'EricGao888'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    /**
+     * flag to indicate whether print debug logs
+     */
+    private static final String PARA_NAME_ASPECTJ_DEBUG = ""PARA_NAME_ASPECTJ_DEBUG"";
+
+    /**
+     * The current application report when application submitted successfully
+     */
+    private ApplicationReport currentApplicationReport = null;
+
+    private String appInfoFilePath;
+    private boolean debug;
+
+    public YarnClientAspect() {
+        appInfoFilePath = System.getProperty(""user.dir"") + ""/appInfo.log"";
+        debug = Boolean.parseBoolean(System.getenv(PARA_NAME_ASPECTJ_DEBUG));
+    }
+
+    /**
+     * Trigger submitApplication when invoking YarnClientImpl.submitApplication
+     *
+     * @param appContext     application context when invoking YarnClientImpl.submitApplication
+     * @param submittedAppId the submitted application id returned by YarnClientImpl.submitApplication
+     * @throws Throwable exceptions
+     */
+    @AfterReturning(pointcut = ""execution(ApplicationId org.apache.hadoop.yarn.client.api.impl.YarnClientImpl."" +
+            ""submitApplication(ApplicationSubmissionContext)) && args(appContext)"",
+            returning = ""submittedAppId"", argNames = ""appContext,submittedAppId"")
+    public void registerApplicationInfo(ApplicationSubmissionContext appContext, ApplicationId submittedAppId) {
+        if (appInfoFilePath != null) {
+            try {
+                Files.write(Paths.get(appInfoFilePath),
+                        Collections.singletonList(submittedAppId.toString()),
+                        StandardOpenOption.CREATE,
+                        StandardOpenOption.WRITE,
+                        StandardOpenOption.APPEND);
+            } catch (IOException ioException) {
+                System.out.println(","[{'comment': 'maybe we should  replace ```System.out``` with ```@Slf4j``` ', 'commenter': 'fuchanghai'}, {'comment': 'System.err is another option', 'commenter': 'gabrywu'}]"
12197,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/utils/TaskExecutionCheckerUtils.java,"@@ -75,14 +75,14 @@ public static void checkTenantExist(WorkerConfig workerConfig, TaskExecutionCont
     public static void createProcessLocalPathIfAbsent(TaskExecutionContext taskExecutionContext) throws TaskException {
         try {
             // local execute path
-            String execLocalPath = FileUtils.getProcessExecDir(
-                    taskExecutionContext.getProjectCode(),
-                    taskExecutionContext.getProcessDefineCode(),
-                    taskExecutionContext.getProcessDefineVersion(),
-                    taskExecutionContext.getProcessInstanceId(),
-                    taskExecutionContext.getTaskInstanceId());
-            taskExecutionContext.setExecutePath(execLocalPath);
-            FileUtils.createWorkDirIfAbsent(execLocalPath);
+            // String execLocalPath = FileUtils.getProcessExecDir(
+            // taskExecutionContext.getProjectCode(),
+            // taskExecutionContext.getProcessDefineCode(),
+            // taskExecutionContext.getProcessDefineVersion(),
+            // taskExecutionContext.getProcessInstanceId(),
+            // taskExecutionContext.getTaskInstanbu iceId());
+            // taskExecutionContext.setExecutePath(execLocalPath);
+            FileUtils.createWorkDirIfAbsent(taskExecutionContext.getExecutePath());","[{'comment': ""If you leave this part out, where did you set the ```execLocalPath```?\r\nplease tell me where it is set, maybe I didn't notice it"", 'commenter': 'fuchanghai'}, {'comment': '> \r\n\r\nI put it in `TaskExecutionContextBuilder` when setting some task related attribution, together with setting of `appInfoPath`.', 'commenter': 'Radeity'}, {'comment': 'Your Aspect can only intercept submissions on yarn, right? If the task is not running on yarn, is it impossible to get the execution path?', 'commenter': 'fuchanghai'}, {'comment': 'Yes, if it\'s not yarn job, aop code will not execute. However, all types of tasks will generate execution path (as well as appInfoPath) in master, so i don\'t get what you mean ""impossible to get the execution path"", would you like to explain it in detail?', 'commenter': 'Radeity'}, {'comment': '> Yes, if it\'s not yarn job, aop code will not execute. However, all types of tasks will generate execution path (as well as appInfoPath) in master, so i don\'t get what you mean ""impossible to get the execution path"", would you like to explain it in detail?\r\n\r\n@Radeity sorry ,I found where you are setting the value. I have no doubts about this piece of code', 'commenter': 'fuchanghai'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    /**
+     * flag to indicate whether print debug logs
+     */
+    private static final String PARA_NAME_ASPECTJ_DEBUG = ""PARA_NAME_ASPECTJ_DEBUG"";
+
+    /**
+     * The current application report when application submitted successfully
+     */
+    private ApplicationReport currentApplicationReport = null;
+
+    private String appInfoFilePath;
+    private boolean debug;
+
+    public YarnClientAspect() {
+        appInfoFilePath = System.getProperty(""user.dir"") + ""/appInfo.log"";
+        debug = Boolean.parseBoolean(System.getenv(PARA_NAME_ASPECTJ_DEBUG));
+    }
+
+    /**
+     * Trigger submitApplication when invoking YarnClientImpl.submitApplication
+     *
+     * @param appContext     application context when invoking YarnClientImpl.submitApplication
+     * @param submittedAppId the submitted application id returned by YarnClientImpl.submitApplication
+     * @throws Throwable exceptions
+     */
+    @AfterReturning(pointcut = ""execution(ApplicationId org.apache.hadoop.yarn.client.api.impl.YarnClientImpl."" +
+            ""submitApplication(ApplicationSubmissionContext)) && args(appContext)"",
+            returning = ""submittedAppId"", argNames = ""appContext,submittedAppId"")
+    public void registerApplicationInfo(ApplicationSubmissionContext appContext, ApplicationId submittedAppId) {
+        if (appInfoFilePath != null) {
+            try {
+                Files.write(Paths.get(appInfoFilePath),
+                        Collections.singletonList(submittedAppId.toString()),
+                        StandardOpenOption.CREATE,
+                        StandardOpenOption.WRITE,
+                        StandardOpenOption.APPEND);
+            } catch (IOException ioException) {
+                System.out.println(
+                        ""YarnClientAspect[registerAppInfo]: can't output current application information, because ""
+                                + ioException.getMessage());
+            }
+        }
+        if (debug) {
+            System.out.println(""YarnClientAspect[submitApplication]: current application context "" + appContext);
+            System.out.println(""YarnClientAspect[submitApplication]: submitted application id "" + submittedAppId);
+            System.out.println(
+                    ""YarnClientAspect[submitApplication]: current application report  "" + currentApplicationReport);
+        }
+    }
+
+    /**
+     * Trigger getAppReport only when invoking getApplicationReport within submitApplication
+     * This method will invoke many times, however, the last ApplicationReport instance assigned to currentApplicationReport
+     *
+     * @param appReport current application report when invoking getApplicationReport within submitApplication
+     * @param appId     current application id, which is the parameter of getApplicationReport
+     * @throws Throwable exceptions
+     */
+    @AfterReturning(pointcut = ""cflow(execution(ApplicationId org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.submitApplication(ApplicationSubmissionContext))) ""
+            +
+            ""&& !within(CfowAspect) && execution(ApplicationReport org.apache.hadoop.yarn.client.api.impl.YarnClientImpl.getApplicationReport(ApplicationId)) && args(appId)"", returning = ""appReport"", argNames = ""appReport,appId"")
+    public void registerApplicationReport(ApplicationReport appReport, ApplicationId appId) {","[{'comment': '## Useless parameter\n\nThe parameter appId is unused.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1580)', 'commenter': 'github-advanced-security[bot]'}]"
12197,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractYarnTask.java,"@@ -107,7 +110,7 @@ public void cancelApplication() throws TaskException {
      */
     @Override
     public List<String> getApplicationIds() throws TaskException {
-        return LogUtils.getAppIdsFromLogFile(taskRequest.getLogPath(), logger);
+        return LogUtils.getAppIds(taskRequest.getLogPath(), taskRequest.getAppInfoPath(), PropertyUtils.getString(APPID_COLLECT, ""log""));","[{'comment': 'It is recommended that the log string be added to the constant.', 'commenter': 'hstdream'}, {'comment': 'Thanks for reminding!', 'commenter': 'Radeity'}]"
12197,docs/docs/en/architecture/configuration.md,"@@ -224,6 +224,9 @@ The default configuration is as follows:
 |sudo.enable | true | whether to enable sudo|
 |alert.rpc.port | 50052 | the RPC port of Alert Server|
 |zeppelin.rest.url | http://localhost:8080 | the RESTful API url of zeppelin|
+|appId.collect | log | way to collect applicationId, if use aop, alter the configuration from log to aop|
+|appId.file.path | appInfo.log | if use aop way，the relative log path to store applicationId (suggest not to change, need to re-package aop jar file)|","[{'comment': ""If we can't change this config except that we re-build the jar, we'd better create a static field in a class. If user can build the jar, a static field is enough to change as users want."", 'commenter': 'gabrywu'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import static org.apache.dolphinscheduler.common.Constants.*;
+
+import org.apache.dolphinscheduler.common.utils.PropertyUtils;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    // public static final Logger logger = LoggerFactory.getLogger(YarnClientAspect.class);","[{'comment': 'please delete unused codes', 'commenter': 'gabrywu'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,101 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import static org.apache.dolphinscheduler.common.Constants.*;
+
+import org.apache.dolphinscheduler.common.utils.PropertyUtils;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    // public static final Logger logger = LoggerFactory.getLogger(YarnClientAspect.class);
+
+    /**
+     * The current application report when application submitted successfully
+     */
+    private ApplicationReport currentApplicationReport = null;
+
+    private String appInfoFilePath;","[{'comment': 'should be a final field', 'commenter': 'gabrywu'}]"
12197,dolphinscheduler-api-test/dolphinscheduler-api-test-case/src/test/resources/docker/file-manage/common.properties,"@@ -15,7 +15,7 @@
 # limitations under the License.
 #
 # user data local directory path, please make sure the directory exists and have read write permissions
-data.basedir.path=/tmp/dolphinscheduler
+data.basedir.path=/home/wangwr/tmp/dolphinscheduler","[{'comment': 'need to change it?', 'commenter': 'gabrywu'}]"
12197,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/utils/LogUtils.java,"@@ -44,10 +44,38 @@ public class LogUtils {
 
     private static final Pattern APPLICATION_REGEX = Pattern.compile(TaskConstants.YARN_APPLICATION_REGEX);
 
-    public List<String> getAppIdsFromLogFile(@NonNull String logPath) {
-        return getAppIdsFromLogFile(logPath, log);
+    public List<String> getAppIds(@NonNull String logPath, @NonNull String appInfoPath, String fetchWay) {
+        switch (fetchWay) {
+            case ""aop"":
+                log.info(""Start finding appId in {}, fetch way: {} "", appInfoPath);
+                return getAppIdsFromAppInfoFile(appInfoPath, log);
+            case ""log"":
+                log.info(""Start finding appId in {}, fetch way: {} "", logPath);
+                return getAppIdsFromLogFile(logPath, log);
+            default:","[{'comment': 'default is `log`', 'commenter': 'gabrywu'}]"
12197,dolphinscheduler-aop/src/test/java/org/apache/dolphinscheduler/poc/YarnClientMoc.java,"@@ -0,0 +1,23 @@
+package org.apache.dolphinscheduler.poc;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+import org.apache.hadoop.yarn.exceptions.YarnException;
+
+import java.io.IOException;
+import java.util.Random;
+
+public class YarnClientMoc {
+
+    private Random random = new Random();
+
+    public ApplicationId createAppId() {
+        ApplicationId created = ApplicationId.newInstance(System.currentTimeMillis(), random.nextInt());
+        System.out.println(""created id "" + created.getId());
+        return created;
+    }
+
+    public ApplicationId submitApplication(ApplicationSubmissionContext appContext) throws YarnException, IOException {","[{'comment': ""## Useless parameter\n\nThe parameter 'appContext' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1996)"", 'commenter': 'github-advanced-security[bot]'}]"
12197,dolphinscheduler-aop/src/test/java/org/apache/dolphinscheduler/YarnClientAspectMocTest.java,"@@ -0,0 +1,54 @@
+package org.apache.dolphinscheduler;
+
+import org.apache.dolphinscheduler.poc.YarnClientMoc;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+import org.apache.hadoop.yarn.api.records.Priority;
+import org.apache.hadoop.yarn.exceptions.YarnException;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.PrintStream;
+
+import org.junit.jupiter.api.AfterEach;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Test;
+
+public class YarnClientAspectMocTest {
+
+    private final PrintStream standardOut = System.out;
+    ByteArrayOutputStream stdoutStream = new ByteArrayOutputStream();
+    @BeforeEach
+    public void beforeEveryTest() {
+        System.setOut(new PrintStream(stdoutStream));
+    }
+    @AfterEach
+    public void afterEveryTest() throws IOException {
+        System.setOut(standardOut);
+        stdoutStream.close();
+    }
+    @Test
+    public void testMoc() {
+        YarnClientMoc moc = new YarnClientMoc();
+        try {
+            ApplicationSubmissionContext appContext = ApplicationSubmissionContext.newInstance(
+                    ApplicationId.newInstance(System.currentTimeMillis(), 1236), ""appName"",
+                    ""queue"", Priority.UNDEFINED,
+                    null, false,
+                    false, 10, null,
+                    ""type"");
+            moc.createAppId();
+            ApplicationId applicationId = moc.submitApplication(appContext);","[{'comment': ""## Unread local variable\n\nVariable 'ApplicationId applicationId' is never read.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1997)"", 'commenter': 'github-advanced-security[bot]'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,94 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    /**
+     * The current application report when application submitted successfully
+     */
+    private ApplicationReport currentApplicationReport = null;
+
+    private final String appInfoFilePath;
+    private boolean debug;
+
+    public YarnClientAspect() {
+        appInfoFilePath = String.format(""%s/%s"", System.getProperty(""user.dir""), ""appInfo.log"");
+        debug = true;
+    }
+
+    /**
+     * Trigger submitApplication when invoking YarnClientImpl.submitApplication
+     *
+     * @param appContext     application context when invoking YarnClientImpl.submitApplication
+     * @param submittedAppId the submitted application id returned by YarnClientImpl.submitApplication
+     * @throws Throwable exceptions
+     */
+    @AfterReturning(pointcut = ""execution(ApplicationId org.apache.hadoop.yarn.client.api.impl.YarnClientImpl."" +
+            ""submitApplication(ApplicationSubmissionContext)) && args(appContext)"", returning = ""submittedAppId"", argNames = ""appContext,submittedAppId"")
+    public void registerApplicationInfo(ApplicationSubmissionContext appContext, ApplicationId submittedAppId) {
+        if (appInfoFilePath != null) {
+            try {
+                Files.write(Paths.get(appInfoFilePath),
+                        Collections.singletonList(submittedAppId.toString()),
+                        StandardOpenOption.CREATE,
+                        StandardOpenOption.WRITE,
+                        StandardOpenOption.APPEND);
+            } catch (IOException ioException) {
+                System.err.println(
+                        ""YarnClientAspect[registerAppInfo]: can't output current application information, because ""
+                                + ioException.getMessage());","[{'comment': 'Please using `logger.error` instead of stdout.', 'commenter': 'SbloodyS'}]"
12197,dolphinscheduler-aop/src/main/java/org/apache/dolphinscheduler/aop/YarnClientAspect.java,"@@ -0,0 +1,94 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.aop;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationReport;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+
+import java.io.IOException;
+import java.nio.file.Files;
+import java.nio.file.Paths;
+import java.nio.file.StandardOpenOption;
+import java.util.Collections;
+
+import org.aspectj.lang.annotation.AfterReturning;
+import org.aspectj.lang.annotation.Aspect;
+
+@Aspect
+public class YarnClientAspect {
+
+    /**
+     * The current application report when application submitted successfully
+     */
+    private ApplicationReport currentApplicationReport = null;
+
+    private final String appInfoFilePath;
+    private boolean debug;
+
+    public YarnClientAspect() {
+        appInfoFilePath = String.format(""%s/%s"", System.getProperty(""user.dir""), ""appInfo.log"");
+        debug = true;
+    }
+
+    /**
+     * Trigger submitApplication when invoking YarnClientImpl.submitApplication
+     *
+     * @param appContext     application context when invoking YarnClientImpl.submitApplication
+     * @param submittedAppId the submitted application id returned by YarnClientImpl.submitApplication
+     * @throws Throwable exceptions
+     */
+    @AfterReturning(pointcut = ""execution(ApplicationId org.apache.hadoop.yarn.client.api.impl.YarnClientImpl."" +
+            ""submitApplication(ApplicationSubmissionContext)) && args(appContext)"", returning = ""submittedAppId"", argNames = ""appContext,submittedAppId"")
+    public void registerApplicationInfo(ApplicationSubmissionContext appContext, ApplicationId submittedAppId) {
+        if (appInfoFilePath != null) {
+            try {
+                Files.write(Paths.get(appInfoFilePath),
+                        Collections.singletonList(submittedAppId.toString()),
+                        StandardOpenOption.CREATE,
+                        StandardOpenOption.WRITE,
+                        StandardOpenOption.APPEND);
+            } catch (IOException ioException) {
+                System.err.println(
+                        ""YarnClientAspect[registerAppInfo]: can't output current application information, because ""
+                                + ioException.getMessage());
+            }
+        }
+        if (debug) {
+            System.out.println(""YarnClientAspect[submitApplication]: current application context "" + appContext);
+            System.out.println(""YarnClientAspect[submitApplication]: submitted application id "" + submittedAppId);
+            System.out.println(","[{'comment': 'Same here.', 'commenter': 'SbloodyS'}]"
12197,dolphinscheduler-aop/src/test/java/org/apache/dolphinscheduler/YarnClientAspectMocTest.java,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler;
+
+import org.apache.dolphinscheduler.poc.YarnClientMoc;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+import org.apache.hadoop.yarn.api.records.Priority;
+import org.apache.hadoop.yarn.exceptions.YarnException;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.PrintStream;
+
+import org.junit.jupiter.api.AfterEach;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Test;
+
+public class YarnClientAspectMocTest {
+
+    private final PrintStream standardOut = System.out;
+    ByteArrayOutputStream stdoutStream = new ByteArrayOutputStream();
+    @BeforeEach
+    public void beforeEveryTest() {
+        System.setOut(new PrintStream(stdoutStream));
+    }
+    @AfterEach
+    public void afterEveryTest() throws IOException {
+        System.setOut(standardOut);
+        stdoutStream.close();
+    }
+    @Test
+    public void testMoc() {
+        YarnClientMoc moc = new YarnClientMoc();
+        try {
+            ApplicationSubmissionContext appContext = ApplicationSubmissionContext.newInstance(
+                    ApplicationId.newInstance(System.currentTimeMillis(), 1236), ""appName"",
+                    ""queue"", Priority.UNDEFINED,
+                    null, false,
+                    false, 10, null,
+                    ""type"");
+            moc.createAppId();
+            ApplicationId applicationId = moc.submitApplication(appContext);
+            String stdoutContent = stdoutStream.toString();
+            Assertions.assertTrue(stdoutContent.contains(""YarnClientAspectMoc[submitApplication]""),
+                    ""trigger YarnClientAspectMoc.submitApplication failed"");
+            Assertions.assertTrue(stdoutContent.contains(""YarnClientAspectMoc[createAppId]:""),
+                    ""trigger YarnClientAspectMoc.createAppId failed"");
+        } catch (YarnException | IOException e) {
+            Assertions.fail(""test YarnClientAspectMoc failed: "" + e.getMessage());
+            e.printStackTrace();","[{'comment': 'Please using `logger.error` instead of this.', 'commenter': 'SbloodyS'}]"
12197,dolphinscheduler-aop/src/test/java/org/apache/dolphinscheduler/poc/YarnClientMoc.java,"@@ -0,0 +1,40 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.poc;
+
+import org.apache.hadoop.yarn.api.records.ApplicationId;
+import org.apache.hadoop.yarn.api.records.ApplicationSubmissionContext;
+import org.apache.hadoop.yarn.exceptions.YarnException;
+
+import java.io.IOException;
+import java.util.Random;
+
+public class YarnClientMoc {
+
+    private Random random = new Random();
+
+    public ApplicationId createAppId() {
+        ApplicationId created = ApplicationId.newInstance(System.currentTimeMillis(), random.nextInt());
+        System.out.println(""created id "" + created.getId());","[{'comment': 'Please using `logger.info` instead of this.', 'commenter': 'SbloodyS'}]"
12197,dolphinscheduler-aop/pom.xml,"@@ -0,0 +1,91 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <artifactId>dolphinscheduler</artifactId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+    <artifactId>dolphinscheduler-aop</artifactId>
+    <packaging>jar</packaging>
+    <name>${project.artifactId}</name>
+    <description>aop 4 YarnClient to get application id when submitting jars using 'yarn jar mainClass args'</description>
+
+    <properties>
+        <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+        <maven.compiler.source>1.8</maven.compiler.source>
+        <maven.compiler.target>1.8</maven.compiler.target>
+        <aspectj.version>1.9.7</aspectj.version>
+        <hadoop.version>3.2.4</hadoop.version>","[{'comment': 'Should move to bom module.', 'commenter': 'caishunfeng'}]"
12207,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessTaskRelationMapper.xml,"@@ -200,7 +200,11 @@
             and post_task_code = #{postTaskCode}
         </if>
     </select>
-
+    <select id=""queryByWorkGroupName"" resultType=""org.apache.dolphinscheduler.dao.entity.ProcessTaskRelation"">
+        select
+            relation.id
+        from t_ds_process_task_relation relation, t_ds_task_definition_log log where
+        log.code = relation.post_task_code and log.worker_group = #{workerGroupName}","[{'comment': 'It looks miss `</select>`, Why not query `t_ds_task_definition_log` directly?', 'commenter': 'caishunfeng'}, {'comment': 'When user delete workerGroup, is it better to check references in `t_ds_task_definition`, but not `t_ds_task_definition_log`? \r\nIf just the old version taskDefinition has this references, can it allow to delete?\r\n\r\ncc @ruanwenjun @SbloodyS ', 'commenter': 'caishunfeng'}]"
12219,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/DateUtils.java,"@@ -575,6 +575,12 @@ public static long getRemainTime(Date baseTime, long intervalSeconds) {
             return 0;
         }
         long usedTime = (System.currentTimeMillis() - baseTime.getTime()) / 1000;
+        // ignore worker's clock later than master nodes.","[{'comment': ""It's better don't add this in this method, this is Utils. And I don't think we need to deal with this, we only need to announce the clock should sync in master/worker, since this change don't solve the problem when the clock is not sync."", 'commenter': 'ruanwenjun'}, {'comment': ""> It's better don't add this in this method, this is Utils. And I don't think we need to deal with this, we only need to announce the clock should sync in master/worker, since this change don't solve the problem when the clock is not sync.\r\n\r\nyes, i agree with u. I also agree that there is no good way to deal with clock inconsistencies between clusters. just add doc should be enough."", 'commenter': 'DarkAssassinator'}]"
12219,dolphinscheduler-common/src/test/java/org/apache/dolphinscheduler/common/utils/DateUtilsTest.java,"@@ -297,4 +297,5 @@ public void testTimeStampToDate() {
         Date date = DateUtils.timeStampToDate(0L);
         Assert.assertNull(date);
     }
+","[{'comment': 'Should we remove this unrelated change here?', 'commenter': 'zhongjiajie'}, {'comment': 'sure. done', 'commenter': 'DarkAssassinator'}]"
12219,docs/docs/zh/about/hardware.md,"@@ -45,3 +45,6 @@ DolphinScheduler正常运行提供如下的网络端口配置：
 ## 4. 客户端 Web 浏览器要求
 
 DolphinScheduler 推荐 Chrome 以及使用 Chromium 内核的较新版本浏览器访问前端可视化操作界面
+
+## 5. 时钟同步","[{'comment': 'BTW, we should remove the prefix number `5.` here. Best practices of markdown and many markdown lint requests avoid it.\r\n\r\nplease also remove other leading number prefix in markdown title', 'commenter': 'zhongjiajie'}, {'comment': 'done ', 'commenter': 'DarkAssassinator'}]"
12297,docs/docs/en/DSIP.md,"@@ -27,7 +27,7 @@ Current DSIPs including all DSIP still work-in-progress, you could see in [curre
 
 Past DSIPs including all DSIP already done or retired for some reason, you could see in [past DSIPs][past-DSIPs]
 
-## DSIP Process
+## DSIP Workflow","[{'comment': 'Wrong change\r\n```suggestion\r\n## DSIP Process\r\n```', 'commenter': 'zhongjiajie'}]"
12297,docs/docs/en/architecture/cache.md,"@@ -2,9 +2,9 @@
 
 ## Purpose
 
-Due to the large database read operations during the master-server scheduling process. Such as read tables like `tenant`, `user`, `processDefinition`, etc. Operations stress read pressure to the DB, and slow down the entire core scheduling process.
+Due to the large database read operations during the master-server scheduling workflow. Such as read tables like `tenant`, `user`, `processDefinition`, etc. Operations stress read pressure to the DB, and slow down the entire core scheduling workflow.","[{'comment': 'I think this content also should not change. Am I right @caishunfeng ', 'commenter': 'zhongjiajie'}, {'comment': '@caishunfeng Please confirm whether it needs to be modified', 'commenter': 'wushanru'}, {'comment': ""Yes,  shouldn't change it."", 'commenter': 'caishunfeng'}]"
12297,docs/docs/en/architecture/design.md,"@@ -55,7 +55,7 @@
 
   - **WorkerManagerThread** is mainly responsible for the submission of the task queue, continuously receives tasks from the task queue, and submits them to the thread pool for processing;
 
-  - **TaskExecuteThread** is mainly responsible for the process of task execution, and the actual processing of tasks according to different task types;
+  - **TaskExecuteThread** is mainly responsible for the workflow of task execution, and the actual processing of tasks according to different task types;","[{'comment': 'personally think this should not change too', 'commenter': 'zhongjiajie'}, {'comment': '@zhongjiajie Please confirm whether it needs to be modified, thank you', 'commenter': 'wushanru'}, {'comment': ""No, shouldn't change it. Keep it as `process`."", 'commenter': 'EricGao888'}, {'comment': ""> No, shouldn't change it. Keep it as `process`.\r\nOK, I understand\r\n"", 'commenter': 'wushanru'}]"
12309,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/parser/TimePlaceholderUtils.java,"@@ -18,35 +18,7 @@
 package org.apache.dolphinscheduler.plugin.task.api.parser;
 
 import static org.apache.commons.lang3.time.DateUtils.addWeeks;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.ADD_CHAR;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.ADD_MONTHS;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.ADD_STRING;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.COMMA;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.DIVISION_CHAR;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.DIVISION_STRING;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.HYPHEN;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.LAST_DAY;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.LEFT_BRACE_CHAR;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.LEFT_BRACE_STRING;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.MONTH_BEGIN;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.MONTH_END;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.MONTH_FIRST_DAY;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.MONTH_LAST_DAY;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.MULTIPLY_CHAR;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.MULTIPLY_STRING;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.N;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.P;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.PARAMETER_FORMAT_TIME;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.RIGHT_BRACE_CHAR;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.SUBTRACT_CHAR;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.SUBTRACT_STRING;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.THIS_DAY;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.TIMESTAMP;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.WEEK_BEGIN;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.WEEK_END;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.WEEK_FIRST_DAY;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.WEEK_LAST_DAY;
-import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.YEAR_WEEK;
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.*;","[{'comment': 'Please avoid import *', 'commenter': 'SbloodyS'}]"
12328,dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/AlertDaoTest.java,"@@ -23,8 +23,8 @@
 
 import java.util.List;
 
-import org.junit.Assert;
-import org.junit.Test;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
 import org.junit.runner.RunWith;","[{'comment': 'We need to remove this, use `ExtendWith` instead as stated in #12301 SOP.', 'commenter': 'EricGao888'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
12328,dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/upgrade/WorkerGroupDaoTest.java,"@@ -25,7 +25,8 @@
 
 import javax.sql.DataSource;
 
-import org.junit.Test;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
 import org.junit.runner.RunWith;","[{'comment': 'Same as above', 'commenter': 'EricGao888'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
12328,dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/upgrade/WorkerGroupDaoTest.java,"@@ -47,14 +45,15 @@
 
         Map<Integer, String> workerGroupMap = workerGroupDao.queryAllOldWorkerGroup(dataSource.getConnection());
 
-        assertThat(workerGroupMap.size(), greaterThanOrEqualTo(0));
+        Assertions.assertTrue(workerGroupMap.size() >= 0);","[{'comment': '## Useless comparison test\n\nTest is always true.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1707)', 'commenter': 'github-advanced-security[bot]'}, {'comment': '## Container size compared to zero\n\nThis expression is always true, since a map can never have negative size.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/1708)', 'commenter': 'github-advanced-security[bot]'}, {'comment': 'done', 'commenter': 'fuchanghai'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
12340,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/SchedulerController.java,"@@ -158,7 +158,7 @@ public Result updateSchedule(@ApiIgnore @RequestAttribute(value = SESSION_USER)
                                  @PathVariable(value = ""id"") Integer id,
                                  @RequestParam(value = ""schedule"") String schedule,
                                  @RequestParam(value = ""warningType"", required = false, defaultValue = DEFAULT_WARNING_TYPE) WarningType warningType,
-                                 @RequestParam(value = ""warningGroupId"", required = false) int warningGroupId,
+                                 @RequestParam(value = ""warningGroupId"", required = false, defaultValue = DEFAULT_NOTIFY_GROUP_ID) int warningGroupId,","[{'comment': ""if value of ```warningType``` is ```WarningType .NONE``` , value of ```warningGroupId``` should be null. so i don't think ```warningGroupId``` be point default value. maybe we should change the type of ```warningGroupId``` to Integer .WDYT? cc @SbloodyS @EricGao888 @caishunfeng "", 'commenter': 'fuchanghai'}, {'comment': ""> if value of `warningType` is `WarningType .NONE` , value of `warningGroupId` should be null. so i don't think `warningGroupId` be point default value. maybe we should change the type of `warningGroupId` to Integer .WDYT? cc @SbloodyS @EricGao888 @caishunfeng\r\n\r\nthis seems like had been fixed #11774 "", 'commenter': 'fuchanghai'}, {'comment': 'Please note different file name, this is \'SchedulerController.java"", that is \'ExecutorController.java\'', 'commenter': 'zuzuviewer'}, {'comment': '> Please note different file name, this is \'SchedulerController.java"", that is \'ExecutorController.java\'\r\n\r\nsorry ,but  i don\'t think ```warningGroupId``` should  be pointed default value', 'commenter': 'fuchanghai'}, {'comment': ""> if value of `warningType` is `WarningType .NONE` , value of `warningGroupId` should be null. so i don't think `warningGroupId` be point default value. maybe we should change the type of `warningGroupId` to Integer .WDYT? cc @SbloodyS @EricGao888 @caishunfeng\r\n\r\n@zuzuviewer  i think  change the type of ```warningGroupId``` to Integer is a good way , WDYT? cc @SbloodyS @EricGao888 "", 'commenter': 'fuchanghai'}, {'comment': ""> if value of `warningType` is `WarningType .NONE` , value of `warningGroupId` should be null. so i don't think `warningGroupId` be point default value. maybe we should change the type of `warningGroupId` to Integer .WDYT? cc @SbloodyS @EricGao888 @caishunfeng\r\n\r\nI agree with that, we should still make `warningGroupId` optional"", 'commenter': 'zhongjiajie'}]"
12379,dolphinscheduler-dist/release-docs/LICENSE,"@@ -377,6 +377,7 @@ The text of each license is also included at licenses/LICENSE-[project].txt.
     spring-context-support 5.3.13: https://mvnrepository.com/artifact/org.springframework/spring-context-support/5.3.13, Apache 2.0
     spring-core 5.3.22: https://mvnrepository.com/artifact/org.springframework/spring-core/5.3.22, Apache 2.0
     spring-expression 5.3.13: https://mvnrepository.com/artifact/org.springframework/spring-expression/5.3.13, Apache 2.0
+    springdoc-openapi-ui 1.6.9: https://mvnrepository.com/artifact/org.springdoc/springdoc-openapi-ui/1.6.9, Apache 2.0","[{'comment': 'Please remove the license announce your delete and update the version you upgrade.', 'commenter': 'ruanwenjun'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
12379,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/OpenAPIConfiguration.java,"@@ -16,107 +16,47 @@
  */
 package org.apache.dolphinscheduler.api.configuration;
 
-import springfox.documentation.builders.ApiInfoBuilder;
-import springfox.documentation.builders.PathSelectors;
-import springfox.documentation.builders.RequestHandlerSelectors;
-import springfox.documentation.service.ApiInfo;
-import springfox.documentation.spi.DocumentationType;
-import springfox.documentation.spring.web.plugins.Docket;
-import springfox.documentation.spring.web.plugins.WebFluxRequestHandlerProvider;
-import springfox.documentation.spring.web.plugins.WebMvcRequestHandlerProvider;
 
-import java.lang.reflect.Field;
-import java.util.List;
-import java.util.stream.Collectors;
 
-import org.springframework.beans.BeansException;
-import org.springframework.beans.factory.config.BeanPostProcessor;
+import io.swagger.v3.oas.models.OpenAPI;
+import io.swagger.v3.oas.models.info.Info;
+import org.springdoc.core.GroupedOpenApi;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;
 import org.springframework.context.annotation.Bean;
 import org.springframework.context.annotation.Configuration;
 import org.springframework.context.annotation.PropertySource;
-import org.springframework.util.ReflectionUtils;
 import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;
-import org.springframework.web.servlet.mvc.method.RequestMappingInfoHandlerMapping;
 
 /**
- *
  * swager2 config class
- *
  */
 @Configuration
 @ConditionalOnWebApplication
 @PropertySource(""classpath:swagger.properties"")
 public class OpenAPIConfiguration implements WebMvcConfigurer {
 
     @Bean
-    public Docket createV1RestApi() {
-        return new Docket(DocumentationType.OAS_30)
-                .groupName(""v1(current)"")
-                .apiInfo(apiV1Info())
-                .select()
-                .apis(RequestHandlerSelectors.basePackage(""org.apache.dolphinscheduler.api.controller""))
-                .paths(PathSelectors.any().and(PathSelectors.ant(""/v2/**"").negate()))
-                .build();
-    }
-
-    private ApiInfo apiV1Info() {
-        return new ApiInfoBuilder()
-                .title(""Dolphin Scheduler Api Docs"")
-                .description(""Dolphin Scheduler Api Docs"")
-                .version(""V1"")
-                .build();
+    public OpenAPI apiV1Info1() {
+        return new OpenAPI()
+                .info(new Info()
+                        .title(""Dolphin Scheduler Api Docs"")
+                        .description(""Dolphin Scheduler Api Docs"")
+                        .version(""V1""));
     }
 
     @Bean
-    public Docket createV2RestApi() {
-        return new Docket(DocumentationType.OAS_30)
-                .groupName(""v2"")
-                .apiInfo(apiV2Info())
-                .select()
-                .apis(RequestHandlerSelectors.basePackage(""org.apache.dolphinscheduler.api.controller""))
-                .paths(PathSelectors.any().and(PathSelectors.ant(""/v2/**"")))
-                .build();
-    }
-
-    private ApiInfo apiV2Info() {
-        return new ApiInfoBuilder()
-                .title(""Dolphin Scheduler Api Docs"")
-                .description(""Dolphin Scheduler Api Docs"")
-                .version(""V2"")
+    public GroupedOpenApi publicApi1() {
+        return GroupedOpenApi.builder()
+                .group(""v1"")
+                .pathsToMatch(""/**"")","[{'comment': '```suggestion\r\n               .pathsToExclude(""v2/**"")\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'thx for you recommend ,but  in my local  ``` /v2/**``` is right. and i had fixed', 'commenter': 'fuchanghai'}]"
12379,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/configuration/OpenAPIConfiguration.java,"@@ -16,107 +16,47 @@
  */
 package org.apache.dolphinscheduler.api.configuration;
 
-import springfox.documentation.builders.ApiInfoBuilder;
-import springfox.documentation.builders.PathSelectors;
-import springfox.documentation.builders.RequestHandlerSelectors;
-import springfox.documentation.service.ApiInfo;
-import springfox.documentation.spi.DocumentationType;
-import springfox.documentation.spring.web.plugins.Docket;
-import springfox.documentation.spring.web.plugins.WebFluxRequestHandlerProvider;
-import springfox.documentation.spring.web.plugins.WebMvcRequestHandlerProvider;
 
-import java.lang.reflect.Field;
-import java.util.List;
-import java.util.stream.Collectors;
 
-import org.springframework.beans.BeansException;
-import org.springframework.beans.factory.config.BeanPostProcessor;
+import io.swagger.v3.oas.models.OpenAPI;
+import io.swagger.v3.oas.models.info.Info;
+import org.springdoc.core.GroupedOpenApi;
 import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;
 import org.springframework.context.annotation.Bean;
 import org.springframework.context.annotation.Configuration;
 import org.springframework.context.annotation.PropertySource;
-import org.springframework.util.ReflectionUtils;
 import org.springframework.web.servlet.config.annotation.WebMvcConfigurer;
-import org.springframework.web.servlet.mvc.method.RequestMappingInfoHandlerMapping;
 
 /**
- *
  * swager2 config class
- *
  */
 @Configuration
 @ConditionalOnWebApplication
 @PropertySource(""classpath:swagger.properties"")
 public class OpenAPIConfiguration implements WebMvcConfigurer {
 
     @Bean
-    public Docket createV1RestApi() {
-        return new Docket(DocumentationType.OAS_30)
-                .groupName(""v1(current)"")
-                .apiInfo(apiV1Info())
-                .select()
-                .apis(RequestHandlerSelectors.basePackage(""org.apache.dolphinscheduler.api.controller""))
-                .paths(PathSelectors.any().and(PathSelectors.ant(""/v2/**"").negate()))
-                .build();
-    }
-
-    private ApiInfo apiV1Info() {
-        return new ApiInfoBuilder()
-                .title(""Dolphin Scheduler Api Docs"")
-                .description(""Dolphin Scheduler Api Docs"")
-                .version(""V1"")
-                .build();
+    public OpenAPI apiV1Info1() {
+        return new OpenAPI()
+                .info(new Info()
+                        .title(""Dolphin Scheduler Api Docs"")
+                        .description(""Dolphin Scheduler Api Docs"")
+                        .version(""V1""));
     }
 
     @Bean
-    public Docket createV2RestApi() {
-        return new Docket(DocumentationType.OAS_30)
-                .groupName(""v2"")
-                .apiInfo(apiV2Info())
-                .select()
-                .apis(RequestHandlerSelectors.basePackage(""org.apache.dolphinscheduler.api.controller""))
-                .paths(PathSelectors.any().and(PathSelectors.ant(""/v2/**"")))
-                .build();
-    }
-
-    private ApiInfo apiV2Info() {
-        return new ApiInfoBuilder()
-                .title(""Dolphin Scheduler Api Docs"")
-                .description(""Dolphin Scheduler Api Docs"")
-                .version(""V2"")
+    public GroupedOpenApi publicApi1() {
+        return GroupedOpenApi.builder()
+                .group(""v1"")
+                .pathsToMatch(""/**"")
                 .build();
     }
 
     @Bean
-    public static BeanPostProcessor springfoxHandlerProviderBeanPostProcessor() {
-        return new BeanPostProcessor() {
-
-            @Override
-            public Object postProcessAfterInitialization(Object bean, String beanName) throws BeansException {
-                if (bean instanceof WebMvcRequestHandlerProvider || bean instanceof WebFluxRequestHandlerProvider) {
-                    customizeSpringfoxHandlerMappings(getHandlerMappings(bean));
-                }
-                return bean;
-            }
-
-            private <T extends RequestMappingInfoHandlerMapping> void customizeSpringfoxHandlerMappings(List<T> mappings) {
-                List<T> copy = mappings.stream()
-                        .filter(mapping -> mapping.getPatternParser() == null)
-                        .collect(Collectors.toList());
-                mappings.clear();
-                mappings.addAll(copy);
-            }
-
-            @SuppressWarnings(""unchecked"")
-            private List<RequestMappingInfoHandlerMapping> getHandlerMappings(Object bean) {
-                try {
-                    Field field = ReflectionUtils.findField(bean.getClass(), ""handlerMappings"");
-                    field.setAccessible(true);
-                    return (List<RequestMappingInfoHandlerMapping>) field.get(bean);
-                } catch (IllegalArgumentException | IllegalAccessException e) {
-                    throw new IllegalStateException(e);
-                }
-            }
-        };
+    public GroupedOpenApi publicApi2() {
+        return GroupedOpenApi.builder()
+                .group(""v2"")
+                .pathsToMatch(""/**"")","[{'comment': '```suggestion\r\n                .pathsToMatch(""v2/**"")\r\n```', 'commenter': 'ruanwenjun'}]"
12384,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/CuringGlobalParams.java,"@@ -157,7 +157,7 @@ public Map<String, Property> paramParsingPreparation(@NonNull TaskInstance taskI
         String timeZone = cmdParam.get(Constants.SCHEDULE_TIMEZONE);
         Map<String, String> params = BusinessTimeUtils.getBusinessTime(commandType, scheduleTime, timeZone);
 
-        if (globalParamsMap != null) {
+        if (!globalParamsMap.isEmpty()) {","[{'comment': '```suggestion\r\n        if (MapUtils.isNotEmpty(globalParamsMap.isEmpty)) {\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'ok.', 'commenter': 'hstdream'}]"
12454,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -214,6 +214,28 @@ private String getFullName(String currentDir, String name) {
                 : String.format(FORMAT_S_S, currentDir, name);
     }
 
+    private List<String> getFullNames(String currentDir, Object[] filesNameSet, Map<String, MultipartFile> fileMap) {","[{'comment': 'Suggest to use `String[] filesNameSet`, type is certain.', 'commenter': 'Radeity'}]"
12454,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -318,6 +340,128 @@ public Result<Object> createResource(User loginUser,
         return result;
     }
 
+    /**
+     * create batch resource
+     *
+     * @param loginUser  login user
+     * @param files      files
+     * @param type       type
+     * @param pid        parent id
+     * @param currentDir current directory
+     * @return create result code
+     */
+    @Override
+    @Transactional
+    public Result<Object> createBatchResources(User loginUser,
+                                               ResourceType type,
+                                               List<MultipartFile> files,
+                                               int pid,
+                                               String currentDir) {
+        Result<Object> result = new Result<>();
+        String funcPermissionKey = type.equals(ResourceType.FILE) ? ApiFuncIdentificationConstant.FILE_UPLOAD
+                : ApiFuncIdentificationConstant.UDF_UPLOAD;
+        boolean canOperatorPermissions =
+                canOperatorPermissions(loginUser, null, AuthorizationType.RESOURCE_FILE_ID, funcPermissionKey);
+        if (!canOperatorPermissions) {
+            putMsg(result, Status.NO_CURRENT_OPERATING_PERMISSION);
+            return result;
+        }
+        result = checkResourceUploadStartupState();
+        if (!result.getCode().equals(Status.SUCCESS.getCode())) {
+            return result;
+        }
+        result = verifyPid(loginUser, pid);
+        if (!result.getCode().equals(Status.SUCCESS.getCode())) {
+            return result;
+        }
+
+        // make sure login user has tenant
+        String tenantCode = getTenantCode(loginUser.getId(), result);
+        if (StringUtils.isEmpty(tenantCode)) {
+            return result;
+        }
+
+        result = verifyFiles(type, files);
+        if (!result.getCode().equals(Status.SUCCESS.getCode())) {
+            return result;
+        }
+        Map<String, MultipartFile> fileMap = files.stream().collect(Collectors.toMap(key -> key.getOriginalFilename(), value -> value, (isOld, isNew) -> isOld));
+
+        Object[] filesNameSet = fileMap.keySet().toArray();","[{'comment': 'Please change to `String[] filesNameSet = fileMap.keySet().toArray(new String[0]);`', 'commenter': 'Radeity'}]"
12454,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -655,6 +799,91 @@ private Result<Object> verifyFile(String name, ResourceType type, MultipartFile
         return result;
     }
 
+    private Result<Object> verifyFiles(ResourceType type, List<MultipartFile> files) {","[{'comment': 'Can we unify `verifyFiles` and `verifyFile`?', 'commenter': 'Radeity'}]"
12454,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/Constants.java,"@@ -24,6 +24,10 @@
 
 public final class Constants {
 
+    public static final String FILE_NAME_RESTRICTED_CONTENT= ""file.name.restricted.content"";","[{'comment': 'Please add these properties in `common.properties` and docs.', 'commenter': 'Radeity'}]"
12499,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessService.java,"@@ -78,6 +75,8 @@ ProcessInstance handleCommand(String host,
 
     ProcessDefinition findProcessDefinition(Long processDefinitionCode, int processDefinitionVersion);
 
+    List<ProcessDefinition> findProcessDefinitions(Map<Long, Integer> codeVersionMap);","[{'comment': ""Please don't add new method in `ProcessService` we will not maintain this class, you need to use ProcessDefinitionService of ProcessDefinitionLogService.\r\n```suggestion\r\n    List<ProcessDefinition> findProcessDefinitionsByProcessInstances(List<ProcessInstance> processInstances);\r\n```"", 'commenter': 'ruanwenjun'}, {'comment': 'I found that there is no `ProcessDefinitionLogService` in module `dolphinscheduler-service`.Do you mean that i need to create a new class in `dolphinscheduler-service` under package `org.apache.dolphinscheduler.service.process`?', 'commenter': 'BongBongBang'}, {'comment': 'Ok, I see the latest code, there is no `ProcessDefinitionLogService`, you can add `findProcessDefinitionsByProcessInstances(List<ProcessInstance> processInstances)` in `ProcessDefinitionDaoImpl` class.', 'commenter': 'ruanwenjun'}, {'comment': ""But how can i use this method in `MasterFailoverService`? Inject `ProcessDefinitionDaoImpl `class directly ? Does that fit in Dolphin's convention?"", 'commenter': 'BongBongBang'}, {'comment': ""OK， I see the `DAO` layer assembles the `Mapper` layer, it's kinda suitable for this purpose👌"", 'commenter': 'BongBongBang'}]"
12499,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessServiceImpl.java,"@@ -462,6 +462,40 @@ public ProcessDefinition findProcessDefinition(Long processDefinitionCode, int v
         return processDefinition;
     }
 
+    /**
+     * find a batch of process definitions by a map of <code, version>.
+     * @param codeVersionMap Map<code, version>
+     * @return
+     */
+    @Override
+    public List<ProcessDefinition> findProcessDefinitions(Map<Long, Integer> codeVersionMap) {
+        Set<Long> codes = codeVersionMap.keySet();
+        List<ProcessDefinition> processDefinitions = processDefineMapper.queryByCodes(codes);
+        Map<Long, Integer> codeVersionNeedToRetrieve = new HashMap<>();
+        codeVersionNeedToRetrieve.putAll(codeVersionMap);
+        // filter out the code/version entry that don't need to retrieve
+        processDefinitions.forEach(processDefinition -> {
+            long code = processDefinition.getCode();
+            if (codeVersionNeedToRetrieve.containsKey(code) && processDefinition.getVersion() == codeVersionNeedToRetrieve.get(code).intValue()) {
+                codeVersionNeedToRetrieve.remove(code);
+            }
+        });
+        if (!codeVersionNeedToRetrieve.isEmpty()) {
+            List<ProcessDefinition> complementProcessDefinitions = codeVersionNeedToRetrieve.entrySet()
+                    .stream()
+                    .map(entry -> {
+                        ProcessDefinition processDefinition = processDefineLogMapper.queryByDefinitionCodeAndVersion(entry.getKey(), entry.getValue());
+                        if (processDefinition != null) {
+                            processDefinition.setId(0);
+                        }
+                        return processDefinition;
+                    })
+                    .collect(Collectors.toList());
+            processDefinitions.addAll(complementProcessDefinitions);
+        }
+        return processDefinitions;","[{'comment': 'Can we directly query from `processDefineLogMapper` by using below SQL?\r\n```\r\nselect * from t_ds_process_definition_log where (code = xx and version = xx) or (code = xxx and version = xxx)\r\n```', 'commenter': 'ruanwenjun'}, {'comment': ""Yeah, got it. It's a better idea. "", 'commenter': 'BongBongBang'}]"
12506,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionLogMapper.xml,"@@ -50,6 +50,16 @@
         where code = #{code}
         and version = #{version}
     </select>
+    <select id=""queryByDefinitionCodesAndVersion"" resultType=""org.apache.dolphinscheduler.dao.entity.ProcessDefinitionLog""
+            parameterType=""org.apache.dolphinscheduler.dao.entity.ProcessInstance"">
+        select
+        <include refid=""baseSql""/>
+        from t_ds_process_definition_log
+        where
+        <foreach collection=""processInstances"" item=""item"" separator=""or"">","[{'comment': 'It should avoid the use `or` in query, because it will miss the index and query slowly.', 'commenter': 'caishunfeng'}, {'comment': ""Ok, I took this change advice from wenjun. Let me check the sql explain. If it doesn't use index in reality, we have to query `ProcessDefinitionLog` one by one here."", 'commenter': 'BongBongBang'}]"
12570,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -1472,6 +1473,8 @@ private void submitStandByTask() {
                         long failedTimeInterval = DateUtils.differSec(new Date(), retryTask.getEndTime());
                         if ((long) retryTask.getRetryInterval() * SEC_2_MINUTES_TIME_UNIT > failedTimeInterval) {
                             logger.info(""task name: {} retry waiting has not exceeded the interval time, and skip submission this time, task id:{}"", task.getName(), task.getId());
+                            readyToSubmitTaskQueue.remove(task);","[{'comment': '```suggestion\r\n                           removeTaskFromStandbyList(task);\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'No, there is no need to print the log when removing, otherwise it is easy to cause confusion', 'commenter': 'brave-lee'}]"
12570,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -1512,6 +1515,10 @@ private void submitStandByTask() {
                     logger.info(""remove task {},id:{} , because depend result : {}"", task.getName(), task.getId(), dependResult);
                 }
             }
+            for (TaskInstance task : skipSubmitInstances) {
+                readyToSubmitTaskQueue.put(task);","[{'comment': 'Why need to add back these skip task instances ?', 'commenter': 'caishunfeng'}, {'comment': 'Please see #12291', 'commenter': 'brave-lee'}]"
12576,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ResourcesServiceImpl.java,"@@ -863,41 +863,43 @@ public Map<String, Object> queryResourceList(User loginUser, ResourceType type,
         }
         String tenantCode = tenant.getTenantCode();
 
-        String defaultPath = """";
+        String defaultPath = EMPTY_STRING;
         List<StorageEntity> resourcesList = new ArrayList<>();
 
-        if (StringUtils.isBlank(fullName)) {
-            if (isAdmin(loginUser)) {
-                List<User> userList = userMapper.selectList(null);
-                Set<String> visitedTenantEntityCode = new HashSet<>();
-                for (User userEntity : userList) {
-                    Tenant tt = tenantMapper.queryById(userEntity.getTenantId());
-                    String tenantEntityCode = tenantMapper.queryById(userEntity.getTenantId()).getTenantCode();
-                    if (!visitedTenantEntityCode.contains(tenantEntityCode)) {
-                        defaultPath = storageOperate.getResDir(tenantEntityCode);
-                        if (type.equals(ResourceType.UDF)) {
-                            defaultPath = storageOperate.getUdfDir(tenantEntityCode);
+        if (PropertyUtils.getResUploadStartupState()) {","[{'comment': 'Please directly return if `PropertyUtils.getResUploadStartupState() == false`', 'commenter': 'ruanwenjun'}]"
12592,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -411,7 +411,7 @@ public enum Status {
     GET_ALERT_PLUGIN_INSTANCE_ERROR(110007, ""get alert plugin instance error"", ""获取告警组和告警组插件实例错误""),
     CREATE_ALERT_PLUGIN_INSTANCE_ERROR(110008, ""create alert plugin instance error"", ""创建告警组和告警组插件实例错误""),
     QUERY_ALL_ALERT_PLUGIN_INSTANCE_ERROR(110009, ""query all alert plugin instance error"", ""查询所有告警实例失败""),
-    PLUGIN_INSTANCE_ALREADY_EXIT(110010, ""plugin instance already exit"", ""该告警插件实例已存在""),
+    PLUGIN_INSTANCE_ALREADY_EXISTS(110010, ""plugin instance already exists"", ""该告警插件实例已存在""),
     LIST_PAGING_ALERT_PLUGIN_INSTANCE_ERROR(110011, ""query plugin instance page error"", ""分页查询告警实例失败""),","[{'comment': 'please update the UT at the same time.', 'commenter': 'DarkAssassinator'}, {'comment': 'Done', 'commenter': 'qingwli'}]"
12606,dolphinscheduler-server/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThread.java,"@@ -534,6 +534,10 @@ private boolean processComplementData() {
             scheduleDate = complementListDate.get(0);
         } else if (processInstance.getState().typeIsFinished()) {
             endProcess();
+            // rerun process instance of complement didn't need create the next process complement
+            if (processInstance.getCommandType() == CommandType.REPEAT_RUNNING) {
+                return true;
+            }","[{'comment': 'Discusstion in https://github.com/apache/dolphinscheduler/issues/12586#issuecomment-1296455628', 'commenter': 'SbloodyS'}, {'comment': ""It's a feature, not a bugfix, should not add into 2.0.x version."", 'commenter': 'caishunfeng'}]"
12636,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessDefinitionMapper.xml,"@@ -195,4 +195,17 @@
         SELECT DISTINCT(id) as project_id
         FROM t_ds_project
     </select>
+    <select id=""queryProcessDefinitionByWorkerGroupName"" resultType=""org.apache.dolphinscheduler.dao.entity.ProcessDefinition"">
+        SELECT DISTINCT
+            pd.id, pd.code, pd.name
+        FROM
+            t_ds_process_task_relation ptr
+        JOIN t_ds_process_definition pd ON ptr.process_definition_code = pd.CODE
+        AND ptr.process_definition_version = pd.version
+        AND ptr.project_code = pd.project_code
+        JOIN t_ds_task_definition td ON ( ptr.pre_task_code = td.CODE AND ptr.pre_task_version = td.version )","[{'comment': ""Please don't use join."", 'commenter': 'ruanwenjun'}, {'comment': 'Thanks for the comments, but if the workflow in the online is deleted from the workergroup, it will cause the workflow to fail to run . cc @ruanwenjun @SbloodyS @caishunfeng .', 'commenter': 'hstdream'}]"
12693,dolphinscheduler-task-plugin/dolphinscheduler-task-linkis/src/main/java/org/apache/dolphinscheduler/plugin/task/linkis/LinkisParameters.java,"@@ -0,0 +1,56 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.linkis;
+
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+
+import org.apache.commons.lang3.BooleanUtils;
+import org.apache.commons.lang3.StringUtils;
+
+import java.util.List;
+
+import lombok.Getter;
+import lombok.Setter;
+import lombok.ToString;
+
+@Getter
+@Setter
+@ToString","[{'comment': '```suggestion\r\n@Data\r\n```', 'commenter': 'caishunfeng'}]"
12693,dolphinscheduler-task-plugin/dolphinscheduler-task-linkis/src/main/java/org/apache/dolphinscheduler/plugin/task/linkis/LinkisTask.java,"@@ -0,0 +1,187 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.linkis;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.EXIT_CODE_FAILURE;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.ShellCommandExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskCallBack;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.model.TaskResponse;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+
+import org.apache.commons.lang3.BooleanUtils;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+
+/**
+ * linkis task
+ */
+public class LinkisTask extends AbstractRemoteTask {
+
+    /**
+     * linkis parameters
+     */
+    private LinkisParameters linkisParameters;
+
+    /**
+     * shell command executor
+     */
+    private ShellCommandExecutor shellCommandExecutor;
+
+    /**
+     * taskExecutionContext
+     */
+    protected final TaskExecutionContext taskExecutionContext;
+
+    /**
+     * constructor
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    public LinkisTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+
+        this.taskExecutionContext = taskExecutionContext;
+        this.shellCommandExecutor = new ShellCommandExecutor(this::logHandle,
+                taskExecutionContext,
+                logger);
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void init() {
+        logger.info(""Linkis task params {}"", taskExecutionContext.getTaskParams());
+        if (!linkisParameters.checkParameters()) {
+            throw new RuntimeException(""Linkis task params is not valid"");
+        }
+    }
+
+    // todo split handle to submit and track
+    @Override
+    public void handle(TaskCallBack taskCallBack) throws TaskException {","[{'comment': 'Please split into `submit` and `track` if this is a remote task, and then when task failover, it will not submit remote task again and just track status.', 'commenter': 'caishunfeng'}]"
12693,dolphinscheduler-task-plugin/dolphinscheduler-task-linkis/src/main/java/org/apache/dolphinscheduler/plugin/task/linkis/LinkisTask.java,"@@ -0,0 +1,248 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.linkis;
+
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.*;
+
+import org.apache.dolphinscheduler.plugin.task.api.AbstractRemoteTask;
+import org.apache.dolphinscheduler.plugin.task.api.ShellCommandExecutor;
+import org.apache.dolphinscheduler.plugin.task.api.TaskException;
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+import org.apache.dolphinscheduler.plugin.task.api.model.Property;
+import org.apache.dolphinscheduler.plugin.task.api.model.TaskResponse;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParamUtils;
+import org.apache.dolphinscheduler.plugin.task.api.parser.ParameterUtils;
+
+import org.apache.commons.lang3.BooleanUtils;
+import org.apache.commons.lang3.StringUtils;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.List;
+import java.util.Map;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+/**
+ * linkis task
+ */
+public class LinkisTask extends AbstractRemoteTask {
+
+    /**
+     * linkis parameters
+     */
+    private LinkisParameters linkisParameters;
+
+    /**
+     * shell command executor
+     */
+    private ShellCommandExecutor shellCommandExecutor;
+
+    /**
+     * taskExecutionContext
+     */
+    protected final TaskExecutionContext taskExecutionContext;
+
+    private String taskId;
+
+    protected static final Pattern LINKIS_TASK_ID_REGEX = Pattern.compile(Constants.LINKIS_TASK_ID_REGEX);
+
+    protected static final Pattern LINKIS_STATUS_REGEX = Pattern.compile(Constants.LINKIS_STATUS_REGEX);
+
+    /**
+     * constructor
+     *
+     * @param taskExecutionContext taskExecutionContext
+     */
+    public LinkisTask(TaskExecutionContext taskExecutionContext) {
+        super(taskExecutionContext);
+
+        this.taskExecutionContext = taskExecutionContext;
+        this.shellCommandExecutor = new ShellCommandExecutor(this::logHandle,
+                taskExecutionContext,
+                logger);
+    }
+
+    @Override
+    public List<String> getApplicationIds() throws TaskException {
+        return Collections.emptyList();
+    }
+
+    @Override
+    public void init() {
+        logger.info(""Linkis task params {}"", taskExecutionContext.getTaskParams());
+        if (!linkisParameters.checkParameters()) {
+            throw new RuntimeException(""Linkis task params is not valid"");
+        }
+    }
+
+    @Override
+    public void submitApplication() throws TaskException {
+        try {
+            // construct process
+            String command = buildCommand();
+            TaskResponse commandExecuteResult = shellCommandExecutor.run(command);
+            setExitStatusCode(commandExecuteResult.getExitStatusCode());
+            setAppIds(findTaskId(commandExecuteResult.getResultString()));
+            setProcessId(commandExecuteResult.getProcessId());
+            linkisParameters.dealOutParam(shellCommandExecutor.getVarPool());
+        } catch (InterruptedException e) {
+            Thread.currentThread().interrupt();
+            logger.error(""The current Linkis task has been interrupted"", e);
+            setExitStatusCode(EXIT_CODE_FAILURE);
+            throw new TaskException(""The current Linkis task has been interrupted"", e);
+        } catch (Exception e) {
+            logger.error(""Linkis task error"", e);
+            setExitStatusCode(EXIT_CODE_FAILURE);
+            throw new TaskException(""Execute Linkis task failed"", e);
+        }
+    }
+
+    @Override
+    public void trackApplicationStatus() throws TaskException {
+        initTaskId();
+        try {
+            List<String> args = new ArrayList<>();
+            args.add(Constants.SHELL_CLI_OPTIONS);
+            args.add(Constants.STATUS_OPTIONS);
+            args.add(taskId);
+            String command = String.join(Constants.SPACE, args);
+            TaskResponse commandExecuteResult = shellCommandExecutor.run(command);
+            String status = findStatus(commandExecuteResult.getResultString());
+            LinkisJobStatus jobStatus = LinkisJobStatus.convertFromJobStatusString(status);
+            switch (jobStatus) {","[{'comment': '## Missing enum case in switch\n\nSwitch statement does not have a case for [SHUTTINGDOWN](1).\nSwitch statement does not have a case for [UNKNOWN](2).\nSwitch statement does not have a case for [TIMEOUT](3).\nSwitch statement does not have a case for [RUNNING](4).\nSwitch statement does not have a case for [SCHEDULED](5).\nSwitch statement does not have a case for [WAIT_FOR_RETRY](6).\nSwitch statement does not have a case for [INITED](7).\nSwitch statement does not have a case for [SUBMITTING](8).\nSwitch statement does not have a case for [UNSUBMITTED](9).\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2245)', 'commenter': 'github-advanced-security[bot]'}]"
12693,docs/docs/en/guide/task/linkis.md,"@@ -0,0 +1,49 @@
+# Apache Linkis","[{'comment': 'Hi, due to we add new docs in this PR, we should also add it into https://github.com/apache/dolphinscheduler/blob/dev/docs/configs/docsdev.js', 'commenter': 'zhongjiajie'}]"
12693,docs/docs/en/guide/task/linkis.md,"@@ -0,0 +1,49 @@
+# Apache Linkis
+
+## Overview
+
+`Linkis` task type for creating and executing `Linkis` tasks. When the worker executes this task, it will parse the shell parameters through the `linkis-cli` command.
+Click [here](https://linkis.apache.org/) for more information about `Apache Linkis`.
+
+## Create Task
+
+- Click Project Management -> Project Name -> Workflow Definition, and click the ""Create Workflow"" button to enter the DAG editing page.
+- Drag the <img src=""../../../../img/tasks/icons/linkis.png"" width=""15""/> from the toolbar to the drawing board.
+
+## Task Parameter
+
+[//]: # (TODO: use the commented anchor below once our website template supports this syntax)
+[//]: # (- Please refer to [DolphinScheduler Task Parameters Appendix]&#40;appendix.md#default-task-parameters&#41; `Default Task Parameters` section for default parameters.)
+
+- Please refer to [DolphinScheduler Task Parameters Appendix](appendix.md) `Default Task Parameters` section for default parameters.
+- Please refer to [Linkis-Cli Task Parameters](https://linkis.apache.org/zh-CN/docs/latest/user-guide/linkiscli-manual) `Linkis Support Parameters` section for Linkis parameters.
+
+## Task Example
+
+This sample demonstrates using the Spark engine to execute sql script.
+
+### Configuring the Linkis environment in DolphinScheduler
+
+If you want to use the Linkis task type in the production environment, you need to configure the required environment first. The configuration file is as follows: `/dolphinscheduler/conf/env/dolphinscheduler_env.sh`.
+
+![linkis_task01](../../../../img/tasks/demo/linkis_task01.png)
+
+### Configuring Linkis Task Node
+
+According to the above parameter description, configure the required content.
+
+![linkis_task02](../../../../img/tasks/demo/linkis_task02.png)
+
+### Config example
+
+```Config
+
+sh ./bin/linkis-cli -engineType spark-2.4.3 -codeType sql -code ""select count(*) from testdb.test;""  -submitUser hadoop -proxyUser hadoop 
+
+```
+
+### Attention
+
+- No need to fill `sh ./bin/linkis-cli` in the configuration column, it has been configured in advance.
+- The default configuration is asynchronous submission. You do not need to configure the `-- async` parameter.","[{'comment': '```suggestion\r\n- The default configuration is asynchronous submission. You do not need to configure the `--async` parameter.\r\n```', 'commenter': 'zhongjiajie'}]"
12693,docs/docs/en/guide/task/linkis.md,"@@ -0,0 +1,49 @@
+# Apache Linkis
+
+## Overview
+
+`Linkis` task type for creating and executing `Linkis` tasks. When the worker executes this task, it will parse the shell parameters through the `linkis-cli` command.
+Click [here](https://linkis.apache.org/) for more information about `Apache Linkis`.
+
+## Create Task
+
+- Click Project Management -> Project Name -> Workflow Definition, and click the ""Create Workflow"" button to enter the DAG editing page.
+- Drag the <img src=""../../../../img/tasks/icons/linkis.png"" width=""15""/> from the toolbar to the drawing board.
+
+## Task Parameter
+
+[//]: # (TODO: use the commented anchor below once our website template supports this syntax)
+[//]: # (- Please refer to [DolphinScheduler Task Parameters Appendix]&#40;appendix.md#default-task-parameters&#41; `Default Task Parameters` section for default parameters.)
+
+- Please refer to [DolphinScheduler Task Parameters Appendix](appendix.md) `Default Task Parameters` section for default parameters.
+- Please refer to [Linkis-Cli Task Parameters](https://linkis.apache.org/zh-CN/docs/latest/user-guide/linkiscli-manual) `Linkis Support Parameters` section for Linkis parameters.
+
+## Task Example
+
+This sample demonstrates using the Spark engine to execute sql script.
+
+### Configuring the Linkis environment in DolphinScheduler
+
+If you want to use the Linkis task type in the production environment, you need to configure the required environment first. The configuration file is as follows: `/dolphinscheduler/conf/env/dolphinscheduler_env.sh`.
+
+![linkis_task01](../../../../img/tasks/demo/linkis_task01.png)
+
+### Configuring Linkis Task Node
+
+According to the above parameter description, configure the required content.
+
+![linkis_task02](../../../../img/tasks/demo/linkis_task02.png)
+
+### Config example
+
+```Config","[{'comment': 'I am not sure about that, but should this be shell syntax instead of config?\r\n```suggestion\r\n```sh\r\n```', 'commenter': 'zhongjiajie'}]"
12726,dolphinscheduler-api/pom.xml,"@@ -142,6 +146,12 @@
         <dependency>
             <groupId>io.fabric8</groupId>
             <artifactId>kubernetes-client</artifactId>
+            <exclusions>
+                <exclusion>
+                    <groupId>org.yaml</groupId>
+                    <artifactId>snakeyaml</artifactId>
+                </exclusion>
+            </exclusions>","[{'comment': ""You don't need this.\r\n\r\n"", 'commenter': 'kezhenxu94'}]"
12726,dolphinscheduler-api/pom.xml,"@@ -194,6 +204,11 @@
             <groupId>org.springdoc</groupId>
             <artifactId>springdoc-openapi-ui</artifactId>
         </dependency>
+
+        <dependency>
+            <groupId>org.yaml</groupId>
+            <artifactId>snakeyaml</artifactId>
+        </dependency>","[{'comment': ""You don't need this"", 'commenter': 'kezhenxu94'}]"
12726,dolphinscheduler-api/pom.xml,"@@ -99,6 +99,10 @@
                     <groupId>org.apache.logging.log4j</groupId>
                     <artifactId>log4j-to-slf4j</artifactId>
                 </exclusion>
+                <exclusion>
+                    <groupId>org.yaml</groupId>
+                    <artifactId>snakeyaml</artifactId>
+                </exclusion>","[{'comment': ""You don't need this"", 'commenter': 'kezhenxu94'}]"
12726,dolphinscheduler-bom/pom.xml,"@@ -94,7 +94,7 @@
         <snappy.version>1.1.8.4</snappy.version>
         <spark.version>3.2.2</spark.version>
         <janino.version>3.0.16</janino.version>
-        <snakeyaml.version>1.31</snakeyaml.version>
+        <snakeyaml.version>1.33</snakeyaml.version>","[{'comment': 'This is the only one place you need to modify, ', 'commenter': 'kezhenxu94'}]"
12736,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRemoteHostController.java,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_PAGE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.SUCCESS;
+import static org.apache.dolphinscheduler.api.enums.Status.TEST_CONNECT_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.VARIFY_TASK_REMOTE_HOST_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.TaskRemoteHostDTO;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.TaskRemoteHostService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.api.vo.TaskRemoteHostVO;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.v3.oas.annotations.Operation;
+import io.swagger.v3.oas.annotations.Parameter;
+import io.swagger.v3.oas.annotations.Parameters;
+import io.swagger.v3.oas.annotations.media.Schema;
+import io.swagger.v3.oas.annotations.tags.Tag;
+
+/**
+ * task remote host controller
+ */
+@Tag(name = ""TASK_REMOTE_HOST_TAG"")
+@RestController
+@RequestMapping(""/remote_host"")
+public class TaskRemoteHostController {
+
+    @Autowired
+    private TaskRemoteHostService taskRemoteHostService;
+
+    @Operation(summary = ""createTaskRemoteHost"", description = ""CREATE_TASK_REMOTE_HOST_NOTES"")
+    @PostMapping(value = ""/create"")
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result createTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.createTaskRemoteHost(loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(CREATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""updateTaskRemoteHost"", description = ""UPDATE_TASK_REMOTE_HOST_NOTES"")
+    @PutMapping(value = ""/update/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result updateTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @PathVariable(""code"") Long code,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.updateTaskRemoteHost(code, loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(UPDATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""delete"", description = ""DELETE_TASK_REMOTE_HOST_NOTES"")
+    @Parameters({
+            @Parameter(name = ""code"", description = ""TASK_REMOTE_HOST_CODE"", schema = @Schema(implementation = long.class, example = ""123456"", required = true))
+    })
+    @PostMapping(value = ""/delete"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(DELETE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result deleteTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @RequestParam(""taskRemoteHostCode"") Long code) {
+        int result = taskRemoteHostService.deleteByCode(code, loginUser);
+        return result > 0 ? Result.success() : Result.error(DELETE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""queryTaskRemoteHostListPaging"", description = ""QUERY_TASK_REMOTE_HOST_PAGE_NOTES"")
+    @Parameters({
+            @Parameter(name = ""searchVal"", description = ""SEARCH_VAL"", schema = @Schema(implementation = String.class)),
+            @Parameter(name = ""pageSize"", description = ""PAGE_SIZE"", required = true, schema = @Schema(implementation = int.class, example = ""20"")),
+            @Parameter(name = ""pageNo"", description = ""PAGE_NO"", required = true, schema = @Schema(implementation = int.class, example = ""1""))
+    })
+    @GetMapping(value = ""/list-paging"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_TASK_REMOTE_HOST_PAGE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result<PageInfo<TaskRemoteHostVO>> queryTaskRemoteHostListPaging(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                                                            @RequestParam(value = ""searchVal"", required = false) String searchVal,
+                                                                            @RequestParam(""pageSize"") Integer pageSize,
+                                                                            @RequestParam(""pageNo"") Integer pageNo) {
+        PageInfo<TaskRemoteHostVO> taskRemoteHostVOPageInfo =
+                taskRemoteHostService.queryTaskRemoteHostListPaging(loginUser, searchVal, pageNo, pageSize);
+        return Result.success(taskRemoteHostVOPageInfo);
+    }
+
+    @Operation(summary = ""queryTaskRemoteHostList"", description = ""QUERY_ALL_TASK_REMOTE_HOST_LIST_NOTES"")
+    @GetMapping(value = ""/query-remote-host-list"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result<List<TaskRemoteHostVO>> queryTaskRemoteHostList(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {
+        List<TaskRemoteHostVO> taskRemoteHostVOList = taskRemoteHostService.queryAllTaskRemoteHosts(loginUser);
+        return Result.success(taskRemoteHostVOList);
+    }
+
+    @Operation(summary = ""textConnect"", description = ""TEXT_CONNECT_HOST_NOTES"")
+    @PostMapping(value = ""/test-connect"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(TEST_CONNECT_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result testConnect(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                              @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        boolean result = taskRemoteHostService.testConnect(taskRemoteHostDTO);
+        return result ? Result.success(SUCCESS) : Result.error(TEST_CONNECT_ERROR);
+    }
+
+    @Operation(summary = ""verifyTaskRemoteHost"", description = ""VERIFY_TASK_REMOTE_HOST_NOTES"")
+    @Parameters({
+            @Parameter(name = ""taskRemoteHostName"", description = ""TASK_REMOTE_HOST_NAME"", required = true, schema = @Schema(implementation = String.class))
+    })
+    @PostMapping(value = ""/verify-host"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(VARIFY_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result verifyTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,","[{'comment': ""## Useless parameter\n\nThe parameter 'loginUser' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2241)"", 'commenter': 'github-advanced-security[bot]'}]"
12736,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRemoteHostController.java,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_PAGE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.SUCCESS;
+import static org.apache.dolphinscheduler.api.enums.Status.TEST_CONNECT_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.VARIFY_TASK_REMOTE_HOST_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.TaskRemoteHostDTO;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.TaskRemoteHostService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.api.vo.TaskRemoteHostVO;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.v3.oas.annotations.Operation;
+import io.swagger.v3.oas.annotations.Parameter;
+import io.swagger.v3.oas.annotations.Parameters;
+import io.swagger.v3.oas.annotations.media.Schema;
+import io.swagger.v3.oas.annotations.tags.Tag;
+
+/**
+ * task remote host controller
+ */
+@Tag(name = ""TASK_REMOTE_HOST_TAG"")
+@RestController
+@RequestMapping(""/remote_host"")
+public class TaskRemoteHostController {
+
+    @Autowired
+    private TaskRemoteHostService taskRemoteHostService;
+
+    @Operation(summary = ""createTaskRemoteHost"", description = ""CREATE_TASK_REMOTE_HOST_NOTES"")
+    @PostMapping(value = ""/create"")
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result createTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.createTaskRemoteHost(loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(CREATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""updateTaskRemoteHost"", description = ""UPDATE_TASK_REMOTE_HOST_NOTES"")
+    @PutMapping(value = ""/update/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result updateTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @PathVariable(""code"") Long code,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.updateTaskRemoteHost(code, loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(UPDATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""delete"", description = ""DELETE_TASK_REMOTE_HOST_NOTES"")
+    @Parameters({
+            @Parameter(name = ""code"", description = ""TASK_REMOTE_HOST_CODE"", schema = @Schema(implementation = long.class, example = ""123456"", required = true))
+    })
+    @PostMapping(value = ""/delete"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(DELETE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result deleteTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @RequestParam(""taskRemoteHostCode"") Long code) {
+        int result = taskRemoteHostService.deleteByCode(code, loginUser);
+        return result > 0 ? Result.success() : Result.error(DELETE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""queryTaskRemoteHostListPaging"", description = ""QUERY_TASK_REMOTE_HOST_PAGE_NOTES"")
+    @Parameters({
+            @Parameter(name = ""searchVal"", description = ""SEARCH_VAL"", schema = @Schema(implementation = String.class)),
+            @Parameter(name = ""pageSize"", description = ""PAGE_SIZE"", required = true, schema = @Schema(implementation = int.class, example = ""20"")),
+            @Parameter(name = ""pageNo"", description = ""PAGE_NO"", required = true, schema = @Schema(implementation = int.class, example = ""1""))
+    })
+    @GetMapping(value = ""/list-paging"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_TASK_REMOTE_HOST_PAGE_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result<PageInfo<TaskRemoteHostVO>> queryTaskRemoteHostListPaging(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                                                            @RequestParam(value = ""searchVal"", required = false) String searchVal,
+                                                                            @RequestParam(""pageSize"") Integer pageSize,
+                                                                            @RequestParam(""pageNo"") Integer pageNo) {
+        PageInfo<TaskRemoteHostVO> taskRemoteHostVOPageInfo =
+                taskRemoteHostService.queryTaskRemoteHostListPaging(loginUser, searchVal, pageNo, pageSize);
+        return Result.success(taskRemoteHostVOPageInfo);
+    }
+
+    @Operation(summary = ""queryTaskRemoteHostList"", description = ""QUERY_ALL_TASK_REMOTE_HOST_LIST_NOTES"")
+    @GetMapping(value = ""/query-remote-host-list"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(QUERY_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result<List<TaskRemoteHostVO>> queryTaskRemoteHostList(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser) {
+        List<TaskRemoteHostVO> taskRemoteHostVOList = taskRemoteHostService.queryAllTaskRemoteHosts(loginUser);
+        return Result.success(taskRemoteHostVOList);
+    }
+
+    @Operation(summary = ""textConnect"", description = ""TEXT_CONNECT_HOST_NOTES"")
+    @PostMapping(value = ""/test-connect"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(TEST_CONNECT_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result testConnect(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,","[{'comment': ""## Useless parameter\n\nThe parameter 'loginUser' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2242)"", 'commenter': 'github-advanced-security[bot]'}]"
12736,dolphinscheduler-dao/src/test/java/org/apache/dolphinscheduler/dao/mapper/TaskRemoteHostMapperTest.java,"@@ -0,0 +1,110 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.dao.mapper;
+
+import org.apache.dolphinscheduler.dao.BaseDaoTest;
+import org.apache.dolphinscheduler.dao.entity.TaskRemoteHost;
+
+import java.util.List;
+
+import org.junit.jupiter.api.AfterEach;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.BeforeEach;
+import org.junit.jupiter.api.Test;
+import org.springframework.beans.factory.annotation.Autowired;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
+import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
+
+public class TaskRemoteHostMapperTest extends BaseDaoTest {
+
+    @Autowired
+    private TaskRemoteHostMapper taskRemoteHostMapper;
+
+    private TaskRemoteHost insertOne() {
+        TaskRemoteHost taskRemoteHost = new TaskRemoteHost();
+        taskRemoteHost.setCode(1L);
+        taskRemoteHost.setName(""app01 server"");
+        taskRemoteHost.setIp(""localhost"");
+        taskRemoteHost.setPort(22);
+        taskRemoteHost.setAccount(""foo"");
+        taskRemoteHost.setPassword(""foo123"");
+        taskRemoteHost.setDescription(""app01 server description"");
+        taskRemoteHost.setOperator(1);
+        taskRemoteHostMapper.insert(taskRemoteHost);
+        return taskRemoteHost;
+    }
+
+    @BeforeEach
+    public void setUp() {
+        clearTestData();
+    }
+
+    @AfterEach
+    public void after() {
+        clearTestData();
+    }
+
+    public void clearTestData() {
+        taskRemoteHostMapper.queryAllTaskRemoteHostList().forEach(taskRemoteHost -> {
+            taskRemoteHostMapper.deleteByCode(taskRemoteHost.getCode());
+        });
+    }
+
+    @Test
+    public void testUpdate() {
+        TaskRemoteHost taskRemoteHost = insertOne();
+        taskRemoteHost.setDescription(""update description"");
+        int update = taskRemoteHostMapper.updateById(taskRemoteHost);
+        Assertions.assertEquals(1, update);
+    }
+
+    @Test
+    public void testDelete() {
+        TaskRemoteHost taskRemoteHost = insertOne();
+        int delete = taskRemoteHostMapper.deleteById(taskRemoteHost);
+        Assertions.assertEquals(1, delete);
+    }
+
+    @Test
+    public void testQueryByTaskRemoteHostName() {
+        TaskRemoteHost taskRemoteHost = insertOne();
+        TaskRemoteHost result = taskRemoteHostMapper.queryByTaskRemoteHostName(taskRemoteHost.getName());
+        Assertions.assertEquals(taskRemoteHost.getName(), result.getName());
+    }
+
+    @Test
+    public void testQueryByTaskRemoteHostCode() {
+        TaskRemoteHost taskRemoteHost = insertOne();
+        TaskRemoteHost result = taskRemoteHostMapper.queryByTaskRemoteHostCode(taskRemoteHost.getCode());
+        Assertions.assertEquals(taskRemoteHost.getCode(), result.getCode());
+    }
+
+    @Test
+    public void testQueryTaskRemoteHostListPaging() {
+        TaskRemoteHost entity = insertOne();","[{'comment': ""## Unread local variable\n\nVariable 'TaskRemoteHost entity' is never read.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2243)"", 'commenter': 'github-advanced-security[bot]'}]"
12736,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -2007,3 +2010,23 @@ CREATE TABLE `t_ds_fav_task`
 ) ENGINE = InnoDB
   AUTO_INCREMENT = 1
   DEFAULT CHARSET = utf8;
+
+-- ----------------------------
+-- Table structure for t_ds_task_remote_host
+-- ----------------------------
+DROP TABLE IF EXISTS `t_ds_task_remote_host`;
+CREATE TABLE `t_ds_task_remote_host`
+(
+    `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'id',
+    `code` bigint(20) NOT NULL DEFAULT '0' COMMENT 'encoding',","[{'comment': ""It's better to add indexes in this table. So as postgresql."", 'commenter': 'SbloodyS'}, {'comment': ""> It's better to add indexes in this table. So as postgresql.\r\n\r\nSure."", 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ssh/SSHSessionHolder.java,"@@ -0,0 +1,348 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.api.ssh;
+
+import org.apache.dolphinscheduler.plugin.task.api.model.SSHSessionHost;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.InputStream;
+import java.io.OutputStream;
+import java.nio.charset.StandardCharsets;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.UUID;
+import java.util.concurrent.TimeUnit;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.jcraft.jsch.Channel;
+import com.jcraft.jsch.ChannelExec;
+import com.jcraft.jsch.ChannelSftp;
+import com.jcraft.jsch.JSch;
+import com.jcraft.jsch.JSchException;
+import com.jcraft.jsch.Session;
+import com.jcraft.jsch.SftpException;
+
+/**
+ * ACP pooled object: JSch Session Wrapper
+ */
+public class SSHSessionHolder {
+
+    private static final Logger logger = LoggerFactory.getLogger(SSHSessionHolder.class);
+
+    private static final String EXEC_TYPE = ""exec"";
+
+    private static final String SFTP_TYPE = ""sftp"";
+
+    private static final String SHELL_TYPE = ""shell"";
+
+    private static final int DEFAULT_CONNECT_TIMEOUT = 5000;
+
+    private static final int KB_UNIT = 1024;
+
+    public static final String SINGLE_SLASH = ""/"";
+
+    private Session session;
+
+    private final SSHSessionHost sessionHost;
+
+    private final String id;
+
+    private SftpConfig sftpConfig;
+
+    public SSHSessionHolder(SSHSessionHost sessionHost) {
+        this.sessionHost = sessionHost;
+        this.id = UUID.randomUUID().toString();
+        this.session = null;
+    }
+
+    public void connect() throws JSchException {
+        this.connect(DEFAULT_CONNECT_TIMEOUT);
+    }
+
+    public void connect(int timeoutMills) throws JSchException {
+        JSch jSch = new JSch();
+        this.session = jSch.getSession(sessionHost.getAccount(), sessionHost.getIp(), sessionHost.getPort());
+        this.session.setTimeout(timeoutMills);
+        this.session.setConfig(""StrictHostKeyChecking"", ""no"");
+        // other authorization methods can be considered in the future
+        this.session.setPassword(sessionHost.getPassword());
+        this.session.connect();
+        logger.info(""Connected to ssh session: {}, session id: {}"", sessionHost.toString(), id);
+    }
+
+    public void disconnect() {
+        if (session != null) {
+            session.disconnect();
+        }
+    }
+
+    public boolean isConnected() {
+        return session.isConnected();
+    }
+
+    public void keepAlive() throws Exception {
+        if (session != null) {
+            session.sendKeepAliveMsg();
+        }
+    }
+
+    public SSHResponse execCommand(String command) {
+        return this.execCommand(command, -1, logger);
+    }
+
+    public SSHResponse execCommand(String command, long timeout, Logger logger) {
+        return this.execCommand(createChannelExec(), command, timeout, logger);
+    }
+
+    public SSHResponse execCommand(ChannelExec channelExec, String command, long timeout, Logger customLogger) {
+        customLogger.info(""Executing command {} on session:{}"", command, this);
+        channelExec.setCommand(command);
+        channelExec.setInputStream(null);
+        channelExec.setErrStream(System.err);
+        // it will kill process when channel disconnect, default true
+        channelExec.setPty(true);
+
+        SSHResponse response = new SSHResponse();
+        try (
+                InputStream in = channelExec.getInputStream();
+                InputStream err = channelExec.getErrStream();) {
+            channelExec.connect(DEFAULT_CONNECT_TIMEOUT);
+
+            long timeoutSave = timeout > 0 ? timeout : Integer.MAX_VALUE;
+            List<String> out = new ArrayList<String>();
+            byte[] outSave = new byte[1024];
+            while (true) {
+                timeoutSave--;
+                while (in.available() > 0) {
+                    int i = in.read(outSave, 0, 1024);
+                    if (i < 0) {
+                        break;
+                    }
+                    String line = new String(outSave, 0, i, StandardCharsets.UTF_8);
+                    out.add(line);
+                    customLogger.info(line);
+                }
+                while (err.available() > 0) {
+                    int i = err.read(outSave, 0, 1024);
+                    if (i < 0) {
+                        break;
+                    }
+                    String line = new String(outSave, 0, i, StandardCharsets.UTF_8);
+                    out.add(line);
+                    customLogger.error(line);
+                }
+                if (channelExec.isClosed() || channelExec.isEOF()) {
+                    response.setExitCode(channelExec.getExitStatus());
+                    break;
+                }
+                TimeUnit.MILLISECONDS.sleep(1000);
+                if (timeoutSave < 0) {
+                    customLogger.error(""Exec command {} on session {} timed out"", command, this);
+                    throw new SSHException(""Exec command "" + command + "" on session "" + this + "" timed out"");
+                }
+            }
+            response.setOut(out);
+            logger.info(""Exec command {} on session {} finished, exit code: {}"", command, this, response.getExitCode());
+            return response;
+        } catch (Exception e) {
+            throw new SSHException(""Exec command "" + command + "" on session "" + this + "" failed"", e);
+        } finally {
+            close(channelExec);
+        }
+    }
+
+    public boolean sftpDir(String localDirPath, String remoteDirPath) {
+        return sftpDir(localDirPath, remoteDirPath, logger);
+    }
+
+    public boolean sftpDir(String localDirPath, String remoteDirPath, Logger customLogger) {
+        return sftpDir(createChannelSftp(), localDirPath, remoteDirPath, sftpConfig.isEnableUploadMonitor(),
+                sftpConfig.getMaxUploadRate(), sftpConfig.getMaxFileSize(), customLogger);
+    }
+
+    /**
+     * Sftp local directory to remote host,
+     * @param channelSftp SSH sftp channel
+     * @param localDirPath local directory path
+     * @param remoteDirPath remote target directory path
+     * @param enableUploadMonitor enable upload monitor thread
+     * @param maxUploadRate max upload rate, if negative, will not limit
+     * @param maxFileSize max file size, if negative, will not limit
+     * @param customLogger custom logger, default local
+     * @return sftp result
+     */
+    public boolean sftpDir(ChannelSftp channelSftp, String localDirPath, String remoteDirPath,
+                           boolean enableUploadMonitor, int maxUploadRate, int maxFileSize, Logger customLogger) {
+        customLogger.info(""Start to sftp local dir: {} to {}:{}"", localDirPath, sessionHost.toString(), remoteDirPath);
+
+        File file = new File(localDirPath);
+        if (!file.exists()) {
+            customLogger.error(""{} not exists."", localDirPath);
+            return false;
+        }
+
+        try {
+            channelSftp.connect(DEFAULT_CONNECT_TIMEOUT);
+            try {
+                channelSftp.cd(remoteDirPath);
+            } catch (SftpException e) {
+                if (!createDirOnRemote(remoteDirPath)) {
+                    customLogger.error(""Create directory:{} on remote:{} failed, so exit."", remoteDirPath,
+                            sessionHost.toString());
+                    return false;
+                }
+            }
+
+            long totalSize = file.length();
+
+            if (maxFileSize >= 0) {
+                if (totalSize > (long) maxFileSize * KB_UNIT * KB_UNIT) {
+                    customLogger.error(""The size of :{} has exceeded the maximum size:{}, size: {}"", totalSize,
+                            maxFileSize, localDirPath);
+                    return false;
+                }
+            }
+
+            if (file.isDirectory()) {
+                File[] files = file.listFiles();
+                if (files == null || files.length == 0) {
+                    customLogger.error(""{} is a empty directory."", localDirPath);
+                    return false;
+                }
+                for (File subFile : files) {
+                    String sf = subFile.getCanonicalPath();
+                    if (subFile.isDirectory()) {
+                        String mkdirPath = remoteDirPath + ""/"" + subFile.getName();
+                        try {
+                            channelSftp.cd(mkdirPath);
+                        } catch (SftpException e) {
+                            if (!createDirOnRemote(mkdirPath)) {
+                                customLogger.error(""Could not create directory {} on remote session:{}"", mkdirPath,
+                                        sessionHost.toString());
+                                return false;
+                            }
+                        }
+                        if (!sftpDir(createChannelSftp(), sf, mkdirPath, enableUploadMonitor, maxUploadRate, -1,
+                                customLogger)) {
+                            customLogger.error(""sftp {} to {}:{} failed."", sf, sessionHost.toString(), mkdirPath);
+                            return false;
+                        }
+                    } else {
+                        upload(channelSftp, sf, remoteDirPath, enableUploadMonitor, maxUploadRate);
+                    }
+                }
+            } else {
+                upload(channelSftp, file.getCanonicalPath(), remoteDirPath, enableUploadMonitor, maxUploadRate);
+            }
+            return true;
+        } catch (Exception e) {
+            throw new SSHException(
+                    ""sftp "" + localDirPath + "" to "" + sessionHost.toString() + "":"" + remoteDirPath + "" failed."", e);
+        }
+    }
+
+    /**
+     * Create a directory on the remote server
+     * Because JSch does not support one-time creation of multi-layer directories, so just use `mkdir -p` instead
+     * @param remoteDirPath remote directory path
+     * @return result
+     */
+    public boolean createDirOnRemote(String remoteDirPath) {
+        logger.info(""create directory:{} on remote:{}"", remoteDirPath, sessionHost.toString());
+        SSHResponse response = execCommand(""mkdir -p "" + remoteDirPath);
+        return response.getExitCode() == 0;
+    }
+
+    public void clearPath(String path) {
+        if (SINGLE_SLASH.equals(path)) {
+            return;
+        }
+        execCommand(""rm -rf "" + path);","[{'comment': ""I think it's better to use `File.delete` to perform operations instead of shell commands."", 'commenter': 'SbloodyS'}, {'comment': ""> I think it's better to use `File.delete` to perform operations instead of shell commands.\r\n\r\nBecuase these codes need to clear the path on the remote SSH server, so use the `rm -rf` command, not `File.delete`\r\n"", 'commenter': 'DarkAssassinator'}, {'comment': ""Please don't mark it as resolved if it's not addressed. cc @zhongjiajie @caishunfeng "", 'commenter': 'SbloodyS'}, {'comment': ""> Please don't mark it as resolved if it's not addressed. cc @zhongjiajie @caishunfeng\r\n\r\nSorry, sure, and i think that `File.delete` cannot delete the remote dir and files, so i think that this case has resolved. WDYT."", 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -2007,3 +2010,25 @@ CREATE TABLE `t_ds_fav_task`
 ) ENGINE = InnoDB
   AUTO_INCREMENT = 1
   DEFAULT CHARSET = utf8;
+
+-- ----------------------------
+-- Table structure for t_ds_task_remote_host
+-- ----------------------------
+DROP TABLE IF EXISTS `t_ds_task_remote_host`;
+CREATE TABLE `t_ds_task_remote_host`","[{'comment': 'I do not think adding a table for a task type is a good idea, can we ship it to our data source center? I know that we will change its name from `datasource center` to `connection center`, which can have various types of connection instead of database only', 'commenter': 'zhongjiajie'}, {'comment': '> Add a Task Remote Host Management page in Security\r\n\r\nIf we add it to `connection center`, we can also migrate it into `connection center`, which may keep our web UI simple and unify', 'commenter': 'zhongjiajie'}, {'comment': '> > Add a Task Remote Host Management page in Security\r\n> \r\n> If we add it to `connection center`, we can also migrate it into `connection center`, which may keep our web UI simple and unify\r\n\r\nyes, but the conclusion we discussed bi-week was to temporarily in `Security`, after `Connection center` fine, we will migrate it into `Connection center`', 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRemoteHostController.java,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_PAGE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.SUCCESS;
+import static org.apache.dolphinscheduler.api.enums.Status.TEST_CONNECT_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.VARIFY_TASK_REMOTE_HOST_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.TaskRemoteHostDTO;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.TaskRemoteHostService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.api.vo.TaskRemoteHostVO;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.v3.oas.annotations.Operation;
+import io.swagger.v3.oas.annotations.Parameter;
+import io.swagger.v3.oas.annotations.Parameters;
+import io.swagger.v3.oas.annotations.media.Schema;
+import io.swagger.v3.oas.annotations.tags.Tag;
+
+/**
+ * task remote host controller
+ */
+@Tag(name = ""TASK_REMOTE_HOST_TAG"")
+@RestController
+@RequestMapping(""/remote_host"")
+public class TaskRemoteHostController {
+
+    @Autowired
+    private TaskRemoteHostService taskRemoteHostService;
+
+    @Operation(summary = ""createTaskRemoteHost"", description = ""CREATE_TASK_REMOTE_HOST_NOTES"")
+    @PostMapping(value = ""/create"")
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result createTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.createTaskRemoteHost(loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(CREATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""updateTaskRemoteHost"", description = ""UPDATE_TASK_REMOTE_HOST_NOTES"")
+    @PutMapping(value = ""/update/{code}"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(UPDATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result updateTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @PathVariable(""code"") Long code,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.updateTaskRemoteHost(code, loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(UPDATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""delete"", description = ""DELETE_TASK_REMOTE_HOST_NOTES"")
+    @Parameters({
+            @Parameter(name = ""code"", description = ""TASK_REMOTE_HOST_CODE"", schema = @Schema(implementation = long.class, example = ""123456"", required = true))
+    })
+    @PostMapping(value = ""/delete"")","[{'comment': '```suggestion\r\n    @DeleteMapping(value = ""/delete"")\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRemoteHostController.java,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_PAGE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.SUCCESS;
+import static org.apache.dolphinscheduler.api.enums.Status.TEST_CONNECT_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.VARIFY_TASK_REMOTE_HOST_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.TaskRemoteHostDTO;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.TaskRemoteHostService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.api.vo.TaskRemoteHostVO;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.v3.oas.annotations.Operation;
+import io.swagger.v3.oas.annotations.Parameter;
+import io.swagger.v3.oas.annotations.Parameters;
+import io.swagger.v3.oas.annotations.media.Schema;
+import io.swagger.v3.oas.annotations.tags.Tag;
+
+/**
+ * task remote host controller
+ */
+@Tag(name = ""TASK_REMOTE_HOST_TAG"")
+@RestController
+@RequestMapping(""/remote_host"")
+public class TaskRemoteHostController {
+
+    @Autowired
+    private TaskRemoteHostService taskRemoteHostService;
+
+    @Operation(summary = ""createTaskRemoteHost"", description = ""CREATE_TASK_REMOTE_HOST_NOTES"")
+    @PostMapping(value = ""/create"")","[{'comment': 'maybe it should remove the value dut to default PostMapping means `create`? cc @zhongjiajie \r\n```suggestion\r\n    @PostMapping()\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskRemoteHostController.java,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.CREATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.DELETE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.QUERY_TASK_REMOTE_HOST_PAGE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.SUCCESS;
+import static org.apache.dolphinscheduler.api.enums.Status.TEST_CONNECT_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.UPDATE_TASK_REMOTE_HOST_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.VARIFY_TASK_REMOTE_HOST_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.dto.TaskRemoteHostDTO;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.TaskRemoteHostService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.api.vo.TaskRemoteHostVO;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.PathVariable;
+import org.springframework.web.bind.annotation.PostMapping;
+import org.springframework.web.bind.annotation.PutMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestBody;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.v3.oas.annotations.Operation;
+import io.swagger.v3.oas.annotations.Parameter;
+import io.swagger.v3.oas.annotations.Parameters;
+import io.swagger.v3.oas.annotations.media.Schema;
+import io.swagger.v3.oas.annotations.tags.Tag;
+
+/**
+ * task remote host controller
+ */
+@Tag(name = ""TASK_REMOTE_HOST_TAG"")
+@RestController
+@RequestMapping(""/remote_host"")
+public class TaskRemoteHostController {
+
+    @Autowired
+    private TaskRemoteHostService taskRemoteHostService;
+
+    @Operation(summary = ""createTaskRemoteHost"", description = ""CREATE_TASK_REMOTE_HOST_NOTES"")
+    @PostMapping(value = ""/create"")
+    @ResponseStatus(HttpStatus.CREATED)
+    @ApiException(CREATE_TASK_REMOTE_HOST_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result createTaskRemoteHost(@Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                       @RequestBody TaskRemoteHostDTO taskRemoteHostDTO) {
+        int result = taskRemoteHostService.createTaskRemoteHost(loginUser, taskRemoteHostDTO);
+        return result > 0 ? Result.success() : Result.error(CREATE_TASK_REMOTE_HOST_ERROR);
+    }
+
+    @Operation(summary = ""updateTaskRemoteHost"", description = ""UPDATE_TASK_REMOTE_HOST_NOTES"")
+    @PutMapping(value = ""/update/{code}"")","[{'comment': 'same here, the PutMapping is update action defaultly.\r\n```suggestion\r\n    @PutMapping(value = ""/{code}"")\r\n```', 'commenter': 'caishunfeng'}]"
12736,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskRemoteHostServiceImpl.java,"@@ -0,0 +1,281 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service.impl;
+
+import static org.apache.dolphinscheduler.api.constants.ApiFuncIdentificationConstant.TASK_REMOTE_HOST_CREATE;
+import static org.apache.dolphinscheduler.api.constants.ApiFuncIdentificationConstant.TASK_REMOTE_HOST_DELETE;
+import static org.apache.dolphinscheduler.api.constants.ApiFuncIdentificationConstant.TASK_REMOTE_HOST_EDIT;
+
+import org.apache.dolphinscheduler.api.dto.TaskRemoteHostDTO;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ServiceException;
+import org.apache.dolphinscheduler.api.service.TaskRemoteHostService;
+import org.apache.dolphinscheduler.api.utils.PageInfo;
+import org.apache.dolphinscheduler.api.vo.TaskRemoteHostVO;
+import org.apache.dolphinscheduler.common.enums.AuthorizationType;
+import org.apache.dolphinscheduler.common.enums.UserType;
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils;
+import org.apache.dolphinscheduler.common.utils.CodeGenerateUtils.CodeGenerateException;
+import org.apache.dolphinscheduler.common.utils.NetUtils;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.dao.entity.TaskRemoteHost;
+import org.apache.dolphinscheduler.dao.entity.User;
+import org.apache.dolphinscheduler.dao.mapper.TaskInstanceMapper;
+import org.apache.dolphinscheduler.dao.mapper.TaskRemoteHostMapper;
+import org.apache.dolphinscheduler.plugin.task.api.model.SSHSessionHost;
+import org.apache.dolphinscheduler.plugin.task.api.ssh.DSSessionAbandonedConfig;
+import org.apache.dolphinscheduler.plugin.task.api.ssh.DSSessionPoolConfig;
+import org.apache.dolphinscheduler.plugin.task.api.ssh.SSHResponse;
+import org.apache.dolphinscheduler.plugin.task.api.ssh.SSHSessionHolder;
+import org.apache.dolphinscheduler.plugin.task.api.ssh.SSHSessionPool;
+import org.apache.dolphinscheduler.service.utils.Constants;
+
+import org.apache.commons.collections.CollectionUtils;
+import org.apache.commons.lang3.StringUtils;
+
+import java.util.ArrayList;
+import java.util.Collections;
+import java.util.Date;
+import java.util.List;
+import java.util.Set;
+import java.util.stream.Collectors;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.springframework.beans.BeanUtils;
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+import org.springframework.transaction.annotation.Transactional;
+
+import com.baomidou.mybatisplus.core.metadata.IPage;
+import com.baomidou.mybatisplus.extension.plugins.pagination.Page;
+
+@Service
+public class TaskRemoteHostServiceImpl extends BaseServiceImpl implements TaskRemoteHostService {
+
+    private static final Logger logger = LoggerFactory.getLogger(TaskRemoteHostServiceImpl.class);
+
+    @Autowired
+    private TaskRemoteHostMapper taskRemoteHostMapper;
+
+    @Autowired
+    private TaskInstanceMapper taskInstanceMapper;
+
+    @Override
+    @Transactional
+    public int createTaskRemoteHost(User loginUser, TaskRemoteHostDTO taskRemoteHostDTO) {
+        checkTaskRemoteHostDTO(taskRemoteHostDTO);
+
+        checkOperatorPermissions(loginUser, null, AuthorizationType.TASK_REMOTE_TASK, TASK_REMOTE_HOST_CREATE);
+
+        if (isExistSameName(taskRemoteHostDTO.getName())) {
+            throw new ServiceException(Status.TASK_REMOTE_HOST_EXIST, taskRemoteHostDTO.getName());
+        }
+
+        TaskRemoteHost remoteHost = new TaskRemoteHost();
+        BeanUtils.copyProperties(taskRemoteHostDTO, remoteHost);
+        long remoteHostCode;
+        try {
+            remoteHostCode = CodeGenerateUtils.getInstance().genCode();
+        } catch (CodeGenerateException e) {
+            throw new ServiceException(Status.INTERNAL_SERVER_ERROR_ARGS);
+        }
+        remoteHost.setCode(remoteHostCode);
+        remoteHost.setOperator(loginUser.getId());
+        remoteHost.setCreateTime(new Date());
+        remoteHost.setUpdateTime(new Date());
+
+        int result = taskRemoteHostMapper.insert(remoteHost);
+        if (result > 0) {
+            permissionPostHandle(AuthorizationType.TASK_REMOTE_TASK, loginUser.getId(),
+                    Collections.singletonList(remoteHost.getId()), logger);
+            logger.info(""Create remote host successes, host name {}."", remoteHost.getName());
+        }","[{'comment': 'In this case, I think checking result > 0 is meanless, due to not multi db write operations after inserting. Defaultly, it will success if no exception. WDYT?\r\n```suggestion\r\n        taskRemoteHostMapper.insert(remoteHost);\r\n        permissionPostHandle(AuthorizationType.TASK_REMOTE_TASK, loginUser.getId(),\r\n                  Collections.singletonList(remoteHost.getId()), logger);\r\n        logger.info(""Create remote host successes, host name {}."", remoteHost.getName());\r\n        \r\n```', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_h2.sql,"@@ -2032,3 +2032,24 @@ CREATE TABLE t_ds_fav_task
     user_id   int         NOT NULL,
     PRIMARY KEY (id)
 );
+
+--
+-- Table structure for t_ds_task_remote_host
+--
+
+DROP TABLE IF EXISTS t_ds_task_remote_host CASCADE;
+CREATE TABLE t_ds_task_remote_host
+(
+    id                   int      NOT NULL   AUTO_INCREMENT,
+    code                 bigint(20)          NOT NULL ,
+    name        varchar(100)    NOT NULL ,
+    ip          varchar(100)    NOT NULL ,
+    port        int             NOT NULL ,
+    account        varchar(100)    NOT NULL ,
+    password    varchar(64)     NOT NULL ,
+    operator             int             DEFAULT NULL ,
+    description          text,
+    create_time          timestamp       DEFAULT NULL ,
+    update_time          timestamp       DEFAULT NULL ,
+    PRIMARY KEY (id)","[{'comment': 'format', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java,"@@ -190,11 +220,105 @@ public TaskResponse run(String execCommand) throws IOException, InterruptedExcep
             return result;
         }
 
+        if (bashTaskExecutionContext.getSessionHost() != null) {
+            runningOnSSH = true;
+        }
+
+        if (runningOnSSH && SystemUtils.IS_OS_WINDOWS) {
+            logger.error(""SSH does not support Windows systems"");
+            TaskExecutionContextCacheManager.removeByTaskInstanceId(taskInstanceId);
+            return result;
+        }
+
         String commandFilePath = buildCommandFilePath();
 
         // create command file if not exists
         createCommandFileIfNotExists(execCommand, commandFilePath);
 
+        result = runCommandFile(commandFilePath);
+
+        return result;
+    }
+
+    private TaskResponse runCommandFile(String commandFilePath) throws IOException, InterruptedException {
+        return runningOnSSH ? runOnSSH(commandFilePath) : runOnLocalProcess(commandFilePath);
+    }
+
+    private TaskResponse runOnSSH(String commandFilePath) {
+        TaskResponse result = new TaskResponse();
+        SSHSessionHolder sessionHolder = null;
+        this.sessionHost = bashTaskExecutionContext.getSessionHost();
+        try {
+            sessionHolder = SSHSessionPool.getSessionHolder(sessionHost);
+            sessionHolder.setSftpConfig(SSHSessionPool.getSftpConfig());
+            logger.info(""borrow session:{} success"", sessionHolder);
+
+            boolean uploadRes =
+                    sessionHolder.sftpDir(taskRequest.getExecutePath(), taskRequest.getExecutePath(), logger);
+            if (!uploadRes) {
+                logger.error(""upload task {} execute path to remote session {} failed"", taskRequest.getExecutePath(),
+                        sessionHost.toString());
+                result.setExitStatusCode(EXIT_CODE_FAILURE);
+                return result;
+            }
+
+            if (taskRequest.getEnvFile() != null) {
+                boolean uploadEnvRes =
+                        sessionHolder.sftpDir(taskRequest.getEnvFile(), taskRequest.getExecutePath(), logger);
+                if (!uploadEnvRes) {
+                    logger.error(""upload task {} execute path to remote session {} failed"", taskRequest.getEnvFile(),
+                            sessionHost.toString());
+                    result.setExitStatusCode(EXIT_CODE_FAILURE);
+                    return result;
+                }
+            }
+
+            // because JSch .chmod is not stable, so use the 'chmod -R' instead
+            logger.info(""update remote path's permission:{} on session:{} to 755"", taskRequest.getExecutePath(),
+                    sessionHost.toString());
+            String chmodCommand = ""chmod -R 755 "" + taskRequest.getExecutePath();","[{'comment': ""Why it should chmod 755? I'm not sure whether it will cause some CVE? cc @ruanwenjun "", 'commenter': 'caishunfeng'}, {'comment': ""> Why it should chmod 755? I'm not sure whether it will cause some CVE? cc @ruanwenjun\r\n\r\nbecause remote server should keep same as DS worker, and just chmod the execute path, if there are any worry, we can change to 600. WDYT"", 'commenter': 'DarkAssassinator'}, {'comment': ""> > Why it should chmod 755? I'm not sure whether it will cause some CVE? cc @ruanwenjun\r\n> \r\n> because remote server should keep same as DS worker, and just chmod the execute path, if there are any worry, we can change to 600. WDYT\r\n\r\nIf chmod 600 can work, I think it is better."", 'commenter': 'caishunfeng'}, {'comment': ""> > > Why it should chmod 755? I'm not sure whether it will cause some CVE? cc @ruanwenjun\r\n> > \r\n> > \r\n> > because remote server should keep same as DS worker, and just chmod the execute path, if there are any worry, we can change to 600. WDYT\r\n> \r\n> If chmod 600 can work, I think it is better.\r\n\r\nohh sorry, my mistake, not 600, chmod 700 should be ok"", 'commenter': 'DarkAssassinator'}]"
12736,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/ssh/PooledSSHSessionFactory.java,"@@ -0,0 +1,68 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.api.ssh;
+
+import org.apache.dolphinscheduler.plugin.task.api.model.SSHSessionHost;
+
+import org.apache.commons.pool2.BaseKeyedPooledObjectFactory;
+import org.apache.commons.pool2.DestroyMode;
+import org.apache.commons.pool2.PooledObject;
+import org.apache.commons.pool2.impl.DefaultPooledObject;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * ACP SSH Session factory
+ */
+public class PooledSSHSessionFactory extends BaseKeyedPooledObjectFactory<SSHSessionHost, SSHSessionHolder> {
+
+    private static final Logger logger = LoggerFactory.getLogger(PooledSSHSessionFactory.class);
+
+    @Override
+    public SSHSessionHolder create(SSHSessionHost sshSessionHost) throws Exception {
+        SSHSessionHolder pooledObject = new SSHSessionHolder(sshSessionHost);
+        pooledObject.connect();
+        return pooledObject;
+    }
+
+    @Override
+    public PooledObject<SSHSessionHolder> wrap(SSHSessionHolder sshSessionHolder) {
+        return new DefaultPooledObject<>(sshSessionHolder);
+    }
+
+    @Override
+    public void destroyObject(SSHSessionHost key, PooledObject<SSHSessionHolder> p,
+                              DestroyMode destroyMode) throws Exception {
+        logger.info(""destroy session {}"", p.getObject().toString());
+        p.getObject().disconnect();
+    }
+
+    @Override
+    public boolean validateObject(SSHSessionHost key, PooledObject<SSHSessionHolder> p) {
+        if (p.getObject().isConnected()) {
+            try {
+                p.getObject().keepAlive();
+                return true;
+            } catch (Exception e) {
+                logger.error(""Cannot send alive msg to session of {}"", p.getObject().toString(), e);","[{'comment': '```suggestion\r\n                logger.error(""Cannot send alive msg to session of {}"", p.getObject(), e);\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'done', 'commenter': 'DarkAssassinator'}]"
12881,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -235,36 +236,19 @@ public class WorkflowExecuteRunnable implements Callable<WorkflowSubmitStatue> {
 
     /**
      * @param processInstance         processInstance
-     * @param processService          processService
-     * @param processInstanceDao      processInstanceDao
-     * @param nettyExecutorManager    nettyExecutorManager
-     * @param processAlertManager     processAlertManager
-     * @param masterConfig            masterConfig
-     * @param stateWheelExecuteThread stateWheelExecuteThread
      */
-    public WorkflowExecuteRunnable(
-                                   @NonNull ProcessInstance processInstance,
-                                   @NonNull CommandService commandService,
-                                   @NonNull ProcessService processService,
-                                   @NonNull ProcessInstanceDao processInstanceDao,
-                                   @NonNull NettyExecutorManager nettyExecutorManager,
-                                   @NonNull ProcessAlertManager processAlertManager,
-                                   @NonNull MasterConfig masterConfig,
-                                   @NonNull StateWheelExecuteThread stateWheelExecuteThread,
-                                   @NonNull CuringParamsService curingParamsService,
-                                   @NonNull TaskInstanceDao taskInstanceDao,
-                                   @NonNull TaskDefinitionLogDao taskDefinitionLogDao) {
-        this.processService = processService;
-        this.commandService = commandService;
-        this.processInstanceDao = processInstanceDao;
+    public WorkflowExecuteRunnable(@NonNull ProcessInstance processInstance) {
+        this.processService = SpringApplicationContext.getBean(ProcessService.class);","[{'comment': ""This is not a good idea to do this change, `WorkflowExecuteRunnable` is not a spring bean, it shouldn't rely spring."", 'commenter': 'ruanwenjun'}, {'comment': ""> This is not a good idea to do this change, `WorkflowExecuteRunnable` is not a spring bean, it shouldn't rely spring.\r\n\r\nBecuase current all `WorkflowExecuteRunnable` params are spring bean, so i think that we add `SpringApplicationContext` just change another way to get these params. If we should keep `WorkflowExecuteRunnable` clear, may we can migrate all DAO related method to other holder service, but this will lead to too scattered logic. Becuase more and more long params is a bad practies. WDYT."", 'commenter': 'DarkAssassinator'}, {'comment': ""Refactor the contractor doesn't help to make `WorkflowExecuteRunnable ` clear."", 'commenter': 'ruanwenjun'}]"
12886,deploy/kubernetes/dolphinscheduler/Chart.yaml,"@@ -35,11 +35,11 @@ type: application
 
 # This is the chart version. This version number should be incremented each time you make changes
 # to the chart and its templates, including the app version.
-version: 2.0.0
+version: 2.0.1","[{'comment': 'Is it a unrelated change?', 'commenter': 'zhongjiajie'}, {'comment': 'The comment says we should increment `version` if we change `app version`. Did I get it wrong?\r\n![image](https://user-images.githubusercontent.com/34905992/201569308-3a4cffaa-b379-46f7-8e35-74c4dfea33b7.png)\r\n', 'commenter': 'EricGao888'}]"
12886,docs/configs/site.js,"@@ -24,7 +24,7 @@ export default {
   port: 8080,
   domain: 'dolphinscheduler.apache.org',
   copyToDist: ['asset', 'img', 'file', '.asf.yaml', 'sitemap.xml', '.nojekyll', '.htaccess', 'googled0df7b96f277a143.html'],
-  docsLatest: '3.0.1',","[{'comment': 'This file should not change, we use change branch `dev` one instead of branch `3.0.2-prepare` one', 'commenter': 'zhongjiajie'}, {'comment': 'Got it, thx : )', 'commenter': 'EricGao888'}]"
12886,docs/configs/index.md.jsx,"@@ -64,6 +64,7 @@ const docsSource = {
   '2.0.5': docs205Config,
   '3.0.0': docs300Config,
   '3.0.1': docs301Config,
+  '3.0.2': docs302Config,","[{'comment': 'So as this file, we should change branch `dev` before we announce instead of this step', 'commenter': 'zhongjiajie'}, {'comment': 'you can see more detail in section **Update Document**', 'commenter': 'zhongjiajie'}, {'comment': '> you can see more detail in section _Update Document_\r\n\r\nLooks like we need some updates for the docs. I will submit a PR later to add more instructions. \r\n![image](https://user-images.githubusercontent.com/34905992/201569718-f36e8365-5c36-4338-baf8-4c9a011c2ba6.png)\r\n', 'commenter': 'EricGao888'}]"
12897,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -477,6 +477,8 @@ private void retryTaskInstance(TaskInstance taskInstance) throws StateEventHandl
                     taskInstance.getId());
             return;
         }
+        // retry set task id
+        newTaskInstance.setId(taskInstance.getId());","[{'comment': 'You can not set the id here, this may cause the task instance cannot insert.', 'commenter': 'ruanwenjun'}]"
12946,dolphinscheduler-tools/src/main/java/org/apache/dolphinscheduler/tools/demo/ProxyProcessDefinitionController.java,"@@ -71,7 +70,7 @@ public ProxyResult createProcessDefinition(String token,
         } catch (IOException e) {
             throw new RuntimeException(e);
         }
-        proxyResult = JSONUtils.parseObject(responseBody, ProxyResult.class);
+        ProxyResult proxyResult = JSONUtils.parseObject(responseBody, ProxyResult.class);
 
         return proxyResult;","[{'comment': '```suggestion\r\n        return JSONUtils.parseObject(responseBody, ProxyResult.class);\r\n```', 'commenter': 'Radeity'}]"
12969,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java,"@@ -153,13 +154,16 @@
      * @param startDate   start date
      * @param endDate     end date
      */
-    private Map<String, Object> countStateByProject(User loginUser, long projectCode, String startDate, String endDate,
-                                                    TriFunction<Date, Date, Long[], List<ExecuteStatusCount>> instanceStateCounter) {
-        Map<String, Object> result = new HashMap<>();
+    private Result countStateByProject(User loginUser, long projectCode, String startDate, String endDate,
+                                       TriFunction<Date, Date, Long[], List<ExecuteStatusCount>> instanceStateCounter) {
+        Result result = new Result();
         if (projectCode != 0) {
             Project project = projectMapper.queryByCode(projectCode);
-            result = projectService.checkProjectAndAuth(loginUser, project, projectCode, PROJECT_OVERVIEW);
-            if (result.get(Constants.STATUS) != Status.SUCCESS) {
+            Map<String, Object> checkResult =
+                    projectService.checkProjectAndAuth(loginUser, project, projectCode, PROJECT_OVERVIEW);","[{'comment': '## User-controlled bypass of sensitive method\n\nSensitive method may not be executed depending on a [this condition](1), which flows from [user-controlled value](2).\nSensitive method may not be executed depending on a [this condition](1), which flows from [user-controlled value](3).\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2342)', 'commenter': 'github-advanced-security[bot]'}]"
12969,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/DataAnalysisServiceImpl.java,"@@ -205,22 +209,25 @@
      * @return definition count data
      */
     @Override
-    public Map<String, Object> countDefinitionByUser(User loginUser, long projectCode) {
-        Map<String, Object> result = new HashMap<>();
+    public Result countDefinitionByUser(User loginUser, long projectCode) {
+        Result result = new Result();
         if (projectCode != 0) {
             Project project = projectMapper.queryByCode(projectCode);
-            result = projectService.checkProjectAndAuth(loginUser, project, projectCode, PROJECT_OVERVIEW);
-            if (result.get(Constants.STATUS) != Status.SUCCESS) {
+            Map<String, Object> checkResult =
+                    projectService.checkProjectAndAuth(loginUser, project, projectCode, PROJECT_OVERVIEW);","[{'comment': '## User-controlled bypass of sensitive method\n\nSensitive method may not be executed depending on a [this condition](1), which flows from [user-controlled value](2).\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2343)', 'commenter': 'github-advanced-security[bot]'}]"
12969,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/DataAnalysisService.java,"@@ -63,23 +62,23 @@
      * @param projectCode project code
      * @return definition count data
      */
-    Map<String, Object> countDefinitionByUser(User loginUser, long projectCode);
+    Result countDefinitionByUser(User loginUser, long projectCode);
 
     /**
      * statistical command status data
      *
      * @param loginUser login user
      * @return command state count data
      */
-    Map<String, Object> countCommandState(User loginUser);
+    Result countCommandState(User loginUser);
 
     /**
      * count queue state
      *
      * @param loginUser login user
      * @return queue state count data
      */
-    Map<String, Object> countQueueState(User loginUser);
+    Result countQueueState(User loginUser);","[{'comment': ""## Useless parameter\n\nThe parameter 'loginUser' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2341)"", 'commenter': 'github-advanced-security[bot]'}]"
12969,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/DataAnalysisService.java,"@@ -41,7 +42,7 @@ public interface DataAnalysisService {
      * @param endDate     end date
      * @return task state count data
      */
-    Map<String, Object> countTaskStateByProject(User loginUser, long projectCode, String startDate, String endDate);
+    Result countTaskStateByProject(User loginUser, long projectCode, String startDate, String endDate);","[{'comment': '`Result` should be encapsulated in `Collonter` layer, not `service` layer', 'commenter': 'CalvinKirs'}, {'comment': 'But in the interface v2(path:src/main/java/org/apache/dolphinscheduler/api/controller/v2), In most cases, Result be encapsulated in service layer', 'commenter': 'Zzih'}, {'comment': 'We better be able to revisit this', 'commenter': 'CalvinKirs'}, {'comment': 'there are too many cases about `Result`, we can discuss where to put the `Result` later', 'commenter': 'davidzollo'}]"
12980,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -241,8 +235,7 @@ private void updateMasterNodes() {
         try {
             registryClient.getLock(nodeLock);
             Collection<String> currentNodes = registryClient.getMasterNodesDirectly();
-            List<Server> masterNodes = registryClient.getServerList(NodeType.MASTER);
-            syncMasterNodes(currentNodes, masterNodes);
+            syncMasterNodes(currentNodes, registryClient.getServerList(NodeType.MASTER));","[{'comment': 'There is no need to do this code change.', 'commenter': 'ruanwenjun'}, {'comment': '> There is no need to do this code change.\r\n\r\nBecause `masterNodes` local variable should not shadow class fields. Override or shadow a variable declared in the outer scope can strongly impact the readability,and it will lead mantainers to introduce bugs because they think they are using one variable but are really using another. WDYT.', 'commenter': 'DarkAssassinator'}, {'comment': 'Make sense.', 'commenter': 'ruanwenjun'}]"
12980,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -153,29 +153,15 @@ class WorkerNodeInfoAndGroupDbSyncTask implements Runnable {
         @Override
         public void run() {
             try {
-
                 // sync worker node info
                 updateWorkerNodes();
                 updateWorkerGroupMappings();
-                notifyWorkerInfoChangeListeners();","[{'comment': 'Why you remove this?  this is used to notifier the `LowerWeightHostManager`', 'commenter': 'ruanwenjun'}, {'comment': '> Why you remove this? this is used to notifier the `LowerWeightHostManager`\r\n\r\nBecause `updateWorkerGroupMapping` has notify(has invoke `notifyWorkerInfoChangeListener`). So we do not need to repeat it a second time.', 'commenter': 'DarkAssassinator'}, {'comment': ""It's better to remove the method in `updateWorkerGroupMappings`"", 'commenter': 'ruanwenjun'}, {'comment': ""> It's better to remove the method in `updateWorkerGroupMappings`\r\n\r\nbut others also will invoke `updateWorkerGroupMappings`, such as spring bean init. May `notifyWorkerInfoChangeListener` keep in `updateWorkerGroupMappings` should be more clear. WDYT.\r\n![image](https://user-images.githubusercontent.com/20518339/203802201-418c5cfb-1d29-4eab-93c1-4499ec801513.png)\r\n"", 'commenter': 'DarkAssassinator'}, {'comment': 'so i move all update worker node info methods to a private methods.', 'commenter': 'DarkAssassinator'}]"
12980,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -382,10 +366,8 @@ public synchronized void addWorkerInfoChangeListener(WorkerInfoChangeListener li
     }
 
     private void notifyWorkerInfoChangeListeners() {
-        Map<String, Set<String>> workerGroupNodes = getWorkerGroupNodes();
-        Map<String, WorkerHeartBeat> workerNodeInfo = getWorkerNodeInfo();
         for (WorkerInfoChangeListener listener : workerInfoChangeListeners) {
-            listener.notify(workerGroupNodes, workerNodeInfo);
+            listener.notify(getWorkerGroupNodes(), getWorkerNodeInfo());","[{'comment': ""I don't think this will make the code clean."", 'commenter': 'ruanwenjun'}, {'comment': ""> I don't think this will make the code clean.\r\n\r\n+1,  I think we should not call `getWorkerGroupNodes` and `getWorkerNodeInfo` in the loop, although they just operate in memory."", 'commenter': 'caishunfeng'}, {'comment': ""> I don't think this will make the code clean.\r\n\r\n+1."", 'commenter': 'SbloodyS'}, {'comment': 'ohh, my mistake. This is a loop, my original intention is to remove the fields that have the same name as the fields defined above. I will rollback it and rename these two fields.', 'commenter': 'DarkAssassinator'}, {'comment': 'done', 'commenter': 'DarkAssassinator'}]"
13050,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/json/DateJsonSerializer.java,"@@ -33,6 +34,14 @@ public class DateJsonSerializer extends JsonSerializer<Date> {
 
     @Override
     public void serialize(Date value, JsonGenerator gen, SerializerProvider serializers) throws IOException {
-        gen.writeString(DateUtils.dateToString(value));
+        Date temp = value;
+        // In the internal implementation of JDK, sql.Date is inherited from util.Date, and sql.Date has rewritten many methods in util.Date, but it has not been implemented.","[{'comment': 'plz write the full path to the class ,like ``` java.util.Date```', 'commenter': 'fuchanghai'}]"
13050,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/json/DateJsonSerializer.java,"@@ -33,6 +34,15 @@ public class DateJsonSerializer extends JsonSerializer<Date> {
 
     @Override
     public void serialize(Date value, JsonGenerator gen, SerializerProvider serializers) throws IOException {
-        gen.writeString(DateUtils.dateToString(value));
+        Date temp = value;
+        // In the internal implementation of JDK, java.sql.Date is inherited from java.util.Date, and java.sql.Date has
+        // rewritten many methods in java.util.Date, but it has not been implemented.
+        // Later, when formatting, you need to call the method in Date to report an error.
+        if (value instanceof java.sql.Date) {
+            Calendar calendar = Calendar.getInstance();
+            calendar.setTime(value);
+            temp = calendar.getTime();
+        }","[{'comment': 'The right way is to fix this at `DateUtils.dateToString`, rather than modify this class.', 'commenter': 'ruanwenjun'}]"
13050,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/DateUtils.java,"@@ -75,6 +75,15 @@ private static LocalDateTime date2LocalDateTime(Date date) {
      * @return local datetime
      */
     private static LocalDateTime date2LocalDateTime(Date date, ZoneId zoneId) {
+        // In the internal implementation of JDK, java.sql.Date is inherited from java.util.Date, and java.sql.Date has
+        // not been implemented toInstant() method. If call this method, it will throw new
+        // java.lang.UnsupportedOperationException(). Here just convert java.sql.Date to java.util.Date
+        // to avoid the error.
+        if (date instanceof java.sql.Date) {
+            Calendar calendar = Calendar.getInstance();
+            calendar.setTime(date);
+            date = calendar.getTime();
+        }
         return LocalDateTime.ofInstant(date.toInstant(), zoneId);","[{'comment': '```suggestion\r\n        return LocalDateTime.ofInstant(Instant.of(date.getTime()), zoneId);\r\n```', 'commenter': 'ruanwenjun'}]"
13050,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/json/DateJsonSerializer.java,"@@ -17,17 +17,15 @@
 
 package org.apache.dolphinscheduler.service.json;
 
+import com.fasterxml.jackson.core.JsonGenerator;","[{'comment': 'Please revert this change.', 'commenter': 'ruanwenjun'}]"
13070,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskInstanceServiceImpl.java,"@@ -306,4 +306,31 @@ public Result stopTask(User loginUser, long projectCode, Integer taskInstanceId)
 
         return result;
     }
+
+    @Override
+    public Result queryTaskInstanceByCode(User loginUser, long projectCode, Long taskCode) {
+        Result result = new Result();
+
+        Project project = projectMapper.queryByCode(projectCode);
+        // check user access for project
+        Map<String, Object> checkResult =
+                projectService.checkProjectAndAuth(loginUser, project, projectCode, FORCED_SUCCESS);
+        Status status = (Status) checkResult.get(Constants.STATUS);
+        if (status != Status.SUCCESS) {
+            putMsg(result, status);
+            return result;
+        }","[{'comment': '```suggestion\r\n        projectService.checkProjectAndAuthThrowException(loginUser, project, projectCode, FORCED_SUCCESS);\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'done.', 'commenter': 'insist777'}]"
13070,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskInstanceServiceImpl.java,"@@ -306,4 +306,31 @@ public Result stopTask(User loginUser, long projectCode, Integer taskInstanceId)
 
         return result;
     }
+
+    @Override
+    public Result queryTaskInstanceByCode(User loginUser, long projectCode, Long taskCode) {","[{'comment': 'This is a new method, I think we should return a exact object but not result, WDYT? @zhongjiajie \r\n```suggestion\r\n    public TaskInstance queryTaskInstanceByCode(User loginUser, long projectCode, Long taskCode) {\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'Yeah, we should return the entity instead of  Result object, the pros is when we have cli or API, they could use the return entity directly instead of by parsing the result object\r\nI think the results object should be wrapper by controller.', 'commenter': 'zhongjiajie'}]"
13070,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/mapper/TaskInstanceMapper.java,"@@ -154,5 +154,7 @@ IPage<TaskInstance> queryStreamTaskInstanceListPaging(IPage<TaskInstance> page,
     List<TaskInstance> loadAllInfosNoRelease(@Param(""processInstanceId"") int processInstanceId,
                                              @Param(""status"") int status);
 
+    TaskInstance selectByCode(Long taskCode);","[{'comment': 'If select by task code, it may exist multi records.\r\n```suggestion\r\n    List<TaskInstance> selectByCode(Long taskCode);\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'So by id indeed, and will return one single record if we use id', 'commenter': 'zhongjiajie'}]"
13070,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceV2Controller.java,"@@ -127,4 +174,27 @@ public TaskInstanceSuccessResponse forceTaskSuccess(@Parameter(hidden = true) @R
         Result result = taskInstanceService.forceTaskSuccess(loginUser, projectCode, id);
         return new TaskInstanceSuccessResponse(result);
     }
+
+    /**
+     * query taskInstance by taskInstanceCode
+     *
+     * @param loginUser   login user
+     * @param projectCode project code
+     * @param taskCode          task code
+     * @return the result code and msg
+     */
+    @Operation(summary = ""queryOneTaskInstance"", description = ""QUERY_ONE_TASK_INSTANCE"")
+    @Parameters({
+            @Parameter(name = ""taskCode"", description = ""TASK_INSTANCE_CODE"", required = true, schema = @Schema(implementation = Long.class), example = ""1234567890"")
+    })
+    @PostMapping(value = ""/{taskCode}"", consumes = {""application/json""})","[{'comment': 'I think we should use id instead of task code to get one single task instance ', 'commenter': 'zhongjiajie'}]"
13070,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskInstanceServiceImpl.java,"@@ -306,4 +306,31 @@ public Result stopTask(User loginUser, long projectCode, Integer taskInstanceId)
 
         return result;
     }
+
+    @Override
+    public Result queryTaskInstanceByCode(User loginUser, long projectCode, Long taskCode) {
+        Result result = new Result();
+
+        Project project = projectMapper.queryByCode(projectCode);
+        // check user access for project
+        Map<String, Object> checkResult =
+                projectService.checkProjectAndAuth(loginUser, project, projectCode, FORCED_SUCCESS);
+        Status status = (Status) checkResult.get(Constants.STATUS);
+        if (status != Status.SUCCESS) {
+            putMsg(result, status);
+            return result;
+        }
+        TaskInstance taskInstance = taskInstanceMapper.selectByCode(taskCode);
+        if (taskInstance == null) {
+            logger.error(""Task definition can not be found, projectCode:{}, taskInstanceCode:{}."", projectCode,
+                    taskCode);","[{'comment': 'we can throw server exception here directly ', 'commenter': 'zhongjiajie'}]"
13070,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/TaskInstanceV2Controller.java,"@@ -127,4 +175,27 @@
         Result result = taskInstanceService.forceTaskSuccess(loginUser, projectCode, id);
         return new TaskInstanceSuccessResponse(result);
     }
+
+    /**
+     * query taskInstance by taskInstanceCode
+     *
+     * @param loginUser   login user
+     * @param projectCode project code
+     * @param taskCode          task code","[{'comment': '## Spurious Javadoc @param tags\n\n@param tag ""taskCode"" does not match any actual parameter of method ""queryTaskInstanceByCode()"".\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2388)', 'commenter': 'github-advanced-security[bot]'}]"
13070,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/TaskInstanceService.java,"@@ -89,4 +90,14 @@
      * @return
      */
     Result stopTask(User loginUser, long projectCode, Integer taskInstanceId);
+
+    /**
+     * query taskInstance by taskInstanceCode
+     *
+     * @param loginUser   login user
+     * @param projectCode project code
+     * @param taskCode          task instance code","[{'comment': '## Spurious Javadoc @param tags\n\n@param tag ""taskCode"" does not match any actual parameter of method ""queryTaskInstanceByCode()"".\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2389)', 'commenter': 'github-advanced-security[bot]'}]"
13092,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/SchedulerServiceImpl.java,"@@ -171,6 +171,9 @@ public Map<String, Object> insertSchedule(User loginUser,
         scheduleObj.setProcessDefinitionName(processDefinition.getName());
 
         ScheduleParam scheduleParam = JSONUtils.parseObject(schedule, ScheduleParam.class);
+        if (now.after(scheduleParam.getStartTime())) {
+            scheduleParam.setStartTime(now);
+        }","[{'comment': 'could we refactor to a private method?', 'commenter': 'DarkAssassinator'}, {'comment': ""> could we refactor to a private method?\r\n\r\nI considered before, actually, there are many duplicated code in `SchedulerServiceImpl`, then i found that codes of api V2 are cleaner. Anyway, i'll refactor some bug-related code part in this file, thx!"", 'commenter': 'Radeity'}, {'comment': ""Hi, @DarkAssassinator, i have thought again, maybe there's not a strong need to move this simple condition judgement into a separate method, like other `startTime` related checks, WDYT?"", 'commenter': 'Radeity'}]"
13092,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/SchedulerServiceImpl.java,"@@ -171,6 +171,9 @@ public Map<String, Object> insertSchedule(User loginUser,
         scheduleObj.setProcessDefinitionName(processDefinition.getName());
 
         ScheduleParam scheduleParam = JSONUtils.parseObject(schedule, ScheduleParam.class);
+        if (now.after(scheduleParam.getStartTime())) {
+            scheduleParam.setStartTime(now);","[{'comment': ""It's better don't modify the user's input, this may be thought as a bug."", 'commenter': 'ruanwenjun'}, {'comment': ""> It's better don't modify the user's input, this may be thought as a bug.\r\n\r\nOkay, i'll make some changes that return warning message if setting start time earlier than current time, also change the default start time in front-end to 0:00 of the next day? WDYT."", 'commenter': 'Radeity'}, {'comment': 'Can we rollback the strategy?', 'commenter': 'ruanwenjun'}, {'comment': 'How to handle the scenario described in https://github.com/apache/dolphinscheduler/issues/12231?', 'commenter': 'Radeity'}, {'comment': '@ruanwenjun Any new suggestions?', 'commenter': 'Radeity'}]"
13092,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/SchedulerServiceImpl.java,"@@ -234,6 +239,10 @@ private void scheduleParamCheck(String scheduleParamStr) {
         if (scheduleParam == null) {
             throw new ServiceException(Status.PARSE_SCHEDULE_PARAM_ERROR, scheduleParamStr);
         }
+        Date now = new Date();
+        if (now.after(scheduleParam.getStartTime())) {
+            throw new ServiceException(Status.START_TIME_BEFORE_CURRENT_TIME_ERROR);
+        }","[{'comment': ""I think this check can only use for the create action, but not for updating.\r\nI found the `scheduleParamCheck` is called by `updateSchedulesV2`, I think it's better to split it."", 'commenter': 'caishunfeng'}, {'comment': ""> I think this check can only use for the create action, but not for updating. I found the `scheduleParamCheck` is called by `updateSchedulesV2`, I think it's better to split it.\r\n\r\nHi, @caishunfeng, `updateSchedulesV2` is called by updateSchedulesV2, either.\r\n```java\r\ntry {\r\n        scheduleUpdate = scheduleUpdateRequest.mergeIntoSchedule(schedule);\r\n        // check update params\r\n        this.scheduleParamCheck(scheduleUpdateRequest.updateScheduleParam(scheduleUpdate));\r\n}\r\n```"", 'commenter': 'Radeity'}]"
13092,dolphinscheduler-ui/src/views/projects/workflow/definition/components/use-form.ts,"@@ -95,7 +95,7 @@ export const useForm = () => {
     timingFormRef: ref(),
     timingForm: {
       startEndTime: [
-        new Date(year, month, day),
+        new Date(year, month, day + 1),","[{'comment': 'Just curious, why did u do this here?', 'commenter': 'EricGao888'}, {'comment': 'It will return warning message if setting start time earlier than current time, so default start time should be valid.\r\n', 'commenter': 'Radeity'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessTaskRelationService.java,"@@ -90,6 +90,7 @@ void deleteTaskProcessRelationV2(User loginUser,
      */
     List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
                                                            long taskCode,
+                                                           boolean needSyncDag,","[{'comment': ""It's better to create a new method like `updateUpstreamTaskDefinitionWithSyncDag`, WDYT?"", 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,104 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }","[{'comment': '```suggestion\r\n        } \r\n       logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",\r\n                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);\r\n```', 'commenter': 'caishunfeng'}, {'comment': 'good catch', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/dto/task/TaskCreateRequest.java,"@@ -97,7 +97,7 @@ public class TaskCreateRequest {
     private Integer memoryMax;
 
     @Schema(example = ""upstream-task-codes1,upstream-task-codes2"", description = ""use , to split multiple upstream task codes"")
-    private String upstreamTasksCodes;
+    private String upstreamTasksCodes = ""0"";","[{'comment': ""What's the default value mean?"", 'commenter': 'caishunfeng'}, {'comment': 'mean the root node of dag, maybe we should add constants for this', 'commenter': 'zhongjiajie'}, {'comment': '@insist777  we should still use constants for this value', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,104 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processDefinitionUpdate.setVersion(insertVersion);
+        return processDefinitionUpdate;
+    }
+    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog(processDefinition);
+        Integer version = processDefinitionLogMapper.queryMaxVersionForDefinition(processDefinition.getCode());
+        int insertVersion = version == null || version == 0 ? Constants.VERSION_FIRST : version + 1;
+        processDefinitionLog.setVersion(insertVersion);
+
+        processDefinitionLog.setOperator(loginUser.getId());
+        processDefinitionLog.setOperateTime(processDefinition.getUpdateTime());
+        processDefinitionLog.setId(null);
+        int insertLog = processDefinitionLogMapper.insert(processDefinitionLog);
+        processDefinitionLog.setId(processDefinition.getId());
+        int result = processDefinitionMapper.updateById(processDefinitionLog);","[{'comment': 'Please use two different object to do it.\r\n\r\nWhy need to update the old one with new object?', 'commenter': 'caishunfeng'}, {'comment': 'Yeah, It seems you directly copy-paste the code from the process service to here, but is it better to refactor them and make them more sense, when we want to operator `processDefinitionMapper ` show use `ProcessDefinition` object instead of  `ProcessDefinitionLog`', 'commenter': 'zhongjiajie'}, {'comment': 'And BTW, as the ProcessDefinitionLog is a snapshot of ProcessDefinition, I think we should better update ProcessDefinition before we ProcessDefinitionLog to make it more sense', 'commenter': 'zhongjiajie'}, {'comment': '> Yeah, It seems you directly copy-paste the code from the process service to here, but is it better to refactor them and make them more sense, when we want to operator `processDefinitionMapper ` show use `ProcessDefinition` object instead of `ProcessDefinitionLog`\r\n\r\nCan we change according this suggestion', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,104 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processDefinitionUpdate.setVersion(insertVersion);
+        return processDefinitionUpdate;
+    }
+    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog(processDefinition);
+        Integer version = processDefinitionLogMapper.queryMaxVersionForDefinition(processDefinition.getCode());
+        int insertVersion = version == null || version == 0 ? Constants.VERSION_FIRST : version + 1;
+        processDefinitionLog.setVersion(insertVersion);
+
+        processDefinitionLog.setOperator(loginUser.getId());
+        processDefinitionLog.setOperateTime(processDefinition.getUpdateTime());
+        processDefinitionLog.setId(null);
+        int insertLog = processDefinitionLogMapper.insert(processDefinitionLog);
+        processDefinitionLog.setId(processDefinition.getId());
+        int result = processDefinitionMapper.updateById(processDefinitionLog);
+        return (insertLog & result) > 0 ? insertVersion : 0;
+    }
+
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,
+                                int processDefinitionVersion) {
+        long projectCode = processDefinition.getProjectCode();
+        long processDefinitionCode = processDefinition.getCode();
+        List<ProcessTaskRelation> taskRelations =
+                processTaskRelationMapper.queryByProcessCode(projectCode, processDefinitionCode);
+        List<ProcessTaskRelationLog> taskRelationList =
+                taskRelations.stream().map(ProcessTaskRelationLog::new).collect(Collectors.toList());
+
+        List<Long> taskCodeList =
+                taskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toList());
+        List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(taskCodeList);
+        List<TaskDefinitionLog> taskDefinitionLogs =
+                taskDefinitions.stream().map(TaskDefinitionLog::new).collect(Collectors.toList());
+
+        if (taskRelationList.isEmpty()) {
+            return Constants.EXIT_CODE_SUCCESS;
+        }
+        Map<Long, TaskDefinitionLog> taskDefinitionLogMap = null;
+        if (org.apache.commons.collections.CollectionUtils.isNotEmpty(taskDefinitionLogs)) {","[{'comment': '```suggestion\r\n        if (CollectionUtils.isNotEmpty(taskDefinitionLogs)) {\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,104 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processDefinitionUpdate.setVersion(insertVersion);
+        return processDefinitionUpdate;
+    }
+    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog(processDefinition);
+        Integer version = processDefinitionLogMapper.queryMaxVersionForDefinition(processDefinition.getCode());
+        int insertVersion = version == null || version == 0 ? Constants.VERSION_FIRST : version + 1;
+        processDefinitionLog.setVersion(insertVersion);
+
+        processDefinitionLog.setOperator(loginUser.getId());
+        processDefinitionLog.setOperateTime(processDefinition.getUpdateTime());
+        processDefinitionLog.setId(null);
+        int insertLog = processDefinitionLogMapper.insert(processDefinitionLog);
+        processDefinitionLog.setId(processDefinition.getId());
+        int result = processDefinitionMapper.updateById(processDefinitionLog);
+        return (insertLog & result) > 0 ? insertVersion : 0;
+    }
+
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,
+                                int processDefinitionVersion) {
+        long projectCode = processDefinition.getProjectCode();
+        long processDefinitionCode = processDefinition.getCode();
+        List<ProcessTaskRelation> taskRelations =
+                processTaskRelationMapper.queryByProcessCode(projectCode, processDefinitionCode);
+        List<ProcessTaskRelationLog> taskRelationList =
+                taskRelations.stream().map(ProcessTaskRelationLog::new).collect(Collectors.toList());
+
+        List<Long> taskCodeList =
+                taskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toList());
+        List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(taskCodeList);
+        List<TaskDefinitionLog> taskDefinitionLogs =
+                taskDefinitions.stream().map(TaskDefinitionLog::new).collect(Collectors.toList());
+
+        if (taskRelationList.isEmpty()) {
+            return Constants.EXIT_CODE_SUCCESS;
+        }
+        Map<Long, TaskDefinitionLog> taskDefinitionLogMap = null;
+        if (org.apache.commons.collections.CollectionUtils.isNotEmpty(taskDefinitionLogs)) {
+            taskDefinitionLogMap = taskDefinitionLogs
+                    .stream()
+                    .collect(Collectors.toMap(TaskDefinition::getCode, taskDefinitionLog -> taskDefinitionLog));
+        }
+        Date now = new Date();
+        for (ProcessTaskRelationLog processTaskRelationLog : taskRelationList) {
+            processTaskRelationLog.setProjectCode(projectCode);
+            processTaskRelationLog.setProcessDefinitionCode(processDefinitionCode);
+            processTaskRelationLog.setProcessDefinitionVersion(processDefinitionVersion);
+            if (taskDefinitionLogMap != null) {
+                TaskDefinitionLog preTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPreTaskCode());
+                if (preTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPreTaskVersion(preTaskDefinitionLog.getVersion());
+                }
+                TaskDefinitionLog postTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPostTaskCode());
+                if (postTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPostTaskVersion(postTaskDefinitionLog.getVersion());
+                }
+            }
+            processTaskRelationLog.setCreateTime(now);
+            processTaskRelationLog.setUpdateTime(now);
+            processTaskRelationLog.setOperator(loginUser.getId());
+            processTaskRelationLog.setOperateTime(now);
+        }
+        if (!taskRelations.isEmpty()) {
+            Set<Integer> processTaskRelationSet =
+                    taskRelations.stream().map(ProcessTaskRelation::hashCode).collect(toSet());
+            Set<Integer> taskRelationSet =
+                    taskRelationList.stream().map(ProcessTaskRelationLog::hashCode).collect(toSet());
+            boolean result = org.apache.commons.collections.CollectionUtils.isEqualCollection(processTaskRelationSet,","[{'comment': '```suggestion\r\n            boolean result = CollectionUtils.isEqualCollection(processTaskRelationSet,\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,104 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processDefinitionUpdate.setVersion(insertVersion);
+        return processDefinitionUpdate;
+    }
+    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog(processDefinition);
+        Integer version = processDefinitionLogMapper.queryMaxVersionForDefinition(processDefinition.getCode());
+        int insertVersion = version == null || version == 0 ? Constants.VERSION_FIRST : version + 1;
+        processDefinitionLog.setVersion(insertVersion);
+
+        processDefinitionLog.setOperator(loginUser.getId());
+        processDefinitionLog.setOperateTime(processDefinition.getUpdateTime());
+        processDefinitionLog.setId(null);
+        int insertLog = processDefinitionLogMapper.insert(processDefinitionLog);
+        processDefinitionLog.setId(processDefinition.getId());
+        int result = processDefinitionMapper.updateById(processDefinitionLog);
+        return (insertLog & result) > 0 ? insertVersion : 0;
+    }
+
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,
+                                int processDefinitionVersion) {
+        long projectCode = processDefinition.getProjectCode();
+        long processDefinitionCode = processDefinition.getCode();
+        List<ProcessTaskRelation> taskRelations =
+                processTaskRelationMapper.queryByProcessCode(projectCode, processDefinitionCode);
+        List<ProcessTaskRelationLog> taskRelationList =
+                taskRelations.stream().map(ProcessTaskRelationLog::new).collect(Collectors.toList());
+
+        List<Long> taskCodeList =
+                taskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toList());
+        List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(taskCodeList);
+        List<TaskDefinitionLog> taskDefinitionLogs =
+                taskDefinitions.stream().map(TaskDefinitionLog::new).collect(Collectors.toList());
+
+        if (taskRelationList.isEmpty()) {
+            return Constants.EXIT_CODE_SUCCESS;
+        }
+        Map<Long, TaskDefinitionLog> taskDefinitionLogMap = null;
+        if (org.apache.commons.collections.CollectionUtils.isNotEmpty(taskDefinitionLogs)) {
+            taskDefinitionLogMap = taskDefinitionLogs
+                    .stream()
+                    .collect(Collectors.toMap(TaskDefinition::getCode, taskDefinitionLog -> taskDefinitionLog));
+        }
+        Date now = new Date();
+        for (ProcessTaskRelationLog processTaskRelationLog : taskRelationList) {
+            processTaskRelationLog.setProjectCode(projectCode);
+            processTaskRelationLog.setProcessDefinitionCode(processDefinitionCode);
+            processTaskRelationLog.setProcessDefinitionVersion(processDefinitionVersion);
+            if (taskDefinitionLogMap != null) {
+                TaskDefinitionLog preTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPreTaskCode());
+                if (preTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPreTaskVersion(preTaskDefinitionLog.getVersion());
+                }
+                TaskDefinitionLog postTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPostTaskCode());
+                if (postTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPostTaskVersion(postTaskDefinitionLog.getVersion());
+                }
+            }
+            processTaskRelationLog.setCreateTime(now);
+            processTaskRelationLog.setUpdateTime(now);
+            processTaskRelationLog.setOperator(loginUser.getId());
+            processTaskRelationLog.setOperateTime(now);
+        }
+        if (!taskRelations.isEmpty()) {
+            Set<Integer> processTaskRelationSet =
+                    taskRelations.stream().map(ProcessTaskRelation::hashCode).collect(toSet());
+            Set<Integer> taskRelationSet =
+                    taskRelationList.stream().map(ProcessTaskRelationLog::hashCode).collect(toSet());
+            boolean result = org.apache.commons.collections.CollectionUtils.isEqualCollection(processTaskRelationSet,
+                    taskRelationSet);
+            if (result) {
+                return Constants.EXIT_CODE_SUCCESS;","[{'comment': 'Please add some log here.', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -473,10 +496,99 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         }
 
         // batch sync to process task relation log
-        this.batchPersist2ProcessTaskRelationLog(loginUser, processTaskRelations);
+        int saveTaskRelation = saveTaskRelation(loginUser, processDefinition, insertVersion);","[{'comment': '```suggestion\r\n        int saveTaskRelationResult = saveTaskRelation(loginUser, processDefinition, insertVersion);\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -473,10 +496,99 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         }
 
         // batch sync to process task relation log
-        this.batchPersist2ProcessTaskRelationLog(loginUser, processTaskRelations);
+        int saveTaskRelation = saveTaskRelation(loginUser, processDefinition, insertVersion);
+        if (saveTaskRelation != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }","[{'comment': '```suggestion\r\n        } \r\n        logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",\r\n                processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -473,10 +496,99 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         }
 
         // batch sync to process task relation log
-        this.batchPersist2ProcessTaskRelationLog(loginUser, processTaskRelations);
+        int saveTaskRelation = saveTaskRelation(loginUser, processDefinition, insertVersion);
+        if (saveTaskRelation != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processTaskRelations.get(0).setProcessDefinitionVersion(insertVersion);","[{'comment': 'Why set workflow version here? Just for the first one?', 'commenter': 'caishunfeng'}, {'comment': 'To return the intuitive and accurate version to the user.', 'commenter': 'insist777'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -473,10 +496,99 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         }
 
         // batch sync to process task relation log
-        this.batchPersist2ProcessTaskRelationLog(loginUser, processTaskRelations);
+        int saveTaskRelation = saveTaskRelation(loginUser, processDefinition, insertVersion);
+        if (saveTaskRelation != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processTaskRelations.get(0).setProcessDefinitionVersion(insertVersion);
         return processTaskRelations;
     }
 
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,
+                                int processDefinitionVersion) {
+        long projectCode = processDefinition.getProjectCode();
+        long processDefinitionCode = processDefinition.getCode();
+        List<ProcessTaskRelation> taskRelations =
+                processTaskRelationMapper.queryByProcessCode(projectCode, processDefinitionCode);
+        List<ProcessTaskRelationLog> taskRelationList =
+                taskRelations.stream().map(ProcessTaskRelationLog::new).collect(Collectors.toList());
+
+        List<Long> taskCodeList =
+                taskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toList());
+        List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(taskCodeList);
+        List<TaskDefinitionLog> taskDefinitionLogs =
+                taskDefinitions.stream().map(TaskDefinitionLog::new).collect(Collectors.toList());
+
+        if (taskRelationList.isEmpty()) {
+            return Constants.EXIT_CODE_SUCCESS;
+        }
+        Map<Long, TaskDefinitionLog> taskDefinitionLogMap = null;
+        if (org.apache.commons.collections.CollectionUtils.isNotEmpty(taskDefinitionLogs)) {
+            taskDefinitionLogMap = taskDefinitionLogs
+                    .stream()
+                    .collect(Collectors.toMap(TaskDefinition::getCode, taskDefinitionLog -> taskDefinitionLog));
+        }
+        Date now = new Date();
+        for (ProcessTaskRelationLog processTaskRelationLog : taskRelationList) {
+            processTaskRelationLog.setProjectCode(projectCode);
+            processTaskRelationLog.setProcessDefinitionCode(processDefinitionCode);
+            processTaskRelationLog.setProcessDefinitionVersion(processDefinitionVersion);
+            if (taskDefinitionLogMap != null) {
+                TaskDefinitionLog preTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPreTaskCode());
+                if (preTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPreTaskVersion(preTaskDefinitionLog.getVersion());
+                }
+                TaskDefinitionLog postTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPostTaskCode());
+                if (postTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPostTaskVersion(postTaskDefinitionLog.getVersion());
+                }
+            }
+            processTaskRelationLog.setCreateTime(now);
+            processTaskRelationLog.setUpdateTime(now);
+            processTaskRelationLog.setOperator(loginUser.getId());
+            processTaskRelationLog.setOperateTime(now);
+        }
+        if (!taskRelations.isEmpty()) {","[{'comment': '```suggestion\r\n        if (CollectionUtils.isNotEmpty(taskRelations)) {\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -473,10 +496,99 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         }
 
         // batch sync to process task relation log
-        this.batchPersist2ProcessTaskRelationLog(loginUser, processTaskRelations);
+        int saveTaskRelation = saveTaskRelation(loginUser, processDefinition, insertVersion);
+        if (saveTaskRelation != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        } else {
+            logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        }
+        processTaskRelations.get(0).setProcessDefinitionVersion(insertVersion);
         return processTaskRelations;
     }
 
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,","[{'comment': 'It seems just copy the function from `processService`, but not delete the old one.', 'commenter': 'caishunfeng'}, {'comment': 'It is said to be separated from the process service code.', 'commenter': 'insist777'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -460,10 +474,19 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         // create relation not exists
         List<ProcessTaskRelation> processTaskRelations = new ArrayList<>();
         for (long createCode : taskCodeCreates) {
-            TaskDefinition upstreamTask = taskDefinitionMapper.queryByCode(createCode);
+            long upstreamCode = 0L;
+            int version = 0;
+            if (createCode != 0L) {","[{'comment': '```suggestion\r\n            // 0 for DAG root, should not, it may already exists and skip to create anymore\r\n            if (createCode != 0L) {\r\n```', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionServiceTest.java,"@@ -1068,11 +1068,23 @@ public void testUpdateProcessDefinitionV2() {
                 ((ServiceException) exception).getCode());
 
         // success
+        Mockito.when(processDefinitionLogMapper.queryMaxVersionForDefinition(processDefinition.getCode()))","[{'comment': 'we should add more test about the version, including\r\n1. update workflow entity only\r\n2. update task only\r\n3. update task dependence only\r\n\r\nall three situation should check workflow, workflow task relation correct or not, and all task still in the workflow', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,105 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        }
+        logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        processDefinitionUpdate.setVersion(insertVersion);
+        return processDefinitionUpdate;
+    }
+    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {","[{'comment': 'should add new blank line\r\n```suggestion\r\n\r\n    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {\r\n```', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/service/TaskDefinitionServiceImplTest.java,"@@ -467,10 +486,53 @@ public void testUpdateTaskDefinitionV2() {
         // success
         Mockito.when(taskDefinitionLogMapper.insert(isA(TaskDefinitionLog.class))).thenReturn(1);
         // we do not test updateUpstreamTaskDefinition, because it should be tested in processTaskRelationService
-        Mockito.when(processTaskRelationService.updateUpstreamTaskDefinition(isA(User.class), isA(Long.class),
-                isA(TaskRelationUpdateUpstreamRequest.class))).thenReturn(getProcessTaskRelationList());
+        Mockito.when(
+                processTaskRelationService.updateUpstreamTaskDefinitionWithSyncDag(isA(User.class), isA(Long.class),
+                        isA(Boolean.class),
+                        isA(TaskRelationUpdateUpstreamRequest.class)))
+                .thenReturn(getProcessTaskRelationList());
         Assertions.assertDoesNotThrow(
                 () -> taskDefinitionService.updateTaskDefinitionV2(user, TASK_CODE, taskUpdateRequest));
+
+        TaskDefinition taskDefinition =
+                taskDefinitionService.updateTaskDefinitionV2(user, TASK_CODE, taskUpdateRequest);
+        Assertions.assertEquals(getTaskDefinition().getVersion() + 1, taskDefinition.getVersion());
+    }
+
+    @Test
+    public void testUpdateDag() {","[{'comment': 'well I remember we tell about testing other functions too during the meeting, did we?', 'commenter': 'zhongjiajie'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -2775,12 +2776,109 @@ public ProcessDefinition updateSingleProcessDefinition(User loginUser,
             }
             processDefinitionUpdate.setTenantId(tenant.getId());
         }
-        int update = processDefinitionMapper.updateById(processDefinitionUpdate);
-        if (update <= 0) {
+        int insertVersion = this.saveProcessDefine(loginUser, processDefinitionUpdate);
+        if (insertVersion == 0) {
+            logger.error(""Update process definition error, projectCode:{}, processDefinitionName:{}."",
+                    processDefinitionUpdate.getCode(),
+                    processDefinitionUpdate.getName());
             throw new ServiceException(Status.UPDATE_PROCESS_DEFINITION_ERROR);
         }
-        this.syncObj2Log(loginUser, processDefinition);
-        return processDefinition;
+
+        int insertRelationVersion = this.saveTaskRelation(loginUser, processDefinitionUpdate, insertVersion);
+        if (insertRelationVersion != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        }
+        logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        processDefinitionUpdate.setVersion(insertVersion);
+        return processDefinitionUpdate;
+    }
+    public int saveProcessDefine(User loginUser, ProcessDefinition processDefinition) {
+        ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog(processDefinition);
+        Integer version = processDefinitionLogMapper.queryMaxVersionForDefinition(processDefinition.getCode());
+        int insertVersion = version == null || version == 0 ? Constants.VERSION_FIRST : version + 1;
+        processDefinitionLog.setVersion(insertVersion);
+        processDefinition.setVersion(insertVersion);
+
+        processDefinitionLog.setOperator(loginUser.getId());
+        processDefinition.setUserId(loginUser.getId());
+        processDefinitionLog.setOperateTime(processDefinition.getUpdateTime());
+        processDefinition.setUpdateTime(processDefinition.getUpdateTime());
+        processDefinitionLog.setId(null);
+        int insertLog = processDefinitionLogMapper.insert(processDefinitionLog);
+        processDefinitionLog.setId(processDefinition.getId());
+
+        int result = processDefinitionMapper.updateById(processDefinition);
+        return (insertLog & result) > 0 ? insertVersion : 0;
+    }
+
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,
+                                int processDefinitionVersion) {
+        long projectCode = processDefinition.getProjectCode();
+        long processDefinitionCode = processDefinition.getCode();
+        List<ProcessTaskRelation> taskRelations =
+                processTaskRelationMapper.queryByProcessCode(projectCode, processDefinitionCode);
+        List<ProcessTaskRelationLog> taskRelationList =
+                taskRelations.stream().map(ProcessTaskRelationLog::new).collect(Collectors.toList());
+
+        List<Long> taskCodeList =
+                taskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toList());
+        List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(taskCodeList);
+        List<TaskDefinitionLog> taskDefinitionLogs =
+                taskDefinitions.stream().map(TaskDefinitionLog::new).collect(Collectors.toList());
+
+        if (taskRelationList.isEmpty()) {
+            return Constants.EXIT_CODE_SUCCESS;
+        }
+        Map<Long, TaskDefinitionLog> taskDefinitionLogMap = null;
+        if (CollectionUtils.isNotEmpty(taskDefinitionLogs)) {
+            taskDefinitionLogMap = taskDefinitionLogs
+                    .stream()
+                    .collect(Collectors.toMap(TaskDefinition::getCode, taskDefinitionLog -> taskDefinitionLog));
+        }
+        Date now = new Date();
+        for (ProcessTaskRelationLog processTaskRelationLog : taskRelationList) {
+            processTaskRelationLog.setProjectCode(projectCode);
+            processTaskRelationLog.setProcessDefinitionCode(processDefinitionCode);
+            processTaskRelationLog.setProcessDefinitionVersion(processDefinitionVersion);
+            if (taskDefinitionLogMap != null) {
+                TaskDefinitionLog preTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPreTaskCode());
+                if (preTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPreTaskVersion(preTaskDefinitionLog.getVersion());
+                }
+                TaskDefinitionLog postTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPostTaskCode());
+                if (postTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPostTaskVersion(postTaskDefinitionLog.getVersion());
+                }
+            }
+            processTaskRelationLog.setCreateTime(now);
+            processTaskRelationLog.setUpdateTime(now);
+            processTaskRelationLog.setOperator(loginUser.getId());
+            processTaskRelationLog.setOperateTime(now);
+        }
+        if (!taskRelations.isEmpty()) {
+            Set<Integer> processTaskRelationSet =
+                    taskRelations.stream().map(ProcessTaskRelation::hashCode).collect(toSet());
+            Set<Integer> taskRelationSet =
+                    taskRelationList.stream().map(ProcessTaskRelationLog::hashCode).collect(toSet());
+            boolean result = CollectionUtils.isEqualCollection(processTaskRelationSet,","[{'comment': '```suggestion\r\n            boolean isSame = CollectionUtils.isEqualCollection(processTaskRelationSet,\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessTaskRelationServiceImpl.java,"@@ -473,10 +497,98 @@ public List<ProcessTaskRelation> updateUpstreamTaskDefinition(User loginUser,
         }
 
         // batch sync to process task relation log
-        this.batchPersist2ProcessTaskRelationLog(loginUser, processTaskRelations);
+        int saveTaskRelationResult = saveTaskRelation(loginUser, processDefinition, insertVersion);
+        if (saveTaskRelationResult != Constants.EXIT_CODE_SUCCESS) {
+            logger.error(""Save process task relations error, projectCode:{}, processCode:{}, processVersion:{}."",
+                    processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+            throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_ERROR);
+        }
+        logger.info(""Save process task relations complete, projectCode:{}, processCode:{}, processVersion:{}."",
+                processDefinition.getProjectCode(), processDefinition.getCode(), insertVersion);
+        processTaskRelations.get(0).setProcessDefinitionVersion(insertVersion);
         return processTaskRelations;
     }
 
+    public int saveTaskRelation(User loginUser, ProcessDefinition processDefinition,
+                                int processDefinitionVersion) {
+        long projectCode = processDefinition.getProjectCode();
+        long processDefinitionCode = processDefinition.getCode();
+        List<ProcessTaskRelation> taskRelations =
+                processTaskRelationMapper.queryByProcessCode(projectCode, processDefinitionCode);
+        List<ProcessTaskRelationLog> taskRelationList =
+                taskRelations.stream().map(ProcessTaskRelationLog::new).collect(Collectors.toList());
+
+        List<Long> taskCodeList =
+                taskRelations.stream().map(ProcessTaskRelation::getPostTaskCode).collect(Collectors.toList());
+        List<TaskDefinition> taskDefinitions = taskDefinitionMapper.queryByCodeList(taskCodeList);
+        List<TaskDefinitionLog> taskDefinitionLogs =
+                taskDefinitions.stream().map(TaskDefinitionLog::new).collect(Collectors.toList());
+
+        if (taskRelationList.isEmpty()) {
+            return Constants.EXIT_CODE_SUCCESS;
+        }
+        Map<Long, TaskDefinitionLog> taskDefinitionLogMap = null;
+        if (org.apache.commons.collections.CollectionUtils.isNotEmpty(taskDefinitionLogs)) {
+            taskDefinitionLogMap = taskDefinitionLogs
+                    .stream()
+                    .collect(Collectors.toMap(TaskDefinition::getCode, taskDefinitionLog -> taskDefinitionLog));
+        }
+        Date now = new Date();
+        for (ProcessTaskRelationLog processTaskRelationLog : taskRelationList) {
+            processTaskRelationLog.setProjectCode(projectCode);
+            processTaskRelationLog.setProcessDefinitionCode(processDefinitionCode);
+            processTaskRelationLog.setProcessDefinitionVersion(processDefinitionVersion);
+            if (taskDefinitionLogMap != null) {
+                TaskDefinitionLog preTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPreTaskCode());
+                if (preTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPreTaskVersion(preTaskDefinitionLog.getVersion());
+                }
+                TaskDefinitionLog postTaskDefinitionLog =
+                        taskDefinitionLogMap.get(processTaskRelationLog.getPostTaskCode());
+                if (postTaskDefinitionLog != null) {
+                    processTaskRelationLog.setPostTaskVersion(postTaskDefinitionLog.getVersion());
+                }
+            }
+            processTaskRelationLog.setCreateTime(now);
+            processTaskRelationLog.setUpdateTime(now);
+            processTaskRelationLog.setOperator(loginUser.getId());
+            processTaskRelationLog.setOperateTime(now);
+        }
+        if (CollectionUtils.isNotEmpty(taskRelations)) {
+            Set<Integer> processTaskRelationSet =
+                    taskRelations.stream().map(ProcessTaskRelation::hashCode).collect(toSet());
+            Set<Integer> taskRelationSet =
+                    taskRelationList.stream().map(ProcessTaskRelationLog::hashCode).collect(toSet());
+            boolean result = org.apache.commons.collections.CollectionUtils.isEqualCollection(processTaskRelationSet,","[{'comment': '```suggestion\r\n            boolean isSame = CollectionUtils.isEqualCollection(processTaskRelationSet,\r\n```', 'commenter': 'caishunfeng'}]"
13094,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -379,6 +379,7 @@ public enum Status {
             ""批量创建工作流任务关系 {0} 错误""),
     PROCESS_TASK_RELATION_BATCH_UPDATE_ERROR(50070, ""batch update process task relation error"",
             ""批量修改工作流任务关系错误""),
+    UPSTREAM_TASK_NOT_EXISTS(50071, ""upstream task want to set dependence do not exists {0}"", ""想要指定的上游任务 {0} 不存在""),","[{'comment': '```suggestion\r\n    UPSTREAM_TASK_NOT_EXISTS(50071, ""upstream task want to set dependence do not exists {0}"", ""指定的上游任务 {0} 不存在""),\r\n```\r\n\r\nIs this better?', 'commenter': 'SbloodyS'}]"
13163,dolphinscheduler-bom/pom.xml,"@@ -35,8 +35,8 @@
         <mybatis-plus.version>3.5.2</mybatis-plus.version>
         <quartz.version>2.3.2</quartz.version>
         <druid.version>1.2.4</druid.version>
-        <zookeeper.version>3.8.0</zookeeper.version>
-        <curator.version>5.3.0</curator.version>
+        <curator.version>4.3.0</curator.version>
+        <zookeeper.version>3.4.14</zookeeper.version>","[{'comment': ""I dont't think it's a good idea. We upgrade to this version mainly to avoid CVE."", 'commenter': 'SbloodyS'}, {'comment': '1. The doc said that DS supports ZooKeeper (3.4.6+). If DS does not support ZooKeeper 3.4 , please update the doc and shell.\r\n2. Currently, ZooKeeper 3.4 has a large number of users. Only one can choose between security and compatibility\r\n3. The ZooKeeper 3.8.0  cannot avoid CVE (Vulnerabilities from dependencies) also. Please see https://mvnrepository.com/artifact/org.apache.zookeeper/zookeeper/3.8.0', 'commenter': 'v-wx-v'}, {'comment': 'In most cases, we only upgrade the dependencies instead of downgrading them. If you think it is necessary to support ZK version 3.4, you could submit a PR to support both 3.4 and 3.8 instead of downgrading it.', 'commenter': 'EricGao888'}, {'comment': ' This PR support both 3.4 and 3.8', 'commenter': 'v-wx-v'}, {'comment': '@SbloodyS @EricGao888 @danielfree @ke4qqq Any other questions?', 'commenter': 'v-wx-v'}, {'comment': '> In most cases, we only upgrade the dependencies instead of downgrading them. If you think it is necessary to support ZK version 3.4, you could submit a PR to support both 3.4 and 3.8 instead of downgrading it.\r\n\r\n+1', 'commenter': 'SbloodyS'}, {'comment': '@SbloodyS  @EricGao888  \r\n1. Usually, upgrading dependencies  versions is easy. But, I did not see the need for this upgrade. \r\n2. When using ZK  3.4.X, this upgrade caused major problems with not installing and not running. \r\n3. ZK is part of the infrastructure.Upgrading ZK should be well discussed and should be done carefully\r\n4. So I don\'t think it should be the ""priority:low"" label.', 'commenter': 'v-wx-v'}]"
13183,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/metrics/TaskMetrics.java,"@@ -83,11 +85,31 @@ public void incTaskDispatch() {
         taskDispatchCounter.increment();
     }
 
-    public void incTaskInstanceByState(final String state) {
-        if (taskInstanceCounters.get(state) == null) {
+    public void incTaskInstanceByState(final String state, Integer taskInstanceId) {","[{'comment': '```suggestion\r\n    public void incTaskInstanceByState(final String state, String taskInstanceName) {\r\n```', 'commenter': 'ruanwenjun'}, {'comment': ""Please don't query the database again."", 'commenter': 'ruanwenjun'}, {'comment': 'Thank you for your suggestion. I will redesign this implementation.', 'commenter': 'acongfly'}]"
13183,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/metrics/TaskMetrics.java,"@@ -83,11 +84,15 @@ public void incTaskDispatch() {
         taskDispatchCounter.increment();
     }
 
-    public void incTaskInstanceByState(final String state) {
-        if (taskInstanceCounters.get(state) == null) {
+    public void incTaskInstanceByState(final String state, String taskInstanceName) {
+        Counter.Builder builder = taskInstanceCountersBuild.get(state);
+        if (builder == null) {
             return;
         }
-        taskInstanceCounters.get(state).increment();
+        if (MasterConfigStatic.masterConfigStatic.isSupportTaskNameTagMetric()) {","[{'comment': ""https://github.com/apache/dolphinscheduler/blob/1ac76e1cbbf25156f3b40dc5035ef7b15dfc9bdf/dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql#L468-L503\r\n\r\n`task name` is not identical, aggregating metrics by `task name` may lead to miscounting. `task definition id` is identical for task definition, however, I haven't found a way for users to get `task definition id` easily from web ui.  "", 'commenter': 'EricGao888'}]"
13183,dolphinscheduler-standalone-server/src/main/resources/application.yaml,"@@ -149,6 +149,8 @@ master:
   # kill yarn/k8s application when failover taskInstance, default true
   kill-application-when-task-failover: true
   worker-group-refresh-interval: 10s
+  # This attribute is mainly supported by task metric, allowing task instance name to be used as a tag.
+  support-task-name-tag-metric: true","[{'comment': 'Since the number of task keeps increasing, we need clean-up mechanism for metrics tagged with task id. Otherwise, users may face memory issue. You may refer to what we did in this PR https://github.com/apache/dolphinscheduler/pull/13640', 'commenter': 'EricGao888'}]"
13235,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/LoginCsrfTokenRepository.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.security;
+
+import org.apache.dolphinscheduler.api.controller.LoginController;
+
+import java.util.UUID;
+
+import javax.servlet.http.Cookie;
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+import org.springframework.security.web.csrf.CsrfFilter;
+import org.springframework.security.web.csrf.CsrfToken;
+import org.springframework.security.web.csrf.CsrfTokenRepository;
+import org.springframework.security.web.csrf.DefaultCsrfToken;
+import org.springframework.util.StringUtils;
+import org.springframework.web.util.WebUtils;
+
+public final class LoginCsrfTokenRepository implements CsrfTokenRepository {
+
+    public static final String PARAMETER_NAME = ""_csrf"";
+    public static final String HEADER_NAME = ""X-XSRF-TOKEN"";
+    public static final String COOKIE_NAME = ""csrfToken"";
+
+    public LoginCsrfTokenRepository() {
+    }
+
+    /**
+     * The csrf token will be generated in {@link CsrfFilter}
+     * @param request http servlet request
+     */
+    public CsrfToken generateToken(HttpServletRequest request) {
+        return new DefaultCsrfToken(HEADER_NAME, PARAMETER_NAME, createNewToken());
+    }
+
+    /**
+     * The csrf token will be stored in the http request so that the login api {@link LoginController} can obtain the csrf token
+     * @param token csrf token generated in {@link CsrfFilter}
+     * @param request http servlet request
+     * @param response http servlet response
+     */
+    public void saveToken(CsrfToken token, HttpServletRequest request, HttpServletResponse response) {
+
+    }
+
+    /**
+     * load csrf token from http request cookie
+     * @param request http servlet request
+     * @return csrf token
+     */
+    public CsrfToken loadToken(HttpServletRequest request) {","[{'comment': '## Missing Override annotation\n\nThis method overrides [CsrfTokenRepository.loadToken](1); it is advisable to add an Override annotation.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2401)', 'commenter': 'github-advanced-security[bot]'}]"
13235,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/LoginCsrfTokenRepository.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.security;
+
+import org.apache.dolphinscheduler.api.controller.LoginController;
+
+import java.util.UUID;
+
+import javax.servlet.http.Cookie;
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+import org.springframework.security.web.csrf.CsrfFilter;
+import org.springframework.security.web.csrf.CsrfToken;
+import org.springframework.security.web.csrf.CsrfTokenRepository;
+import org.springframework.security.web.csrf.DefaultCsrfToken;
+import org.springframework.util.StringUtils;
+import org.springframework.web.util.WebUtils;
+
+public final class LoginCsrfTokenRepository implements CsrfTokenRepository {
+
+    public static final String PARAMETER_NAME = ""_csrf"";
+    public static final String HEADER_NAME = ""X-XSRF-TOKEN"";
+    public static final String COOKIE_NAME = ""csrfToken"";
+
+    public LoginCsrfTokenRepository() {
+    }
+
+    /**
+     * The csrf token will be generated in {@link CsrfFilter}
+     * @param request http servlet request
+     */
+    public CsrfToken generateToken(HttpServletRequest request) {
+        return new DefaultCsrfToken(HEADER_NAME, PARAMETER_NAME, createNewToken());
+    }
+
+    /**
+     * The csrf token will be stored in the http request so that the login api {@link LoginController} can obtain the csrf token
+     * @param token csrf token generated in {@link CsrfFilter}
+     * @param request http servlet request
+     * @param response http servlet response
+     */
+    public void saveToken(CsrfToken token, HttpServletRequest request, HttpServletResponse response) {","[{'comment': '## Missing Override annotation\n\nThis method overrides [CsrfTokenRepository.saveToken](1); it is advisable to add an Override annotation.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2402)', 'commenter': 'github-advanced-security[bot]'}]"
13235,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/LoginCsrfTokenRepository.java,"@@ -0,0 +1,86 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.security;
+
+import org.apache.dolphinscheduler.api.controller.LoginController;
+
+import java.util.UUID;
+
+import javax.servlet.http.Cookie;
+import javax.servlet.http.HttpServletRequest;
+import javax.servlet.http.HttpServletResponse;
+
+import org.springframework.security.web.csrf.CsrfFilter;
+import org.springframework.security.web.csrf.CsrfToken;
+import org.springframework.security.web.csrf.CsrfTokenRepository;
+import org.springframework.security.web.csrf.DefaultCsrfToken;
+import org.springframework.util.StringUtils;
+import org.springframework.web.util.WebUtils;
+
+public final class LoginCsrfTokenRepository implements CsrfTokenRepository {
+
+    public static final String PARAMETER_NAME = ""_csrf"";
+    public static final String HEADER_NAME = ""X-XSRF-TOKEN"";
+    public static final String COOKIE_NAME = ""csrfToken"";
+
+    public LoginCsrfTokenRepository() {
+    }
+
+    /**
+     * The csrf token will be generated in {@link CsrfFilter}
+     * @param request http servlet request
+     */
+    public CsrfToken generateToken(HttpServletRequest request) {","[{'comment': '## Missing Override annotation\n\nThis method overrides [CsrfTokenRepository.generateToken](1); it is advisable to add an Override annotation.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2403)', 'commenter': 'github-advanced-security[bot]'}]"
13235,dolphinscheduler-api-test/dolphinscheduler-api-test-case/src/test/java/org/apache/dolphinscheduler/api.test/utils/RequestClient.java,"@@ -24,16 +24,11 @@
 import org.apache.dolphinscheduler.api.test.entity.HttpResponseBody;
 
 import java.util.HashMap;
+import java.util.List;
 import java.util.Map;
 import java.util.Objects;
 
-import org.testcontainers.shaded.okhttp3.FormBody;
-import org.testcontainers.shaded.okhttp3.Headers;
-import org.testcontainers.shaded.okhttp3.MediaType;
-import org.testcontainers.shaded.okhttp3.OkHttpClient;
-import org.testcontainers.shaded.okhttp3.Request;
-import org.testcontainers.shaded.okhttp3.RequestBody;
-import org.testcontainers.shaded.okhttp3.Response;
+import org.testcontainers.shaded.okhttp3.*;","[{'comment': 'Please roll back these unnessnary changes.', 'commenter': 'SbloodyS'}, {'comment': 'done', 'commenter': 'hdygxsj'}]"
13235,tools/dependencies/known-dependencies.txt,"@@ -313,8 +314,11 @@ spring-jcl-5.3.22.jar
 spring-jdbc-5.3.22.jar
 spring-ldap-core-2.4.1.jar
 spring-retry-1.3.3.jar
+spring-security-config-5.7.3.jar","[{'comment': ""Please also add these dependencies' license to this file \r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-dist/release-docs/LICENSE"", 'commenter': 'kezhenxu94'}]"
13250,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/TaskInstance.java,"@@ -398,9 +398,6 @@ public boolean taskCanRetry() {
         if (this.isSubProcess()) {
             return false;
         }
-        if (this.getState() == TaskExecutionStatus.NEED_FAULT_TOLERANCE) {
-            return true;
-        }","[{'comment': ""Why you remove this, if you remove this the failover task instance will not create a new task instance. When we do failover, some task information will be override if we don't create a new one."", 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/builder/TaskExecutionContextBuilder.java,"@@ -79,6 +79,7 @@ public TaskExecutionContextBuilder buildTaskInstanceRelatedInfo(TaskInstance tas
         taskExecutionContext.setCpuQuota(taskInstance.getCpuQuota());
         taskExecutionContext.setMemoryMax(taskInstance.getMemoryMax());
         taskExecutionContext.setAppIds(taskInstance.getAppLink());
+        taskExecutionContext.setProcessId(taskInstance.getPid());","[{'comment': ""It's not a good practice to set process id here, when the worker failover the pid is useless, when master failover, the pid can get from worker by task instance id."", 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -959,9 +966,15 @@ private Optional<TaskInstance> submitTaskExec(TaskInstance taskInstance) {
             ITaskProcessor taskProcessor = TaskProcessorFactory.getTaskProcessor(taskInstance.getTaskType());
             taskProcessor.init(taskInstance, processInstance);
 
-            if (taskInstance.getState().isRunning()
+            // rebuild channel when master crashes
+            if (taskInstance.getState().isNeedFaultTolerance()","[{'comment': ""It's better to use other flag(When we create a failover workflow we can know this) to judge if the current workflow is execute from master crash, rather than use isNeedFaultTolerance."", 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-remote/src/main/java/org/apache/dolphinscheduler/remote/command/HostUpdateResponseCommand.java,"@@ -72,6 +75,14 @@ public Command convert2Command() {
         return command;
     }
 
+    public Command convert2ResponseCommand(long opaque) {","[{'comment': ""Could you please split this with request/response? don't use one class to represent request and response."", 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/storage/impl/HadoopUtils.java,"@@ -650,6 +652,42 @@ public TaskExecutionStatus getApplicationStatus(String applicationId) throws Bas
         return getExecutionStatus(result);
     }
 
+    public TaskExecutionStatus waitApplicationAccepted(String applicationId) throws BaseException {
+        if (StringUtils.isEmpty(applicationId)) {
+            return null;
+        }
+
+        String result;
+        String applicationUrl = getApplicationUrl(applicationId);
+        logger.debug(""generate yarn application url, applicationUrl={}"", applicationUrl);
+        long startTime = System.currentTimeMillis();
+        while (System.currentTimeMillis() - startTime < 60 * 1000) {
+            String responseContent = Boolean.TRUE
+                    .equals(PropertyUtils.getBoolean(Constants.HADOOP_SECURITY_AUTHENTICATION_STARTUP_STATE, false))
+                            ? KerberosHttpClient.get(applicationUrl)
+                            : HttpUtils.get(applicationUrl);
+            if (responseContent != null) {
+                ObjectNode jsonObject = JSONUtils.parseObject(responseContent);","[{'comment': ""Please don't use `ObjectNode`, this is not a good practice."", 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/utils/ProcessUtils.java,"@@ -186,6 +188,42 @@ public static String getPidsStr(int processId) throws Exception {
         return String.join("" "", pidList).trim();
     }
 
+    /**
+     * get remote host pids str
+     * @param host
+     * @param processId
+     * @return
+     * @throws Exception
+     */
+    public static String getHostPidsStr(String host, int processId) throws Exception {","[{'comment': 'Why we need to add this method?', 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-task-plugin/dolphinscheduler-task-dms/src/main/java/org/apache/dolphinscheduler/plugin/task/dms/DmsTask.java,"@@ -77,8 +77,8 @@ public void init() throws TaskException {
     }
 
     @Override
-    public List<String> getApplicationIds() throws TaskException {
-        return Collections.emptyList();
+    public Set<String> getApplicationIds() throws TaskException {","[{'comment': ""You don't need to do this change here, the return result should be distinct by task."", 'commenter': 'ruanwenjun'}]"
13250,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/runner/WorkerTaskExecuteRunnable.java,"@@ -110,9 +118,24 @@ protected void afterExecute() throws TaskException {
         if (task == null) {
             throw new TaskException(""The current task instance is null"");
         }
+        TaskExecutionStatus taskExecutionStatus = task.getExitStatus();
+
+        if (task.getExitStatus() == TaskExecutionStatus.SUCCESS && StringUtils.isNotEmpty(task.getAppIds())) {
+            // monitor task submitted before
+            logger.info(""monitor task by appId {}, maybe has process id {}"", task.getAppIds(), task.getProcessId());
+
+            taskExecutionStatus = waitApplicationEnd(task.getAppIds());
+        } else if (task.getExitStatus() == TaskExecutionStatus.SUCCESS && task.getProcessId() > 0) {
+            // monitor task by process id
+            logger.info(""monitor task by process id {}, maybe has appId {}"", task.getProcessId(), task.getAppIds());
+
+            taskExecutionStatus = waitProcessEnd(task.getProcess());
+
+        }","[{'comment': 'Why we need to wait status here? right now all task is sync task, the process should already exist here. And the remote status should be generate by task plugin rathere than this runnable.', 'commenter': 'ruanwenjun'}]"
13257,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ExecutorServiceImpl.java,"@@ -1125,6 +1125,15 @@ public int createComplementDependentCommand(List<Schedule> schedules, Command co
                         CronUtils.getMaxCycle(schedules.get(0).getCrontab()), dependentCommand.getWorkerGroup());
         dependentCommand.setTaskDependType(TaskDependType.TASK_POST);
         for (DependentProcessDefinition dependentProcessDefinition : dependentProcessDefinitionList) {
+
+            long processDefinitionCode = dependentProcessDefinition.getProcessDefinitionCode();
+            ProcessDefinition processDefinition = processService.findProcessDefinitionByCode(processDefinitionCode);","[{'comment': 'Querying data in a long loop will result in poor performance. We should avoid this.', 'commenter': 'SbloodyS'}]"
13257,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/WorkFlowLineageMapper.xml,"@@ -163,6 +163,25 @@
         AND a.task_type = 'DEPENDENT'
     </select>
 
+    <select id=""queryDependentOnlineProcessDefinitionByProcessDefinitionCode"" resultType=""DependentProcessDefinition"">","[{'comment': 'Due to the exists mapper `queryDependentProcessDefinitionByProcessDefinitionCode ` only use in one place, can you please replace it instead of add a new entrepoint named `queryDependentOnlineProcessDefinitionByProcessDefinitionCode `', 'commenter': 'zhongjiajie'}, {'comment': ""Create complement dependent command use the method 'queryDependentOnlineProcessDefinitionByProcessDefinitionCode'  only，modify the sql。"", 'commenter': 'xuchunlai'}]"
13261,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -597,8 +597,10 @@ public PageInfo<ProcessDefinition> queryProcessDefinitionListPaging(@NonNull Use
             // todo: use batch query
             ProcessDefinitionLog processDefinitionLog =
                     processDefinitionLogMapper.queryByDefinitionCodeAndVersion(pd.getCode(), pd.getVersion());
-            User user = userMapper.selectById(processDefinitionLog.getOperator());
-            pd.setModifyBy(user.getUserName());
+            User modifiedUser = userMapper.selectById(processDefinitionLog.getOperator());
+            pd.setModifyBy(modifiedUser.getUserName());
+            User createUser = userMapper.selectById(processDefinitionLog.getUserId());","[{'comment': 'If the pageSize is large, the number of queries to the database will double. This will increase the load on the database.', 'commenter': 'SbloodyS'}, {'comment': ""Sure. It definitely increases the load on the database. I'll adjust the way to query users."", 'commenter': 'calvinjiang'}]"
13279,deploy/kubernetes/dolphinscheduler/templates/ingress.yaml,"@@ -33,6 +33,7 @@ metadata:
     {{- toYaml . | nindent 4 }}
   {{- end }}
 spec:
+  ingressClassName: nginx","[{'comment': 'Please make it a variable, not all ingress are `nginx` type', 'commenter': 'kezhenxu94'}]"
13312,docs/docs/zh/guide/howto/datasource-setting.md,"@@ -4,7 +4,7 @@
 
 我们这里以 MySQL 为例来说明如何配置外部数据库：
 
-> 如果使用 MySQL 需要手动下载 [mysql-connector-java 驱动][mysql] (8.0.16) 并移动到 DolphinScheduler 的每个模块的 libs 目录下，其中包括 `api-server/libs` 和 `alert-server/libs` 和 `master-server/libs` 和 `worker-server/libs`。
+> 如果使用 MySQL，需要手动下载 [mysql-connector-java 驱动][mysql] (8.0.16) 并解压后移动到 DolphinScheduler 的每个模块的 libs 目录下，其中包括 `api-server/libs`、`alert-server/libs`、`master-server/libs`、`worker-server/libs`、`tools/libs`。","[{'comment': 'Just for double-check, since DS removes the dependency of `DAO` module in worker, do we still need to add `mysql-connector-java` for worker? https://github.com/apache/dolphinscheduler/pull/13242 cc @ruanwenjun ', 'commenter': 'EricGao888'}, {'comment': ""No, we don't need to add mysql driver for worker, unless you need to use MySQL in task plugin."", 'commenter': 'ruanwenjun'}]"
13312,docs/docs/en/guide/howto/datasource-setting.md,"@@ -4,8 +4,8 @@
 
 We here use MySQL as an example to illustrate how to configure an external database:
 
-> NOTE: If you use MySQL, you need to manually download [mysql-connector-java driver][mysql] (8.0.16) and move it to the libs directory of DolphinScheduler
-> which is `api-server/libs` and `alert-server/libs` and `master-server/libs` and `worker-server/libs`.
+> NOTE: If you use MySQL, you need to manually download [mysql-connector-java driver][mysql] (8.0.16) and unzip then move it to the libs directory of DolphinScheduler","[{'comment': '```suggestion\r\n> NOTE: If you use MySQL, you need to manually download [mysql-connector-java driver][mysql] (8.0.16), unzip it and then copy it to the lib directories of DolphinScheduler components,\r\n```', 'commenter': 'EricGao888'}]"
13312,docs/docs/en/guide/howto/datasource-setting.md,"@@ -4,8 +4,8 @@
 
 We here use MySQL as an example to illustrate how to configure an external database:
 
-> NOTE: If you use MySQL, you need to manually download [mysql-connector-java driver][mysql] (8.0.16) and move it to the libs directory of DolphinScheduler
-> which is `api-server/libs` and `alert-server/libs` and `master-server/libs` and `worker-server/libs`.
+> NOTE: If you use MySQL, you need to manually download [mysql-connector-java driver][mysql] (8.0.16) and unzip then move it to the libs directory of DolphinScheduler
+> which is `api-server/libs` and `alert-server/libs` and `master-server/libs` and `worker-server/libs` and `tools/libs`.","[{'comment': '```suggestion\r\n> which are `api-server/libs`, `alert-server/libs`, `master-server/libs` and `tools/libs`. Because DolphinScheduler worker no more accesses database, there is no need to copy it to `worker-server/libs` unless your task plugins need to access mysql database.\r\n```', 'commenter': 'EricGao888'}]"
13312,docs/docs/zh/guide/howto/datasource-setting.md,"@@ -23,7 +23,7 @@ export SPRING_DATASOURCE_PASSWORD={password}
 
 DolphinScheduler 元数据存储在关系型数据库中，目前支持 PostgreSQL 和 MySQL。下面分别介绍如何使用 MySQL 和 PostgresQL 初始化数据库。
 
-> 如果使用 MySQL 需要手动下载 [mysql-connector-java 驱动][mysql] (8.0.16) 并移动到 DolphinScheduler 的每个模块的 libs 目录下，其中包括 `api-server/libs` 和 `alert-server/libs` 和 `master-server/libs` 和 `worker-server/libs`。
+> 如果使用 MySQL，需要手动下载 [mysql-connector-java 驱动][mysql] (8.0.16) 并解压后移动到 DolphinScheduler 的每个模块的 libs 目录下，其中包括 `api-server/libs`、`alert-server/libs`、`master-server/libs`、`worker-server/libs`、`tools/libs`。","[{'comment': '```suggestion\r\n> 如果使用 MySQL，需要手动下载 [mysql-connector-java 驱动][mysql] (8.0.16) 并解压后移动到 DolphinScheduler 的每个模块的 libs 目录下，其中包括 `api-server/libs`、`alert-server/libs`、`master-server/libs`、`tools/libs`。因为 DolphinScheduler 的 worker 不再需要访问数据库，您不再需要将驱动放到`worker-server/libs`目录下，除非您的任务插件需要访问 MySQL 数据库。\r\n```', 'commenter': 'EricGao888'}]"
13360,dolphinscheduler-task-plugin/dolphinscheduler-task-dataquality/src/main/java/org/apache/dolphinscheduler/plugin/task/dq/DataQualityTask.java,"@@ -71,6 +71,16 @@ public class DataQualityTask extends AbstractYarnTask {
      */
     private static final String SPARK_COMMAND = ""${SPARK_HOME}/bin/spark-submit"";
 
+    /**
+     * --class CLASS_NAME
+     */
+    public static final String MAIN_CLASS = ""--class"";
+
+    /**
+     * DataQuality mainClass name
+     */
+    private static final String DATA_QUALITY_MAIN_CLASS_NAME = ""org.apache.dolphinscheduler.data.quality.DataQualityApplication"";","[{'comment': ""We may don't need to add this after add manifest in pom.xml"", 'commenter': 'ruanwenjun'}, {'comment': ""Yes, you're right. thx"", 'commenter': 'v-wx-v'}]"
13360,docs/docs/zh/guide/data-quality.md,"@@ -19,12 +19,14 @@
 data-quality.jar.name=dolphinscheduler-data-quality-dev-SNAPSHOT.jar
 ```
 
-这里的`data-quality.jar.name`请根据实际打包的名称来填写,
-如果单独打包`data-quality`的话，记得修改包名和`data-quality.jar.name`一致。
-如果是老版本升级使用，运行之前需要先执行`sql`更新脚本进行数据库初始化。
-如果要用到`MySQL`数据，需要将`pom.xml`中`MySQL`的`scope`注释掉
-当前只测试了`MySQL`、`PostgreSQL`和`HIVE`数据源，其他数据源暂时未测试过
-`Spark`需要配置好读取`Hive`元数据，`Spark`不是采用`jdbc`的方式读取`Hive`
+- 这里的`data-quality.jar.name`请根据实际打包的名称来填写,
+- 如果单独打包`data-quality`的话，记得修改包名和`data-quality.jar.name`一致。
+- 如果是老版本升级使用，运行之前需要先执行`SQL`更新脚本进行数据库初始化。
+- 当前 `dolphinscheduler-data-quality-dev-SNAPSHOT.jar` 是瘦包，不包含任何 `JDBC` 驱动。
+  如果有 `JDBC` 驱动需要，可以在`节点设置` `选项参数`处设置 `--jars` 参数，
+  如：`--jars /lib/jars/mysql-connector-java-8.0.16.jar`。
+- 当前只测试了`MySQL`、`PostgreSQL`和`HIVE`数据源，其他数据源暂时未测试过
+  `Spark`需要配置好读取`Hive`元数据，`Spark`不是采用`JDBC`的方式读取`Hive`","[{'comment': '```suggestion\r\n- 当前只测试了`MySQL`、`PostgreSQL`和`HIVE`数据源，其他数据源暂时未测试过。\r\n- `Spark`需要配置好读取`Hive`元数据，`Spark`不是采用`JDBC`的方式读取`Hive`。\r\n```', 'commenter': 'ruanwenjun'}]"
13360,docs/docs/zh/guide/data-quality.md,"@@ -19,12 +19,14 @@
 data-quality.jar.name=dolphinscheduler-data-quality-dev-SNAPSHOT.jar
 ```
 
-这里的`data-quality.jar.name`请根据实际打包的名称来填写,
-如果单独打包`data-quality`的话，记得修改包名和`data-quality.jar.name`一致。
-如果是老版本升级使用，运行之前需要先执行`sql`更新脚本进行数据库初始化。
-如果要用到`MySQL`数据，需要将`pom.xml`中`MySQL`的`scope`注释掉
-当前只测试了`MySQL`、`PostgreSQL`和`HIVE`数据源，其他数据源暂时未测试过
-`Spark`需要配置好读取`Hive`元数据，`Spark`不是采用`jdbc`的方式读取`Hive`
+- 这里的`data-quality.jar.name`请根据实际打包的名称来填写,","[{'comment': '```suggestion\r\n- 这里的`data-quality.jar.name`请根据实际打包的名称来填写。\r\n```', 'commenter': 'ruanwenjun'}]"
13417,dolphinscheduler-api/pom.xml,"@@ -198,6 +198,22 @@
             <groupId>org.springdoc</groupId>
             <artifactId>springdoc-openapi-ui</artifactId>
         </dependency>
+        <dependency>
+            <groupId>mysql</groupId>
+            <artifactId>mysql-connector-java</artifactId>
+            <scope>compile</scope>","[{'comment': 'We should avoid this.', 'commenter': 'SbloodyS'}, {'comment': 'yes, sorry , currently draft', 'commenter': 'Tianqi-Dotes'}]"
13417,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/CloudService.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service;
+
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+public interface CloudService {
+
+    List<String> listDataFactory(User loginUser);
+
+    List<String> listResourceGroup(User loginUser);
+
+    List<String> listPipeline(User loginUser, String factoryName, String resourceGroupName);","[{'comment': ""## Useless parameter\n\nThe parameter 'loginUser' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2535)"", 'commenter': 'github-advanced-security[bot]'}]"
13417,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/CloudService.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service;
+
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+public interface CloudService {
+
+    List<String> listDataFactory(User loginUser);
+
+    List<String> listResourceGroup(User loginUser);","[{'comment': ""## Useless parameter\n\nThe parameter 'loginUser' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2536)"", 'commenter': 'github-advanced-security[bot]'}]"
13417,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/CloudService.java,"@@ -0,0 +1,31 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.service;
+
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+public interface CloudService {
+
+    List<String> listDataFactory(User loginUser);","[{'comment': ""## Useless parameter\n\nThe parameter 'loginUser' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2537)"", 'commenter': 'github-advanced-security[bot]'}]"
13417,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/CloudController.java,"@@ -0,0 +1,91 @@
+package org.apache.dolphinscheduler.api.controller;
+
+import static org.apache.dolphinscheduler.api.enums.Status.LIST_AZURE_DATA_FACTORY_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.LIST_AZURE_DATA_FACTORY_PIPELINE_ERROR;
+import static org.apache.dolphinscheduler.api.enums.Status.LIST_AZURE_RESOURCE_GROUP_ERROR;
+
+import org.apache.dolphinscheduler.api.aspect.AccessLogAnnotation;
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ApiException;
+import org.apache.dolphinscheduler.api.service.CloudService;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import java.util.List;
+
+import javax.annotation.Resource;
+
+import org.springframework.http.HttpStatus;
+import org.springframework.web.bind.annotation.GetMapping;
+import org.springframework.web.bind.annotation.RequestAttribute;
+import org.springframework.web.bind.annotation.RequestMapping;
+import org.springframework.web.bind.annotation.RequestParam;
+import org.springframework.web.bind.annotation.ResponseStatus;
+import org.springframework.web.bind.annotation.RestController;
+
+import io.swagger.v3.oas.annotations.Operation;
+import io.swagger.v3.oas.annotations.Parameter;
+import io.swagger.v3.oas.annotations.tags.Tag;
+
+/**
+ * cloud controller
+ */
+@Tag(name = ""CLOUD_TAG"")
+@RestController
+@RequestMapping(""/cloud"")
+public class CloudController extends BaseController {","[{'comment': 'May I ask whether it is possible to make `CloudController` and `CloudService` pluggable just like how we did it for different task plugins? If people start to put cloud provider related code directly in core module, it might make things hard to maintain.', 'commenter': 'EricGao888'}, {'comment': 'good idea, but sadly cannot make pluggable APIs.\r\nAzure data factory has 3 APIs to call SDK to query the account factory list, resource group list and pipeline list.', 'commenter': 'Tianqi-Dotes'}]"
13417,dolphinscheduler-task-plugin/dolphinscheduler-task-datafactory/src/main/java/org/apache/dolphinscheduler/plugin/task/datafactory/DatafactoryHook.java,"@@ -0,0 +1,147 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datafactory;
+
+import org.apache.dolphinscheduler.common.utils.PropertyUtils;
+import org.apache.dolphinscheduler.plugin.task.api.TaskConstants;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.util.Arrays;
+import java.util.List;
+
+import lombok.Data;
+import lombok.SneakyThrows;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+import com.azure.core.management.AzureEnvironment;
+import com.azure.core.management.profile.AzureProfile;
+import com.azure.identity.ClientSecretCredential;
+import com.azure.identity.ClientSecretCredentialBuilder;
+import com.azure.resourcemanager.datafactory.DataFactoryManager;
+import com.azure.resourcemanager.datafactory.models.CreateRunResponse;
+import com.azure.resourcemanager.datafactory.models.PipelineResource;
+import com.azure.resourcemanager.datafactory.models.PipelineRun;
+import com.azure.resourcemanager.datafactory.models.PipelineRuns;
+
+@Data
+public class DatafactoryHook {
+
+    public static DatafactoryStatus[] taskFinishFlags =
+            {DatafactoryStatus.Failed, DatafactoryStatus.Succeeded, DatafactoryStatus.Cancelled};
+    protected final Logger logger =
+            LoggerFactory.getLogger(String.format(TaskConstants.TASK_LOG_LOGGER_NAME_FORMAT, getClass()));
+    private DataFactoryManager client;
+    private AzureProfile profile;
+    private ClientSecretCredential credential;
+    private String runId;
+
+    public DatafactoryHook() {
+        logger.info(""initDatafactoryClient ......"");
+        client = createClient();
+    }
+
+    protected DataFactoryManager createClient() {
+        final String AZURE_ACCESS_SUB_ID = PropertyUtils.getString(TaskConstants.AZURE_ACCESS_SUB_ID);
+        final String AZURE_SECRET_TENANT_ID = PropertyUtils.getString(TaskConstants.AZURE_SECRET_TENANT_ID);
+        final String AZURE_CLIENT_ID = PropertyUtils.getString(TaskConstants.AZURE_CLIENT_ID);
+        final String AZURE_CLIENT_SECRET = PropertyUtils.getString(TaskConstants.AZURE_CLIENT_SECRET);
+        profile =
+                new AzureProfile(AZURE_SECRET_TENANT_ID, AZURE_ACCESS_SUB_ID, AzureEnvironment.AZURE);
+        credential = new ClientSecretCredentialBuilder()
+                .clientId(AZURE_CLIENT_ID)
+                .clientSecret(AZURE_CLIENT_SECRET)
+                .tenantId(AZURE_SECRET_TENANT_ID)
+                .authorityHost(profile.getEnvironment().getActiveDirectoryEndpoint())
+                .build();
+        return DataFactoryManager.authenticate(credential, profile);
+    }
+
+    public Boolean startDatafactoryTask(DatafactoryParameters parameters) {
+        logger.info(""initDatafactoryTask ......"");
+        PipelineResource pipelineResource = getPipelineResource(parameters);
+        if (pipelineResource == null) {
+            return false;
+        }
+        logger.info(""startDatafactoryTask ......"");
+        CreateRunResponse run = pipelineResource.createRun();
+        if (StringUtils.isEmpty(run.runId())) {
+            return false;
+        }
+        runId = run.runId();
+        parameters.setRunId(runId);
+        return true;
+    }
+
+    public Boolean cancelDatafactoryTask(DatafactoryParameters parameters) {
+        logger.info(""cancelTask ......"");
+        PipelineRuns pipelineRuns = client.pipelineRuns();
+        try {
+            pipelineRuns.cancel(parameters.getResourceGroupName(), parameters.getFactoryName(), runId);
+        } catch (RuntimeException e) {
+            logger.error(""failed to cancel datafactory task: "" + e.getMessage());
+            return false;
+        }
+        return true;
+    }
+
+    public DatafactoryStatus queryDatafactoryTaskStatus(DatafactoryParameters parameters) {
+        logger.info(""queryDatafactoryTaskStatus ......"");
+
+        PipelineRuns pipelineRuns = client.pipelineRuns();
+        PipelineRun pipelineRun =
+                pipelineRuns.get(parameters.getResourceGroupName(), parameters.getFactoryName(), runId);
+
+        if (pipelineRun != null) {
+            logger.info(""queryDatafactoryTaskStatus ......{}"", pipelineRun.status());
+            return DatafactoryStatus.valueOf(pipelineRun.status());
+        }
+        return null;
+    }
+
+    private PipelineResource getPipelineResource(DatafactoryParameters parameters) {
+        return client.pipelines().get(parameters.getResourceGroupName(), parameters.getFactoryName(),
+                parameters.getPipelineName());
+    }
+
+    @SneakyThrows
+    public Boolean queryStatus(DatafactoryParameters parameters) {
+        List<DatafactoryStatus> stopStatusSet = Arrays.asList(taskFinishFlags);
+        int maxRetry = 5;
+        while (maxRetry > 0) {
+            DatafactoryStatus status = queryDatafactoryTaskStatus(parameters);
+
+            if (status == null) {
+                maxRetry--;
+                continue;
+            }
+
+            if (stopStatusSet.contains(status)) {
+                if (status.equals(DatafactoryStatus.Succeeded)) {
+                    return true;
+                }
+                return false;
+            }
+            logger.debug(""wait 10s to recheck finish status...."");
+            Thread.sleep(10000);","[{'comment': 'Is it better to make this 10000 configurable so that users can adjust under extreme network conditions?', 'commenter': 'SbloodyS'}, {'comment': 'have done', 'commenter': 'Tianqi-Dotes'}, {'comment': 'added to common.properties', 'commenter': 'Tianqi-Dotes'}]"
13427,dolphinscheduler-scheduler-plugin/dolphinscheduler-scheduler-quartz/src/main/java/org/apache/dolphinscheduler/scheduler/quartz/ProcessScheduleTask.java,"@@ -90,6 +93,9 @@ protected void executeInternal(JobExecutionContext context) {
         }
 
         Command command = new Command();
+        Map<String, Object> commandParams = new HashMap<>(1);
+        commandParams.put(Constants.SCHEDULE_TIMEZONE, schedule.getTimezoneId());
+        command.setCommandParam(JSONUtils.toJsonString(commandParams));","[{'comment': 'It will set timezone uniformly when create command, see: https://github.com/apache/dolphinscheduler/blob/26c30c9c342bbb9f8aa3b5dc0a752105aa0bb1fc/dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/process/ProcessServiceImpl.java#L409', 'commenter': 'caishunfeng'}]"
13506,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/utils/RegexUtils.java,"@@ -26,7 +26,7 @@
  */
 public class RegexUtils {
 
-    private static final Pattern LINUX_USERNAME_PATTERN = Pattern.compile(""^[a-zA-Z0-9_].{0,30}"");
+    private static final Pattern LINUX_USERNAME_PATTERN = Pattern.compile(""[a-zA-Z_][a-zA-Z\\d_-]{0,30}"");","[{'comment': '```suggestion\r\n    private static final Pattern LINUX_USERNAME_PATTERN = Pattern.compile(""[a-zA-Z\\\\d_-].{0,30}"");\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Could you please add ut for this?', 'commenter': 'ruanwenjun'}, {'comment': ""I think only '-' matches [a-zA-Z\\\\d_-].{0,30}, pure numbers are also matches [a-zA-Z\\\\d_-].{0,30};  such as '-',  123456; but these are not valid linux user names!  "", 'commenter': 'JohnYuu'}, {'comment': 'Looking forward to your reply and suggestions', 'commenter': 'JohnYuu'}, {'comment': 'The regex failed with `10000`?', 'commenter': 'ruanwenjun'}, {'comment': 'regex would not failed with 10000, but 10000 is not a valid linux user name ', 'commenter': 'JohnYuu'}, {'comment': 'Please fix the UT\r\n```\r\nRegexUtilsTest.testIsValidLinuxUserName\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Could you add me wechat or call me, I want to ask you a question? 15651806509', 'commenter': 'JohnYuu'}, {'comment': '> Could you add me wechat or call me, I want to ask you a question? 15651806509\r\n\r\nIt is better to keep it public so that others can participate in the review.', 'commenter': 'SbloodyS'}]"
13691,dolphinscheduler-api/src/test/java/org/apache/dolphinscheduler/api/controller/DynamicTaskTypeControllerTest.java,"@@ -0,0 +1,71 @@
+package org.apache.dolphinscheduler.api.controller;
+
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.utils.Result;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.junit.jupiter.api.*;","[{'comment': 'Please avoid wildcard import.', 'commenter': 'SbloodyS'}]"
13715,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/test/java/org/apache/dolphinscheduler/plugin/task/api/utils/ProcessUtilsTest.java,"@@ -0,0 +1,38 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.api.utils;
+
+import org.apache.dolphinscheduler.plugin.task.api.TaskExecutionContext;
+
+import java.io.IOException;
+
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.Test;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+public class ProcessUtilsTest {
+
+    public static final Logger logger = LoggerFactory.getLogger(ProcessUtilsTest.class);
+
+    @Test
+    public void kill() throws IOException {
+        TaskExecutionContext taskExecutionContext = new TaskExecutionContext();
+        Assertions.assertFalse(ProcessUtils.kill(taskExecutionContext));","[{'comment': 'This UT is meaningless.', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun updated setAppIds step, please check again, thanks.', 'commenter': 'XiaochenNan'}]"
13811,dolphinscheduler-storage-plugin/dolphinscheduler-storage-hdfs/src/main/java/org/apache/dolphinscheduler/plugin/storage/hdfs/HdfsStorageOperator.java,"@@ -182,7 +182,7 @@ public Configuration getConfiguration() {
      * @return DefaultFS
      */
     public String getDefaultFS() {
-        String defaultFS = getConfiguration().get(Constants.FS_DEFAULT_FS);
+        String defaultFS = getConfiguration().get(Constants.HDFS_DEFAULT_FS);","[{'comment': 'We should find a way to compatible with `resource.hdfs.fs.defaultFS`.', 'commenter': 'SbloodyS'}, {'comment': ""Hi, @SbloodyS , if defaultFS here is null, we'll read it from `resource.hdfs.fs.defaultFS`, may i ask what do you mean a compatible way?"", 'commenter': 'Radeity'}, {'comment': ""> Hi, @SbloodyS , if defaultFS here is null, we'll read it from `resource.hdfs.fs.defaultFS`, may i ask what do you mean a compatible way?\r\n\r\nBoth `resource.hdfs.fs.defaultFS` and `core-site.xml` and `hdfs-site.xml` can be used normally."", 'commenter': 'SbloodyS'}, {'comment': '@SbloodyS @Radeity \r\nI thank maybe it  can be  changed to.\r\n\r\n1. first  get config from  `resource.hdfs.fs.defaultFS`\r\n2. if empty then get from  ` core-site.xml/hdfs-site.xml ` \r\n\r\nA :  If user not set the config , it means use `core-site.xml/hdfs-site.xml` ,it works.\r\nB:   They can reset the config by  `resource.hdfs.fs.defaultFS` . \r\n\r\nBoth `resource.hdfs.fs.defaultFS` and  ` core-site.xml/hdfs-site.xml ` canbe used normally.\r\n\r\nWhat do you think? ?\r\n\r\n```java\r\npublic String getDefaultFS() {\r\n        // 1 . first  get config from  resource.hdfs.fs.defaultFS\r\n        String defaultFS =  hdfsProperties.getDefaultFS();\r\n       // 2.  second  . if empty then get from core-site.xml\r\n        if (StringUtils.isBlank(defaultFS)) {\r\n            defaultFS =getConfiguration().get(Constants.HDFS_DEFAULT_FS);\r\n        }\r\n        return defaultFS;\r\n    }\r\n```', 'commenter': 'kingbabingge'}, {'comment': 'Sounds good to me. @kingbabingge ', 'commenter': 'SbloodyS'}, {'comment': 'tks. I commit the code.\r\n\r\n> Sounds good to me. @kingbabingge\r\n\r\n', 'commenter': 'kingbabingge'}]"
13811,dolphinscheduler-storage-plugin/dolphinscheduler-storage-hdfs/src/main/java/org/apache/dolphinscheduler/plugin/storage/hdfs/HdfsStorageOperator.java,"@@ -183,9 +183,9 @@ public Configuration getConfiguration() {
      * @return DefaultFS
      */
     public String getDefaultFS() {
-        String defaultFS = getConfiguration().get(Constants.FS_DEFAULT_FS);
+        String defaultFS = hdfsProperties.getDefaultFS();
         if (StringUtils.isBlank(defaultFS)) {
-            defaultFS = hdfsProperties.getDefaultFS();
+            defaultFS = getConfiguration().get(Constants.HDFS_DEFAULT_FS);","[{'comment': '```suggestion\r\n            defaultFS = getConfiguration().get(Constants.FS_DEFAULT_FS);\r\n```', 'commenter': 'SbloodyS'}]"
13829,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/WorkerGroupServiceImpl.java,"@@ -293,7 +293,9 @@ private List<WorkerGroup> getWorkerGroups(List<Integer> ids) {
             workerGroups = workerGroupMapper.queryAllWorkerGroup();
         }
         Optional<Boolean> containDefaultWorkerGroups = workerGroups.stream()
-                .map(workerGroup -> Constants.DEFAULT_WORKER_GROUP.equals(workerGroup.getName())).findAny();
+                .map(workerGroup -> Constants.DEFAULT_WORKER_GROUP.equals(workerGroup.getName()))
+                .filter(result -> result)","[{'comment': 'Hi, @ralphgj , could you please explain more about this filter()?', 'commenter': 'rickchengx'}, {'comment': 'The `containDefaultWorkerGroups` method should verify whether it contains the `default` work group. The `map` method only converts the work group into true/false, which indicates whether it is the `default` work group or not. The `findAny` method will select the first one. If the first work group converted by `map` is not the `default` work group, the result of `containDefaultWorkerGroups` will be false, but the actual work group retrieved contains the `default` work group.', 'commenter': 'ralphgj'}]"
13848,dolphinscheduler-ui/src/views/resource/index.tsx,"@@ -25,4 +27,15 @@ const resource = defineComponent({
   }
 })
 
+export function getBaseDir(resourceType: ResourceType) {
+  const baseDir = ref(String(""""));","[{'comment': 'Please use single quotes and remove the semicolons.', 'commenter': 'songjianet'}]"
13848,dolphinscheduler-ui/src/views/resource/index.tsx,"@@ -15,7 +15,9 @@
  * limitations under the License.
  */
 
-import { defineComponent } from 'vue'
+import { defineComponent, ref } from 'vue'
+import { queryBaseDir } from ""@/service/modules/resources"";","[{'comment': 'Please remove the semicolon.', 'commenter': 'songjianet'}]"
13848,dolphinscheduler-ui/src/views/resource/index.tsx,"@@ -15,7 +15,9 @@
  * limitations under the License.
  */
 
-import { defineComponent } from 'vue'
+import { defineComponent, ref } from 'vue'
+import { queryBaseDir } from ""@/service/modules/resources"";
+import { ResourceType } from ""@/views/resource/components/resource/types"";","[{'comment': 'Please remove the semicolon.', 'commenter': 'songjianet'}]"
13848,dolphinscheduler-ui/src/views/resource/components/resource/index.tsx,"@@ -46,6 +46,7 @@ import styles from './index.module.scss'
 import type { Router } from 'vue-router'
 import Search from ""@/components/input-search""
 import { ResourceType } from ""@/views/resource/components/resource/types"";","[{'comment': 'Please remove the semicolon.', 'commenter': 'songjianet'}]"
13848,dolphinscheduler-ui/src/views/resource/components/resource/index.tsx,"@@ -46,6 +46,7 @@ import styles from './index.module.scss'
 import type { Router } from 'vue-router'
 import Search from ""@/components/input-search""
 import { ResourceType } from ""@/views/resource/components/resource/types"";
+import { getBaseDir } from ""@/views/resource"";","[{'comment': 'Please remove the semicolon.', 'commenter': 'songjianet'}]"
13848,dolphinscheduler-ui/src/service/modules/resources/index.ts,"@@ -45,6 +45,16 @@ export function queryResourceListPaging(
   })
 }
 
+export function queryBaseDir(
+    params: ResourceTypeReq,","[{'comment': 'Please remove the comma.', 'commenter': 'songjianet'}]"
13858,.github/workflows/publish-docker.yaml,"@@ -71,6 +71,6 @@ jobs:
           -Dmaven.javadoc.skip \
           -Dcheckstyle.skip=true \
           -Dmaven.deploy.skip \
-          -Ddocker.tag=${{ github.sha }} \
+          -Ddocker.tag=${{ github.ref_name }} \","[{'comment': 'This should be conditionally set in line 47 and 52\n', 'commenter': 'kezhenxu94'}, {'comment': 'And you would use `DOCKER_TAG` here', 'commenter': 'kezhenxu94'}, {'comment': 'done', 'commenter': 'zhongjiajie'}]"
13858,.github/workflows/publish-docker.yaml,"@@ -48,11 +48,13 @@ jobs:
             echo ""DOCKER_USERNAME=${{ secrets.DOCKERHUB_USER }}"" >> $GITHUB_ENV
             echo ""DOCKER_PASSWORD=${{ secrets.DOCKERHUB_TOKEN }}"" >> $GITHUB_ENV
             echo ""HUB=apache"" >> $GITHUB_ENV
+            echo ""DOCKER_TAG=${{ github.ref_name }}"" >> $GITHUB_ENV","[{'comment': 'Should be `github.event.release.tag_name`', 'commenter': 'kezhenxu94'}, {'comment': '👍  I find it in https://docs.github.com/en/rest/releases/releases?apiVersion=2022-11-28#get-a-release ', 'commenter': 'zhongjiajie'}]"
13861,dolphinscheduler-ui/src/locales/zh_CN/project.ts,"@@ -668,6 +668,10 @@ export default {
     zeppelin_parameters_tips: '请输入zeppelin dynamic form参数',
     zeppelin_rest_endpoint: 'zeppelinRestEndpoint',
     zeppelin_rest_endpoint_tips: '请输入zeppelin server的rest endpoint',
+    zeppelin_user_name: 'zeppelinUserName',","[{'comment': ""```suggestion\r\n    zeppelin_username: 'zeppelinUsername',\r\n```"", 'commenter': 'EricGao888'}]"
13861,dolphinscheduler-ui/src/locales/zh_CN/project.ts,"@@ -668,6 +668,10 @@ export default {
     zeppelin_parameters_tips: '请输入zeppelin dynamic form参数',
     zeppelin_rest_endpoint: 'zeppelinRestEndpoint',
     zeppelin_rest_endpoint_tips: '请输入zeppelin server的rest endpoint',
+    zeppelin_user_name: 'zeppelinUserName',
+    zeppelin_user_name_tips: '请输入zeppelin server的登陆用户名',
+    zeppelin_pass_word: 'zeppelinPassWord',","[{'comment': ""```suggestion\r\n    zeppelin_password: 'zeppelinPassword',\r\n```"", 'commenter': 'EricGao888'}]"
13861,dolphinscheduler-task-plugin/dolphinscheduler-task-zeppelin/src/main/java/org/apache/dolphinscheduler/plugin/task/zeppelin/ZeppelinParameters.java,"@@ -1,57 +1,59 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.dolphinscheduler.plugin.task.zeppelin;
-
-import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
-import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
-
-import org.apache.commons.lang3.StringUtils;
-
-import java.util.Collections;
-import java.util.List;
-
-import lombok.Getter;
-import lombok.Setter;
-import lombok.ToString;
-
-@Getter
-@Setter
-@ToString
-public class ZeppelinParameters extends AbstractParameters {
-
-    /**
-     * parameters for zeppelin client API
-     * @see <a href=""https://zeppelin.apache.org/docs/0.9.0/usage/zeppelin_sdk/client_api.html"">Zeppelin_Client_API_Examples</a>
-     */
-    private String noteId;
-    private String paragraphId;
-    private String restEndpoint;
-    private String productionNoteDirectory;
-    private String parameters;
-
-    @Override
-    public boolean checkParameters() {
-        return StringUtils.isNotEmpty(this.noteId) && StringUtils.isNotEmpty(this.restEndpoint);
-    }
-
-    @Override
-    public List<ResourceInfo> getResourceFilesList() {
-        return Collections.emptyList();
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.zeppelin;
+
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import lombok.Getter;
+import lombok.Setter;
+import lombok.ToString;
+
+@Getter
+@Setter
+@ToString
+public class ZeppelinParameters extends AbstractParameters {
+
+    /**
+     * parameters for zeppelin client API
+     * @see <a href=""https://zeppelin.apache.org/docs/0.9.0/usage/zeppelin_sdk/client_api.html"">Zeppelin_Client_API_Examples</a>
+     */
+    private String noteId;
+    private String paragraphId;
+    private String restEndpoint;
+    private String productionNoteDirectory;
+    private String parameters;
+    private String userName;","[{'comment': '```suggestion\r\n    private String username;\r\n\r\n```', 'commenter': 'EricGao888'}]"
13861,dolphinscheduler-task-plugin/dolphinscheduler-task-zeppelin/src/main/java/org/apache/dolphinscheduler/plugin/task/zeppelin/ZeppelinParameters.java,"@@ -1,57 +1,59 @@
-/*
- * Licensed to the Apache Software Foundation (ASF) under one or more
- * contributor license agreements.  See the NOTICE file distributed with
- * this work for additional information regarding copyright ownership.
- * The ASF licenses this file to You under the Apache License, Version 2.0
- * (the ""License""); you may not use this file except in compliance with
- * the License.  You may obtain a copy of the License at
- *
- *    http://www.apache.org/licenses/LICENSE-2.0
- *
- * Unless required by applicable law or agreed to in writing, software
- * distributed under the License is distributed on an ""AS IS"" BASIS,
- * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
- * See the License for the specific language governing permissions and
- * limitations under the License.
- */
-
-package org.apache.dolphinscheduler.plugin.task.zeppelin;
-
-import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
-import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
-
-import org.apache.commons.lang3.StringUtils;
-
-import java.util.Collections;
-import java.util.List;
-
-import lombok.Getter;
-import lombok.Setter;
-import lombok.ToString;
-
-@Getter
-@Setter
-@ToString
-public class ZeppelinParameters extends AbstractParameters {
-
-    /**
-     * parameters for zeppelin client API
-     * @see <a href=""https://zeppelin.apache.org/docs/0.9.0/usage/zeppelin_sdk/client_api.html"">Zeppelin_Client_API_Examples</a>
-     */
-    private String noteId;
-    private String paragraphId;
-    private String restEndpoint;
-    private String productionNoteDirectory;
-    private String parameters;
-
-    @Override
-    public boolean checkParameters() {
-        return StringUtils.isNotEmpty(this.noteId) && StringUtils.isNotEmpty(this.restEndpoint);
-    }
-
-    @Override
-    public List<ResourceInfo> getResourceFilesList() {
-        return Collections.emptyList();
-    }
-
-}
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.zeppelin;
+
+import org.apache.dolphinscheduler.plugin.task.api.model.ResourceInfo;
+import org.apache.dolphinscheduler.plugin.task.api.parameters.AbstractParameters;
+
+import org.apache.commons.lang3.StringUtils;
+
+import java.util.Collections;
+import java.util.List;
+
+import lombok.Getter;
+import lombok.Setter;
+import lombok.ToString;
+
+@Getter
+@Setter
+@ToString
+public class ZeppelinParameters extends AbstractParameters {
+
+    /**
+     * parameters for zeppelin client API
+     * @see <a href=""https://zeppelin.apache.org/docs/0.9.0/usage/zeppelin_sdk/client_api.html"">Zeppelin_Client_API_Examples</a>
+     */
+    private String noteId;
+    private String paragraphId;
+    private String restEndpoint;
+    private String productionNoteDirectory;
+    private String parameters;
+    private String userName;
+    private String passWord;","[{'comment': '```suggestion\r\n    private String password;\r\n\r\n```', 'commenter': 'EricGao888'}]"
13861,dolphinscheduler-ui/src/locales/en_US/project.ts,"@@ -680,6 +680,10 @@ export default {
       'Directory for cloned zeppelin note in production mode',
     zeppelin_production_note_directory_tips:
       'Please enter the production note directory to enable production mode',
+    zeppelin_user_name: 'zeppelinUserName',","[{'comment': ""```suggestion\r\n    zeppelin_username: 'zeppelinUsername',\r\n```"", 'commenter': 'EricGao888'}]"
13861,dolphinscheduler-ui/src/locales/en_US/project.ts,"@@ -680,6 +680,10 @@ export default {
       'Directory for cloned zeppelin note in production mode',
     zeppelin_production_note_directory_tips:
       'Please enter the production note directory to enable production mode',
+    zeppelin_user_name: 'zeppelinUserName',
+    zeppelin_user_name_tips: 'Please enter the zeppelin server user name',
+    zeppelin_pass_word: 'zeppelinPassWord',","[{'comment': ""```suggestion\r\n    zeppelin_password: 'zeppelinPassword',\r\n```"", 'commenter': 'EricGao888'}]"
13866,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-databend/src/main/java/org/apache/dolphinscheduler/plugin/datasource/databend/param/DatabendDataSourceProcessor.java,"@@ -0,0 +1,138 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.datasource.databend.param;
+
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.common.constants.DataSourceConstants;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.AbstractDataSourceProcessor;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.BaseDataSourceParamDTO;
+import org.apache.dolphinscheduler.plugin.datasource.api.datasource.DataSourceProcessor;
+import org.apache.dolphinscheduler.plugin.datasource.api.utils.PasswordUtils;
+import org.apache.dolphinscheduler.spi.datasource.ConnectionParam;
+import org.apache.dolphinscheduler.spi.enums.DbType;
+
+import org.apache.commons.collections4.MapUtils;
+
+import java.sql.Connection;
+import java.sql.DriverManager;
+import java.sql.SQLException;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+import com.google.auto.service.AutoService;
+
+@AutoService(DataSourceProcessor.class)
+public class DatabendDataSourceProcessor extends AbstractDataSourceProcessor {
+
+    @Override
+    public BaseDataSourceParamDTO castDatasourceParamDTO(String paramJson) {
+        return JSONUtils.parseObject(paramJson, DatabendDataSourceParamDTO.class);
+    }
+
+    @Override
+    public BaseDataSourceParamDTO createDatasourceParamDTO(String connectionJson) {
+        DatabendConnectionParam connectionParams = (DatabendConnectionParam) createConnectionParams(connectionJson);
+
+        DatabendDataSourceParamDTO databendDatasourceParamDTO = new DatabendDataSourceParamDTO();
+        databendDatasourceParamDTO.setDatabase(connectionParams.getDatabase());
+        databendDatasourceParamDTO.setUserName(connectionParams.getUser());
+        databendDatasourceParamDTO.setOther(connectionParams.getOther());
+
+        String[] hostSeperator = connectionParams.getAddress().split(Constants.DOUBLE_SLASH);
+        String[] hostPortArray = hostSeperator[hostSeperator.length - 1].split(Constants.COMMA);
+        databendDatasourceParamDTO.setPort(Integer.parseInt(hostPortArray[0].split(Constants.COLON)[1]));","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2805)"", 'commenter': 'github-advanced-security[bot]'}]"
13866,dolphinscheduler-spi/src/main/java/org/apache/dolphinscheduler/spi/enums/DbType.java,"@@ -46,7 +46,8 @@ public enum DbType {
     DAMENG(15, ""dameng""),
     OCEANBASE(16, ""oceanbase""),
     SSH(17, ""ssh""),
-    KYUUBI(18, ""kyuubi"");
+    DATABEND(18, ""databend""),
+    KYUUBI(19, ""kyuubi"");","[{'comment': ""Since we've merged kyuubi's PR in #13642. It's better not to change its order."", 'commenter': 'SbloodyS'}, {'comment': 'Thanks! Fixed it.', 'commenter': 'hantmac'}]"
13866,docs/docs/en/guide/datasource/databend.md,"@@ -0,0 +1,21 @@
+# Databend
+
+![Databend Datasource](../../../../img/new_ui/dev/datasource/Databend.png)
+
+## Datasource Parameters
+
+|     **Datasource**      |                       **Description**                       |
+|-------------------------|-------------------------------------------------------------|
+| Datasource              | Select DATABEND.                                            |
+| Datasource Name         | Enter the name of the datasource.                           |
+| Description             | Enter a description of the datasource.                      |
+| IP/Host Name            | Enter the DATABEND service IP.                              |
+| Port                    | Enter the DATABEND service port.                            |
+| Username                | Set the username for DATABEND connection.                   |
+| Password                | Set the password for DATABEND connection.                   |
+| Database Name           | Enter the database name of the DATABEND connection.         |
+| jdbc connect parameters | Parameter settings for DATABEND connection, in JSON format. |
+
+## Native Supported
+
+Yes, could use this datasource by default.","[{'comment': 'Chinese and English version is different?', 'commenter': 'zhongjiajie'}, {'comment': 'should also add new docs in https://github.com/apache/dolphinscheduler/blob/c0126b7f30ff335aa1cfd62508b041084fb090d5/docs/configs/docsdev.js#L1011-L1014 and https://github.com/apache/dolphinscheduler/blob/c0126b7f30ff335aa1cfd62508b041084fb090d5/docs/configs/docsdev.js#L330-L333', 'commenter': 'zhongjiajie'}, {'comment': '> should also add new docs in\r\n> \r\n> https://github.com/apache/dolphinscheduler/blob/c0126b7f30ff335aa1cfd62508b041084fb090d5/docs/configs/docsdev.js#L1011-L1014\r\n> \r\n> and\r\n> https://github.com/apache/dolphinscheduler/blob/c0126b7f30ff335aa1cfd62508b041084fb090d5/docs/configs/docsdev.js#L330-L333\r\n\r\nwe need to add some ci for it, or change our website template', 'commenter': 'zhongjiajie'}, {'comment': 'Add this line for `databend` but where is the content of `/en-us/docs/dev/user_doc/guide/datasource/ssh.html`?', 'commenter': 'hantmac'}, {'comment': 'it will auto-generated during website build, from markdown to html ', 'commenter': 'zhongjiajie'}]"
13866,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-databend/pom.xml,"@@ -0,0 +1,72 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+  ~ Licensed to the Apache Software Foundation (ASF) under one or more
+  ~ contributor license agreements.  See the NOTICE file distributed with
+  ~ this work for additional information regarding copyright ownership.
+  ~ The ASF licenses this file to You under the Apache License, Version 2.0
+  ~ (the ""License""); you may not use this file except in compliance with
+  ~ the License.  You may obtain a copy of the License at
+  ~
+  ~     http://www.apache.org/licenses/LICENSE-2.0
+  ~
+  ~ Unless required by applicable law or agreed to in writing, software
+  ~ distributed under the License is distributed on an ""AS IS"" BASIS,
+  ~ WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+  ~ See the License for the specific language governing permissions and
+  ~ limitations under the License.
+  -->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+    <modelVersion>4.0.0</modelVersion>
+    <parent>
+        <groupId>org.apache.dolphinscheduler</groupId>
+        <artifactId>dolphinscheduler-datasource-plugin</artifactId>
+        <version>dev-SNAPSHOT</version>
+    </parent>
+
+    <artifactId>dolphinscheduler-datasource-databend</artifactId>
+    <packaging>jar</packaging>
+    <name>${project.artifactId}</name>
+
+    <dependencies>
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-spi</artifactId>
+        </dependency>
+
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-datasource-api</artifactId>
+            <version>${project.version}</version>
+        </dependency>
+
+        <dependency>
+            <groupId>com.databend</groupId>
+            <artifactId>databend-jdbc</artifactId>
+            <version>0.0.7</version>","[{'comment': 'version should maintain in the bot module\r\n```suggestion\r\n```', 'commenter': 'zhongjiajie'}]"
13866,dolphinscheduler-ui/src/views/projects/task/components/node/fields/use-datax.ts,"@@ -14,288 +14,289 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
-import { ref, onMounted, watch } from 'vue'
-import { useI18n } from 'vue-i18n'
-import { useCustomParams, useDatasource, useResources } from '.'
-import type { IJsonItem } from '../types'
+import {ref, onMounted, watch} from 'vue'
+import {useI18n} from 'vue-i18n'
+import {useCustomParams, useDatasource, useResources} from '.'
+import type {IJsonItem} from '../types'
 
 export function useDataX(model: { [field: string]: any }): IJsonItem[] {
-  const { t } = useI18n()
-  const jobSpeedByteOptions: any[] = [
-    {
-      label: `0(${t('project.node.unlimited')})`,
-      value: 0
-    },
-    {
-      label: '1KB',
-      value: 1024
-    },
-    {
-      label: '10KB',
-      value: 10240
-    },
-    {
-      label: '50KB',
-      value: 51200
-    },
-    {
-      label: '100KB',
-      value: 102400
-    },
-    {
-      label: '512KB',
-      value: 524288
-    }
-  ]
-  const jobSpeedRecordOptions: any[] = [
-    {
-      label: `0(${t('project.node.unlimited')})`,
-      value: 0
-    },
-    {
-      label: '500',
-      value: 500
-    },
-    {
-      label: '1000',
-      value: 1000
-    },
-    {
-      label: '1500',
-      value: 1500
-    },
-    {
-      label: '2000',
-      value: 2000
-    },
-    {
-      label: '2500',
-      value: 2500
-    },
-    {
-      label: '3000',
-      value: 3000
-    }
-  ]
-  const memoryLimitOptions = [
-    {
-      label: '1G',
-      value: 1
-    },
-    {
-      label: '2G',
-      value: 2
-    },
-    {
-      label: '3G',
-      value: 3
-    },
-    {
-      label: '4G',
-      value: 4
-    }
-  ]
+    const {t} = useI18n()","[{'comment': 'it seem you change the file format, does it in need or modify by accident?', 'commenter': 'zhongjiajie'}, {'comment': 'Aha,Just by accident.', 'commenter': 'hantmac'}]"
13887,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/resource/ResourceCheck.java,"@@ -0,0 +1,114 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.api.resource;
+
+import org.apache.dolphinscheduler.api.enums.Status;
+import org.apache.dolphinscheduler.api.exceptions.ServiceException;
+import org.apache.dolphinscheduler.dao.entity.Resource;
+import org.apache.dolphinscheduler.service.process.ProcessService;
+import org.apache.dolphinscheduler.spi.enums.ResourceType;
+
+import org.apache.commons.collections.CollectionUtils;
+
+import java.util.Arrays;
+import java.util.List;
+
+import lombok.Getter;
+import lombok.Setter;
+
+import org.slf4j.Logger;
+
+import com.google.common.base.Strings;
+
+@Getter
+@Setter
+public class ResourceCheck {
+
+    /**
+     * logger
+     */
+    private Logger logger;
+    /**
+     * Resource Type
+     */
+    private ResourceType resourceType;
+
+    /**
+     * Process Service
+     */
+    private ProcessService processService;
+
+    /**
+     * need check resourceIds
+     */
+    private String resourceIds;
+
+    /**
+     * task name
+     */
+    private String taskName;
+
+    /**
+     * resource exist check
+     * @param resourceType resource type
+     * @param processService process service
+     * @param resourceIds resource ids string with , combine
+     * @param taskName task name
+     * @param logger logger
+     */
+    public ResourceCheck(ResourceType resourceType, ProcessService processService, String resourceIds, String taskName,
+                         Logger logger) {
+        this.resourceType = resourceType;
+        this.processService = processService;
+        this.resourceIds = resourceIds;
+        this.taskName = taskName;
+        this.logger = logger;
+    }
+
+    /**
+     * check all resources exist,
+     * if contains removed resource throws ServiceException
+     */
+    public void checkAllExist() throws ServiceException {
+        switch (resourceType) {
+            case FILE:
+                if (Strings.isNullOrEmpty(this.resourceIds)) {
+                    logger.error(""The given task definition has null resources str, taskName: {}"", this.taskName);
+                    return;
+                }
+
+                Integer[] resourceIdArray =
+                        Arrays.stream(this.resourceIds.split("","")).map(Integer::parseInt).toArray(Integer[]::new);
+
+                if (resourceIdArray.length > 0) {
+                    List<Resource> list = processService.listResourceByIds(resourceIdArray);","[{'comment': 'Since we have refactored the resource center in #12076, ResourceMapper has been deprecated. I think we should not do this way.', 'commenter': 'SbloodyS'}, {'comment': '> Since we have refactored the resource center in #12076, ResourceMapper has been deprecated. I think we should not do this way.\r\n\r\nAdd this pre-check and throw an explicit error msg during task execution, which one is better? ', 'commenter': 'Radeity'}, {'comment': '> Add this pre-check and throw an explicit error msg during task execution, which one is better?\r\n\r\nIf the user deletes files in third-party storage after passing the pre check, it also cannot avoid runtime errors...', 'commenter': 'SbloodyS'}, {'comment': ""In our scenario, we are currently using the 3.1.1 version and I don't know we have refactored about resource center in dev. \r\n\r\nAnd for the 3.1.1 version, we encountered this situation.\r\n\r\nHere are the prerequisites:\r\n1. User can't access third-party storage directly.\r\n2. User only can operate third-party by ds platform.\r\n3. We can't delete the resource that binds online released jobs.\r\n\r\nprocess -> task job -> resource table -> third-party storage\r\n\r\nAnd if a process is maintained by a team. One member A operates offline this process. Another member B can delete resource binds in this process by ds. Member A re-online this process and got successful. Will throw an exception during runtime. And If we add a pre-check will find this exception when online."", 'commenter': 'qingwli'}, {'comment': 'And I agree if the user deletes a third-party storage file directly and we can do nothing about this.', 'commenter': 'qingwli'}, {'comment': ""This code only takes effect in version 3.1.X. And I'm +0 on this. cc @ruanwenjun @zhongjiajie @EricGao888 @caishunfeng "", 'commenter': 'SbloodyS'}, {'comment': 'Maybe we can post this change to 3.1.6, not dev. Because dev is totally different.', 'commenter': 'qingwli'}]"
13887,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -293,6 +293,7 @@ public enum Status {
     RESOURCE_HAS_FOLDER(20018, ""There are files or folders in the current directory:{0}"", ""当前目录下有文件或文件夹[{0}]""),
 
     REMOVE_TASK_INSTANCE_CACHE_ERROR(20019, ""remove task instance cache error"", ""删除任务实例缓存错误""),
+    TASK_RESOURCE_NOT_EXIST(20020, ""Task {0} contains removed resource"", ""任务[{0}]含有被删除的资源文件""),","[{'comment': ""Maybe it's better to return the resource doesn't exist"", 'commenter': 'rickchengx'}]"
13896,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/OSUtils.java,"@@ -466,23 +433,25 @@ public static int getProcessID() {
     /**
      * Check memory and cpu usage is overload the given thredshod.
      *
-     * @param maxCpuLoadAvg  maxCpuLoadAvg
-     * @param reservedMemory reservedMemory
+     * @param maxCpuLoadAvgThreshold  maxCpuLoadAvg
+     * @param reservedMemoryThreshold reservedMemory
      * @return True, if the cpu or memory exceed the given thredshod.
      */
-    public static Boolean isOverload(double maxCpuLoadAvg, double reservedMemory) {
+    public static Boolean isOverload(double maxCpuLoadAvgThreshold, double reservedMemoryThreshold) {
         // system load average
-        double loadAverage = loadAverage();
+        double freeCPUPercentage = 1 - cpuUsagePercentage();
         // system available physical memory
-        double availablePhysicalMemorySize = availablePhysicalMemorySize();
-        if (loadAverage > maxCpuLoadAvg) {
-            log.warn(""Current cpu load average {} is too high, max.cpuLoad.avg={}"", loadAverage, maxCpuLoadAvg);
+        double freeMemoryPercentage = 1 - memoryUsagePercentage();
+        if (freeCPUPercentage > maxCpuLoadAvgThreshold) {
+            log.warn(""Current cpu load average {} is too high, max.cpuLoad.avg={}"", freeCPUPercentage,
+                    maxCpuLoadAvgThreshold);
             return true;
         }
 
-        if (availablePhysicalMemorySize < reservedMemory) {
+        if (freeMemoryPercentage < reservedMemoryThreshold) {
             log.warn(
-                    ""Current available memory {}G is too low, reserved.memory={}G"", maxCpuLoadAvg, reservedMemory);
+                    ""Current available memory percentage{} is too low, reserved.memory={}"", freeMemoryPercentage,
+                    reservedMemoryThreshold);","[{'comment': 'The unit of `reservedMemory ` is still GB, if you also want to change the memory representation to percentage, you may have to modify the check in `getServerStatus `.', 'commenter': 'Radeity'}, {'comment': 'Thanks, done.', 'commenter': 'ruanwenjun'}]"
13896,dolphinscheduler-worker/src/main/java/org/apache/dolphinscheduler/server/worker/task/WorkerHeartBeatTask.java,"@@ -90,16 +88,16 @@ public void writeHeartBeat(WorkerHeartBeat workerHeartBeat) {
                 workerRegistryPath, workerHeartBeatJson);
     }
 
-    public int getServerStatus(double loadAverage,
-                               double maxCpuloadAvg,
+    public int getServerStatus(double cpuUsagePercentage,
+                               double maxCpuUsePercentage,
                                double availablePhysicalMemorySize,
                                double reservedMemory,
                                int workerExecThreadCount,
                                int workerWaitingTaskCount) {
-        if (loadAverage > maxCpuloadAvg || availablePhysicalMemorySize < reservedMemory) {
+        if (cpuUsagePercentage > maxCpuUsePercentage || availablePhysicalMemorySize < reservedMemory) {","[{'comment': 'Here, it still compares the physical memory with reserved memory, their unit are both GB.', 'commenter': 'Radeity'}, {'comment': 'Done', 'commenter': 'ruanwenjun'}]"
13896,dolphinscheduler-worker/src/main/resources/application.yaml,"@@ -48,9 +48,9 @@ worker:
   tenant-auto-create: true
   #Scenes to be used for distributed users.For example,users created by FreeIpa are stored in LDAP.This parameter only applies to Linux, When this parameter is true, worker.tenant.auto.create has no effect and will not automatically create tenants.
   tenant-distributed-user: false
-  # worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks. default value -1: the number of cpu cores * 2
-  max-cpu-load-avg: -1
-  # worker reserved memory, only lower than system available memory, worker server can be dispatched tasks. default value 0.3, the unit is G
+  # worker max cpuload avg, only higher than the system cpu load average, worker server can be dispatched tasks. default value 1: will use 100% cpu.
+  max-cpu-load-avg: 1
+  # worker reserved memory, only lower than system available memory, worker server can be dispatched tasks. default value 0.3, only the available memory is higher than 30%, worker server can receive task.
   reserved-memory: 0.3","[{'comment': 'Maybe you can modify the doc of `reserved-memory`.', 'commenter': 'Radeity'}, {'comment': 'Thanks, done.', 'commenter': 'ruanwenjun'}]"
13900,dolphinscheduler-dao/src/main/resources/sql/upgrade/3.0.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -495,6 +495,104 @@ delimiter ;
 CALL alter_t_ds_task_instance_col_log_path;
 DROP PROCEDURE alter_t_ds_task_instance_col_log_path;
 
+-- Dealing with table name case issues
+drop PROCEDURE if EXISTS qrtz_table_name_lowercase_to_uppercase;
+delimiter d//
+CREATE PROCEDURE qrtz_table_name_lowercase_to_uppercase()
+BEGIN
+IF EXISTS (SELECT 1 FROM INFORMATION_SCHEMA.STATISTICS
+        WHERE TABLE_NAME='qrtz_blob_triggers'","[{'comment': ""When initializing the table structure, it will follow the configuration of the mysql library to create it, and there will be no differences in table naming between different versions.\r\n\r\nThe reason for this issue may be an exception caused by the user manually modifying the table naming method of the MySQL library after initializing the table structure, so I don't think this PR is necessary."", 'commenter': 'SbloodyS'}]"
13939,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java,"@@ -306,6 +312,12 @@ public void cancelApplication() throws InterruptedException {
             return;
         }
 
+        if (StringUtils.isNotBlank(appId)) {
+            String commandFile = String.format(""%s/%s.kill"", taskRequest.getExecutePath(), appId);
+            YarnApplicationManager.execYarnKillCommand(taskRequest.getTenantCode(), appId, commandFile,
+                    ""yarn application -kill "" + appId);
+        }
+","[{'comment': ""We don't have to kill yarn application here, like other yarn tasks(Spark, Flink, etc), plz remove code changes in `AbstractCommandExecutor`. \r\n\r\nIn addition, i will improve the code logic of killing application in later PR, it seems a bit messy."", 'commenter': 'Radeity'}, {'comment': 'I try to use an AbstractYarnTask and submit a new pr later @Radeity ', 'commenter': 'duhanmin'}, {'comment': '> I try to use an AbstractYarnTask and submit a new pr later @Radeity\r\n\r\nYou can push a new commit to this branch instead of open a new PR. ^_^', 'commenter': 'SbloodyS'}, {'comment': '@SbloodyS Too many commits can be ugly', 'commenter': 'duhanmin'}]"
13939,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/utils/LogUtils.java,"@@ -183,6 +183,17 @@ public List<String> getAppIdsFromLogFile(@NonNull String logPath) {
         }
     }
 
+    public String getAppIdsFromLogLine(String logLine) {
+        if (StringUtils.isBlank(logLine))
+            return null;
+        Matcher matcher = APPLICATION_REGEX.matcher(logLine);
+        if (matcher.find()) {
+            String appId = matcher.group();
+            return appId;
+        }
+        return null;
+    }
+","[{'comment': ""Same, we don't need this. When we kill a DataxTask, we will find applicationId in log file if it is submitted to Yarn."", 'commenter': 'Radeity'}]"
13939,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/am/YarnApplicationManager.java,"@@ -160,8 +160,8 @@ private String getJobHistoryUrl(String applicationId) {
      * @param commandFile command file
      * @param cmd cmd
      */
-    private void execYarnKillCommand(String tenantCode, String appId, String commandFile,
-                                     String cmd) {
+    public static void execYarnKillCommand(String tenantCode, String appId, String commandFile,","[{'comment': 'You can remove `static`.', 'commenter': 'Radeity'}]"
13939,dolphinscheduler-task-plugin/dolphinscheduler-task-datax/src/main/java/org/apache/dolphinscheduler/plugin/task/datax/DataxTask.java,"@@ -87,7 +88,16 @@ public class DataxTask extends AbstractTask {
      * todo: Create a shell script to execute the datax task, and read the python version from the env, so we can support multiple versions of datax python
      */
     private static final String DATAX_PYTHON = Optional.ofNullable(System.getenv(""DATAX_PYTHON"")).orElse(""python2.7"");
-
+    /**
+     * datax on yarn jar path
+     * https://github.com/duhanmin/datax-on-yarn
+     */
+    private static final String dataxOnYarnJar = System.getenv(""DATAX_ON_YARN_JAR"");
+    /**
+     * example: HADOOP_OPTS=""-Xms32m -Xmx128m"" /usr/bin/yarn
+     */
+    private static final String YARN_BIN =
+            StringUtils.isEmpty(System.getenv(""YARN_BIN"")) ? ""yarn"" : System.getenv(""YARN_BIN"");","[{'comment': ""It's better to put this to `dolphinscheduler_env.sh` and docs so that users can use it more easily."", 'commenter': 'SbloodyS'}]"
13939,dolphinscheduler-task-plugin/dolphinscheduler-task-datax/src/main/java/org/apache/dolphinscheduler/plugin/task/datax/DataxTask.java,"@@ -160,7 +170,17 @@ public void handle(TaskCallBack taskCallBack) throws TaskException {
 
             // run datax processDataSourceService
             String jsonFilePath = buildDataxJsonFile(paramsMap);
-            String shellCommandFilePath = buildShellCommandFile(jsonFilePath, paramsMap);
+            String shellCommandFilePath;
+            if (dataXParameters.getYarn() == 1) {","[{'comment': 'A bit misleading if `yarn` is a numeric type.\r\nMaybe use enum or Boolean to represent whether to use yarn?', 'commenter': 'rickchengx'}]"
13968,dolphinscheduler-task-plugin/dolphinscheduler-task-datax/src/main/java/org/apache/dolphinscheduler/plugin/task/datax/DataxConstants.java,"@@ -0,0 +1,47 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.plugin.task.datax;
+
+import org.apache.dolphinscheduler.common.utils.PropertyUtils;
+
+public class DataxConstants {
+
+    private DataxConstants() {
+        throw new IllegalStateException(""Utility class"");
+    }
+
+    private static final String DATAX_YARN_JAR_CONFIG = ""datax.yarn.jar"";
+
+    private static final String DATAX_YARN_BIN_CONFIG = ""datax.yarn.bin"";
+
+    private static final String DATAX_YARN_DEFAULT_QUEUE_CONFIG = ""datax.yarn.default.queue"";
+
+    /**
+     * datax on yarn jar path
+     * https://github.com/duhanmin/datax-on-yarn","[{'comment': '```suggestion\r\n```', 'commenter': 'Radeity'}]"
13968,dolphinscheduler-task-plugin/dolphinscheduler-task-datax/src/main/java/org/apache/dolphinscheduler/plugin/task/datax/DataxTask.java,"@@ -177,6 +187,16 @@ public void handle(TaskCallBack taskCallBack) throws TaskException {
         }
     }
 
+    @Override
+    protected String buildCommand() {
+        return null;
+    }
+
+    @Override
+    protected void setMainJarName() {
+
+    }
+","[{'comment': ""In the latest dev, we don't have this method.\r\n```suggestion\r\n```"", 'commenter': 'Radeity'}]"
13968,dolphinscheduler-task-plugin/dolphinscheduler-task-datax/src/main/java/org/apache/dolphinscheduler/plugin/task/datax/DataxTask.java,"@@ -177,6 +187,16 @@ public void handle(TaskCallBack taskCallBack) throws TaskException {
         }
     }
 
+    @Override
+    protected String buildCommand() {
+        return null;","[{'comment': 'Can we merge `buildShellCommandFile` and `buildYarnShellCommandFile` in this method and make `handle` method clearer?', 'commenter': 'Radeity'}, {'comment': '@Radeity Changes have been made', 'commenter': 'duhanmin'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -76,6 +57,8 @@
 import io.swagger.v3.oas.annotations.media.Schema;
 import io.swagger.v3.oas.annotations.tags.Tag;
 
+import static org.apache.dolphinscheduler.api.enums.Status.*;","[{'comment': 'Hi, please run `./mvnw spotless:apply` to auto-format your code, BTW, we do not accept wildcard import ', 'commenter': 'zhongjiajie'}, {'comment': 'Thank you very much, the open source road is full of details, learned.', 'commenter': 'zhangyongtian'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -3054,4 +3057,46 @@ public void deleteOtherRelation(Project project, Map<String, Object> result, Pro
 
     }
 
+    /**
+     * Batch release process definitions by code states.
+     *
+     * @param loginUser    Login user.
+     * @param projectCode  Project code.
+     * @param codeStates   Code states in JSON format.
+     * @return Result of the batch release process definitions.
+     */
+    @Override
+    @Transactional
+    public Map<String, Object> batchReleaseProcessDefinitions(User loginUser, long projectCode, String codeStates) {
+        Map<String, Object> result = new HashMap<>();
+        if (StringUtils.isEmpty(codeStates)) {
+            log.error(""Parameter codeStates is empty, projectCode is {}."", projectCode);
+            putMsg(new HashMap<>(), Status.PROCESS_DEFINITION_CODES_IS_EMPTY);","[{'comment': 'could you directly throw an exception instead of return hash map?https://github.com/apache/dolphinscheduler/blob/73b505f6397155ccdd007cf5fcabca9f6cc6447f/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessInstanceServiceImpl.java#L629', 'commenter': 'zhongjiajie'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -3054,4 +3057,46 @@ public void deleteOtherRelation(Project project, Map<String, Object> result, Pro
 
     }
 
+    /**
+     * Batch release process definitions by code states.
+     *
+     * @param loginUser    Login user.
+     * @param projectCode  Project code.
+     * @param codeStates   Code states in JSON format.
+     * @return Result of the batch release process definitions.
+     */
+    @Override
+    @Transactional
+    public Map<String, Object> batchReleaseProcessDefinitions(User loginUser, long projectCode, String codeStates) {
+        Map<String, Object> result = new HashMap<>();
+        if (StringUtils.isEmpty(codeStates)) {
+            log.error(""Parameter codeStates is empty, projectCode is {}."", projectCode);
+            putMsg(new HashMap<>(), Status.PROCESS_DEFINITION_CODES_IS_EMPTY);
+            return result;
+        }
+
+        try {
+            Map<String, String> codeStateMap = new Gson().fromJson(codeStates, new TypeToken<Map<String, String>>() {}.getType());
+
+            for (Map.Entry<String, String> entry : codeStateMap.entrySet()) {
+                String code = entry.getKey();
+                String releaseState = entry.getValue();
+
+                try {
+                    ReleaseState releaseStateEnum = ReleaseState.valueOf(releaseState);
+                    result = releaseProcessDefinition(loginUser, projectCode, Long.parseLong(code), releaseStateEnum);
+                } catch (IllegalArgumentException e) {
+                    log.error(""Invalid releaseState '{}' in codeStates JSON, projectCode is {}."", releaseState, projectCode);
+                    putMsg(result, Status.INVALID_CODE_STATES_JSON);","[{'comment': 'same here. exception.', 'commenter': 'zhongjiajie'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/ProcessDefinitionService.java,"@@ -521,4 +521,15 @@ void saveOtherRelation(User loginUser, ProcessDefinition processDefinition, Map<
      * @return variables data
      */
     Map<String, Object> viewVariables(User loginUser, long projectCode, long code);
+
+    /**
+     * Batch release process definitions by code states.
+     *
+     * @param loginUser    Login user.
+     * @param projectCode  Project code.
+     * @param codeStates   Code states in JSON format.
+     * @return Result of the batch release process definitions.
+     */
+    Map<String, Object> batchReleaseProcessDefinitions(User loginUser, long projectCode, String codeStates);","[{'comment': 'do you combine release or unreleased in one single interface? how about add two separate interface `batch release` and `batch unreleased`? which will keep our code more easier to read', 'commenter': 'zhongjiajie'}, {'comment': 'Hello, thank you very much for your help. I initially wanted to use two methods to express it, until I saw the implementation method below.\r\nhttps://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java#L384\r\nI feel that this method will be more general. Just pass in the corresponding process definition code and corresponding state, and you can process it in bulk and universally. Do you think so?', 'commenter': 'zhangyongtian'}, {'comment': 'If you want to combine them, maybe use enum class to replace `codeStates` is better, which will also improve code readability. ', 'commenter': 'Radeity'}, {'comment': 'Thank you very much for the suggestion. Perhaps what you said is correct, but the data I sent from the front-end is a jsonstring, with the key being the process definition code and the value being the corresponding state. I feel that using enumeration is not very easy to handle.', 'commenter': 'zhangyongtian'}, {'comment': ""Can you give me a little hint? I'll do my best. emo."", 'commenter': 'zhangyongtian'}, {'comment': 'You can follow the api you mentioned above, String value passed from front-end will be parsed and match your enum class.', 'commenter': 'Radeity'}, {'comment': ""Okay, thank you. I'll give it a try"", 'commenter': 'zhangyongtian'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -3054,4 +3058,48 @@ public void deleteOtherRelation(Project project, Map<String, Object> result, Pro
 
     }
 
+    /**
+     * Batch release process definitions by code states.
+     *
+     * @param loginUser    Login user.
+     * @param projectCode  Project code.
+     * @param codeStates   Code states in JSON format.
+     * @return Result of the batch release process definitions.
+     */
+    @Override
+    @Transactional
+    public Map<String, Object> batchReleaseProcessDefinitions(User loginUser, long projectCode, String codeStates) {
+        Map<String, Object> result = new HashMap<>();
+        if (StringUtils.isEmpty(codeStates)) {
+            log.error(""Parameter codeStates is empty, projectCode is {}."", projectCode);
+            putMsg(result, Status.PROCESS_DEFINITION_CODES_IS_EMPTY);
+            throw new ServiceException(Status.PROCESS_DEFINITION_CODES_IS_EMPTY);
+        }
+
+        try {
+            Map<String, String> codeStateMap = new Gson().fromJson(codeStates, new TypeToken<Map<String, String>>() {","[{'comment': ""We've already have `org.apache.dolphinscheduler.common.utils.JSONUtils`. Please do not introduce new json parsing method."", 'commenter': 'SbloodyS'}, {'comment': ""Okay, I'll make the necessary modifications"", 'commenter': 'zhangyongtian'}]"
14089,dolphinscheduler-ui/src/service/modules/process-definition/index.ts,"@@ -255,3 +256,10 @@ export function viewProcessDefinitionVariables(code: number, processCode: number
   })
 }
 
+export function batchOnlineByCodeStates(data: CodeStateListReq, code: number): any {
+    return axios({
+        url: `/projects/${code}/process-definition/batch-release`,
+        method: 'post',
+        data
+    })
+}","[{'comment': 'We suggest the last line to be blank, so please add a new line here.', 'commenter': 'SbloodyS'}, {'comment': ""Okay, I'll make the necessary modifications"", 'commenter': 'zhangyongtian'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/enums/Status.java,"@@ -532,6 +532,9 @@ public enum Status {
     QUERY_PROCESS_DEFINITION_ALL_VARIABLES_ERROR(1300100, ""query process definition all variables error"",
             ""查询工作流自定义变量信息错误""),
 
+    BATCH_RELEASE_PROCESS_DEFINE_BY_CODE_STATES_ERROR(1300101, ""batch release process definition by code states error"",
+            ""批量释放工作流定义失败""),","[{'comment': 'It is better to change it to  ``` ""批量{0}工作流失败"" ```  Whether it is online or offline, we can get it through the parameters of the interface', 'commenter': 'fuchanghai'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -879,4 +880,29 @@ public Result viewVariables(@Parameter(hidden = true) @RequestAttribute(value =
         return returnDataList(result);
     }
 
+    /**
+     * Batch release process definition by code states
+     *
+     * @param loginUser   Login user
+     * @param projectCode Project code
+     * @param codeStates  Process definition code states
+     * @return Result of the batch release operation
+     */
+    @Operation(summary = ""batchReleaseProcessDefinitionByCodeStates"", description = ""BATCH_RELEASE_PROCESS_DEFINITION_BY_CODE_STATES_NOTES"")
+    @Parameters({
+            @Parameter(name = ""codeStates"", description = ""Process definition code states"", required = true, schema = @Schema(implementation = String.class))
+    })
+    @PostMapping(value = ""/batch-release"")
+    @ResponseStatus(HttpStatus.OK)
+    @ApiException(BATCH_RELEASE_PROCESS_DEFINE_BY_CODE_STATES_ERROR)
+    @AccessLogAnnotation(ignoreRequestArgs = ""loginUser"")
+    public Result batchReleaseProcessDefinitionByCodeStates(
+                                                            @Parameter(hidden = true) @RequestAttribute(value = Constants.SESSION_USER) User loginUser,
+                                                            @Parameter(name = ""projectCode"", description = ""Project code"", required = true) @PathVariable long projectCode,
+                                                            @RequestParam(""codeStates"") String codeStates) {","[{'comment': 'perhaps we can split ```codeStates``` into two parameters, one is the code defined by all processes, and the other is the status of online or offline WDYT? cc @Radeity ', 'commenter': 'fuchanghai'}, {'comment': 'Using json `codeStates` is not a good way. A good way is as mentioned here\r\n https://github.com/apache/dolphinscheduler/pull/14089/files#r1193518157', 'commenter': 'SbloodyS'}, {'comment': ""Okay, thank you. I made some changes over the weekend. I didn't have much time to come a few days ago. Just now, I saw a new submission, so I clicked on the update branch. hh"", 'commenter': 'zhangyongtian'}, {'comment': ""> Okay, thank you. I made some changes over the weekend. I didn't have much time to come a few days ago. Just now, I saw a new submission, so I clicked on the update branch. hh\r\n\r\nOpen source projects do not have 996, So please take your time. ^_^"", 'commenter': 'SbloodyS'}]"
14089,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/ProcessDefinitionController.java,"@@ -134,9 +134,9 @@ public Result createProcessDefinition(@Parameter(hidden = true) @RequestAttribut
     /**
      * copy process definition
      *
-     * @param loginUser login user
-     * @param projectCode project code
-     * @param codes process definition codes
+     * @param loginUser         login user
+     * @param projectCode       project code
+     * @param codes             process definition codes","[{'comment': 'Please remove these blanks.', 'commenter': 'Radeity'}]"
14099,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/CuringGlobalParams.java,"@@ -49,6 +46,8 @@
 import org.springframework.beans.factory.annotation.Autowired;
 import org.springframework.stereotype.Component;
 
+import static org.apache.dolphinscheduler.plugin.task.api.TaskConstants.*;","[{'comment': 'The wildcard import is not allowed in dolphinscheduler source code', 'commenter': 'zhongjiajie'}]"
14099,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/CuringGlobalParams.java,"@@ -155,16 +154,20 @@ public Map<String, Property> paramParsingPreparation(@NonNull TaskInstance taskI
         // of the process instance complement
         Map<String, String> cmdParam = JSONUtils.toMap(processInstance.getCommandParam());
         String timeZone = cmdParam.get(Constants.SCHEDULE_TIMEZONE);
-        Map<String, String> params = BusinessTimeUtils.getBusinessTime(commandType, scheduleTime, timeZone);
-
-        if (MapUtils.isNotEmpty(globalParamsMap)) {
-            params.putAll(globalParamsMap);
-        }
 
+        // build-in params","[{'comment': 'Since we have many build param than before, can we separate to new private method to handle the build-in param?', 'commenter': 'zhongjiajie'}]"
14099,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/TaskConstants.java,"@@ -187,6 +188,25 @@ private TaskConstants() {
      */
     public static final String PARAMETER_TASK_INSTANCE_ID = ""system.task.instance.id"";
 
+    /**
+     * the definition name of current task
+     */
+    public static final String PARAMETER_TASK_DEFINITION_NAME = ""system.task.definition.name"";
+
+    /**
+     * the instance id of the process to which current task belongs
+     */
+    public static final String PARAMETER_PROCESS_INSTANCE_ID = ""system.process.instance.id"";","[{'comment': 'how about use `workflow` as keyword instead of `process`? because our web ui use workflow.', 'commenter': 'zhongjiajie'}]"
14099,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/expand/CuringGlobalParams.java,"@@ -206,6 +206,28 @@ public Map<String, Property> paramParsingPreparation(@NonNull TaskInstance taskI
         return globalParams;
     }
 
+    /**
+     * build all built-in parameters
+     * @param taskInstance
+     * @param timeZone
+     */
+    private Map<String, String> setBuildInParamsMap(@NonNull TaskInstance taskInstance,","[{'comment': 'In my opinion you should change the function name from setBuildInParamsMap to setBuiltInParamsMap.', 'commenter': 'calvinjiang'}, {'comment': 'make sense', 'commenter': 'haibingtown'}]"
14099,docs/docs/en/guide/parameter/built-in.md,"@@ -2,11 +2,17 @@
 
 ## Basic Built-in Parameter
 
-|      Variable      |   Declaration Method    |                                           Meaning                                           |
-|--------------------|-------------------------|---------------------------------------------------------------------------------------------|
-| system.biz.date    | `${system.biz.date}`    | The day before the schedule time of the daily scheduling instance, the format is `yyyyMMdd` |
-| system.biz.curdate | `${system.biz.curdate}` | The schedule time of the daily scheduling instance, the format is `yyyyMMdd`                |
-| system.datetime    | `${system.datetime}`    | The schedule time of the daily scheduling instance, the format is `yyyyMMddHHmmss`          |
+| Variable                        | Declaration Method                   | Meaning                                                                                     |
+|---------------------------------|--------------------------------------|---------------------------------------------------------------------------------------------|
+| system.biz.date                 | `${system.biz.date}`                 | The day before the schedule time of the daily scheduling instance, the format is `yyyyMMdd` |
+| system.biz.curdate              | `${system.biz.curdate}`              | The schedule time of the daily scheduling instance, the format is `yyyyMMdd`                |
+| system.datetime                 | `${system.datetime}`                 | The schedule time of the daily scheduling instance, the format is `yyyyMMddHHmmss`          |
+| system.task.execute.path        | `${system.task.execute.path}`        | the absolute path of current executing task                                                 |","[{'comment': 'the -> The is same as above.', 'commenter': 'calvinjiang'}]"
14099,docs/docs/zh/guide/parameter/built-in.md,"@@ -19,6 +19,36 @@
         <td>${system.datetime}</td>
         <td>日常调度实例定时的定时时间，格式为 yyyyMMddHHmmss</td>
     </tr>
+    <tr>","[{'comment': 'can you change this html table format to markdown one, just like you change in English version', 'commenter': 'zhongjiajie'}]"
14099,docs/docs/en/guide/parameter/built-in.md,"@@ -2,11 +2,17 @@
 
 ## Basic Built-in Parameter
 
-|      Variable      |   Declaration Method    |                                           Meaning                                           |
-|--------------------|-------------------------|---------------------------------------------------------------------------------------------|
-| system.biz.date    | `${system.biz.date}`    | The day before the schedule time of the daily scheduling instance, the format is `yyyyMMdd` |
-| system.biz.curdate | `${system.biz.curdate}` | The schedule time of the daily scheduling instance, the format is `yyyyMMdd`                |
-| system.datetime    | `${system.datetime}`    | The schedule time of the daily scheduling instance, the format is `yyyyMMddHHmmss`          |
+|            Variable             |          Declaration Method          |                                           Meaning                                           |
+|---------------------------------|--------------------------------------|---------------------------------------------------------------------------------------------|
+| system.biz.date                 | `${system.biz.date}`                 | The day before the schedule time of the daily scheduling instance, the format is `yyyyMMdd` |
+| system.biz.curdate              | `${system.biz.curdate}`              | The schedule time of the daily scheduling instance, the format is `yyyyMMdd`                |
+| system.datetime                 | `${system.datetime}`                 | The schedule time of the daily scheduling instance, the format is `yyyyMMddHHmmss`          |
+| system.task.execute.path        | `${system.task.execute.path}`        | The absolute path of current executing task                                                 |
+| system.task.instance.id         | `${ssystem.task.instance.id}`        | The instance id of current task                                                             |
+| system.task.definition.name     | `${system.task.definition.name}`     | The definition name of current task                                                         |
+| system.workflow.instance.id     | `${system.workflow.instance.id}`     | The instance id of the workflow to which current task belongs                               |
+| system.workflow.definition.name | `${system.workflow.definition.name}` | The definition name of the workflow to which current task belongs                           |
+| system.project.name             | `${system.project.name}`             | The name of the project to which current task belongs                                       |","[{'comment': 'can we also add `system.project.code`, `system.workflow.definition.code`, `system.task.definition.code` here?', 'commenter': 'zhongjiajie'}]"
14190,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -44,12 +44,7 @@
 import org.apache.commons.collections4.CollectionUtils;
 import org.apache.commons.lang3.StringUtils;
 
-import java.sql.Connection;
-import java.sql.PreparedStatement;
-import java.sql.ResultSet;
-import java.sql.ResultSetMetaData;
-import java.sql.SQLException;
-import java.sql.Statement;
+import java.sql.*;","[{'comment': 'We should avoid wildcard import.', 'commenter': 'SbloodyS'}, {'comment': 'Fixed. Thanks!!', 'commenter': 'zhaohehuhu'}]"
14190,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -227,8 +230,17 @@ public void executeFuncAndSql(List<SqlBinds> mainStatementsBinds,
         try {
 
             // create connection
-            connection = DataSourceClientProvider.getInstance().getConnection(DbType.valueOf(sqlParameters.getType()),
-                    baseConnectionParam);
+            if (DbType.valueOf(sqlParameters.getType()) == KYUUBI) {
+                log.info(""full jdbc url : {}, user : {} begin to build a connection"",
+                        DataSourceUtils.getJdbcUrl(DbType.KYUUBI, baseConnectionParam), baseConnectionParam.getUser());
+                Class.forName(baseConnectionParam.getDriverClassName());
+                connection = DriverManager.getConnection(baseConnectionParam.getJdbcUrl(),
+                        baseConnectionParam.getUser(), baseConnectionParam.getPassword());
+            } else {
+                connection =
+                        DataSourceClientProvider.getInstance().getConnection(DbType.valueOf(sqlParameters.getType()),
+                                baseConnectionParam);
+            }","[{'comment': ""I'm not sure if this is a good approach. If there are new data sources or task types in the future that need to share the same implementation."", 'commenter': 'SbloodyS'}, {'comment': ""Yup. It's not  a good way to do it. Can we extract part of code into getConnection method ?"", 'commenter': 'zhaohehuhu'}, {'comment': 'done', 'commenter': 'zhaohehuhu'}]"
14190,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-kyuubi/src/main/java/org/apache/dolphinscheduler/plugin/datasource/kyuubi/KyuubiDataSourceClient.java,"@@ -59,7 +67,7 @@ public Connection getConnection() {
         Connection connection = null;
         while (connection == null) {
             try {
-                connection = dataSource.getConnection();
+                connection = driverManagerDataSource.getConnection();","[{'comment': ""Please add max retry times here, this is dangerous code, in fact, it's better to generate a new connection here, rather than use `driverManagerDataSource.getConnection();`"", 'commenter': 'ruanwenjun'}, {'comment': 'Got it', 'commenter': 'zhaohehuhu'}, {'comment': 'done. ', 'commenter': 'zhaohehuhu'}]"
14190,dolphinscheduler-datasource-plugin/dolphinscheduler-datasource-kyuubi/src/main/java/org/apache/dolphinscheduler/plugin/datasource/kyuubi/KyuubiDataSourceClient.java,"@@ -44,9 +48,13 @@ protected void preInit() {
     @Override
     protected void initClient(BaseConnectionParam baseConnectionParam, DbType dbType) {
 
-        this.dataSource = JDBCDataSourceProvider.createOneSessionJdbcDataSource(baseConnectionParam, dbType);
-        this.jdbcTemplate = new JdbcTemplate(dataSource);
-        log.info(""Init {} success."", getClass().getName());
+        this.driverManagerDataSource =
+                new DriverManagerDataSource(DataSourceUtils.getJdbcUrl(DbType.KYUUBI, baseConnectionParam),
+                        baseConnectionParam.getUser(), PasswordUtils.decodePassword(baseConnectionParam.getPassword()));
+        driverManagerDataSource.setDriverClassName(baseConnectionParam.getDriverClassName());
+        this.jdbcTemplate = new JdbcTemplate(driverManagerDataSource);
+        log.info(""Init {} {} success."", getClass().getName(),
+                DataSourceUtils.getJdbcUrl(DbType.KYUUBI, baseConnectionParam));","[{'comment': ""We don't need to use `DriverManagerDataSource` here, we can directly generate new connections."", 'commenter': 'ruanwenjun'}, {'comment': 'DriverManagerDataSource should create a new connection each time, so we possibly can stick to that. ', 'commenter': 'zhaohehuhu'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -254,13 +279,6 @@ private static List<String> buildRunCommandLineForOthers(TaskExecutionContext ta
                     args.add(taskManagerMemory);
                 }
 
-                if (StringUtils.isEmpty(others) || !others.contains(FlinkConstants.FLINK_QUEUE)) {
-                    String queue = flinkParameters.getQueue();
-                    if (StringUtils.isNotEmpty(queue)) { // -yqu
-                        args.add(FlinkConstants.FLINK_QUEUE);
-                        args.add(queue);
-                    }
-                }","[{'comment': 'I think you should add if-else statement here to set different arg name for yarn queue according to Flink version. Please remove judgement from L195-L244, in which just build run command.', 'commenter': 'Radeity'}, {'comment': 'ok', 'commenter': 'ORuteMa'}, {'comment': '> I think you should add if-else statement here to set different arg name for yarn queue according to Flink version. Please remove judgement from L195-L244, in which just build run command.\r\n\r\ndone, and fix the same wrong in sql mode, pls have a look', 'commenter': 'ORuteMa'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -197,16 +196,19 @@ private static List<String> buildRunCommandLineForOthers(TaskExecutionContext ta
                     args.add(FlinkConstants.FLINK_RUN); // run
                     args.add(FlinkConstants.FLINK_EXECUTION_TARGET); // -t
                     args.add(FlinkConstants.FLINK_YARN_PER_JOB); // yarn-per-job
+","[{'comment': 'Please remove redundant blank line.', 'commenter': 'Radeity'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -197,16 +196,19 @@ private static List<String> buildRunCommandLineForOthers(TaskExecutionContext ta
                     args.add(FlinkConstants.FLINK_RUN); // run
                     args.add(FlinkConstants.FLINK_EXECUTION_TARGET); // -t
                     args.add(FlinkConstants.FLINK_YARN_PER_JOB); // yarn-per-job
+
                 } else {
                     args.add(FlinkConstants.FLINK_RUN); // run
                     args.add(FlinkConstants.FLINK_RUN_MODE); // -m
                     args.add(FlinkConstants.FLINK_YARN_CLUSTER); // yarn-cluster
+","[{'comment': 'Ditto.', 'commenter': 'Radeity'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -197,16 +196,19 @@ private static List<String> buildRunCommandLineForOthers(TaskExecutionContext ta
                     args.add(FlinkConstants.FLINK_RUN); // run
                     args.add(FlinkConstants.FLINK_EXECUTION_TARGET); // -t
                     args.add(FlinkConstants.FLINK_YARN_PER_JOB); // yarn-per-job
+
                 } else {
                     args.add(FlinkConstants.FLINK_RUN); // run
                     args.add(FlinkConstants.FLINK_RUN_MODE); // -m
                     args.add(FlinkConstants.FLINK_YARN_CLUSTER); // yarn-cluster
+
                 }
                 break;
             case APPLICATION:
                 args.add(FlinkConstants.FLINK_RUN_APPLICATION); // run-application
                 args.add(FlinkConstants.FLINK_EXECUTION_TARGET); // -t
                 args.add(FlinkConstants.FLINK_YARN_APPLICATION); // yarn-application
+","[{'comment': 'Ditto.', 'commenter': 'Radeity'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -164,12 +164,9 @@ public static List<String> buildInitOptionsForSql(FlinkParameters flinkParameter
             }
 
             // yarn.application.queue
-            String others = flinkParameters.getOthers();
-            if (StringUtils.isEmpty(others) || !others.contains(FlinkConstants.FLINK_QUEUE)) {
-                String queue = flinkParameters.getQueue();
-                if (StringUtils.isNotEmpty(queue)) {
-                    initOptions.add(String.format(FlinkConstants.FLINK_FORMAT_YARN_APPLICATION_QUEUE, queue));
-                }
+            String queue = flinkParameters.getQueue();
+            if (StringUtils.isNotEmpty(queue)) {","[{'comment': 'We will check whether user defines this arg by themselves in `others`, so you just have to modify condition in the original way: `!others.contains(FlinkConstants. FLINK_QUEUE_FOR_TARGETS)`, btw, may I ask why you name them `FLINK_QUEUE_FOR_MODE` and `FLINK_QUEUE_FOR_TARGETS `?', 'commenter': 'Radeity'}, {'comment': ""The YARN queue should be assigned by property `yarn.application.queue` rather than -yqu option, this option is not available in sql-client.sh.  If we want to specify the YARN queue used by a specific Flink SQL task, it would be more appropriate to have an explicit queue option in the task submission form rather than relying on parameters in the 'others' section. Regarding the naming here, it is because in flink-run, the -yqu option only takes effect within the -m option (for mode). When using the -t option (for target), it is necessary to specify it using -Dyarn.application.queue=%s."", 'commenter': 'ORuteMa'}, {'comment': 'The execution of a workflow is tied to a specific tenant, and this tenant holds a queue attribute. This attribute is assigned to the processInstance being executed by the tenant. The queue attribute of the executionContext for any taskInstance belonging to this processInstance will also be consistent. Therefore, the queue of a task is ultimately determined by the queue attribute of the runtime tenant if not explicitly specified.', 'commenter': 'ORuteMa'}, {'comment': ""It seems that this logic is missing, I've debugged and find the queue of `processInstance` is null. Also in codes, I don't find where it's assigned by tenant's queue. Would like to help check in your local env?"", 'commenter': 'Radeity'}, {'comment': 'Sure. From my practice, the queue is assigned. This logic should be correctly implemented in the current version.', 'commenter': 'ORuteMa'}, {'comment': ""It's weird, do you test on branch dev?"", 'commenter': 'Radeity'}, {'comment': 'My dolphin env is 3.1.7', 'commenter': 'ORuteMa'}, {'comment': 'Have you tested the modification in this PR on branch dev?', 'commenter': 'Radeity'}, {'comment': 'I will test it tomorrow, in my env I cp this pr to my 3.1.7.', 'commenter': 'ORuteMa'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -306,6 +299,41 @@ private static List<String> buildRunCommandLineForOthers(TaskExecutionContext ta
             args.add(ParameterUtils.convertParameterPlaceholders(mainArgs, ParamUtils.convert(paramsMap)));
         }
 
+        // determine yarn queue
+        determinedYarnQueue(args, flinkParameters, deployMode, flinkVersion);
         return args;
     }
+
+    private static void determinedYarnQueue(List<String> args, FlinkParameters flinkParameters,
+                                     FlinkDeployMode deployMode, String flinkVersion) {
+        String others = flinkParameters.getOthers();
+        switch (deployMode) {
+            case CLUSTER:
+                if (FLINK_VERSION_AFTER_OR_EQUALS_1_12.equals(flinkVersion)
+                        || FLINK_VERSION_AFTER_OR_EQUALS_1_13.equals(flinkVersion)) {
+                    if (StringUtils.isEmpty(others) || !others.contains(FlinkConstants.FLINK_QUEUE_FOR_TARGETS)) {
+                        String queue = flinkParameters.getQueue();
+                        if (StringUtils.isNotEmpty(queue)) { // -Dyarn.application.queue=%s
+                            args.add(String.format(FlinkConstants.FLINK_QUEUE_FOR_TARGETS, queue));
+                        }
+                    }
+                } else {
+                    if (StringUtils.isEmpty(others) || !others.contains(FlinkConstants.FLINK_QUEUE_FOR_MODE)) {
+                        String queue = flinkParameters.getQueue();
+                        if (StringUtils.isNotEmpty(queue)) { // -yqu
+                            args.add(FlinkConstants.FLINK_QUEUE_FOR_MODE);
+                            args.add(queue);
+                        }
+                    }
+                }
+            case APPLICATION:
+                if (StringUtils.isEmpty(others) || !others.contains(FlinkConstants.FLINK_QUEUE_FOR_TARGETS)) {
+                    String queue = flinkParameters.getQueue();
+                    if (StringUtils.isNotEmpty(queue)) { // -Dyarn.application.queue=%s
+                        args.add(String.format(FlinkConstants.FLINK_QUEUE_FOR_TARGETS, queue));
+                    }
+                }","[{'comment': 'There are some duplicated code. Can we clean up the logic and try to avoid introducing this new method? ', 'commenter': 'Radeity'}, {'comment': 'Sure', 'commenter': 'ORuteMa'}]"
14237,dolphinscheduler-task-plugin/dolphinscheduler-task-flink/src/main/java/org/apache/dolphinscheduler/plugin/task/flink/FlinkArgsUtils.java,"@@ -306,6 +296,40 @@
             args.add(ParameterUtils.convertParameterPlaceholders(mainArgs, ParamUtils.convert(paramsMap)));
         }
 
+        // determine yarn queue
+        determinedYarnQueue(args, flinkParameters, deployMode, flinkVersion);
         return args;
     }
+
+    private static void determinedYarnQueue(List<String> args, FlinkParameters flinkParameters,
+                                            FlinkDeployMode deployMode, String flinkVersion) {
+        switch (deployMode) {","[{'comment': '## Missing enum case in switch\n\nSwitch statement does not have a case for [STANDALONE](1).\nSwitch statement does not have a case for [LOCAL](2).\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2947)', 'commenter': 'github-advanced-security[bot]'}]"
14349,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/security/impl/ldap/LdapService.java,"@@ -70,6 +70,15 @@ public class LdapService {
     @Value(""${security.authentication.ldap.user.not-exist-action:CREATE}"")
     private String ldapUserNotExistAction;
 
+    @Value(""${security.authentication.ldap.ssl.enable:false}"")
+    private Boolean sslEnable;
+
+    @Value(""${security.authentication.ldap.ssl.trust-store:#{null}}"")
+    private String trustStore;
+
+    @Value(""${security.authentication.ldap.ssl.trust-store-password:#{null}}"")
+    private String trustStorePassword;","[{'comment': 'Can we set replace default null value with the same value in `application.yaml`? I think keep consistent is better and can also avoid NPE.', 'commenter': 'Radeity'}, {'comment': 'Hi, For this part, the default will use the value in `application.yaml` not null, and even these two filed is null and is ok because truestore will use in `String.format(""%s/%s"", System.getProperty(""user.dir""), trustStore)` works well, not throw npe, and for trustStorePassword we have a StringUtils.isNotEmpty check. WDYT?', 'commenter': 'qingwli'}]"
14349,dolphinscheduler-standalone-server/src/main/resources/application.yaml,"@@ -106,6 +106,14 @@ security:
         email-attribute: mail
         # action when ldap user is not exist (supported types: CREATE,DENY)
         not-exist-action: CREATE
+      ssl:
+        enable: false
+        # jks file path && password
+        # please store the jks file in dolphinscheduler-standalone-server/src/main/resources/ldapkeystore.jks","[{'comment': ""This doesn't make sense. Bear in mind that the users don't have source codes at hands."", 'commenter': 'kezhenxu94'}, {'comment': 'Deleted', 'commenter': 'qingwli'}, {'comment': 'Please search globally `src/main/resources/ldapkeystore.jks`', 'commenter': 'kezhenxu94'}, {'comment': 'Done, PTAL', 'commenter': 'qingwli'}]"
14349,deploy/kubernetes/dolphinscheduler/templates/secret-external-ldap-ssl.yaml,"@@ -0,0 +1,28 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+{{- if .Values.security.authentication.ldap.ssl.enable }}
+apiVersion: v1
+kind: Secret
+metadata:
+  name: {{ include ""dolphinscheduler.fullname"" . }}-ldap-ssl
+  labels:
+    app.kubernetes.io/name: {{ include ""dolphinscheduler.fullname"" . }}-ldap-ssl
+    {{- include ""dolphinscheduler.common.labels"" . | nindent 4 }}
+type: Opaque
+data:
+  jks-file: {{ .Files.Get .Values.security.authentication.ldap.ssl.truststore | b64enc }}","[{'comment': ""In fact, this doesn't work at all, `.Files.Get` is not able to get arbitrary file on the filesystem, it can only get files within the Chart"", 'commenter': 'kezhenxu94'}, {'comment': 'Yes, So do we need to store jks file within the Chart when we use helm?', 'commenter': 'qingwli'}, {'comment': 'That’s not an option. Please consider putting the content of jks file into the values.yaml file too', 'commenter': 'kezhenxu94'}]"
14355,dolphinscheduler-task-plugin/dolphinscheduler-task-python/src/main/java/org/apache/dolphinscheduler/plugin/task/python/PythonTask.java,"@@ -170,11 +170,11 @@
     protected String buildPythonScriptContent() throws Exception {
         log.info(""raw python script : {}"", pythonParameters.getRawScript());
         String rawPythonScript = pythonParameters.getRawScript().replaceAll(""\\r\\n"", System.lineSeparator());
-        Map<String, Property> paramsMap = mergeParamsWithContext(pythonParameters);
+        Map<String, Parameter> paramsMap = mergeParamsWithContext(pythonParameters);
         return ParameterUtils.convertParameterPlaceholders(rawPythonScript, ParameterUtils.convert(paramsMap));
     }
 
-    protected Map<String, Property> mergeParamsWithContext(AbstractParameters parameters) {
+    protected Map<String, Parameter> mergeParamsWithContext(AbstractParameters parameters) {","[{'comment': ""## Useless parameter\n\nThe parameter 'parameters' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2977)"", 'commenter': 'github-advanced-security[bot]'}]"
14355,dolphinscheduler-task-plugin/dolphinscheduler-task-sql/src/main/java/org/apache/dolphinscheduler/plugin/task/sql/SqlTask.java,"@@ -453,7 +453,7 @@
      * @param rgex rgex
      * @param sqlParamsMap sql params map
      */
-    private void printReplacedSql(String content, String formatSql, String rgex, Map<Integer, Property> sqlParamsMap) {
+    private void printReplacedSql(String content, String formatSql, String rgex, Map<Integer, Parameter> sqlParamsMap) {","[{'comment': ""## Useless parameter\n\nThe parameter 'content' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2978)"", 'commenter': 'github-advanced-security[bot]'}, {'comment': ""## Useless parameter\n\nThe parameter 'rgex' is never used.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/2979)"", 'commenter': 'github-advanced-security[bot]'}]"
14355,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/model/Parameter.java,"@@ -23,13 +23,13 @@
 import java.io.Serializable;
 import java.util.Objects;
 
-public class Property implements Serializable {
+public class Parameter implements Serializable {
 
     private static final long serialVersionUID = -4045513703397452451L;
     /**
      * key
      */
-    private String prop;
+    private String key;","[{'comment': 'It seems this pr will change the metadata structure, we need to refresh the whole data in db.', 'commenter': 'ruanwenjun'}, {'comment': '@ruanwenjun I got you. So it seems that `prop` should remain unchanged, and only rename `Property` to `Parameter`, WDYT?', 'commenter': 'rickchengx'}]"
14379,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/am/KubernetesApplicationManager.java,"@@ -181,15 +181,15 @@ private TaskExecutionStatus getApplicationStatus(KubernetesApplicationManagerCon
     public LogWatch getPodLogWatcher(KubernetesApplicationManagerContext kubernetesApplicationManagerContext) {
         KubernetesClient client = getClient(kubernetesApplicationManagerContext);
         FilterWatchListDeletable<Pod, PodList, PodResource> watchList =
-                getDriverPod(kubernetesApplicationManagerContext);
-        List<Pod> driverPod = watchList.list().getItems();
-        if (CollectionUtils.isEmpty(driverPod)) {
+                getListenPod(kubernetesApplicationManagerContext);
+        List<Pod> podList = watchList.list().getItems();
+        if (CollectionUtils.isEmpty(podList)) {
             return null;
         }
-        Pod driver = driverPod.get(0);
+        Pod pod = podList.get(0);","[{'comment': 'Not sure if there will be multiple Pods. Maybe you should filter the latest pods based on when they were created?\r\n\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/am/KubernetesApplicationManager.java#L100-L110\r\n\r\nWhen getting the pod list, maybe add jobname as a label filter?', 'commenter': 'Gallardot'}, {'comment': ""> Not sure if there will be multiple Pods. Maybe you should filter the latest pods based on when they were created?\r\n\r\nYou are right, one job can launch multiple pods. For this scenario, I think it's better support to read logs from different pods in future PR, rather read from the latest one, WDYT?\r\n\r\n> When getting the pod list, maybe add jobname as a label filter?\r\n\r\nThe label value here is `taskAppId` which can behave like a unique identifier of one job."", 'commenter': 'Radeity'}, {'comment': 'Got it. After the current PR merge, we create a new issue to track the issue', 'commenter': 'Gallardot'}]"
14379,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/am/KubernetesApplicationManager.java,"@@ -180,16 +182,25 @@ private TaskExecutionStatus getApplicationStatus(KubernetesApplicationManagerCon
      */
     public LogWatch getPodLogWatcher(KubernetesApplicationManagerContext kubernetesApplicationManagerContext) {
         KubernetesClient client = getClient(kubernetesApplicationManagerContext);
-        FilterWatchListDeletable<Pod, PodList, PodResource> watchList =
-                getDriverPod(kubernetesApplicationManagerContext);
-        List<Pod> driverPod = watchList.list().getItems();
-        if (CollectionUtils.isEmpty(driverPod)) {
-            return null;
+        boolean podIsReady = false;
+        Pod pod = null;
+        while (!podIsReady) {
+            FilterWatchListDeletable<Pod, PodList, PodResource> watchList =
+                    getListenPod(kubernetesApplicationManagerContext);
+            List<Pod> podList = watchList.list().getItems();
+            if (CollectionUtils.isEmpty(podList)) {
+                return null;
+            }
+            pod = podList.get(0);
+            if (pod.getStatus().getPhase().equals(PENDING)) {
+                ThreadUtils.sleep(SLEEP_TIME_MILLIS);
+            } else {
+                podIsReady = true;
+            }
         }
-        Pod driver = driverPod.get(0);
 
-        return client.pods().inNamespace(driver.getMetadata().getNamespace())
-                .withName(driver.getMetadata().getName())
+        return client.pods().inNamespace(pod.getMetadata().getNamespace())
+                .withName(pod.getMetadata().getName())","[{'comment': 'Add inContainer() to further specify the task container for the pod. In some environments, the infrastructure may automatically add sidecar containers. If the container is not specified, an exception occurs.', 'commenter': 'Gallardot'}]"
14379,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/am/KubernetesApplicationManager.java,"@@ -180,16 +182,25 @@ private TaskExecutionStatus getApplicationStatus(KubernetesApplicationManagerCon
      */
     public LogWatch getPodLogWatcher(KubernetesApplicationManagerContext kubernetesApplicationManagerContext) {
         KubernetesClient client = getClient(kubernetesApplicationManagerContext);
-        FilterWatchListDeletable<Pod, PodList, PodResource> watchList =
-                getDriverPod(kubernetesApplicationManagerContext);
-        List<Pod> driverPod = watchList.list().getItems();
-        if (CollectionUtils.isEmpty(driverPod)) {
-            return null;
+        boolean podIsReady = false;
+        Pod pod = null;
+        while (!podIsReady) {
+            FilterWatchListDeletable<Pod, PodList, PodResource> watchList =
+                    getListenPod(kubernetesApplicationManagerContext);
+            List<Pod> podList = watchList.list().getItems();
+            if (CollectionUtils.isEmpty(podList)) {
+                return null;","[{'comment': 'Should not return directly, perhaps the k8s controller manager is currently under high system load, and the scheduling is a little slow.\r\n\r\nWe should wait and retry, but of course we should set a reasonable number of retries.', 'commenter': 'Gallardot'}, {'comment': ""Really appreciate, I'll make some changes later today :D"", 'commenter': 'Radeity'}]"
14379,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/AbstractCommandExecutor.java,"@@ -327,7 +327,7 @@ private void collectPodLogIfNeeded() {
             ThreadUtils.sleep(SLEEP_TIME_MILLIS * 5L);
             try (
                     LogWatch watcher = ProcessUtils.getPodLogWatcher(taskRequest.getK8sTaskExecutionContext(),
-                            taskRequest.getTaskAppId())) {
+                            taskRequest.getTaskAppId(), """")) {","[{'comment': 'Why is it an empty string?', 'commenter': 'Gallardot'}, {'comment': 'In `AbstractCommandExecutor`, only need to get log watcher for Spark on K8S task, and we directly collect logs from driver pod, however, we can not set container name during task launching. Thus, we set empty string and the effect is same as collecting logs from all containers.', 'commenter': 'Radeity'}]"
14379,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/am/KubernetesApplicationManager.java,"@@ -97,16 +101,20 @@ public ResourceManagerType getResourceManagerType() {
      * @param kubernetesApplicationManagerContext
      * @return
      */
-    private FilterWatchListDeletable<Pod, PodList, PodResource> getDriverPod(KubernetesApplicationManagerContext kubernetesApplicationManagerContext) {
+    private FilterWatchListDeletable<Pod, PodList, PodResource> getListenPod(KubernetesApplicationManagerContext kubernetesApplicationManagerContext) {
         KubernetesClient client = getClient(kubernetesApplicationManagerContext);
         String labelValue = kubernetesApplicationManagerContext.getLabelValue();
-        FilterWatchListDeletable<Pod, PodList, PodResource> watchList = client.pods()
-                .inNamespace(kubernetesApplicationManagerContext.getK8sTaskExecutionContext().getNamespace())
-                .withLabel(UNIQUE_LABEL_NAME, labelValue);
-        List<Pod> podList = watchList.list().getItems();
-        if (podList.size() != 1) {
-            log.warn(""Expected driver pod 1, but get {}."", podList.size());
+        List<Pod> podList = null;
+        FilterWatchListDeletable<Pod, PodList, PodResource> watchList = null;
+        int retryTimes = 0;
+        while (CollectionUtils.isEmpty(podList) && retryTimes < MAX_RETRY_TIMES) {
+            watchList = client.pods()
+                    .inNamespace(kubernetesApplicationManagerContext.getK8sTaskExecutionContext().getNamespace())
+                    .withLabel(UNIQUE_LABEL_NAME, labelValue);
+            podList = watchList.list().getItems();
+            retryTimes += 1;","[{'comment': 'LGTM, while adding `thread.sleep` might be better.', 'commenter': 'Gallardot'}, {'comment': 'Oh sorry, I forgot to add this, thanks for your reminder!', 'commenter': 'Radeity'}]"
14402,dolphinscheduler-ui/pnpm-lock.yaml,"@@ -1,165 +1,108 @@
-# Licensed to the Apache Software Foundation (ASF) under one
-# or more contributor license agreements.  See the NOTICE file
-# distributed with this work for additional information
-# regarding copyright ownership.  The ASF licenses this file
-# to you under the Apache License, Version 2.0 (the
-# ""License""); you may not use this file except in compliance
-# with the License.  You may obtain a copy of the License at
-#
-#   http://www.apache.org/licenses/LICENSE-2.0
-#
-# Unless required by applicable law or agreed to in writing,
-# software distributed under the License is distributed on an
-# ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
-# KIND, either express or implied.  See the License for the
-# specific language governing permissions and limitations
-# under the License.
-lockfileVersion: '6.0'
+lockfileVersion: 5.3
+","[{'comment': 'restore changes to this file', 'commenter': 'EricGao888'}]"
14402,dolphinscheduler-api-test/dolphinscheduler-api-test-case/src/test/resources/workflow-json/test.json,"@@ -0,0 +1,81 @@
+[ {
+  ""processDefinition"" : {
+    ""id"" : 1,
+    ""code"" : 9752686452032,
+    ""name"" : ""test"",
+    ""version"" : 1,
+    ""releaseState"" : ""OFFLINE"",","[{'comment': 'remove this', 'commenter': 'EricGao888'}]"
14402,dolphinscheduler-api-test/dolphinscheduler-api-test-case/src/test/java/org/apache/dolphinscheduler/api/test/utils/MultipartUtility.java,"@@ -0,0 +1,151 @@
+package org.apache.dolphinscheduler.api.test.utils;
+","[{'comment': 'remove this file', 'commenter': 'EricGao888'}]"
14402,dolphinscheduler-api-test/dolphinscheduler-api-test-case/src/test/java/org/apache/dolphinscheduler/api/test/cases/ProjectAPITest.java,"@@ -0,0 +1,211 @@
+/*
+ * Licensed to Apache Software Foundation (ASF) under one or more contributor
+ * license agreements. See the NOTICE file distributed with
+ * this work for additional information regarding copyright
+ * ownership. Apache Software Foundation (ASF) licenses this file to you under
+ * the Apache License, Version 2.0 (the ""License""); you may
+ * not use this file except in compliance with the License.
+ * You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.dolphinscheduler.api.test.cases;
+
+import org.apache.dolphinscheduler.api.test.core.DolphinScheduler;
+import org.apache.dolphinscheduler.api.test.entity.HttpResponse;
+import org.apache.dolphinscheduler.api.test.entity.LoginResponseData;
+import org.apache.dolphinscheduler.api.test.pages.LoginPage;
+import org.apache.dolphinscheduler.api.test.pages.project.ProjectPage;
+import org.apache.dolphinscheduler.api.test.utils.JSONUtils;
+import org.apache.dolphinscheduler.common.enums.UserType;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.User;
+
+import org.junit.jupiter.api.AfterAll;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.api.BeforeAll;
+import org.junit.jupiter.api.Disabled;
+import org.junit.jupiter.api.Order;
+import org.junit.jupiter.api.Test;
+
+import lombok.extern.slf4j.Slf4j;
+
+import java.util.LinkedHashMap;
+import java.util.List;
+
+@DolphinScheduler(composeFiles = ""docker/basic/docker-compose.yaml"")
+@Slf4j
+// TODO: Add more detailed permission control related cases after userPage test cases completed
+public class ProjectAPITest {","[{'comment': ' Please add this to the https://github.com/apache/dolphinscheduler/blob/9c92b4b240a30e54464509b2e696e3310894507a/.github/workflows/api-test.yml#L90-L94', 'commenter': 'SbloodyS'}, {'comment': 'done, thx', 'commenter': 'EricGao888'}]"
14552,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -182,6 +185,18 @@ private void notifyProcessChanged(ProcessInstance finishProcessInstance) {
         }
     }
 
+    private void crossWorkflowParameterPassing(ProcessInstance finishProcessInstance, TaskInstance taskInstance) {
+        try {
+            MasterTaskExecuteRunnable masterTaskExecuteRunnable =
+                    MasterTaskExecuteRunnableHolder.getMasterTaskExecuteRunnable(taskInstance.getId());
+            masterTaskExecuteRunnable.getILogicTask().getTaskParameters()
+                    .setVarPool(finishProcessInstance.getVarPool());
+            log.info(""Cross workflow parameter passing success"");
+        } catch (Exception ex) {
+            log.info(""Cross workflow parameter passing error"");","[{'comment': '```suggestion\r\n            log.error(""Cross workflow parameter passing error: {}"", ex);\r\n```', 'commenter': 'SbloodyS'}]"
14552,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -182,6 +185,18 @@ private void notifyProcessChanged(ProcessInstance finishProcessInstance) {
         }
     }
 
+    private void crossWorkflowParameterPassing(ProcessInstance finishProcessInstance, TaskInstance taskInstance) {
+        try {
+            MasterTaskExecuteRunnable masterTaskExecuteRunnable =
+                    MasterTaskExecuteRunnableHolder.getMasterTaskExecuteRunnable(taskInstance.getId());
+            masterTaskExecuteRunnable.getILogicTask().getTaskParameters()
+                    .setVarPool(finishProcessInstance.getVarPool());
+            log.info(""Cross workflow parameter passing success"");","[{'comment': '```suggestion\r\n            log.info(""Cross workflow parameter passing success, processInstanceId: {}, taskInstanceId"");\r\n```\r\n\r\nIt\'s best to add more effective information for troubleshooting purposes.', 'commenter': 'SbloodyS'}]"
14552,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteThreadPool.java,"@@ -182,6 +185,18 @@ private void notifyProcessChanged(ProcessInstance finishProcessInstance) {
         }
     }
 
+    private void crossWorkflowParameterPassing(ProcessInstance finishProcessInstance, TaskInstance taskInstance) {
+        try {
+            MasterTaskExecuteRunnable masterTaskExecuteRunnable =
+                    MasterTaskExecuteRunnableHolder.getMasterTaskExecuteRunnable(taskInstance.getId());
+            masterTaskExecuteRunnable.getILogicTask().getTaskParameters()
+                    .setVarPool(finishProcessInstance.getVarPool());
+            log.info(""Cross workflow parameter passing success, processInstanceId: {}, taskInstanceId"");","[{'comment': 'The processInstanceId and taskInstanceId Not filled.', 'commenter': 'SbloodyS'}, {'comment': 'Sorry, I didn\'t check carefully\r\n`log.info(""Cross workflow parameter passing success, finishProcessInstanceId: {}, taskInstanceId: {}"", finishProcessInstance.getId(), taskInstance.getId());`\r\nis this ok?', 'commenter': 'Orange-Summer'}, {'comment': 'Yes. Please supplement other relevant logs.', 'commenter': 'SbloodyS'}, {'comment': 'Is there anything else you think needs to be added to the log?', 'commenter': 'Orange-Summer'}, {'comment': 'Exception error log should add too.', 'commenter': 'SbloodyS'}, {'comment': 'I have added it, thanks for your advice.', 'commenter': 'Orange-Summer'}]"
14555,.github/workflows/e2e-k8s.yml,"@@ -0,0 +1,188 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+on:
+  pull_request:
+  push:
+    branches:
+      - dev
+
+name: E2E-K8S
+
+concurrency:
+  group: E2E-K8S-${{ github.event.pull_request.number || github.ref }}
+  cancel-in-progress: true
+
+
+jobs:
+  paths-filter:
+    name: E2E-K8S-Path-Filter
+    runs-on: ubuntu-latest
+    outputs:
+      not-ignore: ${{ steps.filter.outputs.not-ignore }}
+    steps:
+      - uses: actions/checkout@v2
+      - uses: dorny/paths-filter@b2feaf19c27470162a626bd6fa8438ae5b263721
+        id: filter
+        with:
+          filters: |
+            not-ignore:
+              - '!(docs/**)'
+  e2e-k8s:
+    name: E2E-K8S-Execute
+    needs: paths-filter
+    if: ${{ (needs.paths-filter.outputs.not-ignore == 'true') || (github.event_name == 'push') }}
+    runs-on: ubuntu-latest
+    timeout-minutes: 20
+    steps:
+      - uses: actions/checkout@v2
+        with:
+          submodules: true
+      - name: Build Image
+        run: |
+          ./mvnw -B clean package \
+          -Dmaven.test.skip \
+          -Dmaven.javadoc.skip \
+          -Dspotless.skip=true \
+          -Dmaven.checkstyle.skip \
+          -Dmaven.deploy.skip \
+          -Ddocker.push.skip=true \
+          -Pdocker,release -Ddocker.tag=ci \
+          -pl org.apache.dolphinscheduler:dolphinscheduler-alert-server \","[{'comment': 'Just curious, why did you put `org.apache.dolphinscheduler:` only before `dolphinscheduler-alert-server`? Looks a little bit inconsistent to me.', 'commenter': 'EricGao888'}, {'comment': ""Because `olphinscheduler-alert-server` is a submodule of the `dolphinscheduler-alert` and has a different level from the other modules `api` \\ `master` etc. If the submodule is nested, you can use a colon : to separate the path.\r\n\r\nref: [maven -pl](https://maven.apache.org/ref/3.8.1/maven-embedder/cli.html#option-pl)\r\n\r\nMaybe there's a better way?"", 'commenter': 'Gallardot'}, {'comment': ""Got it. I didn't notice that it is `dolphinscheduler-alert-server` here instead of `dolphinscheduler-alert`."", 'commenter': 'EricGao888'}]"
14555,.github/workflows/e2e-k8s.yml,"@@ -0,0 +1,188 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+on:
+  pull_request:
+  push:
+    branches:
+      - dev
+
+name: E2E-K8S
+
+concurrency:
+  group: E2E-K8S-${{ github.event.pull_request.number || github.ref }}
+  cancel-in-progress: true
+
+
+jobs:
+  paths-filter:
+    name: E2E-K8S-Path-Filter
+    runs-on: ubuntu-latest
+    outputs:
+      not-ignore: ${{ steps.filter.outputs.not-ignore }}
+    steps:
+      - uses: actions/checkout@v2
+      - uses: dorny/paths-filter@b2feaf19c27470162a626bd6fa8438ae5b263721
+        id: filter
+        with:
+          filters: |
+            not-ignore:
+              - '!(docs/**)'
+  e2e-k8s:
+    name: E2E-K8S-Execute
+    needs: paths-filter
+    if: ${{ (needs.paths-filter.outputs.not-ignore == 'true') || (github.event_name == 'push') }}
+    runs-on: ubuntu-latest
+    timeout-minutes: 20
+    steps:
+      - uses: actions/checkout@v2
+        with:
+          submodules: true
+      - name: Build Image
+        run: |
+          ./mvnw -B clean package \
+          -Dmaven.test.skip \
+          -Dmaven.javadoc.skip \
+          -Dspotless.skip=true \
+          -Dmaven.checkstyle.skip \
+          -Dmaven.deploy.skip \
+          -Ddocker.push.skip=true \
+          -Pdocker,release -Ddocker.tag=ci \
+          -pl org.apache.dolphinscheduler:dolphinscheduler-alert-server \
+          -pl dolphinscheduler-tools \
+          -pl dolphinscheduler-api \
+          -pl dolphinscheduler-master \
+          -pl dolphinscheduler-worker -am
+      - name: Create k8s Kind Cluster
+        run: |
+          # install kubectl
+          curl -LO ""https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl""
+          sudo chmod +x kubectl /usr/local/bin/kubectl
+          sudo mv kubectl /usr/local/bin/kubectl
+
+          # install kind
+          curl -LO https://github.com/kubernetes-sigs/kind/releases/download/v0.20.0/kind-linux-amd64
+          sudo chmod +x kind-linux-amd64
+          sudo mv kind-linux-amd64 /usr/local/bin/kind
+          kind version
+
+          # create kind cluster
+          kind_node_image=""kindest/node:v1.23.17""
+          echo ""Kubernetes version: ${kind_node_image}""
+          kind create cluster --name dolphinscheduler --image ${kind_node_image}
+          kubectl version --short
+          kubectl get all --all-namespaces
+      - name: Load images
+        run: |
+          components=(""master"" ""worker"" ""api"" ""tools"" ""alert-server"")
+          for component in ""${components[@]}""; do
+            kind load docker-image apache/dolphinscheduler-${component}:ci --name dolphinscheduler
+          done
+      - name: Helm install dolphinscheduler
+        working-directory: ${{ github.workspace }}/deploy/kubernetes/dolphinscheduler
+        run: |
+          curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash
+          helm repo add bitnami https://charts.bitnami.com/bitnami
+          helm dependency update .
+          helm upgrade --install --create-namespace -n dolphinscheduler dolphinscheduler . -f - <<EOF
+          image:
+            registry: apache
+            tag: ci
+          conf:
+            common:
+              resource.azure.client.id: minioadmin","[{'comment': 'Why set `resource.azure.xxxxxx` here? It seems in DS helm chart `values.yaml` there are not such configurations related to `azure`, do I miss anything? https://github.com/apache/dolphinscheduler/blob/dev/deploy/kubernetes/dolphinscheduler/values.yaml', 'commenter': 'EricGao888'}, {'comment': 'This azure configuration item was added mainly because of [the static object initialization requirements in the cloudservice implementation](https://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.java#L44-L55). Of course, it would be better to add these configuration items directly to the values of helm charts as default values.', 'commenter': 'Gallardot'}, {'comment': ""```\r\n[INFO] 2023-07-21 23:09:36.524 +0800 org.apache.dolphinscheduler.remote.factory.NettyRemotingClientFactory:[32] - NettyRemotingClient initialized with config: NettyClientConfig(workerThreads=8, tcpNoDelay=true, soKeepalive=true, sendBufferSize=65535, receiveBufferSize=65535, connectTimeoutMillis=3000)\r\n[INFO] 2023-07-21 23:09:37.645 +0800 com.azure.core.implementation.ReflectionUtils:[542] - Unable to create MethodHandles to use Java 9+ MethodHandles.privateLookupIn. Will attempt to fallback to using the package-private constructor.\r\n[WARN] 2023-07-21 23:09:37.648 +0800 com.azure.identity.ClientSecretCredentialBuilder:[500] - Must provide non-null values for clientId, tenantId, clientSecret properties in ClientSecretCredentialBuilder\r\n[WARN] 2023-07-21 23:09:37.649 +0800 org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext:[591] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/opt/dolphinscheduler/libs/dolphinscheduler-api-dev-SNAPSHOT.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n[INFO] 2023-07-21 23:09:37.657 +0800 org.apache.dolphinscheduler.remote.NettyRemotingClient:[340] - netty client closed\r\n[INFO] 2023-07-21 23:09:37.658 +0800 org.apache.dolphinscheduler.service.log.LogClient:[239] - LogClientService closed\r\n[INFO] 2023-07-21 23:09:37.661 +0800 org.apache.curator.framework.imps.CuratorFrameworkImpl:[998] - backgroundOperationsLoop exiting\r\n[WARN] 2023-07-21 23:09:37.818 +0800 org.springframework.beans.factory.support.DisposableBeanAdapter:[248] - Invocation of close method failed on bean with name 'springApplicationContext': org.springframework.beans.factory.BeanCreationNotAllowedException: Error creating bean with name 'applicationAvailability': Singleton bean creation not allowed while singletons of this factory are in destruction (Do not request a bean from a BeanFactory in a destroy method implementation!)\r\n[INFO] 2023-07-21 23:09:37.822 +0800 com.zaxxer.hikari.HikariDataSource:[350] - DolphinScheduler - Shutdown initiated...\r\n[INFO] 2023-07-21 23:09:37.831 +0800 com.zaxxer.hikari.HikariDataSource:[352] - DolphinScheduler - Shutdown completed.\r\n[INFO] 2023-07-21 23:09:37.837 +0800 org.eclipse.jetty.server.session:[149] - node0 Stopped scavenging\r\n[INFO] 2023-07-21 23:09:37.838 +0800 org.eclipse.jetty.server.handler.ContextHandler:[1159] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@da67c46{application,/dolphinscheduler,[file:///tmp/jetty-docbase.12345.4698056214290860435/, jar:file:/opt/dolphinscheduler/libs/swagger-ui-4.11.1.jar!/META-INF/resources],STOPPED}\r\n[INFO] 2023-07-21 23:09:37.872 +0800 org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener:[136] -\r\n\r\nError starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.\r\n[ERROR] 2023-07-21 23:09:37.923 +0800 org.springframework.boot.SpringApplication:[824] - Application run failed\r\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/opt/dolphinscheduler/libs/dolphinscheduler-api-dev-SNAPSHOT.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:332)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\r\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\r\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)\r\n\tat org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)\r\n\tat org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)\r\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)\r\n\tat org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)\r\n\tat org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)\r\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:308)\r\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)\r\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)\r\n\tat org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:54)\r\nCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/opt/dolphinscheduler/libs/dolphinscheduler-api-dev-SNAPSHOT.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1334)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1232)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\r\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\r\n\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)\r\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)\r\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:544)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:520)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:673)\r\n\tat org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:228)\r\n\tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:329)\r\n\t... 17 common frames omitted\r\nCaused by: java.lang.ExceptionInInitializerError: null\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:211)\r\n\tat org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1326)\r\n\t... 33 common frames omitted\r\nCaused by: java.lang.IllegalArgumentException: Must provide non-null values for clientId, tenantId, clientSecret properties in ClientSecretCredentialBuilder\r\n\tat com.azure.identity.implementation.util.ValidationUtil.validate(ValidationUtil.java:27)\r\n\tat com.azure.identity.ClientSecretCredentialBuilder.build(ClientSecretCredentialBuilder.java:74)\r\n\tat org.apache.dolphinscheduler.api.service.impl.CloudServiceImpl.<clinit>(CloudServiceImpl.java:55)\r\n\t... 40 common frames omitted\r\n```\r\n\r\nAbove is the exception log encountered at that time\r\n"", 'commenter': 'Gallardot'}, {'comment': ""Ok I got it. Could u plz add some comments in the code so that other developers will not get confused? BTW, I think the `CloudServiceImpl` was poorly designed and should be removed in the future. cc @SbloodyS But removing `CloudServiceImpl` is out of the scope of this PR, you don't need to do it in this one."", 'commenter': 'EricGao888'}, {'comment': 'I will copy these Azure configurations to the default values in the Helm charts, as they are not only required for CI but also for production use, even if Azure is not being used.', 'commenter': 'Gallardot'}, {'comment': 'Sounds good to me. It seems to be the best solution at this moment.', 'commenter': 'EricGao888'}, {'comment': 'Done. PTAL.', 'commenter': 'Gallardot'}, {'comment': ""> ```\r\n> [INFO] 2023-07-21 23:09:36.524 +0800 org.apache.dolphinscheduler.remote.factory.NettyRemotingClientFactory:[32] - NettyRemotingClient initialized with config: NettyClientConfig(workerThreads=8, tcpNoDelay=true, soKeepalive=true, sendBufferSize=65535, receiveBufferSize=65535, connectTimeoutMillis=3000)\r\n> [INFO] 2023-07-21 23:09:37.645 +0800 com.azure.core.implementation.ReflectionUtils:[542] - Unable to create MethodHandles to use Java 9+ MethodHandles.privateLookupIn. Will attempt to fallback to using the package-private constructor.\r\n> [WARN] 2023-07-21 23:09:37.648 +0800 com.azure.identity.ClientSecretCredentialBuilder:[500] - Must provide non-null values for clientId, tenantId, clientSecret properties in ClientSecretCredentialBuilder\r\n> [WARN] 2023-07-21 23:09:37.649 +0800 org.springframework.boot.web.servlet.context.AnnotationConfigServletWebServerApplicationContext:[591] - Exception encountered during context initialization - cancelling refresh attempt: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/opt/dolphinscheduler/libs/dolphinscheduler-api-dev-SNAPSHOT.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n> [INFO] 2023-07-21 23:09:37.657 +0800 org.apache.dolphinscheduler.remote.NettyRemotingClient:[340] - netty client closed\r\n> [INFO] 2023-07-21 23:09:37.658 +0800 org.apache.dolphinscheduler.service.log.LogClient:[239] - LogClientService closed\r\n> [INFO] 2023-07-21 23:09:37.661 +0800 org.apache.curator.framework.imps.CuratorFrameworkImpl:[998] - backgroundOperationsLoop exiting\r\n> [WARN] 2023-07-21 23:09:37.818 +0800 org.springframework.beans.factory.support.DisposableBeanAdapter:[248] - Invocation of close method failed on bean with name 'springApplicationContext': org.springframework.beans.factory.BeanCreationNotAllowedException: Error creating bean with name 'applicationAvailability': Singleton bean creation not allowed while singletons of this factory are in destruction (Do not request a bean from a BeanFactory in a destroy method implementation!)\r\n> [INFO] 2023-07-21 23:09:37.822 +0800 com.zaxxer.hikari.HikariDataSource:[350] - DolphinScheduler - Shutdown initiated...\r\n> [INFO] 2023-07-21 23:09:37.831 +0800 com.zaxxer.hikari.HikariDataSource:[352] - DolphinScheduler - Shutdown completed.\r\n> [INFO] 2023-07-21 23:09:37.837 +0800 org.eclipse.jetty.server.session:[149] - node0 Stopped scavenging\r\n> [INFO] 2023-07-21 23:09:37.838 +0800 org.eclipse.jetty.server.handler.ContextHandler:[1159] - Stopped o.s.b.w.e.j.JettyEmbeddedWebAppContext@da67c46{application,/dolphinscheduler,[file:///tmp/jetty-docbase.12345.4698056214290860435/, jar:file:/opt/dolphinscheduler/libs/swagger-ui-4.11.1.jar!/META-INF/resources],STOPPED}\r\n> [INFO] 2023-07-21 23:09:37.872 +0800 org.springframework.boot.autoconfigure.logging.ConditionEvaluationReportLoggingListener:[136] -\r\n> \r\n> Error starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.\r\n> [ERROR] 2023-07-21 23:09:37.923 +0800 org.springframework.boot.SpringApplication:[824] - Application run failed\r\n> org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/opt/dolphinscheduler/libs/dolphinscheduler-api-dev-SNAPSHOT.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n> \tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:332)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)\r\n> \tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\r\n> \tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\r\n> \tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\r\n> \tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\r\n> \tat org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)\r\n> \tat org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)\r\n> \tat org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)\r\n> \tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)\r\n> \tat org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)\r\n> \tat org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)\r\n> \tat org.springframework.boot.SpringApplication.run(SpringApplication.java:308)\r\n> \tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)\r\n> \tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)\r\n> \tat org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:54)\r\n> Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/opt/dolphinscheduler/libs/dolphinscheduler-api-dev-SNAPSHOT.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1334)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1232)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)\r\n> \tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\r\n> \tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\r\n> \tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\r\n> \tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\r\n> \tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)\r\n> \tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)\r\n> \tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)\r\n> \tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:544)\r\n> \tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:520)\r\n> \tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:673)\r\n> \tat org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:228)\r\n> \tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)\r\n> \tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:329)\r\n> \t... 17 common frames omitted\r\n> Caused by: java.lang.ExceptionInInitializerError: null\r\n> \tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n> \tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n> \tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n> \tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n> \tat org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:211)\r\n> \tat org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)\r\n> \tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1326)\r\n> \t... 33 common frames omitted\r\n> Caused by: java.lang.IllegalArgumentException: Must provide non-null values for clientId, tenantId, clientSecret properties in ClientSecretCredentialBuilder\r\n> \tat com.azure.identity.implementation.util.ValidationUtil.validate(ValidationUtil.java:27)\r\n> \tat com.azure.identity.ClientSecretCredentialBuilder.build(ClientSecretCredentialBuilder.java:74)\r\n> \tat org.apache.dolphinscheduler.api.service.impl.CloudServiceImpl.<clinit>(CloudServiceImpl.java:55)\r\n> \t... 40 common frames omitted\r\n> ```\r\n> \r\n> 上面是当时遇到的异常日志\r\n\r\n\r\nI also have this problem in 3.2.1. How can I solve it？\r\n\r\nError starting ApplicationContext. To display the conditions report re-run your application with 'debug' enabled.\r\n[ERROR] 2024-06-03 13:48:22.360 +0800 o.s.b.SpringApplication:[824] - Application run failed\r\norg.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudController': Injection of resource dependencies failed; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/data/opt/datasophon/dolphinscheduler-3.2.1/api-server/libs/dolphinscheduler-api-3.2.1.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:332)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1431)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:619)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\r\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\r\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:955)\r\n\tat org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:918)\r\n\tat org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:583)\r\n\tat org.springframework.boot.web.servlet.context.ServletWebServerApplicationContext.refresh(ServletWebServerApplicationContext.java:147)\r\n\tat org.springframework.boot.SpringApplication.refresh(SpringApplication.java:734)\r\n\tat org.springframework.boot.SpringApplication.refreshContext(SpringApplication.java:408)\r\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:308)\r\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1306)\r\n\tat org.springframework.boot.SpringApplication.run(SpringApplication.java:1295)\r\n\tat org.apache.dolphinscheduler.api.ApiApplicationServer.main(ApiApplicationServer.java:58)\r\nCaused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'cloudServiceImpl' defined in URL [jar:file:/data/opt/datasophon/dolphinscheduler-3.2.1/api-server/libs/dolphinscheduler-api-3.2.1.jar!/org/apache/dolphinscheduler/api/service/impl/CloudServiceImpl.class]: Instantiation of bean failed; nested exception is java.lang.ExceptionInInitializerError\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1334)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1232)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:582)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:542)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.lambda$doGetBean$0(AbstractBeanFactory.java:335)\r\n\tat org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:234)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:333)\r\n\tat org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:208)\r\n\tat org.springframework.beans.factory.config.DependencyDescriptor.resolveCandidate(DependencyDescriptor.java:276)\r\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.doResolveDependency(DefaultListableBeanFactory.java:1391)\r\n\tat org.springframework.beans.factory.support.DefaultListableBeanFactory.resolveDependency(DefaultListableBeanFactory.java:1311)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.autowireResource(CommonAnnotationBeanPostProcessor.java:544)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.getResource(CommonAnnotationBeanPostProcessor.java:520)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor$ResourceElement.getResourceToInject(CommonAnnotationBeanPostProcessor.java:673)\r\n\tat org.springframework.beans.factory.annotation.InjectionMetadata$InjectedElement.inject(InjectionMetadata.java:228)\r\n\tat org.springframework.beans.factory.annotation.InjectionMetadata.inject(InjectionMetadata.java:119)\r\n\tat org.springframework.context.annotation.CommonAnnotationBeanPostProcessor.postProcessProperties(CommonAnnotationBeanPostProcessor.java:329)\r\n\t... 17 common frames omitted\r\nCaused by: java.lang.ExceptionInInitializerError: null\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\r\n\tat sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\r\n\tat sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\r\n\tat java.lang.reflect.Constructor.newInstance(Constructor.java:423)\r\n\tat org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:211)\r\n\tat org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:87)\r\n\tat org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.instantiateBean(AbstractAutowireCapableBeanFactory.java:1326)\r\n\t... 33 common frames omitted\r\nCaused by: java.lang.IllegalArgumentException: Must provide non-null values for clientId, tenantId, clientSecret properties in ClientSecretCredentialBuilder\r\n\tat com.azure.identity.implementation.util.ValidationUtil.validate(ValidationUtil.java:27)\r\n\tat com.azure.identity.ClientSecretCredentialBuilder.build(ClientSecretCredentialBuilder.java:74)\r\n\tat org.apache.dolphinscheduler.api.service.impl.CloudServiceImpl.<clinit>(CloudServiceImpl.java:55)\r\n\t... 40 common frames omitted\r\n"", 'commenter': 'liusy-bd'}]"
14555,.github/workflows/e2e-k8s.yml,"@@ -0,0 +1,145 @@
+#
+# Licensed to the Apache Software Foundation (ASF) under one or more
+# contributor license agreements.  See the NOTICE file distributed with
+# this work for additional information regarding copyright ownership.
+# The ASF licenses this file to You under the Apache License, Version 2.0
+# (the ""License""); you may not use this file except in compliance with
+# the License.  You may obtain a copy of the License at
+#
+#     http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+#
+
+on:
+  pull_request:
+  push:
+    branches:
+      - dev
+
+name: E2E-K8S
+
+concurrency:
+  group: E2E-K8S-${{ github.event.pull_request.number || github.ref }}
+  cancel-in-progress: true
+
+
+jobs:
+  paths-filter:
+    name: E2E-K8S-Path-Filter
+    runs-on: ubuntu-latest
+    outputs:
+      not-ignore: ${{ steps.filter.outputs.not-ignore }}
+    steps:
+      - uses: actions/checkout@v2
+      - uses: dorny/paths-filter@b2feaf19c27470162a626bd6fa8438ae5b263721
+        id: filter
+        with:
+          filters: |
+            not-ignore:
+              - '!(docs/**)'
+  e2e-k8s:
+    name: E2E-K8S-Execute
+    needs: paths-filter
+    if: ${{ (needs.paths-filter.outputs.not-ignore == 'true') || (github.event_name == 'push') }}
+    runs-on: ubuntu-latest
+    timeout-minutes: 20
+    steps:
+      - uses: actions/checkout@v2
+        with:
+          submodules: true
+      - name: Build Image
+        run: |
+          ./mvnw -B clean package \
+          -Dmaven.test.skip \
+          -Dmaven.javadoc.skip \
+          -Dspotless.skip=true \
+          -Dmaven.checkstyle.skip \
+          -Dmaven.deploy.skip \
+          -Ddocker.push.skip=true \
+          -Pdocker,release -Ddocker.tag=ci \
+          -pl org.apache.dolphinscheduler:dolphinscheduler-alert-server \
+          -pl dolphinscheduler-tools \
+          -pl dolphinscheduler-api \
+          -pl dolphinscheduler-master \
+          -pl dolphinscheduler-worker -am
+      - name: Create k8s Kind Cluster","[{'comment': ""It seems that full k8s is not very sufficient for CI's small machines. Can we try to use some ccaled-down version of k8s such as k3s or minikube?\r\n\r\n"", 'commenter': 'SbloodyS'}, {'comment': '`Kind` itself does not consume too many resources. I delayed the health check of the `DS-related` components mainly because multiple Java applications started simultaneously consume a lot of resources. The use of `Kind` is mainly for convenience, so that developers can easily reproduce the environment.', 'commenter': 'Gallardot'}, {'comment': 'At present, it seems that it did not complete its execution in 20 minutes, exceeding the load that CI can withstand.', 'commenter': 'SbloodyS'}, {'comment': 'I analyzed the time consumption from [here](https://github.com/apache/dolphinscheduler/actions/runs/5665279610/job/15349865668?pr=14555) and found that building the image took 7 minutes. Starting Kind and loading the image took 2 minutes. Installing and waiting for DS ready took 10 minutes. Perhaps we can split the image building into a separate task, which would also facilitate executing k8s task-related e2e tasks on the k8s cluster later.\r\n\r\nWDYT? @SbloodyS @EricGao888 ', 'commenter': 'Gallardot'}, {'comment': ""I'm ok with it. How about 20 min for build and 20 min for e2e-k8s?"", 'commenter': 'SbloodyS'}, {'comment': ""I'm not sure about this. If different tasks run on different test machines, is there a way for them to share the images?"", 'commenter': 'EricGao888'}, {'comment': ""> I'm not sure about this. If different tasks run on different test machines, is there a way for them to share the images?\r\n\r\nYes. We did the same in e2e-test and api-e2e-test."", 'commenter': 'SbloodyS'}, {'comment': ""I made some optimizations based on @EricGao888 's suggestions, and the time consumption has been greatly reduced. As for splitting the tasks, perhaps we can do it when adding k8s task-related e2e test cases? @SbloodyS "", 'commenter': 'Gallardot'}, {'comment': ""> I made some optimizations based on @EricGao888 's suggestions, and the time consumption has been greatly reduced. As for splitting the tasks, perhaps we can do it when adding k8s task-related e2e test cases? @SbloodyS\r\n\r\nSure."", 'commenter': 'SbloodyS'}]"
14577,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java,"@@ -1336,7 +1336,7 @@ public Map<String, Object> registerUser(String userName, String userPassword, St
             putMsg(result, Status.REQUEST_PARAMS_NOT_VALID_ERROR, ""two passwords are not same"");
             return result;
         }
-        User user = createUser(userName, userPassword, email, 1, """", """", Flag.NO.ordinal());
+        User user = createUser(userName, userPassword, email, -1, """", """", Flag.NO.ordinal());","[{'comment': 'If we set -1, it will cause some possible NPE, like \r\n`String tenantCode = tenantMapper.queryById(loginUser.getTenantId()).getTenantCode();`\r\nIf you want to modify it, plz make sure to fix those NPE, either :D', 'commenter': 'Radeity'}, {'comment': ""This risk is already dealt with by DML. By default, a tenant with an id of -1 is added. Instead, there is no tenant with id 1.  That's why I made this change.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/399d0d0ce9be29724988dcbd9a7dc5fbfab44de0/dolphinscheduler-dao/src/main/resources/sql/upgrade/3.2.0_schema/mysql/dolphinscheduler_dml.sql#L19-L31"", 'commenter': 'Gallardot'}]"
14577,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/UsersController.java,"@@ -111,6 +111,10 @@ public Result createUser(@Parameter(hidden = true) @RequestAttribute(value = Con
                              @RequestParam(value = ""email"") String email,
                              @RequestParam(value = ""phone"", required = false) String phone,
                              @RequestParam(value = ""state"", required = false) int state) throws Exception {
+        Result verifyRet = usersService.verifyUserName(userName);
+        if (verifyRet.getCode() != Status.SUCCESS.getCode()) {
+            return verifyRet;
+        }","[{'comment': 'Can we also add this check in update api?', 'commenter': 'Radeity'}, {'comment': 'The update API already does this check.\r\n\r\nhttps://github.com/apache/dolphinscheduler/blob/399d0d0ce9be29724988dcbd9a7dc5fbfab44de0/dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/UsersServiceImpl.java#L408-L432', 'commenter': 'Gallardot'}, {'comment': 'Get it.', 'commenter': 'Radeity'}]"
14606,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/runner/WorkflowExecuteRunnable.java,"@@ -784,6 +785,16 @@ public void checkSerialProcess(ProcessDefinition processDefinition) {
             return;
         }
         Map<String, Object> cmdParam = new HashMap<>();
+        // write the parameters of the nextProcessInstance to command
+        if (StringUtils.isNotEmpty(nextProcessInstance.getCommandParam())) {
+            Map<String, String> commandStartParamsMap = JSONUtils.toMap(nextProcessInstance.getCommandParam());
+            if (MapUtils.isNotEmpty(commandStartParamsMap)) {
+                Map<String, String> paramsMap = JSONUtils.toMap(commandStartParamsMap.get(CMD_PARAM_START_PARAMS));
+                if (MapUtils.isNotEmpty(paramsMap)) {
+                    cmdParam.put(CMD_PARAM_START_PARAMS, JSONUtils.toJsonString(paramsMap));
+                }
+            }
+        }","[{'comment': 'Why we need to set the workflow instance param to command?', 'commenter': 'ruanwenjun'}, {'comment': 'The next process instance to be awakened will create a new command, and The new command needs to keep the original ""StartParams"" fields', 'commenter': 'CallMeKingsley97'}, {'comment': 'Whether I need to change the code   @ruanwenjun ', 'commenter': 'CallMeKingsley97'}, {'comment': ""It should work, but it's better to change the command consumer logic rather than put the param in wakeup command."", 'commenter': 'ruanwenjun'}, {'comment': ""> It should work, but it's better to change the command consumer logic rather than put the param in wakeup command.\r\n\r\nthanks! "", 'commenter': 'CallMeKingsley97'}]"
14612,dolphinscheduler-bom/pom.xml,"@@ -56,7 +56,7 @@
         <hadoop.version>3.2.4</hadoop.version>
         <cron-utils.version>9.1.6</cron-utils.version>
         <h2.version>2.2.220</h2.version>
-        <mysql-connector.version>8.0.16</mysql-connector.version>
+        <mysql-connector.version>8.0.33</mysql-connector.version>","[{'comment': 'Please add this to incompatible change to the docs.', 'commenter': 'SbloodyS'}, {'comment': 'Okay', 'commenter': 'eye-gu'}]"
14612,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/entity/Command.java,"@@ -61,6 +61,7 @@ public class Command {
     private String commandParam;
 
     @TableField(""task_depend_type"")
+    @Builder.Default","[{'comment': ""Please add `@Builer.Default` to `failureStrategy` and `updateTime`.\r\n\r\nIn fact I don't think it's a good idea to add default value in DO， but this is a history issue."", 'commenter': 'ruanwenjun'}, {'comment': 'Added', 'commenter': 'eye-gu'}]"
14743,dolphinscheduler-ui/src/views/login/index.tsx,"@@ -38,15 +41,16 @@ import { useLocalesStore } from '@/store/locales/locales'
 import { useThemeStore } from '@/store/theme/theme'
 import cookies from 'js-cookie'
 import { ssoLoginUrl } from '@/service/modules/login'
+import { OAuth2Provider } from '@/service/modules/login/types'","[{'comment': 'Please import type.', 'commenter': 'songjianet'}, {'comment': 'I have already resolve it, could you please help review it again when you are free @songjianet ', 'commenter': 'hdygxsj'}]"
14743,dolphinscheduler-ui/src/views/login/index.tsx,"@@ -38,15 +41,16 @@ import { useLocalesStore } from '@/store/locales/locales'
 import { useThemeStore } from '@/store/theme/theme'
 import cookies from 'js-cookie'
 import { ssoLoginUrl } from '@/service/modules/login'
+import { OAuth2Provider } from '@/service/modules/login/types'
+","[{'comment': 'Please delete enter.', 'commenter': 'songjianet'}]"
14743,dolphinscheduler-ui/src/views/login/index.tsx,"@@ -170,6 +178,15 @@ const login = defineComponent({
               </NButton>
             </a>
           </div>
+            {this.oauth2Providers.length > 0 ? <NDivider >
+              {this.t('login.otherwayLogin')}
+            </NDivider> : <div></div>}","[{'comment': ""Don't use Ternary operator, Please user this.oauth2Providers.length > 0 && <NDivider>\r\n              {this.t('login.otherwayLogin')}\r\n            </NDivider>"", 'commenter': 'songjianet'}]"
14743,dolphinscheduler-ui/src/views/login/use-login.ts,"@@ -16,23 +16,25 @@
  */
 
 import { useRouter } from 'vue-router'
-import { login } from '@/service/modules/login'
+import { clearCookie, getOauth2Provider, login } from '@/service/modules/login'
 import { getUserInfo } from '@/service/modules/users'
 import { useUserStore } from '@/store/user/user'
 import type { Router } from 'vue-router'
-import type { LoginRes } from '@/service/modules/login/types'
+import { useRoute } from 'vue-router'
+import type { LoginRes, OAuth2Provider } from '@/service/modules/login/types'
 import type { UserInfoRes } from '@/service/modules/users/types'
 import { useRouteStore } from '@/store/route/route'
 import { useTimezoneStore } from '@/store/timezone/timezone'
 import cookies from 'js-cookie'
 import { queryBaseDir } from '@/service/modules/resources'
+import { reactive, ref } from 'vue'","[{'comment': 'Please remove unused references.', 'commenter': 'songjianet'}]"
14743,dolphinscheduler-ui/src/views/login/use-login.ts,"@@ -63,7 +65,49 @@ export function useLogin(state: any) {
     })
   }
 
+
+
+  const handleGetOAuth2Provider = () => {
+    getOauth2Provider().then((res: Array<OAuth2Provider> | []) => {
+      oauth2Providers.value = res
+    })
+  }
+
+  const oauth2Providers = ref<Array<OAuth2Provider> | []>([])
+
+  const gotoOAuth2Page = async (oauth2Provider: OAuth2Provider) => {
+    await clearCookie()
+    window.location.href = `${oauth2Provider.authorizationUri}?client_id=${oauth2Provider.clientId}` +
+      `&redirect_uri=${oauth2Provider.redirectUri}?provider=${oauth2Provider.provider}`
+  }
+
+  const handleRedirect = async () => {
+    debugger","[{'comment': 'Please remove debugger.', 'commenter': 'songjianet'}]"
14743,dolphinscheduler-ui/src/views/login/use-login.ts,"@@ -63,7 +65,49 @@ export function useLogin(state: any) {
     })
   }
 
+
+
+  const handleGetOAuth2Provider = () => {
+    getOauth2Provider().then((res: Array<OAuth2Provider> | []) => {
+      oauth2Providers.value = res
+    })
+  }
+
+  const oauth2Providers = ref<Array<OAuth2Provider> | []>([])
+
+  const gotoOAuth2Page = async (oauth2Provider: OAuth2Provider) => {
+    await clearCookie()
+    window.location.href = `${oauth2Provider.authorizationUri}?client_id=${oauth2Provider.clientId}` +
+      `&redirect_uri=${oauth2Provider.redirectUri}?provider=${oauth2Provider.provider}`
+  }
+
+  const handleRedirect = async () => {
+    debugger
+    const authType = route.query.authType
+    if (authType && authType == 'oauth2') {","[{'comment': ""Please use '==='."", 'commenter': 'songjianet'}]"
14743,dolphinscheduler-ui/src/views/login/use-login.ts,"@@ -63,7 +65,49 @@ export function useLogin(state: any) {
     })
   }
 
+
+
+  const handleGetOAuth2Provider = () => {
+    getOauth2Provider().then((res: Array<OAuth2Provider> | []) => {
+      oauth2Providers.value = res
+    })
+  }
+
+  const oauth2Providers = ref<Array<OAuth2Provider> | []>([])
+
+  const gotoOAuth2Page = async (oauth2Provider: OAuth2Provider) => {
+    await clearCookie()
+    window.location.href = `${oauth2Provider.authorizationUri}?client_id=${oauth2Provider.clientId}` +
+      `&redirect_uri=${oauth2Provider.redirectUri}?provider=${oauth2Provider.provider}`
+  }
+
+  const handleRedirect = async () => {
+    debugger
+    const authType = route.query.authType
+    if (authType && authType == 'oauth2') {
+      const sessionId = route.query.sessionId
+      if (sessionId) {
+        cookies.set('sessionId', String(sessionId), { path: '/' })
+        const userInfoRes: UserInfoRes = await getUserInfo()
+        await userStore.setUserInfo(userInfoRes)
+        const timezone = userInfoRes.timeZone ? userInfoRes.timeZone : 'UTC'
+        await timezoneStore.setTimezone(timezone)
+        router.push('home')
+      }
+      const error = route.query.error
+      if (error) {
+        window.$message.error(error)
+      }
+","[{'comment': 'Please delete enter.', 'commenter': 'songjianet'}]"
14743,dolphinscheduler-ui/src/views/login/use-login.ts,"@@ -63,7 +65,49 @@ export function useLogin(state: any) {
     })
   }
 
+
+
+  const handleGetOAuth2Provider = () => {
+    getOauth2Provider().then((res: Array<OAuth2Provider> | []) => {
+      oauth2Providers.value = res
+    })
+  }
+
+  const oauth2Providers = ref<Array<OAuth2Provider> | []>([])
+
+  const gotoOAuth2Page = async (oauth2Provider: OAuth2Provider) => {
+    await clearCookie()
+    window.location.href = `${oauth2Provider.authorizationUri}?client_id=${oauth2Provider.clientId}` +
+      `&redirect_uri=${oauth2Provider.redirectUri}?provider=${oauth2Provider.provider}`
+  }
+
+  const handleRedirect = async () => {
+    debugger
+    const authType = route.query.authType
+    if (authType && authType == 'oauth2') {
+      const sessionId = route.query.sessionId
+      if (sessionId) {
+        cookies.set('sessionId', String(sessionId), { path: '/' })
+        const userInfoRes: UserInfoRes = await getUserInfo()
+        await userStore.setUserInfo(userInfoRes)
+        const timezone = userInfoRes.timeZone ? userInfoRes.timeZone : 'UTC'
+        await timezoneStore.setTimezone(timezone)
+        router.push('home')
+      }
+      const error = route.query.error
+      if (error) {
+        window.$message.error(error)
+      }
+
+    }
+","[{'comment': 'Please delete enter.', 'commenter': 'songjianet'}]"
14743,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/controller/LoginController.java,"@@ -160,4 +180,77 @@ public Result signOut(@Parameter(hidden = true) @RequestAttribute(value = Consta
         request.removeAttribute(Constants.SESSION_USER);
         return success();
     }
+
+    @DeleteMapping(""cookies"")
+    public void clearCookieSessionId(HttpServletRequest request, HttpServletResponse response) {
+        Cookie[] cookies = request.getCookies();
+        for (Cookie cookie : cookies) {
+            cookie.setMaxAge(0);","[{'comment': 'Just for double check, do we need to set the cookie path here? ', 'commenter': 'EricGao888'}, {'comment': 'Yes, now with OAuth2 authorization, the back end will create the user using the user information and return the sessionId.  However, if a user tries to login as a local user before login with OAuth2, two Sessionids will be generated in the cookie, and the Sessionids generated after OAuth2 authorization cannot overwrite the sessionIds generated, resulting in an authorization failure.To sum up, before jumping to the OAuth2 authorization page, we need to clear the current cookie.', 'commenter': 'hdygxsj'}]"
14743,dolphinscheduler-ui/src/locales/en_US/login.ts,"@@ -22,5 +22,6 @@ export default {
   userPassword: 'Password',
   userPassword_tips: 'Please enter your password',
   login: 'Login',
+  otherwayLogin: 'login by otherways',","[{'comment': 'What about giving the tips as `OAuth2.0`? It may be more intuitive to users.', 'commenter': 'EricGao888'}]"
14743,docs/docs/en/guide/security/authentication-type.md,"@@ -1,6 +1,6 @@
 # Authentication Type
 
-* So far we support three authentication types, Apache DolphinScheduler password, LDAP and Casdoor SSO.
+* So far we support three authentication types, Apache DolphinScheduler password, LDAP,Casdoor SSO and OAuth2，the OAuth2 authorization login mode can be used with other authentication modes.","[{'comment': '```suggestion\r\n* So far we support three authentication types, Apache DolphinScheduler password, LDAP, Casdoor SSO and OAuth2，the OAuth2 authorization login mode can be used with other authentication modes.\r\n```', 'commenter': 'qingwli'}, {'comment': 'done', 'commenter': 'hdygxsj'}]"
14743,docs/docs/zh/guide/security/authentication-type.md,"@@ -1,6 +1,6 @@
 # 认证方式
 
-* 目前我们支持三种认证方式，Apache DolphinScheduler自身账号密码登录，LDAP和通过Casdoor实现的SSO登录。
+* 目前我们支持三种认证方式，Apache DolphinScheduler自身账号密码登录，LDAP,通过Casdoor实现的SSO登录和通过Oauth2授权登录，并且oauth2授权登录方式可以和其他认证方式同时使用。","[{'comment': '```suggestion\r\n* 目前我们支持三种认证方式，Apache DolphinScheduler自身账号密码登录，LDAP, 通过Casdoor实现的SSO登录和通过Oauth2授权登录，并且Oauth2授权登录方式可以和其他认证方式同时使用。\r\n```', 'commenter': 'qingwli'}]"
14750,dolphinscheduler-service/src/main/java/org/apache/dolphinscheduler/service/utils/DagHelper.java,"@@ -340,14 +340,18 @@ public static Set<Long> parsePostNodes(Long preNodeCode,
      * if all of the task dependence are skipped, skip it too.
      */
     private static boolean isTaskNodeNeedSkip(TaskNode taskNode,
-                                              Map<Long, TaskNode> skipTaskNodeList) {
+                                              Map<Long, TaskNode> skipTaskNodeList,
+                                              Map<Long, TaskInstance> completeTaskList) {
         if (CollectionUtils.isEmpty(taskNode.getDepList())) {
             return false;
         }
         for (Long depNode : taskNode.getDepList()) {
             if (!skipTaskNodeList.containsKey(depNode)) {
                 return false;
             }
+            if (completeTaskList.containsKey(depNode)) {","[{'comment': 'hi @LiuShuangBJ 1.在s1 之前加一个 s0 ，再次运行不符合预期\r\n2.s1如果依赖一个延迟任务，当从s2 分支执行到s1 时，延时任务还未执行，不包含在compeleteTask 中，导致s1 也会跳过', 'commenter': 'fuchanghai'}, {'comment': 'yes ,and this problem had been closed by #14537, i will close this pr', 'commenter': 'LiuShuangBJ'}]"
14801,dolphinscheduler-dao/src/main/resources/org/apache/dolphinscheduler/dao/mapper/ProcessTaskRelationMapper.xml,"@@ -240,4 +241,18 @@
         from t_ds_process_task_relation
         where process_definition_code = #{workflowDefinitionCode} and process_definition_version = #{workflowDefinitionVersion}
     </delete>
+
+    <select id=""queryProcessTaskRelationByTaskCode"" resultType=""org.apache.dolphinscheduler.dao.entity.ProcessTaskRelation"">
+        select
+        <include refid=""baseSql""/>
+        from t_ds_process_task_relation
+        WHERE process_definition_code in (
+                                            SELECT
+                                            process_definition_code
+                                            FROM
+                                            t_ds_process_task_relation
+                                            WHERE
+                                            post_task_code = #{taskCode}","[{'comment': 'The relationship between task and process can be one-to-many.', 'commenter': 'SbloodyS'}, {'comment': 'BTW, `post_task_code` is not unique, `post_task_code` and `post_task_version` is unique.', 'commenter': 'SbloodyS'}, {'comment': 'The modification has been completed', 'commenter': 'sdhzwc'}]"
14801,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskDefinitionServiceImpl.java,"@@ -781,21 +786,53 @@ private TaskDefinitionLog updateTask(User loginUser, long projectCode, long task
                     projectCode, taskCode, taskDefinitionToUpdate.getVersion());
         // update process task relation
         List<ProcessTaskRelation> processTaskRelations = processTaskRelationMapper
-                .queryByTaskCode(taskDefinitionToUpdate.getCode());
+                .queryProcessTaskRelationByTaskCode(taskDefinitionToUpdate.getCode());
         if (CollectionUtils.isNotEmpty(processTaskRelations)) {
+            ProcessTaskRelation taskRelation = processTaskRelations.get(0);
+            int processDefinitionVersion =
+                    processDefinitionLogMapper.queryMaxVersionForDefinition(taskRelation.getProcessDefinitionCode())
+                            + 1;
+            long processDefinitionCode = taskRelation.getProcessDefinitionCode();
             for (ProcessTaskRelation processTaskRelation : processTaskRelations) {
                 if (taskCode == processTaskRelation.getPreTaskCode()) {
                     processTaskRelation.setPreTaskVersion(version);
                 } else if (taskCode == processTaskRelation.getPostTaskCode()) {
                     processTaskRelation.setPostTaskVersion(version);
                 }
-                int count = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);
-                if (count != 1) {
+                processTaskRelation.setProcessDefinitionVersion(processDefinitionVersion);
+                int update_2 = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);","[{'comment': '```suggestion\r\n                int updateProcessDefinitionVersionCount = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);\r\n```', 'commenter': 'SbloodyS'}, {'comment': 'The modification has been completed', 'commenter': 'sdhzwc'}]"
14801,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskDefinitionServiceImpl.java,"@@ -781,21 +786,53 @@ private TaskDefinitionLog updateTask(User loginUser, long projectCode, long task
                     projectCode, taskCode, taskDefinitionToUpdate.getVersion());
         // update process task relation
         List<ProcessTaskRelation> processTaskRelations = processTaskRelationMapper
-                .queryByTaskCode(taskDefinitionToUpdate.getCode());
+                .queryProcessTaskRelationByTaskCode(taskDefinitionToUpdate.getCode());
         if (CollectionUtils.isNotEmpty(processTaskRelations)) {
+            ProcessTaskRelation taskRelation = processTaskRelations.get(0);
+            int processDefinitionVersion =
+                    processDefinitionLogMapper.queryMaxVersionForDefinition(taskRelation.getProcessDefinitionCode())
+                            + 1;
+            long processDefinitionCode = taskRelation.getProcessDefinitionCode();
             for (ProcessTaskRelation processTaskRelation : processTaskRelations) {
                 if (taskCode == processTaskRelation.getPreTaskCode()) {
                     processTaskRelation.setPreTaskVersion(version);
                 } else if (taskCode == processTaskRelation.getPostTaskCode()) {
                     processTaskRelation.setPostTaskVersion(version);
                 }
-                int count = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);
-                if (count != 1) {
+                processTaskRelation.setProcessDefinitionVersion(processDefinitionVersion);
+                int update_2 = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);
+                if (update_2 != 1) {
                     log.error(""batch update process task relation error, projectCode:{}, taskDefinitionCode:{}."",
                             projectCode, taskCode);
                     putMsg(result, Status.PROCESS_TASK_RELATION_BATCH_UPDATE_ERROR);
                     throw new ServiceException(Status.PROCESS_TASK_RELATION_BATCH_UPDATE_ERROR);
                 }
+                ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog(processTaskRelation);
+                processTaskRelationLog.setOperator(loginUser.getId());
+                processTaskRelationLog.setId(null);
+                processTaskRelationLog.setOperateTime(now);
+                int insert_2 = processTaskRelationLogDao.insert(processTaskRelationLog);
+                if (insert_2 != 1) {
+                    log.error(""batch update process task relation error, projectCode:{}, taskDefinitionCode:{}."",
+                            projectCode, taskCode);
+                    putMsg(result, Status.CREATE_PROCESS_TASK_RELATION_LOG_ERROR);
+                    throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_LOG_ERROR);
+                }
+            }
+            ProcessDefinition processDefinition = processDefinitionMapper.queryByCode(processDefinitionCode);
+            processDefinition.setVersion(processDefinitionVersion);
+            processDefinition.setUpdateTime(now);
+            processDefinition.setUserId(loginUser.getId());
+            // update process definition
+            int update_3 = processDefinitionMapper.updateById(processDefinition);","[{'comment': '```suggestion\r\n            int updateProcessDefinitionCount = processDefinitionMapper.updateById(processDefinition);\r\n```', 'commenter': 'SbloodyS'}, {'comment': 'The modification has been completed', 'commenter': 'sdhzwc'}]"
14801,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/TaskDefinitionServiceImpl.java,"@@ -781,21 +786,53 @@ private TaskDefinitionLog updateTask(User loginUser, long projectCode, long task
                     projectCode, taskCode, taskDefinitionToUpdate.getVersion());
         // update process task relation
         List<ProcessTaskRelation> processTaskRelations = processTaskRelationMapper
-                .queryByTaskCode(taskDefinitionToUpdate.getCode());
+                .queryProcessTaskRelationByTaskCode(taskDefinitionToUpdate.getCode());
         if (CollectionUtils.isNotEmpty(processTaskRelations)) {
+            ProcessTaskRelation taskRelation = processTaskRelations.get(0);
+            int processDefinitionVersion =
+                    processDefinitionLogMapper.queryMaxVersionForDefinition(taskRelation.getProcessDefinitionCode())
+                            + 1;
+            long processDefinitionCode = taskRelation.getProcessDefinitionCode();
             for (ProcessTaskRelation processTaskRelation : processTaskRelations) {
                 if (taskCode == processTaskRelation.getPreTaskCode()) {
                     processTaskRelation.setPreTaskVersion(version);
                 } else if (taskCode == processTaskRelation.getPostTaskCode()) {
                     processTaskRelation.setPostTaskVersion(version);
                 }
-                int count = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);
-                if (count != 1) {
+                processTaskRelation.setProcessDefinitionVersion(processDefinitionVersion);
+                int update_2 = processTaskRelationMapper.updateProcessTaskRelationTaskVersion(processTaskRelation);
+                if (update_2 != 1) {
                     log.error(""batch update process task relation error, projectCode:{}, taskDefinitionCode:{}."",
                             projectCode, taskCode);
                     putMsg(result, Status.PROCESS_TASK_RELATION_BATCH_UPDATE_ERROR);
                     throw new ServiceException(Status.PROCESS_TASK_RELATION_BATCH_UPDATE_ERROR);
                 }
+                ProcessTaskRelationLog processTaskRelationLog = new ProcessTaskRelationLog(processTaskRelation);
+                processTaskRelationLog.setOperator(loginUser.getId());
+                processTaskRelationLog.setId(null);
+                processTaskRelationLog.setOperateTime(now);
+                int insert_2 = processTaskRelationLogDao.insert(processTaskRelationLog);
+                if (insert_2 != 1) {
+                    log.error(""batch update process task relation error, projectCode:{}, taskDefinitionCode:{}."",
+                            projectCode, taskCode);
+                    putMsg(result, Status.CREATE_PROCESS_TASK_RELATION_LOG_ERROR);
+                    throw new ServiceException(Status.CREATE_PROCESS_TASK_RELATION_LOG_ERROR);
+                }
+            }
+            ProcessDefinition processDefinition = processDefinitionMapper.queryByCode(processDefinitionCode);
+            processDefinition.setVersion(processDefinitionVersion);
+            processDefinition.setUpdateTime(now);
+            processDefinition.setUserId(loginUser.getId());
+            // update process definition
+            int update_3 = processDefinitionMapper.updateById(processDefinition);
+            ProcessDefinitionLog processDefinitionLog = new ProcessDefinitionLog(processDefinition);
+            processDefinitionLog.setOperateTime(now);
+            processDefinitionLog.setId(null);
+            processDefinitionLog.setOperator(loginUser.getId());
+            int insert_3 = processDefinitionLogMapper.insert(processDefinitionLog);","[{'comment': '```suggestion\r\n            int insertProcessDefinitionLogCount = processDefinitionLogMapper.insert(processDefinitionLog);\r\n```', 'commenter': 'SbloodyS'}, {'comment': 'The modification has been completed', 'commenter': 'sdhzwc'}]"
14833,dolphinscheduler-master/src/main/resources/application.yaml,"@@ -83,6 +83,9 @@ registry:
     block-until-connected: 600ms
     digest: ~
 
+listener:","[{'comment': 'This config will make confusion.', 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-listener/dolphinscheduler-listener-service/src/main/java/org/apache/dolphinscheduler/listener/service/jdbc/mapper/ListenerEventMapper.java,"@@ -0,0 +1,46 @@
+/*
+ *
+ *  * Licensed to Apache Software Foundation (ASF) under one or more contributor
+ *  * license agreements. See the NOTICE file distributed with
+ *  * this work for additional information regarding copyright
+ *  * ownership. Apache Software Foundation (ASF) licenses this file to you under
+ *  * the Apache License, Version 2.0 (the ""License""); you may
+ *  * not use this file except in compliance with the License.
+ *  * You may obtain a copy of the License at
+ *  *
+ *  *     http://www.apache.org/licenses/LICENSE-2.0
+ *  *
+ *  * Unless required by applicable law or agreed to in writing,
+ *  * software distributed under the License is distributed on an
+ *  * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  * KIND, either express or implied.  See the License for the
+ *  * specific language governing permissions and limitations
+ *  * under the License.
+ *
+ *
+ */
+
+package org.apache.dolphinscheduler.listener.service.jdbc.mapper;
+
+import org.apache.dolphinscheduler.listener.service.jdbc.JdbcListenerEvent;
+
+import org.apache.ibatis.annotations.Insert;
+import org.apache.ibatis.annotations.Param;
+
+import java.util.List;
+
+import com.baomidou.mybatisplus.core.mapper.BaseMapper;
+
+public interface ListenerEventMapper extends BaseMapper<JdbcListenerEvent> {
+
+    @Insert({""<script>"",
+            ""        insert into t_ds_listener_event ( content, post_status, event_type, log, plugin_instance_id, create_time, update_time)"",
+            ""        values"",
+            ""        <foreach collection='jdbcListenerEvents' item='jdbcListenerEvent' separator=','>"",
+            ""            (#{jdbcListenerEvent.content},#{jdbcListenerEvent.postStatus},"" +
+                    ""            #{jdbcListenerEvent.eventType},#{jdbcListenerEvent.log},#{jdbcListenerEvent.pluginInstanceId}, #{jdbcListenerEvent.createTime}, #{jdbcListenerEvent.updateTime})""
+                    +
+                    ""        </foreach>"",
+            ""</script>""})","[{'comment': ""Please don't use `@Annotation` and xml at the same time."", 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-listener/dolphinscheduler-listener-plugin/dolphinscheduler-listener-kafka/src/main/java/org/apache/dolphinscheduler/listener/KafkaListener.java,"@@ -0,0 +1,214 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.listener;
+
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.listener.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.plugin.ListenerPlugin;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.params.base.Validate;
+import org.apache.dolphinscheduler.spi.params.input.InputParam;
+
+import org.apache.commons.lang3.StringUtils;
+import org.apache.kafka.clients.producer.KafkaProducer;
+import org.apache.kafka.clients.producer.ProducerConfig;
+import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.kafka.common.serialization.StringSerializer;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class KafkaListener implements ListenerPlugin {
+
+    private final Map<String, KafkaProducer<String, String>> kafkaProducers = new HashMap<>();
+
+    @Override
+    public String name() {
+        return ""KafkaListener"";
+    }
+
+    @Override
+    public List<PluginParams> params() {
+        List<PluginParams> paramsList = new ArrayList<>();
+        InputParam hostParam = InputParam.newBuilder(""servers"", ""bootstrap.servers"")
+                .setPlaceholder(""please input servers"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        InputParam topicParam = InputParam.newBuilder(""topic"", ""topic"")
+                .setPlaceholder(""please input topic"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        InputParam usernameParam = InputParam.newBuilder(""username"", ""username"")
+                .setPlaceholder(""please input username"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(false)
+                        .build())
+                .build();
+        InputParam passwordParam = InputParam.newBuilder(""password"", ""password"")
+                .setPlaceholder(""please input password"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(false)
+                        .build())
+                .build();
+        paramsList.add(hostParam);
+        paramsList.add(topicParam);
+        paramsList.add(usernameParam);
+        paramsList.add(passwordParam);
+        return paramsList;
+    }
+
+    @Override
+    public void onServerDown(ServerDownListenerEvent serverDownListenerEvent) {
+        sendEvent(serverDownListenerEvent.getListenerInstanceParams(), ServerDownListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(serverDownListenerEvent));
+    }
+
+    @Override
+    public void onWorkflowAdded(WorkflowCreateListenerEvent workflowCreateEvent) {
+        sendEvent(workflowCreateEvent.getListenerInstanceParams(), WorkflowCreateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowCreateEvent));
+    }
+
+    @Override
+    public void onWorkflowUpdate(WorkflowUpdateListenerEvent workflowUpdateEvent) {
+        sendEvent(workflowUpdateEvent.getListenerInstanceParams(), WorkflowUpdateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowUpdateEvent));
+    }
+
+    @Override
+    public void onWorkflowRemoved(WorkflowRemoveListenerEvent workflowRemovedEvent) {
+        sendEvent(workflowRemovedEvent.getListenerInstanceParams(), WorkflowRemoveListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowRemovedEvent));
+    }
+
+    @Override
+    public void onWorkflowStart(WorkflowStartListenerEvent workflowStartEvent) {
+        sendEvent(workflowStartEvent.getListenerInstanceParams(), WorkflowStartListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowStartEvent));
+
+    }
+
+    @Override
+    public void onWorkflowEnd(WorkflowEndListenerEvent workflowEndEvent) {
+        sendEvent(workflowEndEvent.getListenerInstanceParams(), WorkflowEndListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowEndEvent));
+    }
+
+    @Override
+    public void onWorkflowFail(WorkflowFailListenerEvent workflowErrorEvent) {
+        sendEvent(workflowErrorEvent.getListenerInstanceParams(), WorkflowFailListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowErrorEvent));
+    }
+
+    @Override
+    public void onTaskAdded(TaskCreateListenerEvent taskAddedEvent) {
+        sendEvent(taskAddedEvent.getListenerInstanceParams(), TaskCreateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskAddedEvent));
+    }
+
+    @Override
+    public void onTaskUpdate(TaskUpdateListenerEvent taskUpdateEvent) {
+        sendEvent(taskUpdateEvent.getListenerInstanceParams(), TaskUpdateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskUpdateEvent));
+    }
+
+    @Override
+    public void onTaskRemoved(TaskRemoveListenerEvent taskRemovedEvent) {
+        sendEvent(taskRemovedEvent.getListenerInstanceParams(), TaskRemoveListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskRemovedEvent));
+    }
+
+    @Override
+    public void onTaskStart(TaskStartListenerEvent taskStartEvent) {
+        sendEvent(taskStartEvent.getListenerInstanceParams(), TaskStartListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskStartEvent));
+    }
+
+    @Override
+    public void onTaskEnd(TaskEndListenerEvent taskEndEvent) {
+        sendEvent(taskEndEvent.getListenerInstanceParams(), TaskEndListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskEndEvent));
+    }
+
+    @Override
+    public void onTaskFail(TaskFailListenerEvent taskErrorEvent) {
+        sendEvent(taskErrorEvent.getListenerInstanceParams(), TaskFailListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskErrorEvent));
+    }
+
+    private void sendEvent(Map<String, String> listenerInstanceParams, String key, String value) {
+        String uniqueId = uniqueId(listenerInstanceParams);
+        if (!kafkaProducers.containsKey(uniqueId)) {
+            String kafkaBroker = listenerInstanceParams.get(""servers"");
+            String username = listenerInstanceParams.get(""username"");
+            String password = listenerInstanceParams.get(""password"");
+            Map<String, Object> configurations = new HashMap<>();
+            // TODO: when use username/password, throws exception: Unable to find LoginModule class:
+            // org.apache.kafka.common.security.plain.PlainLoginModule
+            configurations.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBroker);
+            configurations.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
+            configurations.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
+            if (StringUtils.isNotEmpty(username) && StringUtils.isNotEmpty(password)) {
+                configurations.put(""sasl.jaas.config"", String.format(
+                        ""org.apache.kafka.common.security.plain.PlainLoginModule required username='%s' password='%s';"",
+                        username, password));
+                configurations.put(""security.protocol"", ""SASL_PLAINTEXT"");
+                configurations.put(""sasl.mechanism"", ""PLAIN"");
+            }
+            KafkaProducer<String, String> producer = new KafkaProducer<>(configurations);
+            kafkaProducers.put(uniqueId, producer);
+
+        }
+        KafkaProducer<String, String> producer = kafkaProducers.get(uniqueId);
+        String topic = listenerInstanceParams.get(""topic"");
+        producer.send(new ProducerRecord<>(topic, key, value), (recordMetadata, e) -> {
+            if (e != null) {
+                throw new RuntimeException(e);
+            }
+        });
+    }
+
+    private String uniqueId(Map<String, String> listenerInstanceParams) {
+        String kafkaBroker = listenerInstanceParams.get(""servers"");
+        String topic = listenerInstanceParams.get(""topic"");
+        String username = listenerInstanceParams.getOrDefault(""username"", ""foo"");
+        String password = listenerInstanceParams.getOrDefault(""password"", ""foo"");","[{'comment': ""We don't need to add default username and password."", 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-listener/dolphinscheduler-listener-plugin/dolphinscheduler-listener-kafka/src/main/java/org/apache/dolphinscheduler/listener/KafkaListener.java,"@@ -0,0 +1,214 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.listener;
+
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.listener.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.plugin.ListenerPlugin;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.params.base.Validate;
+import org.apache.dolphinscheduler.spi.params.input.InputParam;
+
+import org.apache.commons.lang3.StringUtils;
+import org.apache.kafka.clients.producer.KafkaProducer;
+import org.apache.kafka.clients.producer.ProducerConfig;
+import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.kafka.common.serialization.StringSerializer;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class KafkaListener implements ListenerPlugin {
+
+    private final Map<String, KafkaProducer<String, String>> kafkaProducers = new HashMap<>();
+
+    @Override
+    public String name() {
+        return ""KafkaListener"";
+    }
+
+    @Override
+    public List<PluginParams> params() {
+        List<PluginParams> paramsList = new ArrayList<>();
+        InputParam hostParam = InputParam.newBuilder(""servers"", ""bootstrap.servers"")
+                .setPlaceholder(""please input servers"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        InputParam topicParam = InputParam.newBuilder(""topic"", ""topic"")
+                .setPlaceholder(""please input topic"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        InputParam usernameParam = InputParam.newBuilder(""username"", ""username"")
+                .setPlaceholder(""please input username"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(false)
+                        .build())
+                .build();
+        InputParam passwordParam = InputParam.newBuilder(""password"", ""password"")
+                .setPlaceholder(""please input password"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(false)
+                        .build())
+                .build();
+        paramsList.add(hostParam);
+        paramsList.add(topicParam);
+        paramsList.add(usernameParam);
+        paramsList.add(passwordParam);
+        return paramsList;
+    }
+
+    @Override
+    public void onServerDown(ServerDownListenerEvent serverDownListenerEvent) {
+        sendEvent(serverDownListenerEvent.getListenerInstanceParams(), ServerDownListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(serverDownListenerEvent));
+    }
+
+    @Override
+    public void onWorkflowAdded(WorkflowCreateListenerEvent workflowCreateEvent) {
+        sendEvent(workflowCreateEvent.getListenerInstanceParams(), WorkflowCreateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowCreateEvent));
+    }
+
+    @Override
+    public void onWorkflowUpdate(WorkflowUpdateListenerEvent workflowUpdateEvent) {
+        sendEvent(workflowUpdateEvent.getListenerInstanceParams(), WorkflowUpdateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowUpdateEvent));
+    }
+
+    @Override
+    public void onWorkflowRemoved(WorkflowRemoveListenerEvent workflowRemovedEvent) {
+        sendEvent(workflowRemovedEvent.getListenerInstanceParams(), WorkflowRemoveListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowRemovedEvent));
+    }
+
+    @Override
+    public void onWorkflowStart(WorkflowStartListenerEvent workflowStartEvent) {
+        sendEvent(workflowStartEvent.getListenerInstanceParams(), WorkflowStartListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowStartEvent));
+
+    }
+
+    @Override
+    public void onWorkflowEnd(WorkflowEndListenerEvent workflowEndEvent) {
+        sendEvent(workflowEndEvent.getListenerInstanceParams(), WorkflowEndListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowEndEvent));
+    }
+
+    @Override
+    public void onWorkflowFail(WorkflowFailListenerEvent workflowErrorEvent) {
+        sendEvent(workflowErrorEvent.getListenerInstanceParams(), WorkflowFailListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowErrorEvent));
+    }
+
+    @Override
+    public void onTaskAdded(TaskCreateListenerEvent taskAddedEvent) {
+        sendEvent(taskAddedEvent.getListenerInstanceParams(), TaskCreateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskAddedEvent));
+    }
+
+    @Override
+    public void onTaskUpdate(TaskUpdateListenerEvent taskUpdateEvent) {
+        sendEvent(taskUpdateEvent.getListenerInstanceParams(), TaskUpdateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskUpdateEvent));
+    }
+
+    @Override
+    public void onTaskRemoved(TaskRemoveListenerEvent taskRemovedEvent) {
+        sendEvent(taskRemovedEvent.getListenerInstanceParams(), TaskRemoveListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskRemovedEvent));
+    }
+
+    @Override
+    public void onTaskStart(TaskStartListenerEvent taskStartEvent) {
+        sendEvent(taskStartEvent.getListenerInstanceParams(), TaskStartListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskStartEvent));
+    }
+
+    @Override
+    public void onTaskEnd(TaskEndListenerEvent taskEndEvent) {
+        sendEvent(taskEndEvent.getListenerInstanceParams(), TaskEndListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskEndEvent));
+    }
+
+    @Override
+    public void onTaskFail(TaskFailListenerEvent taskErrorEvent) {
+        sendEvent(taskErrorEvent.getListenerInstanceParams(), TaskFailListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskErrorEvent));
+    }
+
+    private void sendEvent(Map<String, String> listenerInstanceParams, String key, String value) {
+        String uniqueId = uniqueId(listenerInstanceParams);
+        if (!kafkaProducers.containsKey(uniqueId)) {
+            String kafkaBroker = listenerInstanceParams.get(""servers"");
+            String username = listenerInstanceParams.get(""username"");
+            String password = listenerInstanceParams.get(""password"");
+            Map<String, Object> configurations = new HashMap<>();
+            // TODO: when use username/password, throws exception: Unable to find LoginModule class:
+            // org.apache.kafka.common.security.plain.PlainLoginModule
+            configurations.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBroker);
+            configurations.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
+            configurations.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
+            if (StringUtils.isNotEmpty(username) && StringUtils.isNotEmpty(password)) {
+                configurations.put(""sasl.jaas.config"", String.format(
+                        ""org.apache.kafka.common.security.plain.PlainLoginModule required username='%s' password='%s';"",
+                        username, password));
+                configurations.put(""security.protocol"", ""SASL_PLAINTEXT"");
+                configurations.put(""sasl.mechanism"", ""PLAIN"");","[{'comment': ""Why don't expose this config,"", 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-listener/dolphinscheduler-listener-plugin/dolphinscheduler-listener-kafka/src/main/java/org/apache/dolphinscheduler/listener/KafkaListener.java,"@@ -0,0 +1,214 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.listener;
+
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.listener.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.plugin.ListenerPlugin;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.params.base.Validate;
+import org.apache.dolphinscheduler.spi.params.input.InputParam;
+
+import org.apache.commons.lang3.StringUtils;
+import org.apache.kafka.clients.producer.KafkaProducer;
+import org.apache.kafka.clients.producer.ProducerConfig;
+import org.apache.kafka.clients.producer.ProducerRecord;
+import org.apache.kafka.common.serialization.StringSerializer;
+
+import java.util.ArrayList;
+import java.util.HashMap;
+import java.util.List;
+import java.util.Map;
+
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class KafkaListener implements ListenerPlugin {
+
+    private final Map<String, KafkaProducer<String, String>> kafkaProducers = new HashMap<>();
+
+    @Override
+    public String name() {
+        return ""KafkaListener"";
+    }
+
+    @Override
+    public List<PluginParams> params() {
+        List<PluginParams> paramsList = new ArrayList<>();
+        InputParam hostParam = InputParam.newBuilder(""servers"", ""bootstrap.servers"")
+                .setPlaceholder(""please input servers"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        InputParam topicParam = InputParam.newBuilder(""topic"", ""topic"")
+                .setPlaceholder(""please input topic"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        InputParam usernameParam = InputParam.newBuilder(""username"", ""username"")
+                .setPlaceholder(""please input username"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(false)
+                        .build())
+                .build();
+        InputParam passwordParam = InputParam.newBuilder(""password"", ""password"")
+                .setPlaceholder(""please input password"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(false)
+                        .build())
+                .build();
+        paramsList.add(hostParam);
+        paramsList.add(topicParam);
+        paramsList.add(usernameParam);
+        paramsList.add(passwordParam);
+        return paramsList;
+    }
+
+    @Override
+    public void onServerDown(ServerDownListenerEvent serverDownListenerEvent) {
+        sendEvent(serverDownListenerEvent.getListenerInstanceParams(), ServerDownListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(serverDownListenerEvent));
+    }
+
+    @Override
+    public void onWorkflowAdded(WorkflowCreateListenerEvent workflowCreateEvent) {
+        sendEvent(workflowCreateEvent.getListenerInstanceParams(), WorkflowCreateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowCreateEvent));
+    }
+
+    @Override
+    public void onWorkflowUpdate(WorkflowUpdateListenerEvent workflowUpdateEvent) {
+        sendEvent(workflowUpdateEvent.getListenerInstanceParams(), WorkflowUpdateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowUpdateEvent));
+    }
+
+    @Override
+    public void onWorkflowRemoved(WorkflowRemoveListenerEvent workflowRemovedEvent) {
+        sendEvent(workflowRemovedEvent.getListenerInstanceParams(), WorkflowRemoveListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowRemovedEvent));
+    }
+
+    @Override
+    public void onWorkflowStart(WorkflowStartListenerEvent workflowStartEvent) {
+        sendEvent(workflowStartEvent.getListenerInstanceParams(), WorkflowStartListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowStartEvent));
+
+    }
+
+    @Override
+    public void onWorkflowEnd(WorkflowEndListenerEvent workflowEndEvent) {
+        sendEvent(workflowEndEvent.getListenerInstanceParams(), WorkflowEndListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowEndEvent));
+    }
+
+    @Override
+    public void onWorkflowFail(WorkflowFailListenerEvent workflowErrorEvent) {
+        sendEvent(workflowErrorEvent.getListenerInstanceParams(), WorkflowFailListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(workflowErrorEvent));
+    }
+
+    @Override
+    public void onTaskAdded(TaskCreateListenerEvent taskAddedEvent) {
+        sendEvent(taskAddedEvent.getListenerInstanceParams(), TaskCreateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskAddedEvent));
+    }
+
+    @Override
+    public void onTaskUpdate(TaskUpdateListenerEvent taskUpdateEvent) {
+        sendEvent(taskUpdateEvent.getListenerInstanceParams(), TaskUpdateListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskUpdateEvent));
+    }
+
+    @Override
+    public void onTaskRemoved(TaskRemoveListenerEvent taskRemovedEvent) {
+        sendEvent(taskRemovedEvent.getListenerInstanceParams(), TaskRemoveListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskRemovedEvent));
+    }
+
+    @Override
+    public void onTaskStart(TaskStartListenerEvent taskStartEvent) {
+        sendEvent(taskStartEvent.getListenerInstanceParams(), TaskStartListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskStartEvent));
+    }
+
+    @Override
+    public void onTaskEnd(TaskEndListenerEvent taskEndEvent) {
+        sendEvent(taskEndEvent.getListenerInstanceParams(), TaskEndListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskEndEvent));
+    }
+
+    @Override
+    public void onTaskFail(TaskFailListenerEvent taskErrorEvent) {
+        sendEvent(taskErrorEvent.getListenerInstanceParams(), TaskFailListenerEvent.class.getSimpleName(),
+                JSONUtils.toJsonString(taskErrorEvent));
+    }
+
+    private void sendEvent(Map<String, String> listenerInstanceParams, String key, String value) {
+        String uniqueId = uniqueId(listenerInstanceParams);
+        if (!kafkaProducers.containsKey(uniqueId)) {
+            String kafkaBroker = listenerInstanceParams.get(""servers"");
+            String username = listenerInstanceParams.get(""username"");
+            String password = listenerInstanceParams.get(""password"");
+            Map<String, Object> configurations = new HashMap<>();
+            // TODO: when use username/password, throws exception: Unable to find LoginModule class:
+            // org.apache.kafka.common.security.plain.PlainLoginModule
+            configurations.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, kafkaBroker);
+            configurations.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
+            configurations.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
+            if (StringUtils.isNotEmpty(username) && StringUtils.isNotEmpty(password)) {
+                configurations.put(""sasl.jaas.config"", String.format(
+                        ""org.apache.kafka.common.security.plain.PlainLoginModule required username='%s' password='%s';"",
+                        username, password));
+                configurations.put(""security.protocol"", ""SASL_PLAINTEXT"");
+                configurations.put(""sasl.mechanism"", ""PLAIN"");
+            }
+            KafkaProducer<String, String> producer = new KafkaProducer<>(configurations);
+            kafkaProducers.put(uniqueId, producer);
+
+        }
+        KafkaProducer<String, String> producer = kafkaProducers.get(uniqueId);
+        String topic = listenerInstanceParams.get(""topic"");
+        producer.send(new ProducerRecord<>(topic, key, value), (recordMetadata, e) -> {","[{'comment': ""You said you need to `ensures that messages are neither lost nor unordered` but this is asyn send, how can you ensure the message doesn't lost."", 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-listener/dolphinscheduler-listener-plugin/dolphinscheduler-listener-logger/src/main/java/org/apache/dolphinscheduler/listener/LoggerListener.java,"@@ -0,0 +1,145 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.listener;
+
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.listener.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.plugin.ListenerPlugin;
+import org.apache.dolphinscheduler.spi.params.base.PluginParams;
+import org.apache.dolphinscheduler.spi.params.base.Validate;
+import org.apache.dolphinscheduler.spi.params.input.InputParam;
+
+import java.io.BufferedWriter;
+import java.io.FileWriter;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.Map;
+
+import lombok.extern.slf4j.Slf4j;
+
+@Slf4j
+public class LoggerListener implements ListenerPlugin {
+
+    @Override
+    public String name() {
+        return ""LoggerListener"";
+    }
+
+    @Override
+    public List<PluginParams> params() {
+        List<PluginParams> paramsList = new ArrayList<>();
+        InputParam param1 = InputParam.newBuilder(""logFile"", ""log_file"")
+                .setPlaceholder(""please input log file"")
+                .addValidate(Validate.newBuilder()
+                        .setRequired(true)
+                        .build())
+                .build();
+        paramsList.add(param1);
+        return paramsList;
+    }
+
+    @Override
+    public void onServerDown(ServerDownListenerEvent serverDownListenerEvent) {
+        printLogIntoFile(serverDownListenerEvent.getListenerInstanceParams(),
+                JSONUtils.toJsonString(serverDownListenerEvent));
+    }
+
+    @Override
+    public void onWorkflowAdded(WorkflowCreateListenerEvent workflowCreateEvent) {
+        printLogIntoFile(workflowCreateEvent.getListenerInstanceParams(), JSONUtils.toJsonString(workflowCreateEvent));
+    }
+
+    @Override
+    public void onWorkflowUpdate(WorkflowUpdateListenerEvent workflowUpdateEvent) {
+        printLogIntoFile(workflowUpdateEvent.getListenerInstanceParams(), JSONUtils.toJsonString(workflowUpdateEvent));
+    }
+
+    @Override
+    public void onWorkflowRemoved(WorkflowRemoveListenerEvent workflowRemovedEvent) {
+        printLogIntoFile(workflowRemovedEvent.getListenerInstanceParams(),
+                JSONUtils.toJsonString(workflowRemovedEvent));
+    }
+
+    @Override
+    public void onWorkflowStart(WorkflowStartListenerEvent workflowStartEvent) {
+        printLogIntoFile(workflowStartEvent.getListenerInstanceParams(), JSONUtils.toJsonString(workflowStartEvent));
+    }
+
+    @Override
+    public void onWorkflowEnd(WorkflowEndListenerEvent workflowEndEvent) {
+        printLogIntoFile(workflowEndEvent.getListenerInstanceParams(), JSONUtils.toJsonString(workflowEndEvent));
+    }
+
+    @Override
+    public void onWorkflowFail(WorkflowFailListenerEvent workflowErrorEvent) {
+        printLogIntoFile(workflowErrorEvent.getListenerInstanceParams(), JSONUtils.toJsonString(workflowErrorEvent));
+    }
+
+    @Override
+    public void onTaskAdded(TaskCreateListenerEvent taskAddedEvent) {
+        printLogIntoFile(taskAddedEvent.getListenerInstanceParams(), JSONUtils.toJsonString(taskAddedEvent));
+    }
+
+    @Override
+    public void onTaskUpdate(TaskUpdateListenerEvent taskUpdateEvent) {
+        printLogIntoFile(taskUpdateEvent.getListenerInstanceParams(), JSONUtils.toJsonString(taskUpdateEvent));
+    }
+
+    @Override
+    public void onTaskRemoved(TaskRemoveListenerEvent taskRemovedEvent) {
+        printLogIntoFile(taskRemovedEvent.getListenerInstanceParams(), JSONUtils.toJsonString(taskRemovedEvent));
+    }
+
+    @Override
+    public void onTaskStart(TaskStartListenerEvent taskStartEvent) {
+        printLogIntoFile(taskStartEvent.getListenerInstanceParams(), JSONUtils.toJsonString(taskStartEvent));
+    }
+
+    @Override
+    public void onTaskEnd(TaskEndListenerEvent taskEndEvent) {
+        printLogIntoFile(taskEndEvent.getListenerInstanceParams(), JSONUtils.toJsonString(taskEndEvent));
+    }
+
+    @Override
+    public void onTaskFail(TaskFailListenerEvent taskErrorEvent) {
+        printLogIntoFile(taskErrorEvent.getListenerInstanceParams(), JSONUtils.toJsonString(taskErrorEvent));
+    }
+
+    private void printLogIntoFile(Map<String, String> listenerInstanceParams, String content) {
+        String logFile = listenerInstanceParams.get(""logFile"");
+        try (BufferedWriter writer = new BufferedWriter(new FileWriter(logFile, true))) {
+            writer.write(content);
+            writer.newLine();
+        } catch (Exception e) {
+            throw new RuntimeException(e);
+        }","[{'comment': 'Have you test the performance? AFAIK, this is very slow.', 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-listener/dolphinscheduler-listener-service/src/main/java/org/apache/dolphinscheduler/listener/service/ListenerEventPublishService.java,"@@ -0,0 +1,273 @@
+/*
+ *
+ *  * Licensed to Apache Software Foundation (ASF) under one or more contributor
+ *  * license agreements. See the NOTICE file distributed with
+ *  * this work for additional information regarding copyright
+ *  * ownership. Apache Software Foundation (ASF) licenses this file to you under
+ *  * the Apache License, Version 2.0 (the ""License""); you may
+ *  * not use this file except in compliance with the License.
+ *  * You may obtain a copy of the License at
+ *  *
+ *  *     http://www.apache.org/licenses/LICENSE-2.0
+ *  *
+ *  * Unless required by applicable law or agreed to in writing,
+ *  * software distributed under the License is distributed on an
+ *  * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ *  * KIND, either express or implied.  See the License for the
+ *  * specific language governing permissions and limitations
+ *  * under the License.
+ *
+ *
+ */
+
+package org.apache.dolphinscheduler.listener.service;
+
+import org.apache.dolphinscheduler.dao.entity.ProcessDefinition;
+import org.apache.dolphinscheduler.dao.entity.ProcessInstance;
+import org.apache.dolphinscheduler.dao.entity.ProcessTaskRelationLog;
+import org.apache.dolphinscheduler.dao.entity.Project;
+import org.apache.dolphinscheduler.dao.entity.ProjectUser;
+import org.apache.dolphinscheduler.dao.entity.TaskDefinition;
+import org.apache.dolphinscheduler.dao.entity.TaskDefinitionLog;
+import org.apache.dolphinscheduler.dao.entity.TaskInstance;
+import org.apache.dolphinscheduler.listener.enums.ListenerEventType;
+import org.apache.dolphinscheduler.listener.event.ListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.TaskUpdateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowCreateListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowEndListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowFailListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowRemoveListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowStartListenerEvent;
+import org.apache.dolphinscheduler.listener.event.WorkflowUpdateListenerEvent;
+
+import java.util.Date;
+import java.util.List;
+import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.LinkedBlockingQueue;
+
+import javax.annotation.PostConstruct;
+
+import lombok.extern.slf4j.Slf4j;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Component;
+
+@Component
+@Slf4j
+public class ListenerEventPublishService {
+
+    private final BlockingQueue<ListenerEvent> listenerEventQueue = new LinkedBlockingQueue<>();
+
+    @Autowired
+    private ListenerEventProducer producer;
+
+    /**
+     * create a daemon thread to process the listener event queue
+     */
+    @PostConstruct
+    private void init() {
+        Thread thread = new Thread(this::doPublish);
+        thread.setDaemon(true);
+        thread.setName(""Listener-Event-Produce-Thread"");
+        thread.start();
+    }
+
+    public void publish(ListenerEvent listenerEvent) {
+        if (!listenerEventQueue.offer(listenerEvent)) {
+            log.error(""Publish listener event failed, message:{}"", listenerEvent);
+        }
+    }","[{'comment': 'If the downstream producer crash, this will cause master OOM, this is not reasonable, DolphinScheduler is use to schedule and trigger workflow, why `event` handle will affect its available?', 'commenter': 'ruanwenjun'}]"
14833,dolphinscheduler-ui/src/views/security/listener-instance-manage/detail.tsx,"@@ -0,0 +1,235 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import {
+  defineComponent,
+  toRefs,
+  watch,
+  onMounted,
+  ref,
+  getCurrentInstance
+} from 'vue'
+import { NSelect, NInput, NCheckboxGroup, NSpace, NCheckbox } from 'naive-ui'
+import { isFunction } from 'lodash'
+import { useI18n } from 'vue-i18n'
+import { useForm } from './use-form'
+import { useDetail } from './use-detail'
+import Modal from '@/components/modal'
+import Form from '@/components/form'
+import getElementByJson from '@/components/form/get-elements-by-json'
+import type { IRecord, IFormRules, IFormItem } from './types'
+import type { PropType, Ref } from 'vue'
+import { stateType } from '@/common/common'
+
+interface IElements extends Omit<Ref, 'value'> {
+  value: IFormItem[]
+}
+
+const props = {
+  show: {
+    type: Boolean as PropType<boolean>,
+    default: false
+  },
+  currentRecord: {
+    type: Object as PropType<IRecord>,
+    default: {}
+  }
+}
+const DetailModal = defineComponent({
+  name: 'DetailModal',
+  props,
+  emits: ['cancel', 'update'],
+  setup(props, ctx) {
+    const { t } = useI18n()
+
+    const rules = ref<IFormRules>({})
+    const elements = ref<IFormItem[]>([]) as IElements
+    const {
+      meta,
+      state,
+      eventTypes,
+      setDetail,
+      initForm,
+      resetForm,
+      getFormValues,
+      changePlugin
+    } = useForm()
+
+    const { status, createOrUpdate } = useDetail(getFormValues)
+
+    const onCancel = () => {
+      resetForm()
+      rules.value = {}
+      elements.value = []
+      ctx.emit('cancel')
+    }
+
+    const onSubmit = async () => {
+      await state.detailFormRef.validate()
+      const res = await createOrUpdate(props.currentRecord, state.json)
+      if (res) {
+        onCancel()
+        ctx.emit('update')
+      }","[{'comment': ""if (!res) return false\r\nonCancel()\r\nctx.emit('update')"", 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-instance-manage/detail.tsx,"@@ -0,0 +1,235 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import {
+  defineComponent,
+  toRefs,
+  watch,
+  onMounted,
+  ref,
+  getCurrentInstance
+} from 'vue'
+import { NSelect, NInput, NCheckboxGroup, NSpace, NCheckbox } from 'naive-ui'
+import { isFunction } from 'lodash'
+import { useI18n } from 'vue-i18n'
+import { useForm } from './use-form'
+import { useDetail } from './use-detail'
+import Modal from '@/components/modal'
+import Form from '@/components/form'
+import getElementByJson from '@/components/form/get-elements-by-json'
+import type { IRecord, IFormRules, IFormItem } from './types'
+import type { PropType, Ref } from 'vue'
+import { stateType } from '@/common/common'
+
+interface IElements extends Omit<Ref, 'value'> {
+  value: IFormItem[]
+}
+
+const props = {
+  show: {
+    type: Boolean as PropType<boolean>,
+    default: false
+  },
+  currentRecord: {
+    type: Object as PropType<IRecord>,
+    default: {}
+  }
+}
+const DetailModal = defineComponent({
+  name: 'DetailModal',
+  props,
+  emits: ['cancel', 'update'],
+  setup(props, ctx) {
+    const { t } = useI18n()
+
+    const rules = ref<IFormRules>({})
+    const elements = ref<IFormItem[]>([]) as IElements
+    const {
+      meta,
+      state,
+      eventTypes,
+      setDetail,
+      initForm,
+      resetForm,
+      getFormValues,
+      changePlugin
+    } = useForm()
+
+    const { status, createOrUpdate } = useDetail(getFormValues)
+
+    const onCancel = () => {
+      resetForm()
+      rules.value = {}
+      elements.value = []
+      ctx.emit('cancel')
+    }
+
+    const onSubmit = async () => {
+      await state.detailFormRef.validate()
+      const res = await createOrUpdate(props.currentRecord, state.json)
+      if (res) {
+        onCancel()
+        ctx.emit('update')
+      }
+    }
+    const onChangePlugin = changePlugin
+
+    const trim = getCurrentInstance()?.appContext.config.globalProperties.trim
+
+    watch(
+      () => props.show,
+      async () => {
+        props.show && props.currentRecord && setDetail(props.currentRecord)
+      }
+    )
+    watch(
+      () => state.json,
+      () => {
+        if (!state.json?.length) return
+        state.json.forEach((item) => {
+          const mergedItem = isFunction(item) ? item() : item
+          mergedItem.name = mergedItem.title
+        })
+        const { rules: fieldsRules, elements: fieldsElements } =
+          getElementByJson(state.json, state.detailForm)
+        rules.value = fieldsRules
+        elements.value = fieldsElements
+      }
+    )
+
+    onMounted(() => {
+      initForm()
+    })
+
+    return {
+      t,
+      ...toRefs(state),
+      ...toRefs(status),
+      meta,
+      rules,
+      elements,
+      eventTypes,
+      onChangePlugin,
+      onSubmit,
+      onCancel,
+      trim
+    }
+  },
+  render(props: { currentRecord: IRecord }) {
+    const {
+      show,
+      t,
+      meta,
+      rules,
+      elements,
+      detailForm,
+      uiPlugins,
+      eventTypes,
+      pluginsLoading,
+      loading,
+      saving,
+      onChangePlugin,
+      onCancel,
+      onSubmit
+    } = this
+    const { currentRecord } = props
+    return (
+      <Modal
+        show={show}
+        title={t(
+          currentRecord?.id
+            ? 'security.listener_instance.edit_listener_instance'
+            : 'security.listener_instance.create_listener_instance'
+        )}
+        onConfirm={onSubmit}
+        confirmLoading={saving || loading}
+        onCancel={onCancel}
+      >
+        {{
+          default: () => (
+            <Form
+              ref='detailFormRef'
+              loading={loading || pluginsLoading}
+              meta={{
+                ...meta,
+                rules: {
+                  ...meta.rules,
+                  ...rules
+                },
+                elements: [
+                  {
+                    path: 'instanceName',
+                    label: t('security.listener_instance.instance_name'),
+                    widget: (
+                      <NInput
+                        allowInput={this.trim}
+                        v-model={[detailForm.instanceName, 'value']}
+                        placeholder={t(
+                          'security.listener_instance.instance_name_tips'
+                        )}
+                      />
+                    )
+                  },
+                  {
+                    path: 'listenerEventTypes',
+                    label: t('security.listener_instance.listener_event_types'),
+                    widget: (
+                      <NCheckboxGroup 
+                        disabled={!this.trim}
+                        v-model={[detailForm.listenerEventTypes, 'value']}>
+                        <NSpace style=""display: flex;"">
+                          {
+                            Object.values(
+                              eventTypes
+                            ).map((item)=>{
+                              return <NCheckbox value={item.value} label={item.label} defaultChecked={true}/>
+                            })","[{'comment': '`map((item) => <NCheckbox value={item.value} label={item.label} defaultChecked={true} />)`', 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-instance-manage/use-form.ts,"@@ -0,0 +1,199 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { reactive, ref, Ref } from 'vue'
+import { useI18n } from 'vue-i18n'
+import {
+  queryUiPluginsByType,
+  queryUiPluginDetailById
+} from '@/service/modules/ui-plugins'
+import type {
+  IPluginId,
+  IPlugin,
+  IFormRules,
+  IMeta,
+  IJsonItem,
+  IRecord
+} from './types'
+export function useForm() {
+  const { t } = useI18n()
+
+  const eventTypes = {
+    SERVER_DOWN: {
+      value: ""SERVER_DOWN"",","[{'comment': 'Please use single quotes.', 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-instance-manage/use-table.ts,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { reactive } from 'vue'
+import {
+  queryListenerInstanceListPaging,
+  deleteListenerInstanceById
+} from '@/service/modules/listener-instance'
+import { format } from 'date-fns'
+import { parseTime } from '@/common/common'
+import type { IRecord } from './types'
+
+export function useTable() {
+  const data = reactive({
+    page: 1,
+    pageSize: 10,
+    itemCount: 0,
+    searchVal: '',
+    list: [],
+    loading: false
+  })
+
+  const getList = async () => {
+    if (data.loading) return
+    data.loading = true
+
+    const { totalList, total } = await queryListenerInstanceListPaging({
+      pageNo: data.page,
+      pageSize: data.pageSize,
+      searchVal: data.searchVal
+    })
+    data.loading = false
+    if (!totalList) throw Error()
+    data.list = totalList.map((record: IRecord) => {
+      record.createTime = record.createTime
+        ? format(parseTime(record.createTime), 'yyyy-MM-dd HH:mm:ss')
+        : ''","[{'comment': ""`record.createTime && record.createTime = format(parseTime(record.createTime), 'yyyy-MM-dd HH:mm:ss')`"", 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-instance-manage/use-table.ts,"@@ -0,0 +1,85 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { reactive } from 'vue'
+import {
+  queryListenerInstanceListPaging,
+  deleteListenerInstanceById
+} from '@/service/modules/listener-instance'
+import { format } from 'date-fns'
+import { parseTime } from '@/common/common'
+import type { IRecord } from './types'
+
+export function useTable() {
+  const data = reactive({
+    page: 1,
+    pageSize: 10,
+    itemCount: 0,
+    searchVal: '',
+    list: [],
+    loading: false
+  })
+
+  const getList = async () => {
+    if (data.loading) return
+    data.loading = true
+
+    const { totalList, total } = await queryListenerInstanceListPaging({
+      pageNo: data.page,
+      pageSize: data.pageSize,
+      searchVal: data.searchVal
+    })
+    data.loading = false
+    if (!totalList) throw Error()
+    data.list = totalList.map((record: IRecord) => {
+      record.createTime = record.createTime
+        ? format(parseTime(record.createTime), 'yyyy-MM-dd HH:mm:ss')
+        : ''
+      record.updateTime = record.updateTime
+        ? format(parseTime(record.updateTime), 'yyyy-MM-dd HH:mm:ss')
+        : ''","[{'comment': 'Ditto', 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-plugin-manage/components/listener-plugin-modal.tsx,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import {
+  defineComponent,
+  getCurrentInstance,
+  PropType,","[{'comment': 'type PropType', 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-plugin-manage/components/listener-plugin-modal.tsx,"@@ -0,0 +1,162 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import {
+  defineComponent,
+  getCurrentInstance,
+  PropType,
+  toRefs,
+  watch
+} from 'vue'
+import Modal from '@/components/modal'
+import { NButton, NForm, NFormItem, NInput, NSelect, NUpload } from 'naive-ui'
+import { useModalData } from './use-modalData'
+import { useI18n } from 'vue-i18n'
+
+const ListenerPluginModal = defineComponent({
+  name: 'tenant-modal',
+  props: {
+    showModalRef: {
+      type: Boolean as PropType<boolean>,
+      default: false
+    },
+    statusRef: {
+      type: Number as PropType<number>,
+      default: 0
+    },
+    row: {
+      type: Object as PropType<any>,
+      default: {}
+    }
+  },
+  emits: ['cancelModal', 'confirmModal'],
+  setup(props, ctx) {
+    const { variables, handleValidate } = useModalData(props, ctx)
+    const { t } = useI18n()
+
+    const cancelModal = () => {
+      if (props.statusRef === 0) {
+        variables.model.classPath = ''
+        variables.model.pluginJar = ''
+      }
+      ctx.emit('cancelModal', props.showModalRef)
+    }
+
+    const confirmModal = () => {
+      handleValidate(props.statusRef)
+    }
+
+    const trim = getCurrentInstance()?.appContext.config.globalProperties.trim
+
+    const customRequest = ({ file }: any) => {
+      variables.model.pluginJar = file.file
+      variables.listenerPluginFormRef.validate()
+    }
+  
+    // watch(
+    //   () => props.showModalRef,
+    //   () => {
+    //     props.showModalRef && getListData(props.statusRef)
+    //   }
+    // )","[{'comment': 'Delete this.', 'commenter': 'songjianet'}]"
14833,dolphinscheduler-ui/src/views/security/listener-plugin-manage/components/use-modalData.ts,"@@ -0,0 +1,98 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+import { reactive, ref, SetupContext } from 'vue'","[{'comment': 'type SetupContext', 'commenter': 'songjianet'}]"
14837,dolphinscheduler-ui/src/views/projects/workflow/components/dag/use-cell-update.ts,"@@ -51,6 +51,18 @@ export function useCellUpdate(options: Options) {
     }
   }
 
+  /**
+   * Set the node's fill color by id
+   * @param {string} id
+   * @param {string} color
+   */
+  function setNodeFillColor(id: string, color: string) {
+    const node = graph.value?.getCellById(id)
+    if (node) {
+      node.attr('rect/fill', color)
+    }","[{'comment': ""if (!node) { return false }\r\nnode.attr('rect/fill', color)"", 'commenter': 'songjianet'}, {'comment': '@songjianet  Here I used the same way like the below code snippet.\r\n<img width=""612"" alt=""image"" src=""https://github.com/apache/dolphinscheduler/assets/4928204/5c99a160-1b68-42b5-8932-5aae81e3c7e3"">\r\n', 'commenter': 'calvinjiang'}]"
14837,.github/workflows/backend.yml,"@@ -267,7 +267,7 @@ jobs:
             echo ""Skip Build!""
             exit 0
           fi
-          if [[ ${{ needs.build.result }} != 'success' || ${{ needs.cluster-test.result }} != 'success' || ${{ needs.schema-check.result }} != 'success' ]]; then
+          if [[ ${{ needs.build.result }} != 'success' || ${{ needs.cluster-test.result }} != 'success' ]]; then","[{'comment': 'Why you remove this?', 'commenter': 'SbloodyS'}]"
14887,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -210,40 +213,59 @@
         public void notify(Event event) {
             final String path = event.path();
             final Type type = event.type();
+            final String data = event.data();
             if (registryClient.isMasterPath(path)) {
                 try {
+                    String[] parts = path.split(""/"");
+                    final String masterAddress = parts[parts.length - 1];
                     if (type.equals(Type.ADD)) {
                         log.info(""master node : {} added."", path);
                         updateMasterNodes();
-                    }
-                    if (type.equals(Type.REMOVE)) {
+                    } else if (type.equals(Type.REMOVE)) {
                         log.info(""master node : {} down."", path);
                         updateMasterNodes();
                         alertDao.sendServerStoppedAlert(1, path, ""MASTER"");
+                    } else if (type == Type.UPDATE) {
+                        MasterHeartBeat info = JSONUtils.parseObject(data, MasterHeartBeat.class);
+                        if (updateSlots(info.isOverload(), masterAddress)) {
+                            log.info(""master node : {} become overload."");","[{'comment': '## Missing format argument\n\nThis format call refers to 1 argument(s) but only supplies 0 argument(s).\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/3478)', 'commenter': 'github-advanced-security[bot]'}]"
14887,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/model/MasterHeartBeat.java,"@@ -36,6 +36,7 @@ public class MasterHeartBeat implements HeartBeat {
     private double reservedMemory;
     private double diskAvailable;
     private int processId;
+    private boolean overload;","[{'comment': 'Add Master status rather than overload flag, master may have other status in the future.', 'commenter': 'ruanwenjun'}]"
14887,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/registry/ServerNodeManager.java,"@@ -210,40 +213,59 @@ class MasterDataListener implements SubscribeListener {
         public void notify(Event event) {
             final String path = event.path();
             final Type type = event.type();
+            final String data = event.data();
             if (registryClient.isMasterPath(path)) {
                 try {
+                    String[] parts = path.split(""/"");
+                    final String masterAddress = parts[parts.length - 1];
                     if (type.equals(Type.ADD)) {
                         log.info(""master node : {} added."", path);
                         updateMasterNodes();
-                    }
-                    if (type.equals(Type.REMOVE)) {
+                    } else if (type.equals(Type.REMOVE)) {
                         log.info(""master node : {} down."", path);
                         updateMasterNodes();
                         alertDao.sendServerStoppedAlert(1, path, ""MASTER"");
+                    } else if (type == Type.UPDATE) {","[{'comment': ""It's better don't change this listener, we need to cache all master heartbeat info, but only need to filter the overload master when calculate slot, so it's better to split this class to ServerNodeManager and MasterSlotManager. ServerNodeManager only need to synchronize the data from the registry."", 'commenter': 'ruanwenjun'}, {'comment': 'Okay, I will move all slot-related info to `MasterSlotManager`, but it seems that `MasterSlotManager` have to listen all `ADD/UPDATE/DELETE` events and update slots info if needed.', 'commenter': 'Radeity'}]"
14892,dolphinscheduler-task-plugin/dolphinscheduler-task-datax/src/main/java/org/apache/dolphinscheduler/plugin/task/datax/DataxUtils.java,"@@ -88,6 +94,8 @@ public static String getWriterPluginName(DbType dbType) {
                 return DATAX_WRITER_PLUGIN_CLICKHOUSE;
             case DATABEND:
                 return DATAX_WRITER_PLUGIN_DATABEND;
+            case XUGU:","[{'comment': '<img width=""1438"" alt=""image"" src=""https://github.com/apache/dolphinscheduler/assets/33984497/97548610-e2fc-46ff-9a0f-5555aa3e5ba3"">\r\nhi @mrliufox   I couldn\'t find the Xugu reader and writer on the official DataX website. I suggest removing this section and hiding the Xugu data source in the frontend module that relation to DATAX  cc @zhuangchong @ruanwenjun ', 'commenter': 'fuchanghai'}]"
14930,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/k8s/K8sTaskMainParameters.java,"@@ -32,6 +32,7 @@ public class K8sTaskMainParameters {
     private String image;
     private String command;
     private String args;
+    private String secret;","[{'comment': 'Please rename this field', 'commenter': 'qingwli'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
14930,dolphinscheduler-task-plugin/dolphinscheduler-task-api/src/main/java/org/apache/dolphinscheduler/plugin/task/api/k8s/impl/K8sTaskExecutor.java,"@@ -184,8 +187,11 @@ public Job buildK8sJob(K8sTaskMainParameters k8STaskMainParameters) {
                 .endTemplate()
                 .withBackoffLimit(retryNum)
                 .endSpec();
-
-        return jobBuilder.build();
+        job = jobBuilder.build();
+        if (!StringUtils.isEmpty(pullSecret)) {
+            job.getSpec().getTemplate().getSpec()
+                    .setImagePullSecrets(singletonList(new LocalObjectReference(pullSecret)));
+        }","[{'comment': ""I'm a bit confused about this code. Why not use `withImagePullSecrets` before the job build?"", 'commenter': 'Gallardot'}, {'comment': 'Looks like we can use this usage avoid empty case\r\n  ```\r\n   .withCommand(commands.size() == 0 ? null : commands)\r\n                .withArgs(args.size() == 0 ? null : args)\r\n  ```', 'commenter': 'qingwli'}, {'comment': 'done', 'commenter': 'fuchanghai'}]"
14937,dolphinscheduler-common/pom.xml,"@@ -177,5 +177,9 @@
                 </exclusion>
             </exclusions>
         </dependency>
+        <dependency>
+            <groupId>org.postgresql</groupId>
+            <artifactId>postgresql</artifactId>
+        </dependency>","[{'comment': ""Don't put this in common module"", 'commenter': 'ruanwenjun'}]"
14937,README.md,"@@ -7,6 +7,8 @@
 [![Slack Status](https://img.shields.io/badge/slack-join_chat-white.svg?logo=slack&style=social)](https://s.apache.org/dolphinscheduler-slack)
 [![CN doc](https://img.shields.io/badge/文档-中文版-blue.svg)](README_zh_CN.md)
 
+
+","[{'comment': '```suggestion\r\n```', 'commenter': 'ruanwenjun'}]"
14937,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/utils/JSONUtils.java,"@@ -419,4 +422,28 @@ public LocalDateTime deserialize(JsonParser p, DeserializationContext context) t
             return LocalDateTime.parse(p.getValueAsString(), formatter);
         }
     }
+
+    public static class PgArraySerializer extends JsonSerializer<PgArray> {
+        @Override
+        public void serialize(PgArray pgArray, JsonGenerator jsonGenerator, SerializerProvider serializerProvider) throws IOException {
+            try {
+                Object[] array = (Object[]) pgArray.getArray();
+
+                // 将 array 转换为合适的类型（List 或数组）
+                // 然后进行序列化
+                // ...
+
+                // 示例：将 array 序列化为 JSON 数组
+                jsonGenerator.writeStartArray();
+                for (Object item : array) {
+                    jsonGenerator.writeObject(item);
+                }
+                jsonGenerator.writeEndArray();
+            } catch (SQLException e) {
+                // 处理异常
+                e.printStackTrace();
+            }
+        }
+    }
+","[{'comment': ""Move this in SqlTask, please don't use Chinese in source code."", 'commenter': 'ruanwenjun'}]"
14940,dolphinscheduler-api/src/main/resources/application.yaml,"@@ -113,9 +113,9 @@ registry:
       base-sleep-time: 60ms
       max-sleep: 300ms
       max-retries: 5
-    session-timeout: 30s
-    connection-timeout: 9s
-    block-until-connected: 600ms
+    session-timeout: 35s
+    connection-timeout: 35s
+    block-until-connected: 30s","[{'comment': ""It's better to use the curator default setting rather than give a untest value.\r\n```suggestion\r\n    session-timeout: 60s\r\n    connection-timeout: 15s\r\n    block-until-connected: 15s\r\n```"", 'commenter': 'ruanwenjun'}, {'comment': ""Okay, I'll adjust it. Thank you"", 'commenter': 'AmriStrong'}, {'comment': '> 最好使用 curator 默认设置，而不是给出未测试的值。最好使用策展人默认设置，而不是给出未测试的值。\r\n\r\nIt has been adjusted and submitted, please review, thank you\r\n', 'commenter': 'AmriStrong'}]"
14981,dolphinscheduler-ui/src/views/security/alarm-instance-manage/detail.tsx,"@@ -95,6 +96,16 @@ const DetailModal = defineComponent({
         props.show && props.currentRecord && setDetail(props.currentRecord)
       }
     )
+    watch(
+      () => state.detailForm.instanceType,
+      () => {
+        if(state.detailForm.instanceType === 'GLOBAL'){
+          warningTypeSpan.value = 0
+        }else{
+          warningTypeSpan.value = 24
+        }","[{'comment': ""warningTypeSpan.value = state.detailForm.instanceType === 'GLOBAL' ? 0 : 24"", 'commenter': 'songjianet'}]"
14981,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -108,6 +115,22 @@
         int i = alertPluginInstanceMapper.insert(alertPluginInstance);
         if (i > 0) {
             log.info(""Create alert plugin instance complete, name:{}"", alertPluginInstance.getInstanceName());
+            // global instance will be added into global alert group automatically
+            if (instanceType == AlertPluginInstanceType.GLOBAL) {
+                AlertGroup globalAlertGroup = alertGroupMapper.selectById(2);
+                if (StringUtils.isEmpty(globalAlertGroup.getAlertInstanceIds())) {
+                    globalAlertGroup.setAlertInstanceIds(String.valueOf(alertPluginInstance.getId()));
+                } else {
+                    List<Integer> ids = Arrays.stream(globalAlertGroup.getAlertInstanceIds().split("",""))
+                            .map(s -> Integer.parseInt(s.trim()))","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/3492)"", 'commenter': 'github-advanced-security[bot]'}]"
14981,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -163,12 +186,26 @@
     @Override
     public Map<String, Object> delete(User loginUser, int id) {
         Map<String, Object> result = new HashMap<>();
-        // check if there is an associated alert group
-        boolean hasAssociatedAlertGroup = checkHasAssociatedAlertGroup(String.valueOf(id));
-        if (hasAssociatedAlertGroup) {
-            log.warn(""Delete alert plugin failed because alert group is using it, pluginId:{}."", id);
-            putMsg(result, Status.DELETE_ALERT_PLUGIN_INSTANCE_ERROR_HAS_ALERT_GROUP_ASSOCIATED);
-            return result;
+        AlertPluginInstance alertPluginInstance = alertPluginInstanceMapper.selectById(id);
+        if (alertPluginInstance.getInstanceType() == AlertPluginInstanceType.GLOBAL) {
+            // global instance will be removed from global alert group automatically
+            AlertGroup globalAlertGroup = alertGroupMapper.selectById(2);
+            List<Integer> ids = Arrays.stream(globalAlertGroup.getAlertInstanceIds().split("",""))
+                    .map(s -> Integer.parseInt(s.trim()))","[{'comment': ""## Missing catch of NumberFormatException\n\nPotential uncaught 'java.lang.NumberFormatException'.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/3493)"", 'commenter': 'github-advanced-security[bot]'}]"
14981,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -108,6 +115,22 @@
         int i = alertPluginInstanceMapper.insert(alertPluginInstance);
         if (i > 0) {
             log.info(""Create alert plugin instance complete, name:{}"", alertPluginInstance.getInstanceName());
+            // global instance will be added into global alert group automatically
+            if (instanceType == AlertPluginInstanceType.GLOBAL) {
+                AlertGroup globalAlertGroup = alertGroupMapper.selectById(2);
+                if (StringUtils.isEmpty(globalAlertGroup.getAlertInstanceIds())) {
+                    globalAlertGroup.setAlertInstanceIds(String.valueOf(alertPluginInstance.getId()));
+                } else {
+                    List<Integer> ids = Arrays.stream(globalAlertGroup.getAlertInstanceIds().split("",""))
+                            .map(s -> Integer.parseInt(s.trim()))
+                            .collect(Collectors.toList());
+                    ids.add(alertPluginInstance.getId());
+                    globalAlertGroup.setAlertInstanceIds(StringUtils.join(ids, "",""));
+                }
+                alertGroupMapper.updateById(globalAlertGroup);
+                log.info(""Add global alert plugin instance into global alert group automatically, name:{}"",
+                        alertPluginInstance.getInstanceName());","[{'comment': '## Log Injection\n\nThis log entry depends on a [user-provided value](1).\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/3495)', 'commenter': 'github-advanced-security[bot]'}]"
14981,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -1051,6 +1051,8 @@ INSERT IGNORE INTO `t_ds_version` VALUES ('1', '3.3.0');
 -- ----------------------------
 INSERT IGNORE INTO `t_ds_alertgroup`(alert_instance_ids, create_user_id, group_name, description, create_time, update_time)
 VALUES (NULL, 1, 'default admin warning group', 'default admin warning group', current_timestamp, current_timestamp);
+INSERT IGNORE INTO `t_ds_alertgroup`(alert_instance_ids, create_user_id, group_name, description, create_time, update_time)
+VALUES (NULL, 1, 'global alert group', 'global alert group', current_timestamp, current_timestamp);","[{'comment': 'Please add this to h2.', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_postgresql.sql,"@@ -1071,6 +1073,8 @@ CREATE TABLE t_ds_alert_plugin_instance (
 	create_time timestamp NULL,
 	update_time timestamp NULL,
 	instance_name varchar(255) NULL,
+	instance_type int4 NOT NULL default '0',","[{'comment': 'Please keep the same datatype in all datasouce.', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-common/src/main/java/org/apache/dolphinscheduler/common/enums/ListenerEventType.java,"@@ -0,0 +1,66 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.common.enums;
+
+import java.util.HashMap;
+import java.util.Map;
+
+import lombok.Getter;
+
+import com.baomidou.mybatisplus.annotation.EnumValue;
+
+@Getter
+public enum ListenerEventType {
+
+    SERVER_DOWN(0, ""SERVER_DOWN""),
+    PROCESS_DEFINITION_CREATED(1, ""PROCESS_DEFINITION_CREATED""),
+    PROCESS_DEFINITION_UPDATED(2, ""PROCESS_DEFINITION_UPDATED""),
+    PROCESS_DEFINITION_DELETED(3, ""PROCESS_DEFINITION_DELETED""),
+    PROCESS_START(4, ""PROCESS_START""),
+    PROCESS_END(5, ""PROCESS_INSTANCE_END""),
+    PROCESS_FAIL(6, ""PROCESS_FAIL""),
+    TASK_START(10, ""TASK_START""),
+    TASK_END(11, ""TASK_END""),
+    TASK_FAIL(12, ""TASK_FAIL"");
+
+    private static final Map<Integer, ListenerEventType> CODE_MAP = new HashMap<>();
+
+    static {
+        for (ListenerEventType listenerEventType : ListenerEventType.values()) {
+            CODE_MAP.put(listenerEventType.getCode(), listenerEventType);
+        }
+    }
+
+    @EnumValue
+    private final int code;
+    private final String descp;
+
+    ListenerEventType(int code, String descp) {
+        this.code = code;
+        this.descp = descp;
+    }
+
+    public static ListenerEventType of(int code) {
+        ListenerEventType listenerEventType = CODE_MAP.get(code);
+        if (listenerEventType == null) {
+            throw new IllegalArgumentException(String.format(""The task execution status code: %s is invalidated"",","[{'comment': '```suggestion\r\n            throw new IllegalArgumentException(String.format(""The task execution status code: %s is invalid"",\r\n```', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/service/ListenerEventPostService.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.alert.service;
+
+import org.apache.dolphinscheduler.alert.api.AlertChannel;
+import org.apache.dolphinscheduler.alert.api.AlertData;
+import org.apache.dolphinscheduler.alert.api.AlertInfo;
+import org.apache.dolphinscheduler.alert.api.AlertResult;
+import org.apache.dolphinscheduler.alert.config.AlertConfig;
+import org.apache.dolphinscheduler.alert.plugin.AlertPluginManager;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.common.enums.AlertStatus;
+import org.apache.dolphinscheduler.common.enums.AlertType;
+import org.apache.dolphinscheduler.common.enums.WarningType;
+import org.apache.dolphinscheduler.common.lifecycle.ServerLifeCycleManager;
+import org.apache.dolphinscheduler.common.thread.BaseDaemonThread;
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.AlertPluginInstance;
+import org.apache.dolphinscheduler.dao.entity.AlertSendStatus;
+import org.apache.dolphinscheduler.dao.entity.ListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.AbstractListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionCreatedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionDeletedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionUpdatedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessEndListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessFailListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessStartListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.dao.mapper.AlertPluginInstanceMapper;
+import org.apache.dolphinscheduler.dao.mapper.ListenerEventMapper;
+
+import org.apache.commons.collections4.CollectionUtils;
+import org.apache.curator.shaded.com.google.common.collect.Lists;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.Nullable;
+
+import lombok.extern.slf4j.Slf4j;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+@Service
+@Slf4j
+public final class ListenerEventPostService extends BaseDaemonThread implements AutoCloseable {
+
+    private static final int QUERY_ALERT_THRESHOLD = 100;","[{'comment': 'Can we make this param configurable in config file so that can adjust this value without recompiling.', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/service/ListenerEventPostService.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.alert.service;
+
+import org.apache.dolphinscheduler.alert.api.AlertChannel;
+import org.apache.dolphinscheduler.alert.api.AlertData;
+import org.apache.dolphinscheduler.alert.api.AlertInfo;
+import org.apache.dolphinscheduler.alert.api.AlertResult;
+import org.apache.dolphinscheduler.alert.config.AlertConfig;
+import org.apache.dolphinscheduler.alert.plugin.AlertPluginManager;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.common.enums.AlertStatus;
+import org.apache.dolphinscheduler.common.enums.AlertType;
+import org.apache.dolphinscheduler.common.enums.WarningType;
+import org.apache.dolphinscheduler.common.lifecycle.ServerLifeCycleManager;
+import org.apache.dolphinscheduler.common.thread.BaseDaemonThread;
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.AlertPluginInstance;
+import org.apache.dolphinscheduler.dao.entity.AlertSendStatus;
+import org.apache.dolphinscheduler.dao.entity.ListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.AbstractListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionCreatedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionDeletedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionUpdatedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessEndListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessFailListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessStartListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.dao.mapper.AlertPluginInstanceMapper;
+import org.apache.dolphinscheduler.dao.mapper.ListenerEventMapper;
+
+import org.apache.commons.collections4.CollectionUtils;
+import org.apache.curator.shaded.com.google.common.collect.Lists;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.Nullable;
+
+import lombok.extern.slf4j.Slf4j;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+@Service
+@Slf4j
+public final class ListenerEventPostService extends BaseDaemonThread implements AutoCloseable {
+
+    private static final int QUERY_ALERT_THRESHOLD = 100;
+
+    @Autowired
+    private ListenerEventMapper listenerEventMapper;
+    @Autowired
+    private AlertPluginInstanceMapper alertPluginInstanceMapper;
+    @Autowired
+    private AlertPluginManager alertPluginManager;
+    @Autowired
+    private AlertConfig alertConfig;
+
+    public ListenerEventPostService() {
+        super(""ListenerEventPostService"");
+    }
+
+    @Override
+    public void run() {
+        log.info(""listener event post thread started"");
+        while (!ServerLifeCycleManager.isStopped()) {
+            try {
+                List<ListenerEvent> listenerEvents = listenerEventMapper
+                        .listingListenerEventByStatus(AlertStatus.WAIT_EXECUTION, QUERY_ALERT_THRESHOLD);
+                if (CollectionUtils.isEmpty(listenerEvents)) {
+                    log.debug(""There is not waiting listener events"");","[{'comment': '```suggestion\r\n                    log.debug(""There is no waiting listener events"");\r\n```', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/service/ListenerEventPostService.java,"@@ -0,0 +1,262 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.alert.service;
+
+import org.apache.dolphinscheduler.alert.api.AlertChannel;
+import org.apache.dolphinscheduler.alert.api.AlertData;
+import org.apache.dolphinscheduler.alert.api.AlertInfo;
+import org.apache.dolphinscheduler.alert.api.AlertResult;
+import org.apache.dolphinscheduler.alert.config.AlertConfig;
+import org.apache.dolphinscheduler.alert.plugin.AlertPluginManager;
+import org.apache.dolphinscheduler.common.constants.Constants;
+import org.apache.dolphinscheduler.common.enums.AlertStatus;
+import org.apache.dolphinscheduler.common.enums.AlertType;
+import org.apache.dolphinscheduler.common.enums.WarningType;
+import org.apache.dolphinscheduler.common.lifecycle.ServerLifeCycleManager;
+import org.apache.dolphinscheduler.common.thread.BaseDaemonThread;
+import org.apache.dolphinscheduler.common.thread.ThreadUtils;
+import org.apache.dolphinscheduler.common.utils.JSONUtils;
+import org.apache.dolphinscheduler.dao.entity.AlertPluginInstance;
+import org.apache.dolphinscheduler.dao.entity.AlertSendStatus;
+import org.apache.dolphinscheduler.dao.entity.ListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.AbstractListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionCreatedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionDeletedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessDefinitionUpdatedListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessEndListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessFailListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ProcessStartListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.ServerDownListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskEndListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskFailListenerEvent;
+import org.apache.dolphinscheduler.dao.entity.event.TaskStartListenerEvent;
+import org.apache.dolphinscheduler.dao.mapper.AlertPluginInstanceMapper;
+import org.apache.dolphinscheduler.dao.mapper.ListenerEventMapper;
+
+import org.apache.commons.collections4.CollectionUtils;
+import org.apache.curator.shaded.com.google.common.collect.Lists;
+
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.List;
+import java.util.Map;
+import java.util.Optional;
+import java.util.concurrent.CompletableFuture;
+import java.util.concurrent.TimeUnit;
+
+import javax.annotation.Nullable;
+
+import lombok.extern.slf4j.Slf4j;
+
+import org.springframework.beans.factory.annotation.Autowired;
+import org.springframework.stereotype.Service;
+
+@Service
+@Slf4j
+public final class ListenerEventPostService extends BaseDaemonThread implements AutoCloseable {
+
+    private static final int QUERY_ALERT_THRESHOLD = 100;
+
+    @Autowired
+    private ListenerEventMapper listenerEventMapper;
+    @Autowired
+    private AlertPluginInstanceMapper alertPluginInstanceMapper;
+    @Autowired
+    private AlertPluginManager alertPluginManager;
+    @Autowired
+    private AlertConfig alertConfig;
+
+    public ListenerEventPostService() {
+        super(""ListenerEventPostService"");
+    }
+
+    @Override
+    public void run() {
+        log.info(""listener event post thread started"");
+        while (!ServerLifeCycleManager.isStopped()) {
+            try {
+                List<ListenerEvent> listenerEvents = listenerEventMapper
+                        .listingListenerEventByStatus(AlertStatus.WAIT_EXECUTION, QUERY_ALERT_THRESHOLD);
+                if (CollectionUtils.isEmpty(listenerEvents)) {
+                    log.debug(""There is not waiting listener events"");
+                    continue;
+                }
+                this.send(listenerEvents);
+            } catch (Exception e) {
+                log.error(""listener event post thread meet an exception"", e);
+            } finally {
+                ThreadUtils.sleep(Constants.SLEEP_TIME_MILLIS * 5L);
+            }
+        }
+        log.info(""listener event post thread stopped"");
+    }
+
+    public void send(List<ListenerEvent> listenerEvents) {
+        for (ListenerEvent listenerEvent : listenerEvents) {
+            int eventId = listenerEvent.getId();
+            List<AlertPluginInstance> globalAlertInstanceList =
+                    alertPluginInstanceMapper.queryAllGlobalAlertPluginInstanceList();
+            if (CollectionUtils.isEmpty(globalAlertInstanceList)) {
+                log.error(""post listener event fail,no bind global plugin instance."");
+                listenerEventMapper.updateListenerEvent(eventId, AlertStatus.EXECUTION_FAILURE,
+                        ""no bind plugin instance"", new Date());
+                continue;
+            }
+            AbstractListenerEvent event = generateEventFromContent(listenerEvent);
+            if (event == null) {
+                log.error(""parse listener event to abstract listener event fail. {}"", listenerEvent.getContent());","[{'comment': '```suggestion\r\n                log.error(""parse listener event to abstract listener event failed: {}"", listenerEvent.getContent());\r\n```', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -1086,6 +1088,8 @@ CREATE TABLE `t_ds_alert_plugin_instance` (
   `create_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
   `update_time` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
   `instance_name` varchar(255) DEFAULT NULL COMMENT 'alert instance name',
+  `instance_type` int NOT NULL default '0',
+  `warning_type` int,","[{'comment': '```suggestion\r\n  `warning_type` int NOT NULL,\r\n```', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_mysql.sql,"@@ -2114,3 +2118,21 @@ CREATE TABLE `t_ds_relation_sub_workflow` (
     KEY `idx_parent_task_code` (`parent_task_code`),
     KEY `idx_sub_workflow_instance_id` (`sub_workflow_instance_id`)
 );
+
+-- ----------------------------
+-- Table structure for t_ds_listener_event
+-- ----------------------------
+DROP TABLE IF EXISTS `t_ds_listener_event`;
+CREATE TABLE `t_ds_listener_event` (
+   `id` int(11) NOT NULL AUTO_INCREMENT COMMENT 'key',
+   `content` text COMMENT 'listener event json content',
+   `sign` char(40) NOT NULL DEFAULT '' COMMENT 'sign=sha1(content)',
+   `post_status` tinyint(4) DEFAULT '0' COMMENT '0:wait running,1:success,2:failed,3:partial success',
+   `event_type` int(11)  COMMENT 'listener event type',","[{'comment': ""```suggestion\r\n   `post_status` tinyint(4) NOT NULL DEFAULT '0' COMMENT '0:wait running,1:success,2:failed,3:partial success',\r\n   `event_type` int(11) NOT NULL  COMMENT 'listener event type',\r\n```"", 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-dao/src/main/resources/sql/dolphinscheduler_postgresql.sql,"@@ -2103,3 +2107,23 @@ CREATE INDEX idx_parent_workflow_instance_id ON t_ds_relation_sub_workflow (pare
 CREATE INDEX idx_parent_task_code ON t_ds_relation_sub_workflow (parent_task_code);
 CREATE INDEX idx_sub_workflow_instance_id ON t_ds_relation_sub_workflow (sub_workflow_instance_id);
 
+--
+-- Table structure for table t_ds_alert
+--
+
+DROP TABLE IF EXISTS t_ds_listener_event;
+CREATE TABLE t_ds_listener_event(
+    id          int         NOT NULL,
+    content     text,
+    sign        varchar(40) NOT NULL DEFAULT '',
+    post_status int                  DEFAULT '0',
+    event_type  int,","[{'comment': ""```suggestion\r\n    post_status int  NOT NULL                DEFAULT '0',\r\n    event_type  int NOT NULL,\r\n```"", 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-dao/src/main/resources/sql/upgrade/3.3.0_schema/mysql/dolphinscheduler_ddl.sql,"@@ -14,3 +14,23 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
 */
+-- Modify ""t_ds_alertgroup"" table
+ALTER TABLE `t_ds_alertgroup` AUTO_INCREMENT 3;
+-- Modify ""t_ds_alert_plugin_instance"" table
+ALTER TABLE `t_ds_alert_plugin_instance`
+    ADD COLUMN `instance_type` int NOT NULL DEFAULT 0, ADD COLUMN `warning_type` int NULL;
+-- Create ""t_ds_listener_event"" table
+CREATE TABLE `t_ds_listener_event`
+(
+    `id`          int      NOT NULL AUTO_INCREMENT COMMENT ""key"",
+    `content`     text NULL COMMENT ""listener event json content"",
+    `sign`        char(40) NOT NULL DEFAULT """" COMMENT ""sign=sha1(content)"",
+    `post_status` tinyint NULL DEFAULT 0 COMMENT ""0:wait running,1:success,2:failed,3:partial success"",
+    `event_type`  int NULL COMMENT ""listener event type"",","[{'comment': '```suggestion\r\n    `post_status` tinyint NOT NULL DEFAULT 0 COMMENT ""0:wait running,1:success,2:failed,3:partial success"",\r\n    `event_type`  int NOT NULL COMMENT ""listener event type"",\r\n```', 'commenter': 'SbloodyS'}]"
14981,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -108,6 +115,20 @@ public Map<String, Object> create(User loginUser, int pluginDefineId, String ins
         int i = alertPluginInstanceMapper.insert(alertPluginInstance);
         if (i > 0) {
             log.info(""Create alert plugin instance complete, name:{}"", alertPluginInstance.getInstanceName());
+            // global instance will be added into global alert group automatically
+            if (instanceType == AlertPluginInstanceType.GLOBAL) {
+                AlertGroup globalAlertGroup = alertGroupMapper.selectById(2);","[{'comment': ""Please don't use magic number 2."", 'commenter': 'ruanwenjun'}, {'comment': 'extract the magic number 2 into local variable: GLOBAL_ALERT_GROUP_ID.\r\n', 'commenter': 'weixiaonan1'}]"
14981,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/ProcessDefinitionServiceImpl.java,"@@ -306,7 +310,13 @@ public Map<String, Object> createProcessDefinition(User loginUser,
                         globalParams, locations, timeout, loginUser.getId());
         processDefinition.setExecutionType(executionType);
 
-        return createDagDefine(loginUser, taskRelationList, processDefinition, taskDefinitionLogs, otherParamsJson);
+        result = createDagDefine(loginUser, taskRelationList, processDefinition, taskDefinitionLogs, otherParamsJson);
+        if (result.get(Constants.STATUS) == Status.SUCCESS) {
+            listenerEventAlertManager.publishProcessDefinitionCreatedListenerEvent(loginUser, processDefinition,
+                    taskDefinitionLogs,
+                    taskRelationList);","[{'comment': 'Can we put this in audit aspect?', 'commenter': 'ruanwenjun'}, {'comment': ""Do you mean to add annotation on the methods where generate events to make publish events unified?  I think it's hard. Because we cannot get enougn information from arguments and return value of the method for most events such as ProcessStartListenerEvent, ProcessDefinitionDeletedListenerEvent. "", 'commenter': 'weixiaonan1'}]"
15012,dolphinscheduler-master/src/main/java/org/apache/dolphinscheduler/server/master/rpc/LogicITaskInstanceDispatchOperationFunction.java,"@@ -62,19 +62,23 @@ public LogicTaskDispatchResponse operate(LogicTaskDispatchRequest taskDispatchRe
             LogUtils.setTaskInstanceLogFullPathMDC(taskExecutionContext.getLogPath());
 
             MasterTaskExecutionContextHolder.putTaskExecutionContext(taskExecutionContext);
-            // todo: calculate the delay in master dispatcher then we don't need to use a queue to store the task
-            final long remainTime =
-                    DateUtils.getRemainTime(DateUtils.timeStampToDate(taskExecutionContext.getFirstSubmitTime()),
-                            TimeUnit.SECONDS.toMillis(taskExecutionContext.getDelayTime()));
-            if (remainTime > 0) {
-                log.info(""Current taskInstance: {} is choosing delay execution, delay time: {}/ms, remainTime: {}/ms"",
-                        taskExecutionContext.getTaskName(),
-                        TimeUnit.SECONDS.toMillis(taskExecutionContext.getDelayTime()), remainTime);
-                taskExecutionContext.setCurrentExecutionStatus(TaskExecutionStatus.DELAY_EXECUTION);
-                // todo: send delay execution message
-                return LogicTaskDispatchResponse.success(taskExecutionContext.getTaskInstanceId());
-            }
 
+            int delayTime = taskExecutionContext.getDelayTime();
+            if (delayTime > 0) {
+                // todo: calculate the delay in master dispatcher then we don't need to use a queue to store the task
+                final long remainTime =
+                        DateUtils.getRemainTime(DateUtils.timeStampToDate(taskExecutionContext.getFirstSubmitTime()),
+                                TimeUnit.SECONDS.toMillis(delayTime));
+                if (remainTime > 0) {
+                    log.info(
+                            ""Current taskInstance: {} is choosing delay execution, delay time: {}/ms, remainTime: {}/ms"",
+                            taskExecutionContext.getTaskName(),
+                            TimeUnit.SECONDS.toMillis(taskExecutionContext.getDelayTime()), remainTime);
+                    taskExecutionContext.setCurrentExecutionStatus(TaskExecutionStatus.DELAY_EXECUTION);
+                    // todo: send delay execution message
+                    return LogicTaskDispatchResponse.success(taskExecutionContext.getTaskInstanceId());
+                }
+            }","[{'comment': 'You also need to add this logic in GlobalTaskInstanceDispatchQueueLooper', 'commenter': 'ruanwenjun'}]"
15153,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/enums/DatabaseId.java,"@@ -0,0 +1,37 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.dao.enums;
+
+import lombok.AllArgsConstructor;
+import lombok.Getter;
+
+/**
+ * mybatis productName and databaseId mapping
+ */
+@AllArgsConstructor
+@Getter
+public enum DatabaseId {
+
+    H2(""H2"", ""h2""),
+    ORACLE(""Oracle"", ""oracle""),","[{'comment': 'We do not support oracle database as meta database.', 'commenter': 'SbloodyS'}]"
15153,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/enums/DatabaseId.java,"@@ -0,0 +1,36 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one or more
+ * contributor license agreements.  See the NOTICE file distributed with
+ * this work for additional information regarding copyright ownership.
+ * The ASF licenses this file to You under the Apache License, Version 2.0
+ * (the ""License""); you may not use this file except in compliance with
+ * the License.  You may obtain a copy of the License at
+ *
+ *    http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.dolphinscheduler.dao.enums;
+
+import lombok.AllArgsConstructor;
+import lombok.Getter;
+
+/**
+ * mybatis productName and databaseId mapping
+ */
+@AllArgsConstructor
+@Getter
+public enum DatabaseId {
+
+    H2(""H2"", ""h2""),
+    MYSQL(""MySQL"", ""mysql""),
+    POSTGRESQL(""PostgreSQL"", ""pg"");
+
+    private final String productName;
+    private final String databaseId;
+}","[{'comment': 'Can we move this into ado-plugin https://github.com/apache/dolphinscheduler/tree/dev/dolphinscheduler-dao-plugin, and add method to get databaseId mapping at https://github.com/apache/dolphinscheduler/blob/dev/dolphinscheduler-dao-plugin/dolphinscheduler-dao-api/src/main/java/org/apache/dolphinscheduler/dao/plugin/api/DaoPluginConfiguration.java', 'commenter': 'ruanwenjun'}]"
15153,dolphinscheduler-dao/src/main/java/org/apache/dolphinscheduler/dao/DaoConfiguration.java,"@@ -61,6 +63,11 @@ public MybatisPlusInterceptor paginationInterceptor(DbType dbType) {
         return interceptor;
     }
 
+    @Bean
+    public DatabaseIdProvider databaseIdProvider() {
+        return new FixedDatabaseIdProvider(daoPluginConfiguration.databaseId());","[{'comment': 'Can we directly use daoPluginConfiguration.dbType().name() as databaseId?\r\nI find the databaseId only exist in `TriggerRelationMapper.xml` if we modify the name to `POSTGRE_SQL` this should work.', 'commenter': 'ruanwenjun'}, {'comment': ""that's what I thought at first, use `DatabaseProductName` as databaseId. view commit https://github.com/apache/dolphinscheduler/pull/15153/commits/19d851011656c9fcc4dc5e07241fe98662340b8c  \r\n"", 'commenter': 'mind-echo'}, {'comment': 'If so, we can remove databaseId, and use the default `VendorDatabaseIdProvider` without add properties after change the datasourceId to PostgreSQL in mapper? .', 'commenter': 'ruanwenjun'}, {'comment': 'yup', 'commenter': 'mind-echo'}, {'comment': 'Please remove databaseId in DaoPlugin, and use this way.', 'commenter': 'ruanwenjun'}, {'comment': 'Can I close this PR and recreate it? Too many commits are not clean enough', 'commenter': 'mind-echo'}, {'comment': ""You can rebase the commit, and I will use squash merge to edit the commit message when merged. So this is not a problem, don't worry."", 'commenter': 'ruanwenjun'}]"
15163,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/AlertServer.java,"@@ -60,13 +61,17 @@ public static void main(String[] args) {
 
     @EventListener
     public void run(ApplicationReadyEvent readyEvent) {
-        log.info(""Alert server is staring ..."");
         alertPluginManager.start();
-        alertRegistryClient.start();
-        alertBootstrapService.start();
-        listenerEventPostService.start();
-        alertRpcServer.start();
-        log.info(""Alert server is started ..."");
+
+        if (this.getClass().getName()
+                .contains(((SpringApplication) readyEvent.getSource()).getMainApplicationClass().getName())) {
+            log.info(""Alert server is staring ..."");
+            alertRegistryClient.start();
+            alertBootstrapService.start();
+            listenerEventPostService.start();
+            alertRpcServer.start();
+            log.info(""Alert server is started ..."");
+        }","[{'comment': 'Why do this change? ', 'commenter': 'ruanwenjun'}, {'comment': 'Pre-design is to import the alert server in API-server, which will run the alert server auto, I just need the alert plugin manager and not need another component, so add this code. But change to use rpc does not need this change.', 'commenter': 'qingwli'}]"
15163,dolphinscheduler-alert/dolphinscheduler-alert-server/src/main/java/org/apache/dolphinscheduler/alert/service/ListenerEventPostService.java,"@@ -260,4 +261,39 @@ public void close() {
         log.info(""Closed ListenerEventPostService..."");
     }
 
+    public AlertChannel getPluginDefine(int pluginDefineId) {
+        Optional<AlertChannel> alertChannelOptional = alertPluginManager.getAlertChannel(pluginDefineId);
+        return alertChannelOptional.orElse(null);
+    }","[{'comment': '```suggestion\r\n    public Optional<AlertChannel> getPluginDefine(int pluginDefineId) {\r\n        return  alertPluginManager.getAlertChannel(pluginDefineId);\r\n    }\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Done', 'commenter': 'qingwli'}]"
15163,dolphinscheduler-api/pom.xml,"@@ -61,6 +61,11 @@
             <artifactId>dolphinscheduler-meter</artifactId>
         </dependency>
 
+        <dependency>
+            <groupId>org.apache.dolphinscheduler</groupId>
+            <artifactId>dolphinscheduler-alert-server</artifactId>
+        </dependency>
+","[{'comment': ""It's not a good idea to import alert-server in api-server, you should exposed a rpc method `testSend`  in alert server, and api call this method to test."", 'commenter': 'ruanwenjun'}, {'comment': 'Done', 'commenter': 'qingwli'}]"
15163,dolphinscheduler-ui/src/views/security/alarm-instance-manage/use-detail.ts,"@@ -41,6 +46,27 @@ export function useDetail(getFormValues: Function) {
     return JSON.stringify(json)
   }
 
+  const testSend = async (json?: IJsonItem[]) => {
+    const values = getFormValues()
+
+    if (status.testing) return
+    status.testing = true
+    try {
+      const res = await testAlertPluginInstance({
+        pluginDefineId: values.pluginDefineId,
+        pluginInstanceParams: formatParams(json, values)
+      })
+      window.$message.success(
+        res
+          ? res.msg
+          : `${t('security.alarm_instance.test_send')} ${t('home.success')}`
+      )
+      status.testing = false
+    } catch (err) {","[{'comment': 'please delete err, because it is not used.', 'commenter': 'songjianet'}, {'comment': 'Done', 'commenter': 'qingwli'}]"
15163,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -352,4 +361,40 @@
         return first.isPresent();
     }
 
+    @Override
+    public Result<Object> testSend(int pluginDefineId, String pluginInstanceParams) {
+        Result<Object> result = new Result<>();
+        Optional<Host> alertServerAddressOptional = registryClient.getAlertServerAddress();
+        if (!alertServerAddressOptional.isPresent()) {
+            log.error(""Cannot get alert server address, please check the alert server is running"");
+            putMsg(result, Status.ALERT_CHANNEL_NOT_EXIST);
+            return result;
+        }
+
+        Host alertServerAddress = alertServerAddressOptional.get();
+        AlertTestSendRequest alertTestSendRequest = new AlertTestSendRequest(
+                pluginDefineId,
+                pluginInstanceParams);
+
+        AlertSendResponse.AlertSendResponseResult alertSendResponse;
+
+        try {
+            IAlertOperator alertOperator = SingletonJdkDynamicRpcClientProxyFactory
+                    .getProxyClient(alertServerAddress.getAddress(), IAlertOperator.class);
+            alertSendResponse = alertOperator.sendTestAlert(alertTestSendRequest);
+            log.info(""Send alert to: {} successfully, response: {}"", alertServerAddress, alertSendResponse);
+        } catch (Exception e) {
+            log.error(""Send alert: {} to: {} failed"", alertTestSendRequest, alertServerAddress, e);
+            putMsg(result, Status.ALERT_CHANNEL_NOT_EXIST);
+            return result;
+        }
+
+        if (alertSendResponse != null && alertSendResponse.isSuccess()) {
+            putMsg(result, Status.SUCCESS);
+        } else {
+            putMsg(result, Status.ALERT_TEST_SENDING_FAILED, alertSendResponse.getMessage());","[{'comment': '## Dereferenced variable may be null\n\nVariable [alertSendResponse](1) may be null at this access as suggested by [this](2) null guard.\n\n[Show more details](https://github.com/apache/dolphinscheduler/security/code-scanning/3552)', 'commenter': 'github-advanced-security[bot]'}]"
15163,dolphinscheduler-extract/dolphinscheduler-extract-alert/src/main/java/org/apache/dolphinscheduler/extract/alert/IAlertOperator.java,"@@ -28,4 +29,7 @@ public interface IAlertOperator {
     @RpcMethod
     AlertSendResponse sendAlert(AlertSendRequest alertSendRequest);
 
+    @RpcMethod
+    AlertSendResponse.AlertSendResponseResult sendTestAlert(AlertTestSendRequest alertSendRequest);","[{'comment': '```suggestion\r\n    AlertSendResponse sendTestAlert(AlertTestSendRequest alertSendRequest);\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Done', 'commenter': 'qingwli'}]"
15163,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -352,4 +361,40 @@ private boolean checkHasAssociatedAlertGroup(String id) {
         return first.isPresent();
     }
 
+    @Override
+    public Result<Object> testSend(int pluginDefineId, String pluginInstanceParams) {","[{'comment': '```suggestion\r\n    public Result<Void> testSend(int pluginDefineId, String pluginInstanceParams) {\r\n```', 'commenter': 'ruanwenjun'}, {'comment': 'Done\r\n', 'commenter': 'qingwli'}]"
15163,dolphinscheduler-api/src/main/java/org/apache/dolphinscheduler/api/service/impl/AlertPluginInstanceServiceImpl.java,"@@ -352,4 +361,40 @@ private boolean checkHasAssociatedAlertGroup(String id) {
         return first.isPresent();
     }
 
+    @Override
+    public Result<Object> testSend(int pluginDefineId, String pluginInstanceParams) {
+        Result<Object> result = new Result<>();
+        Optional<Host> alertServerAddressOptional = registryClient.getAlertServerAddress();
+        if (!alertServerAddressOptional.isPresent()) {
+            log.error(""Cannot get alert server address, please check the alert server is running"");
+            putMsg(result, Status.ALERT_CHANNEL_NOT_EXIST);","[{'comment': 'Alert server not exist', 'commenter': 'ruanwenjun'}, {'comment': 'Done\r\n', 'commenter': 'qingwli'}]"
15163,docs/img/new_ui/dev/alert/alert_instance01.png,,"[{'comment': 'Why change these pictures?', 'commenter': 'ruanwenjun'}, {'comment': 'UI add `test send` button, so change the pic', 'commenter': 'qingwli'}, {'comment': 'Just pic03 contains this button, but pic03 shows table contains in pic1&2, so change those three pics', 'commenter': 'qingwli'}, {'comment': 'I am not sure if the picture is too small.', 'commenter': 'ruanwenjun'}, {'comment': 'Will be well \r\n![image](https://github.com/apache/dolphinscheduler/assets/20885366/c6e1454e-73d2-4b30-ae17-671d7520fd68)\r\n![image](https://github.com/apache/dolphinscheduler/assets/20885366/7937ec8f-58fd-4f9d-aec0-74c423cc052d)\r\n\r\n', 'commenter': 'qingwli'}]"
15163,docs/docs/en/guide/alert/alert_plugin_user_guide.md,"@@ -13,6 +13,8 @@ Steps to be used are as follows:
 - Select the corresponding alarm plug-in and fill in the relevant alarm parameters.
 - Select `Alarm Group Management`, create an alarm group, and choose the corresponding alarm instance.
 
+> You can click `Test send` button to test whether the alarm instance is configured correctly.","[{'comment': '```suggestion\r\n> You can click `Test Send` button to test whether the alarm instance is configured correctly.\r\n```', 'commenter': 'Radeity'}]"
