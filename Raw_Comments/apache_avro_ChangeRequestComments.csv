Pull,Path,Diff_hunk,Comment
97,lang/c++/test/SchemaTests.cc,"@@ -154,6 +205,19 @@ static void testCompile(const char* schema)
     compileJsonSchemaFromString(std::string(schema));
 }
 
+// Test that the JSON output from a valid schema matches the JSON that was 
+// used to construct it, apart from whitespace changes.
+static void testRoundTrip(const char* schema)
+{
+    BOOST_CHECKPOINT(schema);
+    avro::ValidSchema compiledSchema = compileJsonSchemaFromString(std::string(schema));
+    std::ostringstream os;
+    compiledSchema.toJson(os);
+    std::string result = os.str();
+    result.erase( std::remove_if( result.begin(), result.end(), ::isspace ), result.end() ); // Remove whitespace","[{'comment': ""Instead of removing all whitespaces, consecutive whitespaces should be collapsed into a single space. It is true that it doesn't matter how many whitespaces there are, but it does matter whether there is or isn't whitespace between specific characters. A slight modification will give the desired result as described in http://stackoverflow.com/a/8362145/5613485\n\nAdditionally this line uses a different style than the other lines, there should be no spaces after '('-s or before ')'-s.\n"", 'commenter': 'zivanfi'}]"
97,lang/c++/test/SchemaTests.cc,"@@ -136,6 +136,57 @@ const char* basicSchemaErrors[] = {
     ""{\""type\"": \""fixed\"", \""size\"": 314}"",
 };
 
+const char* roundTripSchemas[] = {
+    ""\""null\"""",
+    ""\""boolean\"""",
+    ""\""int\"""",
+    ""\""long\"""",
+    ""\""float\"""",
+    ""\""double\"""",
+    ""\""bytes\"""",
+    ""\""string\"""",
+    // Record
+    ""{\""type\"":\""record\"",\""name\"":\""Test\"",\""fields\"":[]}"",
+    ""{\""type\"":\""record\"",\""name\"":\""Test\"",\""fields\"":""
+        ""[{\""name\"":\""f\"",\""type\"":\""long\""}]}"",
+    ""{\""type\"":\""record\"",\""name\"":\""Test\"",\""fields\"":""
+        ""[{\""name\"":\""f1\"",\""type\"":\""long\""},""
+        ""{\""name\"":\""f2\"",\""type\"":\""int\""}]}"",
+/* Avro-C++ cannot do a round-trip on error schemas. 
+ * ""{\""type\"":\""error\"",\""name\"":\""Test\"",\""fields\"":""
+        ""[{\""name\"":\""f1\"",\""type\"":\""long\""},""","[{'comment': ""Nit: Comment style is inconsistent, some lines start with a *, while others don't.\n"", 'commenter': 'zivanfi'}]"
97,lang/c++/test/SchemaTests.cc,"@@ -154,6 +205,19 @@ static void testCompile(const char* schema)
     compileJsonSchemaFromString(std::string(schema));
 }
 
+// Test that the JSON output from a valid schema matches the JSON that was 
+// used to construct it, apart from whitespace changes.
+static void testRoundTrip(const char* schema)
+{
+    BOOST_CHECKPOINT(schema);","[{'comment': 'Other tests have been updated to use BOOST_TEST_CHECKPOINT, please update this as well.\n', 'commenter': 'zivanfi'}]"
130,lang/java/avro/src/main/java/org/apache/avro/LogicalTypes.java,"@@ -83,6 +88,9 @@ private static LogicalType fromSchemaImpl(Schema schema, boolean throwErrors) {
     } catch (RuntimeException e) {
       if (throwErrors) {
         throw e;
+      } else {
+        LOGGER.warn(""Ignoring invalid logical type for name: {}"", typeName);
+        LOGGER.debug(""Invalid logical type found"", e);","[{'comment': 'Optional: I would suggest moving the `LOGGER.debug` line before the `if`.\n', 'commenter': 'zivanfi'}, {'comment': 'Make sense. Updated. \nThanks for the review.\n', 'commenter': 'gszadovszky'}]"
130,lang/java/avro/src/main/java/org/apache/avro/LogicalTypes.java,"@@ -81,8 +86,11 @@ private static LogicalType fromSchemaImpl(Schema schema, boolean throwErrors) {
         logicalType.validate(schema);
       }
     } catch (RuntimeException e) {
+      LOGGER.debug(""Invalid logical type found"", e);
       if (throwErrors) {
         throw e;
+      } else {
+        LOGGER.warn(""Ignoring invalid logical type for name: {}"", typeName);","[{'comment': 'Ah sorry, one more minor issue. The `logicalType = null;` line below gets executed only if throwErrors is false, and so does the `LOGGER.warn` line, but the former is after the if while the latter is in the else branch, which is a bit confusing/inconsistent. Could you move it out of the else, immediately after the if block like the existing code?\n', 'commenter': 'zivanfi'}, {'comment': 'Good point. However the whole else branch is useless. Removed.\n', 'commenter': 'gszadovszky'}]"
130,lang/java/avro/src/main/java/org/apache/avro/LogicalTypes.java,"@@ -21,8 +21,13 @@
 import java.util.Map;
 import java.util.concurrent.ConcurrentHashMap;
 
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 public class LogicalTypes {
 
+  private static final Logger LOGGER = LoggerFactory.getLogger(LogicalTypes.class);","[{'comment': 'Please change to `LOG` for consistency with the rest of the codebase.\n', 'commenter': 'tomwhite'}, {'comment': ""Sorry, @tomwhite, I've missed your comment. Modified the name.\n"", 'commenter': 'gszadovszky'}]"
133,lang/py3/avro/schema.py,"@@ -385,7 +385,7 @@ def NewWithDefaultNamespace(self, namespace):
     """"""
     return Names(names=self._names, default_namespace=namespace)
 
-  def GetName(self, name, namespace=None):
+  def _get_name(self, name, namespace=None):","[{'comment': 'this might break the usage of GetName in exisitng usage.\nNot sure if we would want to make the function an internal use only.\n', 'commenter': 'spacharya'}, {'comment': ""I wasn't 100% sure on this one, because `get_name` is already a function. When I did a usage search for `GetName`, the usages looked to be all within this file. When I searched for `get_name`, it seemed like other modules were using it.\n\nBeing that the existing `get_name` function delegates to this one, I think the functionality is still available for external use.\n\nDoes that seem appropriate to you? What are your thoughts?\n"", 'commenter': 'ssaamm'}, {'comment': 'I am a bit conflicted on this. I see that this is the only usage, but I am unsure how people use it. \n@rdblue  can you check this out and let us know if moving a function as an internal use only in a minor is okay.\nElse, +1\n', 'commenter': 'spacharya'}, {'comment': 'If I understand correctly, convention is for downstream users to consider methods that do not start with _ to be part of the public API and safe to use. But, all of the renames in the PR are breaking changes so we could just bump the version to indicate what happened.\n', 'commenter': 'rdblue'}]"
141,lang/java/avro/src/main/java/org/apache/avro/message/BinaryMessageDecoder.java,"@@ -128,6 +128,17 @@ public void addSchema(Schema writeSchema) {
         new RawMessageDecoder<D>(model, writeSchema, readSchema));
   }
 
+  /**
+   * Sets the new SchemaStore instance that is to be used to retrieve the schemas.
+   *
+   * @param newResolver a {@link SchemaStore} to use when decoding buffers
+   */
+  public void setSchemaStore(SchemaStore newResolver) {
+    if (newResolver != null) {
+      this.resolver = newResolver;
+    }","[{'comment': ""Don't you think the user of this method should be informed about the fact that the resolver was not set? I would suggest throwing an exception here (e.g. IllegalStateException).\n"", 'commenter': 'gszadovszky'}, {'comment': ""Easier: Remove that check and thus allow 'removing' the SchemaStore again.\n"", 'commenter': 'nielsbasjes'}, {'comment': 'Yes, this would be simpler if it fits the logic. :)\n', 'commenter': 'gszadovszky'}, {'comment': 'It does. The resolver is an optional thing that is common to be null.\n', 'commenter': 'nielsbasjes'}]"
141,lang/java/avro/src/main/java/org/apache/avro/message/BinaryMessageDecoder.java,"@@ -128,6 +128,17 @@ public void addSchema(Schema writeSchema) {
         new RawMessageDecoder<D>(model, writeSchema, readSchema));
   }
 
+  /**
+   * Sets the new SchemaStore instance that is to be used to retrieve the schemas.
+   *
+   * @param newResolver a {@link SchemaStore} to use when decoding buffers
+   */
+  public void setSchemaStore(SchemaStore newResolver) {","[{'comment': 'This class supposed to be thread-safe. I would suggest having this one synchronized.\n', 'commenter': 'gszadovszky'}, {'comment': 'Yes\n', 'commenter': 'nielsbasjes'}]"
149,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -506,12 +506,12 @@ public String toString(Object datum) {
   }
   /** Renders a Java datum as <a href=""http://www.json.org/"">JSON</a>. */
   protected void toString(Object datum, StringBuilder buffer, IdentityHashMap<Object, Object> seenObjects) {
-    if (seenObjects.containsKey(datum)) {
-      buffer.append("" \"">>> CIRCULAR REFERENCE CANNOT BE PUT IN JSON STRING, ABORTING RECURSION<<<\"" "");
-      return;
-    }
-    seenObjects.put(datum, datum);
     if (isRecord(datum)) {","[{'comment': ""I agree with Doug's comment that this check should happen for any type that can contain an object, like maps and lists.\n"", 'commenter': 'rdblue'}]"
149,lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java,"@@ -552,4 +552,28 @@ public void testToStringRecursive() throws IOException {
     }
   }
 
+  @Test
+  public void testToString() throws IOException {","[{'comment': ""Since this is basically testing that identical values can be used as long as they aren't nested, I think it would be good to have this test validate that for all types. Or, have a test case for each type. That should include non-nested records that are identical. For example, a binary tree structure that has a reused leaf node should work with `toString`.\n"", 'commenter': 'rdblue'}]"
149,lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java,"@@ -552,4 +552,28 @@ public void testToStringRecursive() throws IOException {
     }
   }
 
+  @Test
+  public void testToString() throws IOException {
+    List<Field> fields = new ArrayList<Field>();
+    fields.add(new Field(""nullstring1"", Schema.create(Type.STRING), null, null));
+    fields.add(new Field(""nullstring2"", Schema.create(Type.STRING), null, null));
+    fields.add(new Field(""string1"", Schema.create(Type.STRING), null, null));
+    fields.add(new Field(""string2"", Schema.create(Type.STRING), null, null));
+    fields.add(new Field(""int1"", Schema.create(Type.INT), null, null));
+    fields.add(new Field(""int2"", Schema.create(Type.INT), null, null));
+    Schema schema = Schema.createRecord(""Foo"", ""test"", ""mytest"", false);
+    schema.setFields(fields);
+
+    Record testRecord = new Record(schema);
+
+    testRecord.put(""nullstring1"", null);
+    testRecord.put(""nullstring2"", null);
+    testRecord.put(""string1"", ""Hello World"");","[{'comment': 'Minor: The compiler is going to intern the ""Hello World"" string so you get the same object, but it would be more clear if these tests used the same reference instead of relying on that. Like this:\n\n``` java\nString s = ""Hello World"";\ntestRecord.put(""string1"", s);\ntestRecord.put(""string2"", s);\n```\n', 'commenter': 'rdblue'}]"
152,lang/java/avro/src/main/java/org/apache/avro/file/DeflateCodec.java,"@@ -51,6 +53,18 @@ protected Codec createInstance() {
     }
   }
 
+  private static class Buffer extends ByteArrayOutputStream {
+    public synchronized byte[] getData() { return buf; }","[{'comment': 'synchronized is useless here: returning a reference is atomic.\n', 'commenter': 'gszadovszky'}]"
152,lang/java/trevni/core/src/main/java/org/apache/trevni/DeflateCodec.java,"@@ -32,24 +34,41 @@
   private Deflater deflater;
   private Inflater inflater;
 
+  private static class Buffer extends ByteArrayOutputStream {
+    public synchronized byte[] getData() { return buf; }","[{'comment': 'Same as above.\n', 'commenter': 'gszadovszky'}]"
152,lang/java/avro/src/main/java/org/apache/avro/file/DeflateCodec.java,"@@ -81,16 +95,15 @@ public ByteBuffer decompress(ByteBuffer data) throws IOException {
     ByteArrayOutputStream baos = getOutputBuffer(data.remaining());
     InflaterOutputStream ios = new InflaterOutputStream(baos, getInflater());
     writeAndClose(data, ios);
-    ByteBuffer result = ByteBuffer.wrap(baos.toByteArray());
+    ByteBuffer result = ByteBuffer.wrap(((Buffer) baos).getData(), 0, baos.size());
     return result;
   }
 
   private void writeAndClose(ByteBuffer data, OutputStream to) throws IOException {
-    byte[] input = data.array();
-    int offset = data.arrayOffset() + data.position();
-    int length = data.remaining();
     try {
-      to.write(input, offset, length);
+      WritableByteChannel channel = Channels.newChannel(to);
+
+      channel.write(data);","[{'comment': 'How is this change related to the bugfix?\n', 'commenter': 'tomwhite'}, {'comment': '@nandorKollar would it be possible to not include this change to address this issue?\n', 'commenter': 'tomwhite'}]"
162,lang/java/pom.xml,"@@ -35,6 +35,8 @@
 
   <properties>
     <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
+    <jdkVersion>1.6</jdkVersion>
+    <jdk8Version>1.8</jdk8Version> <!-- Some tests need java 8 or newer -->","[{'comment': ""I don't like the naming of this properly. I would rather name it after its purpose e.g. testJdkVersion."", 'commenter': 'gszadovszky'}]"
170,lang/ruby/lib/avro/schema_compatibility.rb,"@@ -0,0 +1,160 @@
+# Licensed to the Apache Software Foundation (ASF) under one
+# or more contributor license agreements.  See the NOTICE file
+# distributed with this work for additional information
+# regarding copyright ownership.  The ASF licenses this file
+# to you under the Apache License, Version 2.0 (the
+# ""License""); you may not use this file except in compliance
+# with the License.  You may obtain a copy of the License at
+#
+# http://www.apache.org/licenses/LICENSE-2.0
+#
+# Unless required by applicable law or agreed to in writing, software
+# distributed under the License is distributed on an ""AS IS"" BASIS,
+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+# See the License for the specific language governing permissions and
+# limitations under the License.
+module Avro
+  module SchemaCompatibility
+    def self.can_read?(writers_schema, readers_schema)
+      Checker.new.can_read?(writers_schema, readers_schema)
+    end
+
+    def self.mutual_read?(writers_schema, readers_schema)
+      Checker.new.mutual_read?(writers_schema, readers_schema)
+    end
+
+    def self.match_schemas(writers_schema, readers_schema)
+      # Note: this does not support aliases!","[{'comment': 'Worth calling out in docs for the method', 'commenter': 'busbey'}, {'comment': ""@busbey Thanks for the review!\r\n\r\nI've added documentation for this method, and a couple of the other public methods here, and included this comment as part of that documentation.\r\n\r\nIf that's not what you meant, please let me know. Also squashed into a single commit."", 'commenter': 'tjwp'}]"
175,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -361,6 +361,7 @@ static Class getClassProp(Schema schema, String prop) {
    * It returns false for non-string-maps because Avro writes out such maps
    * as an array of records. Even their JSON representation is an array.
    */
+","[{'comment': 'nit: unnecessary empty line', 'commenter': 'gszadovszky'}]"
175,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -877,6 +881,18 @@ private void consumeAvroAliasAnnotation(Class<?> c, Schema schema) {
     }
   }
 
+
+  private void consumeFieldAlias(Field field, Schema.Field recordField) {
+    if (field.isAnnotationPresent(AvroAlias.class)) {","[{'comment': 'Field.isAnnotationPresent(Class) checks whether Field.getAnnotation(Class) returns null. I would suggest checking for alias != null to avoid the double invocation. ', 'commenter': 'gszadovszky'}]"
177,lang/java/avro/src/main/java/org/apache/avro/file/DataFileWriter.java,"@@ -195,25 +195,31 @@ public boolean isFlushOnEveryBlock() {
   }
 
   /** Open a writer appending to an existing file.
+   * <strong>This method closes <code>in</code>.</strong>
    * @param in reading the existing file.
    * @param out positioned at the end of the existing file.
    */
   public DataFileWriter<D> appendTo(SeekableInput in, OutputStream out)
     throws IOException {
     assertNotOpen();
-    DataFileReader<D> reader =
-      new DataFileReader<D>(in, new GenericDatumReader<D>());
-    this.schema = reader.getSchema();
-    this.sync = reader.getHeader().sync;
-    this.meta.putAll(reader.getHeader().meta);
-    byte[] codecBytes = this.meta.get(DataFileConstants.CODEC);
-    if (codecBytes != null) {
-      String strCodec = new String(codecBytes, ""UTF-8"");
-      this.codec = CodecFactory.fromString(strCodec).createInstance();
-    } else {
-      this.codec = CodecFactory.nullCodec().createInstance();
+    DataFileReader<D> reader = null;
+    try {
+      reader = new DataFileReader<D>(in, new GenericDatumReader<D>());
+      this.schema = reader.getSchema();
+      this.sync = reader.getHeader().sync;
+      this.meta.putAll(reader.getHeader().meta);
+      byte[] codecBytes = this.meta.get(DataFileConstants.CODEC);
+      if (codecBytes != null) {
+        String strCodec = new String(codecBytes, ""UTF-8"");
+        this.codec = CodecFactory.fromString(strCodec).createInstance();
+      } else {
+        this.codec = CodecFactory.nullCodec().createInstance();
+      }
+    } finally {
+      if (reader != null)
+        reader.close();
+      in.close();","[{'comment': ""Why the change to close the passed SeekableInput? Shouldn't that be up to the caller?"", 'commenter': 'busbey'}, {'comment': ""You're right, it should be closed by the caller but it is already implemented this way as we are closing the reader which closes the SeekableInput as well. I did not want to break backward compatibility but fix the actual situation that the resources are not closed every time.\r\nThat's why I've tried to highlight in the method comment that this method closes the specified SeekableInput."", 'commenter': 'gszadovszky'}, {'comment': 'Can we update DataFileReader to properly not close the passed input stream instead?', 'commenter': 'busbey'}, {'comment': 'We can but it would be a backward incompatible change as this method is public. \r\nIf we would like to follow the usual pattern for this case we would need another method which does not close it and deprecate this one then remove this one in the next major release.\r\nOr is it enough marking this JIRA with ""incompatible change"" and change as you are suggesting?', 'commenter': 'gszadovszky'}]"
177,lang/java/tools/src/main/java/org/apache/avro/tool/IdlTool.java,"@@ -58,12 +58,17 @@ public int run(InputStream in, PrintStream out, PrintStream err,
       parser = new Idl(in);
     }
 
-    if (args.size() == 2 && ! ""-"".equals(args.get(1))) {
-      parseOut = new PrintStream(new FileOutputStream(args.get(1)));
-    }
+      if (args.size() == 2 && !""-"".equals(args.get(1))) {","[{'comment': 'it looks like these indents are incorrect.', 'commenter': 'busbey'}, {'comment': ""Seems you're right. I'll check it out."", 'commenter': 'gszadovszky'}]"
177,lang/java/tools/src/main/java/org/apache/avro/tool/Main.java,"@@ -104,18 +104,26 @@ private int run(String[] args) throws Exception {
 
   private static void printStream(InputStream in) throws Exception {
     byte[] buffer = new byte[1024];
-    for (int i = in.read(buffer); i != -1; i = in.read(buffer))
-      System.err.write(buffer, 0, i);
+    try {
+      for (int i = in.read(buffer); i != -1; i = in.read(buffer))
+        System.err.write(buffer, 0, i);
+    } finally {
+      in.close();","[{'comment': 'Why are we closing in within this method instead of having the caller do it?', 'commenter': 'busbey'}, {'comment': 'This one is a private method and it seemed to be easier and shorter to close the stream inside this method instead of the public caller. Do you think I should rewrite it?', 'commenter': 'gszadovszky'}, {'comment': 'yeah please have the caller close it instead. we should be internally disciplined.', 'commenter': 'busbey'}, {'comment': 'Fair enough. On the way...', 'commenter': 'gszadovszky'}]"
177,lang/java/avro/src/main/java/org/apache/avro/file/DataFileWriter.java,"@@ -190,11 +190,17 @@ public boolean isFlushOnEveryBlock() {
 
   /** Open a writer appending to an existing file. */
   public DataFileWriter<D> appendTo(File file) throws IOException {
-    return appendTo(new SeekableFileInput(file),
-                    new SyncableFileOutputStream(file, true));
+    SeekableInput input = new SeekableFileInput(file);
+    OutputStream output = new SyncableFileOutputStream(file, true);","[{'comment': 'I think this line should be inside the try block as well to guarantee that input is always closed. Or, alternatively, it may be before the first line if order does not matter.', 'commenter': 'zivanfi'}]"
177,lang/java/avro/src/main/java/org/apache/avro/file/DataFileWriter.java,"@@ -190,11 +190,17 @@ public boolean isFlushOnEveryBlock() {
 
   /** Open a writer appending to an existing file. */
   public DataFileWriter<D> appendTo(File file) throws IOException {
-    return appendTo(new SeekableFileInput(file),
-                    new SyncableFileOutputStream(file, true));
+    SeekableInput input = new SeekableFileInput(file);
+    OutputStream output = new SyncableFileOutputStream(file, true);
+    try {
+      return appendTo(input, output);
+    } finally {
+      input.close();","[{'comment': 'Could you please add a comment about why output does not have to be closed?', 'commenter': 'zivanfi'}, {'comment': 'good point. Will do it.', 'commenter': 'gszadovszky'}]"
177,lang/java/avro/src/main/java/org/apache/avro/file/DataFileWriter.java,"@@ -190,11 +190,17 @@ public boolean isFlushOnEveryBlock() {
 
   /** Open a writer appending to an existing file. */
   public DataFileWriter<D> appendTo(File file) throws IOException {
-    return appendTo(new SeekableFileInput(file),
-                    new SyncableFileOutputStream(file, true));
+    SeekableInput input = new SeekableFileInput(file);
+    OutputStream output = new SyncableFileOutputStream(file, true);
+    try {
+      return appendTo(input, output);
+    } finally {
+      input.close();
+    }
   }
 
   /** Open a writer appending to an existing file.
+   * <strong>Since 1.9.0 this method does not close in.</strong>","[{'comment': ""1.9.0 is already out. Additionally, isn't this an API breaking change?"", 'commenter': 'zivanfi'}, {'comment': ""Yes, unfortunately, this changes didn't make 1.9.0. And yes, this is an API breaking change so the next target is 1.10.0. Will rewrite the comment."", 'commenter': 'gszadovszky'}, {'comment': ""1.9.0 isn't out yet afaik, so this should be fine as is."", 'commenter': 'busbey'}, {'comment': 'Ah, sorry, I was thinking of Parquet... :(', 'commenter': 'zivanfi'}, {'comment': 'Yes, that was my mistake too :)', 'commenter': 'gszadovszky'}]"
177,lang/java/avro/src/main/java/org/apache/avro/data/Json.java,"@@ -55,8 +56,12 @@ private Json() {}                               // singleton: no public ctor
   public static final Schema SCHEMA;
   static {
     try {","[{'comment': ""Do we have to support Java 1.6 in Avro, or we require 1.7+? I'm wondering if we can use try-with-resource statements instead of closing the stream in finally. Also, can we merge the two nested try{} blocks into one?"", 'commenter': 'nandorKollar'}, {'comment': 'Currently, Avro supports 1.6 so we are not able to use try-with-resources, unfortunately.', 'commenter': 'gszadovszky'}, {'comment': 'We could start discussing dropping 1.6 support in the 1.9.0 release on the dev list.', 'commenter': 'busbey'}]"
177,lang/java/compiler/src/main/java/org/apache/avro/compiler/specific/SpecificCompiler.java,"@@ -270,17 +270,22 @@ File writeToDestination(File src, File destDir) throws IOException {
       if (src != null && f.exists() && f.lastModified() >= src.lastModified())
         return f;                                 // already up to date: ignore
       f.getParentFile().mkdirs();
-      Writer fw;
-      if (outputCharacterEncoding != null) {
-        fw = new OutputStreamWriter(new FileOutputStream(f), outputCharacterEncoding);
-      } else {
-        fw = new FileWriter(f);
-      }
+      Writer fw = null;
+      FileOutputStream fos = null;
       try {
+        if (outputCharacterEncoding != null) {
+          fos = new FileOutputStream(f);
+          fw = new OutputStreamWriter(fos, outputCharacterEncoding);
+        } else {
+          fw = new FileWriter(f);
+        }
         fw.write(FILE_HEADER);
         fw.write(contents);
       } finally {
-        fw.close();
+        if (fw != null)
+          fw.close();
+        if (fos != null)
+          fos.close();","[{'comment': 'It seems to me that the second close() may not be called if the first one throws an IOException.', 'commenter': 'zivanfi'}, {'comment': 'fos.close() is invoked separately to close the file in case of the fw creation fails (fw starts writing at the constructor). If both fos and fw creation was successful than a problem occurs during writing fw.close() shall close the file. If it fails, fos.close() would probably fail too.', 'commenter': 'gszadovszky'}]"
194,lang/java/avro/src/test/java/org/apache/avro/TestFixed.java,"@@ -0,0 +1,19 @@
+package org.apache.avro;
+
+import org.junit.Assert;
+import org.junit.Test;
+
+public class TestFixed {
+
+
+  @Test
+  public void testFixedDefaultValueDrop() {","[{'comment': 'The code looks good to me.\r\nMy concerns are with the tests. \r\nWhy is this a new class and not merged into SchemaBuilder?', 'commenter': 'spacharya'}, {'comment': 'The main reason I created a separate unit test is that the issue is not only in the schema builder, it is also in the JacksonUtils.java... ', 'commenter': 'zolyfarkas'}]"
195,lang/java/pom.xml,"@@ -33,6 +33,13 @@
   <url>http://avro.apache.org</url>
   <description>Avro parent Java project</description>
 
+  <licenses>
+    <license>
+      <name>Apache License, Version 2.0</name>
+      <url>http://www.apache.org/licenses/LICENSE-2.0</url>","[{'comment': 'You want to make this <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>\r\nYou want a text file and not an HTML file. ', 'commenter': 'spacharya'}, {'comment': 'done', 'commenter': 'benmccann'}]"
199,lang/java/avro/src/test/java/org/apache/avro/TestReadingWritingDataInEvolvedSchemas.java,"@@ -0,0 +1,268 @@
+package org.apache.avro;","[{'comment': 'Missing headers for the apache license', 'commenter': 'spacharya'}, {'comment': 'Added ASL (copied from other test class). Updated same commit (amend, push -f)', 'commenter': 'epkanol'}, {'comment': ""@harshach my branch (actually, the same commit) was updated 10th of April, don't know what else to do. Waiting for your review and acceptance/merge into master.\r\nThe Apache License was added to my new file, and the reason the // is there in the file is in order to preserve formatting across IDEs (My Eclipse has been acting erratically lately - Neon upgrade issue)"", 'commenter': 'epkanol'}]"
199,lang/java/avro/src/test/java/org/apache/avro/TestReadingWritingDataInEvolvedSchemas.java,"@@ -0,0 +1,268 @@
+package org.apache.avro;
+
+import static org.junit.Assert.assertArrayEquals;
+import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertNull;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+
+import org.apache.avro.generic.GenericData;
+import org.apache.avro.generic.GenericData.EnumSymbol;
+import org.apache.avro.generic.GenericData.Record;
+import org.apache.avro.generic.GenericDatumReader;
+import org.apache.avro.generic.GenericDatumWriter;
+import org.apache.avro.generic.GenericRecord;
+import org.apache.avro.io.DatumWriter;
+import org.apache.avro.io.Decoder;
+import org.apache.avro.io.DecoderFactory;
+import org.apache.avro.io.Encoder;
+import org.apache.avro.io.EncoderFactory;
+import org.junit.Rule;
+import org.junit.Test;
+import org.junit.rules.ExpectedException;
+
+public class TestReadingWritingDataInEvolvedSchemas {
+
+  private static final String RECORD_A = ""RecordA"";
+  private static final String FIELD_A = ""fieldA"";
+  private static final char LATIN_SMALL_LETTER_O_WITH_DIARESIS = '\u00F6';
+  
+  @Rule
+  public ExpectedException expectedException = ExpectedException.none();
+  //","[{'comment': 'not sure why ```//``` present on multiple lines.', 'commenter': 'spacharya'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -411,29 +402,267 @@ private SchemaCompatibilityType calculateCompatibility(
         }
       }
     }
+
+    private SchemaCompatibilityResult checkReaderWriterRecordFields(final Schema reader,
+        final Schema writer) {
+      // Check that each field in the reader record can be populated from
+      // the writer record:
+      for (final Field readerField : reader.getFields()) {
+        final Field writerField = lookupWriterField(writer, readerField);
+        if (writerField == null) {
+          // Reader field does not correspond to any field in the writer
+          // record schema, so the reader field must have a default value.
+          if (readerField.defaultValue() == null) {
+            // reader field has no default value
+            return SchemaCompatibilityResult.incompatible(
+                SchemaIncompatibilityType.READER_FIELD_MISSING_DEFAULT_VALUE, reader, writer,
+                readerField.name());
+          }
+        } else {
+          SchemaCompatibilityResult compatibility = getCompatibility(readerField.schema(),
+              writerField.schema());
+          if (compatibility.getCompatibility() == SchemaCompatibilityType.INCOMPATIBLE) {
+            return compatibility;
+          }
+        }
+      }
+      // All fields in the reader record can be populated from the writer
+      // record:
+      return SchemaCompatibilityResult.compatible();
+    }
+
+    private SchemaCompatibilityResult checkReaderEnumContainsAllWriterEnumSymbols(
+        final Schema reader, final Schema writer) {
+      final Set<String> symbols = new TreeSet<String>(writer.getEnumSymbols());
+      symbols.removeAll(reader.getEnumSymbols());
+      return symbols.isEmpty()
+          ? SchemaCompatibilityResult.compatible()
+          : SchemaCompatibilityResult.incompatible(
+              SchemaIncompatibilityType.MISSING_ENUM_SYMBOLS, reader, writer,
+              symbols.toString());
+    }
+
+    private SchemaCompatibilityResult checkFixedSize(final Schema reader, final Schema writer) {
+      int actual = reader.getFixedSize();
+      int expected = writer.getFixedSize();
+      if (actual != expected) {
+        String msg = String.format(""expected: %d, found: %d"", expected, actual);
+        return SchemaCompatibilityResult.incompatible(
+            SchemaIncompatibilityType.FIXED_SIZE_MISMATCH, reader,
+            writer, msg);
+      }
+      return SchemaCompatibilityResult.compatible();
+    }
+
+    private SchemaCompatibilityResult checkSchemaNames(final Schema reader, final Schema writer) {
+      if (!schemaNameEquals(reader, writer)) {
+        String msg = String.format(""expected: %s"", writer.getFullName());
+        return SchemaCompatibilityResult.incompatible(
+            SchemaIncompatibilityType.NAME_MISMATCH,
+            reader, writer, msg);
+      }
+      return SchemaCompatibilityResult.compatible();
+    }
+
+    private SchemaCompatibilityResult typeMismatch(final Schema reader, final Schema writer) {
+      String msg = String.format(""reader type: %s not compatible with writer type: %s"",
+          reader.getType(), writer.getType());
+      return SchemaCompatibilityResult.incompatible(SchemaIncompatibilityType.TYPE_MISMATCH,
+          reader, writer, msg);
+    }
   }
 
-  /**
-   * Identifies the type of a schema compatibility result.
-   */
-  public static enum SchemaCompatibilityType {
-    COMPATIBLE,
-    INCOMPATIBLE,
+  /** Identifies the type of a schema compatibility result. */
+  public enum SchemaCompatibilityType {
+    COMPATIBLE, //
+    INCOMPATIBLE, //
 
-    /** Used internally to tag a reader/writer schema pair and prevent recursion. */
+    /**
+     * Used internally to tag a reader/writer schema pair and prevent recursion.
+     */
     RECURSION_IN_PROGRESS;
   }
 
+  public enum SchemaIncompatibilityType {
+    NAME_MISMATCH, //
+    FIXED_SIZE_MISMATCH, //
+    MISSING_ENUM_SYMBOLS, //
+    READER_FIELD_MISSING_DEFAULT_VALUE, //
+    TYPE_MISMATCH, //
+    MISSING_UNION_BRANCH;
+  }
+
+  /**
+   * Immutable class representing details about a particular schema pair
+   * compatibility check.
+   */
+  public static final class SchemaCompatibilityResult {
+    private final SchemaCompatibilityType mCompatibility;
+    // the below fields are only valid if INCOMPATIBLE
+    private final SchemaIncompatibilityType mSchemaIncompatibilityType;
+    private final Schema mReaderSubset;
+    private final Schema mWriterSubset;
+    private final String mMessage;
+    // cached objects for stateless details
+    private static final SchemaCompatibilityResult COMPATIBLE = new SchemaCompatibilityResult(
+        SchemaCompatibilityType.COMPATIBLE, null, null, null, null);
+    private static final SchemaCompatibilityResult RECURSION_IN_PROGRESS = new SchemaCompatibilityResult(
+        SchemaCompatibilityType.RECURSION_IN_PROGRESS, null, null, null, null);
+
+    private SchemaCompatibilityResult(SchemaCompatibilityType type,
+        SchemaIncompatibilityType errorDetails,
+        Schema readerDetails, Schema writerDetails, String details) {
+      this.mCompatibility = type;
+      this.mSchemaIncompatibilityType = errorDetails;
+      this.mReaderSubset = readerDetails;
+      this.mWriterSubset = writerDetails;
+      this.mMessage = details;
+    }
+
+    /**
+     * Returns a details object representing a compatible schema pair.
+     * @return a SchemaCompatibilityDetails object with COMPATIBLE
+     *         SchemaCompatibilityType, and no other state.
+     */
+    public static SchemaCompatibilityResult compatible() {
+      return COMPATIBLE;
+    }
+
+    /**
+     * Returns a details object representing a state indicating that recursion
+     * is in progress.
+     * @return a SchemaCompatibilityDetails object with RECURSION_IN_PROGRESS
+     *         SchemaCompatibilityType, and no other state.
+     */
+    public static SchemaCompatibilityResult recursionInProgress() {
+      return RECURSION_IN_PROGRESS;
+    }
+
+    /**
+     * Returns a details object representing an incompatible schema pair,
+     * including error details.
+     * @return a SchemaCompatibilityDetails object with INCOMPATIBLE
+     *         SchemaCompatibilityType, and state representing the violating
+     *         part.
+     */
+    public static SchemaCompatibilityResult incompatible(SchemaIncompatibilityType error,
+        Schema reader, Schema writer, String details) {
+      return new SchemaCompatibilityResult(SchemaCompatibilityType.INCOMPATIBLE, error, reader,
+          writer, details);
+    }
+
+    /**
+     * Returns the SchemaCompatibilityType, always non-null.
+     * @return a SchemaCompatibilityType instance, always non-null
+     */
+    public SchemaCompatibilityType getCompatibility() {
+      return mCompatibility;
+    }
+
+    /**
+     * If the compatibility is INCOMPATIBLE, returns the
+     * SchemaIncompatibilityType (first thing that was incompatible), otherwise
+     * null.
+     * @return a SchemaIncompatibilityType instance, or null
+     */
+    public SchemaIncompatibilityType getIncompatibility() {
+      return mSchemaIncompatibilityType;
+    }
+
+    /**
+     * If the compatibility is INCOMPATIBLE, returns the first part of the
+     * reader schema that failed compatibility check.
+     * @return a Schema instance (part of the reader schema), or null
+     */
+    public Schema getReaderSubset() {
+      return mReaderSubset;
+    }
+
+    /**
+     * If the compatibility is INCOMPATIBLE, returns the first part of the
+     * writer schema that failed compatibility check.
+     * @return a Schema instance (part of the writer schema), or null
+     */
+    public Schema getWriterSubset() {
+      return mWriterSubset;
+    }
+
+    /**
+     * If the compatibility is INCOMPATIBLE, returns a human-readable string
+     * with more details about what failed. Syntax depends on the
+     * SchemaIncompatibilityType.
+     * @see #getIncompatibility()
+     * @return a String with details about the incompatibility, or null
+     */
+    public String getMessage() {
+      return mMessage;
+    }
+
+    /** {@inheritDoc} */
+    @Override
+    public int hashCode() {
+      final int prime = 31;
+      int result = 1;
+      result = prime * result + ((mMessage == null) ? 0 : mMessage.hashCode());
+      result = prime * result + ((mReaderSubset == null) ? 0 : mReaderSubset.hashCode());
+      result = prime * result
+          + ((mCompatibility == null) ? 0 : mCompatibility.hashCode());
+      result = prime * result
+          + ((mSchemaIncompatibilityType == null) ? 0 : mSchemaIncompatibilityType.hashCode());
+      result = prime * result + ((mWriterSubset == null) ? 0 : mWriterSubset.hashCode());
+      return result;
+    }
+
+    /** {@inheritDoc} */
+    @Override
+    public boolean equals(Object obj) {
+      if (this == obj)","[{'comment': 'given multiple if statements it will good to have braces around them to separate it out', 'commenter': 'harshach'}, {'comment': ""Thx for spotting this, I don't know why Eclipse Neon started using brace-less equals method, I have set it to always use braces otherwise.\r\nI updated the commit in my repo (push -f)\r\nDoes anyone know of a code-style-template that can be imported into either Eclipse or Idea?"", 'commenter': 'epkanol'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -451,35 +686,40 @@ private SchemaCompatibilityType calculateCompatibility(
 
     /**
      * Constructs a new instance.
-     *
      * @param type of the schema compatibility.","[{'comment': ""Looks like 'type' was renamed to 'result', could you please modify the Javadoc accordingly?"", 'commenter': 'nandorKollar'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -20,20 +20,19 @@
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.HashMap;
-import java.util.HashSet;
 import java.util.List;
 import java.util.Map;
 import java.util.Set;
-
+import java.util.TreeSet;
 import org.apache.avro.Schema.Field;
 import org.apache.avro.Schema.Type;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 /**
- * Evaluate the compatibility between a reader schema and a writer schema.
- * A reader and a writer schema are declared compatible if all datum instances of the writer","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}, {'comment': ""New try, where I manually tried to minimize the formatting differences wrt. master\r\nBut, I must say, it would help development a great deal if Avro could settle on a common coding standard.\r\nWhen reformatting this, I tried following the existing guidelines (Java Lang conventions, and used 100 column width).\r\nSince the early '00's, I have delegated formatting to tools (IDEs). Agreed, not all developers use an IDE, but there are compatibility checkers that can be used to validate compliance (e.g. CheckStyle...)"", 'commenter': 'epkanol'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -43,56 +42,47 @@ private SchemaCompatibility() {
   }
 
   /** Message to annotate reader/writer schema pairs that are compatible. */
-  public static final String READER_WRITER_COMPATIBLE_MESSAGE =
-      ""Reader schema can always successfully decode data written using the writer schema."";","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -43,56 +42,47 @@ private SchemaCompatibility() {
   }
 
   /** Message to annotate reader/writer schema pairs that are compatible. */
-  public static final String READER_WRITER_COMPATIBLE_MESSAGE =
-      ""Reader schema can always successfully decode data written using the writer schema."";
+  public static final String READER_WRITER_COMPATIBLE_MESSAGE = ""Reader schema can always successfully decode data written using the writer schema."";
 
   /**
    * Validates that the provided reader schema can be used to decode avro data written with the
    * provided writer schema.
-   *
    * @param reader schema to check.
    * @param writer schema to check.
    * @return a result object identifying any compatibility errors.
    */
-  public static SchemaPairCompatibility checkReaderWriterCompatibility(
-      final Schema reader,
-      final Schema writer
-  ) {
-    final SchemaCompatibilityType compatibility =
-        new ReaderWriterCompatiblityChecker()
-            .getCompatibility(reader, writer);
+  public static SchemaPairCompatibility checkReaderWriterCompatibility(final Schema reader,","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting. It is very difficult to tell what are the changes that make the code behave differently vs. just different formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -43,56 +42,47 @@ private SchemaCompatibility() {
   }
 
   /** Message to annotate reader/writer schema pairs that are compatible. */
-  public static final String READER_WRITER_COMPATIBLE_MESSAGE =
-      ""Reader schema can always successfully decode data written using the writer schema."";
+  public static final String READER_WRITER_COMPATIBLE_MESSAGE = ""Reader schema can always successfully decode data written using the writer schema."";
 
   /**
    * Validates that the provided reader schema can be used to decode avro data written with the
    * provided writer schema.
-   *
    * @param reader schema to check.
    * @param writer schema to check.
    * @return a result object identifying any compatibility errors.
    */
-  public static SchemaPairCompatibility checkReaderWriterCompatibility(
-      final Schema reader,
-      final Schema writer
-  ) {
-    final SchemaCompatibilityType compatibility =
-        new ReaderWriterCompatiblityChecker()
-            .getCompatibility(reader, writer);
+  public static SchemaPairCompatibility checkReaderWriterCompatibility(final Schema reader,
+      final Schema writer) {
+    final SchemaCompatibilityResult compatibility = new ReaderWriterCompatiblityChecker()
+        .getCompatibility(reader, writer);
 
     final String message;
-    switch (compatibility) {
+    switch (compatibility.getCompatibility()) {
       case INCOMPATIBLE: {
         message = String.format(
             ""Data encoded using writer schema:%n%s%n""
-            + ""will or may fail to decode using reader schema:%n%s%n"",
-            writer.toString(true),
-            reader.toString(true));","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -43,56 +42,47 @@ private SchemaCompatibility() {
   }
 
   /** Message to annotate reader/writer schema pairs that are compatible. */
-  public static final String READER_WRITER_COMPATIBLE_MESSAGE =
-      ""Reader schema can always successfully decode data written using the writer schema."";
+  public static final String READER_WRITER_COMPATIBLE_MESSAGE = ""Reader schema can always successfully decode data written using the writer schema."";
 
   /**
    * Validates that the provided reader schema can be used to decode avro data written with the
    * provided writer schema.
-   *
    * @param reader schema to check.
    * @param writer schema to check.
    * @return a result object identifying any compatibility errors.
    */
-  public static SchemaPairCompatibility checkReaderWriterCompatibility(
-      final Schema reader,
-      final Schema writer
-  ) {
-    final SchemaCompatibilityType compatibility =
-        new ReaderWriterCompatiblityChecker()
-            .getCompatibility(reader, writer);
+  public static SchemaPairCompatibility checkReaderWriterCompatibility(final Schema reader,
+      final Schema writer) {
+    final SchemaCompatibilityResult compatibility = new ReaderWriterCompatiblityChecker()
+        .getCompatibility(reader, writer);
 
     final String message;
-    switch (compatibility) {
+    switch (compatibility.getCompatibility()) {
       case INCOMPATIBLE: {
         message = String.format(
             ""Data encoded using writer schema:%n%s%n""
-            + ""will or may fail to decode using reader schema:%n%s%n"",
-            writer.toString(true),
-            reader.toString(true));
+                + ""will or may fail to decode using reader schema:%n%s%n"",
+            writer.toString(true), reader.toString(true));
         break;
       }
       case COMPATIBLE: {
         message = READER_WRITER_COMPATIBLE_MESSAGE;
         break;
       }
-      default: throw new AvroRuntimeException(""Unknown compatibility: "" + compatibility);
+      default:
+        throw new AvroRuntimeException(""Unknown compatibility: "" + compatibility);
     }
 
-    return new SchemaPairCompatibility(
-        compatibility,
-        reader,
-        writer,
-        message);
+    return new SchemaPairCompatibility(compatibility, reader, writer, message);","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -43,56 +42,47 @@ private SchemaCompatibility() {
   }
 
   /** Message to annotate reader/writer schema pairs that are compatible. */
-  public static final String READER_WRITER_COMPATIBLE_MESSAGE =
-      ""Reader schema can always successfully decode data written using the writer schema."";
+  public static final String READER_WRITER_COMPATIBLE_MESSAGE = ""Reader schema can always successfully decode data written using the writer schema."";
 
   /**
    * Validates that the provided reader schema can be used to decode avro data written with the
    * provided writer schema.
-   *
    * @param reader schema to check.
    * @param writer schema to check.
    * @return a result object identifying any compatibility errors.
    */
-  public static SchemaPairCompatibility checkReaderWriterCompatibility(
-      final Schema reader,
-      final Schema writer
-  ) {
-    final SchemaCompatibilityType compatibility =
-        new ReaderWriterCompatiblityChecker()
-            .getCompatibility(reader, writer);
+  public static SchemaPairCompatibility checkReaderWriterCompatibility(final Schema reader,
+      final Schema writer) {
+    final SchemaCompatibilityResult compatibility = new ReaderWriterCompatiblityChecker()
+        .getCompatibility(reader, writer);
 
     final String message;
-    switch (compatibility) {
+    switch (compatibility.getCompatibility()) {
       case INCOMPATIBLE: {
         message = String.format(
             ""Data encoded using writer schema:%n%s%n""
-            + ""will or may fail to decode using reader schema:%n%s%n"",
-            writer.toString(true),
-            reader.toString(true));
+                + ""will or may fail to decode using reader schema:%n%s%n"",
+            writer.toString(true), reader.toString(true));
         break;
       }
       case COMPATIBLE: {
         message = READER_WRITER_COMPATIBLE_MESSAGE;
         break;
       }
-      default: throw new AvroRuntimeException(""Unknown compatibility: "" + compatibility);
+      default:
+        throw new AvroRuntimeException(""Unknown compatibility: "" + compatibility);
     }
 
-    return new SchemaPairCompatibility(
-        compatibility,
-        reader,
-        writer,
-        message);
+    return new SchemaPairCompatibility(compatibility, reader, writer, message);
   }
 
   // -----------------------------------------------------------------------------------------------
 
   /**
    * Tests the equality of two Avro named schemas.
-   *
-   * <p> Matching includes reader name aliases. </p>
-   *
+   * <p>
+   * Matching includes reader name aliases.","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -132,8 +122,10 @@ public static Field lookupWriterField(final Schema writerSchema, final Field rea
       }
     }
     switch (writerFields.size()) {
-      case 0: return null;
-      case 1: return writerFields.get(0);
+      case 0:","[{'comment': ""This one is more tricky, I would personally also revert this, even though it makes the code more readable, it's still not a change that functionally changes the code - though this could be argued about. "", 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -143,17 +135,15 @@ public static Field lookupWriterField(final Schema writerSchema, final Field rea
   }
 
   /**
-   * Reader/writer schema pair that can be used as a key in a hash map.
-   *
-   * This reader/writer pair differentiates Schema objects based on their system hash code.
+   * Reader/writer schema pair that can be used as a key in a hash map. This reader/writer pair","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -192,8 +182,7 @@ public boolean equals(Object obj) {
       }
       final ReaderWriter that = (ReaderWriter) obj;
       // Use pointer comparison here:
-      return (this.mReader == that.mReader)
-          && (this.mWriter == that.mWriter);","[{'comment': 'Please revert to the original formatting, as there was no impactful change here, except for formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -111,16 +101,16 @@ public static boolean schemaNameEquals(final Schema reader, final Schema writer)
 
   /**
    * Identifies the writer field that corresponds to the specified reader field.
-   *
-   * <p> Matching includes reader name aliases. </p>
-   *
+   * <p>
+   * Matching includes reader name aliases.
+   * </p>
    * @param writerSchema Schema of the record where to look for the writer field.
    * @param readerField Reader field to identify the corresponding writer field of.
    * @return the writer field, if any does correspond, or None.
    */
   public static Field lookupWriterField(final Schema writerSchema, final Field readerField) {
     assert (writerSchema.getType() == Type.RECORD);
-    final List<Field> writerFields = new ArrayList<Field>();
+    final List<Field> writerFields = new ArrayList<>();","[{'comment': 'This is a more interesting one, as it makes sense to switch to using type inference... but since there is no functional code change anywhere around this line, reverting it would make reviewing this patch easier.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -143,17 +135,15 @@ public static Field lookupWriterField(final Schema writerSchema, final Field rea
   }
 
   /**
-   * Reader/writer schema pair that can be used as a key in a hash map.
-   *
-   * This reader/writer pair differentiates Schema objects based on their system hash code.
+   * Reader/writer schema pair that can be used as a key in a hash map. This reader/writer pair
+   * differentiates Schema objects based on their system hash code.
    */
   private static final class ReaderWriter {
     private final Schema mReader;
     private final Schema mWriter;
 
     /**
      * Initializes a new reader/writer pair.
-     *","[{'comment': 'Please revert to the original formatting', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -205,59 +194,52 @@ public String toString() {
 
   /**
    * Determines the compatibility of a reader/writer schema pair.
-   *
-   * <p> Provides memoization to handle recursive schemas. </p>
+   * <p>","[{'comment': 'Please revert to the original formatting.', 'commenter': 'commanderofthegrey'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java,"@@ -427,58 +350,29 @@ public void testUnionReaderWriterSubsetIncompatibility() {
 
   // -----------------------------------------------------------------------------------------------
 
-  /** Collection of reader/writer schema pair that are incompatible. */
-  public static final List<ReaderWriter> INCOMPATIBLE_READER_WRITER_TEST_CASES = list(
-      new ReaderWriter(NULL_SCHEMA, INT_SCHEMA),
-      new ReaderWriter(NULL_SCHEMA, LONG_SCHEMA),
-
-      new ReaderWriter(BOOLEAN_SCHEMA, INT_SCHEMA),
-
-      new ReaderWriter(INT_SCHEMA, NULL_SCHEMA),
-      new ReaderWriter(INT_SCHEMA, BOOLEAN_SCHEMA),
-      new ReaderWriter(INT_SCHEMA, LONG_SCHEMA),
-      new ReaderWriter(INT_SCHEMA, FLOAT_SCHEMA),
-      new ReaderWriter(INT_SCHEMA, DOUBLE_SCHEMA),
-
-      new ReaderWriter(LONG_SCHEMA, FLOAT_SCHEMA),
-      new ReaderWriter(LONG_SCHEMA, DOUBLE_SCHEMA),
-
-      new ReaderWriter(FLOAT_SCHEMA, DOUBLE_SCHEMA),
-
-      new ReaderWriter(STRING_SCHEMA, BOOLEAN_SCHEMA),
-      new ReaderWriter(STRING_SCHEMA, INT_SCHEMA),
-
-      new ReaderWriter(BYTES_SCHEMA, NULL_SCHEMA),
-      new ReaderWriter(BYTES_SCHEMA, INT_SCHEMA),
-
-      new ReaderWriter(INT_ARRAY_SCHEMA, LONG_ARRAY_SCHEMA),
-      new ReaderWriter(INT_MAP_SCHEMA, INT_ARRAY_SCHEMA),
-      new ReaderWriter(INT_ARRAY_SCHEMA, INT_MAP_SCHEMA),
-      new ReaderWriter(INT_MAP_SCHEMA, LONG_MAP_SCHEMA),
-
-      new ReaderWriter(ENUM1_AB_SCHEMA, ENUM1_ABC_SCHEMA),
-      new ReaderWriter(ENUM1_BC_SCHEMA, ENUM1_ABC_SCHEMA),
-
-      new ReaderWriter(ENUM1_AB_SCHEMA, ENUM2_AB_SCHEMA),
-      new ReaderWriter(INT_SCHEMA, ENUM2_AB_SCHEMA),
-      new ReaderWriter(ENUM2_AB_SCHEMA, INT_SCHEMA),
-
-      // Tests involving unions:
-      new ReaderWriter(INT_UNION_SCHEMA, INT_STRING_UNION_SCHEMA),
-      new ReaderWriter(STRING_UNION_SCHEMA, INT_STRING_UNION_SCHEMA),
-      new ReaderWriter(FLOAT_SCHEMA, INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA),
-      new ReaderWriter(LONG_SCHEMA, INT_FLOAT_UNION_SCHEMA),
-      new ReaderWriter(INT_SCHEMA, INT_FLOAT_UNION_SCHEMA),
-
-      new ReaderWriter(EMPTY_RECORD2, EMPTY_RECORD1),
-      new ReaderWriter(A_INT_RECORD1, EMPTY_RECORD1),
-      new ReaderWriter(A_INT_B_DINT_RECORD1, EMPTY_RECORD1),
-
-      new ReaderWriter(INT_LIST_RECORD, LONG_LIST_RECORD),
-
-      // Last check:
-      new ReaderWriter(NULL_SCHEMA, INT_SCHEMA)
-  );
+  /**","[{'comment': 'I think you can delete this comment now, since it is only informative in context of the current change.', 'commenter': 'nandorKollar'}, {'comment': 'Done', 'commenter': 'epkanol'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java,"@@ -15,183 +15,316 @@
  * implied.  See the License for the specific language governing","[{'comment': 'I really like the idea of running these tests on compatible-incompatible pairs, especially since it revealed a bug too!', 'commenter': 'nandorKollar'}, {'comment': 'Although some are redundant, I revived the old tests as well as my new additions.\r\nLike you say, this PR is big enough as it is - if we decide to clean up, it could be done in another PR', 'commenter': 'epkanol'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java,"@@ -15,183 +15,316 @@
  * implied.  See the License for the specific language governing
  * permissions and limitations under the License.
  */
-
 package org.apache.avro;
 
+import static org.apache.avro.TestSchemas.A_DINT_B_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_B_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_B_INT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_RECORD1;
+import static org.apache.avro.TestSchemas.A_LONG_RECORD1;
+import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
+import static org.apache.avro.TestSchemas.BYTES_SCHEMA;
+import static org.apache.avro.TestSchemas.BYTES_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.DOUBLE_SCHEMA;
+import static org.apache.avro.TestSchemas.DOUBLE_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
+import static org.apache.avro.TestSchemas.EMPTY_RECORD2;
+import static org.apache.avro.TestSchemas.EMPTY_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_ABC_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_BC_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM2_AB_SCHEMA;
+import static org.apache.avro.TestSchemas.FLOAT_SCHEMA;
+import static org.apache.avro.TestSchemas.FLOAT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_FLOAT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_LIST_RECORD;
+import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_LONG_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_STRING_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_ARRAY_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_LIST_RECORD;
+import static org.apache.avro.TestSchemas.LONG_MAP_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.NULL_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_INT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.list;
+
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
 
-import org.apache.avro.reflect.ReflectData;
+import org.apache.avro.TestSchemas.ReaderWriter;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.ExpectedException;
 
 public class TestSchemaValidation {
 
-  SchemaValidatorBuilder builder = new SchemaValidatorBuilder();
+  @Rule
+  public ExpectedException expectedException = ExpectedException.none();
+  
+  /** Collection of reader/writer schema pair that are compatible. */
+  public static final List<ReaderWriter> COMPATIBLE_READER_WRITER_TEST_CASES = list(
+      new ReaderWriter(BOOLEAN_SCHEMA, BOOLEAN_SCHEMA),
 
-  Schema rec = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().intType().intDefault(1)
-      .name(""b"").type().longType().noDefault()
-      .endRecord();
+      new ReaderWriter(INT_SCHEMA, INT_SCHEMA),
 
-  Schema rec2 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().intType().intDefault(1)
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      new ReaderWriter(LONG_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, LONG_SCHEMA),
 
-  Schema rec3 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      // Avro spec says INT/LONG can be promoted to FLOAT/DOUBLE.
+      // This is arguable as this causes a loss of precision.
+      new ReaderWriter(FLOAT_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(FLOAT_SCHEMA, LONG_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, LONG_SCHEMA),
 
-  Schema rec4 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().noDefault()
-      .endRecord();
+      new ReaderWriter(DOUBLE_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, FLOAT_SCHEMA),
 
-  Schema rec5 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().stringType().stringDefault("""") // different type from original
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      new ReaderWriter(STRING_SCHEMA, STRING_SCHEMA),
 
-  @Test
-  public void testAllTypes() throws SchemaValidationException {
-    Schema s = SchemaBuilder.record(""r"").fields()
-        .requiredBoolean(""boolF"")
-        .requiredInt(""intF"")
-        .requiredLong(""longF"")
-        .requiredFloat(""floatF"")
-        .requiredDouble(""doubleF"")
-        .requiredString(""stringF"")
-        .requiredBytes(""bytesF"")
-        .name(""fixedF1"").type().fixed(""F1"").size(1).noDefault()
-        .name(""enumF"").type().enumeration(""E1"").symbols(""S"").noDefault()
-        .name(""mapF"").type().map().values().stringType().noDefault()
-        .name(""arrayF"").type().array().items().stringType().noDefault()
-        .name(""recordF"").type().record(""inner"").fields()
-        .name(""f"").type().intType().noDefault()
-        .endRecord().noDefault()
-        .optionalBoolean(""boolO"")
-        .endRecord();
-    testValidatorPasses(builder.mutualReadStrategy().validateLatest(), s, s);
-  }
+      new ReaderWriter(BYTES_SCHEMA, BYTES_SCHEMA),
 
-  @Test
-  public void testReadOnePrior() throws SchemaValidationException {
-    testValidatorPasses(builder.canReadStrategy().validateLatest(), rec3, rec);
-    testValidatorPasses(builder.canReadStrategy().validateLatest(), rec5, rec3);
-    testValidatorFails(builder.canReadStrategy().validateLatest(), rec4, rec);
-  }
+      new ReaderWriter(INT_ARRAY_SCHEMA, INT_ARRAY_SCHEMA),
+      new ReaderWriter(LONG_ARRAY_SCHEMA, INT_ARRAY_SCHEMA),
+      new ReaderWriter(INT_MAP_SCHEMA, INT_MAP_SCHEMA),
+      new ReaderWriter(LONG_MAP_SCHEMA, INT_MAP_SCHEMA),
 
-  @Test
-  public void testReadAllPrior() throws SchemaValidationException {
-    testValidatorPasses(builder.canReadStrategy().validateAll(), rec3, rec, rec2);
-    testValidatorFails(builder.canReadStrategy().validateAll(), rec4, rec, rec2, rec3);
-    testValidatorFails(builder.canReadStrategy().validateAll(), rec5, rec, rec2, rec3);
-  }
+      new ReaderWriter(ENUM1_AB_SCHEMA, ENUM1_AB_SCHEMA),
+      new ReaderWriter(ENUM1_ABC_SCHEMA, ENUM1_AB_SCHEMA),
 
-  @Test
-  public void testOnePriorCanRead() throws SchemaValidationException {
-    testValidatorPasses(builder.canBeReadStrategy().validateLatest(), rec, rec3);
-    testValidatorFails(builder.canBeReadStrategy().validateLatest(), rec, rec4);
-  }
+      // String-to/from-bytes, introduced in Avro 1.7.7
+      new ReaderWriter(STRING_SCHEMA, BYTES_SCHEMA),
+      new ReaderWriter(BYTES_SCHEMA, STRING_SCHEMA),
 
-  @Test
-  public void testAllPriorCanRead() throws SchemaValidationException {
-    testValidatorPasses(builder.canBeReadStrategy().validateAll(), rec, rec3, rec2);
-    testValidatorFails(builder.canBeReadStrategy().validateAll(), rec, rec4, rec3, rec2);
-  }
+      // Tests involving unions:
+      new ReaderWriter(EMPTY_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(INT_UNION_SCHEMA, INT_UNION_SCHEMA),
+      new ReaderWriter(INT_STRING_UNION_SCHEMA, STRING_INT_UNION_SCHEMA),
+      new ReaderWriter(INT_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(LONG_UNION_SCHEMA, INT_UNION_SCHEMA),
+      // float unions cannot read int or long unions
+      // new ReaderWriter(FLOAT_UNION_SCHEMA, INT_UNION_SCHEMA),
+      // new ReaderWriter(FLOAT_UNION_SCHEMA, LONG_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, INT_UNION_SCHEMA),
+      new ReaderWriter(LONG_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, LONG_UNION_SCHEMA),
+      new ReaderWriter(FLOAT_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, FLOAT_UNION_SCHEMA),
+      new ReaderWriter(STRING_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(STRING_UNION_SCHEMA, BYTES_UNION_SCHEMA),
+      new ReaderWriter(BYTES_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(BYTES_UNION_SCHEMA, STRING_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, INT_FLOAT_UNION_SCHEMA),
 
-  @Test
-  public void testOnePriorCompatible() throws SchemaValidationException {
-    testValidatorPasses(builder.mutualReadStrategy().validateLatest(), rec, rec3);
-    testValidatorFails(builder.mutualReadStrategy().validateLatest(), rec, rec4);
-  }
+      // Readers capable of reading all branches of a union are compatible
+      new ReaderWriter(FLOAT_SCHEMA, INT_FLOAT_UNION_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, INT_LONG_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, INT_FLOAT_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA),
 
-  @Test
-  public void testAllPriorCompatible() throws SchemaValidationException {
-    testValidatorPasses(builder.mutualReadStrategy().validateAll(), rec, rec3, rec2);
-    testValidatorFails(builder.mutualReadStrategy().validateAll(), rec, rec4, rec3, rec2);
-  }
+      // Special case of singleton unions:
+      new ReaderWriter(FLOAT_SCHEMA, FLOAT_UNION_SCHEMA),
+      new ReaderWriter(INT_UNION_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, INT_UNION_SCHEMA),
 
-  @Test(expected=AvroRuntimeException.class)
-  public void testInvalidBuild() {
-    builder.strategy(null).validateAll();
-  }
+      // Tests involving records:
+      new ReaderWriter(EMPTY_RECORD1, EMPTY_RECORD1),
+      new ReaderWriter(EMPTY_RECORD1, A_INT_RECORD1),
+
+      new ReaderWriter(A_INT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_DINT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_DINT_RECORD1, A_DINT_RECORD1),
+      new ReaderWriter(A_INT_RECORD1, A_DINT_RECORD1),
+
+      new ReaderWriter(A_LONG_RECORD1, A_INT_RECORD1),
+
+      new ReaderWriter(A_INT_RECORD1, A_INT_B_INT_RECORD1),
+      new ReaderWriter(A_DINT_RECORD1, A_INT_B_INT_RECORD1),
+
+      new ReaderWriter(A_INT_B_DINT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_DINT_B_DINT_RECORD1, EMPTY_RECORD1),
+      new ReaderWriter(A_DINT_B_DINT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_INT_B_INT_RECORD1, A_DINT_B_DINT_RECORD1),
+
+      // The SchemaValidator, unlike the SchemaCompatibility class, cannot cope with recursive schemas","[{'comment': 'Hmmm, this is interesting, looks like a bug! Created a Jira: AVRO-2074', 'commenter': 'nandorKollar'}, {'comment': 'Added note of the JIRA ', 'commenter': 'epkanol'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java,"@@ -15,183 +15,316 @@
  * implied.  See the License for the specific language governing
  * permissions and limitations under the License.
  */
-
 package org.apache.avro;
 
+import static org.apache.avro.TestSchemas.A_DINT_B_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_B_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_B_INT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_RECORD1;
+import static org.apache.avro.TestSchemas.A_LONG_RECORD1;
+import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
+import static org.apache.avro.TestSchemas.BYTES_SCHEMA;
+import static org.apache.avro.TestSchemas.BYTES_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.DOUBLE_SCHEMA;
+import static org.apache.avro.TestSchemas.DOUBLE_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
+import static org.apache.avro.TestSchemas.EMPTY_RECORD2;
+import static org.apache.avro.TestSchemas.EMPTY_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_ABC_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_BC_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM2_AB_SCHEMA;
+import static org.apache.avro.TestSchemas.FLOAT_SCHEMA;
+import static org.apache.avro.TestSchemas.FLOAT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_FLOAT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_LIST_RECORD;
+import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_LONG_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_STRING_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_ARRAY_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_LIST_RECORD;
+import static org.apache.avro.TestSchemas.LONG_MAP_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.NULL_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_INT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.list;
+
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
 
-import org.apache.avro.reflect.ReflectData;
+import org.apache.avro.TestSchemas.ReaderWriter;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.ExpectedException;
 
 public class TestSchemaValidation {
 
-  SchemaValidatorBuilder builder = new SchemaValidatorBuilder();
+  @Rule
+  public ExpectedException expectedException = ExpectedException.none();
+  
+  /** Collection of reader/writer schema pair that are compatible. */
+  public static final List<ReaderWriter> COMPATIBLE_READER_WRITER_TEST_CASES = list(
+      new ReaderWriter(BOOLEAN_SCHEMA, BOOLEAN_SCHEMA),
 
-  Schema rec = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().intType().intDefault(1)
-      .name(""b"").type().longType().noDefault()
-      .endRecord();
+      new ReaderWriter(INT_SCHEMA, INT_SCHEMA),
 
-  Schema rec2 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().intType().intDefault(1)
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      new ReaderWriter(LONG_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, LONG_SCHEMA),
 
-  Schema rec3 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      // Avro spec says INT/LONG can be promoted to FLOAT/DOUBLE.
+      // This is arguable as this causes a loss of precision.
+      new ReaderWriter(FLOAT_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(FLOAT_SCHEMA, LONG_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, LONG_SCHEMA),
 
-  Schema rec4 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().noDefault()
-      .endRecord();
+      new ReaderWriter(DOUBLE_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, FLOAT_SCHEMA),
 
-  Schema rec5 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().stringType().stringDefault("""") // different type from original
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      new ReaderWriter(STRING_SCHEMA, STRING_SCHEMA),
 
-  @Test
-  public void testAllTypes() throws SchemaValidationException {
-    Schema s = SchemaBuilder.record(""r"").fields()
-        .requiredBoolean(""boolF"")
-        .requiredInt(""intF"")
-        .requiredLong(""longF"")
-        .requiredFloat(""floatF"")
-        .requiredDouble(""doubleF"")
-        .requiredString(""stringF"")
-        .requiredBytes(""bytesF"")
-        .name(""fixedF1"").type().fixed(""F1"").size(1).noDefault()
-        .name(""enumF"").type().enumeration(""E1"").symbols(""S"").noDefault()
-        .name(""mapF"").type().map().values().stringType().noDefault()
-        .name(""arrayF"").type().array().items().stringType().noDefault()
-        .name(""recordF"").type().record(""inner"").fields()
-        .name(""f"").type().intType().noDefault()
-        .endRecord().noDefault()
-        .optionalBoolean(""boolO"")
-        .endRecord();
-    testValidatorPasses(builder.mutualReadStrategy().validateLatest(), s, s);
-  }
+      new ReaderWriter(BYTES_SCHEMA, BYTES_SCHEMA),
 
-  @Test
-  public void testReadOnePrior() throws SchemaValidationException {
-    testValidatorPasses(builder.canReadStrategy().validateLatest(), rec3, rec);
-    testValidatorPasses(builder.canReadStrategy().validateLatest(), rec5, rec3);
-    testValidatorFails(builder.canReadStrategy().validateLatest(), rec4, rec);
-  }
+      new ReaderWriter(INT_ARRAY_SCHEMA, INT_ARRAY_SCHEMA),
+      new ReaderWriter(LONG_ARRAY_SCHEMA, INT_ARRAY_SCHEMA),
+      new ReaderWriter(INT_MAP_SCHEMA, INT_MAP_SCHEMA),
+      new ReaderWriter(LONG_MAP_SCHEMA, INT_MAP_SCHEMA),
 
-  @Test
-  public void testReadAllPrior() throws SchemaValidationException {
-    testValidatorPasses(builder.canReadStrategy().validateAll(), rec3, rec, rec2);
-    testValidatorFails(builder.canReadStrategy().validateAll(), rec4, rec, rec2, rec3);
-    testValidatorFails(builder.canReadStrategy().validateAll(), rec5, rec, rec2, rec3);
-  }
+      new ReaderWriter(ENUM1_AB_SCHEMA, ENUM1_AB_SCHEMA),
+      new ReaderWriter(ENUM1_ABC_SCHEMA, ENUM1_AB_SCHEMA),
 
-  @Test
-  public void testOnePriorCanRead() throws SchemaValidationException {
-    testValidatorPasses(builder.canBeReadStrategy().validateLatest(), rec, rec3);
-    testValidatorFails(builder.canBeReadStrategy().validateLatest(), rec, rec4);
-  }
+      // String-to/from-bytes, introduced in Avro 1.7.7
+      new ReaderWriter(STRING_SCHEMA, BYTES_SCHEMA),
+      new ReaderWriter(BYTES_SCHEMA, STRING_SCHEMA),
 
-  @Test
-  public void testAllPriorCanRead() throws SchemaValidationException {
-    testValidatorPasses(builder.canBeReadStrategy().validateAll(), rec, rec3, rec2);
-    testValidatorFails(builder.canBeReadStrategy().validateAll(), rec, rec4, rec3, rec2);
-  }
+      // Tests involving unions:
+      new ReaderWriter(EMPTY_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(INT_UNION_SCHEMA, INT_UNION_SCHEMA),
+      new ReaderWriter(INT_STRING_UNION_SCHEMA, STRING_INT_UNION_SCHEMA),
+      new ReaderWriter(INT_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(LONG_UNION_SCHEMA, INT_UNION_SCHEMA),
+      // float unions cannot read int or long unions
+      // new ReaderWriter(FLOAT_UNION_SCHEMA, INT_UNION_SCHEMA),
+      // new ReaderWriter(FLOAT_UNION_SCHEMA, LONG_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, INT_UNION_SCHEMA),
+      new ReaderWriter(LONG_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, LONG_UNION_SCHEMA),
+      new ReaderWriter(FLOAT_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, FLOAT_UNION_SCHEMA),
+      new ReaderWriter(STRING_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(STRING_UNION_SCHEMA, BYTES_UNION_SCHEMA),
+      new ReaderWriter(BYTES_UNION_SCHEMA, EMPTY_UNION_SCHEMA),
+      new ReaderWriter(BYTES_UNION_SCHEMA, STRING_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_UNION_SCHEMA, INT_FLOAT_UNION_SCHEMA),
 
-  @Test
-  public void testOnePriorCompatible() throws SchemaValidationException {
-    testValidatorPasses(builder.mutualReadStrategy().validateLatest(), rec, rec3);
-    testValidatorFails(builder.mutualReadStrategy().validateLatest(), rec, rec4);
-  }
+      // Readers capable of reading all branches of a union are compatible
+      new ReaderWriter(FLOAT_SCHEMA, INT_FLOAT_UNION_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, INT_LONG_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, INT_FLOAT_UNION_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA),
 
-  @Test
-  public void testAllPriorCompatible() throws SchemaValidationException {
-    testValidatorPasses(builder.mutualReadStrategy().validateAll(), rec, rec3, rec2);
-    testValidatorFails(builder.mutualReadStrategy().validateAll(), rec, rec4, rec3, rec2);
-  }
+      // Special case of singleton unions:
+      new ReaderWriter(FLOAT_SCHEMA, FLOAT_UNION_SCHEMA),
+      new ReaderWriter(INT_UNION_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, INT_UNION_SCHEMA),
 
-  @Test(expected=AvroRuntimeException.class)
-  public void testInvalidBuild() {
-    builder.strategy(null).validateAll();
-  }
+      // Tests involving records:
+      new ReaderWriter(EMPTY_RECORD1, EMPTY_RECORD1),
+      new ReaderWriter(EMPTY_RECORD1, A_INT_RECORD1),
+
+      new ReaderWriter(A_INT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_DINT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_DINT_RECORD1, A_DINT_RECORD1),
+      new ReaderWriter(A_INT_RECORD1, A_DINT_RECORD1),
+
+      new ReaderWriter(A_LONG_RECORD1, A_INT_RECORD1),
+
+      new ReaderWriter(A_INT_RECORD1, A_INT_B_INT_RECORD1),
+      new ReaderWriter(A_DINT_RECORD1, A_INT_B_INT_RECORD1),
+
+      new ReaderWriter(A_INT_B_DINT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_DINT_B_DINT_RECORD1, EMPTY_RECORD1),
+      new ReaderWriter(A_DINT_B_DINT_RECORD1, A_INT_RECORD1),
+      new ReaderWriter(A_INT_B_INT_RECORD1, A_DINT_B_DINT_RECORD1),
+
+      // The SchemaValidator, unlike the SchemaCompatibility class, cannot cope with recursive schemas
+      // 
+      // new ReaderWriter(INT_LIST_RECORD, INT_LIST_RECORD),
+      // new ReaderWriter(LONG_LIST_RECORD, LONG_LIST_RECORD),
+      // new ReaderWriter(LONG_LIST_RECORD, INT_LIST_RECORD),
+
+      new ReaderWriter(NULL_SCHEMA, NULL_SCHEMA));
+
+  /** Collection of reader/writer schema pair that are incompatible. */
+  public static final List<ReaderWriter> INCOMPATIBLE_READER_WRITER_TEST_CASES = list(
+      new ReaderWriter(NULL_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(NULL_SCHEMA, LONG_SCHEMA),
+
+      new ReaderWriter(BOOLEAN_SCHEMA, INT_SCHEMA),
+
+      new ReaderWriter(INT_SCHEMA, NULL_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, BOOLEAN_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, LONG_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, FLOAT_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, DOUBLE_SCHEMA),
+
+      new ReaderWriter(LONG_SCHEMA, FLOAT_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, DOUBLE_SCHEMA),
+
+      new ReaderWriter(FLOAT_SCHEMA, DOUBLE_SCHEMA),
+
+      new ReaderWriter(STRING_SCHEMA, BOOLEAN_SCHEMA),
+      new ReaderWriter(STRING_SCHEMA, INT_SCHEMA),
+
+      new ReaderWriter(BYTES_SCHEMA, NULL_SCHEMA),
+      new ReaderWriter(BYTES_SCHEMA, INT_SCHEMA),
+
+      new ReaderWriter(INT_ARRAY_SCHEMA, LONG_ARRAY_SCHEMA),
+      new ReaderWriter(INT_MAP_SCHEMA, INT_ARRAY_SCHEMA),
+      new ReaderWriter(INT_ARRAY_SCHEMA, INT_MAP_SCHEMA),
+      new ReaderWriter(INT_MAP_SCHEMA, LONG_MAP_SCHEMA),
+
+      new ReaderWriter(ENUM1_AB_SCHEMA, ENUM1_ABC_SCHEMA),
+      new ReaderWriter(ENUM1_BC_SCHEMA, ENUM1_ABC_SCHEMA),
+
+      new ReaderWriter(ENUM1_AB_SCHEMA, ENUM2_AB_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, ENUM2_AB_SCHEMA),
+      new ReaderWriter(ENUM2_AB_SCHEMA, INT_SCHEMA),
+
+      // Tests involving unions:
+      new ReaderWriter(INT_UNION_SCHEMA, INT_STRING_UNION_SCHEMA),
+      new ReaderWriter(STRING_UNION_SCHEMA, INT_STRING_UNION_SCHEMA),
+      new ReaderWriter(FLOAT_SCHEMA, INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, INT_FLOAT_UNION_SCHEMA),
+      new ReaderWriter(INT_SCHEMA, INT_FLOAT_UNION_SCHEMA),
+
+      new ReaderWriter(EMPTY_RECORD2, EMPTY_RECORD1),
+      new ReaderWriter(A_INT_RECORD1, EMPTY_RECORD1),
+      new ReaderWriter(A_INT_B_DINT_RECORD1, EMPTY_RECORD1),
+
+      new ReaderWriter(INT_LIST_RECORD, LONG_LIST_RECORD),
+
+      // Last check:
+      new ReaderWriter(NULL_SCHEMA, INT_SCHEMA));
+
+  SchemaValidatorBuilder builder = new SchemaValidatorBuilder();
+  Schema rec = SchemaBuilder.record(""test.Rec"").fields().name(""a"").type().intType().intDefault(1).name(""b"").type()
+      .longType().noDefault().endRecord();
+  Schema rec2 = SchemaBuilder.record(""test.Rec"").fields().name(""a"").type().intType().intDefault(1).name(""b"").type()
+      .longType().noDefault().name(""c"").type().intType().intDefault(0).endRecord();
+  Schema rec3 = SchemaBuilder.record(""test.Rec"").fields().name(""b"").type().longType().noDefault().name(""c"").type()
+      .intType().intDefault(0).endRecord();
+  Schema rec4 = SchemaBuilder.record(""test.Rec"").fields().name(""b"").type().longType().noDefault().name(""c"").type()
+      .intType().noDefault().endRecord();
+  Schema rec5 = SchemaBuilder.record(""test.Rec"").fields().name(""a"").type().stringType().stringDefault("""") // different
+                                                                                                          // type
+                                                                                                          // from
+                                                                                                          // original
+      .name(""b"").type().longType().noDefault().name(""c"").type().intType().intDefault(0).endRecord();
+  Schema s = SchemaBuilder.record(""r"").fields().requiredBoolean(""boolF"").requiredInt(""intF"").requiredLong(""longF"")
+      .requiredFloat(""floatF"").requiredDouble(""doubleF"").requiredString(""stringF"").requiredBytes(""bytesF"").name(
+          ""fixedF1"")
+      .type().fixed(""F1"").size(1).noDefault().name(""enumF"").type().enumeration(""E1"").symbols(""S"").noDefault()
+      .name(""mapF"").type().map().values().stringType().noDefault().name(
+          ""arrayF"")
+      .type().array().items().stringType().noDefault().name(""recordF"").type().record(""inner"").fields().name(""f"").type()
+      .intType().noDefault().endRecord().noDefault().optionalBoolean(""boolO"").endRecord();
 
   public static class Point {","[{'comment': ""What happened to testReflectMatchStructure and testReflectWithAllowNullMatchStructure test cases? Why are they gone? If there's no need for them, then I think you should also get rid of Point and Circle classes as well as circleSchemaDifferentNames and circleSchema."", 'commenter': 'nandorKollar'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java,"@@ -15,183 +15,316 @@
  * implied.  See the License for the specific language governing
  * permissions and limitations under the License.
  */
-
 package org.apache.avro;
 
+import static org.apache.avro.TestSchemas.A_DINT_B_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_B_DINT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_B_INT_RECORD1;
+import static org.apache.avro.TestSchemas.A_INT_RECORD1;
+import static org.apache.avro.TestSchemas.A_LONG_RECORD1;
+import static org.apache.avro.TestSchemas.BOOLEAN_SCHEMA;
+import static org.apache.avro.TestSchemas.BYTES_SCHEMA;
+import static org.apache.avro.TestSchemas.BYTES_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.DOUBLE_SCHEMA;
+import static org.apache.avro.TestSchemas.DOUBLE_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.EMPTY_RECORD1;
+import static org.apache.avro.TestSchemas.EMPTY_RECORD2;
+import static org.apache.avro.TestSchemas.EMPTY_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_ABC_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_AB_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM1_BC_SCHEMA;
+import static org.apache.avro.TestSchemas.ENUM2_AB_SCHEMA;
+import static org.apache.avro.TestSchemas.FLOAT_SCHEMA;
+import static org.apache.avro.TestSchemas.FLOAT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_ARRAY_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_FLOAT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_LIST_RECORD;
+import static org.apache.avro.TestSchemas.INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_LONG_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_MAP_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_STRING_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.INT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_ARRAY_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_LIST_RECORD;
+import static org.apache.avro.TestSchemas.LONG_MAP_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_SCHEMA;
+import static org.apache.avro.TestSchemas.LONG_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.NULL_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_INT_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_SCHEMA;
+import static org.apache.avro.TestSchemas.STRING_UNION_SCHEMA;
+import static org.apache.avro.TestSchemas.list;
+
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collections;
+import java.util.List;
 
-import org.apache.avro.reflect.ReflectData;
+import org.apache.avro.TestSchemas.ReaderWriter;
 import org.junit.Assert;
+import org.junit.Rule;
 import org.junit.Test;
+import org.junit.rules.ExpectedException;
 
 public class TestSchemaValidation {
 
-  SchemaValidatorBuilder builder = new SchemaValidatorBuilder();
+  @Rule
+  public ExpectedException expectedException = ExpectedException.none();
+  
+  /** Collection of reader/writer schema pair that are compatible. */
+  public static final List<ReaderWriter> COMPATIBLE_READER_WRITER_TEST_CASES = list(
+      new ReaderWriter(BOOLEAN_SCHEMA, BOOLEAN_SCHEMA),
 
-  Schema rec = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().intType().intDefault(1)
-      .name(""b"").type().longType().noDefault()
-      .endRecord();
+      new ReaderWriter(INT_SCHEMA, INT_SCHEMA),
 
-  Schema rec2 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().intType().intDefault(1)
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      new ReaderWriter(LONG_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(LONG_SCHEMA, LONG_SCHEMA),
 
-  Schema rec3 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      // Avro spec says INT/LONG can be promoted to FLOAT/DOUBLE.
+      // This is arguable as this causes a loss of precision.
+      new ReaderWriter(FLOAT_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(FLOAT_SCHEMA, LONG_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, LONG_SCHEMA),
 
-  Schema rec4 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().noDefault()
-      .endRecord();
+      new ReaderWriter(DOUBLE_SCHEMA, INT_SCHEMA),
+      new ReaderWriter(DOUBLE_SCHEMA, FLOAT_SCHEMA),
 
-  Schema rec5 = SchemaBuilder.record(""test.Rec"").fields()
-      .name(""a"").type().stringType().stringDefault("""") // different type from original
-      .name(""b"").type().longType().noDefault()
-      .name(""c"").type().intType().intDefault(0)
-      .endRecord();
+      new ReaderWriter(STRING_SCHEMA, STRING_SCHEMA),
 
-  @Test","[{'comment': 'Several test cases are now removed, are those covered with the new testSchemaCompatibilitySuccesses and testSchemaCompatibilityFailures tests? In the deleted test cases I see validators where it tests for mutual read, this code path is not covered any more, is it?', 'commenter': 'nandorKollar'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemas.java,"@@ -0,0 +1,139 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.avro;
+
+import static org.junit.Assert.assertTrue;
+import java.util.ArrayList;
+import java.util.Collections;
+import org.apache.avro.Schema.Field;
+
+/** Schemas used by other tests in this package. Therefore package protected. */
+public class TestSchemas {
+
+  static final Schema NULL_SCHEMA = Schema.create(Schema.Type.NULL);
+  static final Schema BOOLEAN_SCHEMA = Schema.create(Schema.Type.BOOLEAN);
+  static final Schema INT_SCHEMA = Schema.create(Schema.Type.INT);
+  static final Schema LONG_SCHEMA = Schema.create(Schema.Type.LONG);
+  static final Schema FLOAT_SCHEMA = Schema.create(Schema.Type.FLOAT);
+  static final Schema DOUBLE_SCHEMA = Schema.create(Schema.Type.DOUBLE);
+  static final Schema STRING_SCHEMA = Schema.create(Schema.Type.STRING);
+  static final Schema BYTES_SCHEMA = Schema.create(Schema.Type.BYTES);
+
+  static final Schema INT_ARRAY_SCHEMA = Schema.createArray(INT_SCHEMA);
+  static final Schema LONG_ARRAY_SCHEMA = Schema.createArray(LONG_SCHEMA);
+  static final Schema STRING_ARRAY_SCHEMA = Schema.createArray(STRING_SCHEMA);
+
+  static final Schema INT_MAP_SCHEMA = Schema.createMap(INT_SCHEMA);
+  static final Schema LONG_MAP_SCHEMA = Schema.createMap(LONG_SCHEMA);
+  static final Schema STRING_MAP_SCHEMA = Schema.createMap(STRING_SCHEMA);
+
+  static final Schema ENUM1_AB_SCHEMA = Schema.createEnum(""Enum1"", null, null, list(""A"", ""B""));
+  static final Schema ENUM1_ABC_SCHEMA = Schema.createEnum(""Enum1"", null, null,
+      list(""A"", ""B"", ""C""));
+  static final Schema ENUM1_BC_SCHEMA = Schema.createEnum(""Enum1"", null, null, list(""B"", ""C""));
+  static final Schema ENUM2_AB_SCHEMA = Schema.createEnum(""Enum2"", null, null, list(""A"", ""B""));
+
+  static final Schema EMPTY_UNION_SCHEMA = Schema.createUnion(new ArrayList<Schema>());
+  static final Schema NULL_UNION_SCHEMA = Schema.createUnion(list(NULL_SCHEMA));
+  static final Schema INT_UNION_SCHEMA = Schema.createUnion(list(INT_SCHEMA));
+  static final Schema LONG_UNION_SCHEMA = Schema.createUnion(list(LONG_SCHEMA));
+  static final Schema FLOAT_UNION_SCHEMA = Schema.createUnion(list(FLOAT_SCHEMA));
+  static final Schema DOUBLE_UNION_SCHEMA = Schema.createUnion(list(DOUBLE_SCHEMA));
+  static final Schema STRING_UNION_SCHEMA = Schema.createUnion(list(STRING_SCHEMA));
+  static final Schema BYTES_UNION_SCHEMA = Schema.createUnion(list(BYTES_SCHEMA));
+  static final Schema INT_STRING_UNION_SCHEMA = Schema.createUnion(list(INT_SCHEMA, STRING_SCHEMA));
+  static final Schema STRING_INT_UNION_SCHEMA = Schema.createUnion(list(STRING_SCHEMA, INT_SCHEMA));
+  static final Schema INT_FLOAT_UNION_SCHEMA = Schema.createUnion(list(INT_SCHEMA, FLOAT_SCHEMA));
+  static final Schema INT_LONG_UNION_SCHEMA = Schema.createUnion(list(INT_SCHEMA, LONG_SCHEMA));
+  static final Schema INT_LONG_FLOAT_DOUBLE_UNION_SCHEMA = Schema
+      .createUnion(list(INT_SCHEMA, LONG_SCHEMA, FLOAT_SCHEMA, DOUBLE_SCHEMA));
+
+  // Non recursive records:
+  static final Schema EMPTY_RECORD1 = Schema.createRecord(""Record1"", null, null, false);
+  static final Schema EMPTY_RECORD2 = Schema.createRecord(""Record2"", null, null, false);
+  static final Schema A_INT_RECORD1 = Schema.createRecord(""Record1"", null, null, false);
+  static final Schema A_LONG_RECORD1 = Schema.createRecord(""Record1"", null, null, false);
+  static final Schema A_INT_B_INT_RECORD1 = Schema.createRecord(""Record1"", null, null, false);
+  static final Schema A_DINT_RECORD1 = // DTYPE means TYPE with default value
+      Schema.createRecord(""Record1"", null, null, false);
+  static final Schema A_INT_B_DINT_RECORD1 = Schema.createRecord(""Record1"", null, null, false);
+  static final Schema A_DINT_B_DINT_RECORD1 = Schema.createRecord(""Record1"", null, null, false);
+
+  static final Schema FIXED_4_BYTES = Schema.createFixed(""Fixed"", null, null, 4);
+  static final Schema FIXED_8_BYTES = Schema.createFixed(""Fixed"", null, null, 8);
+
+  static {
+    EMPTY_RECORD1.setFields(Collections.<Field>emptyList());
+    EMPTY_RECORD2.setFields(Collections.<Field>emptyList());
+    A_INT_RECORD1.setFields(list(new Field(""a"", INT_SCHEMA, null, null)));
+    A_LONG_RECORD1.setFields(list(new Field(""a"", LONG_SCHEMA, null, null)));
+    A_INT_B_INT_RECORD1.setFields(
+        list(new Field(""a"", INT_SCHEMA, null, null), new Field(""b"", INT_SCHEMA, null, null)));
+    A_DINT_RECORD1.setFields(list(new Field(""a"", INT_SCHEMA, null, 0)));
+    A_INT_B_DINT_RECORD1.setFields(
+        list(new Field(""a"", INT_SCHEMA, null, null), new Field(""b"", INT_SCHEMA, null, 0)));
+    A_DINT_B_DINT_RECORD1
+        .setFields(list(new Field(""a"", INT_SCHEMA, null, 0), new Field(""b"", INT_SCHEMA, null, 0)));
+  }
+
+  // Recursive records
+  static final Schema INT_LIST_RECORD = Schema.createRecord(""List"", null, null, false);
+  static final Schema LONG_LIST_RECORD = Schema.createRecord(""List"", null, null, false);
+  static {
+    INT_LIST_RECORD.setFields(list(new Field(""head"", INT_SCHEMA, null, null),
+        new Field(""tail"", INT_LIST_RECORD, null, null)));
+    LONG_LIST_RECORD.setFields(list(new Field(""head"", LONG_SCHEMA, null, null),
+        new Field(""tail"", LONG_LIST_RECORD, null, null)));
+  }
+
+  // -----------------------------------------------------------------------------------------------
+
+  /** Reader/writer schema pair. */
+  static final class ReaderWriter {
+    private final Schema mReader;
+    private final Schema mWriter;
+
+    public ReaderWriter(final Schema reader, final Schema writer) {
+      mReader = reader;
+      mWriter = writer;
+    }
+
+    public Schema getReader() {
+      return mReader;
+    }
+
+    public Schema getWriter() {
+      return mWriter;
+    }
+  }
+
+  /** Borrowed from the Guava library. */
+  static <E> ArrayList<E> list(E... elements) {","[{'comment': 'Not sure that we need this at all, since it does the same as Arrays.asList(), though better not change this in this PR, since it is already non-trivial.', 'commenter': 'nandorKollar'}, {'comment': 'It was there before me :-)\r\nI also think it is better to leave it for now\r\nCould we make a ""cleaning JIRA"", where we also could tidy up the formatting of SchemaCompatibility/SchemaValidator related classes?', 'commenter': 'epkanol'}, {'comment': '@epkanol yes, I think a separate Jira is the best option to cleanup the tests related the schema compatibility/schema validation.', 'commenter': 'nandorKollar'}]"
200,lang/java/avro/src/test/java/org/apache/avro/TestSchemaValidation.java,"@@ -121,12 +303,32 @@ public void testInvalidBuild() {
     builder.strategy(null).validateAll();
   }
 
+  Schema s = SchemaBuilder.record(""r"").fields()","[{'comment': 'I cannot see the purpose of this one. Does anyone use `TestSchemaValidation.s`?', 'commenter': 'gszadovszky'}, {'comment': 'My mistake, thanks for pointing this out. Updated commit removed the outer s (which was never used in the first place)', 'commenter': 'epkanol'}]"
201,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -350,59 +357,71 @@ private SchemaCompatibilityType calculateCompatibility(
       } else {
         // Reader and writer have different schema types:
 
-        // Handle the corner case where writer is a union of a singleton branch: { X } === X
-        if ((writer.getType() == Schema.Type.UNION)
-            && writer.getTypes().size() == 1) {
-          return getCompatibility(reader, writer.getTypes().get(0));
+        // Reader compatible with all branches of a writer union is compatible
+        if (writer.getType() == Schema.Type.UNION) {
+          int i = 0;
+          for (Schema s : writer.getTypes()) {
+            location.push(Integer.toString(i));","[{'comment': '@teabot  Missing an increment ☝️, i.e. `i++`?', 'commenter': 'chids'}, {'comment': 'yes, it looks like it. Good catch.', 'commenter': 'teabot'}]"
201,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -663,7 +804,8 @@ public String toString() {
 
     /**
      * Constructs a new instance.
-     * @param result of the schema compatibility.
+     * @param result The result of the compatibility check.
+     * @param type of the schema compatibility.","[{'comment': 'type is not a parameter for this method, please remove this from the javadoc', 'commenter': 'nandorKollar'}, {'comment': 'Done', 'commenter': 'teabot'}]"
201,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -224,22 +211,42 @@ public SchemaCompatibilityResult getCompatibility(
         final Schema reader,
         final Schema writer
     ) {
+      Stack<String> location = new Stack<String>();","[{'comment': ""Can we avoid `Stack` here? I think it is subclass of `Vector`, which has synchronized accessor methods, and in this case I don't using thread-safe classes is needed here. I think you should use some implementation of `Dequeue` interface instead."", 'commenter': 'nandorKollar'}, {'comment': 'Done', 'commenter': 'teabot'}]"
201,lang/java/avro/src/main/java/org/apache/avro/SchemaCompatibility.java,"@@ -480,26 +512,37 @@ private SchemaCompatibilityResult typeMismatch(final Schema reader, final Schema
    * Immutable class representing details about a particular schema pair compatibility check.
    */
   public static final class SchemaCompatibilityResult {
-    private final SchemaCompatibilityType mCompatibility;
+
+    /**
+     * Merges the current {@code SchemaCompatibilityResult} with the supplied result into a new instance, combining the
+     * list of {@code Incompatibility Incompatibilities} and regressing to the
+     * {@code SchemaCompatibilityType#INCOMPATIBLE INCOMPATIBLE} state if any incompatibilities are encountered.
+     *
+     * @param toMerge The {@code SchemaCompatibilityResult} to merge with the current instance.
+     * @return A {@code SchemaCompatibilityResult} that combines the state of the current and supplied instances.
+     */
+    public SchemaCompatibilityResult mergedWith(SchemaCompatibilityResult toMerge) {
+      List<Incompatibility> mergedIncompatibilities = new ArrayList<Incompatibility>(mIncompatibilities);
+      mergedIncompatibilities.addAll(toMerge.getIncompatibilities());
+      SchemaCompatibilityType compatibilityType = mCompatibilityType == SchemaCompatibilityType.COMPATIBLE","[{'comment': ""What happens in case of `RECURSION_IN_PROGRESS`? I'm not sure we need `&& toMerge.mCompatibilityType == SchemaCompatibilityType.COMPATIBLE`, isn't this simpler a bit:\r\n`SchemaCompatibilityType compatibilityType = mCompatibilityType == SchemaCompatibilityType.COMPATIBLE ?  toMerge.getCompatibility() : SchemaCompatibilityType.INCOMPATIBLE;\r\n`"", 'commenter': 'nandorKollar'}, {'comment': 'Done', 'commenter': 'teabot'}]"
201,lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java,"@@ -78,6 +82,7 @@
 import org.apache.avro.io.Encoder;
 import org.apache.avro.io.EncoderFactory;
 import org.apache.avro.util.Utf8;
+import org.junit.Ignore;","[{'comment': '`org.junit.Ignore`, `org.apache.avro.SchemaCompatibility`, `org.apache.avro.Schema` are unused imports', 'commenter': 'nandorKollar'}, {'comment': 'Done', 'commenter': 'teabot'}]"
201,lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibilityMissingUnionBranch.java,"@@ -101,11 +107,16 @@
   @Parameter(1)
   public Schema writer;
   @Parameter(2)
-  public String details;
+  public List<String> details;
+  @Parameter(3)
+  public List<String> location;
 
   @Test
   public void testMissingUnionBranch() throws Exception {
-    validateIncompatibleSchemas(reader, writer, SchemaIncompatibilityType.MISSING_UNION_BRANCH,
-        details);
+    List<SchemaIncompatibilityType> types = new ArrayList<SchemaCompatibility.SchemaIncompatibilityType>(details.size());","[{'comment': 'nit: I think we create a list with N `SchemaIncompatibilityType.MISSING_UNION_BRANCH` items in a single line using `java.util.Collections#nCopies` The return value is immutable, but in this case it is not an issue.', 'commenter': 'nandorKollar'}, {'comment': 'Like', 'commenter': 'teabot'}, {'comment': 'Done', 'commenter': 'teabot'}]"
201,lang/java/avro/src/test/java/org/apache/avro/TestSchemaCompatibility.java,"@@ -355,18 +363,47 @@ public void testUnionReaderWriterSubsetIncompatibility() {
    * per error case (for easier pinpointing of errors). The method to validate incompatibility is
    * still here.
    */
+  public static void validateIncompatibleSchemas(
+      Schema reader,
+      Schema writer,
+      SchemaIncompatibilityType incompatibility,
+      String message,
+      String location
+    ) {
+    validateIncompatibleSchemas(
+        reader,
+        writer,
+        asList(incompatibility),
+        asList(message),
+        asList(location)
+    );
+  }
+
+  // -----------------------------------------------------------------------------------------------
+
+  /**","[{'comment': ""I don't think we need this comment now."", 'commenter': 'nandorKollar'}, {'comment': 'Done', 'commenter': 'teabot'}]"
229,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -181,13 +181,15 @@ protected boolean isRecord(Object datum) {
 
   /**
    * Returns true also for non-string-keyed maps, which are written as an array
-   * of key/value pair records.
+   * of key/value pair records. Returns false for array of bytes, since it should","[{'comment': 'I find it a bit strange that the javadoc comment only documents the exception cases and not the main behavior. I would suggest the following instead:\r\n\r\n> Returns true for arrays and false otherwise, with the following exceptions:\r\n> * Returns true for non-string-keyed maps, which are written as an array of key/value pair records.\r\n> * Returns false for arrays of bytes, since those should be treated as byte data type instead.\r\n', 'commenter': 'zivanfi'}]"
229,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -181,13 +181,15 @@ protected boolean isRecord(Object datum) {
 
   /**
    * Returns true also for non-string-keyed maps, which are written as an array
-   * of key/value pair records.
+   * of key/value pair records. Returns false for array of bytes, since it should
+   * be treated as byte data type instead.
    */
   @Override
   protected boolean isArray(Object datum) {
     if (datum == null) return false;
+    Class c = datum.getClass();
     return (datum instanceof Collection)
-      || datum.getClass().isArray()
+      || (c.isArray() && !(c.getComponentType() == Byte.TYPE))","[{'comment': 'I would suggest `c.getComponentType() != Byte.TYPE` instead of `!(c.getComponentType() == Byte.TYPE)`', 'commenter': 'zivanfi'}]"
229,lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflect.java,"@@ -1048,4 +1050,17 @@ public void testAvroDefault() {
           +""{\""name\"":\""foo\"",\""type\"":\""int\"",\""default\"":1}]}"");
   }
 
+  private static class NullableBytesTest {
+    @Nullable
+    byte[] bytes = ""foo"".getBytes();
+  }
+
+  @Test
+  public void testNullableByteArray() throws IOException {","[{'comment': 'Since there are no asserts in this test, could you document in a comment how this test would fail without the fix? Thanks!', 'commenter': 'zivanfi'}, {'comment': 'Instead of documenting the test, I rewrote it. It asserts for the output in the updated version', 'commenter': 'nandorKollar'}]"
229,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -180,14 +180,18 @@ protected boolean isRecord(Object datum) {
   }
 
   /**
-   * Returns true also for non-string-keyed maps, which are written as an array
-   * of key/value pair records.
+   * Returns true for arrays and false otherwise, with the following exceptions:
+   * <ul>
+   * <li><p>Returns true for non-string-keyed maps, which are written as an array of key/value pair records.</p></li>","[{'comment': 'Nit: No need for the `<p>`-s inside the `<li>`-s.', 'commenter': 'zivanfi'}]"
229,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -180,14 +180,18 @@ protected boolean isRecord(Object datum) {
   }
 
   /**
-   * Returns true also for non-string-keyed maps, which are written as an array
-   * of key/value pair records.
+   * Returns true for arrays and false otherwise, with the following exceptions:
+   * <ul>
+   * <li><p>Returns true for non-string-keyed maps, which are written as an array of key/value pair records.</p></li>
+   * <li><p>Returns false for arrays of bytes, since those should be treated as byte data type instead.</p></li>
+   * <ul>","[{'comment': 'This should be `</ul>`', 'commenter': 'zivanfi'}]"
229,lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflect.java,"@@ -1048,4 +1048,19 @@ public void testAvroDefault() {
           +""{\""name\"":\""foo\"",\""type\"":\""int\"",\""default\"":1}]}"");
   }
 
+  public static class NullableBytesTest {
+    @Nullable
+    byte[] bytes = ""foo"".getBytes();
+
+    @Override
+    public boolean equals(Object obj) {
+      return obj instanceof NullableBytesTest
+              && Arrays.equals(((NullableBytesTest) obj).bytes, this.bytes);
+    }
+  }
+
+  @Test
+  public void testNullableByteArray() throws Exception {
+    checkReadWrite(new NullableBytesTest());","[{'comment': 'As we are testing a nullable field I would also test the scenario when this field is really null.', 'commenter': 'gszadovszky'}, {'comment': '@gszadovszky updated the pul request with an additional test case to cover null field value.', 'commenter': 'nandorKollar'}]"
244,lang/java/ipc/src/test/java/org/apache/avro/TestProtocolHttps.java,"@@ -48,14 +38,14 @@ public Server createServer(Responder testResponder) throws Exception {
     System.setProperty(""javax.net.ssl.password"", ""avrotest"");
     System.setProperty(""javax.net.ssl.trustStore"", ""src/test/truststore"");
     System.setProperty(""javax.net.ssl.trustStorePassword"", ""avrotest"");","[{'comment': 'It might make sense to set the rest of the properties on the connector which were declared above, or remove those if they are not used/needed.', 'commenter': 'commanderofthegrey'}, {'comment': ""I believe those system properties are also used by the client side portions (which I haven't touched) to setup the SSL stuff for the client that connect to it.   "", 'commenter': 'dkulp'}]"
244,lang/java/ipc/src/main/java/org/apache/avro/ipc/HttpServer.java,"@@ -48,38 +50,47 @@ public HttpServer(Responder responder, String bindAddress, int port) throws IOEx
 
   /** Constructs a server to run on the named port on the specified address. */
   public HttpServer(ResponderServlet servlet, String bindAddress, int port) throws IOException {
-    this.server = new org.mortbay.jetty.Server();
-    SelectChannelConnector connector = new SelectChannelConnector();
-    connector.setLowResourceMaxIdleTime(10000);
-    connector.setAcceptQueueSize(128);
-    connector.setResolveNames(false);
-    connector.setUseDirectBuffers(false);
+    this.server = new org.eclipse.jetty.server.Server();
+    ServerConnector connector = new ServerConnector(this.server);
     if (bindAddress != null) {
       connector.setHost(bindAddress);
     }
     connector.setPort(port);
     server.addConnector(connector);
-    new Context(server, ""/"").addServlet(new ServletHolder(servlet), ""/*"");
+
+    ServletHandler handler = new ServletHandler();
+    server.setHandler(handler);
+    handler.addServletWithMapping(new ServletHolder(servlet), ""/*"");","[{'comment': ""I might be off here, but wouldn't using ServerContextHandler be more appropriate here? "", 'commenter': 'commanderofthegrey'}]"
244,lang/java/ipc/src/main/java/org/apache/avro/ipc/HttpServer.java,"@@ -48,38 +50,47 @@ public HttpServer(Responder responder, String bindAddress, int port) throws IOEx
 
   /** Constructs a server to run on the named port on the specified address. */
   public HttpServer(ResponderServlet servlet, String bindAddress, int port) throws IOException {
-    this.server = new org.mortbay.jetty.Server();
-    SelectChannelConnector connector = new SelectChannelConnector();
-    connector.setLowResourceMaxIdleTime(10000);
-    connector.setAcceptQueueSize(128);","[{'comment': ""Would it make sense to set this, as well as setIdleTime so it's more similar to the previous version?"", 'commenter': 'commanderofthegrey'}]"
244,lang/java/ipc/src/test/java/org/apache/avro/ipc/stats/TestStatsPluginAndServlet.java,"@@ -187,7 +186,6 @@ public static void main(String[] args) throws Exception {
         + ""   \""request\"": [{\""name\"": \""millis\"", \""type\"": \""long\""},"" +
           ""{\""name\"": \""data\"", \""type\"": \""bytes\""}], ""
         + ""   \""response\"": \""null\""} } }"");
-    Log.info(""Using protocol: "" + protocol.toString());","[{'comment': ""While it probably makes sense to remove the log, as that way we don't have to add jetty-util as a dependency, but would it not help if we made it more of an exact match initially and later decide whether this Log message even matters? "", 'commenter': 'commanderofthegrey'}]"
244,lang/java/ipc/src/main/java/org/apache/avro/ipc/HttpServer.java,"@@ -48,38 +50,47 @@ public HttpServer(Responder responder, String bindAddress, int port) throws IOEx
 
   /** Constructs a server to run on the named port on the specified address. */
   public HttpServer(ResponderServlet servlet, String bindAddress, int port) throws IOException {
-    this.server = new org.mortbay.jetty.Server();
-    SelectChannelConnector connector = new SelectChannelConnector();
-    connector.setLowResourceMaxIdleTime(10000);
-    connector.setAcceptQueueSize(128);
-    connector.setResolveNames(false);
-    connector.setUseDirectBuffers(false);
+    this.server = new org.eclipse.jetty.server.Server();
+    ServerConnector connector = new ServerConnector(this.server);
     if (bindAddress != null) {
       connector.setHost(bindAddress);
     }
     connector.setPort(port);
     server.addConnector(connector);
-    new Context(server, ""/"").addServlet(new ServletHolder(servlet), ""/*"");
+
+    ServletHandler handler = new ServletHandler();
+    server.setHandler(handler);
+    handler.addServletWithMapping(new ServletHolder(servlet), ""/*"");
   }
 
   /** Constructs a server to run with the given connector. */
-  public HttpServer(Responder responder, Connector connector) throws IOException {","[{'comment': 'Is the diff wonky or was the method with the ""public HttpServer(ResponderServlet servlet, Connector connector) throws IOException"" signature removed? If they were removed in my opinion it would hurt backwards compatibility in this case.', 'commenter': 'commanderofthegrey'}]"
256,lang/java/avro/src/main/java/org/apache/avro/specific/SpecificDatumReader.java,"@@ -101,6 +101,23 @@ private Class getPropAsClass(Schema schema, String prop) {
     }
   }
 
+  @Override
+  protected Object readRecord(Object old, Schema expected, ResolvingDecoder in)
+    throws IOException {
+    SpecificData data = getSpecificData();
+    Object r = data.newRecord(old, expected);","[{'comment': ""'r' should only be created when custom coders are used, no?"", 'commenter': 'cutting'}, {'comment': 'yep', 'commenter': 'rstata'}]"
256,lang/java/avro/src/main/java/org/apache/avro/specific/SpecificRecordBase.java,"@@ -90,4 +92,19 @@ public void readExternal(ObjectInput in)
     new SpecificDatumReader(getSchema())
       .read(this, SpecificData.getDecoder(in));
   }
+
+  /** Returns true iff an instance supports the {@link #encode} and
+    * {@link #decode} operations.  Should only be used by
+    * <code>SpecificDatumReader/Writer</code> to selectively use
+    * {@link #encode} and {@link #decode} to optimize the (de)serialization of
+    * values. */
+  public boolean hasCustomCoders() { return false; }
+","[{'comment': 'Do these need to be public, or is protected enough?  Also, they need some javadoc.', 'commenter': 'cutting'}, {'comment': 'protected is enough', 'commenter': 'rstata'}]"
256,lang/java/compiler/src/main/velocity/org/apache/avro/compiler/specific/templates/java/classic/record.vm,"@@ -473,4 +475,282 @@ public class ${this.mangle($schema.getName())}#if ($schema.isError()) extends or
     READER$.read(this, SpecificData.getDecoder(in));
   }
 
+#if ($this.isCustomCodable($schema))
+  @Override public boolean hasCustomCoders() { return true; }
+
+  @Override public void encode(org.apache.avro.io.Encoder out)
+    throws java.io.IOException
+  {
+#set ($nv = 0)## Counter to ensure unique var-names
+#set ($maxnv = 0)## Holds high-water mark during recursion
+#foreach ($field in $schema.getFields())
+#set ($n = $this.mangle($field.name(), $schema.isError()))
+#set ($s = $field.schema())
+#encodeVar(0 ""this.${n}"" $s)
+
+#set ($nv = $maxnv)
+#end
+  }
+
+  @Override public void decode(org.apache.avro.io.Decoder in)
+    throws java.io.IOException
+  {
+#set ($nv = 0)## Counter to ensure unique var-names
+#set ($maxnv = 0)## Holds high-water mark during recursion
+#foreach ($field in $schema.getFields())
+#set ($n = $this.mangle($field.name(), $schema.isError()))
+#set ($s = $field.schema())
+#set ($rs = ""SCHEMA$.getField(""""${n}"""").schema()"")
+#decodeVar(0 ""this.${n}"" $s $rs)
+
+#set ($nv = $maxnv)
+#end
+  }
+#end
 }
+
+#macro( encodeVar $indent $var $s )
+#set ($I = $this.indent($indent))
+##### Compound types (array, map, and union) require calls
+##### that will recurse back into this encodeVar macro:
+#if ($s.Type.Name.equals(""array""))
+#encodeArray($indent $var $s)
+#elseif ($s.Type.Name.equals(""map""))
+#encodeMap($indent $var $s)
+#elseif ($s.Type.Name.equals(""union""))
+#encodeUnion($indent $var $s)
+##### Use the generated ""encode"" method as fast way to write
+##### (specific) record types:
+#elseif ($s.Type.Name.equals(""record""))
+$I    ${var}.encode(out);
+##### For rest of cases, generate calls out.writeXYZ:
+#elseif ($s.Type.Name.equals(""null""))
+$I    out.writeNull();
+#elseif ($s.Type.Name.equals(""boolean""))
+$I    out.writeBoolean(${var});
+#elseif ($s.Type.Name.equals(""int""))
+$I    out.writeInt(${var});
+#elseif ($s.Type.Name.equals(""long""))
+$I    out.writeLong(${var});
+#elseif ($s.Type.Name.equals(""float""))
+$I    out.writeFloat(${var});
+#elseif ($s.Type.Name.equals(""double""))
+$I    out.writeDouble(${var});
+#elseif ($s.Type.Name.equals(""string""))
+#if ($this.isStringable($s))
+$I    out.writeString(${var}.toString());
+#else
+$I    out.writeString(${var});
+#end
+#elseif ($s.Type.Name.equals(""bytes""))
+$I    out.writeBytes(${var});
+#elseif ($s.Type.Name.equals(""fixed""))
+$I    out.writeFixed(${var}.bytes(), 0, ${s.FixedSize});
+#elseif ($s.Type.Name.equals(""enum""))
+$I    out.writeEnum(${var}.ordinal());
+#else
+## TODO -- singal a code-gen-time error
+#end
+#end
+
+#macro( encodeArray $indent $var $s )
+#set ($I = $this.indent($indent))
+#set ($et = $this.javaType($s.ElementType))
+$I    long size${nv} = ${var}.size();
+$I    out.writeArrayStart();
+$I    out.setItemCount(size${nv});
+$I    long actualSize${nv} = 0;
+$I    for ($et e${nv}: ${var}) {
+$I      actualSize${nv}++;
+$I      out.startItem();
+#set ($var = ""e${nv}"")
+#set ($nv = $nv + 1)
+#set ($maxnv = $nv)
+#set ($indent = $indent + 2)
+#encodeVar($indent $var $s.ElementType)
+#set ($nv = $nv - 1)
+#set ($indent = $indent - 2)
+#set ($I = $this.indent($indent))
+$I    }
+$I    out.writeArrayEnd();
+$I    if (actualSize${nv} != size${nv})
+$I      throw new java.util.ConcurrentModificationException(""Array-size written was "" + size${nv} + "", but element count was "" + actualSize${nv} + ""."");
+#end
+
+#macro( encodeMap $indent $var $s )
+#set ($I = $this.indent($indent))
+#set ($kt = $this.getStringType($s))
+#set ($vt = $this.javaType($s.ValueType))
+$I    long size${nv} = ${var}.size();
+$I    out.writeMapStart();
+$I    out.setItemCount(size${nv});
+$I    long actualSize${nv} = 0;
+$I    for (java.util.Map.Entry<$kt, $vt> e${nv}: ${var}.entrySet()) {
+$I      actualSize${nv}++;
+$I      out.startItem();
+#if ($this.isStringable($s))
+$I      out.writeString(e${nv}.getKey().toString());
+#else
+$I      out.writeString(e${nv}.getKey());
+#end
+$I      $vt v${nv} = e${nv}.getValue();
+#set ($var = ""v${nv}"")
+#set ($nv = $nv + 1)
+#set ($maxnv = $nv)
+#set ($indent = $indent + 2)
+#encodeVar($indent $var $s.ValueType)
+#set ($nv = $nv - 1)
+#set ($indent = $indent - 2)
+#set ($I = $this.indent($indent))
+$I    }
+$I    out.writeMapEnd();
+$I    if (actualSize${nv} != size${nv})
+      throw new java.util.ConcurrentModificationException(""Map-size written was "" + size${nv} + "", but element count was "" + actualSize${nv} + ""."");
+#end
+
+#macro( encodeUnion $indent $var $s )
+#set ($I = $this.indent($indent))
+#set ($et = $this.javaType($s.Types.get($this.getNonNullIndex($s))))
+$I    if (${var} == null) {
+$I      out.writeIndex(#if($this.getNonNullIndex($s)==0)1#{else}0#end);
+$I      out.writeNull();
+$I    } else {
+$I      out.writeIndex(${this.getNonNullIndex($s)});
+#set ($indent = $indent + 2)
+#encodeVar($indent $var $s.Types.get($this.getNonNullIndex($s)))
+#set ($indent = $indent - 2)
+#set ($I = $this.indent($indent))
+$I    }
+#end
+
+
+#macro( decodeVar $indent $var $s $rs )
+#set ($I = $this.indent($indent))
+##### Compound types (array, map, and union) require calls
+##### that will recurse back into this decodeVar macro:
+#if ($s.Type.Name.equals(""array""))
+#decodeArray($indent $var $s $rs)
+#elseif ($s.Type.Name.equals(""map""))
+#decodeMap($indent $var $s $rs)
+#elseif ($s.Type.Name.equals(""union""))
+#decodeUnion($indent $var $s $rs)
+##### Use the generated ""decode"" method as fast way to write
+##### (specific) record types:
+#elseif ($s.Type.Name.equals(""record""))
+$I    if (${var} == null) {
+$I      ${var} = new ${this.javaType($s)}();
+$I    }
+$I    ${var}.decode(in);
+##### For rest of cases, generate calls in.readXYZ:
+#elseif ($s.Type.Name.equals(""null""))
+$I    in.readNull();
+#elseif ($s.Type.Name.equals(""boolean""))
+$I    $var = in.readBoolean();
+#elseif ($s.Type.Name.equals(""int""))
+$I    $var = in.readInt();
+#elseif ($s.Type.Name.equals(""long""))
+$I    $var = in.readLong();
+#elseif ($s.Type.Name.equals(""float""))
+$I    $var = in.readFloat();
+#elseif ($s.Type.Name.equals(""double""))
+$I    $var = in.readDouble();
+#elseif ($s.Type.Name.equals(""string""))
+#decodeString( ""$I"" $var $s )
+#elseif ($s.Type.Name.equals(""bytes""))
+$I    $var = in.readBytes(${var});
+#elseif ($s.Type.Name.equals(""fixed""))
+$I    if (${var} == null) {
+$I      ${var} = new ${this.javaType($s)}();
+$I    }
+$I    in.readFixed(${var}.bytes(), 0, ${s.FixedSize});
+#elseif ($s.Type.Name.equals(""enum""))
+$I    $var = ${this.javaType($s)}.values()[in.readEnum()];
+#else
+## TODO -- singal a code-gen-time error
+#end
+#end
+
+#macro( decodeString $II $var $s )
+#set ($st = ${this.getStringType($s)})
+#if ($this.isStringable($s))
+$II    ${var} = new ${st}(in.readString());
+#elseif ($st.equals(""java.lang.String""))
+$II    $var = in.readString();
+#elseif ($st.equals(""org.apache.avro.util.Utf8""))
+$II    $var = in.readString(${var});
+#else
+$II    $var = in.readString(${var} instanceof Utf8 ? (Utf8)${var} : null);
+#end
+#end
+
+#macro( decodeArray $indent $var $s $rs )
+#set ($I = $this.indent($indent))
+#set ($t = $this.javaType($s))
+#set ($et = $this.javaType($s.ElementType))
+#set ($gat = ""SpecificData.Array<${et}>"")
+$I    long size${nv} = in.readArrayStart();
+$I    $t a${nv} = ${var}; // Need fresh name due to limitation of macro system
+$I    if (a${nv} == null) {","[{'comment': ""but we probably don't need this comment in every generated file"", 'commenter': 'cutting'}, {'comment': 'changed to a velocity comment', 'commenter': 'rstata'}]"
256,lang/java/avro/src/main/java/org/apache/avro/specific/SpecificData.java,"@@ -122,6 +122,10 @@ public DatumWriter createDatumWriter(Schema schema) {
   /** Return the singleton instance. */
   public static SpecificData get() { return INSTANCE; }
 
+  private static final boolean USE_CUSTOM_CODERS
+    = Boolean.parseBoolean(System.getProperty(""org.apache.avro.specific.use_custom_coders"",""false""));
+  public boolean useCustomCoders() { return USE_CUSTOM_CODERS; }","[{'comment': 'useCustomCoders should probably be a settable member variable on each SpecificData instance, so folks can more easily switch it on and off without restarting the JVM.', 'commenter': 'cutting'}, {'comment': ""In https://github.com/rstata-projects/avro/commit/e81a5880be69aef5bffdcf38f7ae3491957a6a68, I changed this flag to be dynamically changable.\r\n\r\nFor the record, here's the roll-out plan I imagined for this feature (See [AVRO-2091](https://issues.apache.org/jira/browse/AVRO-2091)).  The initial release of this feature sets the `use_custom_coders` flag to `false` by default, to allow for some road testing.  The  release after that would set this flag to `true` by default, to allow for some more serious road testing.  The next release of Avro after that would then eliminate this flag altogether, under the assumption that the feature has been sufficiently tested and there's no longer a use for the old way of doing things."", 'commenter': 'rstata'}]"
256,lang/java/avro/src/main/java/org/apache/avro/specific/SpecificDatumWriter.java,"@@ -71,6 +71,21 @@ protected void writeString(Schema schema, Object datum, Encoder out)
     writeString(datum, out);
   }
 
+  @Override
+  protected void writeRecord(Schema schema, Object datum, Encoder out)
+    throws IOException {
+    if (SpecificData.get().useCustomCoders()","[{'comment': 'should use this.getSpecificData() instead of the static instance', 'commenter': 'cutting'}, {'comment': 'ok', 'commenter': 'rstata'}]"
256,lang/java/avro/src/main/java/org/apache/avro/specific/SpecificDatumReader.java,"@@ -101,6 +101,23 @@ private Class getPropAsClass(Schema schema, String prop) {
     }
   }
 
+  @Override
+  protected Object readRecord(Object old, Schema expected, ResolvingDecoder in)
+    throws IOException {
+    SpecificData data = getSpecificData();
+    Object r = data.newRecord(old, expected);
+    if (SpecificData.get().useCustomCoders()","[{'comment': 'should use this.getSpecificData() instead of using the static instance', 'commenter': 'cutting'}, {'comment': 'ok', 'commenter': 'rstata'}]"
261,lang/csharp/.gitignore,"@@ -1,35 +1,51 @@
-#   Licensed to the Apache Software Foundation (ASF) under one or more","[{'comment': ""Please don't remove license headers (though it is odd that this .gitignore has one while the top level doesn't)\r\n\r\nWere the changes to . gitignore automatically made? The lines about uncommenting bits under some circumstances makes me think so."", 'commenter': 'busbey'}, {'comment': ""1st - sorry for delay. I got dragged away with daily work so all my side-projects were on hold for some time.\r\n\r\nI did not remove headers especially not license ones. I don't know what happened. \r\n\r\nFixing that right now."", 'commenter': 'moljac'}]"
261,lang/csharp/src/apache/codegen/Avro.codegen.csproj,"@@ -1,162 +1,18 @@
-﻿<?xml version=""1.0"" encoding=""utf-8""?>
-<!--
-   Licensed to the Apache Software Foundation (ASF) under one or more","[{'comment': 'We need a license header still.', 'commenter': 'busbey'}]"
276,lang/java/avro/src/main/java/org/apache/avro/io/parsing/Symbol.java,"@@ -369,9 +371,19 @@ public Repeater flatten(Map<Sequence, Sequence> map,
    * for some inputs.
    */
   public static boolean hasErrors(Symbol symbol) {
+    return hasErrors(symbol, new HashSet<Symbol>());
+  }
+  ","[{'comment': ""Please remove trailing whitespaces from here, Checkstyle plugin doesn't like it, and mvn test fails"", 'commenter': 'nandorKollar'}]"
276,lang/java/avro/src/main/java/org/apache/avro/io/parsing/Symbol.java,"@@ -369,9 +371,19 @@ public Repeater flatten(Map<Sequence, Sequence> map,
    * for some inputs.
    */
   public static boolean hasErrors(Symbol symbol) {
+    return hasErrors(symbol, new HashSet<Symbol>());
+  }
+  
+  private static boolean hasErrors(Symbol symbol, Set<Symbol> visited) {
+    // avoid infinite recursion
+    if (visited.contains(symbol)) {
+      return false;
+    }
+    visited.add(symbol);
+    ","[{'comment': 'Please remove trailing whitespaces from here too.', 'commenter': 'nandorKollar'}]"
276,lang/java/avro/src/test/java/org/apache/avro/io/parsing/RecursiveSymbolTest.java,"@@ -0,0 +1,41 @@
+/*","[{'comment': 'Instead of adding a new class, could you please add a new test method with a meaningful name to TestSchemaValidation?', 'commenter': 'nandorKollar'}]"
298,lang/java/avro/src/main/java/org/apache/avro/Schema.java,"@@ -765,6 +781,7 @@ public boolean equals(Object o) {
         && symbols.equals(that.symbols)
         && props.equals(that.props);
     }
+    public String getEnumDefault() { return enumDefault; }","[{'comment': 'needs @Override?', 'commenter': 'cutting'}]"
298,lang/java/avro/src/main/java/org/apache/avro/Schema.java,"@@ -1450,7 +1473,7 @@ private static Schema applyAliases(Schema s, Map<Schema,Schema> seen,
     case ENUM:
       if (aliases.containsKey(name))
         result = Schema.createEnum(aliases.get(name).full, s.getDoc(), null,
-                                   s.getEnumSymbols());
+                                   s.getEnumSymbols(), s.getEnumDefault());","[{'comment': 'I scanned for other places where Schema.createEnum is called to see which need updates.\r\nResolvingVisitor.java also needs this same change.  This is used to support IDL.  We should also add support to IDL for enum defaults.\r\nSchemaBuilder.java should be changed to permit specifying an enum default.', 'commenter': 'cutting'}, {'comment': 'Okay yes, I can add that to this PR. ', 'commenter': 'bellemare'}]"
298,lang/java/avro/src/test/java/org/apache/avro/TestSchemaBuilder.java,"@@ -561,6 +561,17 @@ public void testEnum() {
     Assert.assertEquals(expected, schema);
   }
 
+  @Test
+  public void testEnumWithDefault() {
+    List<String> symbols = Arrays.asList(""a"", ""b"");
+    String enumDefault = ""a"";
+    Schema expected = Schema.createEnum(""myenum"", null, null, symbols, enumDefault);
+    expected.addProp(""p"", ""v"");
+    Schema schema = SchemaBuilder.enumeration(""myenum"")
+      .prop(""p"", ""v"").defaultSymbol(enumDefault).symbols(""a"", ""b"");","[{'comment': 'So this particular code decision means that the default must be set before calling .symbols(). It will not work the other way around.', 'commenter': 'bellemare'}]"
298,lang/java/avro/src/main/java/org/apache/avro/Schema.java,"@@ -1354,9 +1359,14 @@ static Schema parse(JsonNode schema, Names names) {
       } else
         throw new SchemaParseException(""Type not supported: ""+type);
       Iterator<String> i = schema.getFieldNames();
+
+      Set reserved = SCHEMA_RESERVED;
+      if (type.equals(""enum"")) {
+        reserved = ENUM_RESERVED;
+      }","[{'comment': 'The intention here was to not cause any unintended side effects. ', 'commenter': 'bellemare'}]"
298,lang/java/avro/src/main/java/org/apache/avro/Schema.java,"@@ -1354,9 +1359,14 @@ static Schema parse(JsonNode schema, Names names) {
       } else
         throw new SchemaParseException(""Type not supported: ""+type);
       Iterator<String> i = schema.getFieldNames();
+
+      Set reserved = SCHEMA_RESERVED;
+      if (type.equals(""enum"")) {","[{'comment': ""The test should instead be 'type == ENUM', no?"", 'commenter': 'cutting'}, {'comment': 'I just kept it consistent with the other references to it in this file. See line 1274 and 1330. ""type"" is actually a string here, believe it or not.', 'commenter': 'bellemare'}, {'comment': 'Sorry, I somehow tagged the wrong line.  I meant line 105, not this one.', 'commenter': 'cutting'}]"
298,doc/src/content/xdocs/idl.xml,"@@ -152,14 +152,24 @@ protocol MyProtocol {
     <section id=""format_enums"">
       <title>Defining an Enumeration</title>
       <p>
-        Enums are defined in Avro IDL using a syntax similar to C or Java:
+        Enums are defined in Avro IDL using a syntax similar to C or Java. They may also be defined with an optional default.
+        In the case that a reader schema is unable to recognize a symbol written by the writer, the reader will fall back to using the defined default value.
+        Note that this default is only used when an incompatible symbol is read but not if the enum field is missing.
+        Example Writer Schema:
       </p>
       <source>
-enum Suit {
-  SPADES, DIAMONDS, CLUBS, HEARTS
-}
+      enum Shapes {
+        SQUARE, TRIANGLE, CIRCLE, OVAL
+      }
+      </source>
+      <p>Example Reader Schema</p>
+      <source>
+        enum Shapes {
+          SQUARE, TRIANGLE, CIRCLE
+        } = CIRCLE","[{'comment': ""This needs a semicolon.  I don't know if that's the best syntax, but it is what we implemented!"", 'commenter': 'cutting'}]"
298,doc/src/content/xdocs/idl.xml,"@@ -152,15 +152,29 @@ protocol MyProtocol {
     <section id=""format_enums"">
       <title>Defining an Enumeration</title>
       <p>
-        Enums are defined in Avro IDL using a syntax similar to C or Java:
+        Enums are defined in Avro IDL using a syntax similar to C or Java. An Avro Enum supports optional default values.
+        In the case that a reader schema is unable to recognize a symbol written by the writer, the reader will fall back to using the defined default value.
+        This default is only used when an incompatible symbol is read. It is not used if the enum field is missing.
+      </p>
+      <p>
+        Example Writer Enum Definition
       </p>
       <source>
-enum Suit {
-  SPADES, DIAMONDS, CLUBS, HEARTS
+enum Shapes {
+  SQUARE, TRIANGLE, CIRCLE, OVAL
 }
       </source>
       <p>
-        Note that, unlike the JSON format, anonymous enums cannot be defined.
+        Example Reader Enum Definition
+      </p>
+      <source>
+enum Shapes {
+  SQUARE, TRIANGLE, CIRCLE
+} = CIRCLE","[{'comment': 'need a semicolon at EOL', 'commenter': 'cutting'}]"
351,lang/java/avro/src/test/java/org/apache/avro/file/TestAllCodecs.java,"@@ -0,0 +1,96 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.avro.file;
+
+import org.junit.Assert;
+import org.junit.Test;
+import org.junit.runner.RunWith;
+import org.junit.runners.Parameterized;
+
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.util.Arrays;
+import java.util.Collection;
+
+import static org.junit.Assert.assertTrue;
+
+@RunWith(Parameterized.class)
+public class TestAllCodecs {
+
+  @Parameterized.Parameters(name = ""{index}: codec={0}"")
+  public static Collection<Object[]> data() {
+    return Arrays.asList(new Object[][] {
+      { ""bzip2"", BZip2Codec.class },
+      { ""zstandard"", ZstandardCodec.class },
+      { ""null"", NullCodec.class },
+      { ""xz"", XZCodec.class },
+      { ""snappy"", SnappyCodec.class },
+      { ""deflate"", DeflateCodec.class },
+    });
+  }
+
+  @Parameterized.Parameter(0)
+  public String codec;
+
+  @Parameterized.Parameter(1)
+  public Class<? extends Codec> codecClass;
+
+
+  @Test
+  public void testCodec() throws IOException {
+    int inputSize = 500_000;
+
+    byte[] input = generateTestData(inputSize);
+
+    Codec codecInstance = CodecFactory.fromString(codec).createInstance();
+    assertTrue(codecClass.isInstance(codecInstance));
+    assertTrue(codecInstance.getName().equals(codec));
+
+    ByteBuffer inputByteBuffer = ByteBuffer.wrap(input);","[{'comment': ""Here, the original tests allocated a 2 times bigger buffer than the original input, which was supposed to test AVRO-1326 is fixed. If i'm not mistaken, with refactor this test like you did, we lose this verification."", 'commenter': 'nandorKollar'}, {'comment': ""Yes, that's true. Although I'd argue that this test wasn't really successfully testing *anything* before. (The test doesn't even clearly verify AVRO-1326, although it sort of does...it would be much more straightforward to allocate a larger buffer and call `rewind` and `limit`. Instead it's actually compressing the second (empty) half of the ByteBuffer. If we allocated `inputSize * 2 + 1` the `assert(inputSize == outputSize)` check would fail.) I honestly can't tell if that assertion passes out of lucky coincidence or if the test was written to be confusing. I think the first. :)\r\n\r\nAnyways: there's actually still a couple little bugs in that code similar to what AVRO-1326 fixes. (With how the compression code is called currently, I don't think these bugs would ever get exercised, but still...they should probably get fixed). There's another PR here: https://github.com/apache/avro/pull/352 to fix those.\r\n\r\nAs part of that PR I was going to add another test in `TestAllCodecs` to verify the changes. Without the changes in #352 the test fails, so, not adding it here; I'll add it there once this is merged. (Basically, this tests that we do the right thing for both compression and decompression, even if we start out in somewhere in the middle of the input bytebuffer). \r\n\r\n```java\r\n  @Test\r\n  public void testCodecSlice() throws IOException {\r\n    int inputSize = 500_000;\r\n    byte[] input = generateTestData(inputSize);\r\n\r\n    Codec codecInstance = CodecFactory.fromString(codec).createInstance();\r\n\r\n    ByteBuffer partialBuffer = ByteBuffer.wrap(input);\r\n    partialBuffer.position(17);\r\n\r\n    ByteBuffer inputByteBuffer = partialBuffer.slice();\r\n    ByteBuffer compressedBuffer = codecInstance.compress(inputByteBuffer);\r\n\r\n    int compressedSize = compressedBuffer.remaining();\r\n\r\n    // Make sure something returned\r\n    assertTrue(compressedSize > 0);\r\n\r\n    // Create a slice from the compressed buffer\r\n    ByteBuffer sliceBuffer = ByteBuffer.allocate(compressedSize + 100);\r\n    sliceBuffer.position(50);\r\n    sliceBuffer.put(compressedBuffer);\r\n    sliceBuffer.limit(compressedSize + 50);\r\n    sliceBuffer.position(50);\r\n\r\n    // Decompress the data\r\n    ByteBuffer decompressedBuffer = codecInstance.decompress(sliceBuffer.slice());\r\n\r\n    // Validate the the input and output are equal.\r\n    inputByteBuffer.rewind();\r\n    Assert.assertEquals(decompressedBuffer, inputByteBuffer);\r\n  }\r\n```"", 'commenter': 'jacobtolar'}]"
452,lang/java/avro/src/main/java/org/apache/avro/SchemaNormalization.java,"@@ -17,31 +17,60 @@
  */
 package org.apache.avro;
 
+import org.apache.avro.util.internal.JacksonUtils;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.HashMap;
 import java.io.IOException;
 import java.io.UnsupportedEncodingException;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
 
-/** Collection of static methods for generating the canonical form of
- * schemas (see {@link #toParsingForm}) -- and fingerprints of canonical
- * forms ({@link #fingerprint}).
+/** Collection of static methods for generating the parser canonical form of
+ * schemas (see {@link #toParsingForm}), standard canonical form of schemas
+ * (see {@link #toCanonicalForm(Schema)} or {@link #toCanonicalForm(Schema, LinkedHashSet)})
+ * with user defined Logical Types (see {@link #setLogicalTypes(LogicalTypes...)} and
+ * fingerprints of canonical forms ({@link #fingerprint}).
  */
 public class SchemaNormalization {
 
   private SchemaNormalization() {}
 
+  private static final LinkedHashSet<String> RESERVED_PROPERTIES = new LinkedHashSet<>();
+
+  private static final LinkedHashSet<LogicalTypes> ADDITIONAL_LOGICAL_TYPES = new LinkedHashSet<>();
+
+  // Avro standard reserved properties
+  static {
+    Collections.addAll(RESERVED_PROPERTIES,
+      ""name"", ""type"", ""fields"", ""symbols"", ""items"", ""values"",
+      ""logicalType"", ""size"", ""order"", ""doc"", ""aliases"", ""default"");
+  }
+
+  // Set user defined logical types for canonical form of schema definition.","[{'comment': 'We should avoid mutating static state like this.  If this is to vary from application to application, then it should probably either be an instance variable or a parameter of toCanonicalForm(), not a global, static variable.', 'commenter': 'cutting'}, {'comment': 'Updated the `Spec` for both canonical form transformation.', 'commenter': 'rumeshkrish'}]"
452,lang/java/avro/src/main/java/org/apache/avro/SchemaNormalization.java,"@@ -17,31 +17,60 @@
  */
 package org.apache.avro;
 
+import org.apache.avro.util.internal.JacksonUtils;
+import java.util.Arrays;
+import java.util.Collections;
+import java.util.LinkedHashSet;
 import java.util.Map;
 import java.util.HashMap;
 import java.io.IOException;
 import java.io.UnsupportedEncodingException;
 import java.security.MessageDigest;
 import java.security.NoSuchAlgorithmException;
 
-/** Collection of static methods for generating the canonical form of
- * schemas (see {@link #toParsingForm}) -- and fingerprints of canonical
- * forms ({@link #fingerprint}).
+/** Collection of static methods for generating the parser canonical form of
+ * schemas (see {@link #toParsingForm}), standard canonical form of schemas
+ * (see {@link #toCanonicalForm(Schema)} or {@link #toCanonicalForm(Schema, LinkedHashSet)})
+ * with user defined Logical Types (see {@link #setLogicalTypes(LogicalTypes...)} and
+ * fingerprints of canonical forms ({@link #fingerprint}).
  */
 public class SchemaNormalization {
 
   private SchemaNormalization() {}
 
+  private static final LinkedHashSet<String> RESERVED_PROPERTIES = new LinkedHashSet<>();
+
+  private static final LinkedHashSet<LogicalTypes> ADDITIONAL_LOGICAL_TYPES = new LinkedHashSet<>();
+
+  // Avro standard reserved properties
+  static {
+    Collections.addAll(RESERVED_PROPERTIES,
+      ""name"", ""type"", ""fields"", ""symbols"", ""items"", ""values"",
+      ""logicalType"", ""size"", ""order"", ""doc"", ""aliases"", ""default"");
+  }
+
+  // Set user defined logical types for canonical form of schema definition.
+  public static void setLogicalTypes(LogicalTypes... lts) {
+    ADDITIONAL_LOGICAL_TYPES.addAll(Arrays.asList(lts));
+  }
+
   /** Returns ""Parsing Canonical Form"" of a schema as defined by Avro
     * spec. */
   public static String toParsingForm(Schema s) {
-    try {
-      Map<String,String> env = new HashMap<>();
-      return build(env, s, new StringBuilder()).toString();
-    } catch (IOException e) {
-      // Shouldn't happen, b/c StringBuilder can't throw IOException
-      throw new RuntimeException(e);
-    }
+    return toNormalizedForm(s, true);
+  }
+
+  /** Returns ""Standard Canonical Form"" of a schema as defined by Avro
+    * spec. */
+  public static String toCanonicalForm(Schema s) {
+    return toCanonicalForm(s, new LinkedHashSet<>());
+  }
+
+  /** Returns ""Standard Canonical Form"" of a schema as defined by Avro","[{'comment': ""Is this in the spec yet? If not, we shouldn't claim it is.  Or else we should add it there.\r\nAlso, it would be good to more thoroughly describe how the properties parameter is used."", 'commenter': 'cutting'}]"
452,lang/java/avro/src/main/java/org/apache/avro/SchemaNormalization.java,"@@ -35,13 +39,23 @@ private SchemaNormalization() {}
   /** Returns ""Parsing Canonical Form"" of a schema as defined by Avro
     * spec. */
   public static String toParsingForm(Schema s) {
-    try {
-      Map<String,String> env = new HashMap<>();
-      return build(env, s, new StringBuilder()).toString();
-    } catch (IOException e) {
-      // Shouldn't happen, b/c StringBuilder can't throw IOException
-      throw new RuntimeException(e);
-    }
+    return toNormalizedForm(s, true, new LinkedHashSet<>());
+  }
+
+  /** Returns ""Standard Canonical Form"" of a schema as defined by Avro
+    * spec. */","[{'comment': 'The ""Standard Canonical Form"" is not yet defined in the spec, only ""Parsing Canonical Form"" is currently defined there.  You should either update the spec to define ""Standard Canonical Form"", or update this comment to define it, listing the properties it preserves and the order it presents them in.', 'commenter': 'cutting'}, {'comment': 'I will write proper `Specs`, so many people can get awareness about new feature and start using this if it is useful. ', 'commenter': 'rumeshkrish'}, {'comment': 'Hi @cutting  kindly review the below `spec`\r\n```\r\n<section>\r\n  <title>Standard Canonical Form for Schemas</title>\r\n\r\n  <p>One of defined way to normalize the avro schema using\r\n    <em>Standard Canonical Form Transformation</em>. This involves\r\n    stripping unwanted properties and maintain same canonical\r\n    ordering. The canonical ordering involves ordering avro\r\n    reserved properties followed by custom properties if mentioned while\r\n    transforming. Normalization schema which helps to reduce the\r\n    total memory size of schema (removed unwanted properties and whitespace)\r\n    while transfer avro schema between two system and also reduce the parsing\r\n    time for compatibility check and schema evolution.\r\n  </p>\r\n\r\n  <p><em>Standard Canonical Form</em> is a transformation of a schema\r\n    into standard canonical ordered. It contains only avro reserved\r\n    properties <code>""name"", ""type"", ""fields"", ""symbols"", ""items"", ""values"",\r\n      ""logicalType"", ""size"", ""order"", ""doc"", ""aliases"", ""default""</code>\r\n    and <em>other (custom properties)</em> schema properties.\r\n  </p>\r\n\r\n  <section>\r\n    <title>Transforming into Standard Canonical Form</title>\r\n\r\n    <p>Assuming an input schema (in JSON form) that\'s already\r\n      UTF-8 text for a <em>valid</em> Avro schema (including all\r\n      quotes as required by JSON), the following transformations\r\n      will produce its Standard Canonical Form:</p>\r\n    <ul>\r\n      <li> [PRIMITIVES] Convert primitive schemas to their simple\r\n        form (e.g., <code>int</code> instead of\r\n        <code>{""type"":""int""}</code>).</li>\r\n\r\n      <li> [FULLNAMES] Replace short names with fullnames, using\r\n        applicable namespaces to do so.  Then eliminate\r\n        <code>namespace</code> attributes, which are now redundant.</li>\r\n\r\n      <li> [STRIP] Keep only attributes that are relevant to\r\n        reserved properties, which are:\r\n        <code>type</code>, <code>name</code>,\r\n        <code>fields</code>, <code>symbols</code>,\r\n        <code>items</code>, <code>values</code>,\r\n        <code>logicalType</code>, <code>size</code>,\r\n        <code>order</code>, <code>doc</code>\r\n        <code>aliases</code> and <code>default</code>.\r\n        Strip all others user defined properties (e.g., <code>format</code>).</li>\r\n\r\n      <li> [ORDER] Order the appearance of fields of JSON objects\r\n        as follows: <code>name</code>, <code>type</code>,\r\n        <code>fields</code>, <code>symbols</code>,\r\n        <code>items</code>, <code>values</code>,\r\n        <code>logicalType</code>, <code>size</code>,\r\n        <code>order</code>, <code>doc</code>,\r\n        <code>aliases</code>, <code>default</code>.\r\n        For example, if an object has <code>type</code>,\r\n        <code>name</code>, and <code>size</code> fields, then the\r\n        <code>name</code> field should appear first, followed by the\r\n        <code>type</code> and then the <code>size</code> fields.</li>\r\n\r\n      <li> [STRINGS] For all JSON string literals in the schema\r\n        text, replace any escaped characters (e.g., \\uXXXX escapes)\r\n        with their UTF-8 equivalents.</li>\r\n\r\n      <li> [INTEGERS] Eliminate quotes around and any leading\r\n        zeros in front of JSON integer literals (which appear in the\r\n        <code>size</code> attributes of <code>fixed</code> schemas).</li>\r\n\r\n      <li> [WHITESPACE] Eliminate all whitespace in JSON outside of string literals.</li>\r\n    </ul>\r\n  </section>\r\n\r\n  <section>\r\n    <title>Transforming with Custom Properties</title>\r\n\r\n    <p>In addition to the standard canonical form transformation, including\r\n      <em>custom</em> <code>Schema</code> or <code>Field</code> properties by\r\n      passing the properties names while transforming.\r\n      For example, if an object has <code>format</code>, <code>type</code>,\r\n      <code>name</code>, and <code>size</code> fields, then the\r\n      <code>name</code> field should appear first, followed by the\r\n      <code>type</code>, <code>size</code> and then <code>format</code>\r\n      (custom properties) fields.\r\n    </p>\r\n  </section>\r\n</section>', 'commenter': 'rumeshkrish'}]"
452,lang/java/avro/src/main/java/org/apache/avro/SchemaNormalization.java,"@@ -35,13 +39,23 @@ private SchemaNormalization() {}
   /** Returns ""Parsing Canonical Form"" of a schema as defined by Avro
     * spec. */
   public static String toParsingForm(Schema s) {
-    try {
-      Map<String,String> env = new HashMap<>();
-      return build(env, s, new StringBuilder()).toString();
-    } catch (IOException e) {
-      // Shouldn't happen, b/c StringBuilder can't throw IOException
-      throw new RuntimeException(e);
-    }
+    return toNormalizedForm(s, true, new LinkedHashSet<>());
+  }
+
+  /** Returns ""Standard Canonical Form"" of a schema as defined by Avro
+    * spec. */
+  public static String toCanonicalForm(Schema s) {
+    return toCanonicalForm(s, new LinkedHashSet<>());
+  }
+
+  /** Returns ""Standard Canonical Form"" of a schema as defined by Avro
+    * spec with additional user standard properties. */","[{'comment': 'Again, we should either update the spec, or refer to the method above.\r\n\r\nAlso, that should just be, ""with additional user properties"", since those properties would be non-standard.', 'commenter': 'cutting'}, {'comment': 'I have created first version of `Spec` as given below, @cutting kindly review the Specification, let me know.\r\n\r\n```\r\n<section>\r\n  <title>Standard Canonical Form for Schemas</title>\r\n\r\n  <p>One of defined way to normalize the avro schema using\r\n    <em>Standard Canonical Form Transformation</em>. This involves\r\n    stripping unwanted properties and maintain same canonical\r\n    ordering. The canonical ordering involves ordering avro\r\n    reserved properties followed by custom properties if mentioned while\r\n    transforming. Normalization schema which helps to reduce the\r\n    total memory size of schema (removed unwanted properties and whitespace)\r\n    while transfer avro schema between two system and also reduce the parsing\r\n    time for compatibility check and schema evolution.\r\n  </p>\r\n\r\n  <p><em>Standard Canonical Form</em> is a transformation of a schema\r\n    into standard canonical ordered. It contains only avro reserved\r\n    properties <code>""name"", ""type"", ""fields"", ""symbols"", ""items"", ""values"",\r\n      ""logicalType"", ""size"", ""order"", ""doc"", ""aliases"", ""default""</code>\r\n    and <em>other (custom properties)</em> schema properties.\r\n  </p>\r\n\r\n  <section>\r\n    <title>Transforming into Standard Canonical Form</title>\r\n\r\n    <p>Assuming an input schema (in JSON form) that\'s already\r\n      UTF-8 text for a <em>valid</em> Avro schema (including all\r\n      quotes as required by JSON), the following transformations\r\n      will produce its Standard Canonical Form:</p>\r\n    <ul>\r\n      <li> [PRIMITIVES] Convert primitive schemas to their simple\r\n        form (e.g., <code>int</code> instead of\r\n        <code>{""type"":""int""}</code>).</li>\r\n\r\n      <li> [FULLNAMES] Replace short names with fullnames, using\r\n        applicable namespaces to do so.  Then eliminate\r\n        <code>namespace</code> attributes, which are now redundant.</li>\r\n\r\n      <li> [STRIP] Keep only attributes that are relevant to\r\n        reserved properties, which are:\r\n        <code>type</code>, <code>name</code>,\r\n        <code>fields</code>, <code>symbols</code>,\r\n        <code>items</code>, <code>values</code>,\r\n        <code>logicalType</code>, <code>size</code>,\r\n        <code>order</code>, <code>doc</code>\r\n        <code>aliases</code> and <code>default</code>.\r\n        Strip all others user defined properties (e.g., <code>format</code>).</li>\r\n\r\n      <li> [ORDER] Order the appearance of fields of JSON objects\r\n        as follows: <code>name</code>, <code>type</code>,\r\n        <code>fields</code>, <code>symbols</code>,\r\n        <code>items</code>, <code>values</code>,\r\n        <code>logicalType</code>, <code>size</code>,\r\n        <code>order</code>, <code>doc</code>,\r\n        <code>aliases</code>, <code>default</code>.\r\n        For example, if an object has <code>type</code>,\r\n        <code>name</code>, and <code>size</code> fields, then the\r\n        <code>name</code> field should appear first, followed by the\r\n        <code>type</code> and then the <code>size</code> fields.</li>\r\n\r\n      <li> [STRINGS] For all JSON string literals in the schema\r\n        text, replace any escaped characters (e.g., \\uXXXX escapes)\r\n        with their UTF-8 equivalents.</li>\r\n\r\n      <li> [INTEGERS] Eliminate quotes around and any leading\r\n        zeros in front of JSON integer literals (which appear in the\r\n        <code>size</code> attributes of <code>fixed</code> schemas).</li>\r\n\r\n      <li> [WHITESPACE] Eliminate all whitespace in JSON outside of string literals.</li>\r\n    </ul>\r\n  </section>\r\n\r\n  <section>\r\n    <title>Transforming with Custom Properties</title>\r\n\r\n    <p>In addition to the standard canonical form transformation, including\r\n      <em>custom</em> <code>Schema</code> or <code>Field</code> properties by\r\n      passing the properties names while transforming.\r\n      For example, if an object has <code>format</code>, <code>type</code>,\r\n      <code>name</code>, and <code>size</code> fields, then the\r\n      <code>name</code> field should appear first, followed by the\r\n      <code>type</code>, <code>size</code> and then <code>format</code>\r\n      (custom properties) fields.\r\n    </p>\r\n  </section>\r\n</section>', 'commenter': 'rumeshkrish'}]"
452,lang/java/avro/src/main/java/org/apache/avro/SchemaNormalization.java,"@@ -147,14 +175,55 @@ private static Appendable build(Map<String,String> env, Schema s,
         for (Schema.Field f: s.getFields()) {
           if (! firstTime) o.append(','); else firstTime = false;
           o.append(""{\""name\"":\"""").append(f.name()).append(""\"""");
-          build(env, f.schema(), o.append("",\""type\"":"")).append(""}"");
+          build(env, f.schema(), o.append("",\""type\"":""), ps, aps);
+          if (!ps) writeFieldProps(o, f, aps); // if standard canonical form then add reserved properties
+          o.append(""}"");
         }
         o.append(""]"");
       }
+      if(!ps) { writeComplexProps(o, s); writeProps(o, s.getObjectProps(), aps); }// adding the reserved property if not parser canonical schema
       return o.append(""}"");
     }
   }
 
+  private static Appendable writeLogicalType(Schema s, LogicalType lt, Appendable o, LinkedHashSet<String> aps) throws IOException {
+    o.append(""{\""type\"":\"""").append(s.getType().getName()).append(""\"""");
+    o.append(""\"""").append(LogicalType.LOGICAL_TYPE_PROP).append(""\"":\"""").append(lt.getName()).append(""\"""");
+    if (lt.getName() == ""decimal"") {
+      LogicalTypes.Decimal dlt = (LogicalTypes.Decimal) lt;
+      o.append("",\""precision\"":"").append(Integer.toString(dlt.getPrecision()));
+      if(dlt.getScale() != 0) o.append("",\""scale\"":"").append(Integer.toString(dlt.getScale()));
+    }
+    // adding the reserved property
+    writeProps(o, s.getObjectProps(), aps);
+    return o.append(""}"");
+  }
+
+  private static Appendable writeProps(Appendable o, Map<String, Object> schemaProps, LinkedHashSet<String> aps) throws IOException {
+    for (String propKey : aps) {
+      if (schemaProps.containsKey(propKey)) {
+        String propValue = JacksonUtils.toJsonNode(schemaProps.get(propKey)).toString();
+        o.append("",\"""").append(propKey).append(""\"":"").append(propValue);
+      }
+    }
+    return o;
+  }
+
+  private static Appendable writeComplexProps(Appendable o, Schema s) throws IOException {
+    if (s.getDoc() !=null && !s.getDoc().isEmpty()) o.append("",\""doc\"":\"""").append(s.getDoc()).append(""\"""");
+    if (s.getAliases() !=null && !s.getAliases().isEmpty()) o.append("",\""aliases\"":"").append(JacksonUtils.toJsonNode(s.getAliases()).toString());","[{'comment': ""Should the values for aliases be sorted when outputting the canonical? I don't believe that the order is important in the schema. Without sorting, two versions of the schema that just differ in the order of the aliases would be considered different canonical schemas."", 'commenter': 'tjwp'}, {'comment': '@tjwp Thanks for review comments. We have the different canonical schema for `aliases` property value unordered. Do you think, any other property have similar cases ?', 'commenter': 'rumeshkrish'}, {'comment': '@cutting @tjwp  as per AVRO standard we are maintain `aliases` as `LinkedHashSet` it provides insertion order  Set. Can we keep it as it is, if user defined order of aliases will maintain in the canonical form of schema. If you think, any where we are maintain similar cases, let me know. Finally, we need to have same canonical schema. ', 'commenter': 'rumeshkrish'}, {'comment': '`aliases` is the only property where I think the string values need to be sorted for the canonical form. \r\n\r\nReading back over the spec I also noticed:\r\n\r\n```\r\nA type alias may be specified either as a fully namespace-qualified, or relative to the namespace of the name it is an alias for. For example, if a type named ""a.b"" has aliases of ""c"" and ""x.y"", then the fully qualified names of its aliases are ""a.c"" and ""x.y"".\r\n```\r\n\r\nI think the implication of this is that `aliases` for types should also be normalized in the canonical form. That normalization would be to either always fully qualify the name, or always strip the namespace if it matches the namespace of the name that is aliased. Of the two options I\'d favor always fully qualifying type aliases as that\'s consistent with the handling of names in the parsing canonical form.\r\n\r\nAn example:\r\n\r\nThis type:\r\n```\r\n{\r\n  ""name"": ""B"",\r\n  ""namespace"": ""A"",\r\n  ""type"": ""record"",\r\n  ""fields"": [\r\n    { ""name"": ""X"", ""type"": ""int"", aliases: [""Y"", ""Z""] }\r\n  ],\r\n  ""aliases"": [""C.B"", ""D""]\r\n}\r\n```\r\n\r\nAnd this type:\r\n\r\n```\r\n{\r\n  ""name"": ""B"",\r\n  ""namespace"": ""A"",\r\n  ""type"": ""record"",\r\n  ""fields"": [\r\n    { ""name"": ""X"", ""type"": ""int"", aliases: [""Z"", ""Y""] }\r\n  ],\r\n  ""aliases"": [""C.B"", ""A.D""]\r\n}\r\n```\r\n\r\nShould have the same canonical form (based on what I\'ve proposed -- excluding whitespace which I\'ve kept for readability):\r\n\r\n```\r\n{\r\n  ""name"": ""A.B"",\r\n  ""type"": ""record"",\r\n  ""fields"": [\r\n    { ""name"": ""X"", ""type"": ""int"", aliases: [""Y"", ""Z""] }\r\n  ],\r\n  ""aliases"": [""A.D"", ""C.B""]\r\n}\r\n```\r\n', 'commenter': 'tjwp'}, {'comment': '@tjwp  as per avro  `NamedSchema` and `Field` has `aliases` property. How this behaviour should order for nested RECORD type ? `namespace` of inner record type field is optional (may or may not be provided), so lot of scenarios we have to handle this ordering.\r\n```\r\n{ \r\n  ""type"": ""record"",\r\n  ""name"": ""person"",\r\n  ""namespace"": ""com.test"",\r\n  ""fields"": [\r\n    {\r\n      ""name"": ""firstname"",\r\n      ""type"": ""string"",\r\n      ""aliases"": [""name"", ""f_n""]\r\n    },\r\n    {\r\n      ""name"": ""lastname"",\r\n      ""type"": ""string"",\r\n      ""aliases"": [""l_n""]\r\n    },\r\n    {\r\n      ""name"": ""address"",\r\n      ""type"": {\r\n\t\t  ""type"": ""record"",\r\n\t\t  ""name"": ""Address"",\r\n\t\t  ""fields"": [\r\n\t\t    {\r\n\t\t      ""name"": ""streetaddress"",\r\n\t\t      ""type"": ""string""\r\n\t\t    },\r\n\t\t    {\r\n\t\t      ""name"": ""city"",\r\n\t\t      ""type"": ""string""\r\n\t\t    }\r\n\t\t  ],\r\n\t\t  ""aliases"": [""Location"", ""Add""]\r\n\t\t}\r\n    }\r\n  ],\r\n  ""aliases"": [""com.mnp.person"", ""com.abc.person"", ""employee""]\r\n}', 'commenter': 'rumeshkrish'}, {'comment': 'Namespacing only applies to the names (and aliases) of records, not fields. So the aliases of fields just need to be ordered.\r\n\r\nIf a namespace is specified for a record name, or alias, then it is a full namespace so we don\'t have to worry about that type of nesting.\r\n\r\nWith nesting, the ""namespace is taken from the most tightly enclosing schema"". A simple way of looking at this is that whatever namespace applies to the record name should be applied to aliases (that are not already fully qualified) for that record.\r\n\r\nFor your example, this looks like (again ignoring whitespace):\r\n\r\n```\r\n{ \r\n  ""name"": “com.test.person"",\r\n  ""type"": ""record”,\r\n  ""fields"": [\r\n    {\r\n      ""name"": ""firstname"",\r\n      ""type"": ""string"",\r\n      ""aliases"": [“f_n”, ""name""]\r\n    },\r\n    {\r\n      ""name"": ""lastname"",\r\n      ""type"": ""string"",\r\n      ""aliases"": [""l_n""]\r\n    },\r\n    {\r\n      ""name"": ""address"",\r\n      ""type"": {\r\n                  ""name"": “com.test.Address"",\r\n                  ""type"": ""record”,\r\n                  ""fields"": [\r\n                    {\r\n                      ""name"": ""streetaddress"",\r\n                      ""type"": ""string""\r\n                    },\r\n                    {\r\n                      ""name"": ""city"",\r\n                      ""type"": ""string""\r\n                    }\r\n                  ],\r\n                  ""aliases"": [“com.test.Add”, “com.test.Location""]\r\n                }\r\n    }\r\n  ],\r\n  ""aliases"": [""com.abc.person”, ""com.mnp.person"", “com.test.employee""]\r\n}\r\n```', 'commenter': 'tjwp'}, {'comment': '@tjwp code changes for aliases ordering also done. Can you review again ?', 'commenter': 'rumeshkrish'}, {'comment': '@tjwp you can see the test cases sample here. Let me know, i will work on spec.\r\n```\r\n// 011\r\n<<INPUT\r\n  {""name"":""PigValue"",""type"":""record"",""fields"":[{""name"":""value"", ""type"":""string"", ""format"": { ""key"": ""value"" }, ""aliases"": [""B"", ""A""]}]}\r\nINPUT\r\n<<canonical {""name"":""PigValue"",""type"":""record"",""fields"":[{""name"":""value"",""type"":""string"",""order"":""ASCENDING"",""aliases"":[""A"",""B""],""format"":{""key"":""value""}}]}\r\n\r\n// 012\r\n<<INPUT\r\n  {""namespace"":""com.avro"",""name"":""PigValue"",""type"":""record"",""aliases"":[""sample"", ""com.sample.PVal""],""fields"":[{""name"":""value"", ""type"":""string"", ""format"": { ""key"": ""value"" }}]}\r\nINPUT\r\n<<canonical {""name"":""com.avro.PigValue"",""type"":""record"",""fields"":[{""name"":""value"",""type"":""string"",""order"":""ASCENDING"",""format"":{""key"":""value""}}],""aliases"":[""com.avro.sample"",""com.sample.PVal""]}\r\n\r\n// 013\r\n<<INPUT\r\n  {""aliases"":[""sample"", ""com.sample.PVal""],""name"":""PigValue"",""type"":""record"",""fields"":[{""name"":""value"", ""aliases"": [""B"", ""A""], ""type"":""string"", ""format"": { ""key"": ""value"" }}]}\r\nINPUT\r\n<<canonical {""name"":""PigValue"",""type"":""record"",""fields"":[{""name"":""value"",""type"":""string"",""order"":""ASCENDING"",""aliases"":[""A"",""B""],""format"":{""key"":""value""}}],""aliases"":[""com.sample.PVal"",""sample""]}\r\n\r\n// 014\r\n<<INPUT\r\n  {""namespace"":""com.avro"",""name"":""PigValue"",""type"":""record"",""aliases"":[""sample"", ""com.sample.PVal""],""fields"":[{""name"":""value"", ""type"":""string"", ""format"": { ""key"": ""value"" }},{""name"":""nested"",""type"":{""type"":""record"",""name"":""Nested"",""fields"":[ ],""aliases"":[""L"",""A""]}}]}\r\nINPUT\r\n<<canonical {""name"":""com.avro.PigValue"",""type"":""record"",""fields"":[{""name"":""value"",""type"":""string"",""order"":""ASCENDING"",""format"":{""key"":""value""}},{""name"":""nested"",""type"":{""name"":""com.avro.Nested"",""type"":""record"",""fields"":[],""aliases"":[""com.avro.A"",""com.avro.L""]},""order"":""ASCENDING""}],""aliases"":[""com.avro.sample"",""com.sample.PVal""]}\r\n\r\n', 'commenter': 'rumeshkrish'}]"
492,.gitignore,"@@ -20,3 +20,4 @@ test-output
 **/.vscode/**/*
 .DS_Store
 .factorypath
+/.vs","[{'comment': ""Change this to `.vs/` and then I don't think you will need the changes in `lang/csharp/.gitignore`"", 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Schema/LogicalSchema.cs,"@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using Avro.Util;
+using Newtonsoft.Json.Linq;
+
+namespace Avro
+{
+    /// <summary>
+    /// Class for logical type schemas.
+    /// </summary>
+    public class LogicalSchema : UnnamedSchema
+    {
+        /// <summary>
+        /// The name of the logical type JSON property.
+        /// </summary>
+        public static readonly string LogicalTypeProperty = ""logicalType"";","[{'comment': '`LogicalTypeProperty` is never used. Should we remove it, or should we use it in `Schema`?', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Schema/LogicalSchema.cs,"@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using Avro.Util;
+using Newtonsoft.Json.Linq;
+
+namespace Avro
+{
+    /// <summary>
+    /// Class for logical type schemas.
+    /// </summary>
+    public class LogicalSchema : UnnamedSchema
+    {
+        /// <summary>
+        /// The name of the logical type JSON property.
+        /// </summary>
+        public static readonly string LogicalTypeProperty = ""logicalType"";
+
+        /// <summary>
+        /// Schema for the underlying type that the logical type is based on.
+        /// </summary>
+        public Schema BaseSchema { get; set; }","[{'comment': 'It appears these properties are never set outside this class. I think we can safely make them `private set`.\r\n\r\n```suggestion\r\n        public Schema BaseSchema { get; private set; }\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Schema/LogicalSchema.cs,"@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using Avro.Util;
+using Newtonsoft.Json.Linq;
+
+namespace Avro
+{
+    /// <summary>
+    /// Class for logical type schemas.
+    /// </summary>
+    public class LogicalSchema : UnnamedSchema
+    {
+        /// <summary>
+        /// The name of the logical type JSON property.
+        /// </summary>
+        public static readonly string LogicalTypeProperty = ""logicalType"";
+
+        /// <summary>
+        /// Schema for the underlying type that the logical type is based on.
+        /// </summary>
+        public Schema BaseSchema { get; set; }
+
+        /// <summary>
+        /// The logical type name.
+        /// </summary>
+        public string LogicalTypeName { get; set; }","[{'comment': '```suggestion\r\n        public string LogicalTypeName { get; private set; }\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Schema/LogicalSchema.cs,"@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using Avro.Util;
+using Newtonsoft.Json.Linq;
+
+namespace Avro
+{
+    /// <summary>
+    /// Class for logical type schemas.
+    /// </summary>
+    public class LogicalSchema : UnnamedSchema
+    {
+        /// <summary>
+        /// The name of the logical type JSON property.
+        /// </summary>
+        public static readonly string LogicalTypeProperty = ""logicalType"";
+
+        /// <summary>
+        /// Schema for the underlying type that the logical type is based on.
+        /// </summary>
+        public Schema BaseSchema { get; set; }
+
+        /// <summary>
+        /// The logical type name.
+        /// </summary>
+        public string LogicalTypeName { get; set; }
+
+        /// <summary>
+        /// The logical type implementation that supports this logical type.
+        /// </summary>
+        public LogicalType LogicalType { get; set; }","[{'comment': '```suggestion\r\n        public LogicalType LogicalType { get; private set; }\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Schema/LogicalSchema.cs,"@@ -0,0 +1,124 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using Avro.Util;
+using Newtonsoft.Json.Linq;
+
+namespace Avro
+{
+    /// <summary>
+    /// Class for logical type schemas.
+    /// </summary>
+    public class LogicalSchema : UnnamedSchema
+    {
+        /// <summary>
+        /// The name of the logical type JSON property.
+        /// </summary>
+        public static readonly string LogicalTypeProperty = ""logicalType"";
+
+        /// <summary>
+        /// Schema for the underlying type that the logical type is based on.
+        /// </summary>
+        public Schema BaseSchema { get; set; }
+
+        /// <summary>
+        /// The logical type name.
+        /// </summary>
+        public string LogicalTypeName { get; set; }
+
+        /// <summary>
+        /// The logical type implementation that supports this logical type.
+        /// </summary>
+        public LogicalType LogicalType { get; set; }
+
+        internal static LogicalSchema NewInstance(JToken jtok, PropertyMap props, SchemaNames names, string encspace)
+        {
+            JToken jtype = jtok[""type""];
+            if (null == jtype) throw new AvroTypeException(""Logical Type does not have 'type'"");
+
+            return new LogicalSchema(Schema.ParseJson(jtype, names, encspace), JsonHelper.GetRequiredString(jtok, ""logicalType""),  props);
+        }
+
+        private LogicalSchema(Schema baseSchema, string logicalTypeName,  PropertyMap props) : base(Type.Logical, props)
+        {
+            if (null == baseSchema) throw new ArgumentNullException(nameof(baseSchema));
+            BaseSchema = baseSchema;
+            LogicalTypeName = logicalTypeName;
+            LogicalType = LogicalTypeFactory.Instance.GetFromLogicalSchema(this);
+        }
+
+        /// <summary>
+        /// Writes logical schema in JSON format
+        /// </summary>
+        /// <param name=""writer"">JSON writer</param>
+        /// <param name=""names"">list of named schemas already written</param>
+        /// <param name=""encspace"">enclosing namespace of the schema</param>
+        protected internal override void WriteJson(Newtonsoft.Json.JsonTextWriter writer, SchemaNames names, string encspace)
+        {
+            writer.WriteStartObject();
+            writer.WritePropertyName(""type"");
+            BaseSchema.WriteJson(writer, names, encspace);
+            writer.WritePropertyName(""logicalType"");
+            writer.WriteValue(LogicalTypeName);
+            if (null != Props)
+                Props.WriteJson(writer);
+            writer.WriteEndObject();
+        }
+
+        /// <summary>
+        /// Checks if this schema can read data written by the given schema. Used for decoding data.
+        /// </summary>
+        /// <param name=""writerSchema"">writer schema</param>
+        /// <returns>true if this and writer schema are compatible based on the AVRO specification, false otherwise</returns>
+        public override bool CanRead(Schema writerSchema)
+        {
+            if (writerSchema.Tag != Tag) return false;
+
+            LogicalSchema that = writerSchema as LogicalSchema;
+            return BaseSchema.CanRead(that.BaseSchema);
+        }
+
+        /// <summary>
+        /// Function to compare equality of two logical schemas
+        /// </summary>
+        /// <param name=""obj"">other logical schema</param>
+        /// <returns>true if two schemas are equal, false otherwise</returns>
+        public override bool Equals(object obj)
+        {
+            if (this == obj) return true;
+
+            if (obj != null && obj is LogicalSchema)
+            {
+                LogicalSchema that = obj as LogicalSchema;","[{'comment': 'This is a good opportunity for the `is` type pattern expression:\r\n\r\n```c#\r\n            if (obj != null && obj is LogicalSchema that)\r\n            {\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/test/Util/LogicalTypeTests.cs,"@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Globalization;
+using Avro.Util;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+    [TestFixture]
+    class LogicalTypeTests
+    {
+        [TestCase(""1234.56"")]
+        [TestCase(""-1234.56"")]
+        [TestCase(""123456789123456789.56"")]
+        [TestCase(""-123456789123456789.56"")]
+        [TestCase(""000000000000000001.01"")]
+        [TestCase(""-000000000000000001.01"")]
+        public void TestDecimal(string s)","[{'comment': '@petersilverwood suggested including `Decimal.MinValue` and `Decimal.MaxValue` over in the confluent fork. Also, `0.0` would be a good one.', 'commenter': 'mhowlett'}]"
492,lang/csharp/src/apache/main/AvroDecimal.cs,"@@ -0,0 +1,983 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Globalization;
+using System.Numerics;
+
+namespace Avro
+{
+    /// <summary>
+    /// Represents a big decimal.
+    /// </summary>
+    #pragma warning disable CS1591 // Missing XML comment for publicly visible type or member
+    public struct AvroDecimal : IConvertible, IFormattable, IComparable, IComparable<AvroDecimal>, IEquatable<AvroDecimal>
+    {
+        /// <summary>
+        /// The number '-1'.
+        /// </summary>
+        public static readonly AvroDecimal MinusOne = new AvroDecimal(BigInteger.MinusOne, 0);","[{'comment': ""Do you think the `MinusOne`, `Zero`, `One`, `IsEven`, `IsOne`, `IsPowerOfTwo`, `IsZero` and `Sign` properties are useful? (I can't see the value in mimicking the BigInteger class here)"", 'commenter': 'mhowlett'}, {'comment': ""`ONE`, `ZERO`, and `TEN` are available on Java's `BigDecimal` class. You could lose the `IsZero` and `IsOne` properties because you could easily compare against `Zero` or `One` (i.e., `myDec == AvroDecimal.Zero`), or even `myDec == 0.0m` which will select the `==` operator.\r\n\r\nI'm not precious about any of these properties."", 'commenter': 'timjroberts'}]"
492,lang/csharp/src/apache/main/AvroDecimal.cs,"@@ -0,0 +1,983 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Globalization;
+using System.Numerics;
+
+namespace Avro
+{
+    /// <summary>
+    /// Represents a big decimal.
+    /// </summary>
+    #pragma warning disable CS1591 // Missing XML comment for publicly visible type or member
+    public struct AvroDecimal : IConvertible, IFormattable, IComparable, IComparable<AvroDecimal>, IEquatable<AvroDecimal>
+    {
+        /// <summary>
+        /// The number '-1'.
+        /// </summary>
+        public static readonly AvroDecimal MinusOne = new AvroDecimal(BigInteger.MinusOne, 0);
+
+        /// <summary>
+        /// The number '0'.
+        /// </summary>
+        public static readonly AvroDecimal Zero = new AvroDecimal(BigInteger.Zero, 0);
+
+        /// <summary>
+        /// The number '1'.
+        /// </summary>
+        public static readonly AvroDecimal One = new AvroDecimal(BigInteger.One, 0);
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given double.
+        /// </summary>
+        /// <param name=""value"">The double value.</param>
+        public AvroDecimal(double value)
+            : this((decimal)value)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given float.
+        /// </summary>
+        /// <param name=""value"">The float value.</param>
+        public AvroDecimal(float value)
+            : this((decimal)value)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given decimal.
+        /// </summary>
+        /// <param name=""value"">The decimal value.</param>
+        public AvroDecimal(decimal value)
+        {
+            var bytes = GetBytesFromDecimal(value);
+
+            var unscaledValueBytes = new byte[12];
+            Array.Copy(bytes, unscaledValueBytes, unscaledValueBytes.Length);
+
+            var unscaledValue = new BigInteger(unscaledValueBytes);
+            var scale = bytes[14];
+
+            if (bytes[15] == 128)
+                unscaledValue *= BigInteger.MinusOne;
+
+            UnscaledValue = unscaledValue;
+            Scale = scale;
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given int.
+        /// </summary>
+        /// <param name=""value"">The int value.</param>
+        public AvroDecimal(int value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given long.
+        /// </summary>
+        /// <param name=""value"">The long value.</param>
+        public AvroDecimal(long value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given unsigned int.
+        /// </summary>
+        /// <param name=""value"">The unsigned int value.</param>
+        public AvroDecimal(uint value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given unsigned long.
+        /// </summary>
+        /// <param name=""value"">The unsigned long value.</param>
+        public AvroDecimal(ulong value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given <see cref=""BigInteger""/>
+        /// and a scale.
+        /// </summary>
+        /// <param name=""unscaledValue"">The double value.</param>
+        /// <param name=""scale"">The scale.</param>
+        public AvroDecimal(BigInteger unscaledValue, int scale)
+        {
+            UnscaledValue = unscaledValue;
+            Scale = scale;
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given array of bytes.
+        /// </summary>
+        /// <param name=""value"">The byte array.</param>
+        public AvroDecimal(byte[] value)
+        {
+            byte[] number = new byte[value.Length - 4];
+            byte[] flags = new byte[4];
+
+            Array.Copy(value, 0, number, 0, number.Length);
+            Array.Copy(value, value.Length - 4, flags, 0, 4);
+
+            UnscaledValue = new BigInteger(number);
+            Scale = BitConverter.ToInt32(flags, 0);
+        }
+
+        /// <summary>
+        /// Gets the unscaled integer value represented by the current <see cref=""AvroDecimal""/>.
+        /// </summary>
+        public BigInteger UnscaledValue { get; }
+
+        /// <summary>
+        /// Gets a value indicating whether the current <see cref=""AvroDecimal""/> represents an even number.
+        /// </summary>
+        public bool IsEven
+        {
+            get { return UnscaledValue.IsEven; }","[{'comment': 'this is not true if scale is != 0 right? same comment with other properties below.', 'commenter': 'mhowlett'}, {'comment': ""Ah, yeah, of course. Decimals don't have the notion of even and odd. As per your previous comment, I'll remove these properties rather than test on the `Scale` which may be confusing."", 'commenter': 'timjroberts'}]"
492,lang/csharp/src/apache/main/AvroDecimal.cs,"@@ -0,0 +1,983 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Globalization;
+using System.Numerics;
+
+namespace Avro
+{
+    /// <summary>
+    /// Represents a big decimal.
+    /// </summary>
+    #pragma warning disable CS1591 // Missing XML comment for publicly visible type or member
+    public struct AvroDecimal : IConvertible, IFormattable, IComparable, IComparable<AvroDecimal>, IEquatable<AvroDecimal>
+    {
+        /// <summary>
+        /// The number '-1'.
+        /// </summary>
+        public static readonly AvroDecimal MinusOne = new AvroDecimal(BigInteger.MinusOne, 0);
+
+        /// <summary>
+        /// The number '0'.
+        /// </summary>
+        public static readonly AvroDecimal Zero = new AvroDecimal(BigInteger.Zero, 0);
+
+        /// <summary>
+        /// The number '1'.
+        /// </summary>
+        public static readonly AvroDecimal One = new AvroDecimal(BigInteger.One, 0);
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given double.
+        /// </summary>
+        /// <param name=""value"">The double value.</param>
+        public AvroDecimal(double value)
+            : this((decimal)value)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given float.
+        /// </summary>
+        /// <param name=""value"">The float value.</param>
+        public AvroDecimal(float value)
+            : this((decimal)value)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given decimal.
+        /// </summary>
+        /// <param name=""value"">The decimal value.</param>
+        public AvroDecimal(decimal value)
+        {
+            var bytes = GetBytesFromDecimal(value);
+
+            var unscaledValueBytes = new byte[12];
+            Array.Copy(bytes, unscaledValueBytes, unscaledValueBytes.Length);
+
+            var unscaledValue = new BigInteger(unscaledValueBytes);
+            var scale = bytes[14];
+
+            if (bytes[15] == 128)
+                unscaledValue *= BigInteger.MinusOne;
+
+            UnscaledValue = unscaledValue;
+            Scale = scale;
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given int.
+        /// </summary>
+        /// <param name=""value"">The int value.</param>
+        public AvroDecimal(int value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given long.
+        /// </summary>
+        /// <param name=""value"">The long value.</param>
+        public AvroDecimal(long value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given unsigned int.
+        /// </summary>
+        /// <param name=""value"">The unsigned int value.</param>
+        public AvroDecimal(uint value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given unsigned long.
+        /// </summary>
+        /// <param name=""value"">The unsigned long value.</param>
+        public AvroDecimal(ulong value)
+            : this(new BigInteger(value), 0) { }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given <see cref=""BigInteger""/>
+        /// and a scale.
+        /// </summary>
+        /// <param name=""unscaledValue"">The double value.</param>
+        /// <param name=""scale"">The scale.</param>
+        public AvroDecimal(BigInteger unscaledValue, int scale)
+        {
+            UnscaledValue = unscaledValue;
+            Scale = scale;
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""AvroDecimal""/> class from a given array of bytes.
+        /// </summary>
+        /// <param name=""value"">The byte array.</param>
+        public AvroDecimal(byte[] value)
+        {
+            byte[] number = new byte[value.Length - 4];
+            byte[] flags = new byte[4];
+
+            Array.Copy(value, 0, number, 0, number.Length);
+            Array.Copy(value, value.Length - 4, flags, 0, 4);
+
+            UnscaledValue = new BigInteger(number);
+            Scale = BitConverter.ToInt32(flags, 0);
+        }
+
+        /// <summary>
+        /// Gets the unscaled integer value represented by the current <see cref=""AvroDecimal""/>.
+        /// </summary>
+        public BigInteger UnscaledValue { get; }
+
+        /// <summary>
+        /// Gets a value indicating whether the current <see cref=""AvroDecimal""/> represents an even number.
+        /// </summary>
+        public bool IsEven
+        {
+            get { return UnscaledValue.IsEven; }
+        }
+
+        /// <summary>
+        /// Gets a value indicating whether the current <see cref=""AvroDecimal""/> represents the number '1'.
+        /// </summary>
+        public bool IsOne
+        {
+            get { return UnscaledValue.IsOne; }
+        }
+
+        /// <summary>
+        /// Gets a value indicating whether the current <see cref=""AvroDecimal""/> represents a number that is a power of two.
+        /// </summary>
+        public bool IsPowerOfTwo
+        {
+            get { return UnscaledValue.IsPowerOfTwo; }
+        }
+
+        /// <summary>
+        /// Gets a value indicating whether the current <see cref=""AvroDecimal""/> represents the number '0'.
+        /// </summary>
+        public bool IsZero
+        {
+            get { return UnscaledValue.IsZero; }
+        }
+
+        /// <summary>
+        /// Gets the sign of the current <see cref=""AvroDecimal""/>.
+        /// </summary>
+        public int Sign
+        {
+            get { return UnscaledValue.Sign; }
+        }
+
+        /// <summary>
+        /// Gets the scale of the current <see cref=""AvroDecimal""/>.
+        /// </summary>
+        public int Scale { get; }
+
+        /// <summary>
+        /// Converts the current <see cref=""AvroDecimal""/> to a string.
+        /// </summary>
+        /// <returns>A string representation of the numeric value.</returns>
+        public override string ToString()
+        {
+            var number = UnscaledValue.ToString(CultureInfo.CurrentCulture);
+
+            if (Scale > 0)
+                return number.Insert(number.Length - Scale, CultureInfo.CurrentCulture.NumberFormat.NumberDecimalSeparator);
+
+            return number;
+        }
+
+        /// <summary>
+        /// Converts the current <see cref=""AvroDecimal""/> to a byte array.
+        /// </summary>
+        /// <returns>The current <see cref=""AvroDecimal""/> converted to an array of bytes.</returns>
+        public byte[] ToByteArray()
+        {
+            var unscaledValue = UnscaledValue.ToByteArray();
+            var scale = BitConverter.GetBytes(Scale);","[{'comment': ""The spec says:\r\n\r\n> The byte array must contain the two's-complement representation of the unscaled integer value in big-endian byte order. The scale is fixed, and is specified using an attribute.\r\n\r\nThis method is used by `ConvertToBaseValue` in `Decimal` to achieve this. However this method serializes the scale in addition to the unscaled value, so it doesn't conform."", 'commenter': 'mhowlett'}, {'comment': ""it'd be ideal to see some evidence of cross language integration testing. not sure how best to set that up, but maybe have a java test app that writes data to disk, read by a dotnet test app & vice versa."", 'commenter': 'mhowlett'}, {'comment': ""Good point, Matt. The [interop tests] exist to test some of the cross language features. However, the [`interop.avsc`] does not currently define any logical types.\r\n\r\n@Fokko, are you aware of any interop tests that exercise logical types? Maybe I'm just missing something.\r\n\r\n[interop tests]: https://github.com/apache/avro/tree/master/lang/csharp/src/apache/test/Interop\r\n[`interop.avsc`]: https://github.com/apache/avro/blob/master/share/test/schemas/interop.avsc"", 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Generic/PreresolvingDatumWriter.cs,"@@ -232,6 +234,17 @@ private void WriteArray(WriteItem itemWriter, object array, Encoder encoder)
             encoder.WriteArrayEnd();
         }
 
+        /// <summary>
+        /// Serializes a logical value object by using the underlying logical type to convert the value
+        /// to its base value.
+        /// </summary>
+        /// <param name=""schema"">The logical schema.</param>
+        protected WriteItem ResolveLogical(LogicalSchema schema)
+        {
+            var baseWriter = ResolveWriter(schema.BaseSchema);
+            return (d, e) => baseWriter(schema.LogicalType.ConvertToBaseValue(d, schema), e);","[{'comment': ""passing `schema` in as an argument to `ConvertToBaseValue` here seems really unorthodox, since it's a method on a property of the object itself. I have not bothered to dig deeper, but suspect this is indication of a factoring that isn't right."", 'commenter': 'mhowlett'}]"
492,lang/csharp/src/apache/main/Util/Date.cs,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+
+namespace Avro.Util
+{
+    /// <summary>
+    /// The 'date' logical type.
+    /// </summary>
+    public class Date : LogicalUnixEpochType<DateTime>
+    {
+        /// <summary>
+        /// The logical type name for Date.
+        /// </summary>
+        public static readonly string LogicalTypeName = ""date"";
+
+        /// <summary>
+        /// Initializes a new Date logical type.
+        /// </summary>
+        public Date() : base(LogicalTypeName)","[{'comment': ""I think you want `schema` to be passed as a constructor argument, not as a parameter in the methods below. Either that or have everything purely functional. Note: again, haven't analysed everything super closely, just pointing out something that seems wrong."", 'commenter': 'mhowlett'}]"
492,lang/csharp/src/apache/test/Schema/SchemaTests.cs,"@@ -261,6 +261,27 @@ public void TestArray(string s, string item)
             testToString(sc);
         }
 
+        [TestCase(""{\""type\"": \""int\"", \""logicalType\"": \""date\""}"", ""int"", ""date"")]
+        public void TestLogicalPrimitive(string s, string baseType, string logicalType)
+        {
+            Schema sc = Schema.Parse(s);
+            Assert.AreEqual(Schema.Type.Logical, sc.Tag);
+            LogicalSchema logsc = sc as LogicalSchema;
+            Assert.AreEqual(baseType, logsc.BaseSchema.Name);
+            Assert.AreEqual(logicalType, logsc.LogicalType.Name);
+
+            testEquality(s, sc);
+            testToString(sc);
+        }
+
+        [TestCase(""{\""type\"": \""int\"", \""logicalType\"": \""unknown\""}"", ""unknown"")]
+        public void TestUnknownLogical(string s, string unknownType)
+        {
+            var err = Assert.Throws<AvroTypeException>(() => Schema.Parse(s));","[{'comment': ""The [spec states](http://avro.apache.org/docs/1.9.1/spec.html#Logical+Types) that unknown and invalid logical types should be ignored, and only the base type should be used.\r\n\r\n> Language implementations must ignore unknown logical types when reading, and should use the underlying Avro type. If a logical type is invalid, for example a decimal with scale greater than its precision, then implementations should ignore the logical type and use the underlying Avro type.\r\n\r\nBased on those statements, I don't believe that we should throw an exception when an unrecognized logical type is encountered."", 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/test/Schema/SchemaTests.cs,"@@ -261,6 +261,27 @@ public void TestArray(string s, string item)
             testToString(sc);
         }
 
+        [TestCase(""{\""type\"": \""int\"", \""logicalType\"": \""date\""}"", ""int"", ""date"")]
+        public void TestLogicalPrimitive(string s, string baseType, string logicalType)","[{'comment': 'Could you add test cases for the other supported logical types in `SchemaTests`?', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/test/Util/LogicalTypeTests.cs,"@@ -0,0 +1,161 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Globalization;
+using Avro.Util;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+    [TestFixture]
+    class LogicalTypeTests
+    {
+        [TestCase(""1234.56"")]
+        [TestCase(""-1234.56"")]
+        [TestCase(""123456789123456789.56"")]
+        [TestCase(""-123456789123456789.56"")]
+        [TestCase(""000000000000000001.01"")]
+        [TestCase(""-000000000000000001.01"")]
+        public void TestDecimal(string s)
+        {
+            var schema = (LogicalSchema)Schema.Parse(""{\""type\"": \""bytes\"", \""logicalType\"": \""decimal\"", \""precision\"": 4, \""scale\"": 2 }"");
+
+            var avroDecimal = new Avro.Util.Decimal();
+            var decimalVal = (AvroDecimal)decimal.Parse(s);
+
+            var convertedDecimalVal = (AvroDecimal)avroDecimal.ConvertToLogicalValue(avroDecimal.ConvertToBaseValue(decimalVal, schema), schema);
+
+            Assert.AreEqual(decimalVal, convertedDecimalVal);
+        }
+
+        [TestCase]
+        public void TestDecimalMinMax()
+        {
+            var schema = (LogicalSchema)Schema.Parse(""{\""type\"": \""bytes\"", \""logicalType\"": \""decimal\"", \""precision\"": 4, \""scale\"": 0 }"");
+
+            var avroDecimal = new Avro.Util.Decimal();
+
+            foreach (var decimalVal in new AvroDecimal[] { decimal.MinValue, decimal.MaxValue })
+            {
+                var convertedDecimalVal = (AvroDecimal)avroDecimal.ConvertToLogicalValue(avroDecimal.ConvertToBaseValue(decimalVal, schema), schema);
+
+                Assert.AreEqual(decimalVal, convertedDecimalVal);
+            }
+        }
+
+        [TestCase]
+        public void TestDecimalOutOfRangeException()
+        {
+            var schema = (LogicalSchema)Schema.Parse(""{\""type\"": \""bytes\"", \""logicalType\"": \""decimal\"", \""precision\"": 4, \""scale\"": 2 }"");
+
+            var avroDecimal = new Avro.Util.Decimal();
+            var decimalVal = (AvroDecimal)1234.567M; // scale of 3 should throw ArgumentOutOfRangeException
+
+            Assert.Throws<ArgumentOutOfRangeException>(() => avroDecimal.ConvertToBaseValue(decimalVal, schema));
+        }
+
+        [TestCase(""01/01/2019"")]
+        [TestCase(""05/05/2019"")]
+        [TestCase(""05/05/2019 00:00:00Z"")]
+        [TestCase(""05/05/2019 01:00:00Z"")]
+        [TestCase(""05/05/2019 01:00:00+01:00"")]
+        public void TestDate(string s)
+        {
+            var schema = (LogicalSchema)Schema.Parse(""{\""type\"": \""int\"", \""logicalType\"": \""date\""}"");
+
+            var date = DateTime.Parse(s, CultureInfo.GetCultureInfo(""en-US"").DateTimeFormat, DateTimeStyles.RoundtripKind);
+
+            if (date.Kind != DateTimeKind.Utc)
+            {
+                date = DateTime.Parse(s, CultureInfo.GetCultureInfo(""en-US"").DateTimeFormat, DateTimeStyles.AssumeLocal);
+            }
+
+            var avroDate = new Date();
+
+            var convertedDate = (DateTime)avroDate.ConvertToLogicalValue(avroDate.ConvertToBaseValue(date, schema), schema);
+
+            Assert.AreEqual(new TimeSpan(0, 0, 0), convertedDate.TimeOfDay); // the time should always be 00:00:00
+            Assert.AreEqual(date.Date, convertedDate.Date);
+        }
+
+        [TestCase(""01/01/2019 14:20:00Z"", ""01/01/2019 14:20:00Z"")]
+        [TestCase(""01/01/2019 14:20:00"", ""01/01/2019 14:20:00Z"")]
+        [TestCase(""05/05/2019 14:20:00Z"", ""05/05/2019 14:20:00Z"")]
+        [TestCase(""05/05/2019 14:20:00+01:00"", ""05/05/2019 13:20:00Z"")]
+        [TestCase(""05/05/2019 00:00:00Z"", ""05/05/2019 00:00:00Z"")]
+        [TestCase(""05/05/2019 00:00:00+01:00"", ""05/04/2019 23:00:00Z"")] // adjusted to UTC
+        public void TestTimestamp(string s, string e)
+        {
+            var schema = (LogicalSchema)Schema.Parse(""{\""type\"": \""int\"", \""logicalType\"": \""date\""}"");","[{'comment': 'Is this schema supposed to mention the logical type `timestamp-millis` or `timestamp-micros` instead of `date`?', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/LogicalType.cs,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/LogicalUnixEpochTimeType.cs,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/TimeMicrosecond.cs,"@@ -0,0 +1,77 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}, {'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/TimestampMicrosecond.cs,"@@ -0,0 +1,71 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/TimestampMillisecond.cs,"@@ -0,0 +1,70 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/LogicalType.cs,"@@ -0,0 +1,75 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ 
+namespace Avro.Util
+{
+    /// <summary>
+    /// Base for all logical type implementations.
+    /// </summary>
+    public abstract class LogicalType
+    {
+        /// <summary>
+        /// The logical type name.
+        /// </summary>
+        public string Name { get; }
+
+        /// <summary>
+        /// Initializes the base logical type.
+        /// </summary>
+        /// <param name=""name"">The logical type name.</param>
+        protected LogicalType(string name)
+        {
+            Name = name;
+        }
+
+        /// <summary>
+        /// Applies logical type validation for a given logical schema.
+        /// </summary>
+        /// <param name=""schema"">The schema to be validated.</param>
+        public virtual void ValidateSchema(LogicalSchema schema)
+        { }
+
+        /// <summary>
+        /// Converts a logical value to an instance of its base type.
+        /// </summary>
+        /// <param name=""logicalValue"">The logical value to convert.</param>
+        /// <param name=""schema"">The schema that represents the target of the conversion.</param>
+        /// <returns>An object representing the encoded value of the base type.</returns>
+        public abstract object ConvertToBaseValue(object logicalValue, LogicalSchema schema);
+
+        /// <summary>
+        /// Converts a base value to an instance of the logical type.
+        /// </summary>
+        /// <param name=""baseValue"">The base value to convert.</param>
+        /// <param name=""schema"">The schema that represents the target of the conversion.</param>
+        /// <returns>An object representing the encoded value of the logical type.</returns>
+        public abstract object ConvertToLogicalValue(object baseValue, LogicalSchema schema);
+
+        /// <summary>
+        /// Retrieve the .NET type that is represented by the logical type implementation.
+        /// </summary>
+        /// <param name=""nullible"">A flag indicating whether it should be nullible.</param>
+        public abstract string GetCSharpTypeName(bool nullible);","[{'comment': 'What do you think of returning the `Type`, rather than the name of the type here. For example: `public abstract Type GetCSharpType(bool nullible);`', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/LogicalUnixEpochTimeType.cs,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+
+namespace Avro.Util
+{
+    /// <summary>
+    /// Base for all logical type implementations that are based on the Unix Epoch date/time.
+    /// </summary>
+    public abstract class LogicalUnixEpochType<T> : LogicalType
+    {
+        /// <summary>
+        /// The date and time of the Unix Epoch.
+        /// </summary>
+        protected static readonly DateTime UnixEpocDateTime = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc);
+
+        /// <summary>
+        /// The date of the Unix Epoch
+        /// </summary>
+        protected static readonly DateTime UnixEpocDate = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc).Date;","[{'comment': ""`UnixEpocDate` and `UnixEpocDateTime` are equivalent. I don't think there is any need for both."", 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/LogicalUnixEpochTimeType.cs,"@@ -0,0 +1,65 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+
+namespace Avro.Util
+{
+    /// <summary>
+    /// Base for all logical type implementations that are based on the Unix Epoch date/time.
+    /// </summary>
+    public abstract class LogicalUnixEpochType<T> : LogicalType
+    {
+        /// <summary>
+        /// The date and time of the Unix Epoch.
+        /// </summary>
+        protected static readonly DateTime UnixEpocDateTime = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc);","[{'comment': '```suggestion\r\n        protected static readonly DateTime UnixEpochDateTime = new DateTime(1970, 1, 1, 0, 0, 0, DateTimeKind.Utc);\r\n```', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/Decimal.cs,"@@ -0,0 +1,157 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Globalization;
+using System.Numerics;
+using Avro.Generic;
+
+namespace Avro.Util
+{
+    /// <summary>
+    /// The 'decimal' logical type.
+    /// </summary>
+    public class Decimal : LogicalType
+    {
+        /// <summary>
+        /// The logical type name for Decimal.
+        /// </summary>
+        public static readonly string LogicalTypeName = ""decimal"";
+
+        /// <summary>
+        /// Initializes a new Decimal logical type.
+        /// </summary>
+        public Decimal() : base(LogicalTypeName)
+        { }
+
+        /// <summary>
+        /// Applies 'decimal' logical type validation for a given logical schema.
+        /// </summary>
+        /// <param name=""schema"">The schema to be validated.</param>
+        public override void ValidateSchema(LogicalSchema schema)
+        {
+            if (Schema.Type.Bytes != schema.BaseSchema.Tag && Schema.Type.Fixed != schema.BaseSchema.Tag)
+                throw new AvroTypeException(""'decimal' can only be used with an underlying bytes or fixed type"");
+
+            var precisionVal = schema.GetProperty(""precision"");
+
+            if (string.IsNullOrEmpty(precisionVal))
+                throw new AvroTypeException(""'decimal' requires a 'precision' property"");
+
+            var precision = int.Parse(precisionVal, CultureInfo.CurrentCulture);
+
+            if (precision <= 0)
+                throw new AvroTypeException(""'decimal' requires a 'precision' property that is greater than zero"");
+
+            var scale = GetIntPropertyValueFromSchema(schema, ""scale"");
+
+            if (scale < 0 || scale > precision)
+                throw new AvroTypeException(""'decimal' requires a 'scale' property that is zero or less than or equal to 'precision'"");
+        }
+
+        /// <summary>
+        /// Converts a logical value to an instance of its base type.
+        /// </summary>
+        /// <param name=""logicalValue"">The logical value to convert.</param>
+        /// <param name=""schema"">The schema that represents the target of the conversion.</param>
+        /// <returns>An object representing the encoded value of the base type.</returns>        
+        public override object ConvertToBaseValue(object logicalValue, LogicalSchema schema)","[{'comment': 'Rather than copy-pasting the documentation of each of these methods from `LogicalType`, use `/// <inheritdoc/>`. Only copy-paste-modify if the specific override of the method requires some customizations.', 'commenter': 'blachniet'}]"
492,lang/csharp/src/apache/main/Util/LogicalTypeFactory.cs,"@@ -0,0 +1,76 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System.Collections.Generic;
+
+namespace Avro.Util
+{
+    /// <summary>
+    /// A factory for logical type implementations.
+    /// </summary>
+    public class LogicalTypeFactory","[{'comment': 'We should probably allow users to register their own logical types, and even override some of the built-in ones. The Java API supports this with a [register method](http://avro.apache.org/docs/1.9.1/api/java/index.html)', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Avro.main.csproj,"@@ -19,7 +19,7 @@
   <Import Project=""../../../common.props"" />
 
   <PropertyGroup>
-    <TargetFrameworks>net40;netstandard2.0</TargetFrameworks>
+    <TargetFrameworks>netstandard2.0</TargetFrameworks>","[{'comment': ""Was there something in these changes that prevented you from targeting net40?\r\n\r\nWe are currently supporting .NET Framework 4.0+ in the Avro C# libraries. Removing it here would be a breaking change. I've been toying with the idea of dumping support for anything prior to 4.6.1 (.NET Standard 2.0 [supports .NET Framework 4.6.1+](https://docs.microsoft.com/en-us/dotnet/standard/net-standard#net-implementation-support)) but I have not actually gotten to the point of proposing that to the Avro team yet.\r\n\r\nIf we were to drop support for .NET 4.0, I think we would probably need to wait for a major release, e.g. `1.10.x`.  For now, I suggest that you add `net40` back in to the target frameworks.\r\n\r\n```suggestion\r\n    <TargetFrameworks>net40;netstandard2.0</TargetFrameworks>\r\n```"", 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/POCO/AvroAttribute.cs,"@@ -0,0 +1,52 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+ using System;
+
+namespace Avro.POCO
+{
+    /// <summary>
+    /// Attribute to indicate how the class is mapped to the schema. If true the mapping is by position
+    /// and the class must have field attributes. If false the class is mapped by field name. Mapping by field
+    /// position allows you to use properties who's name doesnt match the schema.
+    ///
+    /// If there is no attribute mapping by name is the default.
+    /// </summary>
+    public class AvroAttribute : Attribute
+    {
+        /// <summary>
+        /// If true the class is mapped by position.
+        /// </summary>
+        /// <value></value>
+        public bool ByPosition { get; set; }","[{'comment': 'Why map properties to a field at a particular position? This seems fragile, especially since Avro schema evolution allows for the reordering of fields in a schema, which would change their ""position"".\r\n\r\nIn the documentation for this class, you mention that this would be used when your C# property name cannot match your Avro field name. This is definitely a scenario we want to handle. Maybe we should take an approach similar to that of the [`JsonPropertyAttribute`](https://www.newtonsoft.com/json/help/html/JsonPropertyName.htm). In the Avro approach, the `AvroFieldAttribute` would store the Avro field name to map a particular property to.\r\n\r\nFor example, the schema below defines a ""release-date"" field, which cannot be replicated exactly in a C# property name because of the hyphen.\r\n\r\n```json\r\n{\r\n  ""type"": ""record"",\r\n  ""name"": ""Movie"",\r\n  ""fields"" : [\r\n    {""name"": ""title"", ""type"": ""string""},\r\n    {""name"": ""release-date"", ""type"": ""long""}\r\n  ]\r\n}\r\n```\r\n\r\nI imagine we could map the C# property name to the appropriate Avro field name using the `AvroFieldAttribute` like so:\r\n\r\n```c#\r\nclass Movie\r\n{\r\n    public string Title { get; set }\r\n\r\n    [AvroFieldAttribute(""release-date"")]\r\n    public long ReleaseDate { get; set; }\r\n}\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/POCO/AvroAttribute.cs,"@@ -0,0 +1,52 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+ using System;
+
+namespace Avro.POCO","[{'comment': 'The Java API has a similar feature called ""Reflect"". Should we stick with the ""POCO"" term to make it easier for C# devs to grok, or call it ""Reflect"" to match other Avro clients?', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/POCO/POCOWriter.cs,"@@ -0,0 +1,250 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Linq;
+using Avro;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Specific;
+
+namespace Avro.POCO
+{
+    /// <summary>
+    /// Generic wrapper class for writing data from specific objects
+    /// </summary>
+    /// <typeparam name=""T"">type name of specific object</typeparam>
+    public class POCOWriter<T> : SpecificWriter<T>
+    {
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""schema""></param>
+        /// <returns></returns>
+        public POCOWriter(Schema schema) : base(new POCODefaultWriter(typeof(T), schema)) { }
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""writer""></param>
+        /// <returns></returns>
+        public POCOWriter(POCODefaultWriter writer) : base(writer) { }
+    }
+    /// <summary>
+    /// Class for writing data from any specific objects
+    /// </summary>
+    public class POCODefaultWriter : SpecificDefaultWriter
+    {
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""objType""></param>
+        /// <param name=""schema""></param>
+        public POCODefaultWriter(Type objType, Schema schema)
+            : base(schema)
+        {
+            var rs = schema as RecordSchema;
+            if (rs != null)
+            {
+                ClassCache.LoadClassCache(objType, rs);
+            }
+        }
+
+        /// <summary>
+        /// Serialized a record using the given RecordSchema. It uses GetField method
+        /// to extract the field value from the given object.
+        /// </summary>
+        /// <param name=""schema"">The RecordSchema to use for serialization</param>
+        /// <param name=""value"">The value to be serialized</param>
+        /// <param name=""encoder"">The Encoder for serialization</param>
+
+        protected override void WriteRecord(RecordSchema schema, object value, Encoder encoder)
+        {
+
+            foreach (Field field in schema)
+            {
+                try
+                {
+                    var v = ClassCache.GetClass(schema).GetValue(value, field);
+
+                    Write(field.Schema, v, encoder);
+                }
+                catch (Exception ex)
+                {
+                    throw new AvroException(ex.Message + "" in field "" + field.Name, ex);
+                }
+            }
+        }
+
+        /// <summary>
+        /// Validates that the record is a fixed record object and that the schema in the object is the
+        /// same as the given writer schema. Writes the given fixed record into the given encoder
+        /// </summary>
+        /// <param name=""schema"">writer schema</param>
+        /// <param name=""value"">fixed object to write</param>
+        /// <param name=""encoder"">encoder to write to</param>
+        protected override void WriteFixed(FixedSchema schema, object value, Encoder encoder)
+        {
+            var fixedrec = value as byte[];
+            if (fixedrec == null)
+            {
+                throw new AvroTypeException(""Fixed object is not derived from byte[]"");
+            }","[{'comment': 'I think it would be nice to also allow derivatives of `GenericFixed` as `value` in this method. This would allow users of the library to use some of their auto-generated Specific API classes in the POCO API.', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/POCO/POCOWriter.cs,"@@ -0,0 +1,250 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Linq;
+using Avro;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Specific;
+
+namespace Avro.POCO
+{
+    /// <summary>
+    /// Generic wrapper class for writing data from specific objects
+    /// </summary>
+    /// <typeparam name=""T"">type name of specific object</typeparam>
+    public class POCOWriter<T> : SpecificWriter<T>
+    {
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""schema""></param>
+        /// <returns></returns>
+        public POCOWriter(Schema schema) : base(new POCODefaultWriter(typeof(T), schema)) { }
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""writer""></param>
+        /// <returns></returns>
+        public POCOWriter(POCODefaultWriter writer) : base(writer) { }
+    }
+    /// <summary>
+    /// Class for writing data from any specific objects
+    /// </summary>
+    public class POCODefaultWriter : SpecificDefaultWriter
+    {
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""objType""></param>
+        /// <param name=""schema""></param>
+        public POCODefaultWriter(Type objType, Schema schema)
+            : base(schema)
+        {
+            var rs = schema as RecordSchema;
+            if (rs != null)
+            {
+                ClassCache.LoadClassCache(objType, rs);
+            }
+        }
+
+        /// <summary>
+        /// Serialized a record using the given RecordSchema. It uses GetField method
+        /// to extract the field value from the given object.
+        /// </summary>
+        /// <param name=""schema"">The RecordSchema to use for serialization</param>
+        /// <param name=""value"">The value to be serialized</param>
+        /// <param name=""encoder"">The Encoder for serialization</param>
+
+        protected override void WriteRecord(RecordSchema schema, object value, Encoder encoder)
+        {
+
+            foreach (Field field in schema)
+            {
+                try
+                {
+                    var v = ClassCache.GetClass(schema).GetValue(value, field);
+
+                    Write(field.Schema, v, encoder);
+                }
+                catch (Exception ex)
+                {
+                    throw new AvroException(ex.Message + "" in field "" + field.Name, ex);
+                }
+            }
+        }
+
+        /// <summary>
+        /// Validates that the record is a fixed record object and that the schema in the object is the
+        /// same as the given writer schema. Writes the given fixed record into the given encoder
+        /// </summary>
+        /// <param name=""schema"">writer schema</param>
+        /// <param name=""value"">fixed object to write</param>
+        /// <param name=""encoder"">encoder to write to</param>
+        protected override void WriteFixed(FixedSchema schema, object value, Encoder encoder)
+        {
+            var fixedrec = value as byte[];
+            if (fixedrec == null)
+            {
+                throw new AvroTypeException(""Fixed object is not derived from byte[]"");
+            }
+
+            if (fixedrec.Length != schema.Size)
+            {
+                throw new AvroTypeException($""Fixed object length is not the same as schema length {schema.Size}"");
+            }
+
+            encoder.WriteFixed(fixedrec);
+        }
+
+        /// <summary>
+        /// Serialized an array. The default implementation calls EnsureArrayObject() to ascertain that the
+        /// given value is an array. It then calls GetArrayLength() and GetArrayElement()
+        /// to access the members of the array and then serialize them.
+        /// </summary>
+        /// <param name=""schema"">The ArraySchema for serialization</param>
+        /// <param name=""value"">The value being serialized</param>
+        /// <param name=""encoder"">The encoder for serialization</param>
+        protected override void WriteArray(ArraySchema schema, object value, Encoder encoder)
+        {
+            var arr = value as System.Collections.IList;","[{'comment': 'Could we allow `IEnumerable<T>` here rather than requiring an `IList`? `DefaultSpecificWriter` also requires an `IList` at this time, but maybe we could imporve on this here. Would allowing an `IEnumerable` cause problems?', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/POCO/POCOWriter.cs,"@@ -0,0 +1,250 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Linq;
+using Avro;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Specific;
+
+namespace Avro.POCO
+{
+    /// <summary>
+    /// Generic wrapper class for writing data from specific objects
+    /// </summary>
+    /// <typeparam name=""T"">type name of specific object</typeparam>
+    public class POCOWriter<T> : SpecificWriter<T>
+    {
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""schema""></param>
+        /// <returns></returns>
+        public POCOWriter(Schema schema) : base(new POCODefaultWriter(typeof(T), schema)) { }
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""writer""></param>
+        /// <returns></returns>
+        public POCOWriter(POCODefaultWriter writer) : base(writer) { }
+    }
+    /// <summary>
+    /// Class for writing data from any specific objects
+    /// </summary>
+    public class POCODefaultWriter : SpecificDefaultWriter
+    {
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""objType""></param>
+        /// <param name=""schema""></param>
+        public POCODefaultWriter(Type objType, Schema schema)
+            : base(schema)
+        {
+            var rs = schema as RecordSchema;
+            if (rs != null)
+            {
+                ClassCache.LoadClassCache(objType, rs);
+            }
+        }
+
+        /// <summary>
+        /// Serialized a record using the given RecordSchema. It uses GetField method
+        /// to extract the field value from the given object.
+        /// </summary>
+        /// <param name=""schema"">The RecordSchema to use for serialization</param>
+        /// <param name=""value"">The value to be serialized</param>
+        /// <param name=""encoder"">The Encoder for serialization</param>
+
+        protected override void WriteRecord(RecordSchema schema, object value, Encoder encoder)
+        {
+
+            foreach (Field field in schema)
+            {
+                try
+                {
+                    var v = ClassCache.GetClass(schema).GetValue(value, field);
+
+                    Write(field.Schema, v, encoder);
+                }
+                catch (Exception ex)
+                {
+                    throw new AvroException(ex.Message + "" in field "" + field.Name, ex);
+                }
+            }
+        }
+
+        /// <summary>
+        /// Validates that the record is a fixed record object and that the schema in the object is the
+        /// same as the given writer schema. Writes the given fixed record into the given encoder
+        /// </summary>
+        /// <param name=""schema"">writer schema</param>
+        /// <param name=""value"">fixed object to write</param>
+        /// <param name=""encoder"">encoder to write to</param>
+        protected override void WriteFixed(FixedSchema schema, object value, Encoder encoder)
+        {
+            var fixedrec = value as byte[];
+            if (fixedrec == null)
+            {
+                throw new AvroTypeException(""Fixed object is not derived from byte[]"");
+            }
+
+            if (fixedrec.Length != schema.Size)
+            {
+                throw new AvroTypeException($""Fixed object length is not the same as schema length {schema.Size}"");
+            }
+
+            encoder.WriteFixed(fixedrec);
+        }
+
+        /// <summary>
+        /// Serialized an array. The default implementation calls EnsureArrayObject() to ascertain that the
+        /// given value is an array. It then calls GetArrayLength() and GetArrayElement()
+        /// to access the members of the array and then serialize them.
+        /// </summary>
+        /// <param name=""schema"">The ArraySchema for serialization</param>
+        /// <param name=""value"">The value being serialized</param>
+        /// <param name=""encoder"">The encoder for serialization</param>
+        protected override void WriteArray(ArraySchema schema, object value, Encoder encoder)
+        {
+            var arr = value as System.Collections.IList;
+            if (arr == null)
+                throw new AvroTypeException(""Array does not implement IList"");
+
+            long l = arr.Count;
+            encoder.WriteArrayStart();
+            encoder.SetItemCount(l);
+            for (int i = 0; i < l; i++)
+            {
+                encoder.StartItem();
+                Write(schema.ItemSchema, arr[i], encoder);
+            }
+
+            encoder.WriteArrayEnd();
+        }
+
+        /// <summary>
+        /// Writes the given map into the given encoder.
+        /// </summary>
+        /// <param name=""schema"">writer schema</param>
+        /// <param name=""value"">map to write</param>
+        /// <param name=""encoder"">encoder to write to</param>
+        protected override void WriteMap(MapSchema schema, object value, Encoder encoder)
+        {
+            if (value == null)","[{'comment': 'This is a very sensible check. We should probably add this to `DefaultSpecificWriter` as well (not necessarily as part of this PR). Actually, if not for this check, this `WriteMap` method is identical to the base implementation. After running this check, why not call `base.WriteMap()`?', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/POCO/POCOWriter.cs,"@@ -0,0 +1,250 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Linq;
+using Avro;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Specific;
+
+namespace Avro.POCO
+{
+    /// <summary>
+    /// Generic wrapper class for writing data from specific objects
+    /// </summary>
+    /// <typeparam name=""T"">type name of specific object</typeparam>
+    public class POCOWriter<T> : SpecificWriter<T>
+    {
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""schema""></param>
+        /// <returns></returns>
+        public POCOWriter(Schema schema) : base(new POCODefaultWriter(typeof(T), schema)) { }
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""writer""></param>
+        /// <returns></returns>
+        public POCOWriter(POCODefaultWriter writer) : base(writer) { }
+    }
+    /// <summary>
+    /// Class for writing data from any specific objects
+    /// </summary>
+    public class POCODefaultWriter : SpecificDefaultWriter
+    {
+
+        /// <summary>
+        /// Constructor
+        /// </summary>
+        /// <param name=""objType""></param>
+        /// <param name=""schema""></param>
+        public POCODefaultWriter(Type objType, Schema schema)
+            : base(schema)
+        {
+            var rs = schema as RecordSchema;
+            if (rs != null)
+            {
+                ClassCache.LoadClassCache(objType, rs);
+            }
+        }
+
+        /// <summary>
+        /// Serialized a record using the given RecordSchema. It uses GetField method
+        /// to extract the field value from the given object.
+        /// </summary>
+        /// <param name=""schema"">The RecordSchema to use for serialization</param>
+        /// <param name=""value"">The value to be serialized</param>
+        /// <param name=""encoder"">The Encoder for serialization</param>
+
+        protected override void WriteRecord(RecordSchema schema, object value, Encoder encoder)
+        {
+
+            foreach (Field field in schema)
+            {
+                try
+                {
+                    var v = ClassCache.GetClass(schema).GetValue(value, field);
+
+                    Write(field.Schema, v, encoder);
+                }
+                catch (Exception ex)
+                {
+                    throw new AvroException(ex.Message + "" in field "" + field.Name, ex);
+                }
+            }
+        }
+
+        /// <summary>
+        /// Validates that the record is a fixed record object and that the schema in the object is the
+        /// same as the given writer schema. Writes the given fixed record into the given encoder
+        /// </summary>
+        /// <param name=""schema"">writer schema</param>
+        /// <param name=""value"">fixed object to write</param>
+        /// <param name=""encoder"">encoder to write to</param>
+        protected override void WriteFixed(FixedSchema schema, object value, Encoder encoder)
+        {
+            var fixedrec = value as byte[];
+            if (fixedrec == null)
+            {
+                throw new AvroTypeException(""Fixed object is not derived from byte[]"");
+            }
+
+            if (fixedrec.Length != schema.Size)
+            {
+                throw new AvroTypeException($""Fixed object length is not the same as schema length {schema.Size}"");
+            }
+
+            encoder.WriteFixed(fixedrec);
+        }
+
+        /// <summary>
+        /// Serialized an array. The default implementation calls EnsureArrayObject() to ascertain that the
+        /// given value is an array. It then calls GetArrayLength() and GetArrayElement()
+        /// to access the members of the array and then serialize them.
+        /// </summary>
+        /// <param name=""schema"">The ArraySchema for serialization</param>
+        /// <param name=""value"">The value being serialized</param>
+        /// <param name=""encoder"">The encoder for serialization</param>
+        protected override void WriteArray(ArraySchema schema, object value, Encoder encoder)
+        {
+            var arr = value as System.Collections.IList;
+            if (arr == null)
+                throw new AvroTypeException(""Array does not implement IList"");
+
+            long l = arr.Count;
+            encoder.WriteArrayStart();
+            encoder.SetItemCount(l);
+            for (int i = 0; i < l; i++)
+            {
+                encoder.StartItem();
+                Write(schema.ItemSchema, arr[i], encoder);
+            }
+
+            encoder.WriteArrayEnd();
+        }
+
+        /// <summary>
+        /// Writes the given map into the given encoder.
+        /// </summary>
+        /// <param name=""schema"">writer schema</param>
+        /// <param name=""value"">map to write</param>
+        /// <param name=""encoder"">encoder to write to</param>
+        protected override void WriteMap(MapSchema schema, object value, Encoder encoder)
+        {
+            if (value == null)
+            {
+                throw new AvroTypeException(""Map is null - use a union for nullable types"");
+            }
+
+            var map = value as System.Collections.IDictionary;
+            if (map == null)
+            {
+                throw new AvroTypeException(""Map does not implement IDictionary"");
+            }
+
+            encoder.WriteArrayStart();
+            encoder.SetItemCount(map.Count);
+            foreach (System.Collections.DictionaryEntry de in map)
+            {
+                encoder.StartItem();
+                encoder.WriteString(de.Key as string);
+                Write(schema.ValueSchema, de.Value, encoder);
+            }
+
+            encoder.WriteMapEnd();
+        }
+
+        /// <summary>
+        /// Resolves the given value against the given UnionSchema and serializes the object against
+        /// the resolved schema member. The default implementation of this method uses
+        /// ResolveUnion to find the member schema within the UnionSchema.
+        /// </summary>
+        /// <param name=""us"">The UnionSchema to resolve against</param>
+        /// <param name=""value"">The value to be serialized</param>
+        /// <param name=""encoder"">The encoder for serialization</param>
+        protected override void WriteUnion(UnionSchema us, object value, Encoder encoder)
+        {
+            for (int i = 0; i < us.Count; i++)","[{'comment': '`WriteUnion` appears identical to the base implementation. Do we really need to override it?', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/AvroAttribute.cs,"@@ -0,0 +1,69 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Reflection;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Attribute that specifies the mapping between an Avro record schema and C# class property.
+    /// </summary>
+    public class AvroAttribute : Attribute","[{'comment': 'Add an [`AttributeUsage` attribute](https://docs.microsoft.com/en-us/dotnet/api/system.attributeusageattribute?view=netframework-4.8) to this class. I believe this only applies to properties, so `[AttributeUsage(AttributeTargets.Property)]` should do the trick.\r\n```suggestion\r\n    [AttributeUsage(AttributeTargets.Property, AllowMultiple = false)]\r\n    public class AvroAttribute : Attribute\r\n```', 'commenter': 'blachniet'}, {'comment': "" I think this attribute is only supposed to apply directly to fields/properties. If that's true, do you think `AvroFieldAttribute` would be a more appropriate name here?\r\n```suggestion\r\n    public class AvroFieldAttribute : Attribute\r\n```"", 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/AvroAttribute.cs,"@@ -0,0 +1,69 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Reflection;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Attribute that specifies the mapping between an Avro record schema and C# class property.","[{'comment': '```suggestion\r\n    /// Attribute that specifies the mapping between an Avro field and C# class property.\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/AvroAttribute.cs,"@@ -0,0 +1,69 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Reflection;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Attribute that specifies the mapping between an Avro record schema and C# class property.
+    /// </summary>
+    public class AvroAttribute : Attribute
+    {
+        /// <summary>
+        /// Sequence number of the field in the Avro Schema","[{'comment': '```suggestion\r\n        /// Name of the field in the Avro Schema\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/AvroAttribute.cs,"@@ -0,0 +1,69 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Reflection;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Attribute that specifies the mapping between an Avro record schema and C# class property.
+    /// </summary>
+    public class AvroAttribute : Attribute
+    {
+        /// <summary>
+        /// Sequence number of the field in the Avro Schema
+        /// </summary>
+        /// <value></value>
+        public string FieldName { get; set; }
+
+        /// <summary>
+        /// Convert the property into a standard Avro type - e.g. DateTimeOffset to long
+        /// </summary>
+        /// <value></value>
+        public IAvroFieldConverter Converter { get; set; }
+
+        /// <summary>
+        /// Attribute to hold field position and optionally a converter","[{'comment': '```suggestion\r\n        /// Attribute to hold a field name and optionally a converter\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestArray.cs,"@@ -0,0 +1,127 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestArray
+    {
+        private class ListRec
+        {
+            public string S { get; set; }
+        }
+
+        private string _simpleList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",
+            """"name"""": """"A"""",
+            """"items"""": """"string""""
+        }"";
+
+        private string _recordList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",
+            """"name"""": """"A"""",
+            """"items"""": {
+                """"type"""": """"record"""",
+                """"doc"""": """"A simple type with a fixed."""",
+                """"name"""": """"A"""",
+                """"fields"""": [
+                    { """"name"""" : """"S"""", """"type"""" : """"string"""" }
+                ]
+            }
+        }"";
+
+        [TestCase]
+        public void ListTest()
+        {
+            var schema = global::Avro.Schema.Parse(_simpleList);","[{'comment': ""You shouldn't need this `global::` here in front of the `Avro.Schema.Parse`, or in the other tests below."", 'commenter': 'blachniet'}, {'comment': 'Fixed.', 'commenter': 'pa009fa'}]"
521,lang/csharp/src/apache/test/Reflect/TestArray.cs,"@@ -0,0 +1,127 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestArray
+    {
+        private class ListRec
+        {
+            public string S { get; set; }
+        }
+
+        private string _simpleList = @""","[{'comment': ""Could could make each of these schema strings `const` since we don't intend for them to be modified in the tests."", 'commenter': 'blachniet'}, {'comment': 'Done.', 'commenter': 'pa009fa'}, {'comment': 'Done\r\n', 'commenter': 'pa009fa'}]"
521,lang/csharp/src/apache/test/Reflect/TestArray.cs,"@@ -0,0 +1,127 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestArray
+    {
+        private class ListRec
+        {
+            public string S { get; set; }
+        }
+
+        private string _simpleList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",
+            """"name"""": """"A"""",
+            """"items"""": """"string""""
+        }"";
+
+        private string _recordList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",","[{'comment': '```suggestion\r\n            """"doc"""": """"A list with a custom type containing a string."""",\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestArray.cs,"@@ -0,0 +1,127 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestArray
+    {
+        private class ListRec
+        {
+            public string S { get; set; }
+        }
+
+        private string _simpleList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",
+            """"name"""": """"A"""",
+            """"items"""": """"string""""
+        }"";
+
+        private string _recordList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",
+            """"name"""": """"A"""",
+            """"items"""": {
+                """"type"""": """"record"""",
+                """"doc"""": """"A simple type with a fixed."""",
+                """"name"""": """"A"""",
+                """"fields"""": [
+                    { """"name"""" : """"S"""", """"type"""" : """"string"""" }
+                ]
+            }
+        }"";
+
+        [TestCase]
+        public void ListTest()
+        {
+            var schema = global::Avro.Schema.Parse(_simpleList);
+            var fixedRecWrite = new List<string>() {""value""};
+
+            var writer = new ReflectWriter<List<string>>(schema);
+            var reader = new ReflectReader<List<string>>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                var fixedRecRead = reader.Read(new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.Count == 1);
+                Assert.AreEqual(fixedRecWrite[0],fixedRecRead[0]);
+            }
+        }
+
+        [TestCase]
+        public void ListRecTest()
+        {
+            var schema = global::Avro.Schema.Parse(_recordList);
+            var fixedRecWrite = new List<ListRec>() { new ListRec() { S = ""hello""}};
+
+            var writer = new ReflectWriter<List<ListRec>>(schema);
+            var reader = new ReflectReader<List<ListRec>>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                var fixedRecRead = reader.Read(new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.Count == 1);
+                Assert.AreEqual(fixedRecWrite[0].S,fixedRecRead[0].S);
+            }
+        }
+
+        [TestCase]
+        public void ConcurrentQueueTest()
+        {
+            var schema = global::Avro.Schema.Parse(_recordList);
+            var fixedRecWrite = new ConcurrentQueue<ListRec>();
+            fixedRecWrite.Enqueue(new ListRec() { S = ""hello""});
+
+            var arrayHelper = new ReflectArrayHelper();
+            arrayHelper.CountFunc = e=>(e as dynamic).Count;
+            arrayHelper.AddAction = (e,v)=>(e as dynamic).Enqueue(v as ListRec);
+            arrayHelper.ClearAction = e=>(e as dynamic).Clear();
+            arrayHelper.ArrayType = typeof(ConcurrentQueue<>);
+
+            var writer = new ReflectWriter<ConcurrentQueue<ListRec>>(schema, arrayHelper);
+            var reader = new ReflectReader<ConcurrentQueue<ListRec>>(schema, schema, arrayHelper );
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                var fixedRecRead = reader.Read(new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.Count == 1);","[{'comment': 'We should check the value here, like in the other 2 tests above.\r\n```suggestion\r\n                Assert.IsTrue(fixedRecRead.Count == 1);\r\n                Assert.AreEqual(fixedRecWrite[0].S,fixedRecRead[0].S);\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestFixed.cs,"@@ -0,0 +1,164 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.IO;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+    [TestFixture]
+    public class TestFixed
+    {
+            public class ByteArrayFixedRec
+        {
+            public byte[] myFixed { get; set; }
+        }
+
+        public class GenericFixedRec
+        {
+            public GenericFixed myFixed { get; set; }
+        }
+
+        public class GenericFixedConverter : TypedFieldConverter<byte[],GenericFixed>
+        {
+            public override GenericFixed From(byte[] o, Schema s)
+            {
+                return new GenericFixed(s as FixedSchema, o);
+            }
+
+            public override byte[] To(GenericFixed o, Schema s)
+            {
+                return o.Value;
+            }
+        }
+
+        public class GenericFixedConverterRec
+        {
+            [Avro(typeof(GenericFixedConverter))]
+            public GenericFixed myFixed { get; set; }
+        }
+        private string _fixedSchema = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"record"""",
+            """"doc"""": """"A simple type with a fixed."""",
+            """"name"""": """"A"""",
+            """"fields"""": [
+                { """"name"""" : """"myFixed"""", """"type"""" :
+                    {
+                        """"type"""": """"fixed"""",
+                        """"size"""": 16,
+                        """"name"""": """"MyFixed""""
+                    }
+                }
+            ]
+        }"";
+
+        [TestCase]
+        public void ByteArray()
+        {
+            var schema = global::Avro.Schema.Parse(_fixedSchema);
+            var fixedRecWrite = new ByteArrayFixedRec() { myFixed = new byte[16] {1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6} };
+            var fixedRecBad = new ByteArrayFixedRec() { myFixed = new byte[10] };
+            ByteArrayFixedRec fixedRecRead = null;
+
+            var writer = new ReflectWriter<ByteArrayFixedRec>(schema);
+            var reader = new ReflectReader<ByteArrayFixedRec>(schema, schema);
+
+            Assert.Throws(typeof(AvroException), ()=> {
+                using (var stream = new MemoryStream(256))
+                {
+                    writer.Write(fixedRecBad, new BinaryEncoder(stream));
+                }
+            });
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                fixedRecRead = reader.Read(null, new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.myFixed.Length == 16);
+                Assert.AreEqual(fixedRecWrite.myFixed[5],fixedRecRead.myFixed[5]);","[{'comment': '```suggestion\r\n                Assert.IsTrue(fixedRecWrite.myFixed.SequenceEqual(fixedRecRead.myFixed));\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestFixed.cs,"@@ -0,0 +1,164 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.IO;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+    [TestFixture]
+    public class TestFixed
+    {
+            public class ByteArrayFixedRec
+        {
+            public byte[] myFixed { get; set; }
+        }
+
+        public class GenericFixedRec
+        {
+            public GenericFixed myFixed { get; set; }
+        }
+
+        public class GenericFixedConverter : TypedFieldConverter<byte[],GenericFixed>
+        {
+            public override GenericFixed From(byte[] o, Schema s)
+            {
+                return new GenericFixed(s as FixedSchema, o);
+            }
+
+            public override byte[] To(GenericFixed o, Schema s)
+            {
+                return o.Value;
+            }
+        }
+
+        public class GenericFixedConverterRec
+        {
+            [Avro(typeof(GenericFixedConverter))]
+            public GenericFixed myFixed { get; set; }
+        }
+        private string _fixedSchema = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"record"""",
+            """"doc"""": """"A simple type with a fixed."""",
+            """"name"""": """"A"""",
+            """"fields"""": [
+                { """"name"""" : """"myFixed"""", """"type"""" :
+                    {
+                        """"type"""": """"fixed"""",
+                        """"size"""": 16,
+                        """"name"""": """"MyFixed""""
+                    }
+                }
+            ]
+        }"";
+
+        [TestCase]
+        public void ByteArray()
+        {
+            var schema = global::Avro.Schema.Parse(_fixedSchema);
+            var fixedRecWrite = new ByteArrayFixedRec() { myFixed = new byte[16] {1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6} };
+            var fixedRecBad = new ByteArrayFixedRec() { myFixed = new byte[10] };
+            ByteArrayFixedRec fixedRecRead = null;
+
+            var writer = new ReflectWriter<ByteArrayFixedRec>(schema);
+            var reader = new ReflectReader<ByteArrayFixedRec>(schema, schema);
+
+            Assert.Throws(typeof(AvroException), ()=> {
+                using (var stream = new MemoryStream(256))
+                {
+                    writer.Write(fixedRecBad, new BinaryEncoder(stream));
+                }
+            });
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                fixedRecRead = reader.Read(null, new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.myFixed.Length == 16);
+                Assert.AreEqual(fixedRecWrite.myFixed[5],fixedRecRead.myFixed[5]);
+            }
+        }
+
+        [TestCase]
+        public void GenericFixedConverterTest()
+        {
+            var schema = global::Avro.Schema.Parse(_fixedSchema);
+            var rs = schema as RecordSchema;
+            FixedSchema fs = null;
+            foreach (var f in rs.Fields)
+            {
+                if (f.Name == ""myFixed"")
+                {
+                    fs = f.Schema as FixedSchema;
+                }
+            }
+            var fixedRecWrite = new GenericFixedConverterRec() { myFixed = new GenericFixed(fs) {Value = new byte[16] {1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6} }};
+            GenericFixedConverterRec fixedRecRead = null;
+
+            var writer = new ReflectWriter<GenericFixedConverterRec>(schema);
+            var reader = new ReflectReader<GenericFixedConverterRec>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                fixedRecRead = reader.Read(null, new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.myFixed.Value.Length == 16);
+                Assert.AreEqual(fixedRecWrite.myFixed.Value[5],fixedRecRead.myFixed.Value[5]);","[{'comment': '```suggestion\r\n                Assert.IsTrue(fixedRecWrite.myFixed.SequenceEqual(fixedRecRead.myFixed));\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestFixed.cs,"@@ -0,0 +1,164 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.IO;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+
+    [TestFixture]
+    public class TestFixed
+    {
+            public class ByteArrayFixedRec
+        {
+            public byte[] myFixed { get; set; }
+        }
+
+        public class GenericFixedRec
+        {
+            public GenericFixed myFixed { get; set; }
+        }
+
+        public class GenericFixedConverter : TypedFieldConverter<byte[],GenericFixed>
+        {
+            public override GenericFixed From(byte[] o, Schema s)
+            {
+                return new GenericFixed(s as FixedSchema, o);
+            }
+
+            public override byte[] To(GenericFixed o, Schema s)
+            {
+                return o.Value;
+            }
+        }
+
+        public class GenericFixedConverterRec
+        {
+            [Avro(typeof(GenericFixedConverter))]
+            public GenericFixed myFixed { get; set; }
+        }
+        private string _fixedSchema = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"record"""",
+            """"doc"""": """"A simple type with a fixed."""",
+            """"name"""": """"A"""",
+            """"fields"""": [
+                { """"name"""" : """"myFixed"""", """"type"""" :
+                    {
+                        """"type"""": """"fixed"""",
+                        """"size"""": 16,
+                        """"name"""": """"MyFixed""""
+                    }
+                }
+            ]
+        }"";
+
+        [TestCase]
+        public void ByteArray()
+        {
+            var schema = global::Avro.Schema.Parse(_fixedSchema);
+            var fixedRecWrite = new ByteArrayFixedRec() { myFixed = new byte[16] {1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6} };
+            var fixedRecBad = new ByteArrayFixedRec() { myFixed = new byte[10] };
+            ByteArrayFixedRec fixedRecRead = null;
+
+            var writer = new ReflectWriter<ByteArrayFixedRec>(schema);
+            var reader = new ReflectReader<ByteArrayFixedRec>(schema, schema);
+
+            Assert.Throws(typeof(AvroException), ()=> {
+                using (var stream = new MemoryStream(256))
+                {
+                    writer.Write(fixedRecBad, new BinaryEncoder(stream));
+                }
+            });
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                fixedRecRead = reader.Read(null, new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.myFixed.Length == 16);
+                Assert.AreEqual(fixedRecWrite.myFixed[5],fixedRecRead.myFixed[5]);
+            }
+        }
+
+        [TestCase]
+        public void GenericFixedConverterTest()
+        {
+            var schema = global::Avro.Schema.Parse(_fixedSchema);
+            var rs = schema as RecordSchema;
+            FixedSchema fs = null;
+            foreach (var f in rs.Fields)
+            {
+                if (f.Name == ""myFixed"")
+                {
+                    fs = f.Schema as FixedSchema;
+                }
+            }
+            var fixedRecWrite = new GenericFixedConverterRec() { myFixed = new GenericFixed(fs) {Value = new byte[16] {1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6} }};
+            GenericFixedConverterRec fixedRecRead = null;
+
+            var writer = new ReflectWriter<GenericFixedConverterRec>(schema);
+            var reader = new ReflectReader<GenericFixedConverterRec>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                fixedRecRead = reader.Read(null, new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.myFixed.Value.Length == 16);
+                Assert.AreEqual(fixedRecWrite.myFixed.Value[5],fixedRecRead.myFixed.Value[5]);
+            }
+        }
+
+        [TestCase]
+        public void GenericFixedDefaultConverter()
+        {
+            var schema = global::Avro.Schema.Parse(_fixedSchema);
+            var rs = schema as RecordSchema;
+            FixedSchema fs = null;
+            foreach (var f in rs.Fields)
+            {
+                if (f.Name == ""myFixed"")
+                {
+                    fs = f.Schema as FixedSchema;
+                }
+            }
+            var fixedRecWrite = new GenericFixedRec() { myFixed = new GenericFixed(fs) {Value = new byte[16] {1,2,3,4,5,6,7,8,9,0,1,2,3,4,5,6} }};
+            GenericFixedRec fixedRecRead = null;
+
+            ClassCache.AddDefaultConverter<byte[], GenericFixed>((a,s)=>new GenericFixed(s as FixedSchema, a), (p,s)=>p.Value);
+            var writer = new ReflectWriter<GenericFixedRec>(schema);
+            var reader = new ReflectReader<GenericFixedRec>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                fixedRecRead = reader.Read(null, new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.myFixed.Value.Length == 16);
+                Assert.AreEqual(fixedRecWrite.myFixed.Value[5],fixedRecRead.myFixed.Value[5]);","[{'comment': '```suggestion\r\n                Assert.IsTrue(fixedRecWrite.myFixed.SequenceEqual(fixedRecRead.myFixed));\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/IAvroFieldConverter.cs,"@@ -0,0 +1,57 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+ using System;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Converters can be added to properties with an AvroField attribute. Converters convert between the
+    /// property type and the avro type.
+    /// </summary>
+    public interface IAvroFieldConverter
+    {
+        /// <summary>
+        /// Convert from the C# type to the avro type
+        /// </summary>
+        /// <param name=""o""></param>
+        /// <returns></returns>
+        object ToAvroType(object o, Schema s);
+
+        /// <summary>
+        /// Convert from the avro type to the C# type
+        /// </summary>
+        /// <param name=""o""></param>
+        /// <returns></returns>
+        object FromAvroType(object o, Schema s);
+
+        /// <summary>
+        /// Avro type
+        /// </summary>
+        /// <returns></returns>
+        Type GetAvroType();
+
+        /// <summary>
+        /// Property type
+        /// </summary>
+        /// <returns></returns>
+        Type GetPropertyType();","[{'comment': 'This would serve well as a property:\r\n```suggestion\r\n        Type PropertyType { get; }\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/IAvroFieldConverter.cs,"@@ -0,0 +1,57 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+ using System;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Converters can be added to properties with an AvroField attribute. Converters convert between the
+    /// property type and the avro type.
+    /// </summary>
+    public interface IAvroFieldConverter
+    {
+        /// <summary>
+        /// Convert from the C# type to the avro type
+        /// </summary>
+        /// <param name=""o""></param>
+        /// <returns></returns>
+        object ToAvroType(object o, Schema s);
+
+        /// <summary>
+        /// Convert from the avro type to the C# type
+        /// </summary>
+        /// <param name=""o""></param>
+        /// <returns></returns>
+        object FromAvroType(object o, Schema s);
+
+        /// <summary>
+        /// Avro type
+        /// </summary>
+        /// <returns></returns>
+        Type GetAvroType();","[{'comment': '```suggestion\r\n        Type AvroType { get; }\r\n```', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/ClassCache.cs,"@@ -0,0 +1,209 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Concurrent;
+using System.Reflection;
+using Avro;
+
+namespace Avro.Reflect
+{
+    /// <summary>
+    /// Class holds a cache of C# classes and their properties. The key for the cache is the schema full name.
+    /// </summary>
+    public class ClassCache
+    {
+        private ConcurrentDictionary<string, DotnetClass> _nameClassMap = new ConcurrentDictionary<string, DotnetClass>();
+        private static ConcurrentBag<IAvroFieldConverter> _defaultConverters = new ConcurrentBag<IAvroFieldConverter>();
+        private void AddClassNameMapItem(RecordSchema schema, Type dotnetClass)
+        {
+            if (schema != null && GetClass(schema)!=null)
+            {
+                return;
+            }
+
+            if (!dotnetClass.IsClass)
+            {
+                throw new AvroException( $""Type {dotnetClass.Name} is not a class"");
+            }
+
+            _nameClassMap.TryAdd(schema.Fullname, new DotnetClass(dotnetClass, schema, this));
+        }
+
+        /// <summary>
+        /// Add a default field converter
+        /// </summary>
+        /// <param name=""converter""></param>
+        public static void AddDefaultConverter(IAvroFieldConverter converter)
+        {
+            _defaultConverters.Add(converter);
+        }
+
+        public static void AddDefaultConverter<A,P>(Func<A,Schema, P> from, Func<P,Schema, A> to)","[{'comment': ""Add a comment to AddDefaultConverter, and any other externally visible elements. We haven't been good about this in the past in the C# project, but now's a great time to start, especially for new elements. 😄 "", 'commenter': 'blachniet'}, {'comment': 'Done.', 'commenter': 'pa009fa'}]"
521,lang/csharp/src/apache/test/Reflect/TestLogMessage.cs,"@@ -0,0 +1,123 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+    public enum MessageTypes
+    {
+        None,
+        Verbose,
+        Info,
+        Warning,
+        Error
+    }
+
+    public class LogMessage
+    {
+        private Dictionary<string, string> _tags = new Dictionary<string, string>();
+
+        public string IP { get; set; }
+
+        public string Message { get; set; }
+
+        [Avro(typeof(DateTimeOffsetToLongConverter))]
+        public DateTimeOffset TimeStamp { get; set; }
+
+        public Dictionary<string, string> Tags { get => _tags; set => _tags = value; }
+
+        public MessageTypes Severity { get; set; }
+    }
+
+    public class LogMessage2
+    {
+        public string IP { get; set; }
+
+        public string Message { get; set; }
+
+        public DateTimeOffset TimeStamp { get; set; }
+
+        private Dictionary<string, string> _tags = new Dictionary<string, string>();
+
+        public Dictionary<string, string> Tags { get => _tags; set => _tags = value; }
+
+        public MessageTypes Severity { get; set; }
+    }
+
+    [TestFixture]
+    public class TestLogMessage
+    {
+        private string _logMessageSchemaV1 = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"record"""",
+            """"doc"""": """"A simple log message type as used by this blog post."""",
+            """"name"""": """"LogMessage"""",
+            """"fields"""": [
+                { """"name"""": """"IP"""", """"type"""": """"string"""" },
+                { """"name"""": """"Message"""", """"type"""": """"string"""" },
+                { """"name"""": """"TimeStamp"""", """"type"""": """"long"""" },
+                { """"name"""": """"Tags"""",""""type"""":
+                    { """"type"""": """"map"""",
+                        """"values"""": """"string""""},
+                        """"default"""": {}},
+                { """"name"""": """"Severity"""",
+                """"type"""": { """"namespace"""": """"MessageTypes"""",
+                    """"type"""": """"enum"""",
+                    """"doc"""": """"Enumerates the set of allowable log levels."""",
+                    """"name"""": """"LogLevel"""",
+                    """"symbols"""": [""""None"""", """"Verbose"""", """"Info"""", """"Warning"""", """"Error""""]}}
+            ]
+        }"";
+
+        [TestCase]
+        public void Serialize()
+        {
+            var schema = global::Avro.Schema.Parse(_logMessageSchemaV1);
+            var avroWriter = new ReflectWriter<LogMessage>(schema);
+            var avroReader = new ReflectReader<LogMessage>(schema, schema);
+
+            byte[] serialized;
+
+            var logMessage = new LogMessage()
+            {
+                IP = ""10.20.30.40"",
+                Message = ""Log entry"",
+                Severity = MessageTypes.Error
+            };
+
+            using (var stream = new MemoryStream(256))
+            {
+                avroWriter.Write(logMessage, new BinaryEncoder(stream));
+                serialized = stream.ToArray();
+            }
+
+            LogMessage deserialized = null;
+            using (var stream = new MemoryStream(serialized))
+            {
+                deserialized = avroReader.Read(default(LogMessage), new BinaryDecoder(stream));","[{'comment': 'We should probably assert that all the properties of `deserialized` match up with those of `logMessage`.', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestFromAvroProject.cs,"@@ -0,0 +1,252 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+ using System;
+using System.IO;
+using System.Collections.Generic;
+using Avro;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Specific;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+    public enum MyEnum
+    {
+        A,
+        B,
+        C
+    }
+    public class A
+    {
+        public long f1 { get; set; }
+    }
+    public class newRec
+    {
+        public long f1 { get; set; }
+    }
+
+    public class Z
+    {
+        public int? myUInt { get; set; }
+
+        public long? myULong { get; set; }
+
+        public bool? myUBool { get; set; }
+
+        public double? myUDouble { get; set; }
+
+        public float? myUFloat { get; set; }
+
+        public byte[] myUBytes { get; set; }
+
+        public string myUString { get; set; }
+
+        public int myInt { get; set; }
+
+        public long myLong { get; set; }
+
+        public bool myBool { get; set; }
+
+        public double myDouble { get; set; }
+
+        public float myFloat { get; set; }
+
+        public byte[] myBytes { get; set; }
+
+        public string myString { get; set; }
+
+        public object myNull { get; set; }
+
+        public byte[] myFixed { get; set; }
+
+        public A myA { get; set; }
+
+        public MyEnum myE { get; set; }
+
+        public List<byte[]> myArray { get; set; }
+
+        public List<newRec> myArray2 { get; set; }
+
+        public Dictionary<string, string> myMap { get; set; }
+
+        public Dictionary<string, newRec> myMap2 { get; set; }
+
+        public object myObject { get; set; }
+
+        public List<List<object>> myArray3 { get; set; }
+    }
+    [TestFixture]
+    public class TestFromAvroProject
+    {
+        private string _avroTestSchemaV1 = @""{
+        """"protocol"""" : """"MyProtocol"""",
+        """"namespace"""" : """"com.foo"""",
+        """"types"""" :
+        [
+            {
+                """"type"""" : """"record"""",
+                """"name"""" : """"A"""",
+                """"fields"""" : [ { """"name"""" : """"f1"""", """"type"""" : """"long"""" } ]
+            },
+            {
+                """"type"""" : """"enum"""",
+                """"name"""" : """"MyEnum"""",
+                """"symbols"""" : [ """"A"""", """"B"""", """"C"""" ]
+            },
+            {
+                """"type"""": """"fixed"""",
+                """"size"""": 16,
+                """"name"""": """"MyFixed""""
+            },
+            {
+                """"type"""" : """"record"""",
+                """"name"""" : """"Z"""",
+                """"fields"""" :
+                [
+                    { """"name"""" : """"myUInt"""", """"type"""" : [ """"int"""", """"null"""" ] },
+                    { """"name"""" : """"myULong"""", """"type"""" : [ """"long"""", """"null"""" ] },
+                    { """"name"""" : """"myUBool"""", """"type"""" : [ """"boolean"""", """"null"""" ] },
+                    { """"name"""" : """"myUDouble"""", """"type"""" : [ """"double"""", """"null"""" ] },
+                    { """"name"""" : """"myUFloat"""", """"type"""" : [ """"float"""", """"null"""" ] },
+                    { """"name"""" : """"myUBytes"""", """"type"""" : [ """"bytes"""", """"null"""" ] },
+                    { """"name"""" : """"myUString"""", """"type"""" : [ """"string"""", """"null"""" ] },
+                    { """"name"""" : """"myInt"""", """"type"""" : """"int"""" },
+                    { """"name"""" : """"myLong"""", """"type"""" : """"long"""" },
+                    { """"name"""" : """"myBool"""", """"type"""" : """"boolean"""" },
+                    { """"name"""" : """"myDouble"""", """"type"""" : """"double"""" },
+                    { """"name"""" : """"myFloat"""", """"type"""" : """"float"""" },
+                    { """"name"""" : """"myBytes"""", """"type"""" : """"bytes"""" },
+                    { """"name"""" : """"myString"""", """"type"""" : """"string"""" },
+                    { """"name"""" : """"myNull"""", """"type"""" : """"null"""" },
+                    { """"name"""" : """"myFixed"""", """"type"""" : """"MyFixed"""" },
+                    { """"name"""" : """"myA"""", """"type"""" : """"A"""" },
+                    { """"name"""" : """"myE"""", """"type"""" : """"MyEnum"""" },
+                    { """"name"""" : """"myArray"""", """"type"""" : { """"type"""" : """"array"""", """"items"""" : """"bytes"""" } },
+                    { """"name"""" : """"myArray2"""", """"type"""" : { """"type"""" : """"array"""", """"items"""" : { """"type"""" : """"record"""", """"name"""" : """"newRec"""", """"fields"""" : [ { """"name"""" : """"f1"""", """"type"""" : """"long""""} ] } } },
+                    { """"name"""" : """"myMap"""", """"type"""" : { """"type"""" : """"map"""", """"values"""" : """"string"""" } },
+                    { """"name"""" : """"myMap2"""", """"type"""" : { """"type"""" : """"map"""", """"values"""" : """"newRec"""" } },
+                    { """"name"""" : """"myObject"""", """"type"""" : [ """"MyEnum"""", """"A"""", """"null"""" ] },
+                    { """"name"""" : """"myArray3"""", """"type"""" : { """"type"""" : """"array"""", """"items"""" : { """"type"""" : """"array"""", """"items"""" : [ """"double"""", """"string"""", """"null"""" ] } } }
+                ]
+            }
+        ]
+        }"";
+
+        public Z SerializeDeserialize(Z z)
+        {
+            try
+            {
+                Protocol protocol = Protocol.Parse(_avroTestSchemaV1);
+                Schema schema = null;
+                foreach (var s in protocol.Types)
+                {
+                    if (s.Name == ""Z"")
+                    {
+                        schema = s;
+                    }
+                }
+
+                var avroWriter = new ReflectWriter<Z>(schema);
+                var avroReader = new ReflectReader<Z>(schema, schema);
+
+                byte[] serialized;
+
+                using (var stream = new MemoryStream(256))
+                {
+                    avroWriter.Write(z, new BinaryEncoder(stream));
+                    serialized = stream.ToArray();
+                }
+
+                Z deserialized = null;
+                using (var stream = new MemoryStream(serialized))
+                {
+                    deserialized = avroReader.Read(default(Z), new BinaryDecoder(stream));
+                }
+
+                return deserialized;
+            }
+            catch (Exception ex)
+            {
+                Console.WriteLine(ex.ToString());
+                throw ex;
+            }
+        }
+
+        [TestCase]
+        public void DefaultZ()
+        {
+            var z = new Z()
+            {
+                myBytes = new byte[10],
+                myString = ""123"",
+                myFixed = new byte[16],
+                myA = new A(),
+                myArray = new List<byte[]>(),
+                myArray2 = new List<newRec>(),
+                myMap = new Dictionary<string, string>(),
+                myMap2 = new Dictionary<string, newRec>(),
+                myArray3 = new List<List<object>>()
+            };
+
+            var zz = SerializeDeserialize(z);","[{'comment': 'We should assert that all the properties of `zz` equal those of `z`.', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/test/Reflect/TestFromAvroProject.cs,"@@ -0,0 +1,252 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+ using System;
+using System.IO;
+using System.Collections.Generic;
+using Avro;
+using Avro.IO;
+using Avro.Generic;
+using Avro.Specific;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+    public enum MyEnum
+    {
+        A,
+        B,
+        C
+    }
+    public class A
+    {
+        public long f1 { get; set; }
+    }
+    public class newRec
+    {
+        public long f1 { get; set; }
+    }
+
+    public class Z
+    {
+        public int? myUInt { get; set; }
+
+        public long? myULong { get; set; }
+
+        public bool? myUBool { get; set; }
+
+        public double? myUDouble { get; set; }
+
+        public float? myUFloat { get; set; }
+
+        public byte[] myUBytes { get; set; }
+
+        public string myUString { get; set; }
+
+        public int myInt { get; set; }
+
+        public long myLong { get; set; }
+
+        public bool myBool { get; set; }
+
+        public double myDouble { get; set; }
+
+        public float myFloat { get; set; }
+
+        public byte[] myBytes { get; set; }
+
+        public string myString { get; set; }
+
+        public object myNull { get; set; }
+
+        public byte[] myFixed { get; set; }
+
+        public A myA { get; set; }
+
+        public MyEnum myE { get; set; }
+
+        public List<byte[]> myArray { get; set; }
+
+        public List<newRec> myArray2 { get; set; }
+
+        public Dictionary<string, string> myMap { get; set; }
+
+        public Dictionary<string, newRec> myMap2 { get; set; }
+
+        public object myObject { get; set; }
+
+        public List<List<object>> myArray3 { get; set; }
+    }
+    [TestFixture]
+    public class TestFromAvroProject
+    {
+        private string _avroTestSchemaV1 = @""{
+        """"protocol"""" : """"MyProtocol"""",
+        """"namespace"""" : """"com.foo"""",
+        """"types"""" :
+        [
+            {
+                """"type"""" : """"record"""",
+                """"name"""" : """"A"""",
+                """"fields"""" : [ { """"name"""" : """"f1"""", """"type"""" : """"long"""" } ]
+            },
+            {
+                """"type"""" : """"enum"""",
+                """"name"""" : """"MyEnum"""",
+                """"symbols"""" : [ """"A"""", """"B"""", """"C"""" ]
+            },
+            {
+                """"type"""": """"fixed"""",
+                """"size"""": 16,
+                """"name"""": """"MyFixed""""
+            },
+            {
+                """"type"""" : """"record"""",
+                """"name"""" : """"Z"""",
+                """"fields"""" :
+                [
+                    { """"name"""" : """"myUInt"""", """"type"""" : [ """"int"""", """"null"""" ] },
+                    { """"name"""" : """"myULong"""", """"type"""" : [ """"long"""", """"null"""" ] },
+                    { """"name"""" : """"myUBool"""", """"type"""" : [ """"boolean"""", """"null"""" ] },
+                    { """"name"""" : """"myUDouble"""", """"type"""" : [ """"double"""", """"null"""" ] },
+                    { """"name"""" : """"myUFloat"""", """"type"""" : [ """"float"""", """"null"""" ] },
+                    { """"name"""" : """"myUBytes"""", """"type"""" : [ """"bytes"""", """"null"""" ] },
+                    { """"name"""" : """"myUString"""", """"type"""" : [ """"string"""", """"null"""" ] },
+                    { """"name"""" : """"myInt"""", """"type"""" : """"int"""" },
+                    { """"name"""" : """"myLong"""", """"type"""" : """"long"""" },
+                    { """"name"""" : """"myBool"""", """"type"""" : """"boolean"""" },
+                    { """"name"""" : """"myDouble"""", """"type"""" : """"double"""" },
+                    { """"name"""" : """"myFloat"""", """"type"""" : """"float"""" },
+                    { """"name"""" : """"myBytes"""", """"type"""" : """"bytes"""" },
+                    { """"name"""" : """"myString"""", """"type"""" : """"string"""" },
+                    { """"name"""" : """"myNull"""", """"type"""" : """"null"""" },
+                    { """"name"""" : """"myFixed"""", """"type"""" : """"MyFixed"""" },
+                    { """"name"""" : """"myA"""", """"type"""" : """"A"""" },
+                    { """"name"""" : """"myE"""", """"type"""" : """"MyEnum"""" },
+                    { """"name"""" : """"myArray"""", """"type"""" : { """"type"""" : """"array"""", """"items"""" : """"bytes"""" } },
+                    { """"name"""" : """"myArray2"""", """"type"""" : { """"type"""" : """"array"""", """"items"""" : { """"type"""" : """"record"""", """"name"""" : """"newRec"""", """"fields"""" : [ { """"name"""" : """"f1"""", """"type"""" : """"long""""} ] } } },
+                    { """"name"""" : """"myMap"""", """"type"""" : { """"type"""" : """"map"""", """"values"""" : """"string"""" } },
+                    { """"name"""" : """"myMap2"""", """"type"""" : { """"type"""" : """"map"""", """"values"""" : """"newRec"""" } },
+                    { """"name"""" : """"myObject"""", """"type"""" : [ """"MyEnum"""", """"A"""", """"null"""" ] },
+                    { """"name"""" : """"myArray3"""", """"type"""" : { """"type"""" : """"array"""", """"items"""" : { """"type"""" : """"array"""", """"items"""" : [ """"double"""", """"string"""", """"null"""" ] } } }
+                ]
+            }
+        ]
+        }"";
+
+        public Z SerializeDeserialize(Z z)
+        {
+            try
+            {
+                Protocol protocol = Protocol.Parse(_avroTestSchemaV1);
+                Schema schema = null;
+                foreach (var s in protocol.Types)
+                {
+                    if (s.Name == ""Z"")
+                    {
+                        schema = s;
+                    }
+                }
+
+                var avroWriter = new ReflectWriter<Z>(schema);
+                var avroReader = new ReflectReader<Z>(schema, schema);
+
+                byte[] serialized;
+
+                using (var stream = new MemoryStream(256))
+                {
+                    avroWriter.Write(z, new BinaryEncoder(stream));
+                    serialized = stream.ToArray();
+                }
+
+                Z deserialized = null;
+                using (var stream = new MemoryStream(serialized))
+                {
+                    deserialized = avroReader.Read(default(Z), new BinaryDecoder(stream));
+                }
+
+                return deserialized;
+            }
+            catch (Exception ex)
+            {
+                Console.WriteLine(ex.ToString());
+                throw ex;
+            }
+        }
+
+        [TestCase]
+        public void DefaultZ()
+        {
+            var z = new Z()
+            {
+                myBytes = new byte[10],
+                myString = ""123"",
+                myFixed = new byte[16],
+                myA = new A(),
+                myArray = new List<byte[]>(),
+                myArray2 = new List<newRec>(),
+                myMap = new Dictionary<string, string>(),
+                myMap2 = new Dictionary<string, newRec>(),
+                myArray3 = new List<List<object>>()
+            };
+
+            var zz = SerializeDeserialize(z);
+        }
+
+        [TestCase]
+        public void PopulatedZ()
+        {
+            var z = new Z()
+            {
+                myUInt = 1,
+                myULong = 2L,
+                myUBool = true,
+                myUDouble = 3.14,
+                myUFloat = (float)1.59E-3,
+                myUBytes = new byte[3] { 0x01, 0x02, 0x03 },
+                myUString = ""abc"",
+                myInt = 1,
+                myLong = 2L,
+                myBool = true,
+                myDouble = 3.14,
+                myFloat = (float)1.59E-2,
+                myBytes = new byte[3] { 0x01, 0x02, 0x03 },
+                myString = ""def"",
+                myNull = null,
+                myFixed = new byte[16] { 0x01, 0x02, 0x03, 0x04, 0x01, 0x02, 0x03, 0x04, 0x01, 0x02, 0x03, 0x04, 0x01, 0x02, 0x03, 0x04 },
+                myA = new A() { f1 = 3L },
+                myE = MyEnum.B,
+                myArray = new List<byte[]>() { new byte[] { 0x01, 0x02, 0x03, 0x04 } },
+                myArray2 = new List<newRec>() { new newRec() { f1 = 4L } },
+                myMap = new Dictionary<string, string>()
+                {
+                    [""abc""] = ""123""
+                },
+                myMap2 = new Dictionary<string, newRec>()
+                {
+                    [""abc""] = new newRec() { f1 = 5L }
+                },
+                myObject = new A() { f1 = 6L },
+                myArray3 = new List<List<object>>() { new List<object>() { 7.0, ""def"" } }
+            };
+
+            var zz = SerializeDeserialize(z);","[{'comment': 'We should assert that all the properties of `zz` equal those of `z`.', 'commenter': 'blachniet'}]"
521,lang/csharp/src/apache/main/Reflect/ReflectArrayHelper.cs,"@@ -0,0 +1,43 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+
+namespace Avro.Reflect
+{
+    public class ReflectArrayHelper","[{'comment': ""I'm reaching a bit here, but do you think that we could somehow indicate the type of array to create in the `AvroFieldAttribute`, rather than providing this array helper to the reader/writer, which means that all array-like structures must be represented using the same C# type?"", 'commenter': 'blachniet'}]"
525,lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectLogicalTypes.java,"@@ -598,6 +601,18 @@ public void testWriteUUIDList() throws IOException {
         read(REFLECT.createDatumReader(stringArraySchema), test).get(0));
   }
 
+  @Test
+  public void testReflectedSchemaLocalDateTime() {
+    Schema actual = REFLECT.getSchema(RecordWithTimestamps.class);
+
+    Assert.assertEquals(""Should have the correct record name"", ""org.apache.avro.reflect"", actual.getNamespace());","[{'comment': ""It's the namespace, not the name."", 'commenter': 'zivanfi'}]"
525,lang/java/compiler/src/main/javacc/org/apache/avro/compiler/idl/idl.jj,"@@ -242,6 +242,7 @@ TOKEN :
 | < TIME: ""time_ms"" >
 | < TIMESTAMP: ""timestamp_ms"" >
 | < DECIMAL: ""decimal"" >
+| < LOCAL_TIMESTAMP_MS: ""local_timestamp_ms"" >","[{'comment': 'The other tokens above do not have _MS in the name even if there is a _ms in the string.\r\n\r\nAnother question: Why are there only tokens for millisec variants but not for microsec variants? This is not only true for the new type but for the old type as well.', 'commenter': 'zivanfi'}, {'comment': 'Make sense, will address this.', 'commenter': 'nandorKollar'}, {'comment': ""As of the other question: I was wondering on this question too, and I don't know. The author of the logical types seemed to find unimportant to add IDL representation for microsec, hence I didn't add it either for the new types. So far it seems that nobody else added this either, we can add the new token later if needed (to both types). Actually time type has one precision token too. The spec also has a duration type, which doesn't have any IDL token, though it seems that it isn't even implemented for Java, only for Ruby and C++."", 'commenter': 'nandorKollar'}]"
525,lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericLogicalTypes.java,"@@ -47,6 +51,8 @@
   public static void addDecimalAndUUID() {","[{'comment': 'After adding the time conversions to this method the name (or the behavior) is really misleading.', 'commenter': 'gszadovszky'}, {'comment': '+1, will change the name', 'commenter': 'nandorKollar'}]"
525,share/VERSION.txt,"@@ -1 +1 @@
-1.9.0-SNAPSHOT","[{'comment': ""I think, this is not related to this change. Shouldn't it be updated automatically after a release? We might create a JIRA for it..."", 'commenter': 'gszadovszky'}, {'comment': ""Indeed it is not related to this issue, however without this change Python tests failed, that's why I added it to the PR."", 'commenter': 'nandorKollar'}, {'comment': 'Resolving this comment, as the problem is addressed in #527 ', 'commenter': 'nandorKollar'}]"
525,doc/src/content/xdocs/spec.xml,"@@ -1530,6 +1530,26 @@ void initFPTable() {
         </p>
       </section>
 
+      <section>
+        <title>Local timestamp (millisecond precision)</title>
+        <p>
+          The <code>local-timestamp-millis</code> logical type represents a timestamp in a local timezone, regardless of what specific time zone is considered local, with a precision of one millisecond.","[{'comment': 'For local-timestamp-millis the semantics is specified but the interpretation of the numeric value is missing. For timestamp-millis, the interpretation of the numeric value that is specified, but an explanation of the semantics is missing. Could you please add both descriptions to both types? You can use the wording from here, if you would like to: https://github.com/apache/parquet-format/commit/fa6e468540d36122ca8a273e9c49425660c75360', 'commenter': 'zivanfi'}]"
574,lang/csharp/src/apache/test/Interop/InteropDataTests.cs,"@@ -0,0 +1,52 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System.IO;
+using NUnit.Framework;
+using Avro.File;
+using Avro.Generic;
+
+namespace Avro.Test.Interop
+{
+    [TestFixture]
+    public class InteropDataTests
+    {
+        [TestCase(""../../../../../../../../build/interop/data"")]
+        public void TestInterOp(string inputDir)","[{'comment': 'For consistency, make the ""O"" lowercase.\r\n\r\n```suggestion\r\n        public void TestInterop(string inputDir)\r\n```', 'commenter': 'blachniet'}]"
574,lang/csharp/src/apache/test/Interop/InteropDataTests.cs,"@@ -0,0 +1,52 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System.IO;
+using NUnit.Framework;
+using Avro.File;
+using Avro.Generic;
+
+namespace Avro.Test.Interop
+{
+    [TestFixture]
+    public class InteropDataTests","[{'comment': 'This test fails if the interop data has not been generated yet. In other words, when the `<root>/build/interop/data` folder does not exists. I think we should filter out this test when running a standard `lang/csharp/build.sh test`. The easiest way to do this would be to add a test category on this class, which we could use in our test filters.\r\n\r\n```suggestion\r\n    [Category(""Interop"")]\r\n    public class InteropDataTests\r\n```', 'commenter': 'blachniet'}]"
574,lang/csharp/build.sh,"@@ -61,14 +61,22 @@ case ""$1"" in
     cp -pr build/doc/* ${ROOT}/build/avro-doc-${VERSION}/api/csharp
     ;;
 
+  interop-data-generate)
+    dotnet run --project src/apache/test/Avro.test.csproj --framework netcoreapp2.2 ../../share/test/schemas/interop.avsc ../../build/interop/data
+    ;;
+
+  interop-data-test)
+    LANG=en_US.UTF-8 dotnet test --filter ""FullyQualifiedName~Avro.Test.Interop.InteropDataTests""","[{'comment': 'Filter by the `""Interop""` category instead. See comments about adding an ""Interop"" category to the test fixture in `InteropDataTests`.\r\n\r\n```suggestion\r\n    LANG=en_US.UTF-8 dotnet test --filter ""TestCategory=Interop""\r\n```\r\n\r\nIn the `test` case above, filter out this category like so:\r\n\r\n```bash\r\n    # AVRO-2442: Explictly set LANG to work around ICU bug in `dotnet test`\r\n    LANG=en_US.UTF-8 dotnet test  --configuration Release --no-build \\\r\n        --filter ""TestCategory!=Interop"" Avro.sln\r\n```', 'commenter': 'blachniet'}]"
574,lang/csharp/src/apache/test/Interop/InteropDataTests.cs,"@@ -0,0 +1,52 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System.IO;
+using NUnit.Framework;
+using Avro.File;
+using Avro.Generic;
+
+namespace Avro.Test.Interop
+{
+    [TestFixture]
+    public class InteropDataTests
+    {
+        [TestCase(""../../../../../../../../build/interop/data"")]
+        public void TestInterOp(string inputDir)
+        {","[{'comment': 'The ""current directory"" varies depending on how you run this test (e.g. `dotnet test` vs running tests in Visual Studio\'s Test Explorer). It also varies in .NET Framework vs .NET Core. For example, running on my Windows machine, this tests passes in .NET Core but fails in .NET Framework because the current directory is different.\r\n\r\nI was able to resolve this by resolving the `inputDir` relative to the `TestDirectory` rather than the ""current directory"".\r\n\r\n```suggestion\r\n        {\r\n            // Resolve inputDir relative to the TestDirectory\r\n            inputDir = Path.Combine(TestContext.CurrentContext.TestDirectory, inputDir);\r\n\r\n            Assert.True(Directory.Exists(inputDir),\r\n                ""Input directory does not exist. Run `build.sh interop-data-generate` first."");\r\n\r\n```\r\n\r\nThe next `Assert.True` ensures that we fail with a helpful message, in the event that a developer runs all tests without first generating the interop data. The failure message indicates the manual steps required to make the test pass.', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ArrayHelper.cs,"@@ -0,0 +1,98 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': ""[AVRO-2404](https://issues.apache.org/jira/browse/AVRO-2404) (#529) went thru and updated all these to `https://`. I'll insert suggestions that you can apply for each instance.\r\n\r\n```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```\r\n\r\n"", 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ArraySchemaExtensions.cs,"@@ -0,0 +1,48 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/AvroFieldAttribute.cs,"@@ -0,0 +1,70 @@
+/* Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ClassCache.cs,"@@ -0,0 +1,262 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/DateTimeOffsetToLongConverter.cs,"@@ -0,0 +1,71 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/DotnetClass.cs,"@@ -0,0 +1,149 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/DotnetProperty.cs,"@@ -0,0 +1,141 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/EnumCache.cs,"@@ -0,0 +1,58 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}, {'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/FuncFieldConverter.cs,"@@ -0,0 +1,68 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ReflectDefaultReader.cs,"@@ -0,0 +1,547 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ReflectDefaultWriter.cs,"@@ -0,0 +1,209 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ReflectReader.cs,"@@ -0,0 +1,94 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ReflectWriter.cs,"@@ -0,0 +1,74 @@
+/*  Copyright 2019 Pitney Bowes Inc.
+ *
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/TypedFieldConverter.cs,"@@ -0,0 +1,97 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/CompareUtils.cs,"@@ -0,0 +1,50 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/TestArray.cs,"@@ -0,0 +1,243 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/TestFixed.cs,"@@ -0,0 +1,162 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/TestFromAvroProject.cs,"@@ -0,0 +1,369 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/TestLogMessage.cs,"@@ -0,0 +1,113 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/TestReflect.cs,"@@ -0,0 +1,170 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/test/Reflect/TestArray.cs,"@@ -0,0 +1,243 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+using System.Collections;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestArray
+    {
+        private class ListRec
+        {
+            public string S { get; set; }
+        }
+
+        private const string _simpleList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"doc"""": """"A simple list with a string."""",
+            """"name"""": """"A"""",
+            """"items"""": """"string""""
+        }"";
+
+        private const string _recordList = @""
+        {
+            """"namespace"""": """"MessageTypes"""",
+            """"type"""": """"array"""",
+            """"helper"""": """"arrayOfA"""",
+            """"items"""": {
+                """"type"""": """"record"""",
+                """"doc"""": """"A simple type with a fixed."""",
+                """"name"""": """"A"""",
+                """"fields"""": [
+                    { """"name"""" : """"S"""", """"type"""" : """"string"""" }
+                ]
+            }
+        }"";
+
+
+
+        [TestCase]
+        public void ListTest()
+        {
+            var schema = Schema.Parse(_simpleList);
+            var fixedRecWrite = new List<string>() {""value""};
+
+            var writer = new ReflectWriter<List<string>>(schema);
+            var reader = new ReflectReader<List<string>>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                var fixedRecRead = reader.Read(new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.Count == 1);
+                Assert.AreEqual(fixedRecWrite[0],fixedRecRead[0]);
+            }
+        }
+
+        [TestCase]
+        public void ListRecTest()
+        {
+            var schema = Schema.Parse(_recordList);
+            var fixedRecWrite = new List<ListRec>() { new ListRec() { S = ""hello""}};
+
+            var writer = new ReflectWriter<List<ListRec>>(schema);
+            var reader = new ReflectReader<List<ListRec>>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                writer.Write(fixedRecWrite, new BinaryEncoder(stream));
+                stream.Seek(0, SeekOrigin.Begin);
+                var fixedRecRead = reader.Read(new BinaryDecoder(stream));
+                Assert.IsTrue(fixedRecRead.Count == 1);
+                Assert.AreEqual(fixedRecWrite[0].S,fixedRecRead[0].S);
+            }
+        }
+
+        public class ConcurrentQueueHelper<T> : ArrayHelper
+        {
+
+            /// <summary>
+            /// Return the number of elements in the array.
+            /// </summary>
+            /// <value></value>
+            public override int Count()
+            {
+                ConcurrentQueue<T> e = (ConcurrentQueue<T>)Enumerable;
+                return e.Count;
+            }
+            /// <summary>
+            /// Add an element to the array.
+            /// </summary>
+            /// <value></value>
+            public override void Add(object o)
+            {
+                ConcurrentQueue<T> e = (ConcurrentQueue<T>)Enumerable;
+                e.Enqueue((T)o);
+            }
+            /// <summary>
+            /// Clear the array.
+            /// </summary>
+            /// <value></value>
+            public override void Clear()
+            {
+                ConcurrentQueue<T> e = (ConcurrentQueue<T>)Enumerable;
+                e.Clear();","[{'comment': 'This unit test project runs agains NET461 on Windows. NET461 does not define `ConcurrentQueue{T}.Clear()`. Instead, for net461, we should dequeue all items.\r\n\r\n```suggestion\r\n#if NET461\r\n                while (e.TryDequeue(out _)) { }\r\n#else\r\n                e.Clear();\r\n#endif\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/ArrayHelper.cs,"@@ -0,0 +1,98 @@
+/*  Copyright 2019 Pitney Bowes Inc.","[{'comment': 'According to [SOURCE FILE HEADERS FOR CODE DEVELOPED AT THE ASF](https://www.apache.org/legal/src-headers.html#headers), ""there should be no copyright notice in the header"". I believe these Copyright notices need to be removed. @cutting , @busbey, @Fokko  and/or others please correct me if I\'m wrong.', 'commenter': 'blachniet'}, {'comment': 'Hi @pa009fa ,\r\nAs @blachniet  has mentioned can you please cleanup the copyright on the header of the files?\r\nIs there a reason you have them placed here or were those just the default ones? If there is a reason for these to be present please let us know the reason and we can look at it.\r\n\r\nThanks', 'commenter': 'spacharya'}, {'comment': 'Sorry for delay. Piney Bowes has not contributed to an Apache project before so the legal team is getting an undertanding of how it works. As of this morning I got approval to remove the copyright from the source files and to add something to Notice.txt. I have made the changes and pushed to the branch.\r\n', 'commenter': 'pa009fa'}]"
587,lang/csharp/src/apache/main/Reflect/Readme.md,"@@ -0,0 +1,198 @@
+# Namespace Avro.Reflect
+
+This namespace contains classes that implement Avro serialization and deserialization for plain C# objects. The classes use .net reflection to implement the serializers. The interface is similar to the Generic and Specific serialiation classes.
+
+## Serialization
+
+The approach starts with the schema and interates both the schema and the dotnet object together in a depth first manner per the specification. Serialization is the same as the Generic serializer except where the serializer encounters:
+- *A fixed type*: if the corresponding dotnet object type is a byte[] of the correct length then the object is serialized, otherwise an exception is thrown.
+- *A record type*: the serializer matches the schema property name to the dotnet object property name and then reursively serializes the schema property and the dotnet object property
+- *An array type*: See array serialization/deserialization.
+
+Basic serialization is performed as in the following example:
+
+```csharp
+    Schema schema; // created previously
+    T myObject; // created previously
+
+
+    var avroWriter = new ReflectWriter<T>(schema);
+    using (var stream = new MemoryStream(256))
+    {
+        avroWriter.Write(logMessage, new BinaryEncoder(stream));","[{'comment': 'I think you meant `myObject`, rather than `logMessage` on this line.\r\n\r\n```suggestion\r\n        avroWriter.Write(myObject, new BinaryEncoder(stream));\r\n```', 'commenter': 'blachniet'}]"
587,lang/csharp/src/apache/main/Reflect/Readme.md,"@@ -0,0 +1,198 @@
+# Namespace Avro.Reflect","[{'comment': 'Nice write up!\r\n\r\nCould you rename this file to all-caps, `README.md`, for the sake of consistency with other READMEs throughout the project? I believe this will also fix the Travis CI build failure due to this file not having a license header. The [`pom.xml` excludes all `README.md` files](https://github.com/apache/avro/blob/master/pom.xml#L353) from the license header check.', 'commenter': 'blachniet'}]"
587,NOTICE.txt,"@@ -63,3 +63,13 @@ Apache Log4Net includes the following in its NOTICE file:
 |
 | This product includes software developed at
 | The Apache Software Foundation (https://www.apache.org/).
+
+csharp reflect serializers were contributed by Pitney Bowes Inc.
+
+| Copyright 2019 Pitney Bowes Inc.
+| Licensed under the Apache License, Version 2.0 (the ""License""); you may not use this file except in compliance with the License. 
+| You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0.","[{'comment': '```suggestion\r\n| You may obtain a copy of the License at https://www.apache.org/licenses/LICENSE-2.0.\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Avro.main.csproj,"@@ -42,7 +42,7 @@
   </PropertyGroup>
 
   <ItemGroup>
-    <PackageReference Include=""Newtonsoft.Json"" Version=""3.5.8"">
+    <PackageReference Include=""Newtonsoft.Json"" Version=""10.0.3"">","[{'comment': 'Now that we are on an updated version this package, we no long need the `<NoWarn>NU1701</NoWarn>` below.\r\n\r\n```suggestion\r\n    <PackageReference Include=""Newtonsoft.Json"" Version=""10.0.3"" />\r\n\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/test/Protocol/ProtocolParseExceptionTest.cs,"@@ -0,0 +1,108 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/test/Protocol/ProtocolParseExceptionTest.cs,"@@ -0,0 +1,108 @@
+/**","[{'comment': '```suggestion\r\n/*\r\n```', 'commenter': 'blachniet'}, {'comment': 'Sorry.... this was sloppy.', 'commenter': 'pa009fa'}]"
600,lang/csharp/src/apache/test/Protocol/ProtocolParseExceptionTest.cs,"@@ -0,0 +1,108 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using NUnit.Framework;
+
+namespace Avro.Test
+{
+    [TestFixture]
+    public class ProtocolParseExceptionTest
+    {
+        [TestCase]
+        public void TestRecord()","[{'comment': '```suggestion\r\n        public void TestProtocolParseExceptions()\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -54,17 +54,23 @@ internal static UnionSchema NewInstance(JArray jarr, PropertyMap props, SchemaNa
             {
                 Schema unionType = Schema.ParseJson(jvalue, names, encspace);
                 if (null == unionType)
-                    throw new SchemaParseException(""Invalid JSON in union"" + jvalue.ToString());
+                    throw new SchemaParseException($""Invalid JSON in union {jvalue.ToString()} at {jvalue.Path}"");
 
                 string name = unionType.Fullname;
                 if (uniqueSchemas.ContainsKey(name))
-                    throw new SchemaParseException(""Duplicate type in union: "" + name);
+                    throw new SchemaParseException($""Duplicate type in union: {name} at {jvalue.Path}"");
 
                 uniqueSchemas.Add(name, name);
                 schemas.Add(unionType);
             }
-
-            return new UnionSchema(schemas, props);
+            try
+            {
+                return new UnionSchema(schemas, props);","[{'comment': ""I don't see a path in which  calling `new UnionSchema(schemas, props)` could throw an exception here. The `UnionSchema(List<Schema>, PropertyMap)` constructor will throw an `ArgumentNullException` if the list of schemas is null, but that can't happen here. I think we can safely remove the `try`/`catch` here."", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/NamedSchema.cs,"@@ -127,7 +127,14 @@ protected static SchemaName GetName(JToken jtok, string encspace)
         {
             String n = JsonHelper.GetOptionalString(jtok, ""name"");      // Changed this to optional string for anonymous records in messages
             String ns = JsonHelper.GetOptionalString(jtok, ""namespace"");
-            return new SchemaName(n, ns, encspace);
+            try
+            {
+                return new SchemaName(n, ns, encspace);","[{'comment': ""I don't see a way that calling `new SchemaName(n, ns, encspace);` here could throw an exception. I think we can safely remove this `try`/`catch`."", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/MapSchema.cs,"@@ -47,9 +47,15 @@ public static MapSchema CreateMap(Schema type)
         internal static MapSchema NewInstance(JToken jtok, PropertyMap props, SchemaNames names, string encspace)
         {
             JToken jvalue = jtok[""values""];
-            if (null == jvalue) throw new AvroTypeException(""Map does not have 'values'"");
-
-            return new MapSchema(Schema.ParseJson(jvalue, names, encspace), props);
+            if (null == jvalue) throw new AvroTypeException($""Map does not have 'values' at {jtok.Path}"");","[{'comment': 'I think that if we put the path in single quotes (`\'`) within the exceptions methods, it would stand out a little better. If you agree, I suggest doing this everywhere we include a JSONPath in an exception message.\r\n\r\nFor example:\r\n\r\n```suggestion\r\n            if (null == jvalue) throw new AvroTypeException($""Map does not have \'values\' at \'{jtok.Path}\'"");\r\n```', 'commenter': 'blachniet'}, {'comment': 'Will do.', 'commenter': 'pa009fa'}]"
600,lang/csharp/src/apache/main/Schema/MapSchema.cs,"@@ -47,9 +47,15 @@ public static MapSchema CreateMap(Schema type)
         internal static MapSchema NewInstance(JToken jtok, PropertyMap props, SchemaNames names, string encspace)
         {
             JToken jvalue = jtok[""values""];
-            if (null == jvalue) throw new AvroTypeException(""Map does not have 'values'"");
-
-            return new MapSchema(Schema.ParseJson(jvalue, names, encspace), props);
+            if (null == jvalue) throw new AvroTypeException($""Map does not have 'values' at {jtok.Path}"");
+            try
+            {
+                return new MapSchema(Schema.ParseJson(jvalue, names, encspace), props);","[{'comment': '```suggestion\r\n                return new MapSchema(ParseJson(jvalue, names, encspace), props);\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -66,30 +66,45 @@ internal static RecordSchema NewInstance(Type type, JToken jtok, PropertyMap pro
                 if (null != jfields) request = true;
             }
             if (null == jfields)
-                throw new SchemaParseException(""'fields' cannot be null for record"");
+                throw new SchemaParseException($""'fields' cannot be null for record at {jtok.Path}"");
             if (jfields.Type != JTokenType.Array)
-                throw new SchemaParseException(""'fields' not an array for record"");
+                throw new SchemaParseException($""'fields' not an array for record at {jtok.Path}"");
 
             var name = GetName(jtok, encspace);
             var aliases = NamedSchema.GetAliases(jtok, name.Space, name.EncSpace);
             var fields = new List<Field>();
             var fieldMap = new Dictionary<string, Field>();
             var fieldAliasMap = new Dictionary<string, Field>();
-            var result = new RecordSchema(type, name, aliases, props, fields, request, fieldMap, fieldAliasMap, names,
-                JsonHelper.GetOptionalString(jtok, ""doc""));
+            RecordSchema result;
+            try
+            {
+                result = new RecordSchema(type, name, aliases, props, fields, request, fieldMap, fieldAliasMap, names,
+                    JsonHelper.GetOptionalString(jtok, ""doc""));
+            }
+            catch (Exception e)","[{'comment': ""We could limit this to only catch `SchemaParseException`. It looks like that's the only kind of exception we should expect to receive here from `new RecordSchema(...)` and/or `JsonHelper.GetOptionalString(...)`.\r\n\r\n```suggestion\r\n            catch (SchemaParseException e)\r\n```"", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -66,30 +66,45 @@ internal static RecordSchema NewInstance(Type type, JToken jtok, PropertyMap pro
                 if (null != jfields) request = true;
             }
             if (null == jfields)
-                throw new SchemaParseException(""'fields' cannot be null for record"");
+                throw new SchemaParseException($""'fields' cannot be null for record at {jtok.Path}"");
             if (jfields.Type != JTokenType.Array)
-                throw new SchemaParseException(""'fields' not an array for record"");
+                throw new SchemaParseException($""'fields' not an array for record at {jtok.Path}"");
 
             var name = GetName(jtok, encspace);
             var aliases = NamedSchema.GetAliases(jtok, name.Space, name.EncSpace);
             var fields = new List<Field>();
             var fieldMap = new Dictionary<string, Field>();
             var fieldAliasMap = new Dictionary<string, Field>();
-            var result = new RecordSchema(type, name, aliases, props, fields, request, fieldMap, fieldAliasMap, names,
-                JsonHelper.GetOptionalString(jtok, ""doc""));
+            RecordSchema result;
+            try
+            {
+                result = new RecordSchema(type, name, aliases, props, fields, request, fieldMap, fieldAliasMap, names,
+                    JsonHelper.GetOptionalString(jtok, ""doc""));
+            }
+            catch (Exception e)
+            {
+                throw new SchemaParseException($""{e.Message} at {jtok.Path}"", e);
+            }
 
             int fieldPos = 0;
             foreach (JObject jfield in jfields)
             {
                 string fieldName = JsonHelper.GetRequiredString(jfield, ""name"");
                 Field field = createField(jfield, fieldPos++, names, name.Namespace);  // add record namespace for field look up
                 fields.Add(field);
+                try
+                {","[{'comment': 'Indent the body of this `try` block.', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -66,30 +66,45 @@ internal static RecordSchema NewInstance(Type type, JToken jtok, PropertyMap pro
                 if (null != jfields) request = true;
             }
             if (null == jfields)
-                throw new SchemaParseException(""'fields' cannot be null for record"");
+                throw new SchemaParseException($""'fields' cannot be null for record at {jtok.Path}"");
             if (jfields.Type != JTokenType.Array)
-                throw new SchemaParseException(""'fields' not an array for record"");
+                throw new SchemaParseException($""'fields' not an array for record at {jtok.Path}"");
 
             var name = GetName(jtok, encspace);
             var aliases = NamedSchema.GetAliases(jtok, name.Space, name.EncSpace);
             var fields = new List<Field>();
             var fieldMap = new Dictionary<string, Field>();
             var fieldAliasMap = new Dictionary<string, Field>();
-            var result = new RecordSchema(type, name, aliases, props, fields, request, fieldMap, fieldAliasMap, names,
-                JsonHelper.GetOptionalString(jtok, ""doc""));
+            RecordSchema result;
+            try
+            {
+                result = new RecordSchema(type, name, aliases, props, fields, request, fieldMap, fieldAliasMap, names,
+                    JsonHelper.GetOptionalString(jtok, ""doc""));
+            }
+            catch (Exception e)
+            {
+                throw new SchemaParseException($""{e.Message} at {jtok.Path}"", e);
+            }
 
             int fieldPos = 0;
             foreach (JObject jfield in jfields)
             {
                 string fieldName = JsonHelper.GetRequiredString(jfield, ""name"");
                 Field field = createField(jfield, fieldPos++, names, name.Namespace);  // add record namespace for field look up
                 fields.Add(field);
+                try
+                {
                 addToFieldMap(fieldMap, fieldName, field);
                 addToFieldMap(fieldAliasMap, fieldName, field);
 
                 if (null != field.aliases)    // add aliases to field lookup map so reader function will find it when writer field name appears only as an alias on the reader field
                     foreach (string alias in field.aliases)
                         addToFieldMap(fieldAliasMap, alias, field);
+                }
+                catch (Exception e)","[{'comment': 'This is another scenario where we can safely limit to catching only `SchemaParseException`.\r\n```suggestion\r\n                catch (SchemaParseException e)\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -143,10 +158,16 @@ private static Field createField(JToken jfield, int pos, SchemaNames names, stri
 
             JToken jtype = jfield[""type""];
             if (null == jtype)
-                throw new SchemaParseException(""'type' was not found for field: "" + name);
+                throw new SchemaParseException($""'type' was not found for field: name at {jfield.Path}"");
             var schema = Schema.ParseJson(jtype, names, encspace);
-
-            return new Field(schema, name, aliases, pos, doc, defaultValue, sortorder, props);
+            try
+            {
+                return new Field(schema, name, aliases, pos, doc, defaultValue, sortorder, props);","[{'comment': ""In what scenario would this throw an exception? I can't seem to track down such a scenario. If we can do so safely, let's remove this `try`/`catch`."", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/JsonHelper.cs,"@@ -68,12 +68,13 @@ public static string GetRequiredString(JToken jtok, string field)
         /// <returns>property value</returns>
         public static int GetRequiredInteger(JToken jtok, string field)
         {
-            ensureValidFieldName(field);
+            if (string.IsNullOrEmpty(field)) throw new ArgumentNullException($""name at {jtok.Path}"");
+
             JToken child = jtok[field];
-            if (null == child) throw new SchemaParseException(string.Format(""No \""{0}\"" JSON field: {1}"", field, jtok));
+            if (null == child) throw new SchemaParseException($""No \""{field}\"" JSON field: {Regex.Replace(jtok.ToString(), @""\r\n?|\n"", """")} at {jtok.Path}"");","[{'comment': 'Sorry for my ignorance, but why is the `Regex.Replace` required here? Can you provide an example of when this is needed?', 'commenter': 'blachniet'}, {'comment': 'There are newlines in the JSON and, besides not being great in the log files, they make the test results inconsistent between windows and unix style systems. Alternative would be to have a check for the platform in the test. Happy to go either way - let me know.', 'commenter': 'pa009fa'}]"
600,lang/csharp/src/apache/main/Schema/JsonHelper.cs,"@@ -68,12 +68,13 @@ public static string GetRequiredString(JToken jtok, string field)
         /// <returns>property value</returns>
         public static int GetRequiredInteger(JToken jtok, string field)
         {
-            ensureValidFieldName(field);
+            if (string.IsNullOrEmpty(field)) throw new ArgumentNullException($""name at {jtok.Path}"");","[{'comment': '```suggestion\r\n            if (string.IsNullOrEmpty(field)) throw new ArgumentNullException(nameof(field));\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/FixedSchema.cs,"@@ -43,9 +43,15 @@ internal static FixedSchema NewInstance(JToken jtok, PropertyMap props, SchemaNa
         {
             SchemaName name = NamedSchema.GetName(jtok, encspace);
             var aliases = NamedSchema.GetAliases(jtok, name.Space, name.EncSpace);
-
-            return new FixedSchema(name, aliases, JsonHelper.GetRequiredInteger(jtok, ""size""), props, names,
-                JsonHelper.GetOptionalString(jtok, ""doc""));
+            try
+            {
+                return new FixedSchema(name, aliases, JsonHelper.GetRequiredInteger(jtok, ""size""), props, names,
+                    JsonHelper.GetOptionalString(jtok, ""doc""));
+            }
+            catch (Exception e)
+            {
+                throw new SchemaParseException($""E{e.Message} at {jtok.Path}"", e);","[{'comment': '```suggestion\r\n                throw new SchemaParseException($""{e.Message} at {jtok.Path}"", e);\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -65,13 +65,20 @@ internal static EnumSchema NewInstance(JToken jtok, PropertyMap props, SchemaNam
             {
                 string s = (string)jsymbol.Value;
                 if (symbolMap.ContainsKey(s))
-                    throw new SchemaParseException(""Duplicate symbol: "" + s);
+                    throw new SchemaParseException($""Duplicate symbol: {s} at {jtok.Path}"");
 
                 symbolMap[s] = i++;
                 symbols.Add(s);
             }
-            return new EnumSchema(name, aliases, symbols, symbolMap, props, names,
-                JsonHelper.GetOptionalString(jtok, ""doc""));
+            try
+            {
+                return new EnumSchema(name, aliases, symbols, symbolMap, props, names,
+                    JsonHelper.GetOptionalString(jtok, ""doc""));
+            }
+            catch (Exception e)","[{'comment': 'I think we can safely limit this to only catch `SchemaParseException`.\r\n\r\n```suggestion\r\n            catch (SchemaParseException e)\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Generic/PreresolvingDatumReader.cs,"@@ -15,6 +15,7 @@
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
+using System;","[{'comment': '```suggestion\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/Directory.Build.targets,"@@ -0,0 +1,19 @@
+<!--","[{'comment': 'I thought we had eliminated the need for `lang/csharp/Directory.Build.targets` and `lang/csharp/after.Avro.sln.targets`. Are these still necessary? What problem are they resolving?', 'commenter': 'blachniet'}, {'comment': ""I put them in with the reflect work so that 'dotnet test' would just run the test projects and not try to run tests in the other projects that didnt have tests. I'll check whether they still help with this and let you know."", 'commenter': 'pa009fa'}]"
600,lang/csharp/Avro.code-workspace,"@@ -0,0 +1,29 @@
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0","[{'comment': '```suggestion\r\n *     https://www.apache.org/licenses/LICENSE-2.0\r\n```', 'commenter': 'blachniet'}]"
600,lang/csharp/Avro.code-workspace,"@@ -0,0 +1,29 @@
+
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+ 
+ {
+	""folders"": [
+		{
+			""path"": "".""
+		}
+	],
+	""settings"": {
+		""dotnet-test-explorer.testProjectPath"": ""src/test/Avro.test.csproj""","[{'comment': 'This shows up as an ""Unknown configuration setting"" in Visual Studio Code. Is this for a specific plugin?\r\n\r\n![image](https://user-images.githubusercontent.com/785131/62415304-88e78500-b5f5-11e9-8915-b2aa5f637871.png)\r\n', 'commenter': 'blachniet'}]"
600,lang/csharp/Avro.code-workspace,"@@ -0,0 +1,29 @@
+","[{'comment': ""Did you intentionally commit `Avro.code-workspace`? I've not used work-spaces in VS Code much, so I'm not very familiar with them. Are these normally committed to the repository, or are they normally excluded?"", 'commenter': 'blachniet'}, {'comment': ""It was an accident - I created it when I knew slightly less about what I was doing than now. They are for project that have multiple root folders. I'll remove it."", 'commenter': 'pa009fa'}]"
600,lang/csharp/src/apache/ipc.test/Avro.ipc.test.csproj,"@@ -17,7 +17,7 @@
 <Project Sdk=""Microsoft.NET.Sdk"">
 
   <PropertyGroup>
-    <TargetFrameworks>net40</TargetFrameworks>
+    <TargetFramework>netcoreapp2.0</TargetFramework>","[{'comment': ""Is this change necessary now that this project is not included in the `Avro.sln`? Since it's not included in the solution, `dotnet build` and `dotnet test` shouldn't include it.\r\n\r\n```suggestion\r\n    <TargetFrameworks>net40</TargetFrameworks>\r\n```"", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/ipc/Avro.ipc.csproj,"@@ -17,7 +17,7 @@
 <Project Sdk=""Microsoft.NET.Sdk"">
 
   <PropertyGroup>
-    <TargetFrameworks>net40;netstandard2.0</TargetFrameworks>
+    <TargetFramework>netstandard2.0</TargetFramework>","[{'comment': ""Is this change necessary now that this project is not included in the Avro.sln? Since it's not included in the solution, dotnet build and dotnet test shouldn't include it.\r\n\r\n```suggestion\r\n    <TargetFrameworks>net40;netstandard2.0</TargetFrameworks>\r\n```"", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Schema/ArraySchema.cs,"@@ -41,9 +41,16 @@ public class ArraySchema : UnnamedSchema
         internal static ArraySchema NewInstance(JToken jtok, PropertyMap props, SchemaNames names, string encspace)
         {
             JToken jitem = jtok[""items""];
-            if (null == jitem) throw new AvroTypeException(""Array does not have 'items'"");
-
-            return new ArraySchema(Schema.ParseJson(jitem, names, encspace), props);
+            if (null == jitem) throw new AvroTypeException($""Array does not have 'items' at {jtok.Path}"");
+            var schema = Schema.ParseJson(jitem, names, encspace);
+            try
+            {
+                return new ArraySchema(schema, props);","[{'comment': ""I don't think there's any way for this call to throw an exception here. You should be able to safely remove this `try`/`catch`."", 'commenter': 'blachniet'}]"
600,lang/csharp/src/apache/main/Protocol/Protocol.cs,"@@ -147,8 +147,14 @@ private static Protocol Parse(JToken jtok)
                     messages.Add(message.Name, message);
                 }
             }
-
-            return new Protocol(name, space, doc, types, messages);
+            try
+            {
+                return new Protocol(name, space, doc, types, messages);","[{'comment': ""I don't see any reason that this call would throw an exception. I think you can safely remove this `try`/`catch`."", 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/test/Reflect/TestFromAvroProject.cs,"@@ -78,6 +78,7 @@ public class Z
         public byte[] myFixed { get; set; }
 
         public A myA { get; set; }
+        public A myNullableA { get; set; }","[{'comment': 'Insert a blank line abve `myNullableA` for consistency.\r\n\r\n```suggestion\r\n\r\n        public A myNullableA { get; set; }\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/test/Reflect/TestFromAvroProject.cs,"@@ -264,6 +266,15 @@ private void DoAssertions(Z z, Z zz)
                 Assert.IsNotNull(zz.myA);
                 Assert.AreEqual(z.myA.f1, zz.myA.f1);
             }
+            if (z.myNullableA == null)","[{'comment': ""These tests pass, even before the code changes in `ClassCache.cs`. I think it might be because `A` is already cached via the `myA` field.\r\n\r\nTry creating a new class that is only used by this one field so you can exercise this functionality. Make a note in the documentation on that class that we shouldn't use it in other fields in the future for other test cases."", 'commenter': 'blachniet'}, {'comment': 'Added new test', 'commenter': 'pa009fa'}]"
617,lang/csharp/src/apache/main/Reflect/ClassCache.cs,"@@ -254,6 +254,16 @@ public void LoadClassCache(Type objType, Schema s)
                     break;
                 case NamedSchema ns:
                     EnumCache.AddEnumNameMapItem(ns, objType);
+                    break;
+                case UnionSchema us:
+                    foreach (var o in us.Schemas)","[{'comment': 'Please correct me if I\'m wrong, but I think we can only support certain types of unions:\r\n1. Those with only 1 branch\r\n1. Those with only 2 branches, one of which is `""null""`\r\n\r\nIf that\'s true, I think we should make this `case` statement more restrictive. For example, throwing an exception when it doesn\'t meet these criteria.', 'commenter': 'blachniet'}, {'comment': 'Added the test. Multiple branches in a union are supported but when a record type is first defined in a union and the union is not of type [""null"", ""recordType""] then the type needs to be manually registered in the class cache. Added a test to (I hope) make this clearer.  Also added to the README.', 'commenter': 'pa009fa'}]"
617,lang/csharp/src/apache/test/Reflect/TestUnion.cs,"@@ -0,0 +1,184 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+using System.Collections;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestUnion
+    {
+        public class BaseClass
+        {
+            public string A { get; set; }
+        }
+
+        public class Derived1 : BaseClass
+        {
+            public int B { get; set; }
+        }
+
+        public class Derived2 : BaseClass
+        {
+            public double C { get; set; }
+        }
+
+        [TestCase]
+        public void BaseClassTest()
+        {
+            var baseClassSchema = @""
+            [
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied1"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"B"""", """"type"""" : """"int""""}
+                    ]
+                },
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+
+            var schema = Schema.Parse(baseClassSchema);
+            var derived1write = new Derived1() { A = ""derived1"", B = 7 };
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived1), unionSchema[0]);
+            cache.LoadClassCache(typeof(Derived2), unionSchema[1]);
+            var x = schema as RecordSchema;
+
+            var writer = new ReflectWriter<BaseClass>(schema, cache);
+            var reader = new ReflectReader<BaseClass>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived1write, encoder);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived1read = (Derived1)reader.Read(decoder);
+                var derived2read = (Derived2)reader.Read(decoder);
+                Assert.AreEqual(derived1read.A, derived1write.A);
+                Assert.AreEqual(derived1read.B, derived1write.B);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void NullableTest()
+        {
+            var nullableSchema = @""
+            [
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(nullableSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            var writer = new ReflectWriter<Derived2>(schema);
+            var reader = new ReflectReader<Derived2>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void HeterogeneousTest()
+        {
+            var heterogeneousSchema = @""
+            [
+                """"string"""",
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(heterogeneousSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived2), unionSchema[2]);
+
+            var writer = new ReflectWriter<object>(schema, cache);
+            var reader = new ReflectReader<object>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                writer.Write(""string value"", encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = (Derived2)reader.Read(decoder);
+                var stringRead = (string)reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+                Assert.AreEqual(stringRead, ""string value"");
+            }
+        }
+    }
+
+    public static class SchemaExtension","[{'comment': ""Can we remove the `SchemaExtension` class? I don't think it's used."", 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/test/Reflect/TestUnion.cs,"@@ -0,0 +1,184 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+using System.Collections;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestUnion
+    {
+        public class BaseClass
+        {
+            public string A { get; set; }
+        }
+
+        public class Derived1 : BaseClass
+        {
+            public int B { get; set; }
+        }
+
+        public class Derived2 : BaseClass
+        {
+            public double C { get; set; }
+        }
+
+        [TestCase]
+        public void BaseClassTest()
+        {
+            var baseClassSchema = @""
+            [
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied1"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"B"""", """"type"""" : """"int""""}
+                    ]
+                },
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+
+            var schema = Schema.Parse(baseClassSchema);
+            var derived1write = new Derived1() { A = ""derived1"", B = 7 };
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived1), unionSchema[0]);
+            cache.LoadClassCache(typeof(Derived2), unionSchema[1]);
+            var x = schema as RecordSchema;
+
+            var writer = new ReflectWriter<BaseClass>(schema, cache);
+            var reader = new ReflectReader<BaseClass>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived1write, encoder);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived1read = (Derived1)reader.Read(decoder);
+                var derived2read = (Derived2)reader.Read(decoder);
+                Assert.AreEqual(derived1read.A, derived1write.A);
+                Assert.AreEqual(derived1read.B, derived1write.B);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void NullableTest()
+        {
+            var nullableSchema = @""
+            [
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(nullableSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            var writer = new ReflectWriter<Derived2>(schema);
+            var reader = new ReflectReader<Derived2>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);","[{'comment': 'Could you add a scenario where you write a `null` in `NullableTest`?\r\n\r\nFor example note the `writer.Write(null, encoder);` and `var nullRead = reader.Read(decoder);` added below.\r\n\r\n```c#\r\n                var encoder = new BinaryEncoder(stream);\r\n                writer.Write(derived2write, encoder);\r\n                writer.Write(null, encoder);\r\n                stream.Seek(0, SeekOrigin.Begin);\r\n\r\n                var decoder = new BinaryDecoder(stream);\r\n                var derived2read = reader.Read(decoder);\r\n                var nullRead = reader.Read(decoder);\r\n                Assert.AreEqual(derived2read.A, derived2write.A);\r\n                Assert.AreEqual(derived2read.C, derived2write.C);\r\n                Assert.IsNull(nullRead);\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/test/Reflect/TestUnion.cs,"@@ -0,0 +1,184 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+using System.Collections;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestUnion
+    {
+        public class BaseClass
+        {
+            public string A { get; set; }
+        }
+
+        public class Derived1 : BaseClass
+        {
+            public int B { get; set; }
+        }
+
+        public class Derived2 : BaseClass
+        {
+            public double C { get; set; }
+        }
+
+        [TestCase]
+        public void BaseClassTest()
+        {
+            var baseClassSchema = @""
+            [
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied1"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"B"""", """"type"""" : """"int""""}
+                    ]
+                },
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+
+            var schema = Schema.Parse(baseClassSchema);
+            var derived1write = new Derived1() { A = ""derived1"", B = 7 };
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived1), unionSchema[0]);
+            cache.LoadClassCache(typeof(Derived2), unionSchema[1]);
+            var x = schema as RecordSchema;
+
+            var writer = new ReflectWriter<BaseClass>(schema, cache);
+            var reader = new ReflectReader<BaseClass>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived1write, encoder);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived1read = (Derived1)reader.Read(decoder);
+                var derived2read = (Derived2)reader.Read(decoder);
+                Assert.AreEqual(derived1read.A, derived1write.A);
+                Assert.AreEqual(derived1read.B, derived1write.B);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void NullableTest()
+        {
+            var nullableSchema = @""
+            [
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(nullableSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            var writer = new ReflectWriter<Derived2>(schema);
+            var reader = new ReflectReader<Derived2>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void HeterogeneousTest()
+        {
+            var heterogeneousSchema = @""
+            [
+                """"string"""",
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(heterogeneousSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived2), unionSchema[2]);
+
+            var writer = new ReflectWriter<object>(schema, cache);
+            var reader = new ReflectReader<object>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                writer.Write(""string value"", encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = (Derived2)reader.Read(decoder);
+                var stringRead = (string)reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+                Assert.AreEqual(stringRead, ""string value"");","[{'comment': 'Could you add a scenario where you write a `null` in `HeterogeneousTest`?\r\n\r\nFor example, note the `writer.Write(null, encoder);` and `Assert.IsNull(nullRead);` added below.\r\n\r\n```c#\r\n                var encoder = new BinaryEncoder(stream);\r\n                writer.Write(null, encoder);\r\n                writer.Write(derived2write, encoder);\r\n                writer.Write(""string value"", encoder);\r\n                stream.Seek(0, SeekOrigin.Begin);\r\n\r\n                var decoder = new BinaryDecoder(stream);\r\n                var nullRead = reader.Read(decoder);\r\n                var derived2read = (Derived2)reader.Read(decoder);\r\n                var stringRead = (string)reader.Read(decoder);\r\n                Assert.IsNull(nullRead);\r\n                Assert.AreEqual(derived2read.A, derived2write.A);\r\n                Assert.AreEqual(derived2read.C, derived2write.C);\r\n                Assert.AreEqual(stringRead, ""string value"");\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/test/Reflect/TestUnion.cs,"@@ -0,0 +1,184 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.Collections.Concurrent;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+using System.Collections;
+
+namespace Avro.Test
+{
+
+
+    [TestFixture]
+    public class TestUnion
+    {
+        public class BaseClass
+        {
+            public string A { get; set; }
+        }
+
+        public class Derived1 : BaseClass
+        {
+            public int B { get; set; }
+        }
+
+        public class Derived2 : BaseClass
+        {
+            public double C { get; set; }
+        }
+
+        [TestCase]
+        public void BaseClassTest()
+        {
+            var baseClassSchema = @""
+            [
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied1"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"B"""", """"type"""" : """"int""""}
+                    ]
+                },
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+
+            var schema = Schema.Parse(baseClassSchema);
+            var derived1write = new Derived1() { A = ""derived1"", B = 7 };
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived1), unionSchema[0]);
+            cache.LoadClassCache(typeof(Derived2), unionSchema[1]);
+            var x = schema as RecordSchema;
+
+            var writer = new ReflectWriter<BaseClass>(schema, cache);
+            var reader = new ReflectReader<BaseClass>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived1write, encoder);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived1read = (Derived1)reader.Read(decoder);
+                var derived2read = (Derived2)reader.Read(decoder);
+                Assert.AreEqual(derived1read.A, derived1write.A);
+                Assert.AreEqual(derived1read.B, derived1write.B);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void NullableTest()
+        {
+            var nullableSchema = @""
+            [
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(nullableSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            var writer = new ReflectWriter<Derived2>(schema);
+            var reader = new ReflectReader<Derived2>(schema, schema);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+            }
+        }
+
+        [TestCase]
+        public void HeterogeneousTest()
+        {
+            var heterogeneousSchema = @""
+            [
+                """"string"""",
+                """"null"""",
+                { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+                    [
+                        { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                        { """"name"""" : """"C"""", """"type"""" : """"double""""}
+                    ]
+                },
+
+            ]
+            "";
+            var schema = Schema.Parse(heterogeneousSchema);
+            var derived2write = new Derived2() { A = ""derived2"", C = 3.14 };
+
+            // union types (except for [null, type]) need to be manually registered
+            var unionSchema = schema as UnionSchema;
+            var cache = new ClassCache();
+            cache.LoadClassCache(typeof(Derived2), unionSchema[2]);
+
+            var writer = new ReflectWriter<object>(schema, cache);
+            var reader = new ReflectReader<object>(schema, schema, cache);
+
+            using (var stream = new MemoryStream(256))
+            {
+                var encoder = new BinaryEncoder(stream);
+                writer.Write(derived2write, encoder);
+                writer.Write(""string value"", encoder);
+                stream.Seek(0, SeekOrigin.Begin);
+
+                var decoder = new BinaryDecoder(stream);
+                var derived2read = (Derived2)reader.Read(decoder);
+                var stringRead = (string)reader.Read(decoder);
+                Assert.AreEqual(derived2read.A, derived2write.A);
+                Assert.AreEqual(derived2read.C, derived2write.C);
+                Assert.AreEqual(stringRead, ""string value"");
+            }
+        }
+    }
+","[{'comment': 'Could you add another test that confirms that we throw an exception when you fail to manually register types?\r\n\r\n```suggestion\r\n\r\n        /// <summary>\r\n        /// If you fail to manually register types within a union that has more than one non-null\r\n        /// schema, creating a <see cref=""ReflectWriter{T}""/> throws an exception.\r\n        /// </summary>\r\n        [TestCase]\r\n        public void ThrowsIfClassesNotLoadedTest()\r\n        {\r\n            var schema = Schema.Parse(BaseClassSchema);\r\n            var cache = new ClassCache();\r\n\r\n            Assert.Throws<AvroException>(() => new ReflectWriter<BaseClass>(schema, cache));\r\n        }\r\n```\r\n\r\nThis suggestion reuses the `baseClassSchema` from the `BaseClassTest`, but I broke it out into a `const` in `TestUnion`:\r\n\r\n```c#\r\n        public const string BaseClassSchema = @""\r\n        [\r\n            { """"type"""" : """"record"""", """"name"""" : """"Dervied1"""", """"fields"""" :\r\n                [\r\n                    { """"name"""" : """"A"""", """"type"""" : """"string""""},\r\n                    { """"name"""" : """"B"""", """"type"""" : """"int""""}\r\n                ]\r\n            },\r\n            { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :\r\n                [\r\n                    { """"name"""" : """"A"""", """"type"""" : """"string""""},\r\n                    { """"name"""" : """"C"""", """"type"""" : """"double""""}\r\n                ]\r\n            },\r\n\r\n        ]\r\n        "";\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/main/Reflect/ClassCache.cs,"@@ -254,6 +254,32 @@ public void LoadClassCache(Type objType, Schema s)
                     break;
                 case NamedSchema ns:
                     EnumCache.AddEnumNameMapItem(ns, objType);
+                    break;
+                case UnionSchema us:
+                    if (us.Schemas.Count == 2 && (us.Schemas[0].Tag == Schema.Type.Null || us.Schemas[1].Tag == Schema.Type.Null) && objType.IsClass)
+                    {
+                        // in this case objType will match the non null type in the union
+                        foreach (var o in us.Schemas)
+                        {
+                            if (o.Tag != Schema.Type.Null)
+                            {
+                                LoadClassCache(objType, o);
+                            }
+                        }
+
+                    }
+                    else
+                    {
+                        // check the schema types are registered
+                        foreach (var o in us.Schemas)
+                        {
+                            if (o.Tag == Schema.Type.Record && GetClass(o as RecordSchema) == null)
+                            {
+                                throw new AvroException($""Class for union record type {o.Fullname} is not registered. Create a ClassCache object and call RegisterUnionTypes"");","[{'comment': ""`RegisterUnionTypes` isn't a method in `ClassCache`. Did you mean `LoadClassCache`?"", 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/main/Reflect/README.md,"@@ -4,7 +4,7 @@ This namespace contains classes that implement Avro serialization and deserializ
 
 ## Serialization
 
-The approach starts with the schema and interates both the schema and the dotnet object together in a depth first manner per the specification. Serialization is the same as the Generic serializer except where the serializer encounters:
+The approach starts with the schema and interates both the schema and the dotnet type together in a depth first manner per the specification. Serialization is the same as the Generic serializer except where the serializer encounters:","[{'comment': '```suggestion\r\nThe approach starts with the schema and iterates both the schema and the dotnet type together in a depth first manner per the specification. Serialization is the same as the Generic serializer except where the serializer encounters:\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/main/Reflect/README.md,"@@ -196,3 +196,121 @@ _Example_: ConcurrentQueue
     var reader = new ReflectReader<ConcurrentQueue<ConcurrentQueueRec>>(schema, schema, cache);
 
 ```
+## Unions
+
+All union constructs are supported however record types that are first defined in unions may need manual type registration.
+
+### Automatic Type Registration
+
+Types associated with unions of the form can be automatically registered and no special handling is needed.","[{'comment': '```suggestion\r\nTypes associated with unions of this form can be automatically registered and no special handling is needed.\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/main/Reflect/README.md,"@@ -196,3 +196,121 @@ _Example_: ConcurrentQueue
     var reader = new ReflectReader<ConcurrentQueue<ConcurrentQueueRec>>(schema, schema, cache);
 
 ```
+## Unions
+
+All union constructs are supported however record types that are first defined in unions may need manual type registration.
+
+### Automatic Type Registration
+
+Types associated with unions of the form can be automatically registered and no special handling is needed.
+
+```json
+    [""null"", { ""type"": ""record"", ""name"": ""X""}]
+```
+
+_Example_: 
+
+```csharp
+    public class MyClass
+    {
+        public string A { get; set; }
+        public double C { get; set; }
+    }
+    
+    // ...
+
+    var nullableSchema = @""
+    [
+        """"null"""",
+        { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+            [
+                { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                { """"name"""" : """"C"""", """"type"""" : """"double""""}
+            ]
+        },
+
+    ]
+    "";
+    var schema = Schema.Parse(nullableSchema);
+    var derived2write = new MyClass() { A = ""derived2"", C = 3.14 };
+
+    var writer = new ReflectWriter<MyClass>(schema);
+    var reader = new ReflectReader<MyClass>(schema, schema);
+
+    // etc.
+```
+
+### Manual Registration
+
+Where a record type is defined inside a union and the union does not 
+follow the ""nullable construct"" above the CSharp type and schema need to be manually registered. Registration is done using the ClassCache method LoadClassCache.","[{'comment': '```suggestion\r\nfollow the ""nullable construct"" above, the CSharp type and schema need to be manually registered. Registration is done using the ClassCache method LoadClassCache.\r\n```', 'commenter': 'blachniet'}]"
617,lang/csharp/src/apache/main/Reflect/README.md,"@@ -196,3 +196,121 @@ _Example_: ConcurrentQueue
     var reader = new ReflectReader<ConcurrentQueue<ConcurrentQueueRec>>(schema, schema, cache);
 
 ```
+## Unions
+
+All union constructs are supported however record types that are first defined in unions may need manual type registration.
+
+### Automatic Type Registration
+
+Types associated with unions of the form can be automatically registered and no special handling is needed.
+
+```json
+    [""null"", { ""type"": ""record"", ""name"": ""X""}]
+```
+
+_Example_: 
+
+```csharp
+    public class MyClass
+    {
+        public string A { get; set; }
+        public double C { get; set; }
+    }
+    
+    // ...
+
+    var nullableSchema = @""
+    [
+        """"null"""",
+        { """"type"""" : """"record"""", """"name"""" : """"Dervied2"""", """"fields"""" :
+            [
+                { """"name"""" : """"A"""", """"type"""" : """"string""""},
+                { """"name"""" : """"C"""", """"type"""" : """"double""""}
+            ]
+        },
+
+    ]
+    "";
+    var schema = Schema.Parse(nullableSchema);
+    var derived2write = new MyClass() { A = ""derived2"", C = 3.14 };
+
+    var writer = new ReflectWriter<MyClass>(schema);
+    var reader = new ReflectReader<MyClass>(schema, schema);
+
+    // etc.
+```
+
+### Manual Registration
+
+Where a record type is defined inside a union and the union does not 
+follow the ""nullable construct"" above the CSharp type and schema need to be manually registered. Registration is done using the ClassCache method LoadClassCache.
+
+```csharp
+    cache.LoadClassCache(typeof(MyClass), recordSchema);
+```
+
+Note that the schema used here is schema corresponding to the record schema which will contained within the overall schema. See the example below.","[{'comment': '```suggestion\r\nNote that the `recordSchema` used here is the schema corresponding to the `MyClass` type within the overall union schema. See the example below.\r\n```', 'commenter': 'blachniet'}]"
620,lang/ruby/lib/avro/io.rb,"@@ -579,21 +579,23 @@ def write_map(writers_schema, datum, encoder)
 
       def write_union(writers_schema, datum, encoder)
         index_of_schema = -1
-        found = writers_schema.schemas.
-          find{|e| index_of_schema += 1; found = Schema.validate(e, datum) }
-        unless found  # Because find_index doesn't exist in 1.8.6
-          raise AvroTypeError.new(writers_schema, datum)
+        found = writers_schema.schemas.find do |e|
+          index_of_schema += 1
+          found = Schema.validate(e, datum)","[{'comment': 'Is the assignment here necessary?', 'commenter': 'tjwp'}, {'comment': 'removed', 'commenter': 'mpan-wework'}]"
620,lang/ruby/lib/avro/io.rb,"@@ -579,21 +579,23 @@ def write_map(writers_schema, datum, encoder)
 
       def write_union(writers_schema, datum, encoder)
         index_of_schema = -1
-        found = writers_schema.schemas.
-          find{|e| index_of_schema += 1; found = Schema.validate(e, datum) }
-        unless found  # Because find_index doesn't exist in 1.8.6
-          raise AvroTypeError.new(writers_schema, datum)
+        found = writers_schema.schemas.find do |e|
+          index_of_schema += 1
+          found = Schema.validate(e, datum)
         end
+        raise AvroTypeError.new(writers_schema, datum) unless found # Because find_index doesn't exist in 1.8.6","[{'comment': 'This comment can be dropped. I believe only ruby 2.3 and later are currently supported by avro. ', 'commenter': 'tjwp'}, {'comment': 'comment removed', 'commenter': 'mpan-wework'}]"
620,lang/ruby/lib/avro/ipc.rb,"@@ -63,8 +62,8 @@ class AvroRemoteError < Avro::AvroError; end
   SYSTEM_ERROR_SCHEMA = Avro::Schema.parse('[""string""]')
 
   # protocol cache
-  REMOTE_HASHES = {}
-  REMOTE_PROTOCOLS = {}
+  REMOTE_HASHES = {}.freeze","[{'comment': 'Freezing these is going to cause errors.', 'commenter': 'tjwp'}]"
620,lang/ruby/.rubocop.yml,"@@ -0,0 +1,23 @@
+AllCops:
+  Include:
+    - lib/**/*.rb
+Style/Documentation:
+  Enabled: false
+Style/NegatedIf:
+  Enabled: false
+Metrics/LineLength:
+  Enabled: false
+Metrics/MethodLength:
+  Enabled: false
+Metrics/ClassLength:
+  Enabled: false
+Metrics/AbcSize:
+  Enabled: false
+Metrics/CyclomaticComplexity:
+  Enabled: false
+Metrics/PerceivedComplexity:
+  Enabled: false
+Metrics/ParameterLists:
+  Enabled: false
+Naming/UncommunicativeMethodParamName:
+  Enabled: false","[{'comment': 'How was the list of cops to ignore vs fix determined?', 'commenter': 'tjwp'}, {'comment': '@tjwp \r\n`Style/Documentation` requires doc in comment describing a class\r\n`Style/NegatedIf` prefers `unless condition` to `if !condition`\r\n`Naming/UncommunicativeMethodParamName` disallows name-too-short variables (e.g. `n`) as method param\r\n`Metrics` stuff restrict like max character length of a line, max line length of a method and a class, max number of method parameters, max numbers of assignments, returns and if-else branches within a method\r\n\r\nThese are mostly necessary for neat business logic through `@instance_variable` or method extraction.', 'commenter': 'mpan-wework'}, {'comment': ""I'm okay with the list of cops that have been disabled, provided that we're not being too opinionated about the conventions used in this project. I think it is best to stay close to the rubocop defaults for this repo. Or take this repo's existing conventions and enforce them consistently."", 'commenter': 'tjwp'}]"
620,lang/ruby/lib/avro/io.rb,"@@ -254,40 +256,39 @@ def read(decoder)
 
       def read_data(writers_schema, readers_schema, decoder)
         # schema matching
-        unless self.class.match_schemas(writers_schema, readers_schema)
-          raise SchemaMatchException.new(writers_schema, readers_schema)
-        end
+        raise SchemaMatchException.new(writers_schema, readers_schema) unless self.class.match_schemas(writers_schema, readers_schema)
 
         # schema resolution: reader's schema is a union, writer's
         # schema is not
         if writers_schema.type_sym != :union && readers_schema.type_sym == :union
-          rs = readers_schema.schemas.find{|s|
+          rs = readers_schema.schemas.find do |s|
             self.class.match_schemas(writers_schema, s)
-          }
+          end
           return read_data(writers_schema, rs, decoder) if rs
+
           raise SchemaMatchException.new(writers_schema, readers_schema)
         end
 
         # function dispatch for reading data based on type of writer's
         # schema
         datum = case writers_schema.type_sym
-        when :null;    decoder.read_null
-        when :boolean; decoder.read_boolean
-        when :string;  decoder.read_string
-        when :int;     decoder.read_int
-        when :long;    decoder.read_long
-        when :float;   decoder.read_float
-        when :double;  decoder.read_double
-        when :bytes;   decoder.read_bytes
-        when :fixed;   read_fixed(writers_schema, readers_schema, decoder)
-        when :enum;    read_enum(writers_schema, readers_schema, decoder)
-        when :array;   read_array(writers_schema, readers_schema, decoder)
-        when :map;     read_map(writers_schema, readers_schema, decoder)
-        when :union;   read_union(writers_schema, readers_schema, decoder)
-        when :record, :error, :request;  read_record(writers_schema, readers_schema, decoder)
-        else
-          raise AvroError, ""Cannot read unknown schema type: #{writers_schema.type}""
-        end
+                when :null then    decoder.read_null","[{'comment': 'The use of `then` with a `case` statement is not something that I see often with Ruby!', 'commenter': 'tjwp'}, {'comment': 'this is a preferred for one-line `when`', 'commenter': 'mpan-wework'}]"
620,lang/ruby/lib/avro/logical_types.rb,"@@ -87,7 +87,7 @@ def self.decode(datum)
     def self.type_adapter(type, logical_type)
       return unless logical_type
 
-      TYPES.fetch(type, {}.freeze).fetch(logical_type, Identity)","[{'comment': 'I think the freeze here was okay. This existed prior to your change?', 'commenter': 'tjwp'}, {'comment': 'restored', 'commenter': 'mpan-wework'}]"
620,lang/ruby/lib/avro/schema_validator.rb,"@@ -1,5 +1,3 @@
-# frozen_string_literal: true","[{'comment': 'Was the `frozen_string_literal` comment problematic for this file? I tested with your branch and it looks like the `frozen_string_literal` comment is okay to add here.', 'commenter': 'tjwp'}]"
661,lang/java/avro/src/main/java/org/apache/avro/specific/package.html,"@@ -35,7 +35,7 @@
   the value will be mapped to the object returned by that Conversion. The
   logical type conversions for {@code date}, {@code time-millis}, {@code
   timestamp-millis} and {@code decimal} are pre-defined in the class {@link
-  org.apache.avro.compiler.specific.SpecificCompiler SpecificCompiler}.</li>
+  <a href=""javascript:"">org.apache.avro.compiler.specific.SpecificCompiler SpecificCompiler</a>}.</li>","[{'comment': 'See above.', 'commenter': 'RyanSkraba'}]"
661,lang/java/compiler/src/main/java/org/apache/avro/compiler/schema/SchemaVisitor.java,"@@ -25,31 +25,31 @@
    * Invoked for schemas that do not have ""child"" schemas (like string, int ...)
    * or for a previously encountered schema with children, which will be treated
    * as a terminal. (to avoid circular recursion)
-   * 
+   *
    * @param terminal
-   * @return
+   * @return SchemaVisitorAction","[{'comment': 'I\'d get rid of these `@return` tags (which also gets rid of the warning), instead of returning ""non-documentation""!', 'commenter': 'RyanSkraba'}]"
661,lang/java/mapred/src/main/java/org/apache/avro/mapred/tether/TetherJob.java,"@@ -87,9 +87,9 @@ public static void setExecutable(JobConf job, File executable, List<String> args
   /**
    * Extract from the job configuration file an instance of the TRANSPROTO
    * enumeration to represent the protocol to use for the communication
-   * 
+   *
    * @param job
-   * @return
+   * @return TetheredProcess.Protocol","[{'comment': ""Again, I'd prefer losing a `@return` tags over non-documentation."", 'commenter': 'RyanSkraba'}]"
661,lang/java/avro/src/main/java/org/apache/avro/package.html,"@@ -26,8 +26,8 @@
   org.apache.avro.io.DatumReader} and {@link
   org.apache.avro.io.DatumWriter} implementations.  Generic
   implementations are provided in the {@link org.apache.avro.generic}
-  package.  A {@link org.apache.avro.compiler.specific.SpecificCompiler
-  compiler} can generate specific java classes and interfaces for
+  package.  A {@link <a href=""javascript:"">org.apache.avro.compiler.specific.SpecificCompiler","[{'comment': 'I\'m not sure this is right -- oddly enough, the original actually works in the official site doc: https://avro.apache.org/docs/1.9.1/api/java/org/apache/avro/package-summary.html#package.description\r\n\r\nWhen I built the site myself, the link is now inoperative...\r\n\r\nIf the warning is because of SpecificCompiler is in a different package, but we want to link to it anyway, perhaps a relative HTML link would be the best solution instead of a `{@link}`?\r\n\r\n```<a href=""./compiler/specific/SpecificCompiler.html"">SpecificCompiler</a>```', 'commenter': 'RyanSkraba'}, {'comment': 'Thank you,it has been updated', 'commenter': 'zeshuai007'}]"
661,lang/java/mapred/src/main/java/org/apache/avro/mapred/tether/TetherJob.java,"@@ -87,9 +87,9 @@ public static void setExecutable(JobConf job, File executable, List<String> args
   /**
    * Extract from the job configuration file an instance of the TRANSPROTO
    * enumeration to represent the protocol to use for the communication
-   * 
+   *
    * @param job
-   * @return
+   * @return - Get the currently used protocol","[{'comment': '```suggestion\r\n   * @return Get the currently used protocol\r\n```\r\nVery minor: unnecessary dash', 'commenter': 'RyanSkraba'}]"
702,lang/csharp/src/apache/test/File/FileTests.cs,"@@ -198,6 +199,45 @@ public void TestGenericData(string schemaStr, object[] value, Codec.Type codecTy
             }
         }
 
+        /// <summary>
+        /// This test is a single test case of the previous test but introduce a DeflateStream
+        /// as it is a standard non-seekable Stream that have the same behavior as the
+        /// NetworkStream that should be handled.
+        /// </summary>","[{'comment': 'Use `<see cref=""..."" />` to reference the other method. It\'s possible that another test method is introduced between these two, making the ""previous test"" text invalid. I also made a couple grammatical changes in the suggestion below.\r\n\r\n```\r\n        /// <summary>\r\n        /// This test is a single test case of\r\n        /// <see cref=""TestGenericData(string, object[], Codec.Type)""/> but introduces a\r\n        /// DeflateStream as it is a standard non-seekable Stream that has the same behavior as the\r\n        /// NetworkStream, which we should handle.\r\n        /// </summary>\r\n```', 'commenter': 'blachniet'}]"
702,lang/csharp/src/apache/main/File/DataFileReader.cs,"@@ -245,6 +233,8 @@ public bool PastSync(long position)
         /// <inheritdoc/>
         public long PreviousSync()
         {
+            if (!_stream.CanSeek)
+                throw new AvroException(""Not a valid input stream - must be seekable!"");","[{'comment': 'Throw an Avro**Runtime**Exception here instead.\r\n\r\n```suggestion\r\n                throw new AvroRuntimeException(""Not a valid input stream - must be seekable!"");\r\n```', 'commenter': 'blachniet'}]"
702,lang/csharp/src/apache/test/File/FileTests.cs,"@@ -198,6 +199,45 @@ public void TestGenericData(string schemaStr, object[] value, Codec.Type codecTy
             }
         }
 
+        /// <summary>
+        /// This test is a single test case of the previous test but introduce a DeflateStream
+        /// as it is a standard non-seekable Stream that have the same behavior as the
+        /// NetworkStream that should be handled.
+        /// </summary>
+        [TestCase(""{\""type\"":\""record\"", \""name\"":\""n\"", \""fields\"":"" +
+            ""[{\""name\"":\""f1\"", \""type\"":[\""int\"", \""long\""]}]}"",
+            new object[] { ""f1"", 100L }, Codec.Type.Null)]
+        public void TestNonSeekableStream(string schemaStr, object[] value, Codec.Type codecType)
+        {
+            foreach (var rwFactory in GenericOptions<GenericRecord>())
+            {
+                // Create and write out
+                MemoryStream compressedStream = new MemoryStream();
+                // using here a DeflateStream as it is a standard non-seekable stream, so if it works for this one,
+                // it should also works with any standard non-seekable stream (ie: NetworkStreams)
+                DeflateStream dataFileOutputStream = new DeflateStream(compressedStream, CompressionMode.Compress);
+                using (var writer = rwFactory.CreateWriter(dataFileOutputStream, Schema.Parse(schemaStr), Codec.CreateCodec(codecType)))
+                {
+                    writer.Append(mkRecord(value, Schema.Parse(schemaStr) as RecordSchema));
+                }
+
+                DeflateStream dataFileInputStream = new DeflateStream(new MemoryStream(compressedStream.ToArray()), CompressionMode.Decompress);
+
+                // Read back
+                IList<GenericRecord> readFoos = new List<GenericRecord>();
+                using (IFileReader<GenericRecord> reader = rwFactory.CreateReader(dataFileInputStream, null))
+                {
+                    foreach (GenericRecord foo in reader.NextEntries)
+                    {
+                        readFoos.Add(foo);
+                    }","[{'comment': 'Ensure we throw an exception when calling one of the methods that requires a seekable stream.\r\n\r\n```suggestion\r\n                    }\r\n\r\n                    // These methods are not supported for non-seekable streams.\r\n                    Assert.Throws<AvroRuntimeException>(() => reader.Seek(0));\r\n                    Assert.Throws<AvroRuntimeException>(() => reader.PreviousSync());\r\n```', 'commenter': 'blachniet'}]"
702,lang/csharp/src/apache/test/File/FileTests.cs,"@@ -198,6 +199,45 @@ public void TestGenericData(string schemaStr, object[] value, Codec.Type codecTy
             }
         }
 
+        /// <summary>
+        /// This test is a single test case of the previous test but introduce a DeflateStream
+        /// as it is a standard non-seekable Stream that have the same behavior as the
+        /// NetworkStream that should be handled.
+        /// </summary>
+        [TestCase(""{\""type\"":\""record\"", \""name\"":\""n\"", \""fields\"":"" +
+            ""[{\""name\"":\""f1\"", \""type\"":[\""int\"", \""long\""]}]}"",
+            new object[] { ""f1"", 100L }, Codec.Type.Null)]
+        public void TestNonSeekableStream(string schemaStr, object[] value, Codec.Type codecType)
+        {
+            foreach (var rwFactory in GenericOptions<GenericRecord>())
+            {
+                // Create and write out
+                MemoryStream compressedStream = new MemoryStream();
+                // using here a DeflateStream as it is a standard non-seekable stream, so if it works for this one,
+                // it should also works with any standard non-seekable stream (ie: NetworkStreams)
+                DeflateStream dataFileOutputStream = new DeflateStream(compressedStream, CompressionMode.Compress);
+                using (var writer = rwFactory.CreateWriter(dataFileOutputStream, Schema.Parse(schemaStr), Codec.CreateCodec(codecType)))
+                {
+                    writer.Append(mkRecord(value, Schema.Parse(schemaStr) as RecordSchema));
+                }","[{'comment': 'Ensure we throw an exception when calling `Sync` with a non-seekable stream.\r\n\r\n```suggestion\r\n\r\n                    // The Sync method is not supported for non-seekable streams.\r\n                    Assert.Throws<NotSupportedException>(() => writer.Sync());\r\n                }\r\n```', 'commenter': 'blachniet'}]"
741,lang/java/tools/src/main/java/org/apache/avro/tool/SpecificCompilerTool.java,"@@ -62,23 +62,23 @@ public int run(InputStream in, PrintStream out, PrintStream err, List<String> ar
 
     int arg = 0;
 
-    if (""-encoding"".equals(args.get(arg))) {
+    if (args.contains(""-encoding"")) {","[{'comment': 'I think the checks for ""-encoding"" and ""-templateDir"" are incorrect -- the index `arg` won\'t be positioned correctly to assign the value.\r\n\r\n', 'commenter': 'RyanSkraba'}, {'comment': 'Hi @RyanSkraba you are correct about that and I have made changes accordingly so please do review and test it when you have time.', 'commenter': 'rabi-kumar'}]"
764,share/docker/Dockerfile,"@@ -69,7 +69,7 @@ RUN apt-get -qqy update \
  && rm -rf /var/lib/apt/lists
 
 # Install nodejs 6
-RUN curl -sSL https://deb.nodesource.com/setup_6.x \
+RUN curl -sSL https://deb.nodesource.com/node_10.x \","[{'comment': '```suggestion\r\nRUN curl -sSL https://deb.nodesource.com/setup_10.x \\\r\n```\r\nI think you meant this URL!  Comment to be updated...', 'commenter': 'RyanSkraba'}, {'comment': 'thanks, done', 'commenter': 'iemejia'}]"
773,lang/csharp/src/apache/test/CodGen/CodeGenTest.cs,"@@ -30,7 +30,7 @@ namespace Avro.Test
 
     class CodeGenTest
     {
-#if !NETCOREAPP2_2 // System.CodeDom compilation not supported in .NET Core: https://github.com/dotnet/corefx/issues/12180
+#if !NETCOREAPP3_1 // System.CodeDom compilation not supported in .NET Core: https://github.com/dotnet/corefx/issues/12180","[{'comment': ""These can be changed to just `#if !NETCOREAPP`. That way they don't have to be updated every time the TFM changes."", 'commenter': 'eerhardt'}, {'comment': 'That is correct. I wanted to keep the change to be as similar to the original as possible, however the intent is to differentiate between netcoreapp and not netcoreapp.', 'commenter': 'zcsizmadia'}]"
773,lang/csharp/src/apache/test/Avro.test.csproj,"@@ -17,12 +17,13 @@
 <Project Sdk=""Microsoft.NET.Sdk"">
 
   <PropertyGroup>
-    <TargetFrameworks Condition=""'$(OS)'!='Windows_NT'"">netcoreapp2.2</TargetFrameworks>
-    <TargetFrameworks Condition=""'$(OS)'=='Windows_NT'"">net461;netcoreapp2.2</TargetFrameworks>
+    <TargetFrameworks Condition=""'$(OS)'!='Windows_NT'"">netcoreapp3.1</TargetFrameworks>
+    <TargetFrameworks Condition=""'$(OS)'=='Windows_NT'"">net461;netcoreapp3.1</TargetFrameworks>
     <RootNamespace>Avro.test</RootNamespace>
     <AssemblyName>Avro.test</AssemblyName>
     <GenerateAssemblyInfo>false</GenerateAssemblyInfo>
     <GenerateProgramFile>false</GenerateProgramFile>
+    <OutputType>Exe</OutputType>","[{'comment': 'Why is this necessary?', 'commenter': 'eerhardt'}, {'comment': 'I will double check later today, but IIRC the build failed without it using 3.1.', 'commenter': 'zcsizmadia'}, {'comment': 'It is not needed. I messed up my original for branch, Should I redo the whole PR?', 'commenter': 'zcsizmadia'}]"
773,lang/csharp/src/apache/test/Avro.test.csproj,"@@ -42,7 +43,7 @@
     </PackageReference>
   </ItemGroup>
 
-  <ItemGroup Condition=""'$(TargetFramework)'!='netcoreapp2.2'"">
+  <ItemGroup Condition=""'$(TargetFramework)'!='netcoreapp3.1'"">","[{'comment': ""Which version of **Microsoft.NET.Test.Sdk** do we need to reference for **netcoreapp3.1**? We have another condition check for **netcoreapp2.2** a few lines down, on line 50. Before, the logic was\r\n\r\n```\r\nif netcoreapp2.2\r\n    use v15.3.0\r\nelse\r\n    use v15.6.1\r\n```\r\n\r\nI'm surprised that it's actually getting a reference to **Microsoft.NET.Test.Sdk** when targeting **netcoreapp3.1** right now with the current conditions. I must be missing something."", 'commenter': 'blachniet'}, {'comment': 'It is referencing the 15.6.1 version which is not the latest. The latest Test.Sdk version of 16.4.0 can be used without any netcoreapp version checking', 'commenter': 'zcsizmadia'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -43,9 +43,9 @@ static void Main(string[] args)
                 {
                     if (i + 1 >= args.Length)
                     {
-                        Console.WriteLine(""Missing path to protocol file"");
+                        Console.Error.WriteLine(""Missing path to protocol file"");
                         Usage();
-                        return;
+                        return -1;","[{'comment': ""A return code of 1 is more common for a general error like this. `avro-tools.jar` returns exits with 1 in these scenarios as well. Let's switch all the `-1` returns to `1`."", 'commenter': 'blachniet'}, {'comment': '```suggestion\r\n                        return 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -23,13 +23,13 @@ namespace Avro
 {
     class AvroGen
     {
-        static void Main(string[] args)
+        static int Main(string[] args)
         {
             // Print usage if no arguments provided or help requested
             if (args.Length == 0 || args[0] == ""-h"" || args[0] == ""--help"")
             {
                 Usage();
-                return;
+                return 0;","[{'comment': '```suggestion\r\n                return 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -55,9 +55,9 @@ static void Main(string[] args)
                 {
                     if (i + 1 >= args.Length)
                     {
-                        Console.WriteLine(""Missing path to schema file"");
+                        Console.Error.WriteLine(""Missing path to schema file"");
                         Usage();
-                        return;
+                        return -1;","[{'comment': '```suggestion\r\n                        return 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -67,17 +67,17 @@ static void Main(string[] args)
                 {
                     if (i + 1 >= args.Length)
                     {
-                        Console.WriteLine(""Missing namespace mapping"");
+                        Console.Error.WriteLine(""Missing namespace mapping"");
                         Usage();
-                        return;
+                        return -1;","[{'comment': '```suggestion\r\n                        return 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -67,17 +67,17 @@ static void Main(string[] args)
                 {
                     if (i + 1 >= args.Length)
                     {
-                        Console.WriteLine(""Missing namespace mapping"");
+                        Console.Error.WriteLine(""Missing namespace mapping"");
                         Usage();
-                        return;
+                        return -1;
                     }
 
                     var parts = args[++i].Split(new char[] { ':' }, StringSplitOptions.RemoveEmptyEntries);
                     if (parts.Length != 2)
                     {
-                        Console.WriteLine(""Malformed namespace mapping. Required format is \""avro.namespace:csharp.namespace\"""");
+                        Console.Error.WriteLine(""Malformed namespace mapping. Required format is \""avro.namespace:csharp.namespace\"""");
                         Usage();
-                        return;
+                        return -1;","[{'comment': '```suggestion\r\n                        return 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -88,30 +88,37 @@ static void Main(string[] args)
                 }
                 else
                 {
-                    Console.WriteLine(""Unexpected command line argument: {0}"", args[i]);
+                    Console.Error.WriteLine(""Unexpected command line argument: {0}"", args[i]);
                     Usage();
                 }
             }
 
             // Ensure we got all the command line arguments we need
             bool isValid = true;
+            int rc = 0;
             if (!isProtocol.HasValue || inputFile == null)
             {
-                Console.WriteLine(""Must provide either '-p <protocolfile>' or '-s <schemafile>'"");
+                Console.Error.WriteLine(""Must provide either '-p <protocolfile>' or '-s <schemafile>'"");
                 isValid = false;
             }
             else if (outputDir == null)
             {
-                Console.WriteLine(""Must provide 'outputdir'"");
+                Console.Error.WriteLine(""Must provide 'outputdir'"");
                 isValid = false;
             }
 
+
             if (!isValid)
+            {
                 Usage();
+                rc = -1;","[{'comment': '```suggestion\r\n                rc = 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -147,10 +154,13 @@ static void Usage()
             }
             catch (Exception ex)
             {
-                Console.WriteLine(""Exception occurred. "" + ex.Message);
+                Console.Error.WriteLine(""Exception occurred. "" + ex.Message);
+                return -1;","[{'comment': '```suggestion\r\n                return 1;\r\n```', 'commenter': 'blachniet'}]"
775,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -169,8 +179,11 @@ static void Usage()
             }
             catch (Exception ex)
             {
-                Console.WriteLine(""Exception occurred. "" + ex.Message);
+                Console.Error.WriteLine(""Exception occurred. "" + ex.Message);
+                return -1;","[{'comment': '```suggestion\r\n                return 1;\r\n```', 'commenter': 'blachniet'}]"
792,lang/csharp/src/apache/main/Avro.main.csproj,"@@ -19,7 +19,7 @@
   <Import Project=""../../../common.props"" />
 
   <PropertyGroup>
-    <TargetFrameworks>netstandard2.0</TargetFrameworks>
+    <TargetFrameworks>netstandard2.0;netcoreapp2.1</TargetFrameworks>","[{'comment': 'Could we target **netstandard2.1** instead of **netcoreapp2.1**?\r\n```suggestion\r\n    <TargetFrameworks>netstandard2.0;netstandard2.1</TargetFrameworks>\r\n```', 'commenter': 'blachniet'}, {'comment': ""We can't until #773 is merged. See my comment [here](https://github.com/apache/avro/pull/792#issuecomment-579318452)\r\n\r\n>> The CI is failing:\r\n\r\n> In order to fix it, we would need to install the .NET SDK v3.1 on those CI machines. But I don't know how to do that. So instead, I dropped the netstandard2.1 target. We can easily add it back when the CI machines are updated for the latest .NET SDK.\r\n\r\nAlso see my note in the original comment of the PR:\r\n\r\n> I needed to multi-target to netstandard2.1 in order to take advantage of the new APIs. I also added a target for netcoreapp2.1 because .NET Core 2.1 is still supported, so anyone using this library on 2.1 can take advantage of better performance."", 'commenter': 'eerhardt'}, {'comment': 'FYI - now that #798 is merged, I added the `netstandard2.1` target back. I also left the `netcoreapp2.1` target for the above reasons. Let me know what you think.', 'commenter': 'eerhardt'}]"
792,lang/csharp/src/apache/main/IO/BinaryDecoder.notnetstandard2.0.cs,"@@ -0,0 +1,100 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System;
+using System.Buffers;
+using System.Buffers.Binary;
+using System.Text;
+
+namespace Avro.IO
+{
+    /// <content>
+    /// Contains the netstandard2.1 and netcoreapp2.1 specific functionality for BinaryDecoder.
+    /// </content>
+    public partial class BinaryDecoder
+    {
+        private const int StackallocThreshold = 256;
+
+        /// <summary>
+        /// A float is written as 4 bytes.
+        /// The float is converted into a 32-bit integer using a method equivalent to
+        /// Java's floatToIntBits and then encoded in little-endian format.
+        /// </summary>
+        /// <returns></returns>
+        public float ReadFloat()
+        {
+            Span<byte> buffer = stackalloc byte[4];
+            Read(buffer);
+
+            return BitConverter.Int32BitsToSingle(BinaryPrimitives.ReadInt32LittleEndian(buffer));
+        }
+
+        /// <summary>
+        /// A double is written as 8 bytes.
+        /// The double is converted into a 64-bit integer using a method equivalent to
+        /// Java's doubleToLongBits and then encoded in little-endian format.
+        /// </summary>
+        /// <returns>A double value.</returns>
+        public double ReadDouble()
+        {
+            Span<byte> buffer = stackalloc byte[8];
+            Read(buffer);
+
+            return BitConverter.Int64BitsToDouble(BinaryPrimitives.ReadInt64LittleEndian(buffer));
+        }
+
+        /// <summary>
+        /// Reads a string written by <see cref=""BinaryEncoder.WriteString(string)""/>.
+        /// </summary>
+        /// <returns>String read from the stream.</returns>
+        public string ReadString()
+        {
+            byte[] bufferArray = null;
+
+            int length = ReadInt();
+            Span<byte> buffer = length <= StackallocThreshold ?
+                stackalloc byte[length] :
+                (bufferArray = ArrayPool<byte>.Shared.Rent(length));
+
+            Read(buffer);
+
+            string result = Encoding.UTF8.GetString(buffer);
+
+            if (bufferArray != null)
+            {
+                ArrayPool<byte>.Shared.Return(bufferArray);
+            }
+
+            return result;
+        }
+
+        private void Read(byte[] buffer, int start, int len)
+        {
+            Read(buffer.AsSpan(start, len));
+        }
+
+        private void Read(Span<byte> buffer)
+        {
+            while (!buffer.IsEmpty)
+            {
+                int n = stream.Read(buffer);
+                if (n <= 0) throw new AvroException(""End of stream reached"");
+                buffer = buffer.Slice(n);","[{'comment': ""Do you happen to know if any of our unit tests are currently exercising this code? If not, could we change them (I guess through adding TargetFrameworks?) to do so?\r\n\r\nIf I'm following this logic correctly, `buffer` will always be empty when this method returns. Am I misreading this? I'll try to step into this with the debugger tomorrow when I've got my normal dev environment."", 'commenter': 'blachniet'}, {'comment': ""> Do you happen to know if any of our unit tests are currently exercising this code?\r\n\r\nYes, they are. The tests run for both .NET Framework and on .NET Core:\r\n\r\nhttps://github.com/apache/avro/blob/9bc2c62c6a82dbce260d4cc0277f1d0276063468/lang/csharp/src/apache/test/Avro.test.csproj#L21\r\n\r\n> If I'm following this logic correctly, buffer will always be empty when this method returns. Am I misreading this?\r\n\r\nYou are following it correctly and not misreading it. The `Read` method expects to read `buffer.Length` bytes from the stream, and it loops reading from the stream until the whole buffer is filled.  (Note that the callers `Span` is not updated, so the caller is still pointing to the beginning of the buffer upon return.)"", 'commenter': 'eerhardt'}, {'comment': ""Ah, that makes sense. I clearly haven't studied up on `Span<T>` enough yet. Thank you for explaining this!"", 'commenter': 'blachniet'}]"
807,lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java,"@@ -303,13 +304,24 @@ public void testToStringIsJson() throws JsonParseException, IOException {
     Field stringField = new Field(""string"", Schema.create(Type.STRING), null, null);
     Field enumField = new Field(""enum"", Schema.createEnum(""my_enum"", ""doc"", null, Arrays.asList(""a"", ""b"", ""c"")), null,
         null);
+
+    Schema timeSchema = Schema.create(Type.INT);
+    timeSchema.addProp(""logicalType"", ""time-millis"");
+    Field timeField = new Field(""time"", timeSchema, null, null);
+
+    Schema dateSchema = Schema.create(Type.LONG);","[{'comment': '```suggestion\r\n    Schema dateSchema = LogicalTypes.date().addToSchema(Schema.create(Type.INT));\r\n```\r\nThe date type should wrap an INT, not LONG.', 'commenter': 'RyanSkraba'}]"
807,lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java,"@@ -303,13 +304,24 @@ public void testToStringIsJson() throws JsonParseException, IOException {
     Field stringField = new Field(""string"", Schema.create(Type.STRING), null, null);
     Field enumField = new Field(""enum"", Schema.createEnum(""my_enum"", ""doc"", null, Arrays.asList(""a"", ""b"", ""c"")), null,
         null);
+
+    Schema timeSchema = Schema.create(Type.INT);","[{'comment': '```suggestion\r\n    Schema timeSchema = LogicalTypes.timeMillis().addToSchema(Schema.create(Type.INT));\r\n```\r\nThe standard logical types can be constructed without directly playing with properties!\r\n', 'commenter': 'RyanSkraba'}]"
807,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -21,10 +21,12 @@
 import java.io.IOException;
 import java.nio.ByteBuffer;
 import java.nio.charset.StandardCharsets;
+import java.time.Instant;
 import java.util.AbstractList;
 import java.util.Arrays;
 import java.util.Collection;
 import java.util.Collections;
+import java.util.Date;","[{'comment': ""I don't think any of the logical types generate `java.util.Date` : https://github.com/apache/avro/blob/a2098bd88361b5ff9298c462a2dccafbb0c2c508/lang/java/avro/src/main/java/org/apache/avro/data/TimeConversions.java#L34\r\n\r\nOn the other hand, `LocalDate`, `LocalDateTime`, etc. are possible and not covered!  Perhaps testing for `java.time.Temporal` as a common base class for built in logical time types?"", 'commenter': 'RyanSkraba'}]"
807,lang/java/avro/src/test/java/org/apache/avro/generic/TestGenericData.java,"@@ -303,13 +304,24 @@ public void testToStringIsJson() throws JsonParseException, IOException {
     Field stringField = new Field(""string"", Schema.create(Type.STRING), null, null);
     Field enumField = new Field(""enum"", Schema.createEnum(""my_enum"", ""doc"", null, Arrays.asList(""a"", ""b"", ""c"")), null,
         null);
+
+    Schema timeSchema = Schema.create(Type.INT);
+    timeSchema.addProp(""logicalType"", ""time-millis"");
+    Field timeField = new Field(""time"", timeSchema, null, null);
+
+    Schema dateSchema = Schema.create(Type.LONG);
+    dateSchema.addProp(""logicalType"", ""date"");
+    Field dateField = new Field(""date"", dateSchema, null, null);
+
     Schema schema = Schema.createRecord(""my_record"", ""doc"", ""mytest"", false);
-    schema.setFields(Arrays.asList(stringField, enumField));
+    schema.setFields(Arrays.asList(stringField, enumField, timeField, dateField));
 
     GenericRecord r = new GenericData.Record(schema);
     // \u2013 is EN DASH
     r.put(stringField.name(), ""hello\nthere\""\tyou\u2013}"");
     r.put(enumField.name(), new GenericData.EnumSymbol(enumField.schema(), ""a""));
+    r.put(timeField.name(), Instant.now());","[{'comment': ""I'm not sure this is actually validating something useful...  My reasoning is that `r` is not a valid `GenericRecord` at this point because it would expect integers in these fields.\r\n\r\n```\r\n// Would be false\r\nGenericData.get().validate(r.getSchema(), r);\r\n```\r\n\r\nI'm trying to decide at what point we have to be responsible for ensuring that toString is valid JSON even when the datum is bad -- we could put any Object that is not handled by your change and get badly delimited JSON.  What do you think?  Would a test case on a specific record make more sense?"", 'commenter': 'RyanSkraba'}]"
820,lang/csharp/src/apache/main/Generic/GenericEnum.cs,"@@ -37,8 +37,15 @@ public class GenericEnum
             get { return value; }
             set
             {
-                if (! Schema.Contains(value)) throw new AvroException(""Unknown value for enum: "" + value + ""("" + Schema + "")"");
-                this.value = value;
+                if (!string.IsNullOrEmpty(Schema.Default))
+                {
+                    this.value = Schema.Contains(value) ? value : Schema.Default;
+                }
+                else
+                {
+                    if (! Schema.Contains(value)) throw new AvroException(""Unknown value for enum: "" + value + ""("" + Schema + "")"");
+                    this.value = value;
+                }","[{'comment': 'We could change up the order of these checks to simplify the code a little. We would only have to check whether or not `Schema.Default` is null/empty when the schema doesn\'t contain the given value, which is something we always have to check.\r\n\r\n```c#\r\nif (!Schema.Contains(value))\r\n{\r\n    if (!string.IsNullOrEmpty(Schema.Default))\r\n    {\r\n        this.value = Schema.Default;\r\n    }\r\n    else\r\n    {\r\n        throw new AvroException(""Unknown value for enum: "" + value + ""("" + Schema + "")"");\r\n    }\r\n}\r\nelse\r\n{\r\n    this.value = value;\r\n}\r\n```', 'commenter': 'blachniet'}]"
820,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -32,6 +32,11 @@ public class EnumSchema : NamedSchema
         /// </summary>
         public IList<string> Symbols { get; private set;  }
 
+        /// <summary>
+        /// The default token to use when deserializing an enum when the provided token is not found
+        /// </summary>
+        public string Default {get; private set; }","[{'comment': 'nit: space before `get`', 'commenter': 'mhowlett'}]"
820,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -117,6 +126,11 @@ internal static EnumSchema NewInstance(JToken jtok, PropertyMap props, SchemaNam
             foreach (string s in this.Symbols)
                 writer.WriteValue(s);
             writer.WriteEndArray();
+            if(Default != null) ","[{'comment': 'nit: space between `if` and `(`', 'commenter': 'mhowlett'}]"
820,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -92,14 +97,18 @@ internal static EnumSchema NewInstance(JToken jtok, PropertyMap props, SchemaNam
         /// <param name=""props"">custom properties on this schema</param>
         /// <param name=""names"">list of named schema already read</param>
         /// <param name=""doc"">documentation for this named schema</param>
+        /// <param name=""defaultToken"">default token</param>
         private EnumSchema(SchemaName name, IList<SchemaName> aliases, List<string> symbols,
                             IDictionary<String, int> symbolMap, PropertyMap props, SchemaNames names,
-                            string doc)
+                            string doc, string defaultToken)","[{'comment': 'the nomenclature used elsewhere is ""symbol"", not ""token"".', 'commenter': 'mhowlett'}]"
820,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -92,14 +97,18 @@ internal static EnumSchema NewInstance(JToken jtok, PropertyMap props, SchemaNam
         /// <param name=""props"">custom properties on this schema</param>
         /// <param name=""names"">list of named schema already read</param>
         /// <param name=""doc"">documentation for this named schema</param>
+        /// <param name=""defaultToken"">default token</param>
         private EnumSchema(SchemaName name, IList<SchemaName> aliases, List<string> symbols,
                             IDictionary<String, int> symbolMap, PropertyMap props, SchemaNames names,
-                            string doc)
+                            string doc, string defaultToken)
                             : base(Type.Enumeration, name, aliases, props, names, doc)
         {
             if (null == name.Name) throw new SchemaParseException(""name cannot be null for enum schema."");
             this.Symbols = symbols;
             this.symbolMap = symbolMap;
+
+            if (defaultToken != null && !symbolMap.ContainsKey(defaultToken)) throw new SchemaParseException($""Default symbol: {defaultToken} not found in symbols"");","[{'comment': ""nit: line's getting long, would put throw on new line, and consistent with rest of codebase, though not the case immediately above ... "", 'commenter': 'mhowlett'}]"
820,lang/csharp/src/apache/main/Generic/GenericEnum.cs,"@@ -37,8 +37,15 @@ public class GenericEnum
             get { return value; }
             set
             {
-                if (! Schema.Contains(value)) throw new AvroException(""Unknown value for enum: "" + value + ""("" + Schema + "")"");
-                this.value = value;
+                if (!string.IsNullOrEmpty(Schema.Default))
+                {
+                    this.value = Schema.Contains(value) ? value : Schema.Default;
+                }
+                else
+                {
+                    if (! Schema.Contains(value)) throw new AvroException(""Unknown value for enum: "" + value + ""("" + Schema + "")"");","[{'comment': 'nit: might as well get rid of the space after the ""!"" to match the convention in the rest of the code.', 'commenter': 'mhowlett'}]"
822,lang/csharp/src/apache/main/CodeGen/CodeGen.cs,"@@ -777,7 +777,15 @@ internal static string getType(Schema schema, bool nullible, ref bool nullibleEn
                     var logicalSchema = schema as LogicalSchema;
                     if (null == logicalSchema)
                         throw new CodeGenException(""Unable to cast schema into a logical schema"");
-                    return logicalSchema.LogicalType.GetCSharpType(nullible).ToString();
+                    var csharpType = logicalSchema.LogicalType.GetCSharpType(nullible);
+                    if (csharpType.IsGenericType && csharpType.GetGenericTypeDefinition() == typeof(Nullable<>))
+                    {
+                        return $""Nullable<{csharpType.GetGenericArguments()[0]}>"";","[{'comment': 'In all the instances where we return nullable above, we use the fully qualified name. Could you include the fully-qualified name here for the sake of consistency?\r\n```suggestion\r\n                        return $""System.Nullable<{csharpType.GetGenericArguments()[0]}>"";\r\n```', 'commenter': 'blachniet'}]"
840,lang/ruby/lib/avro/logical_types.rb,"@@ -61,6 +61,16 @@ def self.decode(int)
       end
     end
 
+    module Decimal","[{'comment': 'For consistency here, I think this module should be called `BytesDecimal`.', 'commenter': 'tjwp'}]"
842,lang/java/avro/src/test/java/org/apache/avro/reflect/TestReflectData.java,"@@ -90,4 +99,88 @@ public void testGenericProtocol() {
     private String bar;
     private int baz;
   }
+
+  protected static class DefaultReflector extends ReflectData {
+    private static final DefaultReflector INSTANCE = new DefaultReflector();
+
+    /** Return the singleton instance. */
+    public static DefaultReflector get() {
+      return INSTANCE;
+    }
+
+    private final Map<String, Object> defaultValues = new ConcurrentHashMap<>();
+
+    protected Object getOrCreateDefaultValue(String className) {
+      return this.defaultValues.computeIfAbsent(className, ignored -> {
+        try {
+          Class<?> aClass = Class.forName(className);
+          Constructor constructor = aClass.getDeclaredConstructor();
+          constructor.setAccessible(true);
+          return constructor.newInstance();
+        } catch (InstantiationException | IllegalAccessException | ClassNotFoundException | NoSuchMethodException
+            | InvocationTargetException e) {
+          e.printStackTrace();
+        }
+        return null;
+      });
+    }
+
+    @Override
+    protected Object createSchemaDefaultValue(Type type, Field field, Schema fieldSchema) {
+      String className = ((Class) type).getName();
+      field.setAccessible(true);
+      Object def = null;
+
+      try {
+        Object value = getOrCreateDefaultValue(className);
+        if (value != null) {
+          def = field.get(value);
+        }
+      } catch (IllegalAccessException e) {
+        e.printStackTrace();
+      }
+
+      if (def == null) {
+        def = super.createSchemaDefaultValue(type, field, fieldSchema);
+      }
+
+      return def;
+    }
+  }
+
+  static class User {
+    public String first = ""Avro"";
+    public String last = ""Apache"";
+  }
+
+  static class Meta {
+    public int f1 = 55;
+    public String f2 = ""a-string"";
+    public List<String> f3 = Arrays.asList(""one"", ""two"", ""three"");
+    // public User usr = new User();","[{'comment': '@cutting I commented out this field due to an issue with JacksonUtils as described here https://issues.apache.org/jira/browse/AVRO-2775', 'commenter': 'anhldbk'}]"
842,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -110,14 +112,96 @@ public static ReflectData get() {
   }
 
   /**
-   * Cause a class to be treated as though it had an {@link Stringable}
-   ** annotation.
+   * Cause a class to be treated as though it had an {@link Stringable} *
+   * annotation.
    */
   public ReflectData addStringable(Class c) {
     stringableClasses.add(c);
     return this;
   }
 
+  /**
+   * If this flag is set to true, default values for fields will be assigned
+   * dynamically using Java reflections. Let's call this feature `default
+   * reflection`. Initially this feature is disabled
+   */
+  private boolean defaultGenerated = false;
+
+  /**
+   * Enable or disable `default reflection`
+   *
+   * @param enabled set to `true` to enable the feature. This feature is disabled
+   *                by default
+   * @return The current instance
+   */
+  public ReflectData setDefaultsGenerated(boolean enabled) {
+    this.defaultGenerated = enabled;
+    return this;
+  }
+
+  private final Map<String, Object> defaultValues = new WeakHashMap<>();","[{'comment': ""This needs to be <Class,Object> so that defaults are GC'd when a class is.  Also, Class should probably be used instead of String for classes in other code below."", 'commenter': 'cutting'}, {'comment': '@cutting Agree. One small question: can I use `Map<Type, Object>` instead?', 'commenter': 'anhldbk'}, {'comment': 'Sure, that seems reasonable.', 'commenter': 'cutting'}, {'comment': 'Fine for me :D ', 'commenter': 'anhldbk'}]"
842,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -110,14 +112,96 @@ public static ReflectData get() {
   }
 
   /**
-   * Cause a class to be treated as though it had an {@link Stringable}
-   ** annotation.
+   * Cause a class to be treated as though it had an {@link Stringable} *
+   * annotation.
    */
   public ReflectData addStringable(Class c) {
     stringableClasses.add(c);
     return this;
   }
 
+  /**
+   * If this flag is set to true, default values for fields will be assigned
+   * dynamically using Java reflections. Let's call this feature `default","[{'comment': 'We might say a bit more about how this works, that, when enabled, defaults are the field values of an instance created with a no-arg constructor.', 'commenter': 'cutting'}, {'comment': 'I fixed', 'commenter': 'anhldbk'}]"
842,lang/java/avro/src/main/java/org/apache/avro/reflect/ReflectData.java,"@@ -500,6 +582,37 @@ static boolean isNonStringMapSchema(Schema s) {
     return false;
   }
 
+  /**
+   * Get default value for a schema field. Derived classes can override this
+   * method to provide values based on object instantiation
+   *
+   * @param type        Type
+   * @param field       Field
+   * @param fieldSchema Schema of the field
+   * @return The default value
+   */
+  protected Object createSchemaDefaultValue(Type type, Field field, Schema fieldSchema) {
+    Object defaultValue;
+    if (defaultGenerated) {
+      defaultValue = getOrCreateDefaultValue(type, field);
+      if (defaultValue != null) {
+        return defaultValue;","[{'comment': 'Should we instead return deepCopy(fieldSchema, defaultValue)?', 'commenter': 'cutting'}, {'comment': 'Yep, we should.', 'commenter': 'anhldbk'}]"
844,lang/java/compiler/src/main/java/org/apache/avro/compiler/specific/SpecificCompiler.java,"@@ -92,6 +93,16 @@
    */
   protected static final int MAX_FIELD_PARAMETER_UNIT_COUNT = JVM_METHOD_ARG_LIMIT - 1;
 
+  /*
+   * Java reserved words to scape
+   */
+  private List<String> javaReservedWords = Arrays.asList(""abstract"", ""assert"", ""boolean"", ""break"", ""byte"", ""case"",","[{'comment': 'This already exists here: https://github.com/apache/avro/blob/da132659c4676ede53aabb66ebd943b8232a18f3/lang/java/avro/src/main/java/org/apache/avro/specific/SpecificData.java#L83 - can you reuse it?  ', 'commenter': 'RyanSkraba'}]"
844,lang/java/compiler/src/main/java/org/apache/avro/compiler/specific/SpecificCompiler.java,"@@ -1204,4 +1215,17 @@ public static void main(String[] args) throws Exception {
   public void setOutputCharacterEncoding(String outputCharacterEncoding) {
     this.outputCharacterEncoding = outputCharacterEncoding;
   }
+
+  public String escapeNamespace(String namespace) {","[{'comment': ""Quick question on this choice!  Is there any reason the namespace isn't mangled the same way as the name?   It looks like a schema full name `org.apache.avro.public.public` will be mangled into `org/apache/avro/_public/public$.java` here.\r\n\r\nIn my opinion it would be less confusing if they were mangled the same way!\r\n\r\nWhat do you think of using the existing `mangle(..)` method for both namespaces and names instead of having two methods?"", 'commenter': 'RyanSkraba'}]"
844,lang/java/compiler/src/main/velocity/org/apache/avro/compiler/specific/templates/java/classic/enum.vm,"@@ -15,8 +15,8 @@
 ## See the License for the specific language governing permissions and
 ## limitations under the License.
 ##
-#if ($schema.getNamespace())
-package $schema.getNamespace();
+#if ($this.escapeNamespace($this.escapeNamespace($this.escapeNamespace($schema.getNamespace()))))","[{'comment': '`escapeNamespace` is called three times!\r\n\r\nIn my opinion, you can probably omit `escapeNamespace` entirely in the *if* part of the template for readability.', 'commenter': 'RyanSkraba'}]"
884,lang/java/avro/src/main/java/org/apache/avro/Conversions.java,"@@ -117,6 +115,25 @@ public GenericFixed toFixed(BigDecimal value, Schema schema, LogicalType type) {
 
       return new GenericData.Fixed(schema, bytes);
     }
+
+    private static BigDecimal validate(LogicalTypes.Decimal decimal, BigDecimal value) {
+      int scale = decimal.getScale();
+      int valueScale = value.scale();
+      if (valueScale > scale) {
+        throw new AvroTypeException(""Cannot encode decimal with scale "" + valueScale + "" as scale "" + scale);
+      } else if (valueScale < scale) {
+        value = value.setScale(scale, ROUND_UNNECESSARY);","[{'comment': 'this would be a safe operation, but wondering if there is any best-practice to set behind a flag that can be enabled/disabled?', 'commenter': 'maccamlc'}]"
884,lang/java/avro/src/main/java/org/apache/avro/Conversions.java,"@@ -117,6 +115,25 @@ public GenericFixed toFixed(BigDecimal value, Schema schema, LogicalType type) {
 
       return new GenericData.Fixed(schema, bytes);
     }
+
+    private static BigDecimal validate(LogicalTypes.Decimal decimal, BigDecimal value) {
+      int scale = decimal.getScale();
+      int valueScale = value.scale();
+      if (valueScale > scale) {
+        throw new AvroTypeException(""Cannot encode decimal with scale "" + valueScale + "" as scale "" + scale);
+      } else if (valueScale < scale) {
+        value = value.setScale(scale, ROUND_UNNECESSARY);
+      }
+
+      int precision = decimal.getPrecision();
+      int valuePrecision = value.precision();","[{'comment': 'Have noticed in my testing, that a fixed 12 size type, can have a max precision of 28. However currently there are some 29 precision decimals that would fit inside the 12 byte array, and therefore are currently permitted without the offset error I mentioned in issue description.\r\n\r\nThis change would mean that 29 precision decimal would now error. \r\n\r\nMy thinking is that the fixed type config should match the actual value, and therefore checking precision makes sense. But happy to understand any counter-arguments', 'commenter': 'maccamlc'}]"
910,lang/java/pom.xml,"@@ -361,6 +361,7 @@
                       <pluginExecutionFilter>
                         <groupId>com.diffplug.spotless</groupId>
                         <artifactId>spotless-maven-plugin</artifactId>
+                        <version>${spotless-maven-plugin.version}</version>","[{'comment': ""```suggestion\r\n                        <versionRange>${spotless-maven-plugin.version}</versionRange>\r\n```\r\nHello!  Good catch, but I couldn't get it to work with `<version>`, did you mean `<versionRange>` ?"", 'commenter': 'RyanSkraba'}, {'comment': 'Truth be told, the current version in trunk builds fine from the command line, but my Eclipse is unhappy about it, and when Eclipse is unhappy, I am unhappy. :)\r\n\r\nCheck out the error message again:\r\n```\r\nMissing parameter for pluginExecutionFilter. groupId, artifactId, versionRange and goals must be specificed, but found: groupId = \'com.diffplug.spotless\'\r\nartifactId = \'spotless-maven-plugin\'\r\nversionRange = \'null\'\r\ngoals = \'[check]\'\r\n```\r\n\r\nIt requires 5 fields, but only 4 are listed in the ""but found"" section.  The missing one is `artifiactId`.  \'null\' perhaps could be a valid value for `versionRange `', 'commenter': 'belugabehr'}, {'comment': 'Also note that CI does work for JDK8 and JDK 11, so it is building with the current change.', 'commenter': 'belugabehr'}, {'comment': ""I'm glad someone is looking out for working in Eclipse :D  Happy devs make happy software!\r\n\r\nI don't use Eclipse as often, so I tested with Eclipse 2020-03 and still couldn't successfully build after your change.  \r\n\r\nI just did **File** / **Import** / **Existing Maven Projects** and pointed to the top-level `pom.xml` and got a bunch of these errors:\r\n\r\n`Cannot parse lifecycle mapping metadata for maven project MavenProject: org.apache.avro:avro-parent:1.11.0-SNAPSHOT @ /home/rskraba/working/github/avro/lang/java/pom.xml Cause: Unrecognised tag: 'version' (position: START_TAG seen ...</artifactId>\\n        <version>... @8:18) \tpom.xml\t/avro-ipc-netty\tline 1`\r\n\r\nIt works if the XML tag added to the pom is `<versionRange>`, which is why I asked.  Am I doing something wrong while checking this?"", 'commenter': 'RyanSkraba'}, {'comment': 'Hey @RyanSkraba ,\r\n\r\nReally appreciate the help on this.  It\'s quite annoying.\r\n\r\nI just pulled down the latest changes to the master branch and did ""Import [Maven] Project"" and when it\'s doing it\'s initial build, I get this error message.  Nothing special to it.  May be a Eclipse version issue. \r\n\r\nif you add both a `<version>` and `<versionRange>` tag, does that build?  That may be the resolution to make all versions happy.', 'commenter': 'belugabehr'}, {'comment': 'I stuck the `version` tag in here, deleted the project, imported it again, and it came up without the annoying error.', 'commenter': 'belugabehr'}, {'comment': 'I suggest just pushing this change to master, and if someone is using a different version of eclipse, we can deal with that in a new Jira/PR', 'commenter': 'belugabehr'}, {'comment': ""![image](https://user-images.githubusercontent.com/7744819/84166446-31b40b80-aa75-11ea-9b39-0e64752441f3.png)\r\n\r\nI still have the same error on Eclipse 2019-06 -- if `<version>` (or both) is present, the Maven Project Build Lifecycle Mapping fails!  This is Fedora 32 by the way.\r\n\r\nIn any case, the maven import to eclipse is definitely broken as it is, and slightly less broken (even for me!) after the PR.  Let's merge it, or get someone else to try?  Either way, I have more confidence in your setup than mine!"", 'commenter': 'RyanSkraba'}]"
981,lang/csharp/common.props,"@@ -45,6 +45,7 @@
 
   <ItemGroup>
     <None Include=""$(MSBuildThisFileDirectory)\LICENSE"" Pack=""true"" Visible=""false"" PackagePath=""""/>
+    <None Include=""$(MSBuildThisFileDirectory)\icon.png"" Pack=""true"" PackagePath=""""/>","[{'comment': 'Could we use the `avro-logo.png` in [avro/doc/src/resources/images/](https://github.com/apache/avro/tree/master/doc/src/resources/images) rather than adding another copy of it here?', 'commenter': 'blachniet'}, {'comment': 'My bad :) I checked in the roots but not everywhere I will make the changes to use the existing image.', 'commenter': 'zcsizmadia'}, {'comment': 'Done.', 'commenter': 'zcsizmadia'}]"
981,lang/csharp/src/apache/main/Generic/GenericRecord.cs,"@@ -239,7 +239,7 @@ public override string ToString()
                 sb.Append(contents[field.Pos]);
                 sb.Append("", "");
             }
-            sb.Append(""}"");
+            sb.Append('}');","[{'comment': 'Is this change necessary?', 'commenter': 'blachniet'}, {'comment': 'The latest msbuild 16.8 has many new warnings (which are mostly seful/valid). The compiler was complaining that StringBuilder.Append(char) should be used if the string arg is a single character. It is more efficient I guess, sinve only a char has to be passed on the stack to the function. There were many Append(string with 1 char) calls, and all of them caused a warning-> error since all warnings are treated as errors.', 'commenter': 'zcsizmadia'}, {'comment': ""```\r\nerror CA1834: Use 'StringBuilder.Append(char)' instead of 'StringBuilder.Append(string)' when the input is a constant unit string\r\n```"", 'commenter': 'zcsizmadia'}, {'comment': 'Ah, that makes sense. Thanks 👍 ', 'commenter': 'blachniet'}]"
981,lang/csharp/src/apache/test/Avro.test.csproj,"@@ -17,8 +17,8 @@
 <Project Sdk=""Microsoft.NET.Sdk"">
 
   <PropertyGroup>
-    <TargetFrameworks Condition=""'$(OS)'!='Windows_NT'"">netcoreapp3.1</TargetFrameworks>
-    <TargetFrameworks Condition=""'$(OS)'=='Windows_NT'"">net461;netcoreapp3.1</TargetFrameworks>
+    <TargetFrameworks Condition=""'$(OS)'!='Windows_NT'"">net5.0</TargetFrameworks>
+    <TargetFrameworks Condition=""'$(OS)'=='Windows_NT'"">net461;net5.0</TargetFrameworks>","[{'comment': 'It may be good for us to continue testing against .NET Core 3.1, just in case there was some compatibility issue between the two.\r\n\r\n```suggestion\r\n    <TargetFrameworks Condition=""\'$(OS)\'!=\'Windows_NT\'"">netcoreapp3.1;net5.0</TargetFrameworks>\r\n    <TargetFrameworks Condition=""\'$(OS)\'==\'Windows_NT\'"">net461;netcoreapp3.1;net5.0</TargetFrameworks>\r\n```', 'commenter': 'blachniet'}, {'comment': '> I compiled the following table of updated dependencies in this PR. We should probably list these out in the commit message and/or Jira issue.\r\n> \r\n> Package\tOld\tNew\r\n> Microsoft.CodeAnalysis.FxCopAnalyzers\t2.9.8\t3.3.1\r\n> Newtonsoft.Json\t10.0.3\t12.0.3\r\n> System.CodeDom\t4.4.0\t5.0.0\r\n> System.Reflection.Emit.ILGeneration\t4.3.0\t4.7.0\r\n> System.Reflection.Emit.Lightweight\t4.3.0\t4.7.0\r\n> Microsoft.Build.Framework\t15.6.82\t16.8.0\r\n> Microsoft.Build.Utilities.Core\t15.6.82\t16.8.0\r\n> nunit3testadapter\t3.16.1\t3.17.0\r\n> NUnit.ConsoleRunner\t3.10.0\t3.11.1\r\n> Microsoft.NET.Test.Sdk\t16.4.0\t16.8.0\r\n\r\nUsually what I do in .net projects, I add a Versions.prtops file int h eroot and all csproj files include it, just like the Common.props. This file only have PACKAGENAMEVersion defines in them. e.g. ""NewtonsoftJsonVersion"" = ""12.0.3"". Every csproj in the source tree will use only PACKAGENAMEVersion defines in the PackageReference, so the version ""upgrade"" is clean and simple, only change in one place.', 'commenter': 'zcsizmadia'}, {'comment': '> It may be good for us to continue testing against .NET Core 3.1, just in case there was some compatibility issue between the two.\r\n\r\nGood catch. Now thinking about this. I think it should be netcoreapp2.1 added to it (or 2.1 and 3.1). So here is my logic, let me know if I miss or misunderstand something.\r\n\r\nAvro.main is compiled for netstandard2.0, netstandard2.1 and netcoreapp2.1. Netstandard2.1 and netcoreapp2.1 (which is btw is very much like netstandard2.1, without having netstandard2.1 support). There is no other framework in Avro.main, since MS recommends to add netcoreapp or other frameweorks only if the library is really compiled with some specific framweork feature/API (using ifdef). SO we are good there.\r\n\r\nWhen Avro.test is tested, all frameworks will be tested in the TargetFramworks list (if no --framework is specified). \r\nnetf461 will use netstandard2.0 so netstandard2.0 version of Avro.main is tested.\r\nnetcoreapp2.1 fw of Avro.test would be linked against the netcoreapp2.1 version of Avro.main since that specific fw exists in the nuget package and Avro.main.\r\nnetcoreapp3.1 or net5.0 will link against netstandard2.1, since both of them support it, and msbuild will be pick the most appropiate and (best) choice of matching fw.\r\n\r\nHonsetly, since the test is very fast, I would add all supported frtameworks to Avro.test. net461,netcoreapp2.1, netcoreepp3.1 and net5.0 (it might test netstandard2.1 2x.).\r\n', 'commenter': 'zcsizmadia'}, {'comment': ""Wow, that's great! Yes, I  agree that we should just run all the supported frameworks in Avro.test (net461, netcoreapp2.1, netcoreapp3.1 and net5.0) for the sake of simplicity and since the tests are so quick."", 'commenter': 'blachniet'}]"
981,lang/csharp/src/apache/test/Reflect/TestFromAvroProject.cs,"@@ -189,7 +189,8 @@ public Z SerializeDeserialize(Z z)
             catch (Exception ex)
             {
                 Console.WriteLine(ex.ToString());
-                throw ex;
+                // Note: Re-throwing caught exception changes stack information
+                throw;","[{'comment': 'Great catch 😄 ! I think you can safely remove the comment here.\r\n```suggestion\r\n                throw;\r\n```', 'commenter': 'blachniet'}, {'comment': 'Will do :) I ran into probl;ems when I was rethrowing with ex, and my call stack was very misleading ;)', 'commenter': 'zcsizmadia'}, {'comment': 'Done.', 'commenter': 'zcsizmadia'}, {'comment': 'That is great that MS added the warning in this case. \r\n```\r\nerror CA2200: Re-throwing caught exception changes stack information\r\n```', 'commenter': 'zcsizmadia'}]"
981,lang/csharp/src/apache/main/Schema/SchemaNormalization.cs,"@@ -157,7 +157,7 @@ private static StringBuilder Build(IDictionary<string, string> env, Schema s, St
                     {
                         if (!firstTime)
                         {
-                            o.Append("","");
+                            o.Append(',');","[{'comment': 'Why all the changes from double to single quotes? Is this necessary? Was there a warning or code hint that was suggesting this?', 'commenter': 'blachniet'}, {'comment': ""```\r\nerror CA1834: Use 'StringBuilder.Append(char)' instead of 'StringBuilder.Append(string)' when the input is a constant unit string\r\n```"", 'commenter': 'zcsizmadia'}]"
981,lang/csharp/src/apache/main/Schema/SchemaName.cs,"@@ -64,7 +64,7 @@ public SchemaName(String name, String space, String encspace)
                 this.EncSpace = encspace;   // need to save enclosing namespace for anonymous types, so named types within the anonymous type can be resolved
             }
 #pragma warning disable CA1307 // Specify StringComparison
-            else if (name.IndexOf('.') == -1)
+            else if (!name.Contains("".""))","[{'comment': 'Just out of curiosity, did this come up in a code hint or warning?', 'commenter': 'blachniet'}, {'comment': 'This was another msbuild 16.8 warning/error. Use Contains instead of cmparing IndexOf() to -1, to make the code ""more readable"". It is kinda cool how many new warnings they introduced with 16.8 msbuild/net 5', 'commenter': 'zcsizmadia'}, {'comment': ""```\r\nerror CA2249: Use 'string.Contains' instead of 'string.IndexOf' to improve readability\r\n```"", 'commenter': 'zcsizmadia'}, {'comment': 'I  think I added some description to the actual commit message when those files were checked in, however those are kinda lost when you are going through the diff', 'commenter': 'zcsizmadia'}]"
981,lang/csharp/common.props,"@@ -45,6 +45,7 @@
 
   <ItemGroup>
     <None Include=""$(MSBuildThisFileDirectory)\LICENSE"" Pack=""true"" Visible=""false"" PackagePath=""""/>
+    <None Include=""$(MSBuildThisFileDirectory)\..\..\doc\src\resources\images\avro-logo.png"" Pack=""true"" PackagePath=""""/>","[{'comment': 'Could you set `Visible=""false""` so this file doesn\'t show up in the file tree in Visual Studio (like we did with the `LICENSE` file above)?\r\n```suggestion\r\n    <None Include=""$(MSBuildThisFileDirectory)\\..\\..\\doc\\src\\resources\\images\\avro-logo.png"" Pack=""true"" Visible=""false"" PackagePath=""""/>\r\n```\r\n![Screen Shot 2020-11-17 at 9 34 47 PM](https://user-images.githubusercontent.com/785131/99475579-d4be5a80-291c-11eb-87ba-a17ebb1320fe.png)\r\n', 'commenter': 'blachniet'}, {'comment': 'Actually, @RyanSkraba is tackling the logo issue in #1006/([AVRO-2980](https://issues.apache.org/jira/browse/AVRO-2980)).', 'commenter': 'blachniet'}, {'comment': 'Done', 'commenter': 'zcsizmadia'}, {'comment': ""Thanks!  It looks like this change is necessary to build the 1.10.1 release artifacts -- but I managed to cherry-pick your commits into https://github.com/apache/avro/pull/1006, so it should be easy to rebase once they're merged!\r\n\r\n(At least, I think the cherry-pick origin info survives the merge-squash... I know your authorship does!)\r\n\r\nIn any case, thanks for the help.  Especially thanks for the fine-grained and detailed commits :+1: "", 'commenter': 'RyanSkraba'}]"
981,lang/csharp/versions.props,"@@ -0,0 +1,33 @@
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the ""License""); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       https://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an ""AS IS"" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+<Project>
+  <PropertyGroup Label=""Package Versions"">
+    <MicrosoftBuildFrameworkVersion>16.8.0</MicrosoftBuildFrameworkVersion>
+    <MicrosoftBuildUtilitiesCoreVersion>16.8.0</MicrosoftBuildUtilitiesCoreVersion>
+    <MicrosoftCodeAnalysisFxCopAnalyzersVersion>3.3.1</MicrosoftCodeAnalysisFxCopAnalyzersVersion>
+    <MicrosoftNETTestSdkVersion>16.8.0</MicrosoftNETTestSdkVersion>
+    <NewtonsoftJsonVersion>12.0.3</NewtonsoftJsonVersion>
+    <NUnitVersion>3.12.0</NUnitVersion>
+    <NUnitConsoleRunnerVersion>3.11.1</NUnitConsoleRunnerVersion>
+    <NUnit3TestAdapterVersion>3.17.0</NUnit3TestAdapterVersion>
+    <StyleCopAnalyzersVersion>1.1.118</StyleCopAnalyzersVersion>
+    <SystemCodeDomVersion>5.0.0</SystemCodeDomVersion>
+    <SystemReflectionVersion>4.3.0</SystemReflectionVersion>
+    <SystemReflectionEmitILGenerationVersion>4.7.0</SystemReflectionEmitILGenerationVersion>
+    <SystemReflectionEmitLightweightVersion>4.7.0</SystemReflectionEmitLightweightVersion>
+  </PropertyGroup>
+</Project>","[{'comment': ""👍  I like the idea of the `versions.props` file. I also like that you broke this out from the `common.props` since some projects need to reference things in `versions.props` but not `common.props.\r\n\r\nWe require users of the libraries to include the following dependencies:\r\n\r\n- Avro.main\r\n  - Newtonsoft.Json\r\n  - System.CodeDom\r\n  - System.Reflection\r\n  - System.Reflection.Emit.ILGeneration\r\n  - System.Reflection.Emit.Lightweight\r\n- Avro.msbuild\r\n  - Microsoft.Build.Framework\r\n  - Microsoft.Build.Utilities.Core\r\n\r\nBy updating the versions in our libraries, we require users of the library to update to a version equal to or greater than the version we reference. For example, if a user were to reference an older version of Newtonsoft.Json, the would be forced to update to a newer version before they could use a new version of the Avro library.\r\n\r\nIn short, we should only update the version of the dependencies in our libraries if we absolutely must for functionality that we require. We leave it up to the users of the library as to whether or not they want the latest and greatest of a particularly dependency. We're only going to require the bare minimum.\r\n\r\nThat said, we should use the latest and greatest in any executables we ship (i.e. avrogen/Avro.codegen) so that we have the latest security fixes in there.\r\n\r\nDoes all that make sense?"", 'commenter': 'blachniet'}, {'comment': 'Makes sense. Should I downgrade some of the libs? e.g. NewtonsoftJson?', 'commenter': 'zcsizmadia'}, {'comment': ""Yea, let's revert the non-private dependencies back to their original versions.\r\n\r\nIt's perfectly safe to update the private dependencies (e.g. StyleCop and FxCop) and any unit-testing-only dependencies (e.g. NUnit*).\r\n\r\nI created [AVRO-2981](https://issues.apache.org/jira/browse/AVRO-2981) to update the dependencies in Avrogen."", 'commenter': 'blachniet'}, {'comment': '1. Do you prefer to keep the version.props way of defining package versions? If yes how does that would work with dependabot? I have never used it, so I have no expereince with it at all.\r\n\r\n2. Avro.codegen has no explicit package dependency besides Avro.main, so it will inherit the dependencies of Avro.main. If we keep certain packages at a lower version in Avro.main, but still want to use the latest version in Avro.codegen, we must force to use the latest version by explicitly referencing those packages in Avro.codegen.csproj with the latest version.\r\nIf we use versions.props we would need 2 versions for such packages, 1 for the minimum version (e.g. Newtonsoft 10.0.3), and 1 for the latest (e.g. Newtonsoft 12.0.3)\r\nE.g.\r\nAvro.main.csproj: ```<PackageReference Include=""Newtonsoft.Json"" Version=""10.0.3"" />```\r\nAvro.codegen.csproj: ```<PackageReference Include=""Newtonsoft.Json"" Version=""12.0.3"" />```\r\n\r\nThis is a legit thing do to IMO, I did forcing packages to keep at a lower version in other projects. This is the opposite, forsing them to use the latest.\r\n I question if the versiosns.props is a good solution here with the above minimum/latest versions + by using the dependabot.', 'commenter': 'zcsizmadia'}, {'comment': 'Avro.codegen.csproj: ```<PackageReference Include=""Newtonsoft.Json"" Version=""*"" />``` would work too, however, I am not sure how I feel about using an unbound latest version.\r\nIn this case Avro.main is nuspec will specifiy 10.0.3, but Avro.codegen will pick up the latest. Maybe this does not sound too bad? :)', 'commenter': 'zcsizmadia'}]"
984,build.sh,"@@ -92,7 +92,7 @@ do
       (cd lang/csharp; ./build.sh test)
       (cd lang/js; ./build.sh lint test)
       (cd lang/ruby; ./build.sh lint test)
-      (cd lang/php; ./build.sh test)
+      (cd lang/php; ./build.sh lint test)","[{'comment': 'Ooops, this breaks on a **clean** build on my system!\r\n\r\n```\r\n+ cd lang/php\r\n+ ./build.sh lint test\r\nNo syntax errors detected in ./test/IODatumReaderTest.php\r\nNo syntax errors detected in ./test/test_helper.php\r\nNo syntax errors detected in ./examples/write_read.php\r\nNo syntax errors detected in ./test/ProtocolFileTest.php\r\nNo syntax errors detected in ./test/InterOpTest.php\r\nNo syntax errors detected in ./test/FloatIntEncodingTest.php\r\nNo syntax errors detected in ./test/LongEncodingTest.php\r\nNo syntax errors detected in ./test/StringIOTest.php\r\nNo syntax errors detected in ./test/generate_interop_data.php\r\nNo syntax errors detected in ./test/NameTest.php\r\nNo syntax errors detected in ./test/DataFileTest.php\r\nNo syntax errors detected in ./lib/AvroIO.php\r\nNo syntax errors detected in ./test/SchemaTest.php\r\nNo syntax errors detected in ./test/DatumIOTest.php\r\nNo syntax errors detected in ./lib/Protocol/AvroProtocolParseException.php\r\nNo syntax errors detected in ./lib/Protocol/AvroProtocol.php\r\nNo syntax errors detected in ./lib/AvroNotImplementedException.php\r\nNo syntax errors detected in ./lib/Protocol/AvroProtocolMessage.php\r\nNo syntax errors detected in ./lib/AvroUtil.php\r\nNo syntax errors detected in ./lib/autoload.php\r\nNo syntax errors detected in ./lib/Schema/AvroSchemaParseException.php\r\nNo syntax errors detected in ./lib/Schema/AvroMapSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroArraySchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroName.php\r\nNo syntax errors detected in ./lib/Schema/AvroFixedSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroRecordSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroUnionSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroNamedSchemata.php\r\nNo syntax errors detected in ./lib/Schema/AvroField.php\r\nNo syntax errors detected in ./lib/Schema/AvroEnumSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroPrimitiveSchema.php\r\nNo syntax errors detected in ./lib/Schema/AvroNamedSchema.php\r\nNo syntax errors detected in ./lib/DataFile/AvroDataIOException.php\r\nNo syntax errors detected in ./lib/DataFile/AvroDataIOWriter.php\r\nNo syntax errors detected in ./lib/DataFile/AvroDataIO.php\r\nNo syntax errors detected in ./lib/DataFile/AvroDataIOReader.php\r\nNo syntax errors detected in ./lib/IO/AvroStringIO.php\r\nNo syntax errors detected in ./lib/IO/AvroFile.php\r\nNo syntax errors detected in ./lib/IO/AvroIOException.php\r\nNo syntax errors detected in ./lib/Avro.php\r\nNo syntax errors detected in ./lib/Datum/AvroIOSchemaMatchException.php\r\nNo syntax errors detected in ./lib/AvroGMP.php\r\nNo syntax errors detected in ./lib/Datum/AvroIOBinaryEncoder.php\r\nNo syntax errors detected in ./lib/Datum/AvroIODatumWriter.php\r\nNo syntax errors detected in ./lib/Datum/AvroIOBinaryDecoder.php\r\nNo syntax errors detected in ./lib/AvroDebug.php\r\nNo syntax errors detected in ./lib/Datum/AvroIOTypeException.php\r\nNo syntax errors detected in ./lib/AvroException.php\r\nNo syntax errors detected in ./lib/Datum/AvroIODatumReader.php\r\n./build.sh: line 61: vendor/bin/phpcs: No such file or directory\r\n```\r\n\r\nphpcs is installed by composer, we can either run `test` before `lint` or call `composer install ...` in the [lint target](https://github.com/sekikn/avro/blob/AVRO-2975/lang/php/build.sh#L59-L67) as well (it looks like calling it twice is fast).', 'commenter': 'RyanSkraba'}, {'comment': 'Thank you for the comment @RyanSkraba! Will update the PR soon :)', 'commenter': 'sekikn'}]"
1006,lang/csharp/common.props,"@@ -45,6 +46,7 @@
 
   <ItemGroup>
     <None Include=""$(MSBuildThisFileDirectory)\LICENSE"" Pack=""true"" Visible=""false"" PackagePath=""""/>
+    <None Include=""$(MSBuildThisFileDirectory)/../../doc/src/resources/images/avro-logo.png"" Pack=""true"" PackagePath=""\""/>","[{'comment': 'Could you set `Visible=""false""` in this, like with did with `LICENSE` above? That prevents this file from appearing in the project tree view in Visual Studio. I think `PackagePath` should be empty like in `LICENSE` as well. Did you get an error with it being blank?\r\n\r\n```suggestion\r\n    <None Include=""$(MSBuildThisFileDirectory)/../../doc/src/resources/images/avro-logo.png"" Pack=""true"" Visible=""false"" PackagePath=""""/>\r\n```', 'commenter': 'blachniet'}]"
1153,lang/c++/api/DataFile.hh,"@@ -75,11 +75,11 @@ class AVRO_DECL DataFileWriterBase : boost::noncopyable {
     Metadata metadata_;
     int64_t lastSync_;
 
-    static std::unique_ptr<OutputStream> makeStream(const char* filename);
+    static std::unique_ptr<OutputStream> makeStream(const char *filename);","[{'comment': 'same comment as on prior PRs we should ensure this type of style change is discussed and agreed upon on the ML.  Also, having a GHA with formatter that enforces this one way or another would be nice.', 'commenter': 'emkornfield'}, {'comment': ""From the next installment, I'll precede the actual PR with a format-change PR. It is a good idea to have a discussion on the style rule. But in order not to get distracted, I'll just stick to what JetBrains CLion does y default (which is what they call Google style)\r\n"", 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/GenericDatum.hh,"@@ -126,44 +128,44 @@ public:
     void selectBranch(size_t branch);
 
     /// Makes a new AVRO_NULL datum.
-    GenericDatum() : type_(AVRO_NULL), logicalType_(LogicalType::NONE) { }
+    GenericDatum() : type_(AVRO_NULL), logicalType_(LogicalType::NONE) {}
 
     /// Makes a new AVRO_BOOL datum whose value is of type bool.","[{'comment': 'it might be worth a comment here, about why constructors are not marked explicit', 'commenter': 'emkornfield'}, {'comment': 'Did that', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/Node.hh,"@@ -81,14 +81,14 @@ std::ostream &operator<<(std::ostream &os, const Name &n) {
 ///
 /// The Node object uses reference-counted pointers.  This is so that schemas
 /// may be reused in other schemas, without needing to worry about memory
-/// deallocation for nodes that are added to multiple schema parse trees.
+/// de-allocation for nodes that are added to multiple schema parse trees.","[{'comment': ""i don't think this change is necessary."", 'commenter': 'emkornfield'}, {'comment': 'Done', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/Node.hh,"@@ -135,8 +135,8 @@ class AVRO_DECL Node : private boost::noncopyable {
         doAddLeaf(newLeaf);
     }
     virtual size_t leaves() const = 0;
-    virtual const NodePtr &leafAt(int index) const = 0;
-    virtual const GenericDatum &defaultValueAt(int index) {
+    virtual const NodePtr &leafAt(size_t index) const = 0;","[{'comment': 'did you consider the other change, and using int for `leaves()`?  ', 'commenter': 'emkornfield'}, {'comment': 'Yes, but this is never going to be negative and size_t is the better alternative.', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/NodeImpl.hh,"@@ -113,15 +113,15 @@ protected:
         return docAttribute_.get();
     }
 
-    void doAddLeaf(const NodePtr &newLeaf) override {
+    void doAddLeaf(const NodePtr &newLeaf) final {","[{'comment': 'this is semantic in what looks likes a public header, are you sure noone else has subclassed this class, and might have overridden this method?', 'commenter': 'emkornfield'}, {'comment': 'The reason this is final is because this is being invoked from the constructor. Invoking a non-final virtual function from constructor is confusing at the very least.', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/NodeImpl.hh,"@@ -113,15 +113,15 @@ protected:
         return docAttribute_.get();
     }
 
-    void doAddLeaf(const NodePtr &newLeaf) override {
+    void doAddLeaf(const NodePtr &newLeaf) final {
         leafAttributes_.add(newLeaf);
     }
 
     size_t leaves() const override {
         return leafAttributes_.size();
     }
 
-    const NodePtr &leafAt(int index) const override {
+    const NodePtr &leafAt(size_t index) const override {","[{'comment': 'it seems you would want to make this final as well? if you are converting the one above?', 'commenter': 'emkornfield'}, {'comment': 'None of the other virtual methods are called from the constructor and hence leaving them `override` is fine.', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/Serializer.hh,"@@ -71,15 +68,15 @@ class Serializer : private boost::noncopyable
     }
 
     void writeBytes(const void *val, size_t size) {
-        writer_.writeBytes(val);
+        writer_.writeBytes(val, size);","[{'comment': 'this seems like it should be tracked in a separate JIRA, it looks like an actual bug fix?  Is there an associated unit test?', 'commenter': 'emkornfield'}, {'comment': 'This is indeed a bug. The only caller for `writeBytes` is `serialize` in `AvroSerializer.hh`. `serialize` is not used by any of the code here, but could be used by some of generated code. Without this fix, the code can crash because there is no guarantee that the string is null-terminated.', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/Stream.hh,"@@ -160,23 +160,23 @@ AVRO_DECL OutputStreamPtr memoryOutputStream(size_t chunkSize = 4 * 1024);
  * It does not copy the data, the byte array should remain valid
  * until the InputStream is used.
  */
-AVRO_DECL InputStreamPtr memoryInputStream(const uint8_t* data, size_t len);
+AVRO_DECL InputStreamPtr memoryInputStream(const uint8_t *data, size_t len);
 
 /**
  * Returns a new InputStream with the contents written into an
- * outputstream. The output stream must have been returned by
+ * output stream. The output stream must have been returned by","[{'comment': '`OutputStream` seems like the better fix.  Rewording this to be Returns a new InputStream that reads the contents written to `source` might be even better.', 'commenter': 'emkornfield'}, {'comment': 'Done', 'commenter': 'thiru-mg'}]"
1153,lang/c++/api/Validator.hh,"@@ -33,32 +34,32 @@ class AVRO_DECL NullValidator : private boost::noncopyable {
 public:
 
     explicit NullValidator(const ValidSchema &schema) {}
-    NullValidator() {}
+    NullValidator() = default;
 
-    void setCount(int64_t val) {}
+    void setCount(int64_t) {}
 
-    bool typeIsExpected(Type type) const {
+    static bool typeIsExpected(Type) {","[{'comment': 'this change seems a little strange to me (while probably technically correct)', 'commenter': 'emkornfield'}, {'comment': ""This function is not used and hence it doesn't matter, as of now."", 'commenter': 'thiru-mg'}]"
1153,lang/c++/impl/DataFile.cc,"@@ -243,13 +243,13 @@ void DataFileWriterBase::flush()
     sync();
 }
 
-boost::mt19937 random(static_cast<uint32_t>(time(0)));
+boost::mt19937 random(static_cast<uint32_t>(time(nullptr)));
 
 DataFileSync DataFileWriterBase::makeSync()
 {
     DataFileSync sync;
-    for (size_t i = 0; i < sync.size(); ++i) {
-        sync[i] = random();
+    for (unsigned char & i : sync) {","[{'comment': 'this is less straightforward to me than the previous code.  If you want to refactor, I think `std::generate` would work here and be clearer.', 'commenter': 'emkornfield'}, {'comment': 'Nice. Thanks, done.', 'commenter': 'thiru-mg'}, {'comment': 'Nice. Thanks, done.', 'commenter': 'thiru-mg'}]"
1153,lang/c++/impl/DataFile.cc,"@@ -306,20 +306,20 @@ void DataFileReaderBase::init(const ValidSchema& readerSchema)
 
 static void drain(InputStream& in)
 {
-    const uint8_t *p = 0;
+    const uint8_t *p = nullptr;
     size_t n = 0;
     while (in.next(&p, &n));
 }
 
 char hex(unsigned int x)
 {
-    return x + (x < 10 ? '0' :  ('a' - 10));
+    return static_cast<char>(x + (x < 10 ? '0' :  ('a' - 10)));
 }
 
 std::ostream& operator << (std::ostream& os, const DataFileSync& s)
 {
-    for (size_t i = 0; i < s.size(); ++i) {
-        os << hex(s[i] / 16)  << hex(s[i] % 16) << ' ';
+    for (unsigned char i : s) {","[{'comment': 'it looks like elsewhere uint8_t might be used of rhte same type?', 'commenter': 'emkornfield'}, {'comment': ""You're right. Fixed"", 'commenter': 'thiru-mg'}]"
1187,lang/csharp/src/apache/main/Reflect/ClassCache.cs,"@@ -214,8 +215,12 @@ public void LoadClassCache(Type objType, Schema s)
                     var c = GetClass(rs);
                     foreach (var f in rs.Fields)
                     {
-                        var t = c.GetPropertyType(f);
-                        LoadClassCache(t, f.Schema);
+                        if (!_previousFields.ContainsKey(f.Name))
+                        {
+                            _previousFields.TryAdd(f.Name, f.Schema);","[{'comment': 'I believe you can collapse the omit the `ContainsKey` by checking the return value of `TryAdd`. The docs for `TryAdd` [state](https://docs.microsoft.com/en-us/dotnet/api/system.collections.concurrent.concurrentdictionary-2.tryadd?view=net-5.0#returns) that it returns: \r\n\r\n> true if the key/value pair was added to the ConcurrentDictionary<TKey,TValue> successfully; false if the key already exists.\r\n\r\nSo, maybe you can do something like this:\r\n\r\n```suggestion\r\n                        if (_previousFields.TryAdd(f.Name, f.Schema);)\r\n                        {\r\n```', 'commenter': 'blachniet'}]"
1263,lang/java/avro/src/main/java/org/apache/avro/Conversions.java,"@@ -146,6 +149,111 @@ private static BigDecimal validate(final LogicalTypes.Decimal decimal, BigDecima
     }
   }
 
+  public static class DurationConversion extends Conversion<Duration> {
+
+      private static final int MONTH_DAYS = 30;","[{'comment': 'A month has 28, 29, 30 or 31 days. Hardcoding a single value (31 days/month occurs more often) is basically a bug. Note that this cannot be fixed if we choose to support all possible duration values (see the conversation comments for more info).', 'commenter': 'opwvhk'}]"
1301,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -892,6 +902,9 @@ public int resolveUnion(Schema union, Object datum) {
   protected String getSchemaName(Object datum) {
     if (datum == null || datum == JsonProperties.NULL_VALUE)
       return Type.NULL.getName();
+    String primativeType = PRIMATIVE_DATUM_TYPES.get(datum.getClass());
+    if (primativeType != null)
+      return primativeType;","[{'comment': ""Shouldn't we remove the later checks for `isInteger(datum)`, `isLong(datum)`, etc. ?"", 'commenter': 'martin-g'}, {'comment': ""I couldn't find any implementations that override these methods.   They should be safe to remove, but it looks like the intention was that subclasses of GenericData would be able to change their behaviour by overriding these methods. \r\n\r\nThat expectation (which nobody uses) would be broken by the primitive cache anyway... \r\n\r\n@belugabehr what do you think?  Should these methods be cleaned up?"", 'commenter': 'RyanSkraba'}, {'comment': ""Hello,\r\n\r\nIt was my desire to remove these methods, but I feared I would be breaking backwards compatibility (even more than this already does).  It may still be possible for developers to override these methods. For example:\r\n\r\n```java\r\n    if (isInteger(datum))\r\n      return Type.INT.getName();\r\n```\r\n\r\nA developer could allow for the primitive case to be handled by the cache, but also extend the functionality to allow for other logical types to, in this case, return an INT type by overriding `isInteger`.  I'm happy to take away that ability if it offers no real-world use cases, but I didn't want to be so heavy-handed with it."", 'commenter': 'belugabehr'}, {'comment': 'I am not sure whether I was clear enough.\r\nhttps://github.com/apache/avro/blob/cc0eb0bee35681f33a0b5324b106ef744be86d1f/lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java#L905-L907 is the new `if` branch.\r\nIf I understand it correctly if the datum is any of the ""primitive"" types then the following `if` branches won\'t ever be reached: https://github.com/apache/avro/blob/cc0eb0bee35681f33a0b5324b106ef744be86d1f/lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java#L918-L931\r\nSo, even if a user overrides `isInteger()` it won\'t be called at all, because of https://github.com/apache/avro/blob/cc0eb0bee35681f33a0b5324b106ef744be86d1f/lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java#L905-L907\r\n\r\n', 'commenter': 'martin-g'}, {'comment': ""In addition, `PRIMATIVE_DATUM_TYPES` handles primitives' wrapper classes, like `Integer.class`. Does it need to handle `Integer.TYPE` too ?"", 'commenter': 'martin-g'}, {'comment': 'I guess the subsequent code wouldn\'t be **entirely** dead, since somebody might have an implementation that turns their special `MyInteger` class into a `Type.INT`.  Hypothetically, this change would make it impossible for a subclass to specify that all `java.lang.Integer` should be represented by a `Type.LONG`, I guess! \r\n\r\nWhile I doubt anybody is actually doing that, why don\'t we play it with a bit of security and do: \r\n\r\n```\r\nString primativeType = getPrimitiveTypeCache().get(datum.getClass());\r\n```\r\n\r\nwhere `getPrimitiveTypeCache()` is protected and returns `PRIMATIVE_DATUMS_TYPES` by default?  That adds one method call but would give a subclass an ""escape route"" if they do have a specialised behaviour.  Alternatively, a protected data member that is initialised to the static hash instance perhaps?', 'commenter': 'RyanSkraba'}]"
1301,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -69,6 +69,16 @@
 
   private static final GenericData INSTANCE = new GenericData();
 
+  private static final Map<Class<?>, String> PRIMATIVE_DATUM_TYPES = new IdentityHashMap<>();","[{'comment': 'Any reason to use IdentityHashMap in favour of HashMap ?', 'commenter': 'martin-g'}, {'comment': 'Quick note: this should be `PRIMITIVE`', 'commenter': 'RyanSkraba'}, {'comment': ""It's faster to use `IdentityHashMap` as it uses the primitive `==` method instead of `equals`.  When coming up with this solution, I did some research and from everything I can find, it seems that as long as the classes comes from the same class loader (as is the case here since it's populated by the class itself and not an outside reference), then this should be perfectly acceptable."", 'commenter': 'belugabehr'}, {'comment': ""That's true, but `java.lang.Class` does not override `#equals()`, so it inherits `Object#equals()` which uses `==`."", 'commenter': 'martin-g'}, {'comment': ""They're equivalent -- let's go with @belugabehr 's choice!"", 'commenter': 'RyanSkraba'}]"
1357,lang/csharp/src/apache/test/IO/BinaryCodecTests.cs,"@@ -216,21 +217,98 @@ public void TestString(string n, int overhead)
 
 #if NETCOREAPP3_1
         [Test]
-        public void TestLargeString()
+        public void TestStringReadIntoArrayPool()
         {
+            const int maxFastReadLength = 4096;
+
             // Create a 16KB buffer in the Array Pool
             var largeBufferToSeedPool = ArrayPool<byte>.Shared.Rent(2 << 14);
             ArrayPool<byte>.Shared.Return(largeBufferToSeedPool);
 
-            // Create a slightly less than 16KB buffer, which will use the 16KB buffer in the pool
-            var n = string.Concat(Enumerable.Repeat(""1234567890"", 1600));
-            var overhead = 3;
+            var n = string.Concat(Enumerable.Repeat(""A"", maxFastReadLength));
+            var overhead = 2;
 
             TestRead(n, (Decoder d) => d.ReadString(), (Encoder e, string t) => e.WriteString(t), overhead + n.Length);
-            TestSkip(n, (Decoder d) => d.SkipString(), (Encoder e, string t) => e.WriteString(t), overhead + n.Length);
+        }
+
+        [Test]
+        public void TestStringReadByBinaryReader()
+        {
+            const int overhead = 2;
+            const int maxFastReadLength = 4096;
+            const int expectedStringLength = maxFastReadLength + 1;
+            var n = string.Concat(Enumerable.Repeat(""A"", expectedStringLength));
+
+            TestRead(n, (Decoder d) => d.ReadString(), (Encoder e, string t) => e.WriteString(t), expectedStringLength + overhead);
         }
 #endif
 
+        [Test]
+        public void TestInvalidInputWithNegativeStringLength()
+        {
+            using (MemoryStream iostr = new MemoryStream())
+            {
+                Encoder e = new BinaryEncoder(iostr);
+
+                e.WriteLong(-1);
+
+                iostr.Flush();
+                iostr.Position = 0;
+                Decoder d = new BinaryDecoder(iostr);
+
+                var exception = Assert.Throws<AvroException>(() => d.ReadString());
+
+                Assert.NotNull(exception);
+                Assert.AreEqual(""Can not deserialize a string with negative length!"", exception.Message);
+                iostr.Close();
+            }
+        }
+
+        [Test]
+        public void TestInvalidInputWithMaxIntAsStringLength()
+        {
+            using (MemoryStream iostr = new MemoryStream())
+            {
+                Encoder e = new BinaryEncoder(iostr);
+
+                e.WriteLong(int.MaxValue);
+                e.WriteBytes(Encoding.UTF8.GetBytes(""SomeSmallString""));
+
+                iostr.Flush();
+                iostr.Position = 0;
+                Decoder d = new BinaryDecoder(iostr);
+
+                var exception = Assert.Throws<AvroException>(() => d.ReadString());
+
+                Assert.NotNull(exception);
+                Assert.AreEqual(""String length is not supported!"", exception.Message);
+                iostr.Close();
+            }
+        }
+
+        [Test]
+        public void TestInvalidInputWithMaxArrayLengthAsStringLength()","[{'comment': ""This test is failing when running on .NET Framework 4.6.1. It looks like we aren't running the Windows builds/tests in GitHub actions anymore, which would explain why that didn't catch it.\r\n\r\n```\r\n+ dotnet test --configuration Release --no-build --filter 'TestCategory!=Interop' Avro.sln\r\nTest run for C:\\Users\\Brian.Lachniet\\code\\github.com\\apache\\avro\\lang\\csharp\\src\\apache\\test\\bin\\Release\\net461\\Avro.test.dll (.NETFramework,Version=v4.6.1)\r\nMicrosoft (R) Test Execution Command Line Tool Version 16.11.0\r\nCopyright (c) Microsoft Corporation.  All rights reserved.\r\n\r\nStarting test execution, please wait...\r\nA total of 1 test files matched the specified pattern.\r\n  Failed TestInvalidInputWithMaxArrayLengthAsStringLength [75 ms]\r\n  Error Message:\r\n     Expected: <Avro.AvroException>\r\n  But was:  <System.OutOfMemoryException: Exception of type 'System.OutOfMemoryException' was thrown.\r\n   at System.IO.BinaryReader.ReadBytes(Int32 count)\r\n   at Avro.IO.BinaryDecoder.ReadString() in C:\\Users\\Brian.Lachniet\\code\\github.com\\apache\\avro\\lang\\csharp\\src\\apache\\main\\IO\\BinaryDecoder.netstandard2.0.cs:line 90\r\n   at Avro.Test.BinaryCodecTests.<>c__DisplayClass11_0.<TestInvalidInputWithMaxArrayLengthAsStringLength>b__0() in C:\\Users\\Brian.Lachniet\\code\\github.com\\apache\\avro\\lang\\csharp\\src\\apache\\test\\IO\\BinaryCodecTests.cs:line 304\r\n   at NUnit.Framework.Assert.Throws(IResolveConstraint expression, TestDelegate code, String message, Object[] args)>\r\n\r\n  Stack Trace:\r\n     at Avro.Test.BinaryCodecTests.TestInvalidInputWithMaxArrayLengthAsStringLength() in C:\\Users\\Brian.Lachniet\\code\\github.com\\apache\\avro\\lang\\csharp\\src\\apache\\test\\IO\\BinaryCodecTests.cs:line 304\r\n\r\n\r\nFailed!  - Failed:     1, Passed:   626, Skipped:     0, Total:   627, Duration: 3 s - Avro.test.dll (net461)\r\nTest run for C:\\Users\\Brian.Lachniet\\code\\github.com\\apache\\avro\\lang\\csharp\\src\\apache\\test\\bin\\Release\\netcoreapp2.1\\Avro.test.dll (.NETCoreApp,Version=v2.1)\r\n```\r\n\r\nThe [Remarks on the Array Class](https://docs.microsoft.com/en-us/dotnet/api/system.array?view=net-5.0#remarks) indicate that the .NET Framework may have a smaller size limit. However, even after setting `MaxDotNetArrayLength = 0x77359400;`, I'm getting the same test failure (only on the net461 tests).\r\n\r\n@RyanSkraba , how does the Java implementation handle large strings? Does it specify some arbitrary limit?"", 'commenter': 'blachniet'}, {'comment': 'The Java implementation seems also just to use the `MAX_ARRAY_SIZE` as limit: https://github.com/apache/avro/blob/8f0b8d68c3fc10b6a5fc09bae4a5c30defe53897/lang/java/avro/src/main/java/org/apache/avro/io/BinaryDecoder.java#L302-L316\r\n\r\n@blachniet can you fix the test for .NET Framework 4.6.1? It is hard for me to test this on windows.', 'commenter': 'PSanetra'}, {'comment': 'What is the policy for the supported .NET versions in Avro C# ?\r\nAccording to https://dotnet.microsoft.com/platform/support/policy/dotnet-core only 3.1 (LTS) and 5.0 (Current) are supported by Microsoft.', 'commenter': 'martin-g'}, {'comment': ""Huh, that's confusing.  According to https://docs.microsoft.com/en-us/lifecycle/faq/dotnet-framework#what-is-the-lifecycle-policy-for-different-versions-of--net-framework- there's quite a few supported versions in the 4.x range..."", 'commenter': 'RyanSkraba'}, {'comment': '@blachniet @RyanSkraba I have changed the constant `MaxDotNetArrayLength` for .Net Framework 4.6.1 to 0x3FFFFFFF. This seems to work. I could not find any correct official documentation. Thanks @superkartoffel for helping debugging this on windows.', 'commenter': 'PSanetra'}]"
1379,lang/rust/src/decode.rs,"@@ -23,7 +23,7 @@ use crate::{
     util::{safe_len, zag_i32, zag_i64},
     AvroResult, Error,
 };
-use std::{collections::HashMap, convert::TryFrom, io::Read, str::FromStr};
+use std::{collections::HashMap, convert::TryFrom, io::{ErrorKind,Read}, str::FromStr};","[{'comment': 'Add an empty space between `ErrorKind` and `Read`.\r\nI expect clippy to complain once the checks are enabled.', 'commenter': 'martin-g'}]"
1379,lang/rust/src/reader.rs,"@@ -341,6 +343,40 @@ mod tests {
         6u8, 102u8, 111u8, 111u8, 84u8, 6u8, 98u8, 97u8, 114u8, 94u8, 61u8, 54u8, 221u8, 190u8,
         207u8, 108u8, 180u8, 158u8, 57u8, 114u8, 40u8, 173u8, 199u8, 228u8, 239u8,
     ];
+    const TEST_RECORD_SCHEMA: &str = r#""","[{'comment': ""The name of the schema and the struct below are too generic.\r\nLet's add `_3240` (the JIRA number) to them"", 'commenter': 'martin-g'}]"
1379,lang/rust/src/reader.rs,"@@ -341,6 +343,40 @@ mod tests {
         6u8, 102u8, 111u8, 111u8, 84u8, 6u8, 98u8, 97u8, 114u8, 94u8, 61u8, 54u8, 221u8, 190u8,
         207u8, 108u8, 180u8, 158u8, 57u8, 114u8, 40u8, 173u8, 199u8, 228u8, 239u8,
     ];
+    const TEST_RECORD_SCHEMA: &str = r#""
+    {
+      ""type"": ""record"",
+      ""name"": ""test"",
+      ""fields"": [
+        {
+          ""name"": ""a"",
+          ""type"": ""long"",
+          ""default"": 42
+        },
+        {
+          ""name"": ""b"",
+          ""type"": ""string""
+        },
+        {
+            ""name"": ""a_nullable_array"",
+            ""type"": [""null"", {""type"": ""array"", ""items"": {""type"": ""string""}}],
+            ""default"": null
+        },
+        {
+            ""name"": ""a_nullable_boolean"",
+            ""type"": [""null"", {""type"": ""boolean""}],
+            ""default"": null
+        }
+      ]
+    }
+    ""#;
+    #[derive(Default, Debug, Deserialize, PartialEq)]","[{'comment': 'Is `PartialEq` really needed ?', 'commenter': 'martin-g'}]"
1379,lang/rust/src/reader.rs,"@@ -358,6 +394,23 @@ mod tests {
         );
     }
 
+    #[test]
+    fn test_from_avro_datum_with_union_to_struct() {
+        let schema = Schema::parse_str(TEST_RECORD_SCHEMA).unwrap();
+        let mut encoded: &'static [u8] = &[54, 6, 102, 111, 111];
+
+        let avro_datum = from_avro_datum(&schema, &mut encoded, None).unwrap();
+        let test_record: TestRecord = match &avro_datum {
+            Value::Record(_) => from_value::<TestRecord>(&avro_datum).unwrap(),
+            _ => panic!(""could not map avro data to struct""),","[{'comment': ""Let's use a proper name instead of `_`, e.g. `unexpected` and print it in the panic message. It will help for debugging regressions."", 'commenter': 'martin-g'}]"
1379,lang/rust/src/reader.rs,"@@ -358,6 +394,23 @@ mod tests {
         );
     }
 
+    #[test]
+    fn test_from_avro_datum_with_union_to_struct() {
+        let schema = Schema::parse_str(TEST_RECORD_SCHEMA).unwrap();
+        let mut encoded: &'static [u8] = &[54, 6, 102, 111, 111];
+
+        let avro_datum = from_avro_datum(&schema, &mut encoded, None).unwrap();
+        let test_record: TestRecord = match &avro_datum {
+            Value::Record(_) => from_value::<TestRecord>(&avro_datum).unwrap(),
+            _ => panic!(""could not map avro data to struct""),
+        };
+
+        assert_eq!(
+            test_record.a_nullable_array,
+            None
+        );","[{'comment': 'Please add assertions for all record fields.\r\nOr one assertion for the whole struct. To actually use the `PartialEq` trait!', 'commenter': 'martin-g'}]"
1438,lang/csharp/src/apache/main/Schema/PrimitiveSchema.cs,"@@ -82,7 +82,19 @@ public static PrimitiveSchema NewInstance(string type, PropertyMap props = null)
         /// <param name=""encspace""></param>
         protected internal override void WriteJson(JsonTextWriter w, SchemaNames names, string encspace)
         {
-            w.WriteValue(Name);
+            if(this.Props != null && this.Props.Count > 0)","[{'comment': 'shorthand for same check `if(this.Props?.Any() == true)`', 'commenter': 'KyleSchoonover'}]"
1438,lang/csharp/src/apache/main/Schema/PrimitiveSchema.cs,"@@ -82,7 +82,19 @@ public static PrimitiveSchema NewInstance(string type, PropertyMap props = null)
         /// <param name=""encspace""></param>
         protected internal override void WriteJson(JsonTextWriter w, SchemaNames names, string encspace)
         {
-            w.WriteValue(Name);
+            if(this.Props != null && this.Props.Count > 0)
+            {
+                w.WriteStartObject();
+                w.WritePropertyName(""type"");
+                w.WriteValue(Name);
+                foreach(var prop in Props)
+                {
+                    w.WritePropertyName(prop.Key);
+                    w.WriteRawValue(prop.Value);
+                }
+                w.WriteEndObject();
+            }
+            else w.WriteValue(Name);","[{'comment': 'Put else within brackets. Fixes styling related to SA1503', 'commenter': 'KyleSchoonover'}]"
1438,lang/csharp/src/apache/main/Schema/Schema.cs,"@@ -202,8 +202,15 @@ internal static Schema ParseJson(JToken jtok, SchemaNames names, string encspace
                 }
                 else if (jtype.Type == JTokenType.Array)
                     return UnionSchema.NewInstance(jtype as JArray, props, names, encspace);
-                else if (jtype.Type == JTokenType.Object && null != jo[""logicalType""]) // logical type based on a complex type
-                    return LogicalSchema.NewInstance(jtok, props, names, encspace);
+                else if (jtype.Type == JTokenType.Object)
+                {
+                    if (null != jo[""logicalType""]) // logical type based on a complex type
+                        return LogicalSchema.NewInstance(jtok, props, names, encspace);","[{'comment': 'Put within brackets. Fixes styling related to SA1503', 'commenter': 'KyleSchoonover'}]"
1438,lang/csharp/src/apache/main/Schema/Schema.cs,"@@ -202,8 +202,15 @@ internal static Schema ParseJson(JToken jtok, SchemaNames names, string encspace
                 }
                 else if (jtype.Type == JTokenType.Array)
                     return UnionSchema.NewInstance(jtype as JArray, props, names, encspace);
-                else if (jtype.Type == JTokenType.Object && null != jo[""logicalType""]) // logical type based on a complex type
-                    return LogicalSchema.NewInstance(jtok, props, names, encspace);
+                else if (jtype.Type == JTokenType.Object)
+                {
+                    if (null != jo[""logicalType""]) // logical type based on a complex type
+                        return LogicalSchema.NewInstance(jtok, props, names, encspace);
+
+                    var schema = ParseJson(jtype, names, encspace); // primitive schemas are allowed to have additional metadata properties
+                    if (schema is PrimitiveSchema)
+                        return schema;","[{'comment': 'Put within brackets. Fixes styling related to SA1503', 'commenter': 'KyleSchoonover'}]"
1438,lang/csharp/src/apache/test/Schema/SchemaTests.cs,"@@ -167,6 +167,49 @@ private static void testToString(Schema sc)
             }
         }
 
+        [TestCase(""{ \""type\"": \""null\"", \""metafield\"": \""abc\"" }"", Schema.Type.Null)]
+        [TestCase(""{ \""type\"": \""boolean\"", \""metafield\"": \""abc\"" }"", Schema.Type.Boolean)]
+        [TestCase(""{ \""type\"": \""int\"", \""metafield\"": \""abc\"" }"", Schema.Type.Int)]
+        [TestCase(""{ \""type\"": \""long\"", \""metafield\"": \""abc\"" }"", Schema.Type.Long)]
+        [TestCase(""{ \""type\"": \""float\"", \""metafield\"": \""abc\"" }"", Schema.Type.Float)]
+        [TestCase(""{ \""type\"": \""double\"", \""metafield\"": \""abc\"" }"", Schema.Type.Double)]
+        [TestCase(""{ \""type\"": \""bytes\"", \""metafield\"": \""abc\"" }"", Schema.Type.Bytes)]
+        [TestCase(""{ \""type\"": \""string\"", \""metafield\"": \""abc\"" }"", Schema.Type.String)]
+        public void TestPrimitiveWithMetadata(string s, Schema.Type type)
+        {
+            Schema sc1 = Schema.Parse(s);","[{'comment': 'Please use better names for the variables than `s`, `sc1`, `rc`, etc.', 'commenter': 'martin-g'}]"
1481,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -29,7 +29,8 @@ static int Main(string[] args)
             if (args.Length == 0 || args[0] == ""-h"" || args[0] == ""--help"")
             {
                 Usage();
-                return 1;
+                // Return success if help requested
+                return args.Length == 0 ? 1 : 0;","[{'comment': '`            // Print usage if no arguments provided or help requested\r\n            if (args.Length == 0)\r\n            {\r\n                Usage();\r\n                return 1;\r\n            }`\r\n\r\n` if (args[0] == ""-h"" || args[0] == ""--help"")\r\n            {\r\n                Usage();\r\n                return 0;\r\n            }`\r\n\r\n\r\nThis seems cleaner.  No reason to add another evaluation.', 'commenter': 'KyleSchoonover'}, {'comment': 'I am not sure I agree with that statement: double the code for  a very simple  condition. However I modded the PR\r\n', 'commenter': 'zcsizmadia'}]"
1484,lang/csharp/src/apache/main/CodeGen/CodeGen.cs,"@@ -989,29 +990,20 @@ internal static string getType(Schema schema, bool nullible, ref bool nullibleEn
         /// <returns>
         /// schema that is nullable.
         /// </returns>
-        public static Schema getNullableType(UnionSchema schema)","[{'comment': 'Since this is a public method we need to deprecate the old method for some time/releases.\r\nThe old method should delegate to the new one. ', 'commenter': 'martin-g'}, {'comment': 'Updated, will use this pattern in the future.', 'commenter': 'KyleSchoonover'}]"
1484,lang/csharp/src/apache/main/CodeGen/CodeGen.cs,"@@ -989,29 +990,34 @@ internal static string getType(Schema schema, bool nullible, ref bool nullibleEn
         /// <returns>
         /// schema that is nullable.
         /// </returns>
+        /// <exception cref=""System.ArgumentNullException"">schema - UnionSchema can not be null.</exception>
+        [Obsolete(""Use GetNullableType. This method will be deprecated in a future release."")]","[{'comment': 'Am I wrong or `[Obsolete]` in C# is the same as `@Deprecated` in Java ?\r\nI.e. by adding `[Obsolete]` the following statement is already deprecated?\r\nIf I am correct then the message should say `This method is deprecated and it will be removed in a future release.`', 'commenter': 'martin-g'}]"
1485,lang/csharp/src/apache/main/CodeGen/CodeGen.cs,"@@ -219,8 +219,14 @@ protected virtual void processProtocols()
         /// <returns>
         /// List of named schemas.
         /// </returns>
-        protected virtual SchemaNames generateNames(Protocol protocol)
+        /// <exception cref=""System.ArgumentNullException"">protocol - Protocol can not be null.</exception>
+        protected virtual SchemaNames GenerateNames(Protocol protocol)","[{'comment': 'For backward compatibility we need to keep the old method deprecated for few releases.', 'commenter': 'martin-g'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1485,lang/csharp/src/apache/main/CodeGen/CodeGen.cs,"@@ -237,7 +243,7 @@ protected virtual SchemaNames generateNames(Protocol protocol)
         /// <returns>
         /// List of named schemas.
         /// </returns>
-        protected virtual SchemaNames generateNames(Schema schema)
+        protected virtual SchemaNames GenerateNames(Schema schema)","[{'comment': 'As above.', 'commenter': 'martin-g'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1485,lang/csharp/src/apache/main/CodeGen/CodeGen.cs,"@@ -219,8 +219,14 @@ protected virtual void processProtocols()
         /// <returns>
         /// List of named schemas.
         /// </returns>
-        protected virtual SchemaNames generateNames(Protocol protocol)
+        /// <exception cref=""System.ArgumentNullException"">protocol - Protocol can not be null.</exception>
+        protected virtual SchemaNames GenerateNames(Protocol protocol)
         {
+            if (protocol == null)
+            {
+                throw new ArgumentNullException(nameof(protocol), ""Protocol can not be null"");","[{'comment': 'What does `nameof()` returns for `null` ?', 'commenter': 'martin-g'}, {'comment': 'Honestly, it\'s a weird pattern, but really it\'s to make sure your messaging is up to date when you change the name of a variable.  It\'s the equivalent of ""protocol.""  It\'s literally the name of the variable as a string.', 'commenter': 'KyleSchoonover'}]"
1565,lang/csharp/src/apache/test/Avro.test.csproj,"@@ -32,13 +32,22 @@
   </PropertyGroup>
 
   <ItemGroup>
+    <PackageReference Include=""coverlet.collector"" Version=""3.1.2"">","[{'comment': 'Please do not hardcode package versions in csproj files. They should be defined in versions.props', 'commenter': 'zcsizmadia'}]"
1565,.gitignore,"@@ -30,3 +30,5 @@ composer.lock
 .phpunit.result.cache
 .mvn/jvm.config # Maven JVM settings
 **/*.run.xml    # Intellij IDEA Run configurations
+/lang/csharp/src/apache/test/Coverage","[{'comment': 'This should be in the lang specific gitignore file', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/CODECOVERAGE.md,"@@ -0,0 +1,8 @@
+# C# Avro Code Coverage
+
+The following instructions should be followed in order to create a code coverage report locally.  Please note that this assumes you are running on Windows OS and that your local nuget cache is under you user profile.
+
+1. Open a command prompt
+2. Navigate to the test project `avro\lang\csharp\src\apache\test`
+3. Run the following test command `dotnet test --results-directory ./TestResults --collect:""XPlat Code Coverage""`
+4. Generate the report with the following command `dotnet %USERPROFILE%\.nuget\packages\reportgenerator\5.0.4\tools\net6.0\ReportGenerator.dll ""-reports:./TestResults/*/coverage.cobertura.xml"" ""-targetdir:./Coverage/"" -reporttypes:HTML`","[{'comment': 'This could be `reportgenerator -reports:./TestResults/*/coverage.cobertura.xml"" ""-targetdir:./Coverage/ -reporttypes:HTML`\r\nHowever this requires a one time install of: `dotnet tool install --global dotnet-reportgenerator-globaltool`', 'commenter': 'zcsizmadia'}, {'comment': 'You can add it as an option to the documentation later.  Trying to stick with what we can control without a contributor having to run a special install instruction.', 'commenter': 'KyleSchoonover'}, {'comment': 'This is too complicated. Should be `reportgenerator -reports:./TestResults/*/coverage.cobertura.xml -targetdir:./Coverage/ -reporttypes:HTML`', 'commenter': 'zcsizmadia'}, {'comment': 'That assumes someone sets their path via command line to run.  I gave the simple copy paste.', 'commenter': 'KyleSchoonover'}, {'comment': 'This is for sure not the MS suggested way. The reportgenerator tool should be installed fia `dotnet tool install -g` just like any other tool used for development.', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/versions.props,"@@ -57,5 +57,8 @@
     <NUnitConsoleRunnerVersion>3.14.0</NUnitConsoleRunnerVersion>
     <NUnit3TestAdapterVersion>4.2.1</NUnit3TestAdapterVersion>
     <StyleCopAnalyzersVersion>1.1.118</StyleCopAnalyzersVersion>
+    <CoverletCollector>3.1.2</CoverletCollector>","[{'comment': 'plz add Version to the end to follow the naming convention and keep the list sorted if possible', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/src/apache/test/Avro.test.csproj,"@@ -47,7 +47,7 @@
 
   <ItemGroup>
     <PackageReference Include=""Microsoft.NET.Test.Sdk"" Version=""$(MicrosoftNETTestSdkVersion)"" />
-    <PackageReference Include=""ReportGenerator"" Version=""5.0.4"" />
+    <PackageReference Include=""ReportGenerator"" Version=""$(ReportGenerator)"" />","[{'comment': 'Should this be a private asset?', 'commenter': 'zcsizmadia'}, {'comment': 'Is this really needed?', 'commenter': 'zcsizmadia'}, {'comment': ""Is it really needed? No.  It's not needed at all unless you want to generate the report.  This makes it easier so that the local nuget cache has the required files to generate the report.  So no manual install.  As for private that would only matter if someone specifically references the test project."", 'commenter': 'KyleSchoonover'}, {'comment': ""After checking best practices for code coverage, IMO `ReportGenerator` should not be PackageReference'd\r\n"", 'commenter': 'zcsizmadia'}, {'comment': 'Can you send a link to your best practices?  This is exactly what my team does to integrate the reports into the CI/CD pipeline.', 'commenter': 'KyleSchoonover'}, {'comment': 'https://docs.microsoft.com/en-us/dotnet/core/testing/unit-testing-code-coverage?tabs=windows\r\n', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/src/apache/test/Avro.test.csproj,"@@ -32,13 +32,22 @@
   </PropertyGroup>
 
   <ItemGroup>
+    <PackageReference Include=""coverlet.collector"" Version=""$(CoverletCollectorVersion)"">
+      <PrivateAssets>all</PrivateAssets>
+      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>
+    </PackageReference>
+    <PackageReference Include=""coverlet.msbuild"" Version=""$(CoverletMSBuildVersion)"">
+      <PrivateAssets>all</PrivateAssets>
+      <IncludeAssets>runtime; build; native; contentfiles; analyzers; buildtransitive</IncludeAssets>
+    </PackageReference>
     <PackageReference Include=""NUnit"" Version=""$(NUnitVersion)"" />
     <PackageReference Include=""NUnit3TestAdapter"" Version=""$(NUnit3TestAdapterVersion)"" />
     <PackageReference Include=""NUnit.ConsoleRunner"" Version=""$(NUnitConsoleRunnerVersion)"" />
   </ItemGroup>
 
   <ItemGroup>
     <PackageReference Include=""Microsoft.NET.Test.Sdk"" Version=""$(MicrosoftNETTestSdkVersion)"" />
+    <PackageReference Include=""ReportGenerator"" Version=""$(ReportGeneratorVersion)"" />","[{'comment': 'This is not needed', 'commenter': 'zcsizmadia'}, {'comment': ""I disagree.  And since you didn't point me to the code coverage standards I'm still not changing the dependency to generate the report."", 'commenter': 'KyleSchoonover'}, {'comment': 'See below. The tool should be installed via `dotnet tool install -g`. That is the preferred way to handle it. Unless you want to use the ReportGenerator functionality directly from the csproj file. ', 'commenter': 'zcsizmadia'}, {'comment': 'You would need to add packagereferenced `ReportGenerator` if you would create e.g. target (in csproj)  running after testing, which will automatically generate the html documentation each time you run dotnet test. ', 'commenter': 'zcsizmadia'}, {'comment': 'You can find useful info here: https://docs.microsoft.com/en-us/dotnet/core/testing/unit-testing-code-coverage?tabs=windows', 'commenter': 'zcsizmadia'}, {'comment': 'Please follow those recommendations', 'commenter': 'zcsizmadia'}, {'comment': 'There are absolutely no recommendations in this article.', 'commenter': 'KyleSchoonover'}, {'comment': 'I think it shows one way which is very usable for cross platforms. The way it is currently implemented, by calling the report generator from the user nuget packages folder will be very challenging form a UX point of view:\r\n\r\n1. The path will have the version in it, which has to be maintained.\r\n2. Linux vs Windows will be a potential UX issue as well\r\n\r\nI understand that we have different views on this, however I think the report generator should be used via global tool and only the codecoverage packages should be in the csproj file. It is a small change compared to what you have as of now. But will make a huge difference from supporting it on the long term.\r\n\r\n', 'commenter': 'zcsizmadia'}, {'comment': 'Here is some screenshots I referred to as a ""best practive:"""" from that link:\r\n\r\n![image](https://user-images.githubusercontent.com/8504099/157532339-89af80b6-7f5f-4c6c-a42c-a99eb12e8f0d.png)\r\n![image](https://user-images.githubusercontent.com/8504099/157532391-30642d87-545e-41a6-a449-abc40df99a55.png)\r\n![image](https://user-images.githubusercontent.com/8504099/157532635-b9d6311e-929e-4566-8ee2-10a7e2d7819a.png)\r\n\r\n', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/versions.props,"@@ -57,5 +57,8 @@
     <NUnitConsoleRunnerVersion>3.14.0</NUnitConsoleRunnerVersion>
     <NUnit3TestAdapterVersion>4.2.1</NUnit3TestAdapterVersion>
     <StyleCopAnalyzersVersion>1.1.118</StyleCopAnalyzersVersion>
+    <CoverletCollectorVersion>3.1.2</CoverletCollectorVersion>","[{'comment': 'Sort the list plz', 'commenter': 'zcsizmadia'}, {'comment': 'Alphabetical?  Would you also like me to make a comment in there to say that it should be sorted in a certain way?', 'commenter': 'KyleSchoonover'}, {'comment': 'sorted by package name plz in the Itemgroup', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/CODECOVERAGE.md,"@@ -0,0 +1,8 @@
+# C# Avro Code Coverage
+
+The following instructions should be followed in order to create a code coverage report locally.  Please note that this assumes you are running on Windows OS and that your local nuget cache is under you user profile.
+
+1. Open a command prompt
+2. Navigate to the test project `avro\lang\csharp\src\apache\test`
+3. Run the following test command `dotnet test --results-directory ./TestResults --collect:""XPlat Code Coverage""`","[{'comment': 'This could be more convenient and could be running all the time `dotnet test ...` is running by setting `CollectCoverage` to true and the other needed props in the csproj file', 'commenter': 'zcsizmadia'}]"
1565,lang/csharp/CODECOVERAGE.md,"@@ -0,0 +1,8 @@
+# C# Avro Code Coverage","[{'comment': 'misses Apache license header', 'commenter': 'martin-g'}, {'comment': '@KyleSchoonover It seems you resolved several comments from us without actually addressing them.', 'commenter': 'martin-g'}, {'comment': 'None of the other MD files have it. Are we sure we want to add it here?', 'commenter': 'KyleSchoonover'}]"
1569,lang/csharp/src/apache/main/Schema/ArraySchema.cs,"@@ -38,24 +38,27 @@ public class ArraySchema : UnnamedSchema
         /// <param name=""props"">dictionary that provides access to custom properties</param>
         /// <param name=""names"">list of named schemas already parsed</param>
         /// <param name=""encspace"">enclosing namespace for the array schema</param>
-        /// <returns></returns>
+        /// <returns>New instance of Array Schema</returns>
         internal static ArraySchema NewInstance(JToken jtok, PropertyMap props, SchemaNames names, string encspace)
         {
             JToken jitem = jtok[""items""];
-            if (null == jitem) throw new AvroTypeException($""Array does not have 'items' at '{jtok.Path}'"");
-            var schema = Schema.ParseJson(jitem, names, encspace);
+            if (jitem == null)
+            {
+                throw new AvroTypeException($""Array does not have 'items' at '{jtok.Path}'"");
+            }
+
+            Schema schema = Schema.ParseJson(jitem, names, encspace);
             return new ArraySchema(schema, props);
         }
 
         /// <summary>
-        /// Constructor
+        /// Initializes a new instance of the <see cref=""ArraySchema""/> class.
         /// </summary>
         /// <param name=""items"">schema for the array items type</param>
         /// <param name=""props"">dictionary that provides access to custom properties</param>
         private ArraySchema(Schema items, PropertyMap props) : base(Type.Array, props)
         {
-            if (null == items) throw new ArgumentNullException(nameof(items));","[{'comment': 'This exception is basically unreachable since the entry point is NewInstance', 'commenter': 'KyleSchoonover'}]"
1569,lang/csharp/src/apache/test/Schema/ArraySchemaTests.cs,"@@ -0,0 +1,37 @@
+using NUnit.Framework;","[{'comment': 'You need to add the license header at the top of this new file. See ArraySchema.cs for example', 'commenter': 'martin-g'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1569,lang/csharp/src/apache/test/Schema/ArraySchemaTests.cs,"@@ -0,0 +1,37 @@
+using NUnit.Framework;
+
+namespace Avro.test
+{
+    [TestFixture]
+    public class ArraySchemaTests
+    {
+        [Test]
+        public void EqualsNullCheck()
+        {
+            string schemaString = ""{\""type\"": \""array\"", \""items\"": \""long\""}"";
+            ArraySchema nullSchema = null;
+
+            Schema schema = Schema.Parse(schemaString);
+
+            if (schema is ArraySchema arraySchema)
+            {
+                Assert.False(arraySchema.Equals(nullSchema));
+            }
+            else
+            {
+                Assert.Fail(""Schema was not an Array Schema"");","[{'comment': '`Array Schema must not be equal to null` ?!', 'commenter': 'martin-g'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1571,lang/csharp/src/apache/test/Schema/SchemaTests.cs,"@@ -439,5 +439,57 @@ public void TestUnionSchemaWithoutTypeProperty(string schemaJson, string expecte
             var schema = Schema.Parse(schemaJson);
             Assert.AreEqual(schema.ToString(), expectedSchemaJson);
         }
+
+        [TestFixture]
+        public class SchemaTypeExtensionsTests
+        {
+            [TestCase(""null"", Schema.Type.Null)]
+            [TestCase(""boolean"", Schema.Type.Boolean)]
+            [TestCase(""int"", Schema.Type.Int)]
+            [TestCase(""long"", Schema.Type.Long)]
+            [TestCase(""float"", Schema.Type.Float)]
+            [TestCase(""double"", Schema.Type.Double)]
+            [TestCase(""bytes"", Schema.Type.Bytes)]
+            [TestCase(""string"", Schema.Type.String)]
+            [TestCase(""record"", Schema.Type.Record)]
+            [TestCase(""enumeration"", Schema.Type.Enumeration)]
+            [TestCase(""array"", Schema.Type.Array)]
+            [TestCase(""map"", Schema.Type.Map)]
+            [TestCase(""union"", Schema.Type.Union)]
+            [TestCase(""fixed"", Schema.Type.Fixed)]
+            [TestCase(""error"", Schema.Type.Error)]
+            [TestCase(""logical"", Schema.Type.Logical)]
+            [TestCase(""Logical"", null)]
+            [TestCase(""InvalidValue"", null)]
+            [TestCase(""\""null\"""", null)]
+            [TestCase("""", null)]
+            [TestCase(null, null)]
+            public void ParseTypeTest(string value, object expectedResult)","[{'comment': 'This might be a cleaner pattern:\r\n\r\n```\r\n        [TestCase(""null"", ExpectedResult = Schema.Type.Null)]\r\n        [TestCase(""boolean"", ExpectedResult = Schema.Type.Boolean)]\r\n        ...\r\n        [TestCase(""\\""null\\"""", ExpectedResult = null)]\r\n        [TestCase("""", ExpectedResult = null)]\r\n        public Schema.Type? ParseTypeTest(string value)\r\n        {\r\n            return Schema.ParseType(value);\r\n        }\r\n```\r\n', 'commenter': 'zcsizmadia'}, {'comment': 'Using the existing pattern.  If we want to change the pattern I would recommend a separate story with subtasks to update all the existing test files.', 'commenter': 'KyleSchoonover'}, {'comment': 'The same as below', 'commenter': 'zcsizmadia'}]"
1571,lang/csharp/src/apache/test/Schema/SchemaTests.cs,"@@ -439,5 +439,57 @@ public void TestUnionSchemaWithoutTypeProperty(string schemaJson, string expecte
             var schema = Schema.Parse(schemaJson);
             Assert.AreEqual(schema.ToString(), expectedSchemaJson);
         }
+
+        [TestFixture]
+        public class SchemaTypeExtensionsTests
+        {
+            [TestCase(""null"", Schema.Type.Null)]
+            [TestCase(""boolean"", Schema.Type.Boolean)]
+            [TestCase(""int"", Schema.Type.Int)]
+            [TestCase(""long"", Schema.Type.Long)]
+            [TestCase(""float"", Schema.Type.Float)]
+            [TestCase(""double"", Schema.Type.Double)]
+            [TestCase(""bytes"", Schema.Type.Bytes)]
+            [TestCase(""string"", Schema.Type.String)]
+            [TestCase(""record"", Schema.Type.Record)]
+            [TestCase(""enumeration"", Schema.Type.Enumeration)]
+            [TestCase(""array"", Schema.Type.Array)]
+            [TestCase(""map"", Schema.Type.Map)]
+            [TestCase(""union"", Schema.Type.Union)]
+            [TestCase(""fixed"", Schema.Type.Fixed)]
+            [TestCase(""error"", Schema.Type.Error)]
+            [TestCase(""logical"", Schema.Type.Logical)]
+            [TestCase(""Logical"", null)]
+            [TestCase(""InvalidValue"", null)]
+            [TestCase(""\""null\"""", null)]
+            [TestCase("""", null)]
+            [TestCase(null, null)]
+            public void ParseTypeTest(string value, object expectedResult)
+            {
+                if (expectedResult is Schema.Type expectedType)
+                {
+                    Assert.AreEqual(Schema.ParseType(value), expectedType);
+                }
+                else
+                {
+                    Assert.AreEqual(Schema.ParseType(value), expectedResult);
+                }
+            }
+
+            [TestCase(""\""null\"""", Schema.Type.Null)]
+            [TestCase(""\""nu\""ll\"""", null)]
+            [TestCase(""\""\"""", null)]
+            public void ParseTypeRemoveQuotesTest(string value, object expectedResult)","[{'comment': '```\r\n        [TestCase(""\\""null\\"""", ExpectedResult = Schema.Type.Null)]\r\n        [TestCase(""\\""nu\\""ll\\"""", ExpectedResult = null)]\r\n        [TestCase(""\\""\\"""", ExpectedResult = null)]\r\n        public Schema.Type? ParseTypeRemoveQuotesTest(string value)\r\n        {\r\n            return Schema.ParseType(value, true);\r\n        }\r\n```', 'commenter': 'zcsizmadia'}, {'comment': 'Using the existing pattern.  If we want to change the pattern I would recommend a separate story with subtasks to update all the existing test files.', 'commenter': 'KyleSchoonover'}, {'comment': 'In this case keeping previous patterns dont really matter. The test code iotself seems to me over complicated. I really do prefer to use good patterns where it can live side by side with existing code patterns', 'commenter': 'zcsizmadia'}, {'comment': 'I am not sure why, but my github showed this resolved and it should not. I might have clicked the wrong button.', 'commenter': 'zcsizmadia'}, {'comment': 'Again, If we are changing the testing pattern of how the cases are set up, I would rather it be a separate PR.', 'commenter': 'KyleSchoonover'}, {'comment': 'This test is too compliacted as it is since it ahoild be a one liner. Please make the changes. If hou see where unit tests can be clarified more and there is a advantage to rework existing tests, that is absolutely fine. However new code should be optimal IMO.', 'commenter': 'zcsizmadia'}, {'comment': ""Now I see what you were saying.  It's been a while since I could trust a test frameworks Equals method."", 'commenter': 'KyleSchoonover'}]"
1571,lang/csharp/src/apache/main/Schema/Schema.cs,"@@ -380,5 +381,73 @@ protected static int getHashCode(object obj)
         {
             return obj == null ? 0 : obj.GetHashCode();
         }
+
+        /// <summary>
+        /// Parses the Schema.Type from a string.
+        /// </summary>
+        /// <param name=""type"">The type to convert.</param>
+        /// <param name=""removeQuotes"">if set to <c>true</c> [remove quotes].</param>
+        /// <returns>A Schema.Type unless it could not parse then null</returns>
+        /// <remarks>
+        /// usage ParseType(""string"") returns Schema.Type.String
+        /// </remarks>
+        public static Schema.Type? ParseType(string type, bool removeQuotes = false)
+        {
+            string newValue = removeQuotes ? type.Trim('""') : type;","[{'comment': 'Should this only be removing exactly 1 `""` from each side?\r\n`""""""bool""""""""""""""""""""""""""""""""""""` would be a correct input. I am not sure the remove Quotes option belongs  here', 'commenter': 'zcsizmadia'}, {'comment': '@martin-g This should be addressed before merging', 'commenter': 'zcsizmadia'}, {'comment': 'Updated', 'commenter': 'KyleSchoonover'}]"
1571,lang/csharp/src/apache/main/Schema/Schema.cs,"@@ -380,5 +381,91 @@ protected static int getHashCode(object obj)
         {
             return obj == null ? 0 : obj.GetHashCode();
         }
+
+        /// <summary>
+        /// Parses the Schema.Type from a string.
+        /// </summary>
+        /// <param name=""type"">The type to convert.</param>
+        /// <param name=""removeQuotes"">if set to <c>true</c> [remove quotes].</param>
+        /// <returns>A Schema.Type unless it could not parse then null</returns>
+        /// <remarks>
+        /// usage ParseType(""string"") returns Schema.Type.String
+        /// </remarks>
+        public static Schema.Type? ParseType(string type, bool removeQuotes = false)
+        {
+            string newValue = removeQuotes ? RemoveQuotes(type) : type;
+
+            switch (newValue)
+            {
+                case ""null"":
+                    return Schema.Type.Null;
+
+                case ""boolean"":
+                    return Schema.Type.Boolean;
+
+                case ""int"":
+                    return Schema.Type.Int;
+
+                case ""long"":
+                    return Schema.Type.Long;
+
+                case ""float"":
+                    return Schema.Type.Float;
+
+                case ""double"":
+                    return Schema.Type.Double;
+
+                case ""bytes"":
+                    return Schema.Type.Bytes;
+
+                case ""string"":
+                    return Schema.Type.String;
+
+                case ""record"":
+                    return Schema.Type.Record;
+
+                case ""enumeration"":","[{'comment': 'I am surprised that this is ""enumeration"", rather than ""enum"" like in <https://avro.apache.org/docs/current/spec.html#Enums>.', 'commenter': 'KalleOlaviNiemitalo'}]"
1582,lang/rust/avro/src/types.rs,"@@ -1323,4 +1326,236 @@ mod tests {
             JsonValue::String(""936da01f-9abd-4d9d-80c7-02af85c822a8"".into())
         );
     }
+
+    #[test]
+    fn test_recursive_resolves() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"":""Inner""
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(),Value::Int(6))]);
+        let outer = Value::Record(vec![(""a"".into(),inner_value1.clone()), (""b"".into(), inner_value2.clone())]);
+        outer.resolve(&schema).expect(""Record definition defined in one field must be availible in other field"");
+    }
+
+    #[test]
+    fn test_recursive_resolves2() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""array"",
+                        ""items"": {
+                            ""type"":""record"",
+                            ""name"": ""Inner"",
+                            ""fields"": [ {
+                                ""name"":""z"",
+                                ""type"":""int""
+                            }]
+                        }
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""map"",
+                        ""values"":""Inner""
+                    }
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(),Value::Int(6))]);
+        let outer_value = Value::Record(
+            vec![
+                (""a"".into(), Value::Array(vec![inner_value1.clone()])),
+                (""b"".into(), Value::Map(vec![(""akey"".into(),inner_value2.clone())].into_iter().collect()))
+                ]
+            );
+        outer_value.resolve(&schema).expect(""Record defined in array definition must be resolveable from map"");
+    }
+
+    #[test]
+    fn test_recursive_resolves3() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""map"",
+                        ""values"":""Inner""
+                    }
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(),Value::Int(6))]);
+        let outer_value = Value::Record(
+            vec![
+                (""a"".into(), inner_value1.clone()),
+                (""b"".into(), Value::Map(vec![(""akey"".into(),inner_value2.clone())
+                ]
+                .into_iter().collect()))
+                ]
+            );
+        outer_value.resolve(&schema).expect(""Record defined in record field must be resolvable from map field"");
+    }
+
+    #[test]
+    fn test_recursive_resolves4() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""record"",
+                        ""name"": ""InnerWrapper"",
+                        ""fields"": [ {
+                            ""name"":""j"",
+                            ""type"":""Inner""
+                        }]
+                    }
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""j"".into(), Value::Record(vec![(""z"".into(),Value::Int(6))]))]);
+        let outer_value = Value::Record(
+            vec![
+                (""a"".into(), inner_value1.clone()),
+                (""b"".into(), inner_value2.clone())
+                ]
+            );
+        outer_value.resolve(&schema).expect(""Record schema defined in field must be resolvable in Record schema defined in other field"");
+    }
+
+    #[test]
+    fn test_recursive_resolves5() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""map"",
+                        ""values"": {
+                            ""type"":""record"",
+                            ""name"": ""Inner"",
+                            ""fields"": [ {
+                                ""name"":""z"",
+                                ""type"":""int""
+                            }]
+                        }
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""array"",
+                        ""items"":""Inner""
+                    }
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(),Value::Int(6))]);
+        let outer_value = Value::Record(
+            vec![
+                (""a"".into(), Value::Map(vec![(""akey"".into(),inner_value2.clone())].into_iter().collect())),
+                (""b"".into(), Value::Array(vec![inner_value1.clone()])) 
+                ]
+            );
+        outer_value.resolve(&schema).expect(""Record defined in map definition must be resolveable from array"");
+    }
+
+    #[test]
+    fn test_recursive_resolves6() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":[""null"", {
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }]
+                },
+                {
+                    ""name"":""b"",
+                    ""type"":""Inner""
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(),Value::Int(6))]);
+        let outer1 = Value::Record(vec![(""a"".into(),inner_value1.clone()), (""b"".into(), inner_value2.clone())]);
+        outer1.resolve(&schema).expect(""Record definition defined in union must be resolvabled in other field"");
+        let outer2 = Value::Record(vec![(""a"".into(), Value::Null), (""b"".into(), inner_value2.clone())]);
+        outer2.resolve(&schema).expect(""Record definition defined in union must be resolvabled in other field"");","[{'comment': 'This still fails.', 'commenter': 'jklamer'}, {'comment': 'OK. I will try to take a look soon!', 'commenter': 'martin-g'}]"
1582,lang/rust/avro/src/types.rs,"@@ -1323,4 +1326,236 @@ mod tests {
             JsonValue::String(""936da01f-9abd-4d9d-80c7-02af85c822a8"".into())
         );
     }
+
+    #[test]
+    fn test_recursive_resolves() {
+        let schema  = Schema::parse_str(r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"":""Inner""
+                }
+            ]
+        }""#).unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(),Value::Int(3))]);","[{'comment': 'Please run `cargo fmt --all`', 'commenter': 'martin-g'}, {'comment': 'I did it!', 'commenter': 'martin-g'}]"
1582,lang/rust/avro/src/types.rs,"@@ -1323,4 +1326,236 @@ mod tests {
             JsonValue::String(""936da01f-9abd-4d9d-80c7-02af85c822a8"".into())
         );
     }
+
+    #[test]
+    fn test_recursive_resolves() {","[{'comment': 'Please create a new ticket in JIRA and name the test cases like `test_avro_XXXX_recursive_resolves`', 'commenter': 'martin-g'}, {'comment': 'Done!', 'commenter': 'martin-g'}]"
1582,lang/rust/avro/src/types.rs,"@@ -1323,4 +1356,269 @@ mod tests {
             JsonValue::String(""936da01f-9abd-4d9d-80c7-02af85c822a8"".into())
         );
     }
+
+    #[test]
+    fn test_recursive_resolves() {
+        let schema = Schema::parse_str(
+            r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"":""Inner""
+                }
+            ]
+        }""#,
+        )
+        .unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(), Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(), Value::Int(6))]);
+        let outer = Value::Record(vec![(""a"".into(), inner_value1), (""b"".into(), inner_value2)]);
+        outer
+            .resolve(&schema)
+            .expect(""Record definition defined in one field must be availible in other field"");
+    }
+
+    #[test]
+    fn test_recursive_resolves2() {
+        let schema = Schema::parse_str(
+            r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""array"",
+                        ""items"": {
+                            ""type"":""record"",
+                            ""name"": ""Inner"",
+                            ""fields"": [ {
+                                ""name"":""z"",
+                                ""type"":""int""
+                            }]
+                        }
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""map"",
+                        ""values"":""Inner""
+                    }
+                }
+            ]
+        }""#,
+        )
+        .unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(), Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(), Value::Int(6))]);
+        let outer_value = Value::Record(vec![
+            (""a"".into(), Value::Array(vec![inner_value1])),
+            (
+                ""b"".into(),
+                Value::Map(vec![(""akey"".into(), inner_value2)].into_iter().collect()),
+            ),
+        ]);
+        outer_value
+            .resolve(&schema)
+            .expect(""Record defined in array definition must be resolveable from map"");
+    }
+
+    #[test]
+    fn test_recursive_resolves3() {
+        let schema = Schema::parse_str(
+            r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""map"",
+                        ""values"":""Inner""
+                    }
+                }
+            ]
+        }""#,
+        )
+        .unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(), Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(), Value::Int(6))]);
+        let outer_value = Value::Record(vec![
+            (""a"".into(), inner_value1),
+            (
+                ""b"".into(),
+                Value::Map(vec![(""akey"".into(), inner_value2)].into_iter().collect()),
+            ),
+        ]);
+        outer_value
+            .resolve(&schema)
+            .expect(""Record defined in record field must be resolvable from map field"");
+    }
+
+    #[test]
+    fn test_recursive_resolves4() {
+        let schema = Schema::parse_str(
+            r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""record"",
+                        ""name"": ""InnerWrapper"",
+                        ""fields"": [ {
+                            ""name"":""j"",
+                            ""type"":""Inner""
+                        }]
+                    }
+                }
+            ]
+        }""#,
+        )
+        .unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(), Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(
+            ""j"".into(),
+            Value::Record(vec![(""z"".into(), Value::Int(6))]),
+        )]);
+        let outer_value =
+            Value::Record(vec![(""a"".into(), inner_value1), (""b"".into(), inner_value2)]);
+        outer_value.resolve(&schema).expect(""Record schema defined in field must be resolvable in Record schema defined in other field"");
+    }
+
+    #[test]
+    fn test_recursive_resolves5() {
+        let schema = Schema::parse_str(
+            r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":{
+                        ""type"":""map"",
+                        ""values"": {
+                            ""type"":""record"",
+                            ""name"": ""Inner"",
+                            ""fields"": [ {
+                                ""name"":""z"",
+                                ""type"":""int""
+                            }]
+                        }
+                    }
+                },
+                {
+                    ""name"":""b"",
+                    ""type"": {
+                        ""type"":""array"",
+                        ""items"":""Inner""
+                    }
+                }
+            ]
+        }""#,
+        )
+        .unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(), Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(), Value::Int(6))]);
+        let outer_value = Value::Record(vec![
+            (
+                ""a"".into(),
+                Value::Map(vec![(""akey"".into(), inner_value2)].into_iter().collect()),
+            ),
+            (""b"".into(), Value::Array(vec![inner_value1])),
+        ]);
+        outer_value
+            .resolve(&schema)
+            .expect(""Record defined in map definition must be resolveable from array"");
+    }
+
+    #[test]
+    fn test_recursive_resolves6() {
+        let schema = Schema::parse_str(
+            r#""
+        {
+            ""type"":""record"",
+            ""name"":""TestStruct"",
+            ""fields"": [
+                {
+                    ""name"":""a"",
+                    ""type"":[""null"", {
+                        ""type"":""record"",
+                        ""name"": ""Inner"",
+                        ""fields"": [ {
+                            ""name"":""z"",
+                            ""type"":""int""
+                        }]
+                    }]
+                },
+                {
+                    ""name"":""b"",
+                    ""type"":""Inner""
+                }
+            ]
+        }""#,
+        )
+        .unwrap();
+
+        let inner_value1 = Value::Record(vec![(""z"".into(), Value::Int(3))]);
+        let inner_value2 = Value::Record(vec![(""z"".into(), Value::Int(6))]);
+        let outer1 = Value::Record(vec![
+            (""a"".into(), inner_value1),
+            (""b"".into(), inner_value2.clone()),
+        ]);
+        outer1
+            .resolve(&schema)
+            .expect(""Record definition defined in union must be resolvabled in other field"");
+        let outer2 = Value::Record(vec![(""a"".into(), Value::Null), (""b"".into(), inner_value2)]);","[{'comment': 'The test fails because `a`s value is `Null` and there is no way to resolve the `Inner` type from it, so it is not known when `b` asks for it.', 'commenter': 'martin-g'}, {'comment': ""Won't all named elements of the schema need to be visited (depth-first, left-to-right) by `resolve`, regardless of whether they're used in resolution, in order for `resolve` to work properly with references?"", 'commenter': 'travisbrown'}, {'comment': 'Please check https://github.com/apache/avro/pull/1582/commits/09c2cb7bd1a75f65ef359751ff0937987d07b43d\r\nIt solves the current issue.', 'commenter': 'martin-g'}, {'comment': ""@martin-g Thanks! That does seem to resolve the resolution issue for me. I'm now running into what I think is a similar problem during encoding while writing: it's crashing on [this `unwrap`](https://github.com/apache/avro/blob/44b8cd23756b752bf9d0976574453c712dcd44d9/lang/rust/avro/src/encode.rs#L62). I haven't looked closely, but it seems like exactly the same issue (if the value hasn't required the part of the schema with the definition to be looked at, the reference lookup fails).\r\n\r\nIn the longer term do you think it might be better to carry around the name-definition hash map in the schema, rather than having to rebuild it for each item in multiple places?"", 'commenter': 'travisbrown'}, {'comment': ""I will improve it now!\r\n\r\n\r\n> In the longer term do you think it might be better to carry around the name-definition hash map in the schema, rather than having to rebuild it for each item in multiple places?\r\n\r\nLet's merge this PR once all the issues are fixed and then you or @jklamer can send a PR to re-work it the way you imagine. @jklamer also mentioned something similar at https://github.com/apache/avro/pull/1582#issuecomment-1060137762"", 'commenter': 'martin-g'}, {'comment': '@travisbrown Should be fixed with https://github.com/apache/avro/pull/1582/commits/bd34804227c1da228595ff7b5a1f148944749ae9. Please try again!', 'commenter': 'martin-g'}, {'comment': ""That seems to be working! Thanks again! I'll spend some more time with it tomorrow."", 'commenter': 'travisbrown'}, {'comment': 'Great!\r\n\r\n@jklamer If you have time and desire please add some tests for encode.rs for the last fix, similar to the ones you added to types.rs.\r\nIt is late here. \r\nThanks in advance!', 'commenter': 'martin-g'}]"
1583,lang/csharp/src/apache/codegen/AvroGen.cs,"@@ -39,6 +40,13 @@ static int Main(string[] args)
                 return 0;
             }
 
+            if (args.Contains(""--version""))","[{'comment': 'Is the expectation to also support -V? `args.Any(a => a is ""--version"" or ""-V"")` <-- Apparently this is only C# 8\r\n`if (args.Contains(""--version"") || args.Contains(""-V"") )`', 'commenter': 'KyleSchoonover'}, {'comment': 'Good catch. I added -V to the cpp avrogen and I intended to add for C# as well.', 'commenter': 'zcsizmadia'}]"
1597,lang/csharp/src/apache/main/Schema/Aliases.cs,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System;
+using System.Collections.Generic;","[{'comment': 'Can you remove and sort usings.  Assuming you are using VS.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/Aliases.cs,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro
+{
+    internal static class Aliases
+    {
+        internal static IList<SchemaName> GetSchemaNames(IEnumerable<string> aliases, string enclosingTypeName, string enclosingTypeNamespace)
+        {
+            if (aliases == null)","[{'comment': 'Can you add brackets?', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/Aliases.cs,"@@ -0,0 +1,35 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+using System;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro
+{
+    internal static class Aliases
+    {
+        internal static IList<SchemaName> GetSchemaNames(IEnumerable<string> aliases, string enclosingTypeName, string enclosingTypeNamespace)
+        {
+            if (aliases == null)
+                return null;
+
+            var enclosingSchemaName = new SchemaName(enclosingTypeName, enclosingTypeNamespace, null, null);","[{'comment': 'Can you replace var with the actual name of the object?', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/ArraySchema.cs,"@@ -48,11 +48,12 @@ internal static ArraySchema NewInstance(JToken jtok, PropertyMap props, SchemaNa
         }
 
         /// <summary>
-        /// Constructor
+        /// Initializes a new instance of the <see cref=""ArraySchema""/> class.
         /// </summary>
-        /// <param name=""items"">schema for the array items type</param>
-        /// <param name=""props"">dictionary that provides access to custom properties</param>
-        private ArraySchema(Schema items, PropertyMap props) : base(Type.Array, props)
+        /// <param name=""items"">schema for the array items type.</param>
+        /// <param name=""customAttributes"">dictionary that provides access to custom properties.</param>
+        public ArraySchema(Schema items, PropertyMap customAttributes = null)","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"".  I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -47,6 +48,33 @@ public class EnumSchema : NamedSchema
         /// </summary>
         public int Count { get { return Symbols.Count; } }
 
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""EnumSchema""/> class.
+        /// </summary>
+        /// <param name=""name"">name of enum.</param>
+        /// <param name=""space"">namespace of enum.</param>
+        /// <param name=""aliases"">list of aliases for the name.</param>
+        /// <param name=""symbols"">list of enum symbols.</param>
+        /// <param name=""customProperties"">custom properties on this schema.</param>
+        /// <param name=""doc"">documentation for this named schema.</param>
+        /// <param name=""defaultSymbol""></param>
+        public EnumSchema(string name,","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"".  I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}, {'comment': ""NewInstance is internal, and it's more of a deserializer than an object creator, it contains a lot of logic. I can change the public constructors to a factory method (how should I call it?), is that the 'interface' we want the schema classes to expose? I think constructor is a bit more convenient to use. "", 'commenter': 'yanivru'}]"
1597,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -112,6 +140,21 @@ internal static EnumSchema NewInstance(JToken jtok, PropertyMap props, SchemaNam
             Default = defaultSymbol;
         }
 
+        private static IDictionary<string, int> CreateSymbolsMap(IEnumerable<string> symbols)
+        {
+            IDictionary<string, int> symbolMap = new Dictionary<string, int>();
+            int i = 0;
+            foreach (var symbol in symbols)
+            {
+                if (symbolMap.ContainsKey(symbol))","[{'comment': 'Add brackets', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/EnumSchema.cs,"@@ -112,6 +140,21 @@ internal static EnumSchema NewInstance(JToken jtok, PropertyMap props, SchemaNam
             Default = defaultSymbol;
         }
 
+        private static IDictionary<string, int> CreateSymbolsMap(IEnumerable<string> symbols)","[{'comment': 'Document usage and exception case in method summary, params, and exceptions', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/Field.cs,"@@ -105,6 +105,29 @@ public enum SortOrder
         /// </summary>
         internal static JTokenEqualityComparer JtokenEqual = new JTokenEqualityComparer();
 
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""Field""/> class.
+        /// </summary>
+        /// <param name=""schema"">schema for the field type.</param>
+        /// <param name=""name"">name of the field.</param>
+        /// <param name=""aliases"">list of aliases for the name of the field.</param>
+        /// <param name=""pos"">position of the field.</param>
+        /// <param name=""doc"">documentation for the field.</param>
+        /// <param name=""defaultValue"">field's default value if it exists.</param>
+        /// <param name=""sortorder"">sort order of the field.</param>
+        /// <param name=""customProperties"">dictionary that provides access to custom properties.</param>
+        public Field(Schema schema,","[{'comment': ""Is there a reason you didn't modify the existing constructor?"", 'commenter': 'KyleSchoonover'}, {'comment': ""I wanted to add default values to non mandatory parameters. I had to change their order (switch between aliases and pos), and didn't want to make a breaking change."", 'commenter': 'yanivru'}]"
1597,lang/csharp/src/apache/main/Schema/FixedSchema.cs,"@@ -32,6 +32,20 @@ public class FixedSchema : NamedSchema
         /// </summary>
         public int Size { get; set; }
 
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""FixedSchema""/> class.
+        /// </summary>
+        /// <param name=""name"">name of the fixed schema</param>
+        /// <param name=""aliases"">list of aliases for the name</param>
+        /// <param name=""size"">fixed size</param>
+        /// <param name=""space"">namespace of fixed</param>
+        /// <param name=""customProperties"">custom properties on this schema</param>
+        /// <param name=""doc"">documentation for this named schema</param>
+        public FixedSchema(string name, int size, string space = null, IEnumerable<string> aliases = null, PropertyMap customProperties = null, string doc = null)","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"". I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/MapSchema.cs,"@@ -68,8 +68,9 @@ internal static MapSchema NewInstance(JToken jtok, PropertyMap props, SchemaName
         /// Constructor for map schema class
         /// </summary>
         /// <param name=""valueSchema"">schema for map values type</param>
-        /// <param name=""props"">dictionary that provides access to custom properties</param>
-        private MapSchema(Schema valueSchema, PropertyMap props) : base(Type.Map, props)
+        /// <param name=""cutsomProperties"">dictionary that provides access to custom properties</param>
+        public MapSchema(Schema valueSchema, PropertyMap cutsomProperties = null)","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"". I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/PrimitiveSchema.cs,"@@ -17,6 +17,8 @@
  */
 using System;
 using System.Linq;
+using System.Collections.Generic;","[{'comment': 'Remove and sort usings', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/PrimitiveSchema.cs,"@@ -30,8 +32,9 @@ public sealed class PrimitiveSchema : UnnamedSchema
         /// Constructor for primitive schema
         /// </summary>
         /// <param name=""type""></param>
-        /// <param name=""props"">dictionary that provides access to custom properties</param>
-        private PrimitiveSchema(Type type, PropertyMap props) : base(type, props)
+        /// <param name=""customProperties"">dictionary that provides access to custom properties</param>
+        public PrimitiveSchema(Type type, PropertyMap customProperties = null)","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"". I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -28,10 +29,28 @@ namespace Avro
     /// </summary>
     public class RecordSchema : NamedSchema
     {
+        private List<Field> fields;","[{'comment': 'rename _fields', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -28,10 +29,28 @@ namespace Avro
     /// </summary>
     public class RecordSchema : NamedSchema
     {
+        private List<Field> fields;
+
         /// <summary>
         /// List of fields in the record
         /// </summary>
-        public List<Field> Fields { get; private set; }
+        public List<Field> Fields
+        {
+            get
+            {
+                return fields;
+            }
+
+            set
+            {
+                VerifyFieldsPositions(value);","[{'comment': ""We shouldn't throw exceptions in properties"", 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -41,11 +60,111 @@ public class RecordSchema : NamedSchema
         /// <summary>
         /// Map of field name and Field object for faster field lookups
         /// </summary>
-        private readonly IDictionary<string, Field> fieldLookup;
+        private IDictionary<string, Field> fieldLookup;
 
-        private readonly IDictionary<string, Field> fieldAliasLookup;
+        private IDictionary<string, Field> fieldAliasLookup;
         private bool request;
 
+        /// <summary>
+        /// Constructor for the record schema
+        /// </summary>
+        /// <param name=""name"">name of the record schema</param>
+        /// <param name=""fields"">list of fields for the record</param>
+        /// <param name=""space"">type of record schema, either record or error</param>
+        /// <param name=""aliases"">list of aliases for the record name</param>
+        /// <param name=""customProperties"">custom properties on this schema</param>
+        /// <param name=""doc"">documentation for this named schema</param>
+        public RecordSchema(string name,","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"". I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/RecordSchema.cs,"@@ -165,10 +284,19 @@ private static Field createField(JToken jfield, int pos, SchemaNames names, stri
         private static void addToFieldMap(Dictionary<string, Field> map, string name, Field field)
         {
             if (map.ContainsKey(name))
-                throw new SchemaParseException(""field or alias "" + name + "" is a duplicate name"");
+                throw new AvroException(""field or alias "" + name + "" is a duplicate name"");","[{'comment': ""Don't change exception type.  Potentially breaking.  You would want to mark the old method obsolete and recreate with new exception type."", 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -20,6 +20,7 @@
 using System.Text;
 using Newtonsoft.Json.Linq;
 using Newtonsoft.Json;
+using System.Linq;","[{'comment': 'Remove and sort usings', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -71,11 +72,13 @@ internal static UnionSchema NewInstance(JArray jarr, PropertyMap props, SchemaNa
         /// Contructor for union schema
         /// </summary>
         /// <param name=""schemas""></param>
-        /// <param name=""props"">dictionary that provides access to custom properties</param>
-        private UnionSchema(List<Schema> schemas, PropertyMap props) : base(Type.Union, props)
+        /// <param name=""customProperties"">dictionary that provides access to custom properties</param>
+        public UnionSchema(List<Schema> schemas, PropertyMap customProperties = null)","[{'comment': 'Schema classes already use a Factory pattern method ""NewInstance"". I would recommend following the same pattern than exposing the constructor.', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -161,5 +164,17 @@ public override int GetHashCode()
             result += getHashCode(Props);
             return result;
         }
+
+        private void VerifyChildSchemas(List<Schema> schemas)
+        {
+            if (schemas.Any(schema => schema.Tag == Type.Union))
+                throw new ArgumentException(""Unions may not immediately contain other unions"", nameof(schemas));","[{'comment': 'Add brackets', 'commenter': 'KyleSchoonover'}, {'comment': 'Update wording.  May seems optional.  ""Unions can not...""', 'commenter': 'KyleSchoonover'}, {'comment': ""I took that expression from the avro documentation. I believe it's better to be in sync with the documentation (https://avro.apache.org/docs/current/spec.html#Unions)."", 'commenter': 'yanivru'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -161,5 +164,17 @@ public override int GetHashCode()
             result += getHashCode(Props);
             return result;
         }
+
+        private void VerifyChildSchemas(List<Schema> schemas)
+        {
+            if (schemas.Any(schema => schema.Tag == Type.Union))
+                throw new ArgumentException(""Unions may not immediately contain other unions"", nameof(schemas));
+
+            var groupedByFullNames = schemas.GroupBy(schema => schema.Fullname);
+            IGrouping<string, Schema> duplicateType = groupedByFullNames.FirstOrDefault(x => x.Count() > 1);
+
+            if (duplicateType != null)
+                throw new ArgumentException($""Duplicate type in union: {duplicateType.Key}"");","[{'comment': 'add brackets', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -161,5 +164,17 @@ public override int GetHashCode()
             result += getHashCode(Props);
             return result;
         }
+
+        private void VerifyChildSchemas(List<Schema> schemas)
+        {
+            if (schemas.Any(schema => schema.Tag == Type.Union))
+                throw new ArgumentException(""Unions may not immediately contain other unions"", nameof(schemas));
+
+            var groupedByFullNames = schemas.GroupBy(schema => schema.Fullname);","[{'comment': 'replace var with actual type', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -161,5 +164,17 @@ public override int GetHashCode()
             result += getHashCode(Props);
             return result;
         }
+
+        private void VerifyChildSchemas(List<Schema> schemas)","[{'comment': 'Document parameters and exception cases', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/main/Schema/UnionSchema.cs,"@@ -161,5 +164,17 @@ public override int GetHashCode()
             result += getHashCode(Props);
             return result;
         }
+
+        private void VerifyChildSchemas(List<Schema> schemas)
+        {
+            if (schemas.Any(schema => schema.Tag == Type.Union))
+                throw new ArgumentException(""Unions may not immediately contain other unions"", nameof(schemas));
+
+            var groupedByFullNames = schemas.GroupBy(schema => schema.Fullname);
+            IGrouping<string, Schema> duplicateType = groupedByFullNames.FirstOrDefault(x => x.Count() > 1);
+
+            if (duplicateType != null)","[{'comment': 'You can move your linq statement into the if.  There is no reason to create a variable that is not used in another place.', 'commenter': 'KyleSchoonover'}, {'comment': ""It cannot be moved, I am calculating 'duplicateType' in the linq and checking it's value in the if statement."", 'commenter': 'yanivru'}, {'comment': '```\r\nIGrouping<string, Schema> duplicateType = schemas.GroupBy(schema => schema.Fullname).FirstOrDefault(x => x.Count() > 1);\r\n\r\n            if (duplicateType != null)\r\n            {\r\n                throw new ArgumentException($""Duplicate type in union: {duplicateType.Key}"");\r\n            }\r\n```', 'commenter': 'KyleSchoonover'}]"
1597,lang/csharp/src/apache/test/Schema/SchemaTests.cs,"@@ -290,13 +292,99 @@ public void TestRecordDoc(string s, string expectedDoc)
             Assert.AreEqual(expectedDoc, roundTrip.Documentation);
         }
 
-        [TestCase(""{\""type\"": \""enum\"", \""name\"": \""Test\"", \""symbols\"": [\""A\"", \""B\""]}"",
+        [TestCase]
+        public void TestRecordCreation()","[{'comment': 'other test cases would be useful with some expected result test parameter as well.', 'commenter': 'zcsizmadia'}]"
1605,lang/csharp/src/apache/main/CodeGen/CodeGenUtil.cs,"@@ -132,5 +144,21 @@ public string UnMangle(string name)
                     builder.Append(name[i]);
             return builder.ToString();
         }
+
+        private CodeAttributeDeclaration GetGeneratedCodeAttribute()
+        {
+            GeneratedCodeAttribute generatedCodeAttribute =
+            new GeneratedCodeAttribute(System.AppDomain.CurrentDomain.FriendlyName,
+            System.Reflection.Assembly.GetExecutingAssembly().GetName().Version.ToString());","[{'comment': 'These two lines should be indented.', 'commenter': 'martin-g'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1605,lang/csharp/src/apache/main/CodeGen/CodeGenUtil.cs,"@@ -132,5 +144,21 @@ public string UnMangle(string name)
                     builder.Append(name[i]);
             return builder.ToString();
         }
+
+        private CodeAttributeDeclaration GetGeneratedCodeAttribute()
+        {
+            GeneratedCodeAttribute generatedCodeAttribute =
+            new GeneratedCodeAttribute(System.AppDomain.CurrentDomain.FriendlyName,
+            System.Reflection.Assembly.GetExecutingAssembly().GetName().Version.ToString());
+
+            CodeAttributeDeclaration codeAttributeDeclaration =
+            new CodeAttributeDeclaration(generatedCodeAttribute.GetType().Name,","[{'comment': 'Same here', 'commenter': 'martin-g'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1605,lang/csharp/src/apache/main/CodeGen/CodeGenUtil.cs,"@@ -132,5 +144,21 @@ public string UnMangle(string name)
                     builder.Append(name[i]);
             return builder.ToString();
         }
+
+        private CodeAttributeDeclaration GetGeneratedCodeAttribute()","[{'comment': 'Please confirm that the generated attribute in the source code would look like:\r\n`[global::System.CodeDom.Compiler.GeneratedCode(""..."", ""..."")]`', 'commenter': 'zcsizmadia'}, {'comment': 'It uses `[GeneratedCodeAttribute(""avrogen"", ""1.12.0.0"")]`  Why exactly, would you want to use global in this case?', 'commenter': 'KyleSchoonover'}, {'comment': '1. Unfortunately `1.12.0-rc.1`, `1.12.0-rc.2` and `1.12.0` will be shown as `1.12.0.0`. Which seems to be incorrect behavior. Please change it to the full version\r\n2. Namespaces are getting tricky, especially with the latest global usings. It is preferred to use `::global` just to avoid any issue if someone  is implementing its own `GeneratedCodeAttribute`. E.g. Google protobuf is doing the same.', 'commenter': 'zcsizmadia'}, {'comment': '1.  A little unsure on how to get the updated versioning, since this is how the project has been configured as well as the version is the same one we use in the ` <auto-generated>` header. `System.Reflection.Assembly.GetExecutingAssembly().GetName().Version`\r\n2. Added `global::` Which is just odd to me since this used to be a big thing not to do with things under System.  I know there are changes to support how .Net 6 is doing things, which means a lot more global usings.', 'commenter': 'KyleSchoonover'}, {'comment': 'Get the InformationalVersion attribute for the full version. IMO the FileVersion or AssembleVersion are pretty much useless, since it does not support SemVer. Since this project supports pre-release label, we should use it. I would even change it in the header comments, since that version does not reflect the real version (if pre-released). I understand that pre-release version is not pushed to nuget, however it is released in github,\r\n\r\nIMO using the proper and full  version makes your life easier when you implement the unit tests. E.g. whatever avrogen --version returns, should be the version tag written in the cs file. Otherwise it is confusing for the end user if avrogen --version returns something different than the version tag written in the generated cs file', 'commenter': 'zcsizmadia'}, {'comment': '[global::System.CodeDom.Compiler.GeneratedCodeAttribute(""avrogen"", ""1.12.0-SNAPSHOT"")]', 'commenter': 'KyleSchoonover'}, {'comment': 'To make your life more complicated:\r\n\r\n```\r\n// VERSION.txt = 1.12.1-SNAPSHOT\r\nstring version = Assembly.GetExecutingAssembly().GetName().Version.ToString(); // => 1.12.0.0 INCORRECT\r\nstring fullVersion = Assembly.GetExecutingAssembly().GetCustomAttribute<AssemblyInformationalVersionAttribute>().InformationalVersion.ToString(); // => 1.12.1-SNAPSHOT CORRECT\r\n```\r\n\r\nFileVersion is set in common.props, which is defined as `<FileVersion>$(MajorVersion).$(MinorVersion).$(BuildNumber).0</FileVersion>` which IMO is incorrect and it should be `<FileVersion>$(MajorVersion).$(MinorVersion).$(PatchNumber).0</FileVersion>`.\r\n\r\nProbably it is a good idea to fix in another ticket, because the e.g. 1.11.1, the version written into the cs files will be 1.11.0.0 :(. It definetely makes sense not to trust any other version, except he InformationalVersion\r\n', 'commenter': 'zcsizmadia'}, {'comment': 'Yeah, I dug through and found it.  The update makes sense and makes things more consistent. ', 'commenter': 'KyleSchoonover'}]"
1605,lang/csharp/src/apache/main/CodeGen/CodeGenUtil.cs,"@@ -70,6 +71,9 @@ public sealed class CodeGenUtil
         private const char At = '@';
         private const char Dot = '.';
 
+        private readonly string _assemblyInformationVersion = FileVersionInfo.GetVersionInfo(","[{'comment': 'Keep in mind that FileVersionInfo.GetVersionInfo will open the actual dll file and read the library file directly to figure out the version + you will need the using Diagnostics.\r\nhttps://source.dot.net/#System.Diagnostics.FileVersionInfo/System/Diagnostics/FileVersionInfo.Unix.cs,45\r\n\r\nSystem.Reflection.Assembly.GetExecutingAssembly().GetCustomAttribute<AssemblyInformationalVersionAttribute>().InformationalVersion is more efficient.', 'commenter': 'zcsizmadia'}, {'comment': 'Made the change, but not as easy as your line of code suggests.', 'commenter': 'KyleSchoonover'}]"
1605,lang/csharp/src/apache/test/AvroGen/AvroGenHelper.cs,"@@ -97,16 +97,20 @@ public static Assembly CompileCSharpFilesIntoLibrary(IEnumerable<string> sourceF
                     Path.Combine(assemblyPath, ""netstandard.dll"")
                 };
 
+#if NETCOREAPP3_1","[{'comment': 'I prefer to have this in the assemblies List initialization all the time, not just NETCOREAPP. If it is a dependecny, it should be in the assemblies list. NET5.0 and NET6.0 it will be `System.Private.CoreLib.dll` which is the same as the assembly for `object`. NETCORE 3.1 has it in `System.Diagnostics.Tools.dll`. However MS might decide to move it around in net7+. That assemblies list might have duplicates, `CSharpCompilation` takes care of that.', 'commenter': 'zcsizmadia'}, {'comment': 'btw I am adding protocol tests for avrogen in a new PR, and I reuse the piece of code you change. But I wiull take care of themergeconflicts if they occur. Are you planning to add an attribute exists check in the loop which iterates through all the types right after the compilation? In that case you need additional tests or use cases, every type compiled by the unit test must have the attribute.', 'commenter': 'zcsizmadia'}, {'comment': 'I was specifically trying to keep it for .Netcore 3.1 since the line could be removed once 3.1 support is dropped.', 'commenter': 'KyleSchoonover'}, {'comment': 'I was more concerned about the location in future net version  and I really do not like those NETCOREAPP or NET... defines :)', 'commenter': 'zcsizmadia'}]"
1605,lang/csharp/src/apache/test/AvroGen/AvroGenHelper.cs,"@@ -93,20 +93,21 @@ public static Assembly CompileCSharpFilesIntoLibrary(IEnumerable<string> sourceF
                 {
                     typeof(object).Assembly.Location,
                     typeof(Schema).Assembly.Location,
+                    typeof(System.CodeDom.Compiler.GeneratedCodeAttribute).Assembly.Location,
                     Path.Combine(assemblyPath, ""System.Runtime.dll""),
                     Path.Combine(assemblyPath, ""netstandard.dll"")
                 };
 
                 // Create compiler
                 CSharpCompilation compilation = CSharpCompilation
-                    .Create(assemblyName)
-                    .WithOptions(new CSharpCompilationOptions(OutputKind.DynamicallyLinkedLibrary))
-                    .AddReferences(assemblies.Select(path => MetadataReference.CreateFromFile(path)))
-                    .AddSyntaxTrees(sourceFiles.Select(sourceFile =>
-                    {
-                        string sourceText = System.IO.File.ReadAllText(sourceFile);
-                        return CSharpSyntaxTree.ParseText(sourceText);
-                    }));
+                .Create(assemblyName)","[{'comment': 'Which style defines the tabulation of the chained methods? I am not a fan of tabulating this way.', 'commenter': 'zcsizmadia'}, {'comment': 'simplified declaration', 'commenter': 'KyleSchoonover'}, {'comment': 'I meant reverting the tab removal :)', 'commenter': 'zcsizmadia'}, {'comment': 'I chose to make it more legible.', 'commenter': 'KyleSchoonover'}, {'comment': 'Also this formatting is what is default in Visual studio, which we can potentially override in the editorconfig', 'commenter': 'KyleSchoonover'}, {'comment': 'Hmmm, my VS does not do that. Since it is not related to this PR, could you revert that formatting change?', 'commenter': 'zcsizmadia'}, {'comment': ""Sorry, I've been busy.  Easy fix.  For some reason I thought we were talking about tabbing somewhere else.  Yeah, VS won't change that, won't revert it back either."", 'commenter': 'KyleSchoonover'}]"
1606,lang/csharp/src/apache/test/Generic/GenericRecordTests.cs,"@@ -0,0 +1,202 @@
+using System;
+using System.Collections.Generic;
+using Avro.Generic;
+using NUnit.Framework;
+
+namespace Avro.test.Generic
+{
+    [TestFixture]
+    public class GenericRecordTests
+    {
+        private const string baseSchema = ""{\""type\"":\""record\"",\""name\"":\""r\"",\""fields\"":"" +
+            ""[{\""name\"":\""f2\"",\""type\"":\""int\""},{\""name\"":\""f1\"",\""type\"":\""boolean\""}]}"";
+
+        [Test]
+        public void TestAddByFieldNameThrows()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            // Field does not exist
+            Assert.Throws<AvroException>(() => { genericRecord.Add(""badField"", ""test""); });
+        }
+
+        [Test]
+        public void TestAddByPosition()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            genericRecord.Add(0, 2);
+
+            object value = genericRecord.GetValue(0);
+
+            Assert.IsNotNull(value);
+            Assert.IsTrue(value is int);
+            Assert.AreEqual(2, (int)value);
+        }
+
+        [Test]
+        public void TestAddByPositionThrows()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            Assert.Throws<IndexOutOfRangeException>(() => { genericRecord.Add(2, 2); });
+        }
+
+        [Test]
+        public void TestEquals()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+            GenericRecord genericRecord2 = GetBaseGenericRecord();
+
+            Assert.IsTrue(genericRecord.Equals(genericRecord2));
+        }
+
+        [Test]
+        public void TestEqualsNotEqual()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+            GenericRecord genericRecord2 = GetBaseGenericRecord();
+            genericRecord2.Add(0, 2);
+
+            Assert.IsFalse(genericRecord.Equals(genericRecord2));
+        }
+
+        [Test]
+        public void TestEqualsObject()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+            object genericRecord2 = genericRecord;
+
+            Assert.IsTrue(genericRecord.Equals(genericRecord2));
+        }
+
+        [Test]
+        public void TestEqualsObjectNotEqual()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+            GenericRecord genericRecord2 = GetBaseGenericRecord();
+            genericRecord2.Add(0, 2);
+
+            Assert.IsFalse(genericRecord.Equals((object)genericRecord2));
+        }
+
+        [Test]
+        public void TestEqualsObjectNullObject()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            Assert.IsFalse(genericRecord.Equals((object)null));
+        }
+
+        [Test]
+        public void TestGetHashCode()
+        {
+            int hashCode = GetBaseGenericRecord().GetHashCode();
+            Assert.IsTrue(hashCode > 0);
+        }
+
+        [Test]
+        public void TestGetValue()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            object value = genericRecord.GetValue(0);
+
+            Assert.IsNotNull(value);
+            Assert.IsTrue(value is int);
+            Assert.AreEqual(1, (int)value);
+        }
+
+        [Test]
+        public void TestKeyValueLookup()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            // Key Exists
+            object existingKey = genericRecord[""f2""];
+            Assert.IsNotNull(existingKey);
+            Assert.IsTrue(existingKey is int);
+        }
+
+        [Test]
+        public void TestKeyValueLookupThrows()
+        {
+            GenericRecord genericRecord = GetBaseGenericRecord();
+
+            // Key does not exist
+            Assert.Throws<KeyNotFoundException>(() => { object missingKey = genericRecord[""badField""]; });","[{'comment': 'Resolve this CodeQL warning plz', 'commenter': 'zcsizmadia'}, {'comment': 'Changed to discard', 'commenter': 'KyleSchoonover'}]"
1622,lang/csharp/src/apache/test/Generic/GenericTests.cs,"@@ -37,6 +37,45 @@ private static void test<T>(string s, T value)
             Assert.AreEqual(value, output);
         }
 
+        [Test]","[{'comment': 'We need more unit tests here. Something like this:\r\n\r\n```\r\n        private static IEnumerable<TestCaseData> ConvertsDefaultToLogicalTypeSource = new List<TestCaseData>()\r\n        {\r\n            new TestCaseData(@""{""""type"""": """"bytes"""", """"logicalType"""": """"decimal"""", """"precision"""": 4}"", @""""""0"""""", (decimal)0),\r\n            new TestCaseData(@""{""""type"""": """"bytes"""", """"logicalType"""": """"decimal"""", """"precision"""": 4}"", @""""""1234"""""", (decimal)1234),\r\n            new TestCaseData(@""{""""type"""": """"bytes"""", """"logicalType"""": """"decimal"""", """"precision"""": 4}"", @""""""1.234"""""", (decimal)1.234),\r\n            new TestCaseData(@""{""""type"""": """"string"""", """"logicalType"""": """"uuid""""}"", @""""""00000000-0000-0000-0000-000000000000"""""", new Guid()),\r\n            new TestCaseData(@""{""""type"""": """"string"""", """"logicalType"""": """"uuid""""}"", @""""""00000000000000000000000000000000"""""", new Guid()),\r\n            new TestCaseData(@""{""""type"""": """"string"""", """"logicalType"""": """"uuid""""}"", @""""""12345678-1234-5678-1234-123456789012"""""", new Guid(""12345678-1234-5678-1234-123456789012"")),\r\n            new TestCaseData(@""{""""type"""": """"string"""", """"logicalType"""": """"uuid""""}"", @""""""12345678123456781234123456789012"""""", new Guid(""12345678-1234-5678-1234-123456789012"")),\r\n            new TestCaseData(@""{""""type"""": """"int"""", """"logicalType"""": """"date""""}"", ""0"", DateTime.UnixEpoch),\r\n            new TestCaseData(@""{""""type"""": """"int"""", """"logicalType"""": """"date""""}"", ""123456"", DateTime.UnixEpoch.AddDays(123456)),\r\n            new TestCaseData(@""{""""type"""": """"long"""", """"logicalType"""": """"time-micros""""}"", ""0"", new TimeSpan()),\r\n            new TestCaseData(@""{""""type"""": """"long"""", """"logicalType"""": """"time-micros""""}"", ""123456"", new TimeSpan(123456*TimeSpan.TicksPerMillisecond/1000)),\r\n            new TestCaseData(@""{""""type"""": """"int"""", """"logicalType"""": """"time-millis""""}"", ""0"", new TimeSpan()),\r\n            new TestCaseData(@""{""""type"""": """"int"""", """"logicalType"""": """"time-millis""""}"", ""123456"", new TimeSpan(0, 0, 0, 0, 123456)),\r\n            new TestCaseData(@""{""""type"""": """"long"""", """"logicalType"""": """"timestamp-micros""""}"", ""0"", DateTime.UnixEpoch),\r\n            new TestCaseData(@""{""""type"""": """"long"""", """"logicalType"""": """"timestamp-micros""""}"", ""123456"", DateTime.UnixEpoch.AddTicks(123456*TimeSpan.TicksPerMillisecond/1000)),\r\n            new TestCaseData(@""{""""type"""": """"long"""", """"logicalType"""": """"timestamp-millis""""}"", ""0"", DateTime.UnixEpoch),\r\n            new TestCaseData(@""{""""type"""": """"long"""", """"logicalType"""": """"timestamp-millis""""}"", ""123456"", DateTime.UnixEpoch.AddMilliseconds(123456))\r\n        };\r\n\r\n        [TestCaseSource(nameof(ConvertsDefaultToLogicalTypeSource))]\r\n        public void ConvertsDefaultToLogicalType(string typeDefinition, string defaultDefinition, object expected)\r\n        {\r\n            var writerSchemaString = @""{\r\n    """"type"""": """"record"""",\r\n    """"name"""": """"Foo"""",\r\n    """"fields"""": [      \r\n    ]\r\n}"";\r\n\r\n            var readerSchemaString = $@""{{\r\n    """"type"""": """"record"""",\r\n    """"name"""": """"Foo"""",\r\n    """"fields"""": [\r\n        {{\r\n            """"name"""": """"x"""",\r\n            """"type"""": {typeDefinition},\r\n            """"default"""": {defaultDefinition}\r\n        }}\r\n    ]\r\n}}"";\r\n            var writerSchema = Schema.Parse(writerSchemaString);\r\n\r\n            Stream stream;\r\n\r\n            serialize(writerSchemaString,\r\n                mkRecord(new object[] { }, (RecordSchema) writerSchema),\r\n                out stream,\r\n                out _);\r\n\r\n            var output = deserialize<GenericRecord>(stream, writerSchema, Schema.Parse(readerSchemaString));\r\n\r\n            Assert.AreEqual(expected, output.GetValue(0));\r\n        }\r\n```\r\n\r\nYou will note that some unit tests do not expect the way I think they should work, so those cases must be discussed. \r\n\r\n1. microsec logical types swallow/ignore the actual us values and work only for milliseconds.\r\n2. decimal defaults do not work IMO as expected, however I might have been using them wrong in the test cases', 'commenter': 'zcsizmadia'}, {'comment': 'Thank you very much for the comment! I will add further tests. In regards to the two problematic cases you have discovered: \r\n1. The conversion from the base value to the logical value in https://github.com/apache/avro/blob/master/lang/csharp/src/apache/main/Util/TimestampMicrosecond.cs is responsible for this. If this can be changed at all I would consider this a new PR.\r\n2. Decimal uses either ""bytes"" or ""fixed"" as the underlying base schema. Both are represented as a string in the Avro JSON representation, but these strings should not contain a decimal encoding but a binary encoding of a decimal.', 'commenter': 'anekdoti'}, {'comment': 'I agree on the assessment of the the 2 issues. I would ignore the decimal unit test failures, however the micros are a  bigger issue. I would fix that first and put this PR on hold until that is merged.', 'commenter': 'zcsizmadia'}, {'comment': 'If you dont mind I can create the PR for the microsec fix and as soon as it is merged this can be merged as well. In the meantime you can add all the test cases (except the decimal), and we will know theat the unit test failures will be resolved after the us PR is merged', 'commenter': 'zcsizmadia'}, {'comment': 'Sorry for the late reply - thank you very much for your PR!', 'commenter': 'anekdoti'}, {'comment': 'I have fixed the tests for decimals. Strangely, creating a new AvroDecimal for a TestCaseData instance leads to a stack overflow in NUnit - for this reason, the tests for decimal logical type are separate from the others.', 'commenter': 'anekdoti'}]"
1622,lang/csharp/src/apache/test/Specific/SpecificTests.cs,"@@ -440,6 +441,69 @@ public void TestEmbeddedGenerics()
             Assert.AreEqual(0, dstRecord.UserMatrix[2].Count);
         }
 
+        private static void serializeGeneric<T>(string writerSchema, T actual, out Stream stream, out Schema ws)
+        {
+            var ms = new MemoryStream();
+            Encoder e = new BinaryEncoder(ms);
+            ws = Schema.Parse(writerSchema);
+            GenericWriter<T> w = new GenericWriter<T>(ws);
+            w.Write(actual, e);
+            ms.Flush();
+            ms.Position = 0;
+            stream = ms;
+        }
+
+
+        [Test]
+        public void DeserializeToLogicalTypeWithDefault()
+        {
+            var writerSchemaString = @""{
+    """"type"""": """"record"""",
+    """"name"""": """"RecordWithOptionalLogicalType"""",
+    """"namespace"""": """"Avro.Test.Specific.return"""",
+    """"fields"""": [      
+    ]}"";
+
+            var writerSchema = Schema.Parse(writerSchemaString);
+
+            Stream stream;
+
+            serializeGeneric(writerSchemaString,
+                mkRecord(new object[] { }, (RecordSchema)writerSchema),
+                out stream,
+                out _);
+
+            RecordWithOptionalLogicalType output = deserialize<RecordWithOptionalLogicalType>(stream, writerSchema, RecordWithOptionalLogicalType._SCHEMA);
+
+            Assert.AreEqual(output.x, new DateTime(1970, 1, 11));
+
+        }
+
+        private static GenericRecord mkRecord(object[] kv, RecordSchema s)","[{'comment': 'This seems to be the exact replica of the GenericTests.mkRecord() function. Can we make that public and use it, instead uf duplicationg it?', 'commenter': 'zcsizmadia'}, {'comment': 'Sure!', 'commenter': 'anekdoti'}]"
1622,lang/csharp/src/apache/test/Generic/GenericTests.cs,"@@ -17,28 +17,64 @@
  */
 using System;
 using System.IO;
-using System.Linq;
 using Avro.IO;
 using System.Collections.Generic;
+using System.Text;
 using Avro.Generic;
 using NUnit.Framework;
+using Decoder = Avro.IO.Decoder;
+using Encoder = Avro.IO.Encoder;
 
 namespace Avro.Test.Generic
 {
     class GenericTests
     {
-        private static void test<T>(string s, T value)
+        private static string intToUtf8(int value)
         {
-            Stream ms;
-            Schema ws;
-            serialize(s, value, out ms, out ws);
-            Schema rs = Schema.Parse(s);
-            T output = deserialize<T>(ms, ws, rs);
-            Assert.AreEqual(value, output);
+            var decimalLogicalType = new Avro.Util.Decimal();
+            var logicalSchema = (LogicalSchema)
+                Schema.Parse(@""{ """"type"""": """"bytes"""", """"logicalType"""": """"decimal"""", """"precision"""": 4 }"");
+
+            byte[] byteArray = (byte[])decimalLogicalType.ConvertToBaseValue(new AvroDecimal(value), logicalSchema);","[{'comment': 'I have some concern converting the int value to the decimal implementation in the unit test code. I am worried that we might hide some issues  in the unit tests  if e.g. we modify  Decimal.ConvertToBaseValue with some major breaking  change, however the unit test will pass, but the new format is not compatible with the previous one. \r\n\r\nMaybe instead of the intToUtf8(...) function you could hard code the actual string representation of the decimal default .\r\n\r\nsomething like ""\\0"" for 0m and ""\\u0004\\u00d2"" for 1234m. In this case the unit tests are more rigid and are able to detect changes in the underlying implementation. This might even help with the TestCaseDource stack overflow, however , that might not be the case.', 'commenter': 'zcsizmadia'}, {'comment': 'I am not sure about this. I think that what we test here is that a default with the encoding of a decimal (at that time) can be properly read as an instance of a decimal logical type. Therefore I would indeed think that the test should pass even after a breaking change to the encoding.', 'commenter': 'anekdoti'}, {'comment': 'I see your logic there. My intention was that if someone looks at the unit tests, it provides guidence about what to put phusically into the scheam as default value. Is there any higher level public function which can do what intToUtf8 does? I still feel uneasy about putting a very internal piece of code of the library into the unit test\r\n\r\nBtw I checked the code and the internal conversion code of the Decimal class can be modified, and the unit tests still pass. Which is not good and clearly a missing code coverage, but of course it is not in the scope of your PR.\r\n\r\nMost likely we need a  another PR to extend the code coverage of the Decimal object and cover the ConvertTo... public functions.', 'commenter': 'zcsizmadia'}, {'comment': 'I forgot to mention. that there is a `LogicalTypeTests.cs` file, maybe `ConvertsDefaultToLogicalType` unit test belongs there more  than in the `GenericTests.cs`', 'commenter': 'zcsizmadia'}, {'comment': 'I just went and started to move the microsecond tests into the logical type tests file in my other PR but gave up quickly :) so lets just use the Generic Tests file for this ;)', 'commenter': 'zcsizmadia'}, {'comment': 'I agree with this - I think `LogicalTypeTests.cs` is the place where for example the proper encoding of decimals as byte sequences should be verified and in particular that it does not change. Currently, it seems that only a proper round trip decimal -> bytes -> decimal is checked and maybe it would make sense to add a test that verifies a specific encoding to ensure compatibility in the future - but I think as well that this is a different topic and PR.\r\n\r\nAs the tests in this PR are not intended to verify the encoding itself, but just that it is used properly when converting a default value, I think they are in the right place.', 'commenter': 'anekdoti'}, {'comment': 'How about this. Leave the tests as they are. I feel that we have identiifed a missing code coverage, which indirectly has an effect on your unit tests. As much as I dislike to piggyback additional changes to PR which are not related, this is kinda connected in some sense. Here is the unit tests to validate the conversions for Decimal and could be added to `LogicalTypeTests.cs`. I think the comments will make it trivial when the code is reviewed, so a different PR might not be needed. If you feel you rather have in in a different PR, that is ok and I will do that and we will sequence merging the PRs properly:\r\n\r\n```\r\n        [TestCase(""0"", 0, new byte[] { 0 })]\r\n        [TestCase(""000000000000000001.01"", 2, new byte[] { 101 })]\r\n        [TestCase(""123456789123456789.56"", 2, new byte[] { 0, 171, 84, 169, 143, 129, 101, 36, 108 })]\r\n        [TestCase(""1234"", 0, new byte[] { 4, 210 })]\r\n        [TestCase(""1234.5"", 1, new byte[] { 48, 57 })]\r\n        [TestCase(""1234.56"", 2, new byte[] { 1, 226, 64 })]\r\n        [TestCase(""-0"", 0, new byte[] { 0 })]\r\n        [TestCase(""-000000000000000001.01"", 2, new byte[] { 155 })]\r\n        [TestCase(""-123456789123456789.56"", 2, new byte[] { 255, 84, 171, 86, 112, 126, 154, 219, 148 })]\r\n        [TestCase(""-1234"", 0, new byte[] { 251, 46 })]\r\n        [TestCase(""-1234.5"", 1, new byte[] { 207, 199 })]\r\n        [TestCase(""-1234.56"", 2, new byte[] { 254, 29, 192 })]\r\n        // This tests ensures that changes to Decimal.ConvertToBaseValue and ConvertToLogicalValue can be validated (bytes)\r\n        public void TestDecimalConvert(string s, int scale, byte[] converted)\r\n        {\r\n            var schema = (LogicalSchema)Schema.Parse(@$""{{""""type"""": """"bytes"""", """"logicalType"""": """"decimal"""", """"precision"""": 4, """"scale"""": {scale}}}"");\r\n\r\n            var avroDecimal = new Avro.Util.Decimal();\r\n            var decimalVal = (AvroDecimal)decimal.Parse(s);\r\n\r\n            // TestDecimal tests ConvertToLogicalValue(ConvertToBaseValue(...)) which might hide symmetrical breaking changes in both functions\r\n            // The following 2 tests are checking the conversions seperately\r\n\r\n            // Validate Decimal.ConvertToBaseValue\r\n            Assert.AreEqual(converted, avroDecimal.ConvertToBaseValue(decimalVal, schema));\r\n\r\n            // Validate Decimal.ConvertToLogicalValue\r\n            Assert.AreEqual(decimalVal, (AvroDecimal)avroDecimal.ConvertToLogicalValue(converted, schema));\r\n        }\r\n```\r\n', 'commenter': 'zcsizmadia'}, {'comment': 'I had to change the tests (and also TestDecimal) to construct the AvroDecimal with the right scale. Thank you for all your suggestions!', 'commenter': 'anekdoti'}, {'comment': 'Can you explain? What was the issue with the existing scale?', 'commenter': 'zcsizmadia'}, {'comment': ""Yes. The AvroDecimal has to have the same scale as the logical type (https://github.com/apache/avro/blob/master/lang/csharp/src/apache/main/Util/Decimal.cs#L72). However, it seems to be that the scale of the decimal is detected as 0. I guess this requires some additional testing for the conversion between decimal and AvroDecimal - again another topic, but there might be a bug as well now that I think about it. I'll try to check this with another test (AvroDecimal does not seem to be very well tested altogether), but unfortunately I have to discontinue for today soon."", 'commenter': 'anekdoti'}, {'comment': 'No worries. Thanks for your time!', 'commenter': 'zcsizmadia'}, {'comment': 'Fyi, the code snippet I posted above or the original TestDecimal works perfectly locally on my dev machine', 'commenter': 'zcsizmadia'}, {'comment': 'It turned out that this was a culture problem: on my machine, decimals get parsed with "","" as the decimal point by default. Parsing with `CultureInfo.InvariantCulture` solved the problem.', 'commenter': 'anekdoti'}, {'comment': 'Roger. the PR is looking good to me. I think your comment about the decimal point `,` vs `.` is very useful. I would add it to that Parse lines to help out the reviewer or/and contributors in the future.', 'commenter': 'zcsizmadia'}, {'comment': 'Thank you for your support!', 'commenter': 'anekdoti'}]"
1624,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -131,18 +144,15 @@ public ClassLoader getClassLoader() {
 
   /**
    * Registers the given conversion to be used when reading and writing with this
-   * data model.
+   * data model. Conversions can also be registered automatically, as documented
+   * on the class {@link Conversion Conversion&lt;T&gt;}.
    *
    * @param conversion a logical type Conversion.
    */
   public void addLogicalTypeConversion(Conversion<?> conversion) {
     conversions.put(conversion.getLogicalTypeName(), conversion);
     Class<?> type = conversion.getConvertedType();
-    Map<String, Conversion<?>> conversions = conversionsByClass.get(type);
-    if (conversions == null) {
-      conversions = new LinkedHashMap<>();
-      conversionsByClass.put(type, conversions);
-    }
+    Map<String, Conversion<?>> conversions = conversionsByClass.computeIfAbsent(type, k -> new LinkedHashMap<>());","[{'comment': 'maybe rename this local variable to `conversionsByType` to avoid confusion with the field with the same name ?', 'commenter': 'martin-g'}, {'comment': ""`conversionsByType` as a result of `conversionsByClass.get(...)` looks more confusing to me.\r\n\r\nSo I see two options to improve this name: `conversionsForClass`, and `conversionsByLogicalType` (the latter to avoid a class/type confusion).\r\nGiven that the field is named `conversionsBy...`, I'm choosing the first."", 'commenter': 'opwvhk'}, {'comment': 'Agreed!', 'commenter': 'martin-g'}]"
1624,lang/java/avro/src/main/java/org/apache/avro/Conversions.java,"@@ -106,11 +106,12 @@ public GenericFixed toFixed(BigDecimal value, Schema schema, LogicalType type) {
       byte fillByte = (byte) (value.signum() < 0 ? 0xFF : 0x00);
       byte[] unscaled = value.unscaledValue().toByteArray();
       byte[] bytes = new byte[schema.getFixedSize()];
-      int offset = bytes.length - unscaled.length;
+      int unscaledLength = unscaled.length;
+      int offset = bytes.length - unscaledLength;
 
-      // Fill the front of the array and copy remaining with unscaled values
+      // Fill the front with the filler and copy the unscaled value into the remainder
       Arrays.fill(bytes, 0, offset, fillByte);
-      System.arraycopy(unscaled, 0, bytes, offset, bytes.length - offset);
+      System.arraycopy(unscaled, 0, bytes, offset, unscaledLength);","[{'comment': 'nice catch!', 'commenter': 'RyanSkraba'}]"
1624,lang/java/avro/src/test/java/org/apache/avro/CustomType.java,"@@ -0,0 +1,46 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.avro;
+
+public final class CustomType {
+  private final String name;
+
+  public CustomType(CharSequence name) {
+    this.name = name.toString();
+  }
+
+  public String getName() {
+    return name;
+  }
+
+  @Override
+  public int hashCode() {
+    return super.hashCode();","[{'comment': '```suggestion\r\n    return Objects.hashCode(name);\r\n```\r\nJust a nitpick to meet the hashCode contract!', 'commenter': 'RyanSkraba'}]"
1624,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -184,11 +195,11 @@ public <T> Conversion<T> getConversionByClass(Class<T> datumClass, LogicalType l
    * @return the conversion for the logical type, or null
    */
   @SuppressWarnings(""unchecked"")
-  public Conversion<Object> getConversionFor(LogicalType logicalType) {","[{'comment': 'Do you have any idea if changing this signature is backwards binary-compatible ?  If not, we might need to bump these lines of code to a major release.', 'commenter': 'RyanSkraba'}, {'comment': ""Yes, they are:\r\n1. The type erasure of a type variable is the erasure of its leftmost bound (https://docs.oracle.com/javase/specs/jls/se11/html/jls-4.html#jls-4.6)\r\n2. Because T has no bounds in the syntax, it's bound is `Object` (https://docs.oracle.com/javase/specs/jls/se11/html/jls-4.html#jls-4.4)\r\n\r\nSo as far as binary compatibility is concerned, `<T> Conversion<T>` is the same as `Conversion<Object>`."", 'commenter': 'opwvhk'}]"
1624,lang/java/avro/src/main/java/org/apache/avro/generic/GenericData.java,"@@ -131,18 +144,15 @@
 
   /**
    * Registers the given conversion to be used when reading and writing with this
-   * data model.
+   * data model. Conversions can also be registered automatically, as documented
+   * on the class {@link Conversion Conversion&lt;T&gt;}.
    *
    * @param conversion a logical type Conversion.
    */
   public void addLogicalTypeConversion(Conversion<?> conversion) {
     conversions.put(conversion.getLogicalTypeName(), conversion);
     Class<?> type = conversion.getConvertedType();
-    Map<String, Conversion<?>> conversions = conversionsByClass.get(type);
-    if (conversions == null) {
-      conversions = new LinkedHashMap<>();
-      conversionsByClass.put(type, conversions);
-    }
+    Map<String, Conversion<?>> conversions = conversionsByClass.computeIfAbsent(type, k -> new LinkedHashMap<>());","[{'comment': ""## Possible confusion of local and field\n\nConfusing name: method [addLogicalTypeConversion](1) also refers to field [conversions](2) (without qualifying it with 'this').\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2660)"", 'commenter': 'github-advanced-security[bot]'}]"
1642,lang/csharp/src/apache/main/IO/BinaryDecoder.netstandard2.0.cs,"@@ -34,7 +34,7 @@ public partial class BinaryDecoder
         /// <summary>
         /// A float is written as 4 bytes.
         /// The float is converted into a 32-bit integer using a method equivalent to
-        /// Java's floatToIntBits and then encoded in little-endian format.
+        /// Java's floatToIntBits and then encoded in little-little-endian format.","[{'comment': 'fix the fix plz :)', 'commenter': 'zcsizmadia'}, {'comment': 'There is always one.  Fixed.', 'commenter': 'KyleSchoonover'}]"
1647,lang/rust/avro_derive/tests/derive.rs,"@@ -1063,4 +1063,40 @@ mod test_derive {
         serde_assert(TestBasicWithU32 { a: u32::MIN });
         serde_assert(TestBasicWithU32 { a: 1_u32 });
     }
+
+    #[derive(Debug, Serialize, Deserialize, AvroSchema, Clone, PartialEq)]
+    #[avro(alias = ""a"", alias = ""b"", alias = ""c"")]","[{'comment': 'I also wonder if this would work with:\r\n```\r\n#[avro(alias = ""a"")]\r\n#[avro(alias = ""b"")]\r\n#[avro(alias = ""c"")]\r\n```', 'commenter': 'jklamer'}, {'comment': 'It does - https://github.com/apache/avro/pull/1647/commits/05cf7807c947a58a6ab76aa50dfa8bb2a3999296', 'commenter': 'martin-g'}]"
1647,lang/rust/avro_derive/src/lib.rs,"@@ -277,6 +282,15 @@ fn preserve_optional(op: Option<impl quote::ToTokens>) -> TokenStream {
     }
 }
 
+fn preserve_vec(op: Vec<impl quote::ToTokens>) -> TokenStream {","[{'comment': 'nice!', 'commenter': 'jklamer'}, {'comment': 'Just copied your code and adapted! :-)', 'commenter': 'martin-g'}]"
1653,lang/csharp/src/apache/main/Generic/GenericEnum.cs,"@@ -70,10 +70,12 @@ public GenericEnum(EnumSchema schema, string value)
         /// <inheritdoc/>
         public override bool Equals(object obj)
         {
-            if (obj == this) return true;
-            return (obj != null && obj is GenericEnum)
-                ? Value.Equals((obj as GenericEnum).Value, System.StringComparison.Ordinal)
-                : false;
+            if (obj == this)
+            {
+                return true;
+            }
+
+            return obj != null && obj is GenericEnum && Value.Equals((obj as GenericEnum).Value, System.StringComparison.Ordinal);","[{'comment': 'This might be more readable:\r\n\r\n```\r\n    if (obj is GenericEnum ge)\r\n    {\r\n        return Value.Equals(ge.Value, System.StringComparison.Ordinal);\r\n    }\r\n\r\n    return false;\r\n```', 'commenter': 'zcsizmadia'}]"
1653,lang/csharp/src/apache/main/Generic/GenericEnum.cs,"@@ -70,10 +70,12 @@ public GenericEnum(EnumSchema schema, string value)
         /// <inheritdoc/>
         public override bool Equals(object obj)
         {
-            if (obj == this) return true;
-            return (obj != null && obj is GenericEnum)
-                ? Value.Equals((obj as GenericEnum).Value, System.StringComparison.Ordinal)
-                : false;
+            if (obj == this)
+            {
+                return true;
+            }
+
+            return obj != null && obj is GenericEnum && Value.Equals((obj as GenericEnum).Value, System.StringComparison.Ordinal);
         }","[{'comment': 'Are the CodeQL warnings any concern?', 'commenter': 'zcsizmadia'}, {'comment': ""Let me write an inheritance test.  I'm not really changing what is already there.  It's the exact same checks.  Potentially, any class that inherits may have to override equals.  \r\n\r\nI will be recreating the MR, and address the testing there."", 'commenter': 'KyleSchoonover'}, {'comment': ""It's an interesting problem: https://codeql.github.com/codeql-query-help/csharp/cs-equals-uses-is/\r\n\r\nUpdating the code.  I will evaluate the code base after this PR."", 'commenter': 'KyleSchoonover'}]"
1658,lang/csharp/src/apache/main/Generic/GenericEnum.cs,"@@ -70,10 +70,13 @@ public GenericEnum(EnumSchema schema, string value)
         /// <inheritdoc/>
         public override bool Equals(object obj)
         {
-            if (obj == this) return true;
-            return (obj != null && obj is GenericEnum)
-                ? Value.Equals((obj as GenericEnum).Value, System.StringComparison.Ordinal)
-                : false;
+            if (obj == this)
+            {
+                return true;
+            }
+
+            return obj.GetType() == typeof(GenericEnum)","[{'comment': 'There should be  a null check here IMO', 'commenter': 'zcsizmadia'}, {'comment': 'Added back', 'commenter': 'KyleSchoonover'}]"
1658,lang/csharp/src/apache/test/Generic/GenericEnumTests.cs,"@@ -0,0 +1,81 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using Avro.Generic;
+using NUnit.Framework;
+
+namespace Avro.test.Generic
+{
+    [TestFixture]
+    public class GenericEnumTests
+    {
+        private const string baseSchema = ""{\""type\"": \""enum\"", \""name\"": \""Test\"", \""symbols\"": "" +
+            ""[\""Unknown\"", \""A\"", \""B\""], \""default\"": \""Unknown\"" }"";
+
+        [Test]
+        public void TestEquals()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            GenericEnum genericEnum2 = GetBaseGenericEnum();
+
+            Assert.IsTrue(genericEnum.Equals(genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsNotEqual()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            GenericEnum genericEnum2 = new GenericEnum(Schema.Parse(baseSchema) as EnumSchema, ""B"");
+
+            Assert.IsFalse(genericEnum.Equals(genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsObject()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            object genericEnum2 = genericEnum;
+
+            Assert.IsTrue(genericEnum.Equals(genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsObjectNotEqual()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            GenericEnum genericEnum2 = new GenericEnum(Schema.Parse(baseSchema) as EnumSchema, ""B"");
+
+            Assert.IsFalse(genericEnum.Equals((object)genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsObjectNullObject()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+
+            Assert.IsFalse(genericEnum.Equals((object)null));","[{'comment': 'I am surprised that this passes', 'commenter': 'zcsizmadia'}, {'comment': 'ohh. I see it fails. So the null check is definetely needed up in the Equals code', 'commenter': 'zcsizmadia'}, {'comment': 'Fixed', 'commenter': 'KyleSchoonover'}]"
1658,lang/csharp/src/apache/test/Generic/GenericEnumTests.cs,"@@ -0,0 +1,81 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using Avro.Generic;
+using NUnit.Framework;
+
+namespace Avro.test.Generic
+{
+    [TestFixture]
+    public class GenericEnumTests
+    {
+        private const string baseSchema = ""{\""type\"": \""enum\"", \""name\"": \""Test\"", \""symbols\"": "" +
+            ""[\""Unknown\"", \""A\"", \""B\""], \""default\"": \""Unknown\"" }"";
+
+        [Test]
+        public void TestEquals()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            GenericEnum genericEnum2 = GetBaseGenericEnum();
+
+            Assert.IsTrue(genericEnum.Equals(genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsNotEqual()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            GenericEnum genericEnum2 = new GenericEnum(Schema.Parse(baseSchema) as EnumSchema, ""B"");
+
+            Assert.IsFalse(genericEnum.Equals(genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsObject()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            object genericEnum2 = genericEnum;
+
+            Assert.IsTrue(genericEnum.Equals(genericEnum2));
+        }
+
+        [Test]
+        public void TestEqualsObjectNotEqual()
+        {
+            GenericEnum genericEnum = GetBaseGenericEnum();
+            GenericEnum genericEnum2 = new GenericEnum(Schema.Parse(baseSchema) as EnumSchema, ""B"");
+
+            Assert.IsFalse(genericEnum.Equals((object)genericEnum2));","[{'comment': 'Can the casting be removed and fix the CodeQL warnings?', 'commenter': 'zcsizmadia'}, {'comment': 'Updated', 'commenter': 'KyleSchoonover'}]"
1672,lang/java/avro/src/test/java/org/apache/avro/message/TestInteropMessageData.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.avro.message;
+
+import org.apache.avro.Schema;
+import org.apache.avro.generic.GenericData;
+import org.apache.avro.generic.GenericRecordBuilder;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.util.Arrays;
+import java.util.logging.Logger;
+
+public class TestInteropMessageData {
+  private static String inDir = System.getProperty(""share.dir"", ""../../../share"") + ""/test/data/messageV1"";
+  private static File SCHEMA_FILE = new File(inDir + ""/test_schema.json"");
+  private static File MESSAGE_FILE = new File(inDir + ""/test_message.bin"");
+  private static final Schema SCHEMA;
+  private static final GenericRecordBuilder BUILDER;
+
+  static {
+    try {
+      SCHEMA = new Schema.Parser().parse(new FileInputStream(SCHEMA_FILE));
+      BUILDER = new GenericRecordBuilder(SCHEMA);","[{'comment': ""Let's use JUnit's before/after, because now FileInputStream is not closed at the end."", 'commenter': 'martin-g'}]"
1672,lang/java/avro/src/test/java/org/apache/avro/message/TestInteropMessageData.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.avro.message;
+
+import org.apache.avro.Schema;
+import org.apache.avro.generic.GenericData;
+import org.apache.avro.generic.GenericRecordBuilder;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.util.Arrays;
+import java.util.logging.Logger;
+
+public class TestInteropMessageData {
+  private static String inDir = System.getProperty(""share.dir"", ""../../../share"") + ""/test/data/messageV1"";","[{'comment': '`final` ?', 'commenter': 'martin-g'}]"
1672,lang/java/avro/src/test/java/org/apache/avro/message/TestInteropMessageData.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.avro.message;
+
+import org.apache.avro.Schema;
+import org.apache.avro.generic.GenericData;
+import org.apache.avro.generic.GenericRecordBuilder;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.util.Arrays;
+import java.util.logging.Logger;
+
+public class TestInteropMessageData {
+  private static String inDir = System.getProperty(""share.dir"", ""../../../share"") + ""/test/data/messageV1"";
+  private static File SCHEMA_FILE = new File(inDir + ""/test_schema.json"");","[{'comment': '`final`', 'commenter': 'martin-g'}, {'comment': 'Usually schema files use extension `.avsc`', 'commenter': 'martin-g'}]"
1672,lang/java/avro/src/test/java/org/apache/avro/message/TestInteropMessageData.java,"@@ -0,0 +1,62 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *   https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing,
+ * software distributed under the License is distributed on an
+ * ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ * KIND, either express or implied.  See the License for the
+ * specific language governing permissions and limitations
+ * under the License.
+ */
+
+package org.apache.avro.message;
+
+import org.apache.avro.Schema;
+import org.apache.avro.generic.GenericData;
+import org.apache.avro.generic.GenericRecordBuilder;
+import org.junit.Assert;
+import org.junit.Test;
+
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.IOException;
+import java.nio.ByteBuffer;
+import java.nio.file.Files;
+import java.util.Arrays;
+import java.util.logging.Logger;
+
+public class TestInteropMessageData {
+  private static String inDir = System.getProperty(""share.dir"", ""../../../share"") + ""/test/data/messageV1"";
+  private static File SCHEMA_FILE = new File(inDir + ""/test_schema.json"");
+  private static File MESSAGE_FILE = new File(inDir + ""/test_message.bin"");","[{'comment': '`final`', 'commenter': 'martin-g'}, {'comment': 'Usually the extension is `.avro`', 'commenter': 'martin-g'}, {'comment': ""^ this was something I wasn't sure about because the binary format is not the same as the object container files. Wanted to be clear that this shouldn't be read by any Avro File Readers"", 'commenter': 'jklamer'}]"
1672,lang/rust/avro/examples/test_interop_message_data.rs,"@@ -0,0 +1,58 @@
+// Licensed to the Apache Software Foundation (ASF) under one
+// or more contributor license agreements.  See the NOTICE file
+// distributed with this work for additional information
+// regarding copyright ownership.  The ASF licenses this file
+// to you under the Apache License, Version 2.0 (the
+// ""License""); you may not use this file except in compliance
+// with the License.  You may obtain a copy of the License at
+//
+//   http://www.apache.org/licenses/LICENSE-2.0
+//
+// Unless required by applicable law or agreed to in writing,
+// software distributed under the License is distributed on an
+// ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+// KIND, either express or implied.  See the License for the
+// specific language governing permissions and limitations
+// under the License.
+
+use apache_avro::{schema::AvroSchema, types::Value};
+
+struct InteropMessage;
+
+impl AvroSchema for InteropMessage {
+    fn get_schema() -> apache_avro::Schema {
+        let schema = std::fs::read_to_string(""../../share/test/data/messageV1/test_schema.json"")
+            .expect(""File should exist with schema inside"");
+        apache_avro::Schema::parse_str(schema.as_str())
+            .expect(""File should exist with schema inside"")
+    }
+}
+
+impl From<InteropMessage> for Value {","[{'comment': 'Why an impl for Value ?\r\nWhy not a proper struct with fields ?', 'commenter': 'martin-g'}, {'comment': ""In this case, for the Interop testing, there is only one `Value` that the message should ever produce. This pattern only makes sense for this use case where there is one message value that we're going for. "", 'commenter': 'jklamer'}]"
1672,lang/rust/avro/src/writer.rs,"@@ -352,6 +353,110 @@ fn write_avro_datum<T: Into<Value>>(
     Ok(())
 }
 
+/// Writer that encodes messages according to the single object encoding v1 spec
+/// Uses an API similar to the current File Writer
+/// Writes all object bytes at once, and drains internal buffer
+pub struct GenericSingleObjectWriter {
+    buffer: Vec<u8>,
+    resolved: ResolvedOwnedSchema,
+}
+
+impl GenericSingleObjectWriter {
+    pub fn new_with_capacity(
+        schema: &Schema,
+        initial_buffer_cap: usize,
+    ) -> AvroResult<GenericSingleObjectWriter> {
+        let fingerprint = schema.fingerprint::<Rabin>();
+        let mut buffer = Vec::with_capacity(initial_buffer_cap);
+        let header = [
+            0xC3,
+            0x01,
+            fingerprint.bytes[0],
+            fingerprint.bytes[1],
+            fingerprint.bytes[2],
+            fingerprint.bytes[3],
+            fingerprint.bytes[4],
+            fingerprint.bytes[5],
+            fingerprint.bytes[6],
+            fingerprint.bytes[7],
+        ];
+        buffer.extend_from_slice(&header);
+
+        Ok(GenericSingleObjectWriter {
+            buffer,
+            resolved: ResolvedOwnedSchema::try_from(schema.clone())?,
+        })
+    }
+
+    /// Wrtite the referenced Value to the provided Write object. Returns a result with the number of bytes writtern including the header","[{'comment': '```suggestion\r\n    /// Write the referenced Value to the provided Write object. Returns a result with the number of bytes written including the header\r\n```', 'commenter': 'martin-g'}]"
1672,lang/rust/avro/src/writer.rs,"@@ -352,6 +353,110 @@ fn write_avro_datum<T: Into<Value>>(
     Ok(())
 }
 
+/// Writer that encodes messages according to the single object encoding v1 spec
+/// Uses an API similar to the current File Writer
+/// Writes all object bytes at once, and drains internal buffer
+pub struct GenericSingleObjectWriter {
+    buffer: Vec<u8>,
+    resolved: ResolvedOwnedSchema,
+}
+
+impl GenericSingleObjectWriter {
+    pub fn new_with_capacity(
+        schema: &Schema,
+        initial_buffer_cap: usize,
+    ) -> AvroResult<GenericSingleObjectWriter> {
+        let fingerprint = schema.fingerprint::<Rabin>();
+        let mut buffer = Vec::with_capacity(initial_buffer_cap);
+        let header = [
+            0xC3,
+            0x01,
+            fingerprint.bytes[0],
+            fingerprint.bytes[1],
+            fingerprint.bytes[2],
+            fingerprint.bytes[3],
+            fingerprint.bytes[4],
+            fingerprint.bytes[5],
+            fingerprint.bytes[6],
+            fingerprint.bytes[7],
+        ];
+        buffer.extend_from_slice(&header);
+
+        Ok(GenericSingleObjectWriter {
+            buffer,
+            resolved: ResolvedOwnedSchema::try_from(schema.clone())?,
+        })
+    }
+
+    /// Wrtite the referenced Value to the provided Write object. Returns a result with the number of bytes writtern including the header
+    pub fn write_value_ref<W: Write>(&mut self, v: &Value, writer: &mut W) -> AvroResult<usize> {
+        if self.buffer.len() != 10 {
+            Err(Error::IllegalSingleObjectWriterState)
+        } else {
+            write_value_ref_owned_resolved(&self.resolved, v, &mut self.buffer)?;
+            writer.write_all(&self.buffer).map_err(Error::WriteBytes)?;
+            let len = self.buffer.len();
+            self.buffer.truncate(10);
+            Ok(len)
+        }
+    }
+
+    /// Wrtite the Value to the provided Write object. Returns a result with the number of bytes writtern including the header","[{'comment': '```suggestion\r\n    /// Write the Value to the provided Write object. Returns a result with the number of bytes written including the header\r\n```', 'commenter': 'martin-g'}]"
1672,lang/rust/avro/src/writer.rs,"@@ -352,6 +353,110 @@ fn write_avro_datum<T: Into<Value>>(
     Ok(())
 }
 
+/// Writer that encodes messages according to the single object encoding v1 spec
+/// Uses an API similar to the current File Writer
+/// Writes all object bytes at once, and drains internal buffer
+pub struct GenericSingleObjectWriter {
+    buffer: Vec<u8>,
+    resolved: ResolvedOwnedSchema,
+}
+
+impl GenericSingleObjectWriter {
+    pub fn new_with_capacity(
+        schema: &Schema,
+        initial_buffer_cap: usize,
+    ) -> AvroResult<GenericSingleObjectWriter> {
+        let fingerprint = schema.fingerprint::<Rabin>();
+        let mut buffer = Vec::with_capacity(initial_buffer_cap);
+        let header = [
+            0xC3,
+            0x01,
+            fingerprint.bytes[0],
+            fingerprint.bytes[1],
+            fingerprint.bytes[2],
+            fingerprint.bytes[3],
+            fingerprint.bytes[4],
+            fingerprint.bytes[5],
+            fingerprint.bytes[6],
+            fingerprint.bytes[7],
+        ];
+        buffer.extend_from_slice(&header);
+
+        Ok(GenericSingleObjectWriter {
+            buffer,
+            resolved: ResolvedOwnedSchema::try_from(schema.clone())?,
+        })
+    }
+
+    /// Wrtite the referenced Value to the provided Write object. Returns a result with the number of bytes writtern including the header
+    pub fn write_value_ref<W: Write>(&mut self, v: &Value, writer: &mut W) -> AvroResult<usize> {
+        if self.buffer.len() != 10 {
+            Err(Error::IllegalSingleObjectWriterState)
+        } else {
+            write_value_ref_owned_resolved(&self.resolved, v, &mut self.buffer)?;
+            writer.write_all(&self.buffer).map_err(Error::WriteBytes)?;
+            let len = self.buffer.len();
+            self.buffer.truncate(10);
+            Ok(len)
+        }
+    }
+
+    /// Wrtite the Value to the provided Write object. Returns a result with the number of bytes writtern including the header
+    pub fn write_value<W: Write>(&mut self, v: Value, writer: &mut W) -> AvroResult<usize> {
+        self.write_value_ref(&v, writer)
+    }
+}
+
+/// Writer that encodes messages according to the single object encoding v1 spec
+pub struct SingleObjectWriter<T>
+where
+    T: AvroSchema,
+{
+    inner: GenericSingleObjectWriter,
+    _model: PhantomData<T>,
+}
+
+impl<T> SingleObjectWriter<T>
+where
+    T: AvroSchema,
+{
+    pub fn with_capacity(buffer_cap: usize) -> AvroResult<SingleObjectWriter<T>> {
+        let schema = T::get_schema();
+        Ok(SingleObjectWriter {
+            inner: GenericSingleObjectWriter::new_with_capacity(&schema, buffer_cap)?,
+            _model: PhantomData,
+        })
+    }
+}
+
+impl<T> SingleObjectWriter<T>
+where
+    T: AvroSchema + Into<Value>,
+{
+    /// Wrtite the Into<Value> to the provided Write object. Returns a result with the number of bytes writtern including the header","[{'comment': '```suggestion\r\n    /// Write the Into<Value> to the provided Write object. Returns a result with the number of bytes written including the header\r\n```', 'commenter': 'martin-g'}]"
1672,lang/rust/avro/src/writer.rs,"@@ -352,6 +353,110 @@ fn write_avro_datum<T: Into<Value>>(
     Ok(())
 }
 
+/// Writer that encodes messages according to the single object encoding v1 spec
+/// Uses an API similar to the current File Writer
+/// Writes all object bytes at once, and drains internal buffer
+pub struct GenericSingleObjectWriter {
+    buffer: Vec<u8>,
+    resolved: ResolvedOwnedSchema,
+}
+
+impl GenericSingleObjectWriter {
+    pub fn new_with_capacity(
+        schema: &Schema,
+        initial_buffer_cap: usize,
+    ) -> AvroResult<GenericSingleObjectWriter> {
+        let fingerprint = schema.fingerprint::<Rabin>();
+        let mut buffer = Vec::with_capacity(initial_buffer_cap);
+        let header = [
+            0xC3,
+            0x01,
+            fingerprint.bytes[0],
+            fingerprint.bytes[1],
+            fingerprint.bytes[2],
+            fingerprint.bytes[3],
+            fingerprint.bytes[4],
+            fingerprint.bytes[5],
+            fingerprint.bytes[6],
+            fingerprint.bytes[7],
+        ];
+        buffer.extend_from_slice(&header);
+
+        Ok(GenericSingleObjectWriter {
+            buffer,
+            resolved: ResolvedOwnedSchema::try_from(schema.clone())?,
+        })
+    }
+
+    /// Wrtite the referenced Value to the provided Write object. Returns a result with the number of bytes writtern including the header
+    pub fn write_value_ref<W: Write>(&mut self, v: &Value, writer: &mut W) -> AvroResult<usize> {
+        if self.buffer.len() != 10 {
+            Err(Error::IllegalSingleObjectWriterState)
+        } else {
+            write_value_ref_owned_resolved(&self.resolved, v, &mut self.buffer)?;
+            writer.write_all(&self.buffer).map_err(Error::WriteBytes)?;
+            let len = self.buffer.len();
+            self.buffer.truncate(10);
+            Ok(len)
+        }
+    }
+
+    /// Wrtite the Value to the provided Write object. Returns a result with the number of bytes writtern including the header
+    pub fn write_value<W: Write>(&mut self, v: Value, writer: &mut W) -> AvroResult<usize> {
+        self.write_value_ref(&v, writer)
+    }
+}
+
+/// Writer that encodes messages according to the single object encoding v1 spec
+pub struct SingleObjectWriter<T>
+where
+    T: AvroSchema,
+{
+    inner: GenericSingleObjectWriter,
+    _model: PhantomData<T>,
+}
+
+impl<T> SingleObjectWriter<T>
+where
+    T: AvroSchema,
+{
+    pub fn with_capacity(buffer_cap: usize) -> AvroResult<SingleObjectWriter<T>> {
+        let schema = T::get_schema();
+        Ok(SingleObjectWriter {
+            inner: GenericSingleObjectWriter::new_with_capacity(&schema, buffer_cap)?,
+            _model: PhantomData,
+        })
+    }
+}
+
+impl<T> SingleObjectWriter<T>
+where
+    T: AvroSchema + Into<Value>,
+{
+    /// Wrtite the Into<Value> to the provided Write object. Returns a result with the number of bytes writtern including the header
+    pub fn write_value<W: Write>(&mut self, data: T, writer: &mut W) -> AvroResult<usize> {
+        let v: Value = data.into();
+        self.inner.write_value_ref(&v, writer)
+    }
+}
+
+impl<T> SingleObjectWriter<T>
+where
+    T: AvroSchema + Serialize,
+{
+    /// Wrtite the referenced Serialize object to the provided Write object. Returns a result with the number of bytes writtern including the header","[{'comment': '```suggestion\r\n    /// Write the referenced Serialize object to the provided Write object. Returns a result with the number of bytes written including the header\r\n```', 'commenter': 'martin-g'}]"
1672,lang/rust/avro/src/writer.rs,"@@ -943,4 +1069,123 @@ mod tests {
 
         assert_eq!(writer.user_metadata, user_meta_data);
     }
+
+    #[derive(Serialize, Clone)]
+    struct TestSingleObjectWriter {
+        a: i64,
+        b: f64,
+        c: Vec<String>,
+    }
+
+    impl AvroSchema for TestSingleObjectWriter {
+        fn get_schema() -> Schema {
+            let schema = r#""
+            {
+                ""type"":""record"",
+                ""name"":""TestSingleObjectWrtierSerialize"",
+                ""fields"":[
+                    {
+                        ""name"":""a"",
+                        ""type"":""long""
+                    },
+                    {
+                        ""name"":""b"",
+                        ""type"":""double""
+                    },
+                    {
+                        ""name"":""c"",
+                        ""type"":{
+                            ""type"":""array"",
+                            ""items"":""string""
+                        }
+                    }
+                ]
+            }
+            ""#;
+            Schema::parse_str(schema).unwrap()
+        }
+    }
+
+    impl From<TestSingleObjectWriter> for Value {
+        fn from(obj: TestSingleObjectWriter) -> Value {
+            Value::Record(vec![
+                (""a"".into(), obj.a.into()),
+                (""b"".into(), obj.b.into()),
+                (
+                    ""c"".into(),
+                    Value::Array(obj.c.into_iter().map(|s| s.into()).collect()),
+                ),
+            ])
+        }
+    }
+
+    #[test]
+    fn test_single_object_writer() {
+        let mut buf: Vec<u8> = Vec::new();
+        let obj = TestSingleObjectWriter {
+            a: 300,
+            b: 34.555,
+            c: vec![""cat"".into(), ""dog"".into()],
+        };
+        let mut writer = GenericSingleObjectWriter::new_with_capacity(
+            &TestSingleObjectWriter::get_schema(),
+            1024,
+        )
+        .expect(""Should resolve schema"");
+        let value = obj.into();
+        let written_bytes = writer
+            .write_value_ref(&value, &mut buf)
+            .expect(""Error serializing properly"");
+
+        assert!(buf.len() > 10, ""no bytes written"");
+        assert_eq!(buf.len(), written_bytes);
+        assert_eq!(buf[0], 0xC3);
+        assert_eq!(buf[1], 0x01);
+        assert_eq!(
+            &buf[2..10],
+            &TestSingleObjectWriter::get_schema()
+                .fingerprint::<Rabin>()
+                .bytes[..]
+        );
+        let mut msg_binary = Vec::new();
+        encode(
+            &value,
+            &TestSingleObjectWriter::get_schema(),
+            &mut msg_binary,
+        )
+        .expect(""encode should have failed by here as a depndency of any writing"");","[{'comment': '```suggestion\r\n        .expect(""encode should have failed by here as a dependency of any writing"");\r\n```', 'commenter': 'martin-g'}]"
1672,share/test/data/messageV1/README.md,"@@ -0,0 +1,45 @@
+BinaryMessage data in single object encoding https://avro.apache.org/docs/current/spec.html#single_object_encoding
+
+Ground truth data generated with Java Code","[{'comment': 'There is no new code to run the Java test in CI.\r\nSee `.github/workflows/test-lang-rust-ci.yml`', 'commenter': 'martin-g'}, {'comment': 'Do you think we should generate this data every time? I was looking at the `share/test/data/` folder for avro container files data and I wanted to create an extension to that for message format where the bytes are ""stuck in time"". So even if generated by Java at first they can be used to keep checking Rust against Java?', 'commenter': 'jklamer'}, {'comment': ""Agreed! Let's keep it simple!"", 'commenter': 'martin-g'}, {'comment': 'OK, the `.bin` file will be pre-generated!\r\nBut we should run the new example as part of the interop tests, right ?', 'commenter': 'martin-g'}, {'comment': 'done!', 'commenter': 'jklamer'}]"
1672,lang/rust/avro/src/schema.rs,"@@ -434,6 +434,86 @@ impl<'s> ResolvedSchema<'s> {
     }
 }
 
+pub(crate) struct ResolvedOwnedSchema {","[{'comment': 'Can we avoid the code duplication somehow ?\r\nFor example by using `ResolvedSchema.clone()` where needed ?', 'commenter': 'martin-g'}, {'comment': ""Im not sure. The ResolvedSchema has that lifetime that Im not sure how to associate with another field in the struct.\r\nThe design for GenericSingleObjectWriter would have to be \r\n```\r\npub struct GenericSingleObjectWriter {\r\n    buffer: Vec<u8>,\r\n    schema: Schema, // with lifetime 'a?\r\n    resolved: ResolvedSchema<'a>,\r\n}\r\n```"", 'commenter': 'jklamer'}]"
1672,lang/rust/avro/src/types.rs,"@@ -355,7 +356,11 @@ impl Value {
         }
     }
 
-    pub(crate) fn validate_internal(&self, schema: &Schema, names: &NamesRef) -> Option<String> {
+    pub(crate) fn validate_internal<S: std::borrow::Borrow<Schema>>(","[{'comment': 'What is the benefit of using `std::borrow::Borrow` here ?', 'commenter': 'martin-g'}, {'comment': 'This allows me to use the same function with both `Names` and `NamesRef`. Both `Schema` and and `&Schema` implement `Borrow<Schema>`', 'commenter': 'jklamer'}]"
1672,lang/rust/build.sh,"@@ -60,11 +60,13 @@ do
       export RUST_LOG=apache_avro=debug
       export RUST_BACKTRACE=1
       cargo run --all-features --example generate_interop_data
+      cargo run --all-features --example generate_interop_data","[{'comment': 'This should be `test_interop_message_data`. I will take care!', 'commenter': 'martin-g'}]"
1689,lang/py/avro/io.py,"@@ -699,7 +699,7 @@ def read_data(self, writers_schema: avro.schema.Schema, readers_schema: avro.sch
                     warnings.warn(avro.errors.IgnoredLogicalType(f""Invalid decimal precision {precision}. Must be a positive integer.""))
                     return decoder.read_bytes()
                 scale = writers_schema.get_prop(""scale"")
-                if not (isinstance(scale, int) and scale > 0):
+                if not (isinstance(scale, int) and scale >= 0):
                     warnings.warn(avro.errors.IgnoredLogicalType(f""Invalid decimal scale {scale}. Must be a positive integer.""))","[{'comment': '```suggestion\r\n                    warnings.warn(avro.errors.IgnoredLogicalType(f""Invalid decimal scale {scale}. Must be a non-negative integer.""))\r\n```', 'commenter': 'RyanSkraba'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,287 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+ant clean test
+```
+</details>
+
+<details><summary>Python3</summary>
+
+```shell
+cd avro-trunk/lang/py3","[{'comment': 'there is no `py3` ', 'commenter': 'martin-g'}, {'comment': 'Indeed, there is only one python section now, remove python 3 section.\r\nOnly python section with \r\n`./setup.py build test`\r\nfor build', 'commenter': 'clesaec'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,287 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+ant clean test","[{'comment': 'There is no `build.xml` for Ant.\r\nPlease replace with `./build test`.\r\nSame for all langs, including Java.', 'commenter': 'martin-g'}, {'comment': ""As `./build.sh test` doesn't work for me in local, i put `./setup.py build test`"", 'commenter': 'clesaec'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,287 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+ant clean test
+```
+</details>
+
+<details><summary>Python3</summary>
+
+```shell
+cd avro-trunk/lang/py3
+./setup.py build test
+```
+</details>
+
+<details><summary>C</summary>
+
+```shell
+cd avro-trunk/lang/c
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>C++</summary>
+
+```shell
+cd avro-trunk/lang/c++
+./build.sh clean test
+```
+</details>
+
+<details><summary>Ruby</summary>
+
+```shell
+cd avro-trunk/lang/ruby
+gem install echoe
+rake clean test
+```
+</details>
+
+<details><summary>PHP</summary>","[{'comment': 'Please add an entry for `lang/rust` too.', 'commenter': 'martin-g'}, {'comment': ' :+1:  rust section added', 'commenter': 'clesaec'}, {'comment': 'There is also `lang/csharp/build.sh` for C#. When I tried it with Avro 1.11.0 on Windows, Avro.Test.LogicalTypeTests.TestDecimal failed with FormatException, but that has already been fixed as part of AVRO-3468.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'So, nothing to do on doc ?', 'commenter': 'clesaec'}, {'comment': 'I meant, it would be good to add instructions for testing C# changes to this document, but it is not necessary to describe how to install a Bash shell on Windows or how to work around AVRO-3468.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': ""Yes, sorry, i didn't see i forget C# section, it's added"", 'commenter': 'clesaec'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,287 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+ant clean test
+```
+</details>
+
+<details><summary>Python3</summary>
+
+```shell
+cd avro-trunk/lang/py3
+./setup.py build test
+```
+</details>
+
+<details><summary>C</summary>
+
+```shell
+cd avro-trunk/lang/c
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>C++</summary>
+
+```shell
+cd avro-trunk/lang/c++
+./build.sh clean test
+```
+</details>
+
+<details><summary>Ruby</summary>
+
+```shell
+cd avro-trunk/lang/ruby
+gem install echoe
+rake clean test
+```
+</details>
+
+<details><summary>PHP</summary>
+
+```shell
+cd avro-trunk/lang/php
+./build.sh clean
+./build.sh test
+```
+
+</details>
+
+<details><summary>Documentation</summary>
+
+Please also check the documentation.
+Java
+
+```shell
+mvn compile
+mvn javadoc:aggregate
+firefox target/site/apidocs/index.html
+```
+
+Examine all public classes you've changed to see that documentation is complete, informative, and properly formatted. Your patch must not generate any javadoc warnings.
+</details>
+
+## Contributing your code
+
+Contribution can be made directly via github with a Pull Request, or via a patch.
+
+**Via Github**
+
+Method is to create a [pull request](https://help.github.com/articles/using-pull-requests/).
+
+On your fork, create a branch named with JIRA (avro-1234_fixNpe for example) 
+On source, go to it
+```shell
+git pull
+git switch avro-1234_fixNpe
+```
+
+code your changes (following preceding recommendations)
+
+check and add updated sources
+```shell
+git status
+
+# Add any new or changed files with:
+git add src/.../MyNewClass.java
+git add src/.../TestMyNewClass.java
+```
+
+Finally, create a commit with your changes and a good log message, and push it:
+```shell
+git commit -m ""AVRO-1234: Fix NPE by adding check to ...""
+git push
+```
+On your github fork site, a button will propose you to build the Pull Request.
+Click on it, fill Conversation form, and create it.
+Link this PR to the corresponding JIRA ticket (on JIRA ticket, add PR to ""Issue Links"" chapter, and add label 'pull-request-available' to it .
+
+
+<details><summary><b>Via Patch</b> (if you don't have github account)</summary>
+<blockquote>
+<details><summary><b>Clone avro repository</b></summary> 
+
+```shell
+git clone https://github.com/apache/avro.git","[{'comment': 'append `-o github` for consistency with the earlier clone sample', 'commenter': 'martin-g'}, {'comment': 'added', 'commenter': 'clesaec'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,294 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+./setup.py build test
+```
+</details>
+
+<details><summary><a href=""https://www.rust-lang.org/"">Rust</a></summary>
+
+```shell
+cd avro-trunk/lang/rust
+./build.sh clean test
+```
+</details>
+
+<details><summary>C#</summary>
+
+```shell
+cd avro-trunk/lang/csharp
+./build.sh clean test
+```
+</details>
+
+<details><summary>C</summary>
+
+```shell
+cd avro-trunk/lang/c
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>C++</summary>
+
+```shell
+cd avro-trunk/lang/c++
+./build.sh clean test
+```
+</details>
+
+<details><summary>Ruby</summary>
+
+```shell
+cd avro-trunk/lang/ruby
+gem install echoe
+rake clean test
+```
+</details>
+
+<details><summary>PHP</summary>
+
+```shell
+cd avro-trunk/lang/php
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>Documentation</summary>
+
+Please also check the documentation.
+Java
+
+```shell
+mvn compile
+mvn javadoc:aggregate
+firefox target/site/apidocs/index.html
+```
+
+Examine all public classes you've changed to see that documentation is complete, informative, and properly formatted. Your patch must not generate any javadoc warnings.
+</details>
+
+## Contributing your code
+
+Contribution can be made directly via github with a Pull Request, or via a patch.
+
+**Via Github**
+
+Method is to create a [pull request](https://help.github.com/articles/using-pull-requests/).
+
+On your fork, create a branch named with JIRA (avro-1234_fixNpe for example) 
+On source, go to it
+```shell
+git pull
+git switch avro-1234_fixNpe
+```
+
+code your changes (following preceding recommendations)
+
+check and add updated sources
+```shell
+git status
+
+# Add any new or changed files with:
+git add src/.../MyNewClass.java
+git add src/.../TestMyNewClass.java
+```
+
+Finally, create a commit with your changes and a good log message, and push it:
+```shell
+git commit -m ""AVRO-1234: Fix NPE by adding check to ...""
+git push
+```
+On your github fork site, a button will propose you to build the Pull Request.
+Click on it, fill Conversation form, and create it.
+Link this PR to the corresponding JIRA ticket (on JIRA ticket, add PR to ""Issue Links"" chapter, and add label 'pull-request-available' to it .
+
+
+<details><summary><b>Via Patch</b> (if you don't have github account)</summary>
+<blockquote>
+<details><summary><b>Clone avro repository</b></summary> 
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+</details>
+code your changes (following preceding recommendations)
+<details><summary><b>Creating a patch</b></summary>
+
+In order to create a patch, type:
+git diff > AVRO-1234.patch
+
+This will report all modifications done on Avro sources on your local disk and save them into the AVRO-1234.patch file. Read the patch file.
+Make sure it includes ONLY the modifications required to fix a single issue.
+
+Please do not:
+```
+reformat code unrelated to the bug being fixed: formatting changes should be separate patches/commits.
+comment out code that is now obsolete: just remove it.
+insert comments around each change, marking the change: folks can use subversion to figure out what's changed and by whom.
+make things public which are not required by end users.
+```
+Please do:
+```
+try to adhere to the coding style of files you edit;
+comment code whose function or rationale is not obvious;
+update documentation (e.g., package.html files, this wiki, etc.)
+name the patch file after the JIRA – AVRO-<JIRA#>.patch
+```
+</details>
+
+<details><summary><b>Applying a patch</b></summary>
+
+To apply a patch either you generated or found from JIRA, you can issue
+
+patch -p0 < AVRO-<JIRA#>.patch
+
+if you just want to check whether the patch applies you can run patch with --dry-run option
+
+patch -p0 --dry-run < AVRO-<JIRA#>.patch
+
+If you are an Eclipse user, you can apply a patch by:
+
+    Right click project name in Package Explorer
+    Team -> Apply Patch
+
+Finally, patches should be ''attached'' to an issue report in JIRA via the '''Attach File''' link on the issue's Jira. Please add a comment that asks for a code review following our code review checklist.
+</details>
+<details><summary><b>Contributing your patch</b></summary>
+
+When you believe that your patch is ready to be committed, select the '''Submit Patch''' link on the issue's Jira.
+
+Folks should run tests before selecting '''Submit Patch'''. Tests should all pass. Javadoc should report '''no''' warnings or errors. Submitting patches that fail tests is frowned on (unless the failure is not actually due to the patch).
+
+If your patch involves performance optimizations, they should be validated by benchmarks that demonstrate an improvement.
+
+If your patch creates an incompatibility with the latest major release, then you must set the '''Incompatible change''' flag on the issue's Jira 'and' fill in the '''Release Note''' field with an explanation of the impact of the incompatibility and the necessary steps users must take.
+
+If your patch implements a major feature or improvement, then you must fill in the '''Release Note''' field on the issue's Jira with an explanation of the feature that will be comprehensible by the end user.
+
+Once you have submitted your patch, a committer should evaluate it within a few days and either: commit it; or reject it with an explanation.
+
+Please be patient. Committers are busy people too. If no one responds to your patch after a few days, please make friendly reminders. Please incorporate other's suggestions into your patch if you think they're reasonable. Finally, remember that even a patch that is not committed is useful to the community.
+
+Should your patch be rejected, select the '''Resume Progress''' on the issue's Jira, upload a new patch with necessary fixes, and then select the **Submit Patch** link again.
+
+In many cases a patch may need to be updated based on review comments. In this case the updated patch should be re-attached to the Jira with the name name. Jira will archive the older version of the patch and make the new patch the active patch. This will enable a history of patches on the Jira. As stated above patch naming is generally AVRO-#.patch where AVRO-# is the id of the Jira issue.
+
+Committers: for non-trivial changes, it is best to get another committer to review your patches before commit. Use Submit Patch link like other contributors, and then wait for a ""+1"" from another committer before committing. Please also try to frequently review things in the patch queue.
+
+</details>
+
+<details><summary><b>Committing Guidelines for committers</b></summary>
+
+Apply the patch uploaded by the user or check out their pull request. Edit the CHANGES.txt file, adding a description of the change, including the bug number it fixes. Add it to the appropriate section - BUGFIXES, IMPROVEMENTS, NEW FEATURES. Please follow the format in CHANGES.txt file. While adding an entry please add it to the end of a section. Use the same entry for the first line of the git commit message.
+
+Changes are normally committed to master first, then, if they're backward-compatible, cherry-picked to a branch.
+
+When you commit a change, resolve the issue in Jira. When resolving, always set the fix version and assign the issue. Set the fix version to either to the next minor release if the change is compatible and will be merged to that branch, or to the next major release if the change is incompatible and will only be committed to trunk. Assign the issue to the primary author of the patch. If the author is not in the list of project contributors, edit their Jira roles and make them an Avro contributor.
+</details>
+</blockquote>
+</details>
+","[{'comment': '```suggestion\r\n-->\r\n```', 'commenter': 'RyanSkraba'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,294 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+./setup.py build test
+```
+</details>
+
+<details><summary><a href=""https://www.rust-lang.org/"">Rust</a></summary>
+
+```shell
+cd avro-trunk/lang/rust
+./build.sh clean test
+```
+</details>
+
+<details><summary>C#</summary>
+
+```shell
+cd avro-trunk/lang/csharp
+./build.sh clean test
+```
+</details>
+
+<details><summary>C</summary>
+
+```shell
+cd avro-trunk/lang/c
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>C++</summary>
+
+```shell
+cd avro-trunk/lang/c++
+./build.sh clean test
+```
+</details>
+
+<details><summary>Ruby</summary>
+
+```shell
+cd avro-trunk/lang/ruby
+gem install echoe
+rake clean test
+```
+</details>
+
+<details><summary>PHP</summary>
+
+```shell
+cd avro-trunk/lang/php
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>Documentation</summary>
+
+Please also check the documentation.
+Java
+
+```shell
+mvn compile
+mvn javadoc:aggregate
+firefox target/site/apidocs/index.html
+```
+
+Examine all public classes you've changed to see that documentation is complete, informative, and properly formatted. Your patch must not generate any javadoc warnings.
+</details>
+
+## Contributing your code
+
+Contribution can be made directly via github with a Pull Request, or via a patch.
+
+**Via Github**
+
+Method is to create a [pull request](https://help.github.com/articles/using-pull-requests/).
+
+On your fork, create a branch named with JIRA (avro-1234_fixNpe for example) 
+On source, go to it
+```shell
+git pull
+git switch avro-1234_fixNpe
+```
+
+code your changes (following preceding recommendations)
+
+check and add updated sources
+```shell
+git status
+
+# Add any new or changed files with:
+git add src/.../MyNewClass.java
+git add src/.../TestMyNewClass.java
+```
+
+Finally, create a commit with your changes and a good log message, and push it:
+```shell
+git commit -m ""AVRO-1234: Fix NPE by adding check to ...""
+git push
+```
+On your github fork site, a button will propose you to build the Pull Request.
+Click on it, fill Conversation form, and create it.
+Link this PR to the corresponding JIRA ticket (on JIRA ticket, add PR to ""Issue Links"" chapter, and add label 'pull-request-available' to it .
+
+
+<details><summary><b>Via Patch</b> (if you don't have github account)</summary>","[{'comment': ""```suggestion\r\n<!--  TODO: Fix formatting and decide whether this should be included in this section, moved to another section\r\n<details><summary><b>Via Patch</b> (if you don't have github account)</summary>\r\n```"", 'commenter': 'RyanSkraba'}, {'comment': 'section put in comments', 'commenter': 'clesaec'}]"
1707,doc/content/en/project/How to contribute/_index.md,"@@ -0,0 +1,294 @@
+---
+title: ""How to contribute""
+linkTitle: ""How to contribute""
+weight: 3
+---
+
+<!--
+
+ Licensed to the Apache Software Foundation (ASF) under one
+ or more contributor license agreements.  See the NOTICE file
+ distributed with this work for additional information
+ regarding copyright ownership.  The ASF licenses this file
+ to you under the Apache License, Version 2.0 (the
+ ""License""); you may not use this file except in compliance
+ with the License.  You may obtain a copy of the License at
+
+   https://www.apache.org/licenses/LICENSE-2.0
+
+ Unless required by applicable law or agreed to in writing,
+ software distributed under the License is distributed on an
+ ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
+ KIND, either express or implied.  See the License for the
+ specific language governing permissions and limitations
+ under the License.
+
+-->
+
+## Getting the source code
+
+First of all, you need the Avro source code.
+
+The easiest way is to clone or fork the GitHub mirror:
+
+```shell
+git clone https://github.com/apache/avro.git -o github
+```
+
+
+## Making Changes
+
+Before you start, file an issue in [JIRA](https://issues.apache.org/jira/browse/AVRO) or discuss your ideas on the [Avro developer mailing list](http://avro.apache.org/mailing_lists.html). Describe your proposed changes and check that they fit in with what others are doing and have planned for the project. Be patient, it may take folks a while to understand your requirements.
+
+Modify the source code and add some (very) nice features using your favorite IDE.
+
+But take care about the following points
+
+**All Languages**
+- Contributions should pass existing unit tests.
+- Contributions should document public facing APIs.
+- Contributions should add new tests to demonstrate bug fixes or test new features.
+
+**Java**
+
+- All public classes and methods should have informative [Javadoc comments](https://www.oracle.com/fr/technical-resources/articles/java/javadoc-tool.html).
+- Do not use @author tags.
+- Java code should be formatted according to [Oracle's conventions](https://www.oracle.com/java/technologies/javase/codeconventions-introduction.html), with one exception:
+  - Indent two spaces per level, not four.
+- [JUnit](http://www.junit.org/) is our test framework:
+- You must implement a class whose class name starts with Test.
+- Define methods within your class and tag them with the @Test annotation. Call JUnit's many assert methods to verify conditions; these methods will be executed when you run mvn test.
+- By default, do not let tests write any temporary files to /tmp. Instead, the tests should write to the location specified by the test.dir system property.
+- Place your class in the src/test/java/ tree.
+- You can run all the unit tests with the command mvn test, or you can run a specific unit test with the command mvn -Dtest=<class name, fully qualified or short name> test (for example mvn -Dtest=TestFoo test)
+
+
+## Code Style (Autoformatting)
+
+For Java code we use [Spotless](https://github.com/diffplug/spotless/) to format the code to comply with Avro's code style conventions (see above). Automatic formatting relies on [Avro's Eclipse JDT formatter definition](https://github.com/apache/avro/blob/master/lang/java/eclipse-java-formatter.xml). You can use the same definition to auto format from Eclipse or from IntelliJ configuring the Eclipse formatter plugin.
+
+If you use maven code styles issues are checked at the compile phase. If your code breaks because of bad formatting, you can format it automatically by running the command:
+```shell
+mvn spotless:apply
+```
+
+## Unit Tests
+
+Please make sure that all unit tests succeed before constructing your patch and that no new compiler warnings are introduced by your patch. Each language has its own directory and test process.
+
+<details><summary>Java</summary>
+
+```shell
+cd avro-trunk/lang/java
+mvn clean test
+```
+</details>
+
+<details><summary>Python</summary>
+
+```shell
+cd avro-trunk/lang/py
+./setup.py build test
+```
+</details>
+
+<details><summary><a href=""https://www.rust-lang.org/"">Rust</a></summary>
+
+```shell
+cd avro-trunk/lang/rust
+./build.sh clean test
+```
+</details>
+
+<details><summary>C#</summary>
+
+```shell
+cd avro-trunk/lang/csharp
+./build.sh clean test
+```
+</details>
+
+<details><summary>C</summary>
+
+```shell
+cd avro-trunk/lang/c
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>C++</summary>
+
+```shell
+cd avro-trunk/lang/c++
+./build.sh clean test
+```
+</details>
+
+<details><summary>Ruby</summary>
+
+```shell
+cd avro-trunk/lang/ruby
+gem install echoe
+rake clean test
+```
+</details>
+
+<details><summary>PHP</summary>
+
+```shell
+cd avro-trunk/lang/php
+./build.sh clean
+./build.sh test
+```
+</details>
+
+<details><summary>Documentation</summary>","[{'comment': ""This is largely overpromising what the given commands do!  I'd just take this out."", 'commenter': 'RyanSkraba'}, {'comment': 'Documentation generation removed.', 'commenter': 'clesaec'}]"
1718,lang/csharp/src/apache/main/Reflect/DotnetProperty.cs,"@@ -74,34 +75,38 @@ private bool IsPropertyCompatible(Avro.Schema.Type schemaTag)
                     return propType == typeof(byte[]);
                 case Avro.Schema.Type.Error:
                     return propType.IsClass;
+                case Avro.Schema.Type.Logical:
+                    var logicalSchema = (LogicalSchema)schema;
+                    var type = logicalSchema.LogicalType.GetCSharpType(false);
+                    return type == propType;
             }
 
             return false;
         }
 
-        public DotnetProperty(PropertyInfo property, Avro.Schema.Type schemaTag,  IAvroFieldConverter converter, ClassCache cache)
+        public DotnetProperty(PropertyInfo property, Avro.Schema schema, IAvroFieldConverter converter, ClassCache cache)","[{'comment': 'This does not break public API because DotnetProperty is an internal class.', 'commenter': 'KalleOlaviNiemitalo'}]"
1718,lang/csharp/src/apache/main/Reflect/ReflectDefaultWriter.cs,"@@ -199,6 +199,8 @@ protected override bool Matches(Schema sc, object obj)
                     return false;   // Union directly within another union not allowed!
                 case Schema.Type.Fixed:
                     return obj is byte[];
+                case Schema.Type.Logical:
+                    return ((LogicalSchema)sc).LogicalType.IsInstanceOfLogicalType(obj);","[{'comment': 'OK, `((LogicalSchema)sc).LogicalType` cannot be null here, because the LogicalSchema constructor assigns `LogicalType = LogicalTypeFactory.Instance.GetFromLogicalSchema(this)` without `ignoreInvalidOrUnknown: true`.\r\n\r\nBefore this PR, ReflectDefaultWriter.Matches always returned false for LogicalSchema, causing SpecificWriter.WriteUnion not to choose that schema. Is there any `obj` for which SpecificWriter could have succeeeded before, but for which it now starts choosing the logical schema? I think not, because IsInstanceOfLogicalType can only return true for AvroDecimal, Guid, DateTime, or TimeSpan, and none of those types matches any other Schema.Type in this `switch`. OK.', 'commenter': 'KalleOlaviNiemitalo'}]"
1718,lang/csharp/src/apache/test/Reflect/TestLogicalSchema.cs,"@@ -0,0 +1,177 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.test.Reflect
+{
+    public class TestLogicalSchema
+    {
+        [TestCase]
+        public void WriteAndReadObjectsWithLogicalSchemaFields_WithNullValues()
+        {
+            //Arrange
+            var obj = new TestObject
+            {
+                AvroDecimalNullableProperty = null,
+                AvroDecimalProperty = 13.42m,
+                GuidNullableProperty = null,
+                GuidProperty = Guid.NewGuid(),
+                DateNullableProperty = null,
+                DateProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateTimeMicrosecondNullableProperty = null,
+                DateTimeMicrosecondProperty = DateTime.UtcNow,
+                DateTimeMillisecondNullableProperty = null,
+                DateTimeMillisecondProperty = DateTime.UtcNow,
+                TimeSpanMicrosecondNullableProperty = null,
+                TimeSpanMicrosecondProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondNullableProperty = null,
+                TimeSpanMillisecondProperty = new TimeSpan(23, 59, 59),
+            };
+
+            var schema = Schema.Parse(SchemaJson);
+            var writer = new ReflectWriter<TestObject>(schema);
+            var reader = new ReflectReader<TestObject>(schema, schema);
+            var writeStream = new MemoryStream();
+            var writeBinaryEncoder = new BinaryEncoder(writeStream);
+
+            //Act
+            writer.Write(obj, writeBinaryEncoder);
+            var data = writeStream.ToArray();
+
+            var readStream = new MemoryStream(data);
+            var result = reader.Read(null, new BinaryDecoder(readStream));
+
+            //Assert
+            Assert.NotNull(result);
+            Assert.AreEqual(obj.AvroDecimalNullableProperty, result.AvroDecimalNullableProperty);
+            Assert.AreEqual(obj.AvroDecimalProperty, result.AvroDecimalProperty);
+            Assert.AreEqual(obj.GuidNullableProperty, result.GuidNullableProperty);
+            Assert.AreEqual(obj.GuidProperty, result.GuidProperty);
+            Assert.IsNull(obj.DateNullableProperty);
+            Assert.AreEqual(obj.DateProperty.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondNullableProperty, obj.DateTimeMicrosecondNullableProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondProperty, obj.DateTimeMicrosecondProperty);","[{'comment': 'These should truncate to microseconds (one tick of DateTime is 100 nanoseconds = 0.1 microseconds). The test passes because it compares to properties of the same object (`obj.` in both arguments, but one should be `result.`).', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Done', 'commenter': 'KhrystynaPopadyuk'}]"
1718,lang/csharp/src/apache/test/Reflect/TestLogicalSchema.cs,"@@ -0,0 +1,177 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.test.Reflect
+{
+    public class TestLogicalSchema
+    {
+        [TestCase]
+        public void WriteAndReadObjectsWithLogicalSchemaFields_WithNullValues()
+        {
+            //Arrange
+            var obj = new TestObject
+            {
+                AvroDecimalNullableProperty = null,
+                AvroDecimalProperty = 13.42m,
+                GuidNullableProperty = null,
+                GuidProperty = Guid.NewGuid(),
+                DateNullableProperty = null,
+                DateProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateTimeMicrosecondNullableProperty = null,
+                DateTimeMicrosecondProperty = DateTime.UtcNow,
+                DateTimeMillisecondNullableProperty = null,
+                DateTimeMillisecondProperty = DateTime.UtcNow,
+                TimeSpanMicrosecondNullableProperty = null,
+                TimeSpanMicrosecondProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondNullableProperty = null,
+                TimeSpanMillisecondProperty = new TimeSpan(23, 59, 59),
+            };
+
+            var schema = Schema.Parse(SchemaJson);
+            var writer = new ReflectWriter<TestObject>(schema);
+            var reader = new ReflectReader<TestObject>(schema, schema);
+            var writeStream = new MemoryStream();
+            var writeBinaryEncoder = new BinaryEncoder(writeStream);
+
+            //Act
+            writer.Write(obj, writeBinaryEncoder);
+            var data = writeStream.ToArray();
+
+            var readStream = new MemoryStream(data);
+            var result = reader.Read(null, new BinaryDecoder(readStream));
+
+            //Assert
+            Assert.NotNull(result);
+            Assert.AreEqual(obj.AvroDecimalNullableProperty, result.AvroDecimalNullableProperty);
+            Assert.AreEqual(obj.AvroDecimalProperty, result.AvroDecimalProperty);
+            Assert.AreEqual(obj.GuidNullableProperty, result.GuidNullableProperty);
+            Assert.AreEqual(obj.GuidProperty, result.GuidProperty);
+            Assert.IsNull(obj.DateNullableProperty);
+            Assert.AreEqual(obj.DateProperty.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondNullableProperty, obj.DateTimeMicrosecondNullableProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondProperty, obj.DateTimeMicrosecondProperty);
+            Assert.IsNull(result.DateTimeMillisecondNullableProperty);
+            Assert.AreEqual((obj.DateTimeMillisecondProperty.Ticks / 10000) * 10000, result.DateTimeMillisecondProperty.Ticks);
+            Assert.AreEqual(obj.TimeSpanMicrosecondNullableProperty, result.TimeSpanMicrosecondNullableProperty);
+            Assert.AreEqual(obj.TimeSpanMicrosecondProperty, result.TimeSpanMicrosecondProperty);
+            Assert.AreEqual(obj.TimeSpanMillisecondNullableProperty, result.TimeSpanMillisecondNullableProperty);
+            Assert.AreEqual(obj.TimeSpanMillisecondProperty, result.TimeSpanMillisecondProperty);","[{'comment': ""OK, these don't need to truncate, because the values are constant."", 'commenter': 'KalleOlaviNiemitalo'}]"
1718,lang/csharp/src/apache/test/Reflect/TestLogicalSchema.cs,"@@ -0,0 +1,177 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.test.Reflect
+{
+    public class TestLogicalSchema
+    {
+        [TestCase]
+        public void WriteAndReadObjectsWithLogicalSchemaFields_WithNullValues()
+        {
+            //Arrange
+            var obj = new TestObject
+            {
+                AvroDecimalNullableProperty = null,
+                AvroDecimalProperty = 13.42m,
+                GuidNullableProperty = null,
+                GuidProperty = Guid.NewGuid(),
+                DateNullableProperty = null,
+                DateProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateTimeMicrosecondNullableProperty = null,
+                DateTimeMicrosecondProperty = DateTime.UtcNow,
+                DateTimeMillisecondNullableProperty = null,
+                DateTimeMillisecondProperty = DateTime.UtcNow,
+                TimeSpanMicrosecondNullableProperty = null,
+                TimeSpanMicrosecondProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondNullableProperty = null,
+                TimeSpanMillisecondProperty = new TimeSpan(23, 59, 59),
+            };
+
+            var schema = Schema.Parse(SchemaJson);
+            var writer = new ReflectWriter<TestObject>(schema);
+            var reader = new ReflectReader<TestObject>(schema, schema);
+            var writeStream = new MemoryStream();
+            var writeBinaryEncoder = new BinaryEncoder(writeStream);
+
+            //Act
+            writer.Write(obj, writeBinaryEncoder);
+            var data = writeStream.ToArray();
+
+            var readStream = new MemoryStream(data);
+            var result = reader.Read(null, new BinaryDecoder(readStream));
+
+            //Assert
+            Assert.NotNull(result);
+            Assert.AreEqual(obj.AvroDecimalNullableProperty, result.AvroDecimalNullableProperty);
+            Assert.AreEqual(obj.AvroDecimalProperty, result.AvroDecimalProperty);
+            Assert.AreEqual(obj.GuidNullableProperty, result.GuidNullableProperty);
+            Assert.AreEqual(obj.GuidProperty, result.GuidProperty);
+            Assert.IsNull(obj.DateNullableProperty);
+            Assert.AreEqual(obj.DateProperty.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondNullableProperty, obj.DateTimeMicrosecondNullableProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondProperty, obj.DateTimeMicrosecondProperty);
+            Assert.IsNull(result.DateTimeMillisecondNullableProperty);
+            Assert.AreEqual((obj.DateTimeMillisecondProperty.Ticks / 10000) * 10000, result.DateTimeMillisecondProperty.Ticks);
+            Assert.AreEqual(obj.TimeSpanMicrosecondNullableProperty, result.TimeSpanMicrosecondNullableProperty);
+            Assert.AreEqual(obj.TimeSpanMicrosecondProperty, result.TimeSpanMicrosecondProperty);
+            Assert.AreEqual(obj.TimeSpanMillisecondNullableProperty, result.TimeSpanMillisecondNullableProperty);
+            Assert.AreEqual(obj.TimeSpanMillisecondProperty, result.TimeSpanMillisecondProperty);
+        }
+
+        [TestCase]
+        public void WriteAndReadObjectsWithLogicalSchemaFields_WithoutNullValues()
+        {
+            //Arrange
+            var obj = new TestObject
+            {
+                AvroDecimalNullableProperty = 136.42m,
+                AvroDecimalProperty = 13.42m,
+                GuidNullableProperty = Guid.NewGuid(),
+                GuidProperty = Guid.NewGuid(),
+                DateNullableProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateTimeMicrosecondNullableProperty = DateTime.UtcNow,
+                DateTimeMicrosecondProperty = DateTime.UtcNow,
+                DateTimeMillisecondNullableProperty = DateTime.UtcNow,
+                DateTimeMillisecondProperty = DateTime.UtcNow,
+                TimeSpanMicrosecondNullableProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMicrosecondProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondNullableProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondProperty = new TimeSpan(23, 59, 59),
+            };
+
+            var schema = Schema.Parse(SchemaJson);
+            var writer = new ReflectWriter<TestObject>(schema);
+            var reader = new ReflectReader<TestObject>(schema, schema);
+            var writeStream = new MemoryStream();
+            var writeBinaryEncoder = new BinaryEncoder(writeStream);
+
+            //Act
+            writer.Write(obj, writeBinaryEncoder);
+            var data = writeStream.ToArray();
+
+            var readStream = new MemoryStream(data);
+            var result = reader.Read(null, new BinaryDecoder(readStream));
+
+            //Assert
+            Assert.NotNull(result);
+            Assert.AreEqual(obj.AvroDecimalNullableProperty, result.AvroDecimalNullableProperty);
+            Assert.AreEqual(obj.AvroDecimalProperty, result.AvroDecimalProperty);
+            Assert.AreEqual(obj.GuidNullableProperty, result.GuidNullableProperty);
+            Assert.AreEqual(obj.GuidProperty, result.GuidProperty);
+            Assert.AreEqual(obj.DateNullableProperty?.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateProperty.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondNullableProperty, obj.DateTimeMicrosecondNullableProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondProperty, obj.DateTimeMicrosecondProperty);","[{'comment': 'The same bugs as in WriteAndReadObjectsWithLogicalSchemaFields_WithNullValues.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Referring to <https://github.com/apache/avro/pull/1718#discussion_r910120155>', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Done', 'commenter': 'KhrystynaPopadyuk'}]"
1718,lang/csharp/src/apache/test/Reflect/TestLogicalSchema.cs,"@@ -0,0 +1,177 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.IO;
+using Avro.IO;
+using Avro.Reflect;
+using NUnit.Framework;
+
+namespace Avro.test.Reflect
+{
+    public class TestLogicalSchema
+    {
+        [TestCase]
+        public void WriteAndReadObjectsWithLogicalSchemaFields_WithNullValues()
+        {
+            //Arrange
+            var obj = new TestObject
+            {
+                AvroDecimalNullableProperty = null,
+                AvroDecimalProperty = 13.42m,
+                GuidNullableProperty = null,
+                GuidProperty = Guid.NewGuid(),
+                DateNullableProperty = null,
+                DateProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateTimeMicrosecondNullableProperty = null,
+                DateTimeMicrosecondProperty = DateTime.UtcNow,
+                DateTimeMillisecondNullableProperty = null,
+                DateTimeMillisecondProperty = DateTime.UtcNow,
+                TimeSpanMicrosecondNullableProperty = null,
+                TimeSpanMicrosecondProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondNullableProperty = null,
+                TimeSpanMillisecondProperty = new TimeSpan(23, 59, 59),
+            };
+
+            var schema = Schema.Parse(SchemaJson);
+            var writer = new ReflectWriter<TestObject>(schema);
+            var reader = new ReflectReader<TestObject>(schema, schema);
+            var writeStream = new MemoryStream();
+            var writeBinaryEncoder = new BinaryEncoder(writeStream);
+
+            //Act
+            writer.Write(obj, writeBinaryEncoder);
+            var data = writeStream.ToArray();
+
+            var readStream = new MemoryStream(data);
+            var result = reader.Read(null, new BinaryDecoder(readStream));
+
+            //Assert
+            Assert.NotNull(result);
+            Assert.AreEqual(obj.AvroDecimalNullableProperty, result.AvroDecimalNullableProperty);
+            Assert.AreEqual(obj.AvroDecimalProperty, result.AvroDecimalProperty);
+            Assert.AreEqual(obj.GuidNullableProperty, result.GuidNullableProperty);
+            Assert.AreEqual(obj.GuidProperty, result.GuidProperty);
+            Assert.IsNull(obj.DateNullableProperty);
+            Assert.AreEqual(obj.DateProperty.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondNullableProperty, obj.DateTimeMicrosecondNullableProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondProperty, obj.DateTimeMicrosecondProperty);
+            Assert.IsNull(result.DateTimeMillisecondNullableProperty);
+            Assert.AreEqual((obj.DateTimeMillisecondProperty.Ticks / 10000) * 10000, result.DateTimeMillisecondProperty.Ticks);
+            Assert.AreEqual(obj.TimeSpanMicrosecondNullableProperty, result.TimeSpanMicrosecondNullableProperty);
+            Assert.AreEqual(obj.TimeSpanMicrosecondProperty, result.TimeSpanMicrosecondProperty);
+            Assert.AreEqual(obj.TimeSpanMillisecondNullableProperty, result.TimeSpanMillisecondNullableProperty);
+            Assert.AreEqual(obj.TimeSpanMillisecondProperty, result.TimeSpanMillisecondProperty);
+        }
+
+        [TestCase]
+        public void WriteAndReadObjectsWithLogicalSchemaFields_WithoutNullValues()
+        {
+            //Arrange
+            var obj = new TestObject
+            {
+                AvroDecimalNullableProperty = 136.42m,
+                AvroDecimalProperty = 13.42m,
+                GuidNullableProperty = Guid.NewGuid(),
+                GuidProperty = Guid.NewGuid(),
+                DateNullableProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateProperty = new DateTime(2022, 05, 26, 14, 57, 24, 123),
+                DateTimeMicrosecondNullableProperty = DateTime.UtcNow,
+                DateTimeMicrosecondProperty = DateTime.UtcNow,
+                DateTimeMillisecondNullableProperty = DateTime.UtcNow,
+                DateTimeMillisecondProperty = DateTime.UtcNow,
+                TimeSpanMicrosecondNullableProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMicrosecondProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondNullableProperty = new TimeSpan(23, 59, 59),
+                TimeSpanMillisecondProperty = new TimeSpan(23, 59, 59),
+            };
+
+            var schema = Schema.Parse(SchemaJson);
+            var writer = new ReflectWriter<TestObject>(schema);
+            var reader = new ReflectReader<TestObject>(schema, schema);
+            var writeStream = new MemoryStream();
+            var writeBinaryEncoder = new BinaryEncoder(writeStream);
+
+            //Act
+            writer.Write(obj, writeBinaryEncoder);
+            var data = writeStream.ToArray();
+
+            var readStream = new MemoryStream(data);
+            var result = reader.Read(null, new BinaryDecoder(readStream));
+
+            //Assert
+            Assert.NotNull(result);
+            Assert.AreEqual(obj.AvroDecimalNullableProperty, result.AvroDecimalNullableProperty);
+            Assert.AreEqual(obj.AvroDecimalProperty, result.AvroDecimalProperty);
+            Assert.AreEqual(obj.GuidNullableProperty, result.GuidNullableProperty);
+            Assert.AreEqual(obj.GuidProperty, result.GuidProperty);
+            Assert.AreEqual(obj.DateNullableProperty?.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateProperty.Date, result.DateProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondNullableProperty, obj.DateTimeMicrosecondNullableProperty);
+            Assert.AreEqual(obj.DateTimeMicrosecondProperty, obj.DateTimeMicrosecondProperty);
+            Assert.AreEqual((obj.TimeSpanMicrosecondNullableProperty?.Ticks / 10000) * 10000, result.TimeSpanMicrosecondNullableProperty?.Ticks);","[{'comment': 'Should compare DateTimeMillisecondNullableProperty rather than TimeSpanMicrosecondNullableProperty, which is compared again below.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Done', 'commenter': 'KhrystynaPopadyuk'}]"
1775,lang/rust/avro/src/schema.rs,"@@ -2030,6 +2030,51 @@ mod tests {
         assert_eq!(schema_c, schema_c_expected);
     }
 
+    // AVRO-3584 : recursion in type definitions
+    #[test]
+    fn test_recursion_records() {","[{'comment': '```suggestion\r\n    fn avro_3584_test_recursion_records() {\r\n```', 'commenter': 'martin-g'}, {'comment': 'updated', 'commenter': 'clesaec'}]"
1775,lang/rust/avro/src/schema.rs,"@@ -2030,6 +2030,51 @@ mod tests {
         assert_eq!(schema_c, schema_c_expected);
     }
 
+    // AVRO-3584 : recursion in type definitions
+    #[test]
+    fn test_recursion_records() {
+        use std::iter::FromIterator;
+
+        // A and B are the same except the name.
+        let schema_str_a = r#""{
+            ""name"": ""A"",
+            ""type"": ""record"",
+            ""fields"": [ {""name"": ""field_one"", ""type"": ""B""} ]
+        }""#;
+
+        let schema_str_b = r#""{
+            ""name"": ""B"",
+            ""type"": ""record"",
+            ""fields"": [   {""name"": ""field_one"", ""type"": ""A""} ]
+        }""#;
+
+        let list = Schema::parse_list(&[schema_str_a, schema_str_b])
+            .unwrap();
+
+        let schema_a = list
+            .first()
+            .unwrap()
+            .clone();
+        let schema_b = list
+            .get(1)
+            .unwrap()
+            .clone();
+
+        match schema_a {
+            Schema::Record { fields, .. } => {
+                let f1 = fields.get(0);
+                let string = f1.unwrap().schema.canonical_form();","[{'comment': '`string` looks unused', 'commenter': 'martin-g'}, {'comment': 'removed', 'commenter': 'clesaec'}]"
1775,lang/rust/avro/src/schema.rs,"@@ -2030,6 +2030,44 @@ mod tests {
         assert_eq!(schema_c, schema_c_expected);
     }
 
+    // AVRO-3584 : recursion in type definitions
+    #[test]
+    fn avro_3584_test_recursion_records() {
+        // A and B are the same except the name.
+        let schema_str_a = r#""{
+            ""name"": ""A"",
+            ""type"": ""record"",
+            ""fields"": [ {""name"": ""field_one"", ""type"": ""B""} ]
+        }""#;
+
+        let schema_str_b = r#""{
+            ""name"": ""B"",
+            ""type"": ""record"",
+            ""fields"": [   {""name"": ""field_one"", ""type"": ""A""} ]
+        }""#;
+
+        let list = Schema::parse_list(&[schema_str_a, schema_str_b])
+            .unwrap();
+
+        let schema_a = list
+            .first()
+            .unwrap()
+            .clone();
+
+        match schema_a {
+            Schema::Record { fields, .. } => {
+                let f1 = fields.get(0);
+
+                let refSchema = Schema::Ref {","[{'comment': ""in the previous run `clippy` complained that `refSchema` should be `ref_schema`, but it didn't complain in this run ...\r\nStrange."", 'commenter': 'martin-g'}, {'comment': 'ok, renamed to ref_schema.', 'commenter': 'clesaec'}]"
1778,lang/rust/avro/src/encode.rs,"@@ -134,6 +134,9 @@ pub(crate) fn encode_internal<S: Borrow<Schema>>(
                     return Err(Error::GetEnumSymbol(s.clone()));
                 }
             }
+            Schema::Uuid => {","[{'comment': 'You should be able to add this condition to the above. L 126\r\n\r\n```\r\nSchema::String | Schema::Uuid => ....\r\n```\r\n', 'commenter': 'jklamer'}, {'comment': ""Agreed!\r\n@RikHeijdens Please update the PR with @jklamer's suggestion."", 'commenter': 'martin-g'}, {'comment': ""Updated the PR with @jklamer's suggestion in https://github.com/apache/avro/pull/1778/commits/f0203f0ff4b46bb008c5c89d6856abc45c10cf3b!"", 'commenter': 'RikHeijdens'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/JsonGrammarGenerator.cs,"@@ -0,0 +1,104 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// The class that generates a grammar suitable to parse Avro data in JSON
+    /// format.
+    /// </summary>
+    public class JsonGrammarGenerator : ValidatingGrammarGenerator
+    {
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// grammar for the given schema <tt>sc</tt>.
+        /// </summary>
+        public override Symbol Generate(Schema schema)
+        {
+            return Symbol.NewRoot(Generate(schema, new Dictionary<LitS, Symbol>()));
+        }
+
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for grammar of the given
+        /// schema <tt>sc</tt>. If there is already an entry for the given schema in the
+        /// given map <tt>seen</tt> then that entry is returned. Otherwise a new symbol
+        /// is generated and an entry is inserted into the map.
+        /// </summary>
+        /// <param name=""sc"">   The schema for which the start symbol is required </param>
+        /// <param name=""seen""> A map of schema to symbol mapping done so far. </param>
+        /// <returns> The start symbol for the schema </returns>
+        protected override Symbol Generate(Schema sc, IDictionary<LitS, Symbol> seen)
+        {
+            switch (sc.Tag)
+            {
+                case Schema.Type.Null:
+                case Schema.Type.Boolean:
+                case Schema.Type.Int:
+                case Schema.Type.Long:
+                case Schema.Type.Float:
+                case Schema.Type.Double:
+                case Schema.Type.String:
+                case Schema.Type.Bytes:
+                case Schema.Type.Fixed:
+                case Schema.Type.Union:
+                    return base.Generate(sc, seen);
+                case Schema.Type.Enumeration:
+                    return Symbol.NewSeq(new Symbol.EnumLabelsAction(((EnumSchema)sc).Symbols), Symbol.Enum);
+                case Schema.Type.Array:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.ArrayEnd, Symbol.ItemEnd, Generate(((ArraySchema)sc).ItemSchema, seen)),
+                        Symbol.ArrayStart);
+                case Schema.Type.Map:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.MapEnd, Symbol.ItemEnd, Generate(((MapSchema)sc).ValueSchema, seen),
+                            Symbol.MapKeyMarker, Symbol.String), Symbol.MapStart);
+                case Schema.Type.Record:
+                    {
+                        LitS wsc = new LitS(sc);
+                        Symbol rresult = seen.ContainsKey(wsc) ? seen[wsc] : null;
+                        if (rresult == null)
+                        {
+                            Symbol[] production = new Symbol[((RecordSchema)sc).Fields.Count * 3 + 2];
+                            rresult = Symbol.NewSeq(production);
+                            seen[wsc] = rresult;
+
+                            int i = production.Length;
+                            int n = 0;
+                            production[--i] = Symbol.RecordStart;
+                            foreach (Field f in ((RecordSchema)sc).Fields)
+                            {
+                                production[--i] = Symbol.fieldAdjustAction(n, f.Name, f.Aliases);
+                                production[--i] = Generate(f.Schema, seen);
+                                production[--i] = Symbol.FieldEnd;
+                                n++;
+                            }
+
+                            production[--i] = Symbol.RecordEnd;","[{'comment': '## Useless assignment to local variable\n\nThis assignment to [i](1) is useless, since its value is never read.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2896)', 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/ValidatingGrammarGenerator.cs,"@@ -0,0 +1,152 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// The class that generates validating grammar.
+    /// </summary>
+    public class ValidatingGrammarGenerator
+    {
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// given schema <tt>sc</tt>.
+        /// </summary>
+        public virtual Symbol Generate(Schema schema)
+        {
+            return Symbol.NewRoot(Generate(schema, new Dictionary<LitS, Symbol>()));
+        }
+
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// given schema <tt>sc</tt>. If there is already an entry for the given schema
+        /// in the given map <tt>seen</tt> then that entry is returned. Otherwise a new
+        /// symbol is generated and an entry is inserted into the map.
+        /// </summary>
+        /// <param name=""sc"">   The schema for which the start symbol is required </param>
+        /// <param name=""seen""> A map of schema to symbol mapping done so far. </param>
+        /// <returns> The start symbol for the schema </returns>
+        protected virtual Symbol Generate(Schema sc, IDictionary<LitS, Symbol> seen)
+        {
+            switch (sc.Tag)
+            {
+                case Schema.Type.Null:
+                    return Symbol.Null;
+                case Schema.Type.Boolean:
+                    return Symbol.Boolean;
+                case Schema.Type.Int:
+                    return Symbol.Int;
+                case Schema.Type.Long:
+                    return Symbol.Long;
+                case Schema.Type.Float:
+                    return Symbol.Float;
+                case Schema.Type.Double:
+                    return Symbol.Double;
+                case Schema.Type.String:
+                    return Symbol.String;
+                case Schema.Type.Bytes:
+                    return Symbol.Bytes;
+                case Schema.Type.Fixed:
+                    return Symbol.NewSeq(new Symbol.IntCheckAction(((FixedSchema)sc).Size), Symbol.Fixed);
+                case Schema.Type.Enumeration:
+                    return Symbol.NewSeq(new Symbol.IntCheckAction(((EnumSchema)sc).Symbols.Count), Symbol.Enum);
+                case Schema.Type.Array:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.ArrayEnd, Generate(((ArraySchema)sc).ItemSchema, seen)),
+                        Symbol.ArrayStart);
+                case Schema.Type.Map:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.MapEnd, Generate(((MapSchema)sc).ValueSchema, seen), Symbol.String),
+                        Symbol.MapStart);
+                case Schema.Type.Record:
+                    {
+                        LitS wsc = new LitS(sc);
+                        Symbol rresult = seen.ContainsKey(wsc) ? seen[wsc] : null;
+                        if (rresult == null)
+                        {
+                            Symbol[] production = new Symbol[((RecordSchema)sc).Fields.Count];
+
+                            // We construct a symbol without filling the array. Please see
+                            // <seealso cref=""Symbol.production""/> for the reason.
+                            rresult = Symbol.NewSeq(production);
+                            seen[wsc] = rresult;
+
+                            int j = production.Length;
+                            foreach (Field f in ((RecordSchema)sc).Fields)
+                            {
+                                production[--j] = Generate(f.Schema, seen);
+                            }
+                        }
+
+                        return rresult;
+                    }
+                case Schema.Type.Union:
+                    IList<Schema> subs = ((UnionSchema)sc).Schemas;
+                    Symbol[] symbols = new Symbol[subs.Count];
+                    string[] labels = new string[subs.Count];
+
+                    int i = 0;
+                    foreach (Schema b in ((UnionSchema)sc).Schemas)
+                    {
+                        symbols[i] = Generate(b, seen);
+                        labels[i] = b.Fullname;
+                        i++;
+                    }
+
+                    return Symbol.NewSeq(Symbol.NewAlt(symbols, labels), Symbol.Union);
+
+                default:
+                    throw new Exception(""Unexpected schema type"");
+            }
+        }
+
+        /// <summary>
+        /// A wrapper around Schema that does ""=="" equality. </summary>
+        protected class LitS
+        {
+            private readonly Schema actual;
+
+            public LitS(Schema actual)
+            {
+                this.actual = actual;
+            }
+
+            /// <summary>
+            /// Two LitS are equal if and only if their underlying schema is the same (not
+            /// merely equal).
+            /// </summary>
+            public override bool Equals(object o)
+            {
+                if (!(o is LitS))","[{'comment': '## Equals should not apply ""is""\n\nLitS.Equals(object) should not use ""is"" on its parameter, as it will not work properly for subclasses of LitS.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2902)', 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Symbol.cs,"@@ -0,0 +1,778 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Symbol is the base of all symbols (terminals and non-terminals) of the
+    /// grammar.
+    /// </summary>
+    public abstract class Symbol
+    {
+        /// <summary>
+        /// The type of symbol.
+        /// </summary>
+        public enum Kind
+        {
+            /// <summary>
+            /// terminal symbols which have no productions </summary>
+            Terminal,
+
+            /// <summary>
+            /// Start symbol for some grammar </summary>
+            Root,
+
+            /// <summary>
+            /// non-terminal symbol which is a sequence of one or more other symbols </summary>
+            Sequence,
+
+            /// <summary>
+            /// non-terminal to represent the contents of an array or map </summary>
+            Repeater,
+
+            /// <summary>
+            /// non-terminal to represent the union </summary>
+            Alternative,
+
+            /// <summary>
+            /// non-terminal action symbol which are automatically consumed </summary>
+            ImplicitAction,
+
+            /// <summary>
+            /// non-terminal action symbol which is explicitly consumed </summary>
+            ExplicitAction
+        }
+
+        /// The kind of this symbol.
+        public readonly Kind SymKind;
+
+        /// <summary>
+        /// The production for this symbol. If this symbol is a terminal this is
+        /// <tt>null</tt>. Otherwise this holds the the sequence of the symbols that
+        /// forms the production for this symbol. The sequence is in the reverse order of
+        /// production. This is useful for easy copying onto parsing stack.
+        ///
+        /// Please note that this is a final. So the production for a symbol should be
+        /// known before that symbol is constructed. This requirement cannot be met for
+        /// those symbols which are recursive (e.g. a record that holds union a branch of
+        /// which is the record itself). To resolve this problem, we initialize the
+        /// symbol with an array of nulls. Later we fill the symbols. Not clean, but
+        /// works. The other option is to not have this field a final. But keeping it
+        /// final and thus keeping symbol immutable gives some comfort. See various
+        /// generators how we generate records.
+        /// </summary>
+        public readonly Symbol[] Production;
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind.
+        /// </summary>
+        protected Symbol(Kind kind) : this(kind, null)
+        {
+        }
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind and production.
+        /// </summary>
+        protected Symbol(Kind kind, Symbol[] production)
+        {
+            this.Production = production;
+            this.SymKind = kind;
+        }
+
+        /// <summary>
+        /// A convenience method to construct a root symbol.
+        /// </summary>
+        public static Symbol NewRoot(params Symbol[] symbols)
+        {
+            return new Root(symbols);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a sequence.
+        /// </summary>
+        /// <param name=""production""> The constituent symbols of the sequence. </param>
+        public static Symbol NewSeq(params Symbol[] production)
+        {
+            return new Sequence(production);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a repeater.
+        /// </summary>
+        /// <param name=""endSymbol""> The end symbol. </param>
+        /// <param name=""symsToRepeat""> The symbols to repeat in the repeater. </param>
+        public static Symbol NewRepeat(Symbol endSymbol, params Symbol[] symsToRepeat)
+        {
+            return new Repeater(endSymbol, symsToRepeat);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a union.
+        /// </summary>
+        public static Symbol NewAlt(Symbol[] symbols, string[] labels)
+        {
+            return new Alternative(symbols, labels);
+        }
+
+        /// <summary>
+        /// A convenience method to construct an ErrorAction.
+        /// </summary>
+        /// <param name=""e""> </param>
+        protected static Symbol Error(string e)
+        {
+            return new ErrorAction(e);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a ResolvingAction.
+        /// </summary>
+        /// <param name=""w""> The writer symbol </param>
+        /// <param name=""r""> The reader symbol </param>
+        protected static Symbol Resolve(Symbol w, Symbol r)
+        {
+            return new ResolvingAction(w, r);
+        }
+
+        protected class Fixup
+        {
+            public readonly Symbol[] Symbols;
+            public readonly int Pos;
+
+            public Fixup(Symbol[] symbols, int pos)","[{'comment': ""## Exposing internal representation\n\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](1).\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](2).\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](3).\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](4).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2895)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/test/IO/JsonCodecTests.cs,"@@ -0,0 +1,226 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using NUnit.Framework;
+using System.IO;
+using System.Text;
+using Avro.Generic;
+using Avro.IO;
+using Newtonsoft.Json.Linq;
+
+namespace Avro.Test
+{
+    using Decoder = Avro.IO.Decoder;
+    using Encoder = Avro.IO.Encoder;
+
+    /// <summary>
+    /// Tests the JsonEncoder and JsonDecoder.
+    /// </summary>
+    [TestFixture]
+    public class JsonCodecTests
+    {
+        [TestCase]
+        public void TestJsonEncoderWhenIncludeNamespaceOptionIsFalse()
+        {
+            string value = ""{\""b\"": {\""string\"":\""myVal\""}, \""a\"": 1}"";
+            string schemaStr = ""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": ["" +
+                               ""{\""name\"": \""a\"", \""type\"": \""int\""}, {\""name\"": \""b\"", \""type\"": [\""null\"", \""string\""]}"" +
+                               ""]}"";
+            Schema schema = Schema.Parse(schemaStr);
+            byte[] avroBytes = fromJsonToAvro(value, schema);
+
+            Assert.IsTrue(JToken.DeepEquals(JObject.Parse(""{\""b\"":\""myVal\"",\""a\"":1}""),
+                JObject.Parse(fromAvroToJson(avroBytes, schema, false))));
+        }
+
+        [TestCase]
+        public void TestJsonEncoderWhenIncludeNamespaceOptionIsTrue()
+        {
+            string value = ""{\""b\"": {\""string\"":\""myVal\""}, \""a\"": 1}"";
+            string schemaStr = ""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": ["" +
+                               ""{\""name\"": \""a\"", \""type\"": \""int\""}, {\""name\"": \""b\"", \""type\"": [\""null\"", \""string\""]}"" +
+                               ""]}"";
+            Schema schema = Schema.Parse(schemaStr);
+            byte[] avroBytes = fromJsonToAvro(value, schema);
+
+            Assert.IsTrue(JToken.DeepEquals(JObject.Parse(""{\""b\"":{\""string\"":\""myVal\""},\""a\"":1}""),
+                JObject.Parse(fromAvroToJson(avroBytes, schema, true))));
+        }
+
+        [TestCase]
+        public void TestJsonRecordOrdering()
+        {
+            string value = ""{\""b\"": 2, \""a\"": 1}"";
+            Schema schema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": ["" +
+                                         ""{\""name\"": \""a\"", \""type\"": \""int\""}, {\""name\"": \""b\"", \""type\"": \""int\""}"" +
+                                         ""]}"");
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(schema, schema);
+            Decoder decoder = new JsonDecoder(schema, value);
+            object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":1,\""b\"":2}"", fromDatumToJson(o, schema, false));
+        }
+
+        [TestCase]
+        public void TestJsonRecordOrdering2()
+        {
+            string value = ""{\""b\"": { \""b3\"": 1.4, \""b2\"": 3.14, \""b1\"": \""h\""}, \""a\"": {\""a2\"":true, \""a1\"": null}}"";
+            Schema schema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n"" +
+                                         ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n"" +
+                                         ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}},\n"" +
+                                         ""{\""name\"": \""b\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""B\"",\""fields\"":\n"" +
+                                         ""[{\""name\"":\""b1\"", \""type\"":\""string\""}, {\""name\"":\""b2\"", \""type\"":\""float\""}, {\""name\"":\""b3\"", \""type\"":\""double\""}]}}\n"" +
+                                         ""]}"");
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(schema, schema);
+            Decoder decoder = new JsonDecoder(schema, value);
+            object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":{\""a1\"":null,\""a2\"":true},\""b\"":{\""b1\"":\""h\"",\""b2\"":3.14,\""b3\"":1.4}}"",
+                fromDatumToJson(o, schema, false));
+        }
+
+        [TestCase]
+        public void TestJsonRecordOrderingWithProjection()
+        {
+            String value = ""{\""b\"": { \""b3\"": 1.4, \""b2\"": 3.14, \""b1\"": \""h\""}, \""a\"": {\""a2\"":true, \""a1\"": null}}"";
+            Schema writerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}},\n""
+                                               + ""{\""name\"": \""b\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""B\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""b1\"", \""type\"":\""string\""}, {\""name\"":\""b2\"", \""type\"":\""float\""}, {\""name\"":\""b3\"", \""type\"":\""double\""}]}}\n""
+                                               + ""]}"");
+            Schema readerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}}\n"" +
+                                               ""]}"");
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(writerSchema, readerSchema);
+            Decoder decoder = new JsonDecoder(writerSchema, value);
+            Object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":{\""a1\"":null,\""a2\"":true}}"",
+                fromDatumToJson(o, readerSchema, false));
+        }
+
+
+        [TestCase]
+        public void testJsonRecordOrderingWithProjection2()
+        {
+            String value =
+                ""{\""b\"": { \""b1\"": \""h\"", \""b2\"": [3.14, 3.56], \""b3\"": 1.4}, \""a\"": {\""a2\"":true, \""a1\"": null}}"";
+            Schema writerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}},\n""
+                                               + ""{\""name\"": \""b\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""B\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""b1\"", \""type\"":\""string\""}, {\""name\"":\""b2\"", \""type\"":{\""type\"":\""array\"", \""items\"":\""float\""}}, {\""name\"":\""b3\"", \""type\"":\""double\""}]}}\n""
+                                               + ""]}"");
+
+            Schema readerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}}\n"" +
+                                               ""]}"");
+
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(writerSchema, readerSchema);
+            Decoder decoder = new JsonDecoder(writerSchema, value);
+            object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":{\""a1\"":null,\""a2\"":true}}"",
+                fromDatumToJson(o, readerSchema, false));
+        }
+
+        [TestCase(""int"", 1)]
+        [TestCase(""long"", 1L)]
+        [TestCase(""float"", 1.0F)]
+        [TestCase(""double"", 1.0)]
+        public void TestJsonDecoderNumeric(string type, object value)
+        {
+            string def = ""{\""type\"":\""record\"",\""name\"":\""X\"",\""fields\"":"" + ""[{\""type\"":\"""" + type +
+                         ""\"",\""name\"":\""n\""}]}"";
+            Schema schema = Schema.Parse(def);
+            DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>(schema, schema);
+
+            string[] records = { ""{\""n\"":1}"", ""{\""n\"":1.0}"" };
+
+            foreach (string record in records)
+            {
+                Decoder decoder = new JsonDecoder(schema, record);
+                GenericRecord r = reader.Read(null, decoder);
+                Assert.AreEqual(value, r[""n""]);
+            }","[{'comment': ""## Missed opportunity to use Select\n\nThis foreach loop immediately maps its iteration variable to another variable [here](1) - consider mapping the sequence explicitly using '.Select(...)'.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2897)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/JsonGrammarGenerator.cs,"@@ -0,0 +1,104 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// The class that generates a grammar suitable to parse Avro data in JSON
+    /// format.
+    /// </summary>
+    public class JsonGrammarGenerator : ValidatingGrammarGenerator
+    {
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// grammar for the given schema <tt>sc</tt>.
+        /// </summary>
+        public override Symbol Generate(Schema schema)
+        {
+            return Symbol.NewRoot(Generate(schema, new Dictionary<LitS, Symbol>()));
+        }
+
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for grammar of the given
+        /// schema <tt>sc</tt>. If there is already an entry for the given schema in the
+        /// given map <tt>seen</tt> then that entry is returned. Otherwise a new symbol
+        /// is generated and an entry is inserted into the map.
+        /// </summary>
+        /// <param name=""sc"">   The schema for which the start symbol is required </param>
+        /// <param name=""seen""> A map of schema to symbol mapping done so far. </param>
+        /// <returns> The start symbol for the schema </returns>
+        protected override Symbol Generate(Schema sc, IDictionary<LitS, Symbol> seen)
+        {
+            switch (sc.Tag)
+            {
+                case Schema.Type.Null:
+                case Schema.Type.Boolean:
+                case Schema.Type.Int:
+                case Schema.Type.Long:
+                case Schema.Type.Float:
+                case Schema.Type.Double:
+                case Schema.Type.String:
+                case Schema.Type.Bytes:
+                case Schema.Type.Fixed:
+                case Schema.Type.Union:
+                    return base.Generate(sc, seen);
+                case Schema.Type.Enumeration:
+                    return Symbol.NewSeq(new Symbol.EnumLabelsAction(((EnumSchema)sc).Symbols), Symbol.Enum);
+                case Schema.Type.Array:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.ArrayEnd, Symbol.ItemEnd, Generate(((ArraySchema)sc).ItemSchema, seen)),
+                        Symbol.ArrayStart);
+                case Schema.Type.Map:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.MapEnd, Symbol.ItemEnd, Generate(((MapSchema)sc).ValueSchema, seen),
+                            Symbol.MapKeyMarker, Symbol.String), Symbol.MapStart);
+                case Schema.Type.Record:
+                    {
+                        LitS wsc = new LitS(sc);
+                        Symbol rresult = seen.ContainsKey(wsc) ? seen[wsc] : null;","[{'comment': ""## Inefficient use of ContainsKey\n\nInefficient use of 'ContainsKey' and [indexer](1).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2898)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Symbol.cs,"@@ -0,0 +1,778 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Symbol is the base of all symbols (terminals and non-terminals) of the
+    /// grammar.
+    /// </summary>
+    public abstract class Symbol
+    {
+        /// <summary>
+        /// The type of symbol.
+        /// </summary>
+        public enum Kind
+        {
+            /// <summary>
+            /// terminal symbols which have no productions </summary>
+            Terminal,
+
+            /// <summary>
+            /// Start symbol for some grammar </summary>
+            Root,
+
+            /// <summary>
+            /// non-terminal symbol which is a sequence of one or more other symbols </summary>
+            Sequence,
+
+            /// <summary>
+            /// non-terminal to represent the contents of an array or map </summary>
+            Repeater,
+
+            /// <summary>
+            /// non-terminal to represent the union </summary>
+            Alternative,
+
+            /// <summary>
+            /// non-terminal action symbol which are automatically consumed </summary>
+            ImplicitAction,
+
+            /// <summary>
+            /// non-terminal action symbol which is explicitly consumed </summary>
+            ExplicitAction
+        }
+
+        /// The kind of this symbol.
+        public readonly Kind SymKind;
+
+        /// <summary>
+        /// The production for this symbol. If this symbol is a terminal this is
+        /// <tt>null</tt>. Otherwise this holds the the sequence of the symbols that
+        /// forms the production for this symbol. The sequence is in the reverse order of
+        /// production. This is useful for easy copying onto parsing stack.
+        ///
+        /// Please note that this is a final. So the production for a symbol should be
+        /// known before that symbol is constructed. This requirement cannot be met for
+        /// those symbols which are recursive (e.g. a record that holds union a branch of
+        /// which is the record itself). To resolve this problem, we initialize the
+        /// symbol with an array of nulls. Later we fill the symbols. Not clean, but
+        /// works. The other option is to not have this field a final. But keeping it
+        /// final and thus keeping symbol immutable gives some comfort. See various
+        /// generators how we generate records.
+        /// </summary>
+        public readonly Symbol[] Production;
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind.
+        /// </summary>
+        protected Symbol(Kind kind) : this(kind, null)
+        {
+        }
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind and production.
+        /// </summary>
+        protected Symbol(Kind kind, Symbol[] production)
+        {
+            this.Production = production;
+            this.SymKind = kind;
+        }
+
+        /// <summary>
+        /// A convenience method to construct a root symbol.
+        /// </summary>
+        public static Symbol NewRoot(params Symbol[] symbols)
+        {
+            return new Root(symbols);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a sequence.
+        /// </summary>
+        /// <param name=""production""> The constituent symbols of the sequence. </param>
+        public static Symbol NewSeq(params Symbol[] production)
+        {
+            return new Sequence(production);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a repeater.
+        /// </summary>
+        /// <param name=""endSymbol""> The end symbol. </param>
+        /// <param name=""symsToRepeat""> The symbols to repeat in the repeater. </param>
+        public static Symbol NewRepeat(Symbol endSymbol, params Symbol[] symsToRepeat)
+        {
+            return new Repeater(endSymbol, symsToRepeat);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a union.
+        /// </summary>
+        public static Symbol NewAlt(Symbol[] symbols, string[] labels)
+        {
+            return new Alternative(symbols, labels);
+        }
+
+        /// <summary>
+        /// A convenience method to construct an ErrorAction.
+        /// </summary>
+        /// <param name=""e""> </param>
+        protected static Symbol Error(string e)
+        {
+            return new ErrorAction(e);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a ResolvingAction.
+        /// </summary>
+        /// <param name=""w""> The writer symbol </param>
+        /// <param name=""r""> The reader symbol </param>
+        protected static Symbol Resolve(Symbol w, Symbol r)
+        {
+            return new ResolvingAction(w, r);
+        }
+
+        protected class Fixup
+        {
+            public readonly Symbol[] Symbols;
+            public readonly int Pos;
+
+            public Fixup(Symbol[] symbols, int pos)
+            {
+                this.Symbols = symbols;
+                this.Pos = pos;
+            }
+        }
+
+        protected virtual Symbol Flatten(IDictionary<Sequence, Sequence> map, IDictionary<Sequence, IList<Fixup>> map2)
+        {
+            return this;
+        }
+
+        public virtual int FlattenedSize()
+        {
+            return 1;
+        }
+
+        /// <summary>
+        /// Flattens the given sub-array of symbols into an sub-array of symbols. Every
+        /// <tt>Sequence</tt> in the input are replaced by its production recursively.
+        /// Non-<tt>Sequence</tt> symbols, they internally have other symbols those
+        /// internal symbols also get flattened. When flattening is done, the only place
+        /// there might be Sequence symbols is in the productions of a Repeater,
+        /// Alternative, or the symToParse and symToSkip in a UnionAdjustAction or
+        /// SkipAction.
+        ///
+        /// Why is this done? We want our parsers to be fast. If we left the grammars
+        /// unflattened, then the parser would be constantly copying the contents of
+        /// nested Sequence productions onto the parsing stack. Instead, because of
+        /// flattening, we have a long top-level production with no Sequences unless the
+        /// Sequence is absolutely needed, e.g., in the case of a Repeater or an
+        /// Alternative.
+        ///
+        /// Well, this is not exactly true when recursion is involved. Where there is a
+        /// recursive record, that record will be ""inlined"" once, but any internal (ie,
+        /// recursive) references to that record will be a Sequence for the record. That
+        /// Sequence will not further inline itself -- it will refer to itself as a
+        /// Sequence. The same is true for any records nested in this outer recursive
+        /// record. Recursion is rare, and we want things to be fast in the typical case,
+        /// which is why we do the flattening optimization.
+        ///
+        ///
+        /// The algorithm does a few tricks to handle recursive symbol definitions. In
+        /// order to avoid infinite recursion with recursive symbols, we have a map of
+        /// Symbol->Symbol. Before fully constructing a flattened symbol for a
+        /// <tt>Sequence</tt> we insert an empty output symbol into the map and then
+        /// start filling the production for the <tt>Sequence</tt>. If the same
+        /// <tt>Sequence</tt> is encountered due to recursion, we simply return the
+        /// (empty) output <tt>Sequence</tt> from the map. Then we actually fill out
+        /// the production for the <tt>Sequence</tt>. As part of the flattening process
+        /// we copy the production of <tt>Sequence</tt>s into larger arrays. If the
+        /// original <tt>Sequence</tt> has not not be fully constructed yet, we copy a
+        /// bunch of <tt>null</tt>s. Fix-up remembers all those <tt>null</tt> patches.
+        /// The fix-ups gets finally filled when we know the symbols to occupy those
+        /// patches.
+        /// </summary>
+        /// <param name=""in"">    The array of input symbols to flatten </param>
+        /// <param name=""start""> The position where the input sub-array starts. </param>
+        /// <param name=""out"">   The output that receives the flattened list of symbols. The
+        ///              output array should have sufficient space to receive the
+        ///              expanded sub-array of symbols. </param>
+        /// <param name=""skip"">  The position where the output input sub-array starts. </param>
+        /// <param name=""map"">   A map of symbols which have already been expanded. Useful for
+        ///              handling recursive definitions and for caching. </param>
+        /// <param name=""map2"">  A map to to store the list of fix-ups. </param>
+        protected static void Flatten(Symbol[] @in, int start, Symbol[] @out, int skip,
+            IDictionary<Sequence, Sequence> map, IDictionary<Sequence, IList<Fixup>> map2)
+        {
+            for (int i = start, j = skip; i < @in.Length; i++)
+            {
+                Symbol s = @in[i].Flatten(map, map2);
+                if (s is Sequence)
+                {
+                    Symbol[] p = s.Production;
+                    IList<Fixup> l = map2.ContainsKey((Sequence)s) ? map2[(Sequence)s] : null;","[{'comment': ""## Inefficient use of ContainsKey\n\nInefficient use of 'ContainsKey' and [indexer](1).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2899)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Symbol.cs,"@@ -0,0 +1,778 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Symbol is the base of all symbols (terminals and non-terminals) of the
+    /// grammar.
+    /// </summary>
+    public abstract class Symbol
+    {
+        /// <summary>
+        /// The type of symbol.
+        /// </summary>
+        public enum Kind
+        {
+            /// <summary>
+            /// terminal symbols which have no productions </summary>
+            Terminal,
+
+            /// <summary>
+            /// Start symbol for some grammar </summary>
+            Root,
+
+            /// <summary>
+            /// non-terminal symbol which is a sequence of one or more other symbols </summary>
+            Sequence,
+
+            /// <summary>
+            /// non-terminal to represent the contents of an array or map </summary>
+            Repeater,
+
+            /// <summary>
+            /// non-terminal to represent the union </summary>
+            Alternative,
+
+            /// <summary>
+            /// non-terminal action symbol which are automatically consumed </summary>
+            ImplicitAction,
+
+            /// <summary>
+            /// non-terminal action symbol which is explicitly consumed </summary>
+            ExplicitAction
+        }
+
+        /// The kind of this symbol.
+        public readonly Kind SymKind;
+
+        /// <summary>
+        /// The production for this symbol. If this symbol is a terminal this is
+        /// <tt>null</tt>. Otherwise this holds the the sequence of the symbols that
+        /// forms the production for this symbol. The sequence is in the reverse order of
+        /// production. This is useful for easy copying onto parsing stack.
+        ///
+        /// Please note that this is a final. So the production for a symbol should be
+        /// known before that symbol is constructed. This requirement cannot be met for
+        /// those symbols which are recursive (e.g. a record that holds union a branch of
+        /// which is the record itself). To resolve this problem, we initialize the
+        /// symbol with an array of nulls. Later we fill the symbols. Not clean, but
+        /// works. The other option is to not have this field a final. But keeping it
+        /// final and thus keeping symbol immutable gives some comfort. See various
+        /// generators how we generate records.
+        /// </summary>
+        public readonly Symbol[] Production;
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind.
+        /// </summary>
+        protected Symbol(Kind kind) : this(kind, null)
+        {
+        }
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind and production.
+        /// </summary>
+        protected Symbol(Kind kind, Symbol[] production)
+        {
+            this.Production = production;
+            this.SymKind = kind;
+        }
+
+        /// <summary>
+        /// A convenience method to construct a root symbol.
+        /// </summary>
+        public static Symbol NewRoot(params Symbol[] symbols)
+        {
+            return new Root(symbols);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a sequence.
+        /// </summary>
+        /// <param name=""production""> The constituent symbols of the sequence. </param>
+        public static Symbol NewSeq(params Symbol[] production)
+        {
+            return new Sequence(production);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a repeater.
+        /// </summary>
+        /// <param name=""endSymbol""> The end symbol. </param>
+        /// <param name=""symsToRepeat""> The symbols to repeat in the repeater. </param>
+        public static Symbol NewRepeat(Symbol endSymbol, params Symbol[] symsToRepeat)
+        {
+            return new Repeater(endSymbol, symsToRepeat);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a union.
+        /// </summary>
+        public static Symbol NewAlt(Symbol[] symbols, string[] labels)
+        {
+            return new Alternative(symbols, labels);
+        }
+
+        /// <summary>
+        /// A convenience method to construct an ErrorAction.
+        /// </summary>
+        /// <param name=""e""> </param>
+        protected static Symbol Error(string e)
+        {
+            return new ErrorAction(e);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a ResolvingAction.
+        /// </summary>
+        /// <param name=""w""> The writer symbol </param>
+        /// <param name=""r""> The reader symbol </param>
+        protected static Symbol Resolve(Symbol w, Symbol r)
+        {
+            return new ResolvingAction(w, r);
+        }
+
+        protected class Fixup
+        {
+            public readonly Symbol[] Symbols;
+            public readonly int Pos;
+
+            public Fixup(Symbol[] symbols, int pos)
+            {
+                this.Symbols = symbols;
+                this.Pos = pos;
+            }
+        }
+
+        protected virtual Symbol Flatten(IDictionary<Sequence, Sequence> map, IDictionary<Sequence, IList<Fixup>> map2)
+        {
+            return this;
+        }
+
+        public virtual int FlattenedSize()
+        {
+            return 1;
+        }
+
+        /// <summary>
+        /// Flattens the given sub-array of symbols into an sub-array of symbols. Every
+        /// <tt>Sequence</tt> in the input are replaced by its production recursively.
+        /// Non-<tt>Sequence</tt> symbols, they internally have other symbols those
+        /// internal symbols also get flattened. When flattening is done, the only place
+        /// there might be Sequence symbols is in the productions of a Repeater,
+        /// Alternative, or the symToParse and symToSkip in a UnionAdjustAction or
+        /// SkipAction.
+        ///
+        /// Why is this done? We want our parsers to be fast. If we left the grammars
+        /// unflattened, then the parser would be constantly copying the contents of
+        /// nested Sequence productions onto the parsing stack. Instead, because of
+        /// flattening, we have a long top-level production with no Sequences unless the
+        /// Sequence is absolutely needed, e.g., in the case of a Repeater or an
+        /// Alternative.
+        ///
+        /// Well, this is not exactly true when recursion is involved. Where there is a
+        /// recursive record, that record will be ""inlined"" once, but any internal (ie,
+        /// recursive) references to that record will be a Sequence for the record. That
+        /// Sequence will not further inline itself -- it will refer to itself as a
+        /// Sequence. The same is true for any records nested in this outer recursive
+        /// record. Recursion is rare, and we want things to be fast in the typical case,
+        /// which is why we do the flattening optimization.
+        ///
+        ///
+        /// The algorithm does a few tricks to handle recursive symbol definitions. In
+        /// order to avoid infinite recursion with recursive symbols, we have a map of
+        /// Symbol->Symbol. Before fully constructing a flattened symbol for a
+        /// <tt>Sequence</tt> we insert an empty output symbol into the map and then
+        /// start filling the production for the <tt>Sequence</tt>. If the same
+        /// <tt>Sequence</tt> is encountered due to recursion, we simply return the
+        /// (empty) output <tt>Sequence</tt> from the map. Then we actually fill out
+        /// the production for the <tt>Sequence</tt>. As part of the flattening process
+        /// we copy the production of <tt>Sequence</tt>s into larger arrays. If the
+        /// original <tt>Sequence</tt> has not not be fully constructed yet, we copy a
+        /// bunch of <tt>null</tt>s. Fix-up remembers all those <tt>null</tt> patches.
+        /// The fix-ups gets finally filled when we know the symbols to occupy those
+        /// patches.
+        /// </summary>
+        /// <param name=""in"">    The array of input symbols to flatten </param>
+        /// <param name=""start""> The position where the input sub-array starts. </param>
+        /// <param name=""out"">   The output that receives the flattened list of symbols. The
+        ///              output array should have sufficient space to receive the
+        ///              expanded sub-array of symbols. </param>
+        /// <param name=""skip"">  The position where the output input sub-array starts. </param>
+        /// <param name=""map"">   A map of symbols which have already been expanded. Useful for
+        ///              handling recursive definitions and for caching. </param>
+        /// <param name=""map2"">  A map to to store the list of fix-ups. </param>
+        protected static void Flatten(Symbol[] @in, int start, Symbol[] @out, int skip,
+            IDictionary<Sequence, Sequence> map, IDictionary<Sequence, IList<Fixup>> map2)
+        {
+            for (int i = start, j = skip; i < @in.Length; i++)
+            {
+                Symbol s = @in[i].Flatten(map, map2);
+                if (s is Sequence)
+                {
+                    Symbol[] p = s.Production;
+                    IList<Fixup> l = map2.ContainsKey((Sequence)s) ? map2[(Sequence)s] : null;
+                    if (l == null)
+                    {
+                        Array.Copy(p, 0, @out, j, p.Length);
+                        // Copy any fixups that will be applied to p to add missing symbols
+                        foreach (IList<Fixup> fixups in map2.Values)
+                        {
+                            copyFixups(fixups, @out, j, p);
+                        }
+                    }
+                    else
+                    {
+                        l.Add(new Fixup(@out, j));
+                    }
+
+                    j += p.Length;
+                }
+                else
+                {
+                    @out[j++] = s;
+                }
+            }
+        }
+
+        private static void copyFixups(IList<Fixup> fixups, Symbol[] @out, int outPos, Symbol[] toCopy)
+        {
+            for (int i = 0, n = fixups.Count; i < n; i += 1)
+            {
+                Fixup fixup = fixups[i];
+                if (fixup.Symbols == toCopy)
+                {
+                    fixups.Add(new Fixup(@out, fixup.Pos + outPos));
+                }
+            }
+        }
+
+        /// <summary>
+        /// Returns the amount of space required to flatten the given sub-array of
+        /// symbols.
+        /// </summary>
+        /// <param name=""symbols""> The array of input symbols. </param>
+        /// <param name=""start"">   The index where the subarray starts. </param>
+        /// <returns> The number of symbols that will be produced if one expands the given
+        ///         input. </returns>
+        protected static int FlattenedSize(Symbol[] symbols, int start)
+        {
+            int result = 0;
+            for (int i = start; i < symbols.Length; i++)
+            {
+                if (symbols[i] is Sequence)
+                {
+                    Sequence s = (Sequence)symbols[i];
+                    result += s.FlattenedSize();
+                }
+                else
+                {
+                    result += 1;
+                }
+            }
+
+            return result;
+        }
+
+        protected class Terminal : Symbol
+        {
+            public readonly string PrintName;
+
+            public Terminal(string printName) : base(Kind.Terminal)
+            {
+                this.PrintName = printName;
+            }
+
+            public override string ToString()
+            {
+                return PrintName;
+            }
+        }
+
+        public class ImplicitAction : Symbol
+        {
+            /// <summary>
+            /// Set to <tt>true</tt> if and only if this implicit action is a trailing
+            /// action. That is, it is an action that follows real symbol. E.g
+            /// <seealso cref=""Symbol.DefaultEndAction""/>.
+            /// </summary>
+            public readonly bool IsTrailing;
+
+            public ImplicitAction() : this(false)
+            {
+            }
+
+            public ImplicitAction(bool isTrailing) : base(Kind.ImplicitAction)
+            {
+                this.IsTrailing = isTrailing;
+            }
+        }
+
+        protected class Root : Symbol
+        {
+            public Root(params Symbol[] symbols) : base(Kind.Root, makeProduction(symbols))
+            {
+                Production[0] = this;
+            }
+
+            private static Symbol[] makeProduction(Symbol[] symbols)
+            {
+                Symbol[] result = new Symbol[FlattenedSize(symbols, 0) + 1];
+                Flatten(symbols, 0, result, 1, new Dictionary<Sequence, Sequence>(),
+                    new Dictionary<Sequence, IList<Fixup>>());
+                return result;
+            }
+        }
+
+        protected class Sequence : Symbol, IEnumerable<Symbol>
+        {
+            public Sequence(Symbol[] productions) : base(Kind.Sequence, productions)
+            {
+            }
+
+            public virtual Symbol Get(int index)
+            {
+                return Production[index];
+            }
+
+            public virtual int Size()
+            {
+                return Production.Length;
+            }
+
+            public IEnumerator<Symbol> GetEnumerator()
+            {
+                return Enumerable.Reverse(Production).GetEnumerator();
+            }
+
+            IEnumerator IEnumerable.GetEnumerator()
+            {
+                return this.GetEnumerator();
+            }
+
+            protected override Symbol Flatten(IDictionary<Sequence, Sequence> map,
+                IDictionary<Sequence, IList<Fixup>> map2)
+            {
+                Sequence result = map.ContainsKey(this) ? map[this] : null;","[{'comment': ""## Inefficient use of ContainsKey\n\nInefficient use of 'ContainsKey' and [indexer](1).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2900)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/ValidatingGrammarGenerator.cs,"@@ -0,0 +1,152 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// The class that generates validating grammar.
+    /// </summary>
+    public class ValidatingGrammarGenerator
+    {
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// given schema <tt>sc</tt>.
+        /// </summary>
+        public virtual Symbol Generate(Schema schema)
+        {
+            return Symbol.NewRoot(Generate(schema, new Dictionary<LitS, Symbol>()));
+        }
+
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// given schema <tt>sc</tt>. If there is already an entry for the given schema
+        /// in the given map <tt>seen</tt> then that entry is returned. Otherwise a new
+        /// symbol is generated and an entry is inserted into the map.
+        /// </summary>
+        /// <param name=""sc"">   The schema for which the start symbol is required </param>
+        /// <param name=""seen""> A map of schema to symbol mapping done so far. </param>
+        /// <returns> The start symbol for the schema </returns>
+        protected virtual Symbol Generate(Schema sc, IDictionary<LitS, Symbol> seen)
+        {
+            switch (sc.Tag)
+            {
+                case Schema.Type.Null:
+                    return Symbol.Null;
+                case Schema.Type.Boolean:
+                    return Symbol.Boolean;
+                case Schema.Type.Int:
+                    return Symbol.Int;
+                case Schema.Type.Long:
+                    return Symbol.Long;
+                case Schema.Type.Float:
+                    return Symbol.Float;
+                case Schema.Type.Double:
+                    return Symbol.Double;
+                case Schema.Type.String:
+                    return Symbol.String;
+                case Schema.Type.Bytes:
+                    return Symbol.Bytes;
+                case Schema.Type.Fixed:
+                    return Symbol.NewSeq(new Symbol.IntCheckAction(((FixedSchema)sc).Size), Symbol.Fixed);
+                case Schema.Type.Enumeration:
+                    return Symbol.NewSeq(new Symbol.IntCheckAction(((EnumSchema)sc).Symbols.Count), Symbol.Enum);
+                case Schema.Type.Array:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.ArrayEnd, Generate(((ArraySchema)sc).ItemSchema, seen)),
+                        Symbol.ArrayStart);
+                case Schema.Type.Map:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.MapEnd, Generate(((MapSchema)sc).ValueSchema, seen), Symbol.String),
+                        Symbol.MapStart);
+                case Schema.Type.Record:
+                    {
+                        LitS wsc = new LitS(sc);
+                        Symbol rresult = seen.ContainsKey(wsc) ? seen[wsc] : null;","[{'comment': ""## Inefficient use of ContainsKey\n\nInefficient use of 'ContainsKey' and [indexer](1).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2901)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/ValidatingGrammarGenerator.cs,"@@ -0,0 +1,159 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// The class that generates validating grammar.
+    /// </summary>
+    public class ValidatingGrammarGenerator
+    {
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// given schema <tt>sc</tt>.
+        /// </summary>
+        public virtual Symbol Generate(Schema schema)
+        {
+            return Symbol.NewRoot(Generate(schema, new Dictionary<LitS, Symbol>()));
+        }
+
+        /// <summary>
+        /// Returns the non-terminal that is the start symbol for the grammar for the
+        /// given schema <tt>sc</tt>. If there is already an entry for the given schema
+        /// in the given map <tt>seen</tt> then that entry is returned. Otherwise a new
+        /// symbol is generated and an entry is inserted into the map.
+        /// </summary>
+        /// <param name=""sc"">   The schema for which the start symbol is required </param>
+        /// <param name=""seen""> A map of schema to symbol mapping done so far. </param>
+        /// <returns> The start symbol for the schema </returns>
+        protected virtual Symbol Generate(Schema sc, IDictionary<LitS, Symbol> seen)
+        {
+            switch (sc.Tag)
+            {
+                case Schema.Type.Null:
+                    return Symbol.Null;
+                case Schema.Type.Boolean:
+                    return Symbol.Boolean;
+                case Schema.Type.Int:
+                    return Symbol.Int;
+                case Schema.Type.Long:
+                    return Symbol.Long;
+                case Schema.Type.Float:
+                    return Symbol.Float;
+                case Schema.Type.Double:
+                    return Symbol.Double;
+                case Schema.Type.String:
+                    return Symbol.String;
+                case Schema.Type.Bytes:
+                    return Symbol.Bytes;
+                case Schema.Type.Fixed:
+                    return Symbol.NewSeq(new Symbol.IntCheckAction(((FixedSchema)sc).Size), Symbol.Fixed);
+                case Schema.Type.Enumeration:
+                    return Symbol.NewSeq(new Symbol.IntCheckAction(((EnumSchema)sc).Symbols.Count), Symbol.Enum);
+                case Schema.Type.Array:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.ArrayEnd, Generate(((ArraySchema)sc).ItemSchema, seen)),
+                        Symbol.ArrayStart);
+                case Schema.Type.Map:
+                    return Symbol.NewSeq(
+                        Symbol.NewRepeat(Symbol.MapEnd, Generate(((MapSchema)sc).ValueSchema, seen), Symbol.String),
+                        Symbol.MapStart);
+                case Schema.Type.Record:
+                    {
+                        LitS wsc = new LitS(sc);
+                        Symbol rresult = seen.ContainsKey(wsc) ? seen[wsc] : null;
+                        if (rresult == null)
+                        {
+                            Symbol[] production = new Symbol[((RecordSchema)sc).Fields.Count];
+
+                            // We construct a symbol without filling the array. Please see
+                            // <seealso cref=""Symbol.production""/> for the reason.
+                            rresult = Symbol.NewSeq(production);
+                            seen[wsc] = rresult;
+
+                            int j = production.Length;
+                            foreach (Field f in ((RecordSchema)sc).Fields)
+                            {
+                                production[--j] = Generate(f.Schema, seen);
+                            }
+                        }
+
+                        return rresult;
+                    }
+                case Schema.Type.Union:
+                    IList<Schema> subs = ((UnionSchema)sc).Schemas;
+                    Symbol[] symbols = new Symbol[subs.Count];
+                    string[] labels = new string[subs.Count];
+
+                    int i = 0;
+                    foreach (Schema b in ((UnionSchema)sc).Schemas)
+                    {
+                        symbols[i] = Generate(b, seen);
+                        labels[i] = b.Fullname;
+                        i++;
+                    }
+
+                    return Symbol.NewSeq(Symbol.NewAlt(symbols, labels), Symbol.Union);
+
+                default:
+                    throw new Exception(""Unexpected schema type"");
+            }
+        }
+
+        /// <summary>
+        /// A wrapper around Schema that does ""=="" equality.
+        /// </summary>
+        protected class LitS
+        {
+            private readonly Schema actual;
+
+            /// <summary>
+            /// Initializes a new instance of the <see cref=""LitS""/> class.
+            /// </summary>
+            public LitS(Schema actual)
+            {
+                this.actual = actual;
+            }
+
+            /// <summary>
+            /// Two LitS are equal if and only if their underlying schema is the same (not
+            /// merely equal).
+            /// </summary>
+            public override bool Equals(object o)
+            {
+                if (!(o is LitS))","[{'comment': '## Equals should not apply ""is""\n\nLitS.Equals(object) should not use ""is"" on its parameter, as it will not work properly for subclasses of LitS.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2904)', 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Symbol.cs,"@@ -0,0 +1,1044 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Symbol is the base of all symbols (terminals and non-terminals) of the
+    /// grammar.
+    /// </summary>
+    public abstract class Symbol
+    {
+        /// <summary>
+        /// The type of symbol.
+        /// </summary>
+        public enum Kind
+        {
+            /// <summary>
+            /// terminal symbols which have no productions </summary>
+            Terminal,
+
+            /// <summary>
+            /// Start symbol for some grammar </summary>
+            Root,
+
+            /// <summary>
+            /// non-terminal symbol which is a sequence of one or more other symbols </summary>
+            Sequence,
+
+            /// <summary>
+            /// non-terminal to represent the contents of an array or map </summary>
+            Repeater,
+
+            /// <summary>
+            /// non-terminal to represent the union </summary>
+            Alternative,
+
+            /// <summary>
+            /// non-terminal action symbol which are automatically consumed </summary>
+            ImplicitAction,
+
+            /// <summary>
+            /// non-terminal action symbol which is explicitly consumed </summary>
+            ExplicitAction
+        }
+
+        /// The kind of this symbol.
+        public readonly Kind SymKind;
+
+        /// <summary>
+        /// The production for this symbol. If this symbol is a terminal this is
+        /// <tt>null</tt>. Otherwise this holds the the sequence of the symbols that
+        /// forms the production for this symbol. The sequence is in the reverse order of
+        /// production. This is useful for easy copying onto parsing stack.
+        ///
+        /// Please note that this is a final. So the production for a symbol should be
+        /// known before that symbol is constructed. This requirement cannot be met for
+        /// those symbols which are recursive (e.g. a record that holds union a branch of
+        /// which is the record itself). To resolve this problem, we initialize the
+        /// symbol with an array of nulls. Later we fill the symbols. Not clean, but
+        /// works. The other option is to not have this field a final. But keeping it
+        /// final and thus keeping symbol immutable gives some comfort. See various
+        /// generators how we generate records.
+        /// </summary>
+        public readonly Symbol[] Production;
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind.
+        /// </summary>
+        protected Symbol(Kind kind) : this(kind, null)
+        {
+        }
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind and production.
+        /// </summary>
+        protected Symbol(Kind kind, Symbol[] production)
+        {
+            this.Production = production;
+            this.SymKind = kind;
+        }
+
+        /// <summary>
+        /// A convenience method to construct a root symbol.
+        /// </summary>
+        public static Symbol NewRoot(params Symbol[] symbols)
+        {
+            return new Root(symbols);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a sequence.
+        /// </summary>
+        /// <param name=""production""> The constituent symbols of the sequence. </param>
+        public static Symbol NewSeq(params Symbol[] production)
+        {
+            return new Sequence(production);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a repeater.
+        /// </summary>
+        /// <param name=""endSymbol""> The end symbol. </param>
+        /// <param name=""symsToRepeat""> The symbols to repeat in the repeater. </param>
+        public static Symbol NewRepeat(Symbol endSymbol, params Symbol[] symsToRepeat)
+        {
+            return new Repeater(endSymbol, symsToRepeat);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a union.
+        /// </summary>
+        public static Symbol NewAlt(Symbol[] symbols, string[] labels)
+        {
+            return new Alternative(symbols, labels);
+        }
+
+        /// <summary>
+        /// A convenience method to construct an ErrorAction.
+        /// </summary>
+        /// <param name=""e""> </param>
+        protected static Symbol Error(string e)
+        {
+            return new ErrorAction(e);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a ResolvingAction.
+        /// </summary>
+        /// <param name=""w""> The writer symbol </param>
+        /// <param name=""r""> The reader symbol </param>
+        protected static Symbol Resolve(Symbol w, Symbol r)
+        {
+            return new ResolvingAction(w, r);
+        }
+
+        /// <summary>
+        /// Fixup symbol.
+        /// </summary>
+        protected class Fixup
+        {
+            /// <summary>
+            /// The symbols.
+            /// </summary>
+            public readonly Symbol[] Symbols;
+            /// <summary>
+            /// The position.
+            /// </summary>
+            public readonly int Pos;
+
+            /// <summary>
+            /// Initializes a new instance of the <see cref=""Fixup""/> class.
+            /// </summary>
+            public Fixup(Symbol[] symbols, int pos)","[{'comment': ""## Exposing internal representation\n\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](1).\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](2).\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](3).\n'Fixup' exposes the internal representation stored in field 'Symbols'. The value may be modified [through the variable out](4).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2903)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Symbol.cs,"@@ -0,0 +1,1049 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Symbol is the base of all symbols (terminals and non-terminals) of the
+    /// grammar.
+    /// </summary>
+    public abstract class Symbol
+    {
+        /// <summary>
+        /// The type of symbol.
+        /// </summary>
+        public enum Kind
+        {
+            /// <summary>
+            /// terminal symbols which have no productions </summary>
+            Terminal,
+
+            /// <summary>
+            /// Start symbol for some grammar </summary>
+            Root,
+
+            /// <summary>
+            /// non-terminal symbol which is a sequence of one or more other symbols </summary>
+            Sequence,
+
+            /// <summary>
+            /// non-terminal to represent the contents of an array or map </summary>
+            Repeater,
+
+            /// <summary>
+            /// non-terminal to represent the union </summary>
+            Alternative,
+
+            /// <summary>
+            /// non-terminal action symbol which are automatically consumed </summary>
+            ImplicitAction,
+
+            /// <summary>
+            /// non-terminal action symbol which is explicitly consumed </summary>
+            ExplicitAction
+        }
+
+        /// The kind of this symbol.
+        public readonly Kind SymKind;
+
+        /// <summary>
+        /// The production for this symbol. If this symbol is a terminal this is
+        /// <tt>null</tt>. Otherwise this holds the the sequence of the symbols that
+        /// forms the production for this symbol. The sequence is in the reverse order of
+        /// production. This is useful for easy copying onto parsing stack.
+        ///
+        /// Please note that this is a final. So the production for a symbol should be
+        /// known before that symbol is constructed. This requirement cannot be met for
+        /// those symbols which are recursive (e.g. a record that holds union a branch of
+        /// which is the record itself). To resolve this problem, we initialize the
+        /// symbol with an array of nulls. Later we fill the symbols. Not clean, but
+        /// works. The other option is to not have this field a final. But keeping it
+        /// final and thus keeping symbol immutable gives some comfort. See various
+        /// generators how we generate records.
+        /// </summary>
+        public readonly Symbol[] Production;
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind.
+        /// </summary>
+        protected Symbol(Kind kind) : this(kind, null)
+        {
+        }
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind and production.
+        /// </summary>
+        protected Symbol(Kind kind, Symbol[] production)
+        {
+            this.Production = production;
+            this.SymKind = kind;
+        }
+
+        /// <summary>
+        /// A convenience method to construct a root symbol.
+        /// </summary>
+        public static Symbol NewRoot(params Symbol[] symbols)
+        {
+            return new Root(symbols);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a sequence.
+        /// </summary>
+        /// <param name=""production""> The constituent symbols of the sequence. </param>
+        public static Symbol NewSeq(params Symbol[] production)
+        {
+            return new Sequence(production);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a repeater.
+        /// </summary>
+        /// <param name=""endSymbol""> The end symbol. </param>
+        /// <param name=""symsToRepeat""> The symbols to repeat in the repeater. </param>
+        public static Symbol NewRepeat(Symbol endSymbol, params Symbol[] symsToRepeat)
+        {
+            return new Repeater(endSymbol, symsToRepeat);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a union.
+        /// </summary>
+        public static Symbol NewAlt(Symbol[] symbols, string[] labels)
+        {
+            return new Alternative(symbols, labels);
+        }
+
+        /// <summary>
+        /// A convenience method to construct an ErrorAction.
+        /// </summary>
+        /// <param name=""e""> </param>
+        protected static Symbol Error(string e)
+        {
+            return new ErrorAction(e);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a ResolvingAction.
+        /// </summary>
+        /// <param name=""w""> The writer symbol </param>
+        /// <param name=""r""> The reader symbol </param>
+        protected static Symbol Resolve(Symbol w, Symbol r)
+        {
+            return new ResolvingAction(w, r);
+        }
+
+        /// <summary>
+        /// Fixup symbol.
+        /// </summary>
+        protected class Fixup
+        {
+            private Symbol[] symbols;
+
+            /// <summary>
+            /// The symbols.
+            /// </summary>
+            public Symbol[] Symbols
+            {
+                get { return (Symbol[])symbols.Clone(); }
+            }
+            /// <summary>
+            /// The position.
+            /// </summary>
+            public readonly int Pos;
+
+            /// <summary>
+            /// Initializes a new instance of the <see cref=""Fixup""/> class.
+            /// </summary>
+            public Fixup(Symbol[] symbols, int pos)","[{'comment': ""## Exposing internal representation\n\n'Fixup' exposes the internal representation stored in field 'symbols'. The value may be modified [through the variable output](1).\n'Fixup' exposes the internal representation stored in field 'symbols'. The value may be modified [through the variable output](2).\n'Fixup' exposes the internal representation stored in field 'symbols'. The value may be modified [through the variable output](3).\n'Fixup' exposes the internal representation stored in field 'symbols'. The value may be modified [through the variable output](4).\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2905)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Symbol.cs,"@@ -0,0 +1,1049 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections;
+using System.Collections.Generic;
+using System.Linq;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Symbol is the base of all symbols (terminals and non-terminals) of the
+    /// grammar.
+    /// </summary>
+    public abstract class Symbol
+    {
+        /// <summary>
+        /// The type of symbol.
+        /// </summary>
+        public enum Kind
+        {
+            /// <summary>
+            /// terminal symbols which have no productions </summary>
+            Terminal,
+
+            /// <summary>
+            /// Start symbol for some grammar </summary>
+            Root,
+
+            /// <summary>
+            /// non-terminal symbol which is a sequence of one or more other symbols </summary>
+            Sequence,
+
+            /// <summary>
+            /// non-terminal to represent the contents of an array or map </summary>
+            Repeater,
+
+            /// <summary>
+            /// non-terminal to represent the union </summary>
+            Alternative,
+
+            /// <summary>
+            /// non-terminal action symbol which are automatically consumed </summary>
+            ImplicitAction,
+
+            /// <summary>
+            /// non-terminal action symbol which is explicitly consumed </summary>
+            ExplicitAction
+        }
+
+        /// The kind of this symbol.
+        public readonly Kind SymKind;
+
+        /// <summary>
+        /// The production for this symbol. If this symbol is a terminal this is
+        /// <tt>null</tt>. Otherwise this holds the the sequence of the symbols that
+        /// forms the production for this symbol. The sequence is in the reverse order of
+        /// production. This is useful for easy copying onto parsing stack.
+        ///
+        /// Please note that this is a final. So the production for a symbol should be
+        /// known before that symbol is constructed. This requirement cannot be met for
+        /// those symbols which are recursive (e.g. a record that holds union a branch of
+        /// which is the record itself). To resolve this problem, we initialize the
+        /// symbol with an array of nulls. Later we fill the symbols. Not clean, but
+        /// works. The other option is to not have this field a final. But keeping it
+        /// final and thus keeping symbol immutable gives some comfort. See various
+        /// generators how we generate records.
+        /// </summary>
+        public readonly Symbol[] Production;
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind.
+        /// </summary>
+        protected Symbol(Kind kind) : this(kind, null)
+        {
+        }
+
+        /// <summary>
+        /// Constructs a new symbol of the given kind and production.
+        /// </summary>
+        protected Symbol(Kind kind, Symbol[] production)
+        {
+            this.Production = production;
+            this.SymKind = kind;
+        }
+
+        /// <summary>
+        /// A convenience method to construct a root symbol.
+        /// </summary>
+        public static Symbol NewRoot(params Symbol[] symbols)
+        {
+            return new Root(symbols);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a sequence.
+        /// </summary>
+        /// <param name=""production""> The constituent symbols of the sequence. </param>
+        public static Symbol NewSeq(params Symbol[] production)
+        {
+            return new Sequence(production);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a repeater.
+        /// </summary>
+        /// <param name=""endSymbol""> The end symbol. </param>
+        /// <param name=""symsToRepeat""> The symbols to repeat in the repeater. </param>
+        public static Symbol NewRepeat(Symbol endSymbol, params Symbol[] symsToRepeat)
+        {
+            return new Repeater(endSymbol, symsToRepeat);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a union.
+        /// </summary>
+        public static Symbol NewAlt(Symbol[] symbols, string[] labels)
+        {
+            return new Alternative(symbols, labels);
+        }
+
+        /// <summary>
+        /// A convenience method to construct an ErrorAction.
+        /// </summary>
+        /// <param name=""e""> </param>
+        protected static Symbol Error(string e)
+        {
+            return new ErrorAction(e);
+        }
+
+        /// <summary>
+        /// A convenience method to construct a ResolvingAction.
+        /// </summary>
+        /// <param name=""w""> The writer symbol </param>
+        /// <param name=""r""> The reader symbol </param>
+        protected static Symbol Resolve(Symbol w, Symbol r)
+        {
+            return new ResolvingAction(w, r);
+        }
+
+        /// <summary>
+        /// Fixup symbol.
+        /// </summary>
+        protected class Fixup
+        {
+            private Symbol[] symbols;","[{'comment': ""## Missed 'readonly' opportunity\n\nField 'symbols' can be 'readonly'.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2906)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/test/IO/JsonCodecTests.cs,"@@ -0,0 +1,226 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using NUnit.Framework;
+using System.IO;
+using System.Linq;
+using System.Text;
+using Avro.Generic;
+using Avro.IO;
+using Newtonsoft.Json.Linq;
+
+namespace Avro.Test
+{
+    using Decoder = Avro.IO.Decoder;
+    using Encoder = Avro.IO.Encoder;
+
+    /// <summary>
+    /// Tests the JsonEncoder and JsonDecoder.
+    /// </summary>
+    [TestFixture]
+    public class JsonCodecTests
+    {
+        [TestCase]
+        public void TestJsonEncoderWhenIncludeNamespaceOptionIsFalse()
+        {
+            string value = ""{\""b\"": {\""string\"":\""myVal\""}, \""a\"": 1}"";
+            string schemaStr = ""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": ["" +
+                               ""{\""name\"": \""a\"", \""type\"": \""int\""}, {\""name\"": \""b\"", \""type\"": [\""null\"", \""string\""]}"" +
+                               ""]}"";
+            Schema schema = Schema.Parse(schemaStr);
+            byte[] avroBytes = fromJsonToAvro(value, schema);
+
+            Assert.IsTrue(JToken.DeepEquals(JObject.Parse(""{\""b\"":\""myVal\"",\""a\"":1}""),
+                JObject.Parse(fromAvroToJson(avroBytes, schema, false))));
+        }
+
+        [TestCase]
+        public void TestJsonEncoderWhenIncludeNamespaceOptionIsTrue()
+        {
+            string value = ""{\""b\"": {\""string\"":\""myVal\""}, \""a\"": 1}"";
+            string schemaStr = ""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": ["" +
+                               ""{\""name\"": \""a\"", \""type\"": \""int\""}, {\""name\"": \""b\"", \""type\"": [\""null\"", \""string\""]}"" +
+                               ""]}"";
+            Schema schema = Schema.Parse(schemaStr);
+            byte[] avroBytes = fromJsonToAvro(value, schema);
+
+            Assert.IsTrue(JToken.DeepEquals(JObject.Parse(""{\""b\"":{\""string\"":\""myVal\""},\""a\"":1}""),
+                JObject.Parse(fromAvroToJson(avroBytes, schema, true))));
+        }
+
+        [TestCase]
+        public void TestJsonRecordOrdering()
+        {
+            string value = ""{\""b\"": 2, \""a\"": 1}"";
+            Schema schema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": ["" +
+                                         ""{\""name\"": \""a\"", \""type\"": \""int\""}, {\""name\"": \""b\"", \""type\"": \""int\""}"" +
+                                         ""]}"");
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(schema, schema);
+            Decoder decoder = new JsonDecoder(schema, value);
+            object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":1,\""b\"":2}"", fromDatumToJson(o, schema, false));
+        }
+
+        [TestCase]
+        public void TestJsonRecordOrdering2()
+        {
+            string value = ""{\""b\"": { \""b3\"": 1.4, \""b2\"": 3.14, \""b1\"": \""h\""}, \""a\"": {\""a2\"":true, \""a1\"": null}}"";
+            Schema schema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n"" +
+                                         ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n"" +
+                                         ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}},\n"" +
+                                         ""{\""name\"": \""b\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""B\"",\""fields\"":\n"" +
+                                         ""[{\""name\"":\""b1\"", \""type\"":\""string\""}, {\""name\"":\""b2\"", \""type\"":\""float\""}, {\""name\"":\""b3\"", \""type\"":\""double\""}]}}\n"" +
+                                         ""]}"");
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(schema, schema);
+            Decoder decoder = new JsonDecoder(schema, value);
+            object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":{\""a1\"":null,\""a2\"":true},\""b\"":{\""b1\"":\""h\"",\""b2\"":3.14,\""b3\"":1.4}}"",
+                fromDatumToJson(o, schema, false));
+        }
+
+        [TestCase]
+        public void TestJsonRecordOrderingWithProjection()
+        {
+            String value = ""{\""b\"": { \""b3\"": 1.4, \""b2\"": 3.14, \""b1\"": \""h\""}, \""a\"": {\""a2\"":true, \""a1\"": null}}"";
+            Schema writerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}},\n""
+                                               + ""{\""name\"": \""b\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""B\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""b1\"", \""type\"":\""string\""}, {\""name\"":\""b2\"", \""type\"":\""float\""}, {\""name\"":\""b3\"", \""type\"":\""double\""}]}}\n""
+                                               + ""]}"");
+            Schema readerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}}\n"" +
+                                               ""]}"");
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(writerSchema, readerSchema);
+            Decoder decoder = new JsonDecoder(writerSchema, value);
+            Object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":{\""a1\"":null,\""a2\"":true}}"",
+                fromDatumToJson(o, readerSchema, false));
+        }
+
+
+        [TestCase]
+        public void testJsonRecordOrderingWithProjection2()
+        {
+            String value =
+                ""{\""b\"": { \""b1\"": \""h\"", \""b2\"": [3.14, 3.56], \""b3\"": 1.4}, \""a\"": {\""a2\"":true, \""a1\"": null}}"";
+            Schema writerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}},\n""
+                                               + ""{\""name\"": \""b\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""B\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""b1\"", \""type\"":\""string\""}, {\""name\"":\""b2\"", \""type\"":{\""type\"":\""array\"", \""items\"":\""float\""}}, {\""name\"":\""b3\"", \""type\"":\""double\""}]}}\n""
+                                               + ""]}"");
+
+            Schema readerSchema = Schema.Parse(""{\""type\"": \""record\"", \""name\"": \""ab\"", \""fields\"": [\n""
+                                               + ""{\""name\"": \""a\"", \""type\"": {\""type\"":\""record\"",\""name\"":\""A\"",\""fields\"":\n""
+                                               + ""[{\""name\"":\""a1\"", \""type\"":\""null\""}, {\""name\"":\""a2\"", \""type\"":\""boolean\""}]}}\n"" +
+                                               ""]}"");
+
+            GenericDatumReader<object> reader = new GenericDatumReader<object>(writerSchema, readerSchema);
+            Decoder decoder = new JsonDecoder(writerSchema, value);
+            object o = reader.Read(null, decoder);
+
+            Assert.AreEqual(""{\""a\"":{\""a1\"":null,\""a2\"":true}}"",
+                fromDatumToJson(o, readerSchema, false));
+        }
+
+        [TestCase(""int"", 1)]
+        [TestCase(""long"", 1L)]
+        [TestCase(""float"", 1.0F)]
+        [TestCase(""double"", 1.0)]
+        public void TestJsonDecoderNumeric(string type, object value)
+        {
+            string def = ""{\""type\"":\""record\"",\""name\"":\""X\"",\""fields\"":"" + ""[{\""type\"":\"""" + type +
+                         ""\"",\""name\"":\""n\""}]}"";
+            Schema schema = Schema.Parse(def);
+            DatumReader<GenericRecord> reader = new GenericDatumReader<GenericRecord>(schema, schema);
+
+            string[] records = { ""{\""n\"":1}"", ""{\""n\"":1.0}"" };
+
+            foreach (JsonDecoder decoder in records.Select(r => new JsonDecoder(schema, r)))
+            {
+                GenericRecord r = reader.Read(null, decoder);
+                Assert.AreEqual(value, r[""n""]);
+            }","[{'comment': ""## Missed opportunity to use Select\n\nThis foreach loop immediately maps its iteration variable to another variable [here](1) - consider mapping the sequence explicitly using '.Select(...)'.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2907)"", 'commenter': 'github-advanced-security[bot]'}]"
1833,lang/csharp/src/apache/main/IO/JsonDecoder.cs,"@@ -0,0 +1,787 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.IO;
+using System.Text;
+using Avro.IO.Parsing;
+using Newtonsoft.Json;
+
+namespace Avro.IO
+{
+    /// <summary>
+    /// A <seealso cref=""Decoder""/> for Avro's JSON data encoding.
+    ///
+    /// JsonDecoder is not thread-safe.
+    /// </summary>
+    public class JsonDecoder : ParsingDecoder
+    {
+        private JsonReader reader;
+        private readonly Stack<ReorderBuffer> reorderBuffers = new Stack<ReorderBuffer>();
+        private ReorderBuffer currentReorderBuffer;
+
+        private class ReorderBuffer
+        {
+            public readonly IDictionary<string, IList<JsonElement>> SavedFields =
+                new Dictionary<string, IList<JsonElement>>();
+
+            public JsonReader OrigParser;
+        }
+
+        private JsonDecoder(Symbol root, Stream stream) : base(root)
+        {
+            Configure(stream);
+        }
+
+        private JsonDecoder(Symbol root, string str) : base(root)
+        {
+            Configure(str);
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonDecoder""/> class.
+        /// </summary>
+        public JsonDecoder(Schema schema, Stream stream) : this(getSymbol(schema), stream)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonDecoder""/> class.
+        /// </summary>
+        public JsonDecoder(Schema schema, string str) : this(getSymbol(schema), str)
+        {
+        }
+
+        private static Symbol getSymbol(Schema schema)
+        {
+            return (new JsonGrammarGenerator()).Generate(schema);
+        }
+
+        /// <summary>
+        /// Reconfigures this JsonDecoder to use the InputStream provided.
+        /// <p/>
+        /// Otherwise, this JsonDecoder will reset its state and then reconfigure its
+        /// input.
+        /// </summary>","[{'comment': 'Not important: The [para](https://docs.microsoft.com/dotnet/csharp/language-reference/xmldoc/recommended-tags#para) element would be more standard in C# XML documentation comments, and is apparently [supported by Doxygen](https://doxygen.nl/manual/xmlcmds.html).', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Fixed', 'commenter': 'rayokota'}]"
1833,lang/csharp/src/apache/main/IO/JsonDecoder.cs,"@@ -0,0 +1,787 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+using System.Collections.Generic;
+using System.IO;
+using System.Text;
+using Avro.IO.Parsing;
+using Newtonsoft.Json;
+
+namespace Avro.IO
+{
+    /// <summary>
+    /// A <seealso cref=""Decoder""/> for Avro's JSON data encoding.
+    ///
+    /// JsonDecoder is not thread-safe.
+    /// </summary>
+    public class JsonDecoder : ParsingDecoder
+    {
+        private JsonReader reader;
+        private readonly Stack<ReorderBuffer> reorderBuffers = new Stack<ReorderBuffer>();
+        private ReorderBuffer currentReorderBuffer;
+
+        private class ReorderBuffer
+        {
+            public readonly IDictionary<string, IList<JsonElement>> SavedFields =
+                new Dictionary<string, IList<JsonElement>>();
+
+            public JsonReader OrigParser;
+        }
+
+        private JsonDecoder(Symbol root, Stream stream) : base(root)
+        {
+            Configure(stream);
+        }
+
+        private JsonDecoder(Symbol root, string str) : base(root)
+        {
+            Configure(str);
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonDecoder""/> class.
+        /// </summary>
+        public JsonDecoder(Schema schema, Stream stream) : this(getSymbol(schema), stream)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonDecoder""/> class.
+        /// </summary>
+        public JsonDecoder(Schema schema, string str) : this(getSymbol(schema), str)
+        {
+        }
+
+        private static Symbol getSymbol(Schema schema)
+        {
+            return (new JsonGrammarGenerator()).Generate(schema);
+        }
+
+        /// <summary>
+        /// Reconfigures this JsonDecoder to use the InputStream provided.
+        /// <p/>
+        /// Otherwise, this JsonDecoder will reset its state and then reconfigure its
+        /// input.
+        /// </summary>
+        /// <param name=""stream""> The InputStream to read from. Cannot be null. </param>
+        /// <returns> this JsonDecoder </returns>
+        public JsonDecoder Configure(Stream stream)
+        {
+            Parser.Reset();
+            reorderBuffers.Clear();
+            currentReorderBuffer = null;
+            this.reader = new JsonTextReader(new StreamReader(stream));
+            this.reader.Read();
+            return this;
+        }
+
+        /// <summary>
+        /// Reconfigures this JsonDecoder to use the String provided for input.
+        /// <p/>
+        /// Otherwise, this JsonDecoder will reset its state and then reconfigure its
+        /// input.
+        /// </summary>
+        /// <param name=""str""> The String to read from. Cannot be null. </param>
+        /// <returns> this JsonDecoder </returns>
+        public JsonDecoder Configure(string str)
+        {
+            Parser.Reset();
+            reorderBuffers.Clear();
+            currentReorderBuffer = null;
+            this.reader = new JsonTextReader(new StringReader(str));
+            this.reader.Read();
+            return this;
+        }
+
+        private void advance(Symbol symbol)
+        {
+            this.Parser.ProcessTrailingImplicitActions();
+            Parser.Advance(symbol);
+        }
+
+        /// <inheritdoc />
+        public override void ReadNull()
+        {
+            advance(Symbol.Null);
+            if (reader.TokenType == JsonToken.Null)
+            {
+                reader.Read();
+            }
+            else
+            {
+                throw error(""null"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override bool ReadBoolean()
+        {
+            advance(Symbol.Boolean);
+            if (reader.TokenType == JsonToken.Boolean)
+            {
+                bool result = Convert.ToBoolean(reader.Value);
+                reader.Read();
+                return result;
+            }
+            else
+            {
+                throw error(""boolean"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override int ReadInt()
+        {
+            advance(Symbol.Int);
+            if (reader.TokenType == JsonToken.Integer || reader.TokenType == JsonToken.Float)
+            {
+                int result = Convert.ToInt32(reader.Value);
+                reader.Read();
+                return result;
+            }
+            else
+            {
+                throw error(""int"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override long ReadLong()
+        {
+            advance(Symbol.Long);
+            if (reader.TokenType == JsonToken.Integer || reader.TokenType == JsonToken.Float)
+            {
+                long result = Convert.ToInt64(reader.Value);
+                reader.Read();
+                return result;
+            }
+            else
+            {
+                throw error(""long"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override float ReadFloat()
+        {
+            advance(Symbol.Float);
+            if (reader.TokenType == JsonToken.Integer || reader.TokenType == JsonToken.Float)
+            {
+                float result = (float)Convert.ToDouble(reader.Value);
+                reader.Read();
+                return result;
+            }
+            else
+            {
+                throw error(""float"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override double ReadDouble()
+        {
+            advance(Symbol.Double);
+            if (reader.TokenType == JsonToken.Integer || reader.TokenType == JsonToken.Float)
+            {
+                double result = Convert.ToDouble(reader.Value);
+                reader.Read();
+                return result;
+            }
+            else
+            {
+                throw error(""double"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override string ReadString()
+        {
+            advance(Symbol.String);
+            if (Parser.TopSymbol() == Symbol.MapKeyMarker)
+            {
+                Parser.Advance(Symbol.MapKeyMarker);
+                if (reader.TokenType != JsonToken.PropertyName)
+                {
+                    throw error(""map-key"");
+                }
+            }
+            else
+            {
+                if (reader.TokenType != JsonToken.String)
+                {
+                    throw error(""string"");
+                }
+            }
+
+            string result = Convert.ToString(reader.Value);
+            reader.Read();
+            return result;
+        }
+
+        /// <inheritdoc />
+        public override void SkipString()
+        {
+            advance(Symbol.String);
+            if (Parser.TopSymbol() == Symbol.MapKeyMarker)
+            {
+                Parser.Advance(Symbol.MapKeyMarker);
+                if (reader.TokenType != JsonToken.PropertyName)
+                {
+                    throw error(""map-key"");
+                }
+            }
+            else
+            {
+                if (reader.TokenType != JsonToken.String)
+                {
+                    throw error(""string"");
+                }
+            }
+
+            reader.Read();
+        }
+
+        /// <inheritdoc />
+        public override byte[] ReadBytes()
+        {
+            advance(Symbol.Bytes);
+            if (reader.TokenType == JsonToken.String)
+            {
+                byte[] result = readByteArray();
+                reader.Read();
+                return result;
+            }
+            else
+            {
+                throw error(""bytes"");
+            }
+        }
+
+        private byte[] readByteArray()
+        {
+            Encoding iso = Encoding.GetEncoding(""ISO-8859-1"");
+            byte[] result = iso.GetBytes(Convert.ToString(reader.Value));
+            return result;
+        }
+
+        /// <inheritdoc />
+        public override void SkipBytes()
+        {
+            advance(Symbol.Bytes);
+            if (reader.TokenType == JsonToken.String)
+            {
+                reader.Read();
+            }
+            else
+            {
+                throw error(""bytes"");
+            }
+        }
+
+        private void checkFixed(int size)
+        {
+            advance(Symbol.Fixed);
+            Symbol.IntCheckAction top = (Symbol.IntCheckAction)Parser.PopSymbol();
+            if (size != top.Size)
+            {
+                throw new AvroTypeException(""Incorrect length for fixed binary: expected "" + top.Size +
+                                            "" but received "" + size + "" bytes."");
+            }
+        }
+
+        /// <inheritdoc />
+        public override void ReadFixed(byte[] bytes)
+        {
+            ReadFixed(bytes, 0, bytes.Length);
+        }
+
+        /// <inheritdoc />
+        public override void ReadFixed(byte[] bytes, int start, int len)
+        {
+            checkFixed(len);
+            if (reader.TokenType == JsonToken.String)
+            {
+                byte[] result = readByteArray();
+                reader.Read();
+                if (result.Length != len)
+                {
+                    throw new AvroTypeException(""Expected fixed length "" + len + "", but got"" + result.Length);
+                }
+
+                Array.Copy(result, 0, bytes, start, len);
+            }
+            else
+            {
+                throw error(""fixed"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override void SkipFixed(int length)
+        {
+            checkFixed(length);
+            doSkipFixed(length);
+        }
+
+        private void doSkipFixed(int length)
+        {
+            if (reader.TokenType == JsonToken.String)
+            {
+                byte[] result = readByteArray();
+                reader.Read();
+                if (result.Length != length)
+                {
+                    throw new AvroTypeException(""Expected fixed length "" + length + "", but got"" + result.Length);
+                }
+            }
+            else
+            {
+                throw error(""fixed"");
+            }
+        }
+
+        /// <inheritdoc />
+        protected override void SkipFixed()
+        {
+            advance(Symbol.Fixed);
+            Symbol.IntCheckAction top = (Symbol.IntCheckAction)Parser.PopSymbol();
+            doSkipFixed(top.Size);
+        }
+
+        /// <inheritdoc />
+        public override int ReadEnum()
+        {
+            advance(Symbol.Enum);
+            Symbol.EnumLabelsAction top = (Symbol.EnumLabelsAction)Parser.PopSymbol();
+            if (reader.TokenType == JsonToken.String)
+            {
+                string label = Convert.ToString(reader.Value);
+                int n = top.FindLabel(label);
+                if (n >= 0)
+                {
+                    reader.Read();
+                    return n;
+                }
+
+                throw new AvroTypeException(""Unknown symbol in enum "" + label);
+            }
+            else
+            {
+                throw error(""fixed"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override long ReadArrayStart()
+        {
+            advance(Symbol.ArrayStart);
+            if (reader.TokenType == JsonToken.StartArray)
+            {
+                reader.Read();
+                return doArrayNext();
+            }
+            else
+            {
+                throw error(""array-start"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override long ReadArrayNext()
+        {
+            advance(Symbol.ItemEnd);
+            return doArrayNext();
+        }
+
+        private long doArrayNext()
+        {
+            if (reader.TokenType == JsonToken.EndArray)
+            {
+                Parser.Advance(Symbol.ArrayEnd);
+                reader.Read();
+                return 0;
+            }
+            else
+            {
+                return 1;
+            }
+        }
+
+        /// <inheritdoc />
+        public override void SkipArray()
+        {
+            advance(Symbol.ArrayStart);
+            if (reader.TokenType == JsonToken.StartArray)
+            {
+                reader.Skip();
+                reader.Read();
+                advance(Symbol.ArrayEnd);
+            }
+            else
+            {
+                throw error(""array-start"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override long ReadMapStart()
+        {
+            advance(Symbol.MapStart);
+            if (reader.TokenType == JsonToken.StartObject)
+            {
+                reader.Read();
+                return doMapNext();
+            }
+            else
+            {
+                throw error(""map-start"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override long ReadMapNext()
+        {
+            advance(Symbol.ItemEnd);
+            return doMapNext();
+        }
+
+        private long doMapNext()
+        {
+            if (reader.TokenType == JsonToken.EndObject)
+            {
+                reader.Read();
+                advance(Symbol.MapEnd);
+                return 0;
+            }
+            else
+            {
+                return 1;
+            }
+        }
+
+        /// <inheritdoc />
+        public override void SkipMap()
+        {
+            advance(Symbol.MapStart);
+            if (reader.TokenType == JsonToken.StartObject)
+            {
+                reader.Skip();
+                reader.Read();
+                advance(Symbol.MapEnd);
+            }
+            else
+            {
+                throw error(""map-start"");
+            }
+        }
+
+        /// <inheritdoc />
+        public override int ReadUnionIndex()
+        {
+            advance(Symbol.Union);
+            Symbol.Alternative a = (Symbol.Alternative)Parser.PopSymbol();
+
+            string label;
+            if (reader.TokenType == JsonToken.Null)
+            {
+                label = ""null"";
+            }
+            else if (reader.TokenType == JsonToken.StartObject)
+            {
+                reader.Read();
+                if (reader.TokenType == JsonToken.PropertyName)
+                {
+                    label = Convert.ToString(reader.Value);
+                    reader.Read();
+                    Parser.PushSymbol(Symbol.UnionEnd);
+                }
+                else
+                {
+                    throw error(""start-union"");
+                }
+            }
+            else
+            {
+                throw error(""start-union"");
+            }
+
+            int n = a.FindLabel(label);
+            if (n < 0)
+            {
+                throw new AvroTypeException(""Unknown union branch "" + label);
+            }
+
+            Parser.PushSymbol(a.GetSymbol(n));
+            return n;
+        }
+
+        /// <inheritdoc />
+        public override void SkipNull()
+        {
+            ReadNull();
+        }
+
+        /// <inheritdoc />
+        public override void SkipBoolean()
+        {
+            ReadBoolean();
+        }
+
+        /// <inheritdoc />
+        public override void SkipInt()
+        {
+            ReadInt();
+        }
+
+        /// <inheritdoc />
+        public override void SkipLong()
+        {
+            ReadLong();
+        }
+
+        /// <inheritdoc />
+        public override void SkipFloat()
+        {
+            ReadFloat();
+        }
+
+        /// <inheritdoc />
+        public override void SkipDouble()
+        {
+            ReadDouble();
+        }
+
+        /// <inheritdoc />
+        public override void SkipEnum()
+        {
+            ReadEnum();
+        }
+
+        /// <inheritdoc />
+        public override void SkipUnionIndex()
+        {
+            ReadUnionIndex();
+        }
+
+        /// <inheritdoc />
+        public override Symbol DoAction(Symbol input, Symbol top)
+        {
+            if (top is Symbol.FieldAdjustAction)
+            {
+                Symbol.FieldAdjustAction fa = (Symbol.FieldAdjustAction)top;
+                string name = fa.FName;
+                if (currentReorderBuffer != null)
+                {
+                    IList<JsonElement> node = currentReorderBuffer.SavedFields[name];
+                    if (node != null)
+                    {
+                        currentReorderBuffer.SavedFields.Remove(name);
+                        currentReorderBuffer.OrigParser = reader;
+                        reader = makeParser(node);
+                        return null;
+                    }
+                }
+
+                if (reader.TokenType == JsonToken.PropertyName)
+                {
+                    do
+                    {
+                        string fn = Convert.ToString(reader.Value);
+                        reader.Read();
+                        if (name.Equals(fn) || (fa.Aliases != null && fa.Aliases.Contains(fn)))
+                        {
+                            return null;
+                        }
+                        else
+                        {
+                            if (currentReorderBuffer == null)
+                            {
+                                currentReorderBuffer = new ReorderBuffer();
+                            }
+
+                            currentReorderBuffer.SavedFields[fn] = getValueAsTree(reader);
+                        }
+                    } while (reader.TokenType == JsonToken.PropertyName);
+
+                    throw new AvroTypeException(""Expected field name not found: "" + fa.FName);
+                }
+            }
+            else if (top == Symbol.FieldEnd)
+            {
+                if (currentReorderBuffer != null && currentReorderBuffer.OrigParser != null)
+                {
+                    reader = currentReorderBuffer.OrigParser;
+                    currentReorderBuffer.OrigParser = null;
+                }
+            }
+            else if (top == Symbol.RecordStart)
+            {
+                if (reader.TokenType == JsonToken.StartObject)
+                {
+                    reader.Read();
+                    reorderBuffers.Push(currentReorderBuffer);
+                    currentReorderBuffer = null;
+                }
+                else
+                {
+                    throw error(""record-start"");
+                }
+            }
+            else if (top == Symbol.RecordEnd || top == Symbol.UnionEnd)
+            {
+                // AVRO-2034 advance to the end of our object
+                while (reader.TokenType != JsonToken.EndObject)
+                {
+                    reader.Read();
+                }
+
+                if (top == Symbol.RecordEnd)
+                {
+                    if (currentReorderBuffer != null && currentReorderBuffer.SavedFields.Count > 0)
+                    {
+                        throw error(""Unknown fields: "" + currentReorderBuffer.SavedFields.Keys);
+                    }
+
+                    currentReorderBuffer = reorderBuffers.Pop();
+                }
+
+                // AVRO-2034 advance beyond the end object for the next record.
+                reader.Read();
+            }
+            else
+            {
+                throw new AvroTypeException(""Unknown action symbol "" + top);
+            }
+
+            return null;
+        }
+
+
+        private class JsonElement
+        {
+            public readonly JsonToken Token;
+            public readonly object Value;
+
+            public JsonElement(JsonToken t, object value)
+            {
+                this.Token = t;
+                this.Value = value;
+            }
+
+            public JsonElement(JsonToken t) : this(t, null)
+            {
+            }
+        }
+
+        private static IList<JsonElement> getValueAsTree(JsonReader reader)
+        {
+            int level = 0;
+            IList<JsonElement> result = new List<JsonElement>();
+            do
+            {
+                JsonToken t = reader.TokenType;
+                switch (t)
+                {
+                    case JsonToken.StartObject:
+                    case JsonToken.StartArray:
+                        level++;
+                        result.Add(new JsonElement(t));
+                        break;
+                    case JsonToken.EndObject:
+                    case JsonToken.EndArray:
+                        level--;
+                        result.Add(new JsonElement(t));
+                        break;
+                    case JsonToken.PropertyName:
+                    case JsonToken.String:
+                    case JsonToken.Integer:
+                    case JsonToken.Float:
+                    case JsonToken.Boolean:
+                    case JsonToken.Null:
+                        result.Add(new JsonElement(t, reader.Value));
+                        break;
+                }
+
+                reader.Read();
+            } while (level != 0);
+
+            result.Add(new JsonElement(JsonToken.None));
+            return result;
+        }
+
+        private JsonReader makeParser(in IList<JsonElement> elements)
+        {
+            return new JsonElementReader(elements);
+        }
+
+        private class JsonElementReader : JsonReader
+        {
+            private readonly IList<JsonElement> elements;
+
+            public JsonElementReader(IList<JsonElement> elements)
+            {
+                this.elements = elements;
+                pos = 0;
+            }
+
+            private int pos;
+
+            public override object Value
+            {
+                get { return elements[pos].Value; }
+            }
+
+            public override JsonToken TokenType
+            {
+                get { return elements[pos].Token; }
+            }
+
+            public override bool Read()
+            {
+                pos++;
+                return true;
+            }
+
+            public new void Skip()","[{'comment': 'Is JsonElementReader.Skip() ever called? JsonDecoder.SkipArray() and JsonDecoder.SkipMap() can call reader.Skip(), but that refers to the field `private JsonReader reader;`, so the call goes to [JsonReader.Skip()](https://www.newtonsoft.com/json/help/html/M_Newtonsoft_Json_JsonReader_Skip.htm), which is not virtual.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Removed', 'commenter': 'rayokota'}]"
1833,lang/csharp/src/apache/main/IO/Parsing/Parser.cs,"@@ -0,0 +1,229 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using System;
+
+namespace Avro.IO.Parsing
+{
+    /// <summary>
+    /// Parser is the class that maintains the stack for parsing. This class is used
+    /// by encoders, which are not required to skip.
+    /// </summary>
+    public class Parser
+    {
+        /// <summary>
+        /// The parser knows how to handle the terminal and non-terminal symbols. But it
+        /// needs help from outside to handle implicit and explicit actions. The clients
+        /// implement this interface to provide this help.
+        /// </summary>
+        public interface ActionHandler","[{'comment': 'Please name interfaces starting with ""I"" according to the .NET convention, at least if they are visible outside the assembly. Likewise in SkipParser.SkipHandler.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Fixed', 'commenter': 'rayokota'}]"
1833,lang/csharp/src/apache/main/IO/JsonEncoder.cs,"@@ -0,0 +1,360 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using Avro.IO.Parsing;
+using System.Collections;
+using System.IO;
+using System.Text;
+using Newtonsoft.Json;
+
+namespace Avro.IO
+{
+    /// <summary>
+    /// An <seealso cref=""Encoder""/> for Avro's JSON data encoding.","[{'comment': 'For inline links, please use [see](https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/xmldoc/recommended-tags#see) rather than seealso.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Done', 'commenter': 'rayokota'}]"
1833,lang/csharp/src/apache/main/IO/JsonEncoder.cs,"@@ -0,0 +1,360 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using Avro.IO.Parsing;
+using System.Collections;
+using System.IO;
+using System.Text;
+using Newtonsoft.Json;
+
+namespace Avro.IO
+{
+    /// <summary>
+    /// An <seealso cref=""Encoder""/> for Avro's JSON data encoding.
+    ///
+    /// JsonEncoder buffers output, and data may not appear on the output until
+    /// <seealso cref=""Encoder.Flush()""/> is called.
+    ///
+    /// JsonEncoder is not thread-safe.
+    /// </summary>
+    public class JsonEncoder : ParsingEncoder, Parser.ActionHandler
+    {
+        private readonly Parser parser;
+        private JsonWriter writer;
+        private bool includeNamespace = true;
+
+        // Has anything been written into the collections?
+        private readonly BitArray isEmpty = new BitArray(64);
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonEncoder""/> class.
+        /// </summary>
+        public JsonEncoder(Schema sc, Stream stream) : this(sc, getJsonWriter(stream, false))
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonEncoder""/> class.
+        /// </summary>
+        public JsonEncoder(Schema sc, Stream stream, bool pretty) : this(sc, getJsonWriter(stream, pretty))
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonEncoder""/> class.
+        /// </summary>
+        public JsonEncoder(Schema sc, JsonWriter writer)
+        {
+            Configure(writer);
+            this.parser = new Parser((new JsonGrammarGenerator()).Generate(sc), this);
+        }
+
+        /// <inheritdoc />
+        public override void Flush()
+        {
+            parser.ProcessImplicitActions();
+            if (writer != null)
+            {
+                writer.Flush();
+            }
+        }
+
+        // by default, one object per line.
+        // with pretty option use default pretty printer with root line separator.
+        private static JsonWriter getJsonWriter(Stream stream, bool pretty)
+        {
+            JsonWriter writer = new JsonTextWriter(new StreamWriter(stream));
+            if (pretty)
+            {
+                writer.Formatting = Formatting.Indented;
+            }
+
+            return writer;
+        }
+
+        /// <summary>
+        /// Whether to include the namespace.
+        /// </summary>
+        public virtual bool IncludeNamespace
+        {
+            get { return includeNamespace; }
+            set { this.includeNamespace = value; }
+        }
+
+
+        /// <summary>
+        /// Reconfigures this JsonEncoder to use the output stream provided.
+        /// <p/>
+        /// Otherwise, this JsonEncoder will flush its current output and then
+        /// reconfigure its output to use a default UTF8 JsonWriter that writes to the
+        /// provided OutputStream.","[{'comment': 'OutputStream is a Java thing', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Fixed', 'commenter': 'rayokota'}]"
1833,lang/csharp/src/apache/main/IO/JsonEncoder.cs,"@@ -0,0 +1,360 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using Avro.IO.Parsing;
+using System.Collections;
+using System.IO;
+using System.Text;
+using Newtonsoft.Json;
+
+namespace Avro.IO
+{
+    /// <summary>
+    /// An <seealso cref=""Encoder""/> for Avro's JSON data encoding.
+    ///
+    /// JsonEncoder buffers output, and data may not appear on the output until
+    /// <seealso cref=""Encoder.Flush()""/> is called.
+    ///
+    /// JsonEncoder is not thread-safe.
+    /// </summary>
+    public class JsonEncoder : ParsingEncoder, Parser.ActionHandler
+    {
+        private readonly Parser parser;
+        private JsonWriter writer;
+        private bool includeNamespace = true;
+
+        // Has anything been written into the collections?
+        private readonly BitArray isEmpty = new BitArray(64);
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonEncoder""/> class.
+        /// </summary>
+        public JsonEncoder(Schema sc, Stream stream) : this(sc, getJsonWriter(stream, false))
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonEncoder""/> class.
+        /// </summary>
+        public JsonEncoder(Schema sc, Stream stream, bool pretty) : this(sc, getJsonWriter(stream, pretty))
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""JsonEncoder""/> class.
+        /// </summary>
+        public JsonEncoder(Schema sc, JsonWriter writer)
+        {
+            Configure(writer);
+            this.parser = new Parser((new JsonGrammarGenerator()).Generate(sc), this);
+        }
+
+        /// <inheritdoc />
+        public override void Flush()
+        {
+            parser.ProcessImplicitActions();
+            if (writer != null)
+            {
+                writer.Flush();
+            }
+        }
+
+        // by default, one object per line.
+        // with pretty option use default pretty printer with root line separator.
+        private static JsonWriter getJsonWriter(Stream stream, bool pretty)
+        {
+            JsonWriter writer = new JsonTextWriter(new StreamWriter(stream));
+            if (pretty)
+            {
+                writer.Formatting = Formatting.Indented;
+            }
+
+            return writer;
+        }
+
+        /// <summary>
+        /// Whether to include the namespace.
+        /// </summary>
+        public virtual bool IncludeNamespace
+        {
+            get { return includeNamespace; }
+            set { this.includeNamespace = value; }
+        }
+
+
+        /// <summary>
+        /// Reconfigures this JsonEncoder to use the output stream provided.
+        /// <p/>
+        /// Otherwise, this JsonEncoder will flush its current output and then
+        /// reconfigure its output to use a default UTF8 JsonWriter that writes to the
+        /// provided OutputStream.
+        /// </summary>
+        /// <param name=""stream""> The OutputStream to direct output to. Cannot be null. </param>
+        /// <returns> this JsonEncoder </returns>
+        public JsonEncoder Configure(Stream stream)
+        {
+            this.Configure(getJsonWriter(stream, false));
+            return this;
+        }
+
+        /// <summary>
+        /// Reconfigures this JsonEncoder to output to the JsonWriter provided.
+        /// <p/>
+        /// Otherwise, this JsonEncoder will flush its current output and then
+        /// reconfigure its output to use the provided JsonWriter.
+        /// </summary>
+        /// <param name=""jsonWriter""> The JsonWriter to direct output to. Cannot be null. </param>
+        /// <returns> this JsonEncoder </returns>
+        public JsonEncoder Configure(JsonWriter jsonWriter)
+        {
+            if (null != parser)
+            {
+                Flush();
+            }
+
+            this.writer = jsonWriter;
+            return this;
+        }
+
+        /// <inheritdoc />
+        public override void WriteNull()
+        {
+            parser.Advance(Symbol.Null);
+            writer.WriteNull();
+        }
+
+        /// <inheritdoc />
+        public override void WriteBoolean(bool b)
+        {
+            parser.Advance(Symbol.Boolean);
+            writer.WriteValue(b);
+        }
+
+        /// <inheritdoc />
+        public override void WriteInt(int n)
+        {
+            parser.Advance(Symbol.Int);
+            writer.WriteValue(n);
+        }
+
+        /// <inheritdoc />
+        public override void WriteLong(long n)
+        {
+            parser.Advance(Symbol.Long);
+            writer.WriteValue(n);
+        }
+
+        /// <inheritdoc />
+        public override void WriteFloat(float f)
+        {
+            parser.Advance(Symbol.Float);
+            writer.WriteValue(f);
+        }
+
+        /// <inheritdoc />
+        public override void WriteDouble(double d)
+        {
+            parser.Advance(Symbol.Double);
+            writer.WriteValue(d);
+        }
+
+        /// <inheritdoc />
+        public override void WriteString(string str)
+        {
+            parser.Advance(Symbol.String);
+            if (parser.TopSymbol() == Symbol.MapKeyMarker)
+            {
+                parser.Advance(Symbol.MapKeyMarker);
+                writer.WritePropertyName(str);
+            }
+            else
+            {
+                writer.WriteValue(str);
+            }
+        }
+
+        /// <inheritdoc />
+        public override void WriteBytes(byte[] bytes)
+        {
+            WriteBytes(bytes, 0, bytes.Length);
+        }
+
+        /// <inheritdoc />
+        public override void WriteBytes(byte[] bytes, int start, int len)
+        {
+            parser.Advance(Symbol.Bytes);
+            writeByteArray(bytes, start, len);
+        }
+
+        private void writeByteArray(byte[] bytes, int start, int len)
+        {
+            Encoding iso = Encoding.GetEncoding(""ISO-8859-1"");
+            writer.WriteValue(iso.GetString(bytes, start, len));
+        }
+
+        /// <inheritdoc />
+        public override void WriteFixed(byte[] bytes)
+        {
+            WriteFixed(bytes, 0, bytes.Length);
+        }
+
+        /// <inheritdoc />
+        public override void WriteFixed(byte[] bytes, int start, int len)
+        {
+            parser.Advance(Symbol.Fixed);
+            Symbol.IntCheckAction top = (Symbol.IntCheckAction)parser.PopSymbol();
+            if (len != top.Size)
+            {
+                throw new AvroTypeException(""Incorrect length for fixed binary: expected "" + top.Size +
+                                            "" but received "" + len + "" bytes."");
+            }
+
+            writeByteArray(bytes, start, len);
+        }
+
+        /// <inheritdoc />
+        public override void WriteEnum(int e)
+        {
+            parser.Advance(Symbol.Enum);
+            Symbol.EnumLabelsAction top = (Symbol.EnumLabelsAction)parser.PopSymbol();
+            if (e < 0 || e >= top.Size)
+            {
+                throw new AvroTypeException(""Enumeration out of range: max is "" + top.Size + "" but received "" + e);
+            }
+
+            writer.WriteValue(top.GetLabel(e));
+        }
+
+        /// <inheritdoc />
+        public override void WriteArrayStart()
+        {
+            parser.Advance(Symbol.ArrayStart);
+            writer.WriteStartArray();
+            Push();
+            if (Depth() >= isEmpty.Length)
+            {
+                isEmpty.Length += isEmpty.Length;
+            }
+
+            isEmpty.Set(Depth(), true);
+        }
+
+        /// <inheritdoc />
+        public override void WriteArrayEnd()
+        {
+            if (!isEmpty.Get(Pos))
+            {
+                parser.Advance(Symbol.ItemEnd);
+            }
+
+            Pop();
+            parser.Advance(Symbol.ArrayEnd);
+            writer.WriteEndArray();
+        }
+
+        /// <inheritdoc />
+        public override void WriteMapStart()
+        {
+            Push();
+            if (Depth() >= isEmpty.Length)
+            {
+                isEmpty.Length += isEmpty.Length;
+            }
+
+            isEmpty.Set(Depth(), true);
+
+            parser.Advance(Symbol.MapStart);
+            writer.WriteStartObject();
+        }
+
+        /// <inheritdoc />
+        public override void WriteMapEnd()
+        {
+            if (!isEmpty.Get(Pos))
+            {
+                parser.Advance(Symbol.ItemEnd);
+            }
+
+            Pop();
+
+            parser.Advance(Symbol.MapEnd);
+            writer.WriteEndObject();
+        }
+
+        /// <summary>
+        /// Start an array item.
+        /// </summary>
+        public new void StartItem()","[{'comment': 'Is JsonEncoder.StartItem() ever called?', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'This is inherited from `Encoder`, and `encoder.StartItem` does seem to be called in several places.', 'commenter': 'rayokota'}, {'comment': 'The Encoder.StartItem() implementation comes from ParsingEncoder.StartItem(), not from JsonEncoder.StartItem(). The following outputs ""BaseImpl.Run"":\r\n\r\n```C#\r\nusing System;\r\n\r\nnamespace InterfaceImpl\r\n{\r\n    interface IFace\r\n    {\r\n        void Run();\r\n    }\r\n\r\n    class BaseImpl : IFace\r\n    {\r\n        public void Run()\r\n        {\r\n            Console.WriteLine(""BaseImpl.Run"");\r\n        }\r\n    }\r\n\r\n    class DerivedImpl : BaseImpl\r\n    {\r\n        public new void Run()\r\n        {\r\n            Console.WriteLine(""DerivedImpl.Run"");\r\n        }\r\n    }\r\n\r\n    class Program\r\n    {\r\n        static void Main()\r\n        {\r\n            IFace i = new DerivedImpl();\r\n            i.Run();\r\n        }\r\n    }\r\n}\r\n```\r\n\r\nIf you change that to `class DerivedImpl : BaseImpl, IFace`, then it outputs ""DerivedImpl.Run"". Which would correspond to `public class JsonEncoder : ParsingEncoder, Encoder, Parser.IActionHandler` in the Avro library. However, I think it would be simpler to make ParsingEncoder.StartItem() virtual, because methods that implement interface methods must be virtual in the CLI metadata anyway (ECMA-335 6th ed. §II.12.2 and §II.22.27; if such a method is not virtual in C# source code, then the C# compiler makes it final virtual in the metadata).', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Ah, thanks for the detailed explained.  I fixed this.', 'commenter': 'rayokota'}]"
1833,lang/csharp/src/apache/main/IO/ParsingDecoder.cs,"@@ -0,0 +1,205 @@
+﻿/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+using Avro.IO.Parsing;
+
+namespace Avro.IO
+{
+    /// <summary>
+    /// Base class for <a href=""parsing/package-summary.html"">parser</a>-based","[{'comment': 'Not sure what ""parsing/package-summary.html"" refers to. Likewise in ParsingEncoder.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'The C# compiler supports linking to a namespace with `<see cref=""Parsing""/>`. I don\'t know whether Doxygen supports it too.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Fixed', 'commenter': 'rayokota'}]"
1836,lang/c++/impl/ValidSchema.cc,"@@ -70,7 +70,7 @@ static bool validate(const NodePtr &node, SymbolMap &symbolMap) {
 
     node->lock();
     auto leaves = node->leaves();
-    for (auto i = 0; i < leaves; ++i) {
+    for (long unsigned int i = 0; i < leaves; ++i) {","[{'comment': 'Better use size_t, because Node::leaves returns size_t, and Node::leafAt takes a size_t parameter. Or perhaps decltype(leaves).', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': ""On 64-bit Microsoft Windows, `size_t` is 64-bit, but `long unsigned int` is 32-bit and would not be pedantically correct. In practice though, it's rather unlikely that a node would have billions of leaves."", 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Improved! Thanks!', 'commenter': 'martin-g'}]"
1842,lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryDecoder.java,"@@ -317,7 +320,7 @@ private void validateInputStreamSkips(InputStream test, InputStream check) throw
   public void testBadIntEncoding() throws IOException {
     byte[] badint = new byte[5];
     Arrays.fill(badint, (byte) 0xff);
-    Decoder bd = factory.binaryDecoder(badint, null);
+    Decoder bd = this.newDecoder(badint);","[{'comment': 'To clarify the purpose of the JIRA: this test only checks that `binaryEncoder` correctly deals with badly encoded INTs, and it does it twice.  One of those times, `directBinaryEncoder` should be called!', 'commenter': 'RyanSkraba'}, {'comment': 'Change, all methods now test DirectBinaryDecoder, then BinaryDecoder. We can see that the behavior sometimes differs  with the type of exceptions that are thrown. ', 'commenter': 'clesaec'}]"
1863,lang/java/maven-plugin/pom.xml,"@@ -60,6 +60,7 @@
       <groupId>org.apache.maven</groupId>
       <artifactId>maven-core</artifactId>
       <version>${maven-core.version}</version>
+      <scope>provided</scope>","[{'comment': ""This fixes the following Maven error:\r\n```\r\n[INFO] --- maven-plugin-plugin:3.6.4:helpmojo (generated-helpmojo) @ avro-maven-plugin ---\r\n[ERROR] \r\n\r\nSome dependencies of Maven Plugins are expected to be in provided scope.\r\nPlease make sure that dependencies listed below declared in POM\r\nhave set '<scope>provided</scope>' as well.\r\n\r\nThe following dependencies are in wrong scope:\r\n * org.apache.maven:maven-core:jar:3.3.9:compile\r\n * org.apache.maven:maven-model:jar:3.3.9:compile\r\n * org.apache.maven:maven-settings:jar:3.3.9:compile\r\n * org.apache.maven:maven-settings-builder:jar:3.3.9:compile\r\n * org.apache.maven:maven-builder-support:jar:3.3.9:compile\r\n * org.apache.maven:maven-repository-metadata:jar:3.3.9:compile\r\n * org.apache.maven:maven-artifact:jar:3.3.9:compile\r\n * org.apache.maven:maven-plugin-api:jar:3.3.9:compile\r\n * org.apache.maven:maven-model-builder:jar:3.3.9:compile\r\n * org.apache.maven:maven-aether-provider:jar:3.3.9:compile\r\n```"", 'commenter': 'martin-g'}]"
1863,lang/java/maven-plugin/src/test/resources/unit/idl/pom-injecting-velocity-tools.xml,"@@ -22,7 +22,7 @@
   <parent>
     <artifactId>avro-parent</artifactId>
     <groupId>org.apache.avro</groupId>
-    <version>1.11.0-SNAPSHOT</version>
+    <version>1.12.0-SNAPSHOT</version>","[{'comment': 'It seems something is wrong with the release process. Several pom.xml files were still pointing to the old 1.11.0-SNAPSHOT parent.', 'commenter': 'martin-g'}, {'comment': 'Good catch, this should have been done in https://cwiki.apache.org/confluence/display/AVRO/How+To+Release#HowToRelease-Branching (Step 2c)!', 'commenter': 'RyanSkraba'}]"
1863,lang/java/archetypes/avro-service-archetype/src/main/pom/pom.xml,"@@ -79,9 +79,9 @@
       <version>\${logback.version}</version>
     </dependency>
     <dependency>
-      <groupId>junit</groupId>
-      <artifactId>junit</artifactId>
-      <version>\${junit.version}</version>
+      <groupId>org.junit.vintage</groupId>
+      <artifactId>junit-vintage-engine</artifactId>
+      <version>\${junit5.version}</version>","[{'comment': 'This looks like it (only) uses the vintage engine. Do we also want to run JUnit5 (Jupiter) tests?\r\n\r\nIn that case, we also need to add the Jupiter engine IIRC.', 'commenter': 'opwvhk'}, {'comment': 'Huh -- as far as I remember @opwvhk is correct, and yet JUnit5 tests [are being run](https://github.com/apache/avro/actions/runs/3044499132/jobs/4904953694#step:7:404)!  (TestDataFile is definitely a JUnit5 migrated class).', 'commenter': 'RyanSkraba'}, {'comment': 'Oh, my mistake, I see -- yes, this archetype can probably be safely left as it is (on JUnit4) or entirely migrate the generated test to [JUnit5](https://github.com/apache/avro/blob/70260919426f89825ca148f5ee815f3b2cf4764d/lang/java/archetypes/avro-service-archetype/src/main/resources/archetype-resources/src/test/java/integration/SimpleOrderServiceIntegrationTest.java#L33-L35) \r\n\r\nLets not mix JUnit4 and JUnit5 in the archetype, however!', 'commenter': 'RyanSkraba'}, {'comment': 'Good catch! I will migrate the archetype to JUnit 5.x!', 'commenter': 'martin-g'}, {'comment': 'Done with https://github.com/apache/avro/pull/1863/commits/65c3ac3354fceaaa6aaa2e81bf54475b1541b2b1', 'commenter': 'martin-g'}]"
1863,lang/java/maven-plugin/pom.xml,"@@ -24,7 +24,7 @@
     <artifactId>avro-parent</artifactId>
     <groupId>org.apache.avro</groupId>
     <version>1.12.0-SNAPSHOT</version>
-    <relativePath>../</relativePath>","[{'comment': 'Just for info, is this a best practice?', 'commenter': 'RyanSkraba'}, {'comment': ""At least Intellij IDEA suggests so. It shows `../` as a warning.\r\nI'm OK to revert it."", 'commenter': 'martin-g'}]"
1901,lang/rust/avro/src/error.rs,"@@ -229,6 +229,9 @@ pub enum Error {
     #[error(""Unions cannot contain duplicate types"")]
     GetUnionDuplicate,
 
+    #[error(""Unions first type {0:?} must match default value type {1:?}"")]","[{'comment': '```suggestion\r\n    #[error(""Union\'s first type {0:?} must match the `default`\'s value type {1:?}"")]\r\n```', 'commenter': 'martin-g'}]"
1901,lang/rust/avro/src/schema.rs,"@@ -1373,12 +1376,35 @@ impl Parser {
         &mut self,
         items: &[Value],
         enclosing_namespace: &Namespace,
+        default: Option<&Value>
     ) -> AvroResult<Schema> {
         items
             .iter()
             .map(|v| self.parse(v, enclosing_namespace))
             .collect::<Result<Vec<_>, _>>()
+            .and_then(|schemas| {
+                if let Some(default_value) = default {
+                    let avro_value = types::Value::from(default_value.clone());
+                    let first_schema = schemas.first().cloned();
+                    if let Some(schema) = first_schema {
+                        // Try to resolve the schema
+                        let resolved_value = avro_value.clone().resolve(&schema);
+                        let schema_kind = SchemaKind::from(schema);
+                        let value_kind = types::ValueKind::from(avro_value);","[{'comment': 'nit: The last two lines should be moved to line 1397.', 'commenter': 'martin-g'}]"
1920,lang/c++/CMakeLists.txt,"@@ -21,7 +21,7 @@ cmake_minimum_required (VERSION 3.1)
 set (CMAKE_LEGACY_CYGWIN_WIN32 0)
 
 if (NOT DEFINED CMAKE_CXX_STANDARD)
-    set(CMAKE_CXX_STANDARD 11)
+    set(CMAKE_CXX_STANDARD 14)","[{'comment': ""Let's jump directly to 17  - https://issues.apache.org/jira/browse/AVRO-3610"", 'commenter': 'martin-g'}, {'comment': ""Sure, I've updated the PR."", 'commenter': 'jmccl'}]"
2024,lang/rust/avro/src/de.rs,"@@ -435,6 +433,7 @@ impl<'a, 'de> de::Deserializer<'de> for &'a Deserializer<'de> {
     {
         match *self.input {
             Value::Map(ref items) => visitor.visit_map(MapDeserializer::new(items)),
+            Value::Record(ref fields) => visitor.visit_map(RecordDeserializer::new(fields)),
             _ => Err(de::Error::custom(""not a map"")),","[{'comment': '```suggestion\r\n            _ => Err(de::Error::custom(format!(""Expected a Record or a Map! Got: {:?}"", &self.input))),\r\n```', 'commenter': 'martin-g'}]"
2024,lang/rust/avro/src/de.rs,"@@ -857,6 +856,33 @@ mod tests {
         );
     }
 
+    #[test]
+    fn test_from_value_struct_flatten() {","[{'comment': '```suggestion\r\n    fn test_avro_3692_from_value_struct_flatten() {\r\n```', 'commenter': 'martin-g'}]"
2101,lang/csharp/src/apache/msbuild/Apache.Avro.MSBuild.props,"@@ -0,0 +1,19 @@
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the ""License""); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       https://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an ""AS IS"" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+<Project>
+  <UsingTask TaskName=""Avro.msbuild.AvroGenTask"" AssemblyFile=""$(MSBuildThisFileDirectory)..\tasks\$(TargetFramework)\Avro.msbuild.dll"" />","[{'comment': ""Please don't use `$(TargetFramework)` in the AssemblyFile parameter.\r\n\r\nThis is apparently included in the Apache.Avro.MSBuild package and imported by projects that reference the package. `$(TargetFramework)` is wrong for these reasons:\r\n\r\n* If my project targets net6.0 but is built using MSBuild.exe on .NET Framework, then the MSBuild process cannot load an Avro.msbuild.dll that was built for net6.0. It needs an Avro.msbuild.dll that was built for .NET Framework or .NET Standard 2.0.\r\n* If my project targets net45, then the `UsingTask` won't find Avro.msbuild.dll because there is no `tasks\\net45` directory in the package.\r\n* If my project has multiple target frameworks, then I want to run AvroGenTask just once in the crosstargeting build in which `$(TargetFramework)` is empty, rather than separately for each target framework; the generated files should be identical anyway and this lets the target-framework-specific builds run in parallel without trying to write the same files.\r\n* TargetFramework might be a custom alias that my project maps to some standard TargetFrameworkIdentifier and TargetFrameworkVersion. <https://github.com/NuGet/Home/issues/5154>\r\n\r\nIt would be easiest would be to always use netstandard2.0 in AssemblyFile.  Alternatively, add conditions on `$(MSBuildRuntimeType)` and `$(MSBuildVersion)`."", 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'OTOH, this props file wouldn\'t even be imported in the crosstargeting build, because it is packed with `PackagePath=""build\\""` rather than `PackagePath=""buildMultiTargeting\\""`.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': ""Re using `$(MSBuildVersion)`, the idea is that although MSBuild provides neither a built-in property nor a property function for getting the version of .NET on which MSBuild is running, each version of MSBuild on .NET requires some minimum version of .NET, so if `$(MSBuildVersion)` shows you have that version of MSBuild, then you can assume it can load assemblies built for the corresponding version of .NET. But I don't really see what advantage this would have over always using netstandard2.0."", 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'understood - pushed change', 'commenter': 'Freds72AtWork'}]"
2142,lang/java/tools/src/test/compiler/output-string/avro/examples/baseball/NullSafeAnnotationsFieldsTest.java,"@@ -0,0 +1,597 @@
+/**
+ * Autogenerated by Avro
+ *
+ * DO NOT EDIT DIRECTLY
+ */
+package avro.examples.baseball;
+
+import org.apache.avro.generic.GenericArray;
+import org.apache.avro.specific.SpecificData;
+import org.apache.avro.util.Utf8;
+import org.apache.avro.message.BinaryMessageEncoder;
+import org.apache.avro.message.BinaryMessageDecoder;
+import org.apache.avro.message.SchemaStore;
+import org.jetbrains.annotations.Nullable;
+import org.jetbrains.annotations.NotNull;
+
+/** Test that @Nullable and @NotNull annotations are created for all fields */
+@org.apache.avro.specific.AvroGenerated
+public class NullSafeAnnotationsFieldsTest extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
+  private static final long serialVersionUID = 2020521726426674816L;
+
+
+  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse(""{\""type\"":\""record\"",\""name\"":\""NullSafeAnnotationsFieldsTest\"",\""namespace\"":\""avro.examples.baseball\"",\""doc\"":\""Test that @Nullable and @NotNull annotations are created for all fields\"",\""fields\"":[{\""name\"":\""name\"",\""type\"":{\""type\"":\""string\"",\""avro.java.string\"":\""String\""}},{\""name\"":\""nullable_name\"",\""type\"":[{\""type\"":\""string\"",\""avro.java.string\"":\""String\""},\""null\""]},{\""name\"":\""favorite_number\"",\""type\"":\""int\""},{\""name\"":\""nullable_favorite_number\"",\""type\"":[\""int\"",\""null\""]}]}"");
+  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
+
+  private static final SpecificData MODEL$ = new SpecificData();
+
+  private static final BinaryMessageEncoder<NullSafeAnnotationsFieldsTest> ENCODER =
+      new BinaryMessageEncoder<>(MODEL$, SCHEMA$);
+
+  private static final BinaryMessageDecoder<NullSafeAnnotationsFieldsTest> DECODER =
+      new BinaryMessageDecoder<>(MODEL$, SCHEMA$);
+
+  /**
+   * Return the BinaryMessageEncoder instance used by this class.
+   * @return the message encoder used by this class
+   */
+  public static BinaryMessageEncoder<NullSafeAnnotationsFieldsTest> getEncoder() {
+    return ENCODER;
+  }
+
+  /**
+   * Return the BinaryMessageDecoder instance used by this class.
+   * @return the message decoder used by this class
+   */
+  public static BinaryMessageDecoder<NullSafeAnnotationsFieldsTest> getDecoder() {
+    return DECODER;
+  }
+
+  /**
+   * Create a new BinaryMessageDecoder instance for this class that uses the specified {@link SchemaStore}.
+   * @param resolver a {@link SchemaStore} used to find schemas by fingerprint
+   * @return a BinaryMessageDecoder instance for this class backed by the given SchemaStore
+   */
+  public static BinaryMessageDecoder<NullSafeAnnotationsFieldsTest> createDecoder(SchemaStore resolver) {
+    return new BinaryMessageDecoder<>(MODEL$, SCHEMA$, resolver);
+  }
+
+  /**
+   * Serializes this NullSafeAnnotationsFieldsTest to a ByteBuffer.
+   * @return a buffer holding the serialized data for this instance
+   * @throws java.io.IOException if this instance could not be serialized
+   */
+  public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException {
+    return ENCODER.encode(this);
+  }
+
+  /**
+   * Deserializes a NullSafeAnnotationsFieldsTest from a ByteBuffer.
+   * @param b a byte buffer holding serialized data for an instance of this class
+   * @return a NullSafeAnnotationsFieldsTest instance decoded from the given buffer
+   * @throws java.io.IOException if the given bytes could not be deserialized into an instance of this class
+   */
+  public static NullSafeAnnotationsFieldsTest fromByteBuffer(
+      java.nio.ByteBuffer b) throws java.io.IOException {
+    return DECODER.decode(b);
+  }
+
+  private java.lang.String name;
+  private java.lang.String nullable_name;
+  private int favorite_number;
+  private java.lang.Integer nullable_favorite_number;
+
+  /**
+   * Default constructor.  Note that this does not initialize fields
+   * to their default values from the schema.  If that is desired then
+   * one should use <code>newBuilder()</code>.
+   */
+  public NullSafeAnnotationsFieldsTest() {}
+
+  /**
+   * All-args constructor.
+   * @param name The new value for name
+   * @param nullable_name The new value for nullable_name
+   * @param favorite_number The new value for favorite_number
+   * @param nullable_favorite_number The new value for nullable_favorite_number
+   */
+  public NullSafeAnnotationsFieldsTest(@NotNull java.lang.String name, @Nullable java.lang.String nullable_name, @NotNull java.lang.Integer favorite_number, @Nullable java.lang.Integer nullable_favorite_number) {
+    this.name = name;
+    this.nullable_name = nullable_name;
+    this.favorite_number = favorite_number;
+    this.nullable_favorite_number = nullable_favorite_number;
+  }
+
+  @Override
+  public org.apache.avro.specific.SpecificData getSpecificData() { return MODEL$; }
+
+  @Override
+  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
+
+  // Used by DatumWriter.  Applications should not call.
+  @Override
+  public java.lang.Object get(int field$) {
+    switch (field$) {
+    case 0: return name;
+    case 1: return nullable_name;
+    case 2: return favorite_number;
+    case 3: return nullable_favorite_number;
+    default: throw new IndexOutOfBoundsException(""Invalid index: "" + field$);
+    }
+  }
+
+  // Used by DatumReader.  Applications should not call.
+  @Override
+  @SuppressWarnings(value=""unchecked"")
+  public void put(int field$, java.lang.Object value$) {
+    switch (field$) {
+    case 0: name = value$ != null ? value$.toString() : null; break;
+    case 1: nullable_name = value$ != null ? value$.toString() : null; break;
+    case 2: favorite_number = (java.lang.Integer)value$; break;
+    case 3: nullable_favorite_number = (java.lang.Integer)value$; break;
+    default: throw new IndexOutOfBoundsException(""Invalid index: "" + field$);
+    }
+  }
+
+  /**
+   * Gets the value of the 'name' field.
+   * @return The value of the 'name' field.
+   */
+  @NotNull
+  public java.lang.String getName() {
+    return name;
+  }
+
+
+  /**
+   * Sets the value of the 'name' field.
+   * @param value the value to set.
+   */
+  public void setName(@NotNull java.lang.String value) {
+    this.name = value;
+  }
+
+  /**
+   * Gets the value of the 'nullable_name' field.
+   * @return The value of the 'nullable_name' field.
+   */
+  @Nullable
+  public java.lang.String getNullableName() {
+    return nullable_name;
+  }
+
+
+  /**
+   * Sets the value of the 'nullable_name' field.
+   * @param value the value to set.
+   */
+  public void setNullableName(@Nullable java.lang.String value) {
+    this.nullable_name = value;
+  }
+
+  /**
+   * Gets the value of the 'favorite_number' field.
+   * @return The value of the 'favorite_number' field.
+   */
+  @NotNull
+  public int getFavoriteNumber() {
+    return favorite_number;
+  }
+
+
+  /**
+   * Sets the value of the 'favorite_number' field.
+   * @param value the value to set.
+   */
+  public void setFavoriteNumber(@NotNull int value) {
+    this.favorite_number = value;
+  }
+
+  /**
+   * Gets the value of the 'nullable_favorite_number' field.
+   * @return The value of the 'nullable_favorite_number' field.
+   */
+  @Nullable
+  public java.lang.Integer getNullableFavoriteNumber() {
+    return nullable_favorite_number;
+  }
+
+
+  /**
+   * Sets the value of the 'nullable_favorite_number' field.
+   * @param value the value to set.
+   */
+  public void setNullableFavoriteNumber(@Nullable java.lang.Integer value) {
+    this.nullable_favorite_number = value;
+  }
+
+  /**
+   * Creates a new NullSafeAnnotationsFieldsTest RecordBuilder.
+   * @return A new NullSafeAnnotationsFieldsTest RecordBuilder
+   */
+  public static avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder newBuilder() {
+    return new avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder();
+  }
+
+  /**
+   * Creates a new NullSafeAnnotationsFieldsTest RecordBuilder by copying an existing Builder.
+   * @param other The existing builder to copy.
+   * @return A new NullSafeAnnotationsFieldsTest RecordBuilder
+   */
+  public static avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder newBuilder(avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder other) {
+    if (other == null) {
+      return new avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder();
+    } else {
+      return new avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder(other);
+    }
+  }
+
+  /**
+   * Creates a new NullSafeAnnotationsFieldsTest RecordBuilder by copying an existing NullSafeAnnotationsFieldsTest instance.
+   * @param other The existing instance to copy.
+   * @return A new NullSafeAnnotationsFieldsTest RecordBuilder
+   */
+  public static avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder newBuilder(avro.examples.baseball.NullSafeAnnotationsFieldsTest other) {
+    if (other == null) {
+      return new avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder();
+    } else {
+      return new avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder(other);
+    }
+  }
+
+  /**
+   * RecordBuilder for NullSafeAnnotationsFieldsTest instances.
+   */
+  @org.apache.avro.specific.AvroGenerated
+  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<NullSafeAnnotationsFieldsTest>
+    implements org.apache.avro.data.RecordBuilder<NullSafeAnnotationsFieldsTest> {
+
+    private java.lang.String name;
+    private java.lang.String nullable_name;
+    private int favorite_number;
+    private java.lang.Integer nullable_favorite_number;
+
+    /** Creates a new Builder */
+    private Builder() {
+      super(SCHEMA$, MODEL$);
+    }
+
+    /**
+     * Creates a Builder by copying an existing Builder.
+     * @param other The existing Builder to copy.
+     */
+    private Builder(avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder other) {
+      super(other);
+      if (isValidValue(fields()[0], other.name)) {
+        this.name = data().deepCopy(fields()[0].schema(), other.name);
+        fieldSetFlags()[0] = other.fieldSetFlags()[0];
+      }
+      if (isValidValue(fields()[1], other.nullable_name)) {
+        this.nullable_name = data().deepCopy(fields()[1].schema(), other.nullable_name);
+        fieldSetFlags()[1] = other.fieldSetFlags()[1];
+      }
+      if (isValidValue(fields()[2], other.favorite_number)) {
+        this.favorite_number = data().deepCopy(fields()[2].schema(), other.favorite_number);
+        fieldSetFlags()[2] = other.fieldSetFlags()[2];
+      }
+      if (isValidValue(fields()[3], other.nullable_favorite_number)) {
+        this.nullable_favorite_number = data().deepCopy(fields()[3].schema(), other.nullable_favorite_number);
+        fieldSetFlags()[3] = other.fieldSetFlags()[3];
+      }
+    }
+
+    /**
+     * Creates a Builder by copying an existing NullSafeAnnotationsFieldsTest instance
+     * @param other The existing instance to copy.
+     */
+    private Builder(avro.examples.baseball.NullSafeAnnotationsFieldsTest other) {
+      super(SCHEMA$, MODEL$);
+      if (isValidValue(fields()[0], other.name)) {
+        this.name = data().deepCopy(fields()[0].schema(), other.name);
+        fieldSetFlags()[0] = true;
+      }
+      if (isValidValue(fields()[1], other.nullable_name)) {
+        this.nullable_name = data().deepCopy(fields()[1].schema(), other.nullable_name);
+        fieldSetFlags()[1] = true;
+      }
+      if (isValidValue(fields()[2], other.favorite_number)) {
+        this.favorite_number = data().deepCopy(fields()[2].schema(), other.favorite_number);
+        fieldSetFlags()[2] = true;
+      }
+      if (isValidValue(fields()[3], other.nullable_favorite_number)) {
+        this.nullable_favorite_number = data().deepCopy(fields()[3].schema(), other.nullable_favorite_number);
+        fieldSetFlags()[3] = true;
+      }
+    }
+
+    /**
+      * Gets the value of the 'name' field.
+      * @return The value.
+      */
+    public java.lang.String getName() {
+      return name;
+    }
+
+
+    /**
+      * Sets the value of the 'name' field.
+      * @param value The value of 'name'.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder setName(@NotNull java.lang.String value) {
+      validate(fields()[0], value);
+      this.name = value;
+      fieldSetFlags()[0] = true;
+      return this;
+    }
+
+    /**
+      * Checks whether the 'name' field has been set.
+      * @return True if the 'name' field has been set, false otherwise.
+      */
+    public boolean hasName() {
+      return fieldSetFlags()[0];
+    }
+
+
+    /**
+      * Clears the value of the 'name' field.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder clearName() {
+      name = null;
+      fieldSetFlags()[0] = false;
+      return this;
+    }
+
+    /**
+      * Gets the value of the 'nullable_name' field.
+      * @return The value.
+      */
+    public java.lang.String getNullableName() {
+      return nullable_name;
+    }
+
+
+    /**
+      * Sets the value of the 'nullable_name' field.
+      * @param value The value of 'nullable_name'.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder setNullableName(@Nullable java.lang.String value) {
+      validate(fields()[1], value);
+      this.nullable_name = value;
+      fieldSetFlags()[1] = true;
+      return this;
+    }
+
+    /**
+      * Checks whether the 'nullable_name' field has been set.
+      * @return True if the 'nullable_name' field has been set, false otherwise.
+      */
+    public boolean hasNullableName() {
+      return fieldSetFlags()[1];
+    }
+
+
+    /**
+      * Clears the value of the 'nullable_name' field.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder clearNullableName() {
+      nullable_name = null;
+      fieldSetFlags()[1] = false;
+      return this;
+    }
+
+    /**
+      * Gets the value of the 'favorite_number' field.
+      * @return The value.
+      */
+    public int getFavoriteNumber() {
+      return favorite_number;
+    }
+
+
+    /**
+      * Sets the value of the 'favorite_number' field.
+      * @param value The value of 'favorite_number'.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder setFavoriteNumber(@NotNull int value) {
+      validate(fields()[2], value);
+      this.favorite_number = value;
+      fieldSetFlags()[2] = true;
+      return this;
+    }
+
+    /**
+      * Checks whether the 'favorite_number' field has been set.
+      * @return True if the 'favorite_number' field has been set, false otherwise.
+      */
+    public boolean hasFavoriteNumber() {
+      return fieldSetFlags()[2];
+    }
+
+
+    /**
+      * Clears the value of the 'favorite_number' field.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder clearFavoriteNumber() {
+      fieldSetFlags()[2] = false;
+      return this;
+    }
+
+    /**
+      * Gets the value of the 'nullable_favorite_number' field.
+      * @return The value.
+      */
+    public java.lang.Integer getNullableFavoriteNumber() {
+      return nullable_favorite_number;
+    }
+
+
+    /**
+      * Sets the value of the 'nullable_favorite_number' field.
+      * @param value The value of 'nullable_favorite_number'.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder setNullableFavoriteNumber(@Nullable java.lang.Integer value) {
+      validate(fields()[3], value);
+      this.nullable_favorite_number = value;
+      fieldSetFlags()[3] = true;
+      return this;
+    }
+
+    /**
+      * Checks whether the 'nullable_favorite_number' field has been set.
+      * @return True if the 'nullable_favorite_number' field has been set, false otherwise.
+      */
+    public boolean hasNullableFavoriteNumber() {
+      return fieldSetFlags()[3];
+    }
+
+
+    /**
+      * Clears the value of the 'nullable_favorite_number' field.
+      * @return This builder.
+      */
+    public avro.examples.baseball.NullSafeAnnotationsFieldsTest.Builder clearNullableFavoriteNumber() {
+      nullable_favorite_number = null;
+      fieldSetFlags()[3] = false;
+      return this;
+    }
+
+    @Override
+    @SuppressWarnings(""unchecked"")
+    public NullSafeAnnotationsFieldsTest build() {
+      try {
+        NullSafeAnnotationsFieldsTest record = new NullSafeAnnotationsFieldsTest();
+        record.name = fieldSetFlags()[0] ? this.name : (java.lang.String) defaultValue(fields()[0]);
+        record.nullable_name = fieldSetFlags()[1] ? this.nullable_name : (java.lang.String) defaultValue(fields()[1]);
+        record.favorite_number = fieldSetFlags()[2] ? this.favorite_number : (java.lang.Integer) defaultValue(fields()[2]);
+        record.nullable_favorite_number = fieldSetFlags()[3] ? this.nullable_favorite_number : (java.lang.Integer) defaultValue(fields()[3]);
+        return record;
+      } catch (org.apache.avro.AvroMissingFieldException e) {
+        throw e;
+      } catch (java.lang.Exception e) {
+        throw new org.apache.avro.AvroRuntimeException(e);
+      }
+    }
+  }
+
+  @SuppressWarnings(""unchecked"")
+  private static final org.apache.avro.io.DatumWriter<NullSafeAnnotationsFieldsTest>
+    WRITER$ = (org.apache.avro.io.DatumWriter<NullSafeAnnotationsFieldsTest>)MODEL$.createDatumWriter(SCHEMA$);
+
+  @Override public void writeExternal(java.io.ObjectOutput out)
+    throws java.io.IOException {
+    WRITER$.write(this, SpecificData.getEncoder(out));
+  }
+
+  @SuppressWarnings(""unchecked"")
+  private static final org.apache.avro.io.DatumReader<NullSafeAnnotationsFieldsTest>
+    READER$ = (org.apache.avro.io.DatumReader<NullSafeAnnotationsFieldsTest>)MODEL$.createDatumReader(SCHEMA$);
+
+  @Override public void readExternal(java.io.ObjectInput in)
+    throws java.io.IOException {
+    READER$.read(this, SpecificData.getDecoder(in));
+  }
+
+  @Override protected boolean hasCustomCoders() { return true; }
+
+  @Override public void customEncode(org.apache.avro.io.Encoder out)
+    throws java.io.IOException
+  {
+    out.writeString(this.name);
+
+    if (this.nullable_name == null) {
+      out.writeIndex(1);
+      out.writeNull();
+    } else {
+      out.writeIndex(0);
+      out.writeString(this.nullable_name);
+    }
+
+    out.writeInt(this.favorite_number);
+
+    if (this.nullable_favorite_number == null) {
+      out.writeIndex(1);
+      out.writeNull();
+    } else {
+      out.writeIndex(0);
+      out.writeInt(this.nullable_favorite_number);
+    }
+
+  }
+
+  @Override public void customDecode(org.apache.avro.io.ResolvingDecoder in)
+    throws java.io.IOException
+  {
+    org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();
+    if (fieldOrder == null) {
+      this.name = in.readString();
+
+      if (in.readIndex() != 0) {
+        in.readNull();
+        this.nullable_name = null;
+      } else {
+        this.nullable_name = in.readString();
+      }
+
+      this.favorite_number = in.readInt();
+
+      if (in.readIndex() != 0) {
+        in.readNull();
+        this.nullable_favorite_number = null;
+      } else {
+        this.nullable_favorite_number = in.readInt();
+      }
+
+    } else {
+      for (int i = 0; i < 4; i++) {
+        switch (fieldOrder[i].pos()) {
+        case 0:
+          this.name = in.readString();
+          break;
+
+        case 1:
+          if (in.readIndex() != 0) {
+            in.readNull();
+            this.nullable_name = null;
+          } else {
+            this.nullable_name = in.readString();
+          }
+          break;
+
+        case 2:
+          this.favorite_number = in.readInt();
+          break;
+
+        case 3:
+          if (in.readIndex() != 0) {
+            in.readNull();
+            this.nullable_favorite_number = null;
+          } else {
+            this.nullable_favorite_number = in.readInt();
+          }
+          break;
+
+        default:
+          throw new java.io.IOException(""Corrupt ResolvingDecoder."");
+        }
+      }
+    }
+  }
+}
+
+
+
+
+
+
+
+
+
+","[{'comment': 'Minor issue: we can to with less newlines here, can we?', 'commenter': 'opwvhk'}, {'comment': 'Removed the empty lines now. They are generated by Velocity but the result matches anyway.', 'commenter': 'peknu'}, {'comment': 'Some problem with the build status made me revert the change.', 'commenter': 'peknu'}]"
2142,lang/java/ipc/pom.xml,"@@ -168,6 +168,10 @@
       <groupId>org.apache.velocity</groupId>
       <artifactId>velocity-engine-core</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.jetbrains</groupId>
+      <artifactId>annotations</artifactId>
+    </dependency>","[{'comment': 'Is this dependency actually used here?', 'commenter': 'opwvhk'}]"
2142,lang/java/compiler/pom.xml,"@@ -232,6 +232,10 @@
       <groupId>com.fasterxml.jackson.core</groupId>
       <artifactId>jackson-databind</artifactId>
     </dependency>
+    <dependency>
+      <groupId>org.jetbrains</groupId>
+      <artifactId>annotations</artifactId>
+    </dependency>","[{'comment': 'I only see the dependency being used in the test code (which is perfect IMHO). Can we please reduce the scope to test?', 'commenter': 'opwvhk'}]"
2142,lang/java/compiler/src/main/velocity/org/apache/avro/compiler/specific/templates/java/classic/record.vm,"@@ -28,6 +28,9 @@ import org.apache.avro.message.BinaryMessageDecoder;
 import org.apache.avro.message.SchemaStore;
 #end
 #if (${this.gettersReturnOptional} || ${this.createOptionalGetters})import java.util.Optional;#end
+#if (${this.createNullSafeAnnotations})import org.jetbrains.annotations.Nullable;
+import org.jetbrains.annotations.NotNull;
+#end","[{'comment': 'Instead of an import, can we please use the same pattern as for other types?\r\n\r\nInstead of `String`, the code used `java.lang.String` as well, because this makes name clashes less likely.\r\n\r\nAdditionally, using explicit annotation classes allows us to make the annotations configurable.', 'commenter': 'opwvhk'}]"
2142,lang/java/maven-plugin/src/main/java/org/apache/avro/mojo/AbstractAvroMojo.java,"@@ -164,6 +164,15 @@ public abstract class AbstractAvroMojo extends AbstractMojo {
    */
   protected boolean createSetters;
 
+  /**
+   * The createNullSafeAnnotations parameters adds @Nullable and @NotNull
+   * annotations for fhe fields of the record. The default is to not include
+   * annotations.","[{'comment': ""Can we please mention here that the annotations are JetBrains annotations?\r\n\r\nThen it'll automatically be documented by the plugin help. Ideally, it also lists the dependency coordinates / package-url (`pkg:maven/org.jetbrains/annotations@24.0.1`)."", 'commenter': 'opwvhk'}, {'comment': 'At this point in time, there are no other places on the website that document the maven plugin, or code generation options. It\'s only mentioned in passing on the ""Getting started"" page for Java.', 'commenter': 'opwvhk'}]"
2161,lang/csharp/src/apache/test/IO/JsonCodecTests.cs,"@@ -285,6 +286,28 @@
             decoder.SkipArray();
         }
 
+        [Test]
+        public void TestJsonDecoderSpecificWithArray()
+        {
+            Root data = new Root();
+            Item item = new Item { id = 123456 };
+            data.myarray = new List<Item> { item };
+
+            DatumWriter<Root> writer = new SpecificDatumWriter<Root>(data.Schema);
+
+            ByteBufferOutputStream bbos = new ByteBufferOutputStream();
+
+            Encoder encoder = new JsonEncoder(data.Schema, bbos);
+            writer.Write(data, encoder);
+            encoder.Flush();
+
+            List<MemoryStream> listStreams = bbos.GetBufferList();
+
+            StreamReader reader = new StreamReader(listStreams[0]);","[{'comment': ""## Missing Dispose call on local IDisposable\n\nDisposable 'StreamReader' is created but not disposed.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/2980)"", 'commenter': 'github-advanced-security[bot]'}, {'comment': '@rayokota Should we fix this warning ?', 'commenter': 'martin-g'}, {'comment': 'Yes. I was looking at the PR on my hone and could not see it.', 'commenter': 'zcsizmadia'}, {'comment': 'Just needs `using` at the beginning of that line with the warning', 'commenter': 'zcsizmadia'}, {'comment': 'Thanks @martin-g , @zcsizmadia , I fixed the warning by adding a using clause.', 'commenter': 'rayokota'}]"
2282,lang/java/avro/src/main/java/org/apache/avro/Conversions.java,"@@ -146,6 +152,65 @@ private static BigDecimal validate(final LogicalTypes.Decimal decimal, BigDecima
     }
   }
 
+  public static class BigDecimalConversion extends Conversion<BigDecimal> {
+
+    @Override
+    public Class<BigDecimal> getConvertedType() {
+      return BigDecimal.class;
+    }
+
+    @Override
+    public String getLogicalTypeName() {
+      return ""bigdecimal"";","[{'comment': ""This name does not equals the one in the documentation and the tests. Can we please adjust so they're the same?"", 'commenter': 'opwvhk'}, {'comment': 'changed', 'commenter': 'clesaec'}]"
2282,doc/content/en/docs/++version++/Specification/_index.md,"@@ -810,6 +810,20 @@ Scale must be zero or a positive integer less than or equal to the precision.
 
 For the purposes of schema resolution, two schemas that are `decimal` logical types _match_ if their scales and precisions match.
 
+**alternative**
+
+As it's not always possible to fix scale and precision in advance for a decimal field, `big-decimal` is another `decimal` logical type restrict to Avro _bytes_.
+
+_only available in Java_
+
+```json
+{
+  ""type"": ""bytes"",
+  ""logicalType"": ""big-decimal""
+}
+```
+Here, as scale property is stored in value itself it needs more bytes than preceding `decimal` type, but it allows more flexibility.
+","[{'comment': 'No comments on the Java code, but I\'d like to see the specification clarified a bit.\r\n\r\n* Separate the ""big-decimal"" description under its own `### Decimal (variable scale)` heading, for these purposes:\r\n\r\n  + Gives it an ID in HTML so that it can be linked to.\r\n  + Makes it show up in the table of contents.\r\n  + Makes it clear that the schema-resolution matching rule of ""decimal"" does not apply.\r\n\r\n* Describe how the decimal value is encoded.  AFAICT, it goes like this:\r\n\r\n  > A `big-decimal` logical type annotates an Avro `bytes` type, which stores the [binary encoding](https://avro.apache.org/docs/1.11.1/specification/#binary-encoding) of the following record:\r\n  >\r\n  > ```JSON\r\n  > {\r\n  >     ""type"": ""record"",\r\n  >     ""name"": ""BigDecimal"",\r\n  >     ""doc"": ""Avro \'big-decimal\' value encoded within \'bytes\'"",\r\n  >     ""fields"": [\r\n  >         {\r\n  >             ""name"": ""unscaled"",\r\n  >             ""type"": ""bytes"",\r\n  >             ""doc"": ""The two’s-complement representation of the unscaled integer value in big-endian byte order""\r\n  >         },\r\n  >         {\r\n  >             ""name"": ""scale"",\r\n  >             ""type"": ""int"",\r\n  >             ""doc"": ""How many digits of the unscaled value lie at the right side of the decimal point.  Must not be negative.""\r\n  >         }\r\n  >     ]\r\n  > }\r\n\r\n  Or describe it in prose -- as long as the specification is clear enough that the logical type can be implemented without looking at how the Java code does it.\r\n', 'commenter': 'KalleOlaviNiemitalo'}]"
2334,lang/java/maven-plugin/src/main/java/org/apache/avro/mojo/AbstractAvroMojo.java,"@@ -213,7 +213,9 @@ public void execute() throws MojoExecutionException {
     if (hasImports) {
       for (String importedFile : imports) {
         File file = new File(importedFile);
-        if (file.isDirectory()) {
+        if (!file.exists()) {","[{'comment': 'Nice !!\r\nSame logic should apply to getIncludedFiles method, line 259 ?\r\n(or may be put this control in another method as ""checkImportFiles"", as it concerns only ""imports"" variables.', 'commenter': 'clesaec'}, {'comment': ""I was considering that, but it seems that if _imports_ field is non-null, then we may be sure that during the execution we will check every imported file in line 216. Indeed, even if _getIncludedFiles_ would execute first, the nonexistent file will be found by line 216 in a next iteration. Do you think it's beneficial to check it anyway in _getIncludedFiles_?"", 'commenter': 'dervan'}, {'comment': 'On line 256, getIncludedFiles method scan for all imports ...\r\n```\r\n      for (String importFile : this.imports) {\r\n        File file = new File(importFile);\r\n  ...\r\n```\r\nSo, if you have 2 files, and only the first exists, this second method will encountered this unexisting file before the ""execute()"" method. So, even if used method (isFile & isDirectory) won\'t fails, i found that checking before using cleaner.\r\n', 'commenter': 'clesaec'}, {'comment': 'Of course I understand that - I just pointed out that _getIncludedFiles_ touches this file earlier, but with no real downside. Anyway, I moved existence check to the separate method that checks everything in the first place - will that work for you?', 'commenter': 'dervan'}]"
2334,lang/java/maven-plugin/src/test/resources/unit/schema/pom-nonexistent-file.pom,"@@ -0,0 +1,69 @@
+<?xml version=""1.0"" encoding=""UTF-8""?>
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the ""License""); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       https://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an ""AS IS"" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+<project xmlns=""http://maven.apache.org/POM/4.0.0"" xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
+         xsi:schemaLocation=""http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"">
+  <modelVersion>4.0.0</modelVersion>
+
+  <parent>
+    <artifactId>avro-parent</artifactId>
+    <groupId>org.apache.avro</groupId>
+    <version>1.12.0-SNAPSHOT</version>
+    <relativePath>../../../../../../../../../pom.xml</relativePath>
+  </parent>
+
+  <artifactId>avro-maven-plugin-test</artifactId>
+  <packaging>jar</packaging>
+
+  <name>testproject</name>
+
+  <build>
+    <plugins>
+      <plugin>
+        <artifactId>avro-maven-plugin</artifactId>
+        <executions>
+          <execution>
+            <id>schema</id>
+            <goals>
+              <goal>schema</goal>
+            </goals>
+          </execution>
+        </executions>
+        <configuration>
+          <sourceDirectory>${basedir}/src/test/avro</sourceDirectory>
+          <outputDirectory>${basedir}/target/test-harness/schema</outputDirectory>
+          <imports>
+            <import>${basedir}/src/test/avro/nonexistent-dir</import>","[{'comment': 'Check also the case where first file exists (to check getIncludedFiles methods)', 'commenter': 'clesaec'}, {'comment': ""I've added another test for the case where first file exist and the second one doesn't."", 'commenter': 'dervan'}]"
2433,lang/rust/avro/src/schema.rs,"@@ -1440,7 +1440,12 @@ impl Parser {
                     .collect::<Result<_, _>>()
             })?;
 
+        let mut existing_fields: HashSet<&String> = HashSet::with_capacity(fields.len());
         for field in &fields {
+            if existing_fields.contains(&field.name) {
+                return Err(Error::FieldNameDuplicate(field.name.clone()));
+            }
+            existing_fields.insert(&field.name);","[{'comment': 'Do we need the new data structure ?\r\nWe can use the returned value of https://doc.rust-lang.org/std/collections/struct.BTreeMap.html#method.insert to decide whether to return an error or not.', 'commenter': 'martin-g'}, {'comment': ""Yes, we can use `lookup`. I've fixed."", 'commenter': 'sarutak'}]"
2433,lang/rust/avro/src/schema.rs,"@@ -1441,6 +1441,9 @@ impl Parser {
             })?;
 
         for field in &fields {
+            if lookup.contains_key(&field.name) {
+                return Err(Error::FieldNameDuplicate(field.name.clone()));
+            }
             lookup.insert(field.name.clone(), field.position);","[{'comment': 'I still think using the returned `Option` from `#insert()` is better than doing two lookups.\r\n```suggestion\r\n            if let Some(_old) = lookup.insert(field.name.clone(), field.position) {\r\n                      return Err(Error::FieldNameDuplicate(field.name.clone()));\r\n            }\r\n```', 'commenter': 'martin-g'}, {'comment': 'Ah, exactly.', 'commenter': 'sarutak'}, {'comment': ""I'll manually fix."", 'commenter': 'sarutak'}]"
2439,lang/csharp/src/apache/main/File/DeflateCodec.cs,"@@ -58,18 +58,19 @@ public override void Compress(MemoryStream inputStream, MemoryStream outputStrea
         /// <inheritdoc/>
         public override byte[] Decompress(byte[] compressedData, int length)
         {
-
-            MemoryStream inStream = new MemoryStream(compressedData);
-            MemoryStream outStream = new MemoryStream();
-
-            using (DeflateStream Decompress =
-                        new DeflateStream(inStream,
-                        CompressionMode.Decompress))
+            using (MemoryStream inStream = new MemoryStream(compressedData))
             {
-                CopyTo(Decompress, outStream);
+                using (MemoryStream outStream = new MemoryStream(inStream.Capacity))","[{'comment': ""Is `inStream.Capacity` worthwhile here?  It's the compressed size, and the uncompressed data that is written to `outStream` could be much larger.  I guess it won't hurt."", 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Personally I like to stack the using in the beginning in cases like this. e.g. https://github.com/apache/avro/blob/master/lang/csharp/src/apache/codec/Avro.File.BZip2/BZip2.cs#L78-L79\r\n\r\nAddistionaly use the MemoryStream constructor to limit the inSTream access only to length, mentioned by @KalleOlaviNiemitalo ', 'commenter': 'zcsizmadia'}]"
2439,lang/csharp/src/apache/main/File/DeflateCodec.cs,"@@ -58,18 +58,19 @@ public override void Compress(MemoryStream inputStream, MemoryStream outputStrea
         /// <inheritdoc/>
         public override byte[] Decompress(byte[] compressedData, int length)
         {
-
-            MemoryStream inStream = new MemoryStream(compressedData);
-            MemoryStream outStream = new MemoryStream();
-
-            using (DeflateStream Decompress =
-                        new DeflateStream(inStream,
-                        CompressionMode.Decompress))
+            using (MemoryStream inStream = new MemoryStream(compressedData))
             {
-                CopyTo(Decompress, outStream);
+                using (MemoryStream outStream = new MemoryStream(inStream.Capacity))
+                {
+                    using (DeflateStream decompress =
+                           new DeflateStream(inStream,
+                               CompressionMode.Decompress))
+                    {
+                        decompress.CopyTo(outStream, length);","[{'comment': '`length` seems to be the compressed size, not the uncompressed size, so it should not be used in this `CopyTo`.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'With this change, `private static void CopyTo(Stream from, Stream to)` is no longer used; please delete it then.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Instead, I think you could use the `MemoryStream(byte[] buffer, int index, int count)` constructor for `inStream`, to prevent the `DeflateStream` from reading more than `length` bytes of compressed data.', 'commenter': 'KalleOlaviNiemitalo'}]"
2439,lang/csharp/src/apache/test/File/FileTests.cs,"@@ -668,6 +668,55 @@ public void TestPartialReadAll([Values(specificSchema)] string schemaStr, [Value
             }
         }
 
+        [Test]
+        public void TestDeflateReadMemoryUsage([Values(specificSchema)] string schemaStr)
+        {
+            // create and write out
+            IList<Foo> records = MakeRecords(GetTestFooObject());
+
+            Process currentProcess = Process.GetCurrentProcess();
+
+            MemoryStream dataFileOutputStream = new MemoryStream();
+
+            Schema schema = Schema.Parse(schemaStr);
+            DatumWriter<Foo> writer = new SpecificWriter<Foo>(schema);
+            using (IFileWriter<Foo> dataFileWriter = DataFileWriter<Foo>.OpenWriter(writer, dataFileOutputStream, Codec.CreateCodec(Codec.Type.Deflate)))
+            {
+                for (int i = 0; i < 10; ++i)
+                {
+                    foreach (Foo foo in records)
+                    {
+                        dataFileWriter.Append(foo);
+                    }
+
+                    // write out block
+                    if (i == 1 || i == 4)
+                    {
+                        dataFileWriter.Sync();
+                    }
+                }
+            }
+
+            long startMemoryUsedBytes = currentProcess.WorkingSet64;
+
+            MemoryStream dataFileInputStream = new MemoryStream(dataFileOutputStream.ToArray());
+            dataFileInputStream.Position = 0;
+
+            // read back
+            IList<Foo> readRecords = new List<Foo>();
+            using (IFileReader<Foo> reader = DataFileReader<Foo>.OpenReader(dataFileInputStream, schema))
+            {
+                // read records from synced position
+                foreach (Foo rec in reader.NextEntries)
+                    readRecords.Add(rec);
+            }
+
+            long totalMemoryUsedBytes = currentProcess.WorkingSet64 - startMemoryUsedBytes;
+
+            Assert.IsTrue(totalMemoryUsedBytes  == 0, ""Total memory usage in working set"");","[{'comment': ""This test looks unreliable:\r\n\r\n* WorkingSet64 is the amount of physical memory reserved for the process.  If the process allocates some memory and doesn't use it afterwards, and the operating system pages it out, then it won't be included in WorkingSet64.\r\n* Process.WorkingSet64 updates only when you call Process.Refresh().\r\n* Can other tests be run in parallel with this one?  If they can, the memory allocated by them could cause this test to fail.\r\n* The test code between the `currentProcess.WorkingSet64` evaluations allocates new objects whose memory might not be garbage-collected and released to the OS soon enough.  The runtime can also allocate memory for JIT-compiled methods.\r\n\r\nThe test might become more reliable if it were changed to:\r\n\r\n* Run the decompression a few times before the measurement, to get to a stable state.\r\n* Measure AppDomain.MonitoringTotalAllocatedMemorySize or GC.GetAllocatedBytesForCurrentThread(), rather than Process.WorkingSet64.\r\n* Allow some amount of allocations but not too much.  This might require a larger data file, in order to distinguish the important allocations from noise."", 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Agreed with @KalleOlaviNiemitalo. This test is unreliable and IMO not needed.', 'commenter': 'zcsizmadia'}]"
2439,lang/csharp/src/apache/main/IO/BinaryDecoder.cs,"@@ -296,5 +296,8 @@ private void Skip(long p)
         {
             stream.Seek(p, SeekOrigin.Current);
         }
+
+        /// <inheritdoc />
+        public void Dispose() => stream?.Dispose();","[{'comment': 'This is a breaking change. This assumes, that the BinaryDecoder object takes ownership if the stream and once the BinaryDecoder is disposed, the stream is disposed as well and cannot be used any more. Most of the nurmal use cases the stream can be disposed here without any harm, however the calling code might need to keep trhe stream alive in special cases, e.g. there is still some additional data in the stream for other purposes.\r\n', 'commenter': 'zcsizmadia'}, {'comment': ""If the stream should be disposed when The BinaryDecoder is disposed, a new constructor with `bool ownStream` can be added, which marks the stream for disposal in the Decoder's Dispose. Similiarly what https://github.com/apache/avro/blob/master/lang/csharp/src/apache/main/File/DataFileReader.cs#L125-L137. Of course that feature is not really in the scope of this PR."", 'commenter': 'zcsizmadia'}]"
2439,lang/csharp/src/apache/main/IO/BinaryEncoder.cs,"@@ -228,5 +228,8 @@ public void Flush()
         {
             Stream.Flush();
         }
+
+        /// <inheritdoc />
+        public void Dispose() => Stream?.Dispose();","[{'comment': 'Same issue as BinaryDecoder.Dispose', 'commenter': 'zcsizmadia'}]"
2439,lang/csharp/src/apache/main/Specific/SpecificReader.cs,"@@ -130,20 +130,22 @@ protected override object ReadRecord(object reuse, RecordSchema writerSchema, Sc
                 }
             }
 
-            var defaultStream = new MemoryStream();","[{'comment': 'Similar code like this is in GenericReader and PreresolvingDatumReader. If SpecificReader fixes the MemoryStream leak, those others should be fixed as well.', 'commenter': 'zcsizmadia'}]"
2439,lang/csharp/src/apache/main/Specific/SpecificReader.cs,"@@ -130,20 +130,22 @@
                 }
             }
 
-            var defaultStream = new MemoryStream();
-            var defaultEncoder = new BinaryEncoder(defaultStream);
-            var defaultDecoder = new BinaryDecoder(defaultStream);
-            foreach (Field rf in rs)
+            using (var defaultStream = new MemoryStream())
             {
-                if (writerSchema.Contains(rf.Name)) continue;
+                var defaultEncoder = new BinaryEncoder(defaultStream);
+                var defaultDecoder = new BinaryDecoder(defaultStream);
+                foreach (Field rf in rs)
+                {
+                    if (writerSchema.Contains(rf.Name)) continue;
 
-                defaultStream.Position = 0; // reset for writing
-                Resolver.EncodeDefaultValue(defaultEncoder, rf.Schema, rf.DefaultValue);
-                defaultStream.Flush();
-                defaultStream.Position = 0; // reset for reading
+                    defaultStream.Position = 0; // reset for writing
+                    Resolver.EncodeDefaultValue(defaultEncoder, rf.Schema, rf.DefaultValue);
+                    defaultStream.Flush();
+                    defaultStream.Position = 0; // reset for reading
 
-                obj = rec.Get(rf.Pos);
-                rec.Put(rf.Pos, Read(obj, rf.Schema, rf.Schema, defaultDecoder));
+                    obj = rec.Get(rf.Pos);","[{'comment': '## Dereferenced variable may be null\n\nVariable [rec](1) may be null at this access because of [this](2) assignment.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3104)', 'commenter': 'github-advanced-security[bot]'}]"
2439,lang/csharp/src/apache/main/Specific/SpecificReader.cs,"@@ -130,20 +130,22 @@
                 }
             }
 
-            var defaultStream = new MemoryStream();
-            var defaultEncoder = new BinaryEncoder(defaultStream);
-            var defaultDecoder = new BinaryDecoder(defaultStream);
-            foreach (Field rf in rs)
+            using (var defaultStream = new MemoryStream())
             {
-                if (writerSchema.Contains(rf.Name)) continue;
+                var defaultEncoder = new BinaryEncoder(defaultStream);
+                var defaultDecoder = new BinaryDecoder(defaultStream);
+                foreach (Field rf in rs)
+                {
+                    if (writerSchema.Contains(rf.Name)) continue;
 
-                defaultStream.Position = 0; // reset for writing
-                Resolver.EncodeDefaultValue(defaultEncoder, rf.Schema, rf.DefaultValue);
-                defaultStream.Flush();
-                defaultStream.Position = 0; // reset for reading
+                    defaultStream.Position = 0; // reset for writing
+                    Resolver.EncodeDefaultValue(defaultEncoder, rf.Schema, rf.DefaultValue);
+                    defaultStream.Flush();
+                    defaultStream.Position = 0; // reset for reading
 
-                obj = rec.Get(rf.Pos);
-                rec.Put(rf.Pos, Read(obj, rf.Schema, rf.Schema, defaultDecoder));
+                    obj = rec.Get(rf.Pos);
+                    rec.Put(rf.Pos, Read(obj, rf.Schema, rf.Schema, defaultDecoder));
+                }","[{'comment': ""## Missed opportunity to use Where\n\nThis foreach loop [implicitly filters its target sequence](1) - consider filtering the sequence explicitly using '.Where(...)'.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3105)"", 'commenter': 'github-advanced-security[bot]'}]"
2439,lang/csharp/src/apache/test/File/FileTests.cs,"@@ -668,6 +668,55 @@
             }
         }
 
+        [Test]
+        public void TestDeflateReadMemoryUsage([Values(specificSchema)] string schemaStr)
+        {
+            // create and write out
+            IList<Foo> records = MakeRecords(GetTestFooObject());
+
+            Process currentProcess = Process.GetCurrentProcess();
+
+            MemoryStream dataFileOutputStream = new MemoryStream();
+
+            Schema schema = Schema.Parse(schemaStr);
+            DatumWriter<Foo> writer = new SpecificWriter<Foo>(schema);
+            using (IFileWriter<Foo> dataFileWriter = DataFileWriter<Foo>.OpenWriter(writer, dataFileOutputStream, Codec.CreateCodec(Codec.Type.Deflate)))
+            {
+                for (int i = 0; i < 10; ++i)
+                {
+                    foreach (Foo foo in records)
+                    {
+                        dataFileWriter.Append(foo);
+                    }
+
+                    // write out block
+                    if (i == 1 || i == 4)
+                    {
+                        dataFileWriter.Sync();
+                    }
+                }
+            }
+
+            long startMemoryUsedBytes = currentProcess.WorkingSet64;
+
+            MemoryStream dataFileInputStream = new MemoryStream(dataFileOutputStream.ToArray());
+            dataFileInputStream.Position = 0;
+
+            // read back
+            IList<Foo> readRecords = new List<Foo>();","[{'comment': '## Container contents are never accessed\n\nThe contents of this container are never accessed.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3107)', 'commenter': 'github-advanced-security[bot]'}]"
2439,lang/csharp/src/apache/main/IO/BinaryDecoder.cs,"@@ -26,14 +26,25 @@ namespace Avro.IO
     public partial class BinaryDecoder : Decoder, IDisposable
     {
         private readonly Stream stream;
+        private readonly bool ownStream;
 
         /// <summary>
         /// Initializes a new instance of the <see cref=""BinaryDecoder""/> class.
         /// </summary>
         /// <param name=""stream"">Stream to decode.</param>
-        public BinaryDecoder(Stream stream)
+        public BinaryDecoder(Stream stream) : this(stream, false)
+        {
+        }
+
+        /// <summary>
+        /// Initializes a new instance of the <see cref=""BinaryDecoder""/> class.
+        /// </summary>
+        /// <param name=""stream"">Stream to decode.</param>
+        /// <param name=""ownStream"">Leave stream open after disposing the object.</param>","[{'comment': 'For me the ownStream name indicates that this object (BinaryDecoder) will now takes ownership of the stream. So ownStream means ""Stream is disposed when this object is disposed"".', 'commenter': 'zcsizmadia'}, {'comment': 'The [StreamReader constructor](https://learn.microsoft.com/dotnet/api/system.io.streamreader.-ctor?view=netstandard-2.0#system-io-streamreader-ctor(system-io-stream-system-text-encoding-system-boolean-system-int32-system-boolean)) has a `bool leaveOpen` parameter for a similar purpose.  The default value is `false`.\r\n\r\nThe [HttpClient constructor](https://learn.microsoft.com/dotnet/api/system.net.http.httpclient.-ctor?view=netstandard-2.0#system-net-http-httpclient-ctor(system-net-http-httpmessagehandler-system-boolean)) instead has a `bool disposeHandler` parameter.  The default value is `true`.\r\n\r\nTo preserve compatibility with earlier Avro versions while being easy to understand, I think this should be `bool disposeStream` and default to `false`.  The caller tells BinaryDecoder whether BinaryDecoder should dispose the stream.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'Alternatively, it could be `bool leaveOpen` and default to `true`; but I feel `false` is generally nicer than `true` as a default value of a `bool` parameter.', 'commenter': 'KalleOlaviNiemitalo'}, {'comment': 'This makes a lot of sense. Will change the descriptions and Dispose logic of the encoder and decoder', 'commenter': 'CamilAbraham'}]"
2439,lang/csharp/src/apache/main/IO/BinaryDecoder.cs,"@@ -298,6 +309,10 @@ private void Skip(long p)
         }
 
         /// <inheritdoc />
-        public void Dispose() => stream?.Dispose();
+        public void Dispose()
+        {
+            if(!ownStream)","[{'comment': 'This condition IMO should be `if (ownStream) { stream?.Dispose(); }`', 'commenter': 'zcsizmadia'}, {'comment': 'Since the ownStream = false in the default constructor, the stream would be disposed using the default constructor, which would make it a breaking change.', 'commenter': 'zcsizmadia'}]"
2439,lang/csharp/src/apache/main/Generic/GenericReader.cs,"@@ -290,21 +290,23 @@
                 }
             }
 
-            var defaultStream = new MemoryStream();
-            var defaultEncoder = new BinaryEncoder(defaultStream);
-            var defaultDecoder = new BinaryDecoder(defaultStream);
-            foreach (Field rf in rs)
+            using (var defaultStream = new MemoryStream())
             {
-                if (writerSchema.Contains(rf.Name)) continue;
+                var defaultEncoder = new BinaryEncoder(defaultStream);
+                var defaultDecoder = new BinaryDecoder(defaultStream);
+                foreach (Field rf in rs)
+                {
+                    if (writerSchema.Contains(rf.Name)) continue;
 
-                defaultStream.Position = 0; // reset for writing
-                Resolver.EncodeDefaultValue(defaultEncoder, rf.Schema, rf.DefaultValue);
-                defaultStream.Flush();
-                defaultStream.Position = 0; // reset for reading
+                    defaultStream.Position = 0; // reset for writing
+                    Resolver.EncodeDefaultValue(defaultEncoder, rf.Schema, rf.DefaultValue);
+                    defaultStream.Flush();
+                    defaultStream.Position = 0; // reset for reading
 
-                object obj = null;
-                TryGetField(rec, rf.Name, rf.Pos, out obj);
-                AddField(rec, rf.Name, rf.Pos, Read(obj, rf.Schema, rf.Schema, defaultDecoder));
+                    object obj = null;
+                    TryGetField(rec, rf.Name, rf.Pos, out obj);
+                    AddField(rec, rf.Name, rf.Pos, Read(obj, rf.Schema, rf.Schema, defaultDecoder));
+                }","[{'comment': ""## Missed opportunity to use Where\n\nThis foreach loop [implicitly filters its target sequence](1) - consider filtering the sequence explicitly using '.Where(...)'.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3115)"", 'commenter': 'github-advanced-security[bot]'}]"
2439,lang/csharp/src/apache/main/Generic/GenericReader.cs,"@@ -297,8 +297,6 @@ protected virtual object ReadRecord(object reuse, RecordSchema writerSchema, Sch
                 var defaultDecoder = new BinaryDecoder(defaultStream);
                 foreach (Field rf in rs.Fields.Where(rf => !writerSchema.Contains(rf.Name)))","[{'comment': 'CodeQL warnings like this, I ussuallyh just ignore, since it is really not a concern in a legacy code like avro. However thanks for getting rid of it ;)', 'commenter': 'zcsizmadia'}, {'comment': 'I expect this change makes the code slower, as it now has to allocate a closure and a delegate, and the calls become indirect too.  Roslyn contribution guidelines advise ""Avoid LINQ"" for that reason.  So I\'d prefer reverting this and disabling the CodeQL warning.\r\n\r\n* <https://github.com/dotnet/roslyn/blob/34268d1bb9370c7b01c742303a895a99daf10d6a/CONTRIBUTING.md?plain=1#L83>\r\n* <https://stackoverflow.com/questions/22894877/avoid-allocations-in-compiler-hot-paths-roslyn-coding-conventions>', 'commenter': 'KalleOlaviNiemitalo'}]"
2439,lang/csharp/src/apache/main/File/DeflateCodec.cs,"@@ -58,32 +58,14 @@ public override void Compress(MemoryStream inputStream, MemoryStream outputStrea
         /// <inheritdoc/>
         public override byte[] Decompress(byte[] compressedData, int length)
         {
-
-            MemoryStream inStream = new MemoryStream(compressedData);
-            MemoryStream outStream = new MemoryStream();
-
-            using (DeflateStream Decompress =
-                        new DeflateStream(inStream,
-                        CompressionMode.Decompress))
-            {
-                CopyTo(Decompress, outStream);
-            }
-
-            return outStream.ToArray();
-        }
-
-        /// <summary>
-        /// Copies to stream.
-        /// </summary>
-        /// <param name=""from"">stream you are copying from</param>
-        /// <param name=""to"">stream you are copying to</param>
-        private static void CopyTo(Stream from, Stream to)
-        {
-            byte[] buffer = new byte[4096];
-            int read;
-            while ((read = from.Read(buffer, 0, buffer.Length)) != 0)
+            using (MemoryStream inStream = new MemoryStream(compressedData, 0, length))","[{'comment': ""Could make `MemoryStream inStream` read-only by [constructing it](https://learn.microsoft.com/dotnet/api/system.io.memorystream.-ctor#system-io-memorystream-ctor(system-byte()-system-int32-system-int32-system-boolean)) with `writable: false` (the default is `true`).  Not important though, as DeflateStream with CompressionMode.Decompress won't try to write to it anyway."", 'commenter': 'KalleOlaviNiemitalo'}]"
2445,lang/java/tools/src/test/java/org/apache/avro/tool/TestRpcProtocolTool.java,"@@ -86,8 +60,10 @@
 
     p2.flush();
 
-    assertEquals(""Expected the simple.avpr protocol to be echoed to standout"", simpleProtocol,
-        Protocol.parse(baos2.toString(""UTF-8"")));
+    Assertions.assertEquals(simpleProtocol, Protocol.parse(baos2.toString(""UTF-8"")),
+        ""Expected the simple.avpr protocol to be echoed to standout"");
 
+    if (receive != null)","[{'comment': '## Useless null check\n\nThis check is useless. [receive](1) cannot be null at this check, since [new RpcReceiveTool(...)](2) always is non-null.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3108)', 'commenter': 'github-advanced-security[bot]'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/file/TestAllCodecs.java,"@@ -18,68 +18,53 @@
 
 package org.apache.avro.file;
 
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.Arguments;
+import org.junit.jupiter.params.provider.MethodSource;
 
 import java.io.IOException;
 import java.nio.ByteBuffer;
-import java.util.Arrays;
-import java.util.Collection;
+import java.util.stream.Stream;
 
-import static org.junit.Assert.assertTrue;
-
-@RunWith(Parameterized.class)
 public class TestAllCodecs {
 
-  @Parameterized.Parameters(name = ""{index}: codec={0}"")
-  public static Collection<Object[]> data() {
-    return Arrays.asList(new Object[][] { { ""bzip2"", BZip2Codec.class }, { ""zstandard"", ZstandardCodec.class },
-        { ""null"", NullCodec.class }, { ""xz"", XZCodec.class }, { ""snappy"", SnappyCodec.class },
-        { ""deflate"", DeflateCodec.class }, });
-  }
-
-  @Parameterized.Parameter(0)
-  public String codec;
-
-  @Parameterized.Parameter(1)
-  public Class<? extends Codec> codecClass;
-
-  @Test
-  public void testCodec() throws IOException {
+  @ParameterizedTest
+  @MethodSource(""codecTypes"")
+  void codec(String codec, Class<? extends Codec> codecClass) throws IOException {
     int inputSize = 500_000;
 
     byte[] input = generateTestData(inputSize);
 
     Codec codecInstance = CodecFactory.fromString(codec).createInstance();
-    assertTrue(codecClass.isInstance(codecInstance));
-    assertTrue(codecInstance.getName().equals(codec));
+    Assertions.assertTrue(codecClass.isInstance(codecInstance));
+    Assertions.assertTrue(codecInstance.getName().equals(codec));
 
     ByteBuffer inputByteBuffer = ByteBuffer.wrap(input);
     ByteBuffer compressedBuffer = codecInstance.compress(inputByteBuffer);
 
     int compressedSize = compressedBuffer.remaining();
 
     // Make sure something returned
-    assertTrue(compressedSize > 0);
+    Assertions.assertTrue(compressedSize > 0);
 
     // While the compressed size could in many real cases
     // *increase* compared to the input size, our input data
     // is extremely easy to compress and all Avro's compression algorithms
     // should have a compression ratio greater than 1 (except 'null').
-    assertTrue(compressedSize < inputSize || codec.equals(""null""));
+    Assertions.assertTrue(compressedSize < inputSize || codec.equals(""null""));
 
     // Decompress the data
     ByteBuffer decompressedBuffer = codecInstance.decompress(compressedBuffer);
 
     // Validate the the input and output are equal.
     inputByteBuffer.rewind();
-    Assert.assertEquals(decompressedBuffer, inputByteBuffer);
+    Assertions.assertEquals(inputByteBuffer, decompressedBuffer);
   }
 
-  @Test
-  public void testCodecSlice() throws IOException {
+  @ParameterizedTest
+  @MethodSource(""codecTypes"")
+  void codecSlice(String codec, Class<? extends Codec> codecClass) throws IOException {","[{'comment': ""## Useless parameter\n\nThe parameter 'codecClass' is never used.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3109)"", 'commenter': 'github-advanced-security[bot]'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java,"@@ -17,47 +17,33 @@
  */
 package org.apache.avro.io;
 
+import org.apache.avro.Schema;
+import org.apache.avro.io.TestValidatingIO.Encoding;
+
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.Arguments;
+import org.junit.jupiter.params.provider.MethodSource;
+
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.Arrays;
-import java.util.Collection;
+import java.util.stream.Stream;
 
-import org.apache.avro.Schema;
-import org.apache.avro.io.TestValidatingIO.Encoding;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-
-@RunWith(Parameterized.class)
 public class TestResolvingIO {
 
-  protected final Encoding eEnc;
-  protected final int iSkipL;
-  protected final String sJsWrtSchm;
-  protected final String sWrtCls;
-  protected final String sJsRdrSchm;
-  protected final String sRdrCls;
-
-  public TestResolvingIO(Encoding encoding, int skipLevel, String jsonWriterSchema, String writerCalls,
-      String jsonReaderSchema, String readerCalls) {
-    this.eEnc = encoding;
-    this.iSkipL = skipLevel;
-    this.sJsWrtSchm = jsonWriterSchema;
-    this.sWrtCls = writerCalls;
-    this.sJsRdrSchm = jsonReaderSchema;
-    this.sRdrCls = readerCalls;
-  }
-
-  @Test
-  public void testIdentical() throws IOException {
+  @ParameterizedTest
+  @MethodSource(""data2"")
+  public void testIdentical(Encoding eEnc, int iSkipL, String sJsWrtSchm, String sWrtCls, String sJsRdrSchm,","[{'comment': ""## Useless parameter\n\nThe parameter 'sJsRdrSchm' is never used.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3110)"", 'commenter': 'github-advanced-security[bot]'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java,"@@ -17,47 +17,33 @@
  */
 package org.apache.avro.io;
 
+import org.apache.avro.Schema;
+import org.apache.avro.io.TestValidatingIO.Encoding;
+
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.Arguments;
+import org.junit.jupiter.params.provider.MethodSource;
+
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.Arrays;
-import java.util.Collection;
+import java.util.stream.Stream;
 
-import org.apache.avro.Schema;
-import org.apache.avro.io.TestValidatingIO.Encoding;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-
-@RunWith(Parameterized.class)
 public class TestResolvingIO {
 
-  protected final Encoding eEnc;
-  protected final int iSkipL;
-  protected final String sJsWrtSchm;
-  protected final String sWrtCls;
-  protected final String sJsRdrSchm;
-  protected final String sRdrCls;
-
-  public TestResolvingIO(Encoding encoding, int skipLevel, String jsonWriterSchema, String writerCalls,
-      String jsonReaderSchema, String readerCalls) {
-    this.eEnc = encoding;
-    this.iSkipL = skipLevel;
-    this.sJsWrtSchm = jsonWriterSchema;
-    this.sWrtCls = writerCalls;
-    this.sJsRdrSchm = jsonReaderSchema;
-    this.sRdrCls = readerCalls;
-  }
-
-  @Test
-  public void testIdentical() throws IOException {
+  @ParameterizedTest
+  @MethodSource(""data2"")
+  public void testIdentical(Encoding eEnc, int iSkipL, String sJsWrtSchm, String sWrtCls, String sJsRdrSchm,
+      String sRdrCls) throws IOException {","[{'comment': ""## Useless parameter\n\nThe parameter 'sRdrCls' is never used.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3111)"", 'commenter': 'github-advanced-security[bot]'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/io/TestBlockingIO2.java,"@@ -99,6 +89,6 @@ public static Collection<Object[]> data() {
 
         { 100, 1, ""{c1sK5e10}"" }, { 100, 1, ""{c1sK5U1S10}"" }, { 100, 1, ""{c1sK5f10S10}"" }, { 100, 1, ""{c1sK5NS10}"" },
         { 100, 1, ""{c1sK5BS10}"" }, { 100, 1, ""{c1sK5IS10}"" }, { 100, 1, ""{c1sK5LS10}"" }, { 100, 1, ""{c1sK5FS10}"" },
-        { 100, 1, ""{c1sK5DS10}"" }, });
+        { 100, 1, ""{c1sK5DS10}"" }, }).map(Arguments::of);","[{'comment': ""You're using a different strategy here than above. Both are good, but I usually prefer just one. Let's keep this however, given the number of lines that would change otherwise."", 'commenter': 'opwvhk'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/io/TestValidatingIO.java,"@@ -507,29 +496,27 @@ private static int skip(String msg, InputScanner cs, Decoder vi, boolean isArray
     throw new RuntimeException(""Don't know how to skip"");
   }
 
-  @Parameterized.Parameters
-  public static Collection<Object[]> data() {
-    return Arrays.asList(convertTo2dArray(encodings, skipLevels, testSchemas()));
+  public static Stream<Arguments> data() {
+    return convertTo2dArray(encodings, skipLevels, testSchemas());
   }
 
   private static Object[][] encodings = new Object[][] { { Encoding.BINARY }, { Encoding.BLOCKING_BINARY },
       { Encoding.JSON } };
 
   private static Object[][] skipLevels = new Object[][] { { -1 }, { 0 }, { 1 }, { 2 }, };
 
-  public static Object[][] convertTo2dArray(final Object[][]... values) {
-    ArrayList<Object[]> ret = new ArrayList<>();
+  public static Stream<Arguments> convertTo2dArray(final Object[][]... values) {","[{'comment': ""Please rename (this method no longer creates an array), and remove the commented code (it's there in git, on the off chance anyone would want to look)."", 'commenter': 'opwvhk'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/specific/TestSpecificRecordWithUnion.java,"@@ -29,7 +29,8 @@
 import org.apache.avro.io.DatumWriter;
 import org.apache.avro.io.BinaryEncoder;
 import org.apache.avro.io.Decoder;
-import org.junit.Test;
+
+import org.junit.jupiter.api.Test;","[{'comment': 'Usually, you also rename the test methods (and remove the `public` keyword). Why not here?', 'commenter': 'opwvhk'}]"
2445,lang/java/trevni/core/src/test/java/org/apache/trevni/TestColumnFile.java,"@@ -19,140 +19,137 @@
 
 import java.io.File;
 import java.util.Random;
-import java.util.Collection;
 import java.util.Arrays;
 import java.util.Iterator;
 import java.util.Map;
 import java.util.HashMap;
+import java.util.stream.Stream;
 
-import org.junit.Assert;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
+import org.junit.jupiter.api.Assertions;
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.Arguments;
+import org.junit.jupiter.params.provider.MethodSource;
 import org.junit.runners.Parameterized.Parameters;
 
-@RunWith(value = Parameterized.class)
 public class TestColumnFile {
 
   private static final File FILE = new File(""target"", ""test.trv"");
   private static final int COUNT = 1024 * 64;
 
-  private String codec;
-  private String checksum;
-
-  public TestColumnFile(String codec, String checksum) {
-    this.codec = codec;
-    this.checksum = checksum;
-  }
-
   @Parameters
-  public static Collection<Object[]> codecs() {
-    Object[][] data = new Object[][] { { ""null"", ""null"" }, { ""snappy"", ""crc32"" }, { ""deflate"", ""crc32"" } };
-    return Arrays.asList(data);
+  public static Stream<Arguments> codecs() {
+    return Stream.of(Arguments.of(createFileMeta(""null"", ""null"")), Arguments.of(createFileMeta(""snappy"", ""crc32"")),
+        Arguments.of(createFileMeta(""deflate"", ""crc32"")));
   }
 
-  private ColumnFileMetaData createFileMeta() {
+  private static ColumnFileMetaData createFileMeta(String codec, String checksum) {
     return new ColumnFileMetaData().setCodec(codec).setChecksum(checksum);
   }
 
-  @Test
-  public void testEmptyFile() throws Exception {
+  @ParameterizedTest
+  @MethodSource(""codecs"")
+  void emptyFile(ColumnFileMetaData fileMeta) throws Exception {
     FILE.delete();
-    ColumnFileWriter out = new ColumnFileWriter(createFileMeta());
+    ColumnFileWriter out = new ColumnFileWriter(fileMeta);
     out.writeTo(FILE);
     ColumnFileReader in = new ColumnFileReader(FILE);
-    Assert.assertEquals(0, in.getRowCount());
-    Assert.assertEquals(0, in.getColumnCount());
+    Assertions.assertEquals(0, in.getRowCount());
+    Assertions.assertEquals(0, in.getColumnCount());
     in.close();
   }
 
-  @Test
-  public void testEmptyColumn() throws Exception {
+  @ParameterizedTest
+  @MethodSource(""codecs"")
+  void emptyColumn(ColumnFileMetaData fileMeta) throws Exception {
     FILE.delete();
-    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData(""test"", ValueType.INT));
+    ColumnFileWriter out = new ColumnFileWriter(fileMeta, new ColumnMetaData(""test"", ValueType.INT));
     out.writeTo(FILE);
     ColumnFileReader in = new ColumnFileReader(FILE);
-    Assert.assertEquals(0, in.getRowCount());
-    Assert.assertEquals(1, in.getColumnCount());
+    Assertions.assertEquals(0, in.getRowCount());
+    Assertions.assertEquals(1, in.getColumnCount());
     ColumnValues<Integer> values = in.getValues(""test"");
     for (int i : values)
       throw new Exception(""no value should be found"");
     in.close();
   }
 
-  @Test
-  public void testInts() throws Exception {
+  @ParameterizedTest
+  @MethodSource(""codecs"")
+  void ints(ColumnFileMetaData fileMeta) throws Exception {
     FILE.delete();
 
-    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData(""test"", ValueType.INT));
+    ColumnFileWriter out = new ColumnFileWriter(fileMeta, new ColumnMetaData(""test"", ValueType.INT));
     Random random = TestUtil.createRandom();
     for (int i = 0; i < COUNT; i++)
       out.writeRow(TestUtil.randomLength(random));
     out.writeTo(FILE);
 
     random = TestUtil.createRandom();
     ColumnFileReader in = new ColumnFileReader(FILE);
-    Assert.assertEquals(COUNT, in.getRowCount());
-    Assert.assertEquals(1, in.getColumnCount());
+    Assertions.assertEquals(COUNT, in.getRowCount());
+    Assertions.assertEquals(1, in.getColumnCount());
     Iterator<Integer> i = in.getValues(""test"");
     int count = 0;
     while (i.hasNext()) {
-      Assert.assertEquals(TestUtil.randomLength(random), (int) i.next());
+      Assertions.assertEquals(TestUtil.randomLength(random), (int) i.next());
       count++;
     }
-    Assert.assertEquals(COUNT, count);
+    Assertions.assertEquals(COUNT, count);
   }
 
-  @Test
-  public void testLongs() throws Exception {
+  @ParameterizedTest
+  @MethodSource(""codecs"")
+  void longs(ColumnFileMetaData fileMeta) throws Exception {
     FILE.delete();
 
-    ColumnFileWriter out = new ColumnFileWriter(createFileMeta(), new ColumnMetaData(""test"", ValueType.LONG));
+    ColumnFileWriter out = new ColumnFileWriter(fileMeta, new ColumnMetaData(""test"", ValueType.LONG));
     Random random = TestUtil.createRandom();
     for (int i = 0; i < COUNT; i++)
       out.writeRow(random.nextLong());
     out.writeTo(FILE);
 
     random = TestUtil.createRandom();
     ColumnFileReader in = new ColumnFileReader(FILE);
-    Assert.assertEquals(COUNT, in.getRowCount());
-    Assert.assertEquals(1, in.getColumnCount());
+    Assertions.assertEquals(COUNT, in.getRowCount());
+    Assertions.assertEquals(1, in.getColumnCount());
     Iterator<Long> i = in.getValues(""test"");
     int count = 0;
     while (i.hasNext()) {
-      Assert.assertEquals(random.nextLong(), (long) i.next());
+      Assertions.assertEquals(random.nextLong(), (long) i.next());
       count++;
     }
-    Assert.assertEquals(COUNT, count);
+    Assertions.assertEquals(COUNT, count);
   }
 
-  @Test
-  public void testStrings() throws Exception {
+  @ParameterizedTest
+  @MethodSource(""codecs"")
+  void strings(ColumnFileMetaData fileMeta) throws Exception {","[{'comment': 'Nice!', 'commenter': 'opwvhk'}]"
2445,lang/java/avro/src/test/java/org/apache/avro/io/TestResolvingIO.java,"@@ -17,48 +17,34 @@
  */
 package org.apache.avro.io;
 
+import org.apache.avro.Schema;
+import org.apache.avro.io.TestValidatingIO.Encoding;
+
+import org.junit.jupiter.params.ParameterizedTest;
+import org.junit.jupiter.params.provider.Arguments;
+import org.junit.jupiter.params.provider.MethodSource;
+
 import java.io.ByteArrayInputStream;
 import java.io.IOException;
 import java.io.InputStream;
-import java.util.Arrays;
-import java.util.Collection;
+import java.util.stream.Stream;
 
-import org.apache.avro.Schema;
-import org.apache.avro.io.TestValidatingIO.Encoding;
-import org.junit.Test;
-import org.junit.runner.RunWith;
-import org.junit.runners.Parameterized;
-
-@RunWith(Parameterized.class)
 public class TestResolvingIO {
 
-  protected final Encoding eEnc;
-  protected final int iSkipL;
-  protected final String sJsWrtSchm;
-  protected final String sWrtCls;
-  protected final String sJsRdrSchm;
-  protected final String sRdrCls;
-
-  public TestResolvingIO(Encoding encoding, int skipLevel, String jsonWriterSchema, String writerCalls,
-      String jsonReaderSchema, String readerCalls) {
-    this.eEnc = encoding;
-    this.iSkipL = skipLevel;
-    this.sJsWrtSchm = jsonWriterSchema;
-    this.sWrtCls = writerCalls;
-    this.sJsRdrSchm = jsonReaderSchema;
-    this.sRdrCls = readerCalls;
-  }
-
-  @Test
-  public void testIdentical() throws IOException {
-    performTest(eEnc, iSkipL, sJsWrtSchm, sWrtCls, sJsWrtSchm, sWrtCls);
+  @ParameterizedTest
+  @MethodSource(""data2"")
+  public void testIdentical(Encoding encoding, int skip, String jsonWriterSchema, String writerCalls,
+      String jsonReaderSchema, String readerCalls) throws IOException {","[{'comment': ""## Useless parameter\n\nThe parameter 'jsonReaderSchema' is never used.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3113)"", 'commenter': 'github-advanced-security[bot]'}, {'comment': ""## Useless parameter\n\nThe parameter 'readerCalls' is never used.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3114)"", 'commenter': 'github-advanced-security[bot]'}]"
2506,lang/java/avro/src/test/java/org/apache/avro/io/TestEncoders.java,"@@ -262,6 +262,7 @@ void arrayBackedByteBuffer() throws IOException {
   @Test
   void mappedByteBuffer() throws IOException {
     Path file = Paths.get(DIR.getPath() + ""testMappedByteBuffer.avro"");
+    file.toFile().deleteOnExit();","[{'comment': '```suggestion\r\n    Path file = DIR.toPath().resolve( ""testMappedByteBuffer.avro"");\r\n```\r\nFor example: here we have a `@TempDir` already present, and cleaned up automatically in the test case -- we just accidentally forgot the path separator so the file was _outside_! ', 'commenter': 'RyanSkraba'}, {'comment': ""Ah, O.K. I'll try it."", 'commenter': 'sarutak'}]"
2506,lang/java/avro/src/test/java/org/apache/avro/TestDataFileReader.java,"@@ -38,9 +38,12 @@
 import org.apache.avro.generic.GenericDatumReader;
 import org.apache.avro.generic.GenericDatumWriter;
 import org.junit.jupiter.api.Test;
+import org.junit.jupiter.api.io.TempDir;
 
 @SuppressWarnings(""restriction"")
 public class TestDataFileReader {
+  @TempDir
+  public Path DATA_DIR;","[{'comment': 'Can we relook at the variable name once please? This format used is for constants, giving an impression that it is static final. Same for similar name in other classes', 'commenter': 'paliwalashish'}]"
2517,.github/workflows/test-lang-rust-ci.yml,"@@ -58,20 +58,59 @@ jobs:
       - name: Checkout
         uses: actions/checkout@v4
 
-      - name: Cache Cargo
+      - name: Cache Cargo for 1.65.0
+        if: matrix.rust == '1.65.0' && matrix.target == 'x86_64-unknown-linux-gnu'
         uses: actions/cache@v3
         with:
           # these represent dependencies downloaded by cargo
           # and thus do not depend on the OS, arch nor rust version.
           path: ~/.cargo
-          key: cargo-cache1-
+          key: cargo-cache1-1.65.0-${{ hashFiles('**/Cargo.lock') }}
+
+      - name: Cache Cargo for 1.65.0 (Restore Only)
+        if: matrix.rust == '1.65.0' && matrix.target != 'x86_64-unknown-linux-gnu'
+        uses: actions/cache/restore@v3","[{'comment': 'This looks weird. \r\n` actions/cache@v3` does two things - first it restores the cache and later in the post-processing saves the cache.\r\nNow you introduce the new `actions/cache/restore@v3` which gives you more control when to `restore` but it should be used with `actions/cache/save@v3` to have a better control **when** to `save`.\r\nUsing both `actions/cache` with any of the new more granular actions does not make sense to me.\r\n', 'commenter': 'martin-g'}, {'comment': ""Having only `restore` for some cache is intended.\r\nFor `lang/rust/target`, if a target is `wasm32-unknown-unknown`, cargo test doesn't run. So if `wasm32-unknown-unknown` finishes earlier than `x86_64-unknown-linux-gnu`, the dependencies built for tests will not be cached right?\r\n\r\nFor `~/.cargo`, it might not be necessary to separate by conditions.\r\nBut, at least `web-assembly` job should be configured `restore` only.\r\n\r\nSee https://github.com/apache/avro/actions/runs/6277247580/job/17048597779#step:7:12\r\nAll the jobs download dependencies except for `web-assembly` job.\r\nI guess this means `~/.cargo` of `web-assembly` was cached because `web-assembly` job finished first but `~/.cargo` of `web-assembly` doesn't contain all the necessary dependencies for other jobs."", 'commenter': 'sarutak'}, {'comment': ""I am still very confused about these changes :-/\r\nIMO we should add `${{ matrix.target }}` to the cache key. This way x86_64 caches won't interfere with the wasm ones."", 'commenter': 'martin-g'}, {'comment': ""Also the handling of pre-1.70 and post-1.70 adds to the confusion.\r\nLet's just disable the new sparse protocol until MSRV is 1.70.0 via https://doc.rust-lang.org/cargo/reference/config.html#registriescrates-ioprotocol (i.e. a global env variable for the whole workflow)"", 'commenter': 'martin-g'}, {'comment': ""I'll open a new PR with the proposed simplifications!"", 'commenter': 'martin-g'}, {'comment': 'https://github.com/apache/avro/pull/2538', 'commenter': 'martin-g'}, {'comment': ""> I am still very confused about these changes :-/\r\nIMO we should add ${{ matrix.target }} to the cache key. This way x86_64 caches won't interfere with the wasm ones.\r\n\r\nAs I explained [here](https://github.com/apache/avro/pull/2538#discussion_r1344376019), I didn't intentionally use `${{ matrix.target }}`.\r\n\r\n> Also the handling of pre-1.70 and post-1.70 adds to the confusion.\r\nLet's just disable the new sparse protocol until MSRV is 1.70.0 via https://doc.rust-lang.org/cargo/reference/config.html#registriescrates-ioprotocol (i.e. a global env variable for the whole workflow)\r\n\r\nThis idea seems awesome!"", 'commenter': 'sarutak'}]"
2517,.github/workflows/test-lang-rust-ci.yml,"@@ -58,20 +58,59 @@ jobs:
       - name: Checkout
         uses: actions/checkout@v4
 
-      - name: Cache Cargo
+      - name: Cache Cargo for 1.65.0
+        if: matrix.rust == '1.65.0' && matrix.target == 'x86_64-unknown-linux-gnu'
         uses: actions/cache@v3
         with:
           # these represent dependencies downloaded by cargo
           # and thus do not depend on the OS, arch nor rust version.
           path: ~/.cargo
-          key: cargo-cache1-
+          key: cargo-cache1-1.65.0-${{ hashFiles('**/Cargo.lock') }}
+
+      - name: Cache Cargo for 1.65.0 (Restore Only)
+        if: matrix.rust == '1.65.0' && matrix.target != 'x86_64-unknown-linux-gnu'
+        uses: actions/cache/restore@v3
+        with:
+          # these represent dependencies downloaded by cargo
+          # and thus do not depend on the OS, arch nor rust version.
+          path: ~/.cargo
+          key: cargo-cache1-1.65.0-${{ hashFiles('**/Cargo.lock') }}
+
+      - name: Cache Cargo for 1.70.0+
+        if: matrix.rust != '1.65.0' && matrix.target == 'x86_64-unknown-linux-gnu'
+        uses: actions/cache@v3
+        with:
+          # these represent dependencies downloaded by cargo
+          # and thus do not depend on the OS, arch nor rust version.
+          path: ~/.cargo
+          key: cargo-cache1-${{ hashFiles('**/Cargo.lock') }}
+
+      - name: Cache Cargo for 1.70.0+ (Restore Only)
+        if: matrix.rust != '1.65.0' && matrix.target != 'x86_64-unknown-linux-gnu'
+        uses: actions/cache/restore@v3
+        with:
+          # these represent dependencies downloaded by cargo
+          # and thus do not depend on the OS, arch nor rust version.
+          path: ~/.cargo
+          key: cargo-cache1-${{ hashFiles('**/Cargo.lock') }}
+
       - name: Cache Rust dependencies
+        if: matrix.target == 'x86_64-unknown-linux-gnu'
         uses: actions/cache@v3
         with:
           # these represent compiled steps of both dependencies and avro
           # and thus are specific for a particular OS, arch and rust version.
-          path: ~/target
-          key: ${{ runner.os }}-target-cache1-${{ matrix.rust }}-
+          path: lang/rust/target","[{'comment': 'IMO this should be \r\n```suggestion\r\n          path: ./target\r\n```\r\nbut it has to be tested!', 'commenter': 'martin-g'}, {'comment': ""Actually, I have already tried `./target` first. But it doesn't work. `defaults.run.working-directory` seems not to affect here."", 'commenter': 'sarutak'}]"
2517,.github/workflows/test-lang-rust-ci.yml,"@@ -58,20 +58,59 @@ jobs:
       - name: Checkout
         uses: actions/checkout@v4
 
-      - name: Cache Cargo
+      - name: Cache Cargo for 1.65.0
+        if: matrix.rust == '1.65.0' && matrix.target == 'x86_64-unknown-linux-gnu'
         uses: actions/cache@v3
         with:
           # these represent dependencies downloaded by cargo
           # and thus do not depend on the OS, arch nor rust version.
           path: ~/.cargo","[{'comment': 'See https://github.com/actions/cache/blob/main/examples.md#rust---cargo', 'commenter': 'martin-g'}, {'comment': 'You mean we should configure the path more granularly like\r\n```\r\n      ~/.cargo/bin/\r\n      ~/.cargo/registry/index/\r\n      ~/.cargo/registry/cache/\r\n      ~/.cargo/git/db/\r\n```\r\nthan `~/.cargo` right?', 'commenter': 'sarutak'}]"
2521,lang/java/avro/src/main/java/org/apache/avro/io/BlockingDirectBinaryEncoder.java,"@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.avro.io;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.ByteBuffer;
+
+/**
+ * An {@link Encoder} for Avro's binary encoding that does not buffer output.
+ * <p/>
+ * This encoder does not buffer writes, and as a result is slower than
+ * {@link BufferedBinaryEncoder}. However, it is lighter-weight and useful when
+ * the buffering in BufferedBinaryEncoder is not desired and/or the Encoder is
+ * very short-lived.
+ * <p/>
+ * To construct, use
+ * {@link EncoderFactory#blockingDirectBinaryEncoder(OutputStream, BinaryEncoder)}
+ * <p/>
+ * BlockingDirectBinaryEncoder is not thread-safe
+ *
+ * @see BinaryEncoder
+ * @see EncoderFactory
+ * @see Encoder
+ * @see Decoder
+ */
+public class BlockingDirectBinaryEncoder extends DirectBinaryEncoder {
+  private static final ThreadLocal<BufferOutputStream> BUFFER = ThreadLocal.withInitial(BufferOutputStream::new);","[{'comment': 'Why here a ""static ThreadLocal"" and not a simple field member.\r\nBinaryEncoder are not robust to multi-thread, but you can have 2 encoder on one thread, that are writing data alternatively.', 'commenter': 'clesaec'}, {'comment': ""Oh that's an excellent question. The idea was to re-use the buffer since it can grow quite a bit (in the case of the Apache Iceberg metadata), but a local variable is indeed a better plan to avoid race conditions."", 'commenter': 'Fokko'}]"
2521,lang/java/avro/src/main/java/org/apache/avro/io/BlockingDirectBinaryEncoder.java,"@@ -0,0 +1,131 @@
+/*
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * ""License""); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     https://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an ""AS IS"" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+package org.apache.avro.io;
+
+import java.io.ByteArrayOutputStream;
+import java.io.IOException;
+import java.io.OutputStream;
+import java.nio.ByteBuffer;
+
+/**
+ * An {@link Encoder} for Avro's binary encoding that does not buffer output.
+ * <p/>
+ * This encoder does not buffer writes, and as a result is slower than
+ * {@link BufferedBinaryEncoder}. However, it is lighter-weight and useful when
+ * the buffering in BufferedBinaryEncoder is not desired and/or the Encoder is
+ * very short-lived.
+ * <p/>
+ * To construct, use
+ * {@link EncoderFactory#blockingDirectBinaryEncoder(OutputStream, BinaryEncoder)}
+ * <p/>
+ * BlockingDirectBinaryEncoder is not thread-safe
+ *
+ * @see BinaryEncoder
+ * @see EncoderFactory
+ * @see Encoder
+ * @see Decoder
+ */
+public class BlockingDirectBinaryEncoder extends DirectBinaryEncoder {
+  private static final ThreadLocal<BufferOutputStream> BUFFER = ThreadLocal.withInitial(BufferOutputStream::new);
+
+  private OutputStream originalStream;
+
+  private boolean inBlock = false;
+
+  private long blockItemCount;
+
+  /**
+   * Create a writer that sends its output to the underlying stream
+   * <code>out</code>.
+   *
+   * @param out The Outputstream to write to
+   */
+  public BlockingDirectBinaryEncoder(OutputStream out) {
+    super(out);
+  }
+
+  private void startBlock() {
+    if (inBlock) {
+      throw new RuntimeException(""Nested Maps/Arrays are not supported by the BlockingDirectBinaryEncoder"");","[{'comment': 'Just put BUFFER as a stack of outputStream, and it would become possible; but not mandatory :).', 'commenter': 'clesaec'}, {'comment': ""Yes, I was thinking of that as well, but this would potentially allocate quite some buffers. For Apache Iceberg we don't use any nested structures, so I went with the simplest approach, but if you think this should be in, I'm happy to add it."", 'commenter': 'Fokko'}, {'comment': ""Ok, let's go step by step; this is good for a first version, moreover if it's aims to be used for specific software like iceberg :) "", 'commenter': 'clesaec'}, {'comment': ""What I do like about this, is the exception thrown: it's in the right place to start looking if you want to lift this limitation."", 'commenter': 'opwvhk'}]"
2521,lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryEncoderFidelity.java,"@@ -181,6 +181,50 @@ void directBinaryEncoder() throws IOException {
     assertArrayEquals(complexdata, result2);
   }
 
+  @Test
+  void blockingDirectBinaryEncoder() throws IOException {
+    ByteArrayOutputStream baos = new ByteArrayOutputStream();
+    BinaryEncoder e = factory.blockingDirectBinaryEncoder(baos, null);
+    generateData(e, true);
+
+    byte[] result = baos.toByteArray();
+    assertEquals(legacydata.length, result.length);
+    assertArrayEquals(legacydata, result);
+    baos.reset();
+
+    generateComplexData(e);
+    byte[] result2 = baos.toByteArray();
+    // blocking will cause different length, should be two bytes larger
+    assertEquals(complexdata.length + 2, result2.length);
+    // the first byte is the array start, with the count of items negative
+    assertEquals(complexdata[0] >>> 1, result2[0]);
+    baos.reset();
+
+    e.writeArrayStart();
+    e.setItemCount(1);
+    e.startItem();
+    e.writeInt(1);
+    e.writeArrayEnd();
+
+    // 1: 1 element in the array
+    // 2: 1 byte for the int
+    // 3: zigzag encoded int
+    // 4: 0 elements in the next block
+    assertArrayEquals(baos.toByteArray(), new byte[] { 1, 2, 2, 0 });
+    baos.reset();
+
+    e.writeArrayStart();
+    e.setItemCount(0);
+    e.writeArrayEnd();","[{'comment': ""Could you test this 2 last byte array with a binary decoder to ensure it works with this new encoder. (if it can't, create a specific decoder class)"", 'commenter': 'clesaec'}, {'comment': ""I've added this test-case in `TestBlockingDirectBinaryEncoder`"", 'commenter': 'Fokko'}]"
2521,lang/java/avro/src/test/java/org/apache/avro/io/TestBinaryEncoderFidelity.java,"@@ -181,6 +181,50 @@ void directBinaryEncoder() throws IOException {
     assertArrayEquals(complexdata, result2);
   }
 
+  @Test
+  void blockingDirectBinaryEncoder() throws IOException {
+    ByteArrayOutputStream baos = new ByteArrayOutputStream();
+    BinaryEncoder e = factory.blockingDirectBinaryEncoder(baos, null);
+    generateData(e, true);
+
+    byte[] result = baos.toByteArray();
+    assertEquals(legacydata.length, result.length);
+    assertArrayEquals(legacydata, result);
+    baos.reset();
+
+    generateComplexData(e);
+    byte[] result2 = baos.toByteArray();
+    // blocking will cause different length, should be two bytes larger
+    assertEquals(complexdata.length + 2, result2.length);
+    // the first byte is the array start, with the count of items negative
+    assertEquals(complexdata[0] >>> 1, result2[0]);
+    baos.reset();
+
+    e.writeArrayStart();
+    e.setItemCount(1);
+    e.startItem();
+    e.writeInt(1);
+    e.writeArrayEnd();
+
+    // 1: 1 element in the array
+    // 2: 1 byte for the int
+    // 3: zigzag encoded int
+    // 4: 0 elements in the next block
+    assertArrayEquals(baos.toByteArray(), new byte[] { 1, 2, 2, 0 });
+    baos.reset();
+
+    e.writeArrayStart();
+    e.setItemCount(0);
+    e.writeArrayEnd();
+
+    // This is correct
+    // 0: 0 elements in the block
+    assertArrayEquals(baos.toByteArray(), new byte[] { 0 });
+    baos.reset();","[{'comment': 'Could you add a test where an array (or map) is skiped; if i understood well, by calling setItemCount(0) before end array ? (or i missed the purpose of this)\r\n```java\r\n    e.writeArrayStart();\r\n    e.setItemCount(1);\r\n    e.startItem();\r\n    e.writeInt(1);\r\n    e.setItemCount(0);  // here, to skip the array ??\r\n    e.writeArrayEnd();\r\n```\r\n', 'commenter': 'clesaec'}, {'comment': 'It is used at read time. It can be used for skipping over the Array/Maps when they are not part of your read schema. Instead of reading all the fields, you can just skip over the whole Array/Map at once since the length is encoded in the Avro file.', 'commenter': 'Fokko'}, {'comment': 'Let me check if I can add a test for it 👍 ', 'commenter': 'Fokko'}, {'comment': 'Added a test for it. LMKWYT', 'commenter': 'Fokko'}]"
2521,lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithMapsAndArrays.java,"@@ -0,0 +1,523 @@
+/**
+ * Autogenerated by Avro
+ *
+ * DO NOT EDIT DIRECTLY
+ */
+package org.apache.avro.specific;
+
+import org.apache.avro.generic.GenericArray;
+import org.apache.avro.specific.SpecificData;
+import org.apache.avro.util.Utf8;
+import org.apache.avro.message.BinaryMessageEncoder;
+import org.apache.avro.message.BinaryMessageDecoder;
+import org.apache.avro.message.SchemaStore;
+
+@org.apache.avro.specific.AvroGenerated
+public class TestRecordWithMapsAndArrays extends org.apache.avro.specific.SpecificRecordBase
+    implements org.apache.avro.specific.SpecificRecord {
+  private static final long serialVersionUID = 3113266652594662627L;
+
+  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse(
+      ""{\""type\"":\""record\"",\""name\"":\""TestRecordWithMapsAndArrays\"",\""namespace\"":\""org.apache.avro.specific\"",\""fields\"":[{\""name\"":\""arr\"",\""type\"":{\""type\"":\""array\"",\""items\"":{\""type\"":\""string\"",\""avro.java.string\"":\""String\""},\""default\"":[]}},{\""name\"":\""map\"",\""type\"":{\""type\"":\""map\"",\""values\"":\""long\"",\""avro.java.string\"":\""String\"",\""default\"":{}}}]}"");
+
+  public static org.apache.avro.Schema getClassSchema() {
+    return SCHEMA$;
+  }
+
+  private static final SpecificData MODEL$ = new SpecificData();
+
+  private static final BinaryMessageEncoder<TestRecordWithMapsAndArrays> ENCODER = new BinaryMessageEncoder<>(MODEL$,
+      SCHEMA$);
+
+  private static final BinaryMessageDecoder<TestRecordWithMapsAndArrays> DECODER = new BinaryMessageDecoder<>(MODEL$,
+      SCHEMA$);
+
+  /**
+   * Return the BinaryMessageEncoder instance used by this class.
+   *
+   * @return the message encoder used by this class
+   */
+  public static BinaryMessageEncoder<TestRecordWithMapsAndArrays> getEncoder() {
+    return ENCODER;
+  }
+
+  /**
+   * Return the BinaryMessageDecoder instance used by this class.
+   *
+   * @return the message decoder used by this class
+   */
+  public static BinaryMessageDecoder<TestRecordWithMapsAndArrays> getDecoder() {
+    return DECODER;
+  }
+
+  /**
+   * Create a new BinaryMessageDecoder instance for this class that uses the
+   * specified {@link SchemaStore}.
+   *
+   * @param resolver a {@link SchemaStore} used to find schemas by fingerprint
+   * @return a BinaryMessageDecoder instance for this class backed by the given
+   *         SchemaStore
+   */
+  public static BinaryMessageDecoder<TestRecordWithMapsAndArrays> createDecoder(SchemaStore resolver) {
+    return new BinaryMessageDecoder<>(MODEL$, SCHEMA$, resolver);
+  }
+
+  /**
+   * Serializes this TestRecordWithMapsAndArrays to a ByteBuffer.
+   *
+   * @return a buffer holding the serialized data for this instance
+   * @throws java.io.IOException if this instance could not be serialized
+   */
+  public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException {
+    return ENCODER.encode(this);
+  }
+
+  /**
+   * Deserializes a TestRecordWithMapsAndArrays from a ByteBuffer.
+   *
+   * @param b a byte buffer holding serialized data for an instance of this class
+   * @return a TestRecordWithMapsAndArrays instance decoded from the given buffer
+   * @throws java.io.IOException if the given bytes could not be deserialized into
+   *                             an instance of this class
+   */
+  public static TestRecordWithMapsAndArrays fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException {
+    return DECODER.decode(b);
+  }
+
+  private java.util.List<java.lang.String> arr;
+  private java.util.Map<java.lang.String, java.lang.Long> map;
+
+  /**
+   * Default constructor. Note that this does not initialize fields to their
+   * default values from the schema. If that is desired then one should use
+   * <code>newBuilder()</code>.
+   */
+  public TestRecordWithMapsAndArrays() {
+  }
+
+  /**
+   * All-args constructor.
+   *
+   * @param arr The new value for arr
+   * @param map The new value for map
+   */
+  public TestRecordWithMapsAndArrays(java.util.List<java.lang.String> arr,
+      java.util.Map<java.lang.String, java.lang.Long> map) {
+    this.arr = arr;
+    this.map = map;
+  }
+
+  @Override
+  public org.apache.avro.specific.SpecificData getSpecificData() {
+    return MODEL$;
+  }
+
+  @Override
+  public org.apache.avro.Schema getSchema() {
+    return SCHEMA$;
+  }
+
+  // Used by DatumWriter. Applications should not call.
+  @Override
+  public java.lang.Object get(int field$) {
+    switch (field$) {
+    case 0:
+      return arr;
+    case 1:
+      return map;
+    default:
+      throw new IndexOutOfBoundsException(""Invalid index: "" + field$);
+    }
+  }
+
+  // Used by DatumReader. Applications should not call.
+  @Override
+  @SuppressWarnings(value = ""unchecked"")
+  public void put(int field$, java.lang.Object value$) {
+    switch (field$) {
+    case 0:
+      arr = (java.util.List<java.lang.String>) value$;
+      break;
+    case 1:
+      map = (java.util.Map<java.lang.String, java.lang.Long>) value$;
+      break;
+    default:
+      throw new IndexOutOfBoundsException(""Invalid index: "" + field$);
+    }
+  }
+
+  /**
+   * Gets the value of the 'arr' field.
+   *
+   * @return The value of the 'arr' field.
+   */
+  public java.util.List<java.lang.String> getArr() {
+    return arr;
+  }
+
+  /**
+   * Sets the value of the 'arr' field.
+   *
+   * @param value the value to set.
+   */
+  public void setArr(java.util.List<java.lang.String> value) {
+    this.arr = value;
+  }
+
+  /**
+   * Gets the value of the 'map' field.
+   *
+   * @return The value of the 'map' field.
+   */
+  public java.util.Map<java.lang.String, java.lang.Long> getMap() {
+    return map;
+  }
+
+  /**
+   * Sets the value of the 'map' field.
+   *
+   * @param value the value to set.
+   */
+  public void setMap(java.util.Map<java.lang.String, java.lang.Long> value) {
+    this.map = value;
+  }
+
+  /**
+   * Creates a new TestRecordWithMapsAndArrays RecordBuilder.
+   *
+   * @return A new TestRecordWithMapsAndArrays RecordBuilder
+   */
+  public static org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder newBuilder() {
+    return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder();
+  }
+
+  /**
+   * Creates a new TestRecordWithMapsAndArrays RecordBuilder by copying an
+   * existing Builder.
+   *
+   * @param other The existing builder to copy.
+   * @return A new TestRecordWithMapsAndArrays RecordBuilder
+   */
+  public static org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder newBuilder(
+      org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder other) {
+    if (other == null) {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder();
+    } else {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder(other);
+    }
+  }
+
+  /**
+   * Creates a new TestRecordWithMapsAndArrays RecordBuilder by copying an
+   * existing TestRecordWithMapsAndArrays instance.
+   *
+   * @param other The existing instance to copy.
+   * @return A new TestRecordWithMapsAndArrays RecordBuilder
+   */
+  public static org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder newBuilder(
+      org.apache.avro.specific.TestRecordWithMapsAndArrays other) {
+    if (other == null) {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder();
+    } else {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder(other);
+    }
+  }
+
+  /**
+   * RecordBuilder for TestRecordWithMapsAndArrays instances.
+   */
+  @org.apache.avro.specific.AvroGenerated
+  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<TestRecordWithMapsAndArrays>
+      implements org.apache.avro.data.RecordBuilder<TestRecordWithMapsAndArrays> {
+
+    private java.util.List<java.lang.String> arr;
+    private java.util.Map<java.lang.String, java.lang.Long> map;
+
+    /** Creates a new Builder */
+    private Builder() {
+      super(SCHEMA$, MODEL$);
+    }
+
+    /**
+     * Creates a Builder by copying an existing Builder.
+     *
+     * @param other The existing Builder to copy.
+     */
+    private Builder(org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder other) {
+      super(other);
+      if (isValidValue(fields()[0], other.arr)) {
+        this.arr = data().deepCopy(fields()[0].schema(), other.arr);
+        fieldSetFlags()[0] = other.fieldSetFlags()[0];
+      }
+      if (isValidValue(fields()[1], other.map)) {
+        this.map = data().deepCopy(fields()[1].schema(), other.map);
+        fieldSetFlags()[1] = other.fieldSetFlags()[1];
+      }
+    }
+
+    /**
+     * Creates a Builder by copying an existing TestRecordWithMapsAndArrays instance
+     *
+     * @param other The existing instance to copy.
+     */
+    private Builder(org.apache.avro.specific.TestRecordWithMapsAndArrays other) {
+      super(SCHEMA$, MODEL$);
+      if (isValidValue(fields()[0], other.arr)) {
+        this.arr = data().deepCopy(fields()[0].schema(), other.arr);
+        fieldSetFlags()[0] = true;
+      }
+      if (isValidValue(fields()[1], other.map)) {
+        this.map = data().deepCopy(fields()[1].schema(), other.map);
+        fieldSetFlags()[1] = true;
+      }
+    }
+
+    /**
+     * Gets the value of the 'arr' field.
+     *
+     * @return The value.
+     */
+    public java.util.List<java.lang.String> getArr() {
+      return arr;
+    }
+
+    /**
+     * Sets the value of the 'arr' field.
+     *
+     * @param value The value of 'arr'.
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder setArr(java.util.List<java.lang.String> value) {
+      validate(fields()[0], value);
+      this.arr = value;
+      fieldSetFlags()[0] = true;
+      return this;
+    }
+
+    /**
+     * Checks whether the 'arr' field has been set.
+     *
+     * @return True if the 'arr' field has been set, false otherwise.
+     */
+    public boolean hasArr() {
+      return fieldSetFlags()[0];
+    }
+
+    /**
+     * Clears the value of the 'arr' field.
+     *
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder clearArr() {
+      arr = null;
+      fieldSetFlags()[0] = false;
+      return this;
+    }
+
+    /**
+     * Gets the value of the 'map' field.
+     *
+     * @return The value.
+     */
+    public java.util.Map<java.lang.String, java.lang.Long> getMap() {
+      return map;
+    }
+
+    /**
+     * Sets the value of the 'map' field.
+     *
+     * @param value The value of 'map'.
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder setMap(
+        java.util.Map<java.lang.String, java.lang.Long> value) {
+      validate(fields()[1], value);
+      this.map = value;
+      fieldSetFlags()[1] = true;
+      return this;
+    }
+
+    /**
+     * Checks whether the 'map' field has been set.
+     *
+     * @return True if the 'map' field has been set, false otherwise.
+     */
+    public boolean hasMap() {
+      return fieldSetFlags()[1];
+    }
+
+    /**
+     * Clears the value of the 'map' field.
+     *
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder clearMap() {
+      map = null;
+      fieldSetFlags()[1] = false;
+      return this;
+    }
+
+    @Override
+    @SuppressWarnings(""unchecked"")
+    public TestRecordWithMapsAndArrays build() {
+      try {
+        TestRecordWithMapsAndArrays record = new TestRecordWithMapsAndArrays();
+        record.arr = fieldSetFlags()[0] ? this.arr : (java.util.List<java.lang.String>) defaultValue(fields()[0]);
+        record.map = fieldSetFlags()[1] ? this.map
+            : (java.util.Map<java.lang.String, java.lang.Long>) defaultValue(fields()[1]);
+        return record;
+      } catch (org.apache.avro.AvroMissingFieldException e) {
+        throw e;
+      } catch (java.lang.Exception e) {
+        throw new org.apache.avro.AvroRuntimeException(e);
+      }
+    }
+  }
+
+  @SuppressWarnings(""unchecked"")
+  private static final org.apache.avro.io.DatumWriter<TestRecordWithMapsAndArrays> WRITER$ = (org.apache.avro.io.DatumWriter<TestRecordWithMapsAndArrays>) MODEL$
+      .createDatumWriter(SCHEMA$);
+
+  @Override
+  public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException {
+    WRITER$.write(this, SpecificData.getEncoder(out));
+  }
+
+  @SuppressWarnings(""unchecked"")
+  private static final org.apache.avro.io.DatumReader<TestRecordWithMapsAndArrays> READER$ = (org.apache.avro.io.DatumReader<TestRecordWithMapsAndArrays>) MODEL$
+      .createDatumReader(SCHEMA$);
+
+  @Override
+  public void readExternal(java.io.ObjectInput in) throws java.io.IOException {
+    READER$.read(this, SpecificData.getDecoder(in));
+  }
+
+  @Override
+  protected boolean hasCustomCoders() {
+    return true;
+  }
+
+  @Override
+  public void customEncode(org.apache.avro.io.Encoder out) throws java.io.IOException {
+    long size0 = this.arr.size();
+    out.writeArrayStart();
+    out.setItemCount(size0);
+    long actualSize0 = 0;
+    for (java.lang.String e0 : this.arr) {
+      actualSize0++;
+      out.startItem();
+      out.writeString(e0);
+    }
+    out.writeArrayEnd();
+    if (actualSize0 != size0)
+      throw new java.util.ConcurrentModificationException(
+          ""Array-size written was "" + size0 + "", but element count was "" + actualSize0 + ""."");
+
+    long size1 = this.map.size();
+    out.writeMapStart();
+    out.setItemCount(size1);
+    long actualSize1 = 0;
+    for (java.util.Map.Entry<java.lang.String, java.lang.Long> e1 : this.map.entrySet()) {
+      actualSize1++;
+      out.startItem();
+      out.writeString(e1.getKey());
+      java.lang.Long v1 = e1.getValue();
+      out.writeLong(v1);
+    }
+    out.writeMapEnd();
+    if (actualSize1 != size1)
+      throw new java.util.ConcurrentModificationException(
+          ""Map-size written was "" + size1 + "", but element count was "" + actualSize1 + ""."");
+
+  }
+
+  @Override
+  public void customDecode(org.apache.avro.io.ResolvingDecoder in) throws java.io.IOException {
+    org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();
+    if (fieldOrder == null) {
+      long size0 = in.readArrayStart();
+      java.util.List<java.lang.String> a0 = this.arr;
+      if (a0 == null) {
+        a0 = new SpecificData.Array<java.lang.String>((int) size0, SCHEMA$.getField(""arr"").schema());
+        this.arr = a0;
+      } else
+        a0.clear();
+      SpecificData.Array<java.lang.String> ga0 = (a0 instanceof SpecificData.Array
+          ? (SpecificData.Array<java.lang.String>) a0","[{'comment': '## Cast from abstract to concrete collection\n\n[List<String>](1) is cast to the concrete type [Array<String>](2), losing abstraction.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3135)', 'commenter': 'github-advanced-security[bot]'}]"
2521,lang/java/avro/src/test/java/org/apache/avro/specific/TestRecordWithMapsAndArrays.java,"@@ -0,0 +1,523 @@
+/**
+ * Autogenerated by Avro
+ *
+ * DO NOT EDIT DIRECTLY
+ */
+package org.apache.avro.specific;
+
+import org.apache.avro.generic.GenericArray;
+import org.apache.avro.specific.SpecificData;
+import org.apache.avro.util.Utf8;
+import org.apache.avro.message.BinaryMessageEncoder;
+import org.apache.avro.message.BinaryMessageDecoder;
+import org.apache.avro.message.SchemaStore;
+
+@org.apache.avro.specific.AvroGenerated
+public class TestRecordWithMapsAndArrays extends org.apache.avro.specific.SpecificRecordBase
+    implements org.apache.avro.specific.SpecificRecord {
+  private static final long serialVersionUID = 3113266652594662627L;
+
+  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse(
+      ""{\""type\"":\""record\"",\""name\"":\""TestRecordWithMapsAndArrays\"",\""namespace\"":\""org.apache.avro.specific\"",\""fields\"":[{\""name\"":\""arr\"",\""type\"":{\""type\"":\""array\"",\""items\"":{\""type\"":\""string\"",\""avro.java.string\"":\""String\""},\""default\"":[]}},{\""name\"":\""map\"",\""type\"":{\""type\"":\""map\"",\""values\"":\""long\"",\""avro.java.string\"":\""String\"",\""default\"":{}}}]}"");
+
+  public static org.apache.avro.Schema getClassSchema() {
+    return SCHEMA$;
+  }
+
+  private static final SpecificData MODEL$ = new SpecificData();
+
+  private static final BinaryMessageEncoder<TestRecordWithMapsAndArrays> ENCODER = new BinaryMessageEncoder<>(MODEL$,
+      SCHEMA$);
+
+  private static final BinaryMessageDecoder<TestRecordWithMapsAndArrays> DECODER = new BinaryMessageDecoder<>(MODEL$,
+      SCHEMA$);
+
+  /**
+   * Return the BinaryMessageEncoder instance used by this class.
+   *
+   * @return the message encoder used by this class
+   */
+  public static BinaryMessageEncoder<TestRecordWithMapsAndArrays> getEncoder() {
+    return ENCODER;
+  }
+
+  /**
+   * Return the BinaryMessageDecoder instance used by this class.
+   *
+   * @return the message decoder used by this class
+   */
+  public static BinaryMessageDecoder<TestRecordWithMapsAndArrays> getDecoder() {
+    return DECODER;
+  }
+
+  /**
+   * Create a new BinaryMessageDecoder instance for this class that uses the
+   * specified {@link SchemaStore}.
+   *
+   * @param resolver a {@link SchemaStore} used to find schemas by fingerprint
+   * @return a BinaryMessageDecoder instance for this class backed by the given
+   *         SchemaStore
+   */
+  public static BinaryMessageDecoder<TestRecordWithMapsAndArrays> createDecoder(SchemaStore resolver) {
+    return new BinaryMessageDecoder<>(MODEL$, SCHEMA$, resolver);
+  }
+
+  /**
+   * Serializes this TestRecordWithMapsAndArrays to a ByteBuffer.
+   *
+   * @return a buffer holding the serialized data for this instance
+   * @throws java.io.IOException if this instance could not be serialized
+   */
+  public java.nio.ByteBuffer toByteBuffer() throws java.io.IOException {
+    return ENCODER.encode(this);
+  }
+
+  /**
+   * Deserializes a TestRecordWithMapsAndArrays from a ByteBuffer.
+   *
+   * @param b a byte buffer holding serialized data for an instance of this class
+   * @return a TestRecordWithMapsAndArrays instance decoded from the given buffer
+   * @throws java.io.IOException if the given bytes could not be deserialized into
+   *                             an instance of this class
+   */
+  public static TestRecordWithMapsAndArrays fromByteBuffer(java.nio.ByteBuffer b) throws java.io.IOException {
+    return DECODER.decode(b);
+  }
+
+  private java.util.List<java.lang.String> arr;
+  private java.util.Map<java.lang.String, java.lang.Long> map;
+
+  /**
+   * Default constructor. Note that this does not initialize fields to their
+   * default values from the schema. If that is desired then one should use
+   * <code>newBuilder()</code>.
+   */
+  public TestRecordWithMapsAndArrays() {
+  }
+
+  /**
+   * All-args constructor.
+   *
+   * @param arr The new value for arr
+   * @param map The new value for map
+   */
+  public TestRecordWithMapsAndArrays(java.util.List<java.lang.String> arr,
+      java.util.Map<java.lang.String, java.lang.Long> map) {
+    this.arr = arr;
+    this.map = map;
+  }
+
+  @Override
+  public org.apache.avro.specific.SpecificData getSpecificData() {
+    return MODEL$;
+  }
+
+  @Override
+  public org.apache.avro.Schema getSchema() {
+    return SCHEMA$;
+  }
+
+  // Used by DatumWriter. Applications should not call.
+  @Override
+  public java.lang.Object get(int field$) {
+    switch (field$) {
+    case 0:
+      return arr;
+    case 1:
+      return map;
+    default:
+      throw new IndexOutOfBoundsException(""Invalid index: "" + field$);
+    }
+  }
+
+  // Used by DatumReader. Applications should not call.
+  @Override
+  @SuppressWarnings(value = ""unchecked"")
+  public void put(int field$, java.lang.Object value$) {
+    switch (field$) {
+    case 0:
+      arr = (java.util.List<java.lang.String>) value$;
+      break;
+    case 1:
+      map = (java.util.Map<java.lang.String, java.lang.Long>) value$;
+      break;
+    default:
+      throw new IndexOutOfBoundsException(""Invalid index: "" + field$);
+    }
+  }
+
+  /**
+   * Gets the value of the 'arr' field.
+   *
+   * @return The value of the 'arr' field.
+   */
+  public java.util.List<java.lang.String> getArr() {
+    return arr;
+  }
+
+  /**
+   * Sets the value of the 'arr' field.
+   *
+   * @param value the value to set.
+   */
+  public void setArr(java.util.List<java.lang.String> value) {
+    this.arr = value;
+  }
+
+  /**
+   * Gets the value of the 'map' field.
+   *
+   * @return The value of the 'map' field.
+   */
+  public java.util.Map<java.lang.String, java.lang.Long> getMap() {
+    return map;
+  }
+
+  /**
+   * Sets the value of the 'map' field.
+   *
+   * @param value the value to set.
+   */
+  public void setMap(java.util.Map<java.lang.String, java.lang.Long> value) {
+    this.map = value;
+  }
+
+  /**
+   * Creates a new TestRecordWithMapsAndArrays RecordBuilder.
+   *
+   * @return A new TestRecordWithMapsAndArrays RecordBuilder
+   */
+  public static org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder newBuilder() {
+    return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder();
+  }
+
+  /**
+   * Creates a new TestRecordWithMapsAndArrays RecordBuilder by copying an
+   * existing Builder.
+   *
+   * @param other The existing builder to copy.
+   * @return A new TestRecordWithMapsAndArrays RecordBuilder
+   */
+  public static org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder newBuilder(
+      org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder other) {
+    if (other == null) {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder();
+    } else {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder(other);
+    }
+  }
+
+  /**
+   * Creates a new TestRecordWithMapsAndArrays RecordBuilder by copying an
+   * existing TestRecordWithMapsAndArrays instance.
+   *
+   * @param other The existing instance to copy.
+   * @return A new TestRecordWithMapsAndArrays RecordBuilder
+   */
+  public static org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder newBuilder(
+      org.apache.avro.specific.TestRecordWithMapsAndArrays other) {
+    if (other == null) {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder();
+    } else {
+      return new org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder(other);
+    }
+  }
+
+  /**
+   * RecordBuilder for TestRecordWithMapsAndArrays instances.
+   */
+  @org.apache.avro.specific.AvroGenerated
+  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<TestRecordWithMapsAndArrays>
+      implements org.apache.avro.data.RecordBuilder<TestRecordWithMapsAndArrays> {
+
+    private java.util.List<java.lang.String> arr;
+    private java.util.Map<java.lang.String, java.lang.Long> map;
+
+    /** Creates a new Builder */
+    private Builder() {
+      super(SCHEMA$, MODEL$);
+    }
+
+    /**
+     * Creates a Builder by copying an existing Builder.
+     *
+     * @param other The existing Builder to copy.
+     */
+    private Builder(org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder other) {
+      super(other);
+      if (isValidValue(fields()[0], other.arr)) {
+        this.arr = data().deepCopy(fields()[0].schema(), other.arr);
+        fieldSetFlags()[0] = other.fieldSetFlags()[0];
+      }
+      if (isValidValue(fields()[1], other.map)) {
+        this.map = data().deepCopy(fields()[1].schema(), other.map);
+        fieldSetFlags()[1] = other.fieldSetFlags()[1];
+      }
+    }
+
+    /**
+     * Creates a Builder by copying an existing TestRecordWithMapsAndArrays instance
+     *
+     * @param other The existing instance to copy.
+     */
+    private Builder(org.apache.avro.specific.TestRecordWithMapsAndArrays other) {
+      super(SCHEMA$, MODEL$);
+      if (isValidValue(fields()[0], other.arr)) {
+        this.arr = data().deepCopy(fields()[0].schema(), other.arr);
+        fieldSetFlags()[0] = true;
+      }
+      if (isValidValue(fields()[1], other.map)) {
+        this.map = data().deepCopy(fields()[1].schema(), other.map);
+        fieldSetFlags()[1] = true;
+      }
+    }
+
+    /**
+     * Gets the value of the 'arr' field.
+     *
+     * @return The value.
+     */
+    public java.util.List<java.lang.String> getArr() {
+      return arr;
+    }
+
+    /**
+     * Sets the value of the 'arr' field.
+     *
+     * @param value The value of 'arr'.
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder setArr(java.util.List<java.lang.String> value) {
+      validate(fields()[0], value);
+      this.arr = value;
+      fieldSetFlags()[0] = true;
+      return this;
+    }
+
+    /**
+     * Checks whether the 'arr' field has been set.
+     *
+     * @return True if the 'arr' field has been set, false otherwise.
+     */
+    public boolean hasArr() {
+      return fieldSetFlags()[0];
+    }
+
+    /**
+     * Clears the value of the 'arr' field.
+     *
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder clearArr() {
+      arr = null;
+      fieldSetFlags()[0] = false;
+      return this;
+    }
+
+    /**
+     * Gets the value of the 'map' field.
+     *
+     * @return The value.
+     */
+    public java.util.Map<java.lang.String, java.lang.Long> getMap() {
+      return map;
+    }
+
+    /**
+     * Sets the value of the 'map' field.
+     *
+     * @param value The value of 'map'.
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder setMap(
+        java.util.Map<java.lang.String, java.lang.Long> value) {
+      validate(fields()[1], value);
+      this.map = value;
+      fieldSetFlags()[1] = true;
+      return this;
+    }
+
+    /**
+     * Checks whether the 'map' field has been set.
+     *
+     * @return True if the 'map' field has been set, false otherwise.
+     */
+    public boolean hasMap() {
+      return fieldSetFlags()[1];
+    }
+
+    /**
+     * Clears the value of the 'map' field.
+     *
+     * @return This builder.
+     */
+    public org.apache.avro.specific.TestRecordWithMapsAndArrays.Builder clearMap() {
+      map = null;
+      fieldSetFlags()[1] = false;
+      return this;
+    }
+
+    @Override
+    @SuppressWarnings(""unchecked"")
+    public TestRecordWithMapsAndArrays build() {
+      try {
+        TestRecordWithMapsAndArrays record = new TestRecordWithMapsAndArrays();
+        record.arr = fieldSetFlags()[0] ? this.arr : (java.util.List<java.lang.String>) defaultValue(fields()[0]);
+        record.map = fieldSetFlags()[1] ? this.map
+            : (java.util.Map<java.lang.String, java.lang.Long>) defaultValue(fields()[1]);
+        return record;
+      } catch (org.apache.avro.AvroMissingFieldException e) {
+        throw e;
+      } catch (java.lang.Exception e) {
+        throw new org.apache.avro.AvroRuntimeException(e);
+      }
+    }
+  }
+
+  @SuppressWarnings(""unchecked"")
+  private static final org.apache.avro.io.DatumWriter<TestRecordWithMapsAndArrays> WRITER$ = (org.apache.avro.io.DatumWriter<TestRecordWithMapsAndArrays>) MODEL$
+      .createDatumWriter(SCHEMA$);
+
+  @Override
+  public void writeExternal(java.io.ObjectOutput out) throws java.io.IOException {
+    WRITER$.write(this, SpecificData.getEncoder(out));
+  }
+
+  @SuppressWarnings(""unchecked"")
+  private static final org.apache.avro.io.DatumReader<TestRecordWithMapsAndArrays> READER$ = (org.apache.avro.io.DatumReader<TestRecordWithMapsAndArrays>) MODEL$
+      .createDatumReader(SCHEMA$);
+
+  @Override
+  public void readExternal(java.io.ObjectInput in) throws java.io.IOException {
+    READER$.read(this, SpecificData.getDecoder(in));
+  }
+
+  @Override
+  protected boolean hasCustomCoders() {
+    return true;
+  }
+
+  @Override
+  public void customEncode(org.apache.avro.io.Encoder out) throws java.io.IOException {
+    long size0 = this.arr.size();
+    out.writeArrayStart();
+    out.setItemCount(size0);
+    long actualSize0 = 0;
+    for (java.lang.String e0 : this.arr) {
+      actualSize0++;
+      out.startItem();
+      out.writeString(e0);
+    }
+    out.writeArrayEnd();
+    if (actualSize0 != size0)
+      throw new java.util.ConcurrentModificationException(
+          ""Array-size written was "" + size0 + "", but element count was "" + actualSize0 + ""."");
+
+    long size1 = this.map.size();
+    out.writeMapStart();
+    out.setItemCount(size1);
+    long actualSize1 = 0;
+    for (java.util.Map.Entry<java.lang.String, java.lang.Long> e1 : this.map.entrySet()) {
+      actualSize1++;
+      out.startItem();
+      out.writeString(e1.getKey());
+      java.lang.Long v1 = e1.getValue();
+      out.writeLong(v1);
+    }
+    out.writeMapEnd();
+    if (actualSize1 != size1)
+      throw new java.util.ConcurrentModificationException(
+          ""Map-size written was "" + size1 + "", but element count was "" + actualSize1 + ""."");
+
+  }
+
+  @Override
+  public void customDecode(org.apache.avro.io.ResolvingDecoder in) throws java.io.IOException {
+    org.apache.avro.Schema.Field[] fieldOrder = in.readFieldOrderIfDiff();
+    if (fieldOrder == null) {
+      long size0 = in.readArrayStart();
+      java.util.List<java.lang.String> a0 = this.arr;
+      if (a0 == null) {
+        a0 = new SpecificData.Array<java.lang.String>((int) size0, SCHEMA$.getField(""arr"").schema());
+        this.arr = a0;
+      } else
+        a0.clear();
+      SpecificData.Array<java.lang.String> ga0 = (a0 instanceof SpecificData.Array
+          ? (SpecificData.Array<java.lang.String>) a0
+          : null);
+      for (; 0 < size0; size0 = in.arrayNext()) {
+        for (; size0 != 0; size0--) {
+          java.lang.String e0 = (ga0 != null ? ga0.peek() : null);
+          e0 = in.readString();
+          a0.add(e0);
+        }
+      }
+
+      long size1 = in.readMapStart();
+      java.util.Map<java.lang.String, java.lang.Long> m1 = this.map; // Need fresh name due to limitation of macro
+                                                                     // system
+      if (m1 == null) {
+        m1 = new java.util.HashMap<java.lang.String, java.lang.Long>((int) size1);
+        this.map = m1;
+      } else
+        m1.clear();
+      for (; 0 < size1; size1 = in.mapNext()) {
+        for (; size1 != 0; size1--) {
+          java.lang.String k1 = null;
+          k1 = in.readString();
+          java.lang.Long v1 = null;
+          v1 = in.readLong();
+          m1.put(k1, v1);
+        }
+      }
+
+    } else {
+      for (int i = 0; i < 2; i++) {
+        switch (fieldOrder[i].pos()) {
+        case 0:
+          long size0 = in.readArrayStart();
+          java.util.List<java.lang.String> a0 = this.arr;
+          if (a0 == null) {
+            a0 = new SpecificData.Array<java.lang.String>((int) size0, SCHEMA$.getField(""arr"").schema());
+            this.arr = a0;
+          } else
+            a0.clear();
+          SpecificData.Array<java.lang.String> ga0 = (a0 instanceof SpecificData.Array
+              ? (SpecificData.Array<java.lang.String>) a0","[{'comment': '## Cast from abstract to concrete collection\n\n[List<String>](1) is cast to the concrete type [Array<String>](2), losing abstraction.\n\n[Show more details](https://github.com/apache/avro/security/code-scanning/3136)', 'commenter': 'github-advanced-security[bot]'}]"
2555,doc/config.toml,"@@ -257,7 +257,7 @@ url = ""http://www.apache.org/security/""
   desc = ""Chat with other project developers at #avro channel""
 [[params.links.developer]]
   name = ""Developer mailing list""
-  url = ""mailto:dev@avro.apache.org""
+  url = ""https://lists.apache.org/list.html?dev@avro.apache.org""","[{'comment': 'If we do this then we have to do it for `user@` too (https://github.com/apache/avro/pull/2555/files#diff-8cb6d82f590d5eac7989519b7da2ebbe792c228aa3a402be1bc2fa1aa0ba80ccR229).', 'commenter': 'martin-g'}, {'comment': 'Great suggestion!', 'commenter': 'Fokko'}]"
2555,doc/config.toml,"@@ -226,7 +226,7 @@ url = ""http://www.apache.org/security/""
 # End user relevant links. These will show up on left side of footer and in the community page if you have one.
 [[params.links.user]]
   name = ""User mailing list""
-  url = ""mailto:user@avro.apache.org""
+  url = ""https://lists.apache.org/list.html?user@avro.apache.org""","[{'comment': 'Do we want to keep the user stay on the current page and open the lists.a.o in a new browser tab ?\r\nIf YES then we will have to add `target=""_blank""` to the Markdown page where this `url` is rendered.', 'commenter': 'martin-g'}, {'comment': ""I don't think opening is the same page or tab is unexpected!  If anyone feels otherwise, we can probably revisit this decision!"", 'commenter': 'RyanSkraba'}]"
2567,lang/rust/avro/src/de.rs,"@@ -350,6 +354,7 @@ impl<'a, 'de> de::Deserializer<'de> for &'a Deserializer<'de> {
             Value::String(ref s) => visitor.visit_bytes(s.as_bytes()),
             Value::Bytes(ref bytes) | Value::Fixed(_, ref bytes) => visitor.visit_bytes(bytes),
             Value::Uuid(ref u) => visitor.visit_bytes(u.as_bytes()),
+            Value::Decimal(ref d) => visitor.visit_bytes(&d.to_vec()?),","[{'comment': ""It'd be nice to add new unit tests for the changes above."", 'commenter': 'martin-g'}, {'comment': 'Thanks for review! I have added the test for it.', 'commenter': 'ZENOTME'}]"
2567,lang/rust/avro/src/de.rs,"@@ -350,6 +354,7 @@ impl<'a, 'de> de::Deserializer<'de> for &'a Deserializer<'de> {
             Value::String(ref s) => visitor.visit_bytes(s.as_bytes()),
             Value::Bytes(ref bytes) | Value::Fixed(_, ref bytes) => visitor.visit_bytes(bytes),
             Value::Uuid(ref u) => visitor.visit_bytes(u.as_bytes()),
+            Value::Decimal(ref d) => visitor.visit_bytes(&d.to_vec()?),
             _ => Err(de::Error::custom(format!(
                 ""Expected a String|Bytes|Fixed|Uuid, but got {:?}"",","[{'comment': '```suggestion\r\n                ""Expected a String|Bytes|Fixed|Uuid|Decimal, but got {:?}"",\r\n```', 'commenter': 'martin-g'}]"
2567,lang/rust/avro/src/de.rs,"@@ -1315,4 +1323,67 @@ mod tests {
 
         Ok(())
     }
+
+    #[test]
+    fn test_avro_3892_deserialize_string_from_bytes() -> TestResult {
+        let raw_value = vec![1, 2, 3, 4];
+        let value = Value::Bytes(raw_value.clone());
+        let result = from_value::<String>(&value)?;
+        assert_eq!(result, String::from_utf8(raw_value)?);
+        Ok(())
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_str_from_bytes() -> TestResult {
+        let raw_value = &[1, 2, 3, 4];
+        let value = Value::Bytes(raw_value.to_vec());
+        let result = from_value::<&str>(&value)?;
+        assert_eq!(result, std::str::from_utf8(raw_value)?);
+        Ok(())
+    }
+
+    struct Bytes(Vec<u8>);
+
+    impl<'de> Deserialize<'de> for Bytes {
+        fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
+        where
+            D: serde::Deserializer<'de>,
+        {
+            struct BytesVisitor;
+            impl<'de> serde::de::Visitor<'de> for BytesVisitor {
+                type Value = Bytes;
+
+                fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
+                    formatter.write_str(""a byte array"")
+                }
+
+                fn visit_bytes<E>(self, v: &[u8]) -> Result<Self::Value, E>
+                where
+                    E: serde::de::Error,
+                {
+                    Ok(Bytes(v.to_vec()))
+                }
+            }
+            deserializer.deserialize_bytes(BytesVisitor)
+        }
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_bytes_from_decimal() -> TestResult {
+        let expeced_bytes = BigInt::from(123456789).to_signed_bytes_be();
+        let value = Value::Decimal(Decimal::from(&expeced_bytes));
+        let raw_bytes = from_value::<Bytes>(&value)?;
+        assert_eq!(raw_bytes.0, expeced_bytes);
+        Ok(())
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_bytes_from_uuid() -> TestResult {
+        let uuid_str = ""10101010-2020-2020-2020-101010101010"";
+        let expected_bytes = Uuid::parse_str(uuid_str)?.as_bytes().to_vec();","[{'comment': 'One thing may need to notice: I find that the behaviour of deserialize_str and deserialize_bytes for Value::Uuid is different. We can see that in deserialize_bytes for Value::Uuid, the bytes representation is `Uuid::parse_str(uuid_str)?.as_bytes()` rathern than `uuid_str.as_bytes()`. But for deserialize_str, the result will be `uuid_str.as_bytes()` I think. Is this behaviour is expect? cc @martin-g', 'commenter': 'ZENOTME'}, {'comment': ""Dunno!\r\nI have to check what `Uuid::as_bytes()` does. I'll check tomorrow!\r\nBut feel free to propose a PR with a fix if you think it is wrong!"", 'commenter': 'martin-g'}]"
2567,lang/rust/avro/src/de.rs,"@@ -1315,4 +1323,67 @@ mod tests {
 
         Ok(())
     }
+
+    #[test]
+    fn test_avro_3892_deserialize_string_from_bytes() -> TestResult {
+        let raw_value = vec![1, 2, 3, 4];
+        let value = Value::Bytes(raw_value.clone());
+        let result = from_value::<String>(&value)?;
+        assert_eq!(result, String::from_utf8(raw_value)?);
+        Ok(())
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_str_from_bytes() -> TestResult {
+        let raw_value = &[1, 2, 3, 4];
+        let value = Value::Bytes(raw_value.to_vec());
+        let result = from_value::<&str>(&value)?;
+        assert_eq!(result, std::str::from_utf8(raw_value)?);
+        Ok(())
+    }
+
+    struct Bytes(Vec<u8>);
+
+    impl<'de> Deserialize<'de> for Bytes {
+        fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
+        where
+            D: serde::Deserializer<'de>,
+        {
+            struct BytesVisitor;
+            impl<'de> serde::de::Visitor<'de> for BytesVisitor {
+                type Value = Bytes;
+
+                fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
+                    formatter.write_str(""a byte array"")
+                }
+
+                fn visit_bytes<E>(self, v: &[u8]) -> Result<Self::Value, E>
+                where
+                    E: serde::de::Error,
+                {
+                    Ok(Bytes(v.to_vec()))
+                }
+            }
+            deserializer.deserialize_bytes(BytesVisitor)
+        }
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_bytes_from_decimal() -> TestResult {
+        let expeced_bytes = BigInt::from(123456789).to_signed_bytes_be();","[{'comment': '```suggestion\r\n        let expected_bytes = BigInt::from(123456789).to_signed_bytes_be();\r\n```', 'commenter': 'martin-g'}]"
2567,lang/rust/avro/src/de.rs,"@@ -1315,4 +1323,67 @@ mod tests {
 
         Ok(())
     }
+
+    #[test]
+    fn test_avro_3892_deserialize_string_from_bytes() -> TestResult {
+        let raw_value = vec![1, 2, 3, 4];
+        let value = Value::Bytes(raw_value.clone());
+        let result = from_value::<String>(&value)?;
+        assert_eq!(result, String::from_utf8(raw_value)?);
+        Ok(())
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_str_from_bytes() -> TestResult {
+        let raw_value = &[1, 2, 3, 4];
+        let value = Value::Bytes(raw_value.to_vec());
+        let result = from_value::<&str>(&value)?;
+        assert_eq!(result, std::str::from_utf8(raw_value)?);
+        Ok(())
+    }
+
+    struct Bytes(Vec<u8>);
+
+    impl<'de> Deserialize<'de> for Bytes {
+        fn deserialize<D>(deserializer: D) -> Result<Self, D::Error>
+        where
+            D: serde::Deserializer<'de>,
+        {
+            struct BytesVisitor;
+            impl<'de> serde::de::Visitor<'de> for BytesVisitor {
+                type Value = Bytes;
+
+                fn expecting(&self, formatter: &mut std::fmt::Formatter) -> std::fmt::Result {
+                    formatter.write_str(""a byte array"")
+                }
+
+                fn visit_bytes<E>(self, v: &[u8]) -> Result<Self::Value, E>
+                where
+                    E: serde::de::Error,
+                {
+                    Ok(Bytes(v.to_vec()))
+                }
+            }
+            deserializer.deserialize_bytes(BytesVisitor)
+        }
+    }
+
+    #[test]
+    fn test_avro_3892_deserialize_bytes_from_decimal() -> TestResult {
+        let expeced_bytes = BigInt::from(123456789).to_signed_bytes_be();
+        let value = Value::Decimal(Decimal::from(&expeced_bytes));
+        let raw_bytes = from_value::<Bytes>(&value)?;
+        assert_eq!(raw_bytes.0, expeced_bytes);
+        Ok(())","[{'comment': 'Please add tests also for the `Value::Bytes` and `Value::Fixed`, and `Value::Union` with them.', 'commenter': 'martin-g'}]"
