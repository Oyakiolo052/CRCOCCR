{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9900a1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sets created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('withAuthor_comments_apache.csv')\n",
    "\n",
    "# Filter rows where Prediction column is 1\n",
    "df_positive = df[df['prediction'] == 1]\n",
    "\n",
    "# Check if there are enough rows to create three sets of 4000 rows each\n",
    "total_positive_rows = len(df_positive)\n",
    "required_rows = 3 * 4000\n",
    "\n",
    "if total_positive_rows < required_rows:\n",
    "    raise ValueError(f\"Not enough rows with Prediction = 1. Available: {total_positive_rows}, Required: {required_rows}\")\n",
    "\n",
    "# Shuffle the filtered dataframe\n",
    "df_positive_shuffled = df_positive.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Split the shuffled dataframe into three sets\n",
    "set1 = df_positive_shuffled.iloc[:4000]\n",
    "set2 = df_positive_shuffled.iloc[4000:8000]\n",
    "set3 = df_positive_shuffled.iloc[8000:12000]\n",
    "\n",
    "# Optionally, save these sets to separate CSV files\n",
    "set1.to_csv('set1_apache.csv', index=False)\n",
    "set2.to_csv('set2_apache.csv', index=False)\n",
    "set3.to_csv('set3_apache.csv', index=False)\n",
    "\n",
    "print(\"Sets created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fe1376d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in Positive.csv: 32623\n",
      "Number of rows in set1_apache.csv: 4000\n",
      "Number of rows in set2_apache.csv: 4000\n",
      "Number of rows in set3_apache.csv: 4000\n",
      "Number of remaining rows: 32623\n",
      "Remaining rows created and saved successfully.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5acf3158",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in Positive.csv: 32623\n",
      "Number of rows in set1_apache.csv: 4000\n",
      "Number of rows in set2_apache.csv: 4000\n",
      "Number of rows in set3_apache.csv: 4000\n",
      "Number of remaining rows: 18719\n",
      "Remaining rows created and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the original CSV file\n",
    "df = pd.read_csv('withAuthor_comments_apache.csv')\n",
    "\n",
    "# Filter rows where Prediction column is 1\n",
    "df_positive = df[df['prediction'] == 1]\n",
    "\n",
    "# Load the existing sets from their CSV files\n",
    "set1 = pd.read_csv('set1_apache.csv')\n",
    "set2 = pd.read_csv('set2_apache.csv')\n",
    "set3 = pd.read_csv('set3_apache.csv')\n",
    "\n",
    "# Combine the three sets into one dataframe\n",
    "combined_sets = pd.concat([set1, set2, set3])\n",
    "\n",
    "# Find the remaining rows in df_positive that are not in the combined sets\n",
    "remaining_rows = df_positive.merge(combined_sets, how='outer', indicator=True).loc[lambda x: x['_merge'] == 'left_only']\n",
    "\n",
    "# Drop the merge indicator column\n",
    "remaining_rows = remaining_rows.drop(columns=['_merge'])\n",
    "\n",
    "# Optionally, save the remaining rows to a new CSV file\n",
    "remaining_rows.to_csv('remaining_rows_apache.csv', index=False)\n",
    "\n",
    "# Print the row counts for each set\n",
    "print(f\"Number of rows in Positive.csv: {len(df_positive)}\")\n",
    "print(f\"Number of rows in set1_apache.csv: {len(set1)}\")\n",
    "print(f\"Number of rows in set2_apache.csv: {len(set2)}\")\n",
    "print(f\"Number of rows in set3_apache.csv: {len(set3)}\")\n",
    "print(f\"Number of remaining rows: {len(remaining_rows)}\")\n",
    "\n",
    "print(\"Remaining rows created and saved successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0b181df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3999\n",
      "The list has been added as a new column in the new CSV file.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Open the file in read mode and get the last values\n",
    "with open('set3_apache_answer.txt', 'r') as file:\n",
    "    last_values = [int(line.strip().split(':')[-1]) for line in file]\n",
    "\n",
    "print(len(last_values))    \n",
    "    \n",
    "# Read the existing CSV file and store its content\n",
    "with open('set3_apache.csv', 'r', newline='') as csvfile:\n",
    "    reader = csv.reader(csvfile)\n",
    "    rows = list(reader)\n",
    "\n",
    "# Add the new header for the column\n",
    "if rows:\n",
    "    rows[0].append(\"actual\")  # Add new header to the first row\n",
    "\n",
    "# Append the last values as a new column to each row\n",
    "for i, row in enumerate(rows[1:]):  # Skip the header row\n",
    "    # Ensure we have enough last_values to add to each row\n",
    "    if i < len(last_values):\n",
    "        row.append(last_values[i])\n",
    "    else:\n",
    "        row.append('')  # Handle case where there are fewer last_values than rows\n",
    "\n",
    "# Write the updated content to a new CSV file\n",
    "with open('updated_set3_apache.csv', 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerows(rows)\n",
    "\n",
    "print(\"The list has been added as a new column in the new CSV file.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "249ada5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV files to merge\n",
    "csv_files = ['updated_set3_apache.csv', 'updated_set1_apache.csv', 'updated_set2_apache.csv', 'updated_remaining_rows_apache.csv']\n",
    "\n",
    "# Read and concatenate CSV files\n",
    "dataframes = [pd.read_csv(file) for file in csv_files]\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "merged_df.to_csv('merged_all_apache.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "efa50202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('withAuthor_comments_apache.csv')\n",
    "\n",
    "# Filter rows where Prediction column is 1\n",
    "df_positive = df[df['prediction'] == 0]\n",
    "df_positive.to_csv('rowsWith0_apache.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed46593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
