{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93c64c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /home/mdr614/anaconda3/lib/python3.10/site-packages (3.0.10)\r\n",
      "Requirement already satisfied: et_xmlfile in /home/mdr614/anaconda3/lib/python3.10/site-packages (from openpyxl) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a40d8f6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jupyter in /home/mdr614/anaconda3/lib/python3.10/site-packages (1.1.1)\n",
      "Requirement already satisfied: ipywidgets in /home/mdr614/anaconda3/lib/python3.10/site-packages (8.1.5)\n",
      "Requirement already satisfied: notebook in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter) (6.5.2)\n",
      "Requirement already satisfied: ipykernel in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter) (6.19.2)\n",
      "Requirement already satisfied: jupyter-console in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter) (6.6.2)\n",
      "Requirement already satisfied: jupyterlab in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter) (3.5.3)\n",
      "Requirement already satisfied: nbconvert in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter) (6.5.4)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: comm>=0.1.3 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipywidgets) (0.1.4)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipywidgets) (5.7.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipywidgets) (8.10.0)\n",
      "Requirement already satisfied: pickleshare in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.30 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.36)\n",
      "Requirement already satisfied: decorator in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: backcall in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: stack-data in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.1)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (23.2.0)\n",
      "Requirement already satisfied: nest-asyncio in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (1.5.6)\n",
      "Requirement already satisfied: psutil in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (5.9.0)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (7.3.4)\n",
      "Requirement already satisfied: packaging in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (22.0)\n",
      "Requirement already satisfied: debugpy>=1.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from ipykernel->jupyter) (1.5.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter-console->jupyter) (5.2.0)\n",
      "Requirement already satisfied: nbclassic in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab->jupyter) (0.5.2)\n",
      "Requirement already satisfied: tomli in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.0.1)\n",
      "Requirement already satisfied: jupyterlab-server~=2.10 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab->jupyter) (2.19.0)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.16.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab->jupyter) (1.23.4)\n",
      "Requirement already satisfied: jinja2>=2.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab->jupyter) (3.1.2)\n",
      "Requirement already satisfied: ipython-genutils in /home/mdr614/anaconda3/lib/python3.10/site-packages (from notebook->jupyter) (0.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/mdr614/anaconda3/lib/python3.10/site-packages (from notebook->jupyter) (21.3.0)\n",
      "Requirement already satisfied: nbformat in /home/mdr614/anaconda3/lib/python3.10/site-packages (from notebook->jupyter) (5.7.0)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from notebook->jupyter) (1.8.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from notebook->jupyter) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /home/mdr614/anaconda3/lib/python3.10/site-packages (from notebook->jupyter) (0.14.1)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (1.5.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (4.11.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: defusedxml in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (2.1.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (0.5.13)\n",
      "Requirement already satisfied: bleach in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (4.1.0)\n",
      "Requirement already satisfied: tinycss2 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (1.2.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (0.4)\n",
      "Requirement already satisfied: lxml in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbconvert->jupyter) (4.9.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter-client>=6.1.12->ipykernel->jupyter) (2.8.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter-core!=5.0.*,>=4.12->jupyter-console->jupyter) (2.5.2)\n",
      "Requirement already satisfied: websocket-client in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (0.58.0)\n",
      "Requirement already satisfied: anyio<4,>=3.1.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (3.7.1)\n",
      "Requirement already satisfied: jsonschema>=4.17.3 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab-server~=2.10->jupyterlab->jupyter) (4.17.3)\n",
      "Requirement already satisfied: requests>=2.28 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab-server~=2.10->jupyterlab->jupyter) (2.28.1)\n",
      "Requirement already satisfied: json5>=0.9.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab-server~=2.10->jupyterlab->jupyter) (0.9.6)\n",
      "Requirement already satisfied: babel>=2.10 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jupyterlab-server~=2.10->jupyterlab->jupyter) (2.11.0)\n",
      "Requirement already satisfied: notebook-shim>=0.1.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbclassic->jupyterlab->jupyter) (0.2.2)\n",
      "Requirement already satisfied: fastjsonschema in /home/mdr614/anaconda3/lib/python3.10/site-packages (from nbformat->notebook->jupyter) (2.16.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wcwidth in /home/mdr614/anaconda3/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.30->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/mdr614/anaconda3/lib/python3.10/site-packages (from argon2-cffi->notebook->jupyter) (21.2.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from beautifulsoup4->nbconvert->jupyter) (2.3.2.post1)\n",
      "Requirement already satisfied: six>=1.9.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from bleach->nbconvert->jupyter) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /home/mdr614/anaconda3/lib/python3.10/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: pure-eval in /home/mdr614/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: executing in /home/mdr614/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /home/mdr614/anaconda3/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.5)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/mdr614/anaconda3/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (1.1.3)\n",
      "Requirement already satisfied: idna>=2.8 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from anyio<4,>=3.1.0->jupyter-server<3,>=1.16.0->jupyterlab->jupyter) (3.4)\n",
      "Requirement already satisfied: pytz>=2015.7 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from babel>=2.10->jupyterlab-server~=2.10->jupyterlab->jupyter) (2022.7)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.10->jupyterlab->jupyter) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from jsonschema>=4.17.3->jupyterlab-server~=2.10->jupyterlab->jupyter) (0.18.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from requests>=2.28->jupyterlab-server~=2.10->jupyterlab->jupyter) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from requests>=2.28->jupyterlab-server~=2.10->jupyterlab->jupyter) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from requests>=2.28->jupyterlab-server~=2.10->jupyterlab->jupyter) (2.0.4)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/mdr614/anaconda3/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /home/mdr614/anaconda3/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da534d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f06d97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>beam</td>\n",
       "      <td>16917</td>\n",
       "      <td>yeandy</td>\n",
       "      <td>Renamed `PytorchModel` to `PytorchModelSpec` s...</td>\n",
       "      <td>sdks/python/apache_beam/ml/inference/api.py</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>flink</td>\n",
       "      <td>13648</td>\n",
       "      <td>curcur</td>\n",
       "      <td>But I can think of a possible case that might ...</td>\n",
       "      <td>flink-runtime/src/main/java/org/apache/flink/r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>seatunnel</td>\n",
       "      <td>4683</td>\n",
       "      <td>sunxiaojian</td>\n",
       "      <td>&gt; Please add this to `pom.xml` not in submodul...</td>\n",
       "      <td>seatunnel-engine/seatunnel-engine-storage/imap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bookkeeper</td>\n",
       "      <td>1225</td>\n",
       "      <td>reddycharan</td>\n",
       "      <td>changing</td>\n",
       "      <td>bookkeeper-server/src/test/java/org/apache/boo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>flink</td>\n",
       "      <td>3621</td>\n",
       "      <td>dawidwys</td>\n",
       "      <td>done</td>\n",
       "      <td>flink-libraries/flink-cep/src/main/java/org/ap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sl     Project  pullNumber       author  \\\n",
       "0   1        beam       16917       yeandy   \n",
       "1   2       flink       13648       curcur   \n",
       "2   3   seatunnel        4683  sunxiaojian   \n",
       "3   4  bookkeeper        1225  reddycharan   \n",
       "4   5       flink        3621     dawidwys   \n",
       "\n",
       "                                             comment  \\\n",
       "0  Renamed `PytorchModel` to `PytorchModelSpec` s...   \n",
       "1  But I can think of a possible case that might ...   \n",
       "2  > Please add this to `pom.xml` not in submodul...   \n",
       "3                                           changing   \n",
       "4                                               done   \n",
       "\n",
       "                                                path  label  \n",
       "0        sdks/python/apache_beam/ml/inference/api.py      1  \n",
       "1  flink-runtime/src/main/java/org/apache/flink/r...      1  \n",
       "2  seatunnel-engine/seatunnel-engine-storage/imap...      1  \n",
       "3  bookkeeper-server/src/test/java/org/apache/boo...      0  \n",
       "4  flink-libraries/flink-cep/src/main/java/org/ap...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file ='/u1/mdr614/On the compleness of review comments/Notebook_on the compleness/BERT_CONFU_AUTHOR/train_bert_author.xlsx' \n",
    "df = pd.read_excel(csv_file)\n",
    "#df = pd.read_csv(csv_file)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa60f761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    22624\n",
       "1     8095\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b3ace9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df.label.unique()\n",
    "possible_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9464e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d792c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 1, '0': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {'1': 1, '0': 0}\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cad10c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df.label.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d347c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>beam</td>\n",
       "      <td>16917</td>\n",
       "      <td>yeandy</td>\n",
       "      <td>Renamed `PytorchModel` to `PytorchModelSpec` s...</td>\n",
       "      <td>sdks/python/apache_beam/ml/inference/api.py</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>flink</td>\n",
       "      <td>13648</td>\n",
       "      <td>curcur</td>\n",
       "      <td>But I can think of a possible case that might ...</td>\n",
       "      <td>flink-runtime/src/main/java/org/apache/flink/r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>seatunnel</td>\n",
       "      <td>4683</td>\n",
       "      <td>sunxiaojian</td>\n",
       "      <td>&gt; Please add this to `pom.xml` not in submodul...</td>\n",
       "      <td>seatunnel-engine/seatunnel-engine-storage/imap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bookkeeper</td>\n",
       "      <td>1225</td>\n",
       "      <td>reddycharan</td>\n",
       "      <td>changing</td>\n",
       "      <td>bookkeeper-server/src/test/java/org/apache/boo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>flink</td>\n",
       "      <td>3621</td>\n",
       "      <td>dawidwys</td>\n",
       "      <td>done</td>\n",
       "      <td>flink-libraries/flink-cep/src/main/java/org/ap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sl     Project  pullNumber       author  \\\n",
       "0   1        beam       16917       yeandy   \n",
       "1   2       flink       13648       curcur   \n",
       "2   3   seatunnel        4683  sunxiaojian   \n",
       "3   4  bookkeeper        1225  reddycharan   \n",
       "4   5       flink        3621     dawidwys   \n",
       "\n",
       "                                             comment  \\\n",
       "0  Renamed `PytorchModel` to `PytorchModelSpec` s...   \n",
       "1  But I can think of a possible case that might ...   \n",
       "2  > Please add this to `pom.xml` not in submodul...   \n",
       "3                                           changing   \n",
       "4                                               done   \n",
       "\n",
       "                                                path  label  \n",
       "0        sdks/python/apache_beam/ml/inference/api.py      1  \n",
       "1  flink-runtime/src/main/java/org/apache/flink/r...      1  \n",
       "2  seatunnel-engine/seatunnel-engine-storage/imap...      1  \n",
       "3  bookkeeper-server/src/test/java/org/apache/boo...      0  \n",
       "4  flink-libraries/flink-cep/src/main/java/org/ap...      0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21fd566",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06001f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df.index.values, \n",
    "                                                  df.label.values, \n",
    "                                                  test_size=0.15, \n",
    "                                                  random_state=17, \n",
    "                                                  stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a3b84e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20974,  9795, 25388, ..., 12691,  7531, 23254])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36b37ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['data_type'] = ['not_set']*df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52bcb33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c36488d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>beam</td>\n",
       "      <td>16917</td>\n",
       "      <td>yeandy</td>\n",
       "      <td>Renamed `PytorchModel` to `PytorchModelSpec` s...</td>\n",
       "      <td>sdks/python/apache_beam/ml/inference/api.py</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>flink</td>\n",
       "      <td>13648</td>\n",
       "      <td>curcur</td>\n",
       "      <td>But I can think of a possible case that might ...</td>\n",
       "      <td>flink-runtime/src/main/java/org/apache/flink/r...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>seatunnel</td>\n",
       "      <td>4683</td>\n",
       "      <td>sunxiaojian</td>\n",
       "      <td>&gt; Please add this to `pom.xml` not in submodul...</td>\n",
       "      <td>seatunnel-engine/seatunnel-engine-storage/imap...</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>bookkeeper</td>\n",
       "      <td>1225</td>\n",
       "      <td>reddycharan</td>\n",
       "      <td>changing</td>\n",
       "      <td>bookkeeper-server/src/test/java/org/apache/boo...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>flink</td>\n",
       "      <td>3621</td>\n",
       "      <td>dawidwys</td>\n",
       "      <td>done</td>\n",
       "      <td>flink-libraries/flink-cep/src/main/java/org/ap...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30714</th>\n",
       "      <td>30715</td>\n",
       "      <td>apex-core</td>\n",
       "      <td>568</td>\n",
       "      <td>sandeshh</td>\n",
       "      <td>Not required, changing it back.</td>\n",
       "      <td>engine/src/main/java/com/datatorrent/stram/Str...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30715</th>\n",
       "      <td>30716</td>\n",
       "      <td>apex-core</td>\n",
       "      <td>568</td>\n",
       "      <td>sandeshh</td>\n",
       "      <td>Done</td>\n",
       "      <td>bufferserver/src/main/java/com/datatorrent/buf...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30716</th>\n",
       "      <td>30717</td>\n",
       "      <td>apex-core</td>\n",
       "      <td>569</td>\n",
       "      <td>sanjaypujare</td>\n",
       "      <td>fixed</td>\n",
       "      <td>engine/src/test/java/com/datatorrent/stram/cli...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30717</th>\n",
       "      <td>30718</td>\n",
       "      <td>apex-core</td>\n",
       "      <td>569</td>\n",
       "      <td>sanjaypujare</td>\n",
       "      <td>fixed</td>\n",
       "      <td>engine/src/test/java/com/datatorrent/stram/cli...</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30718</th>\n",
       "      <td>30719</td>\n",
       "      <td>apex-core</td>\n",
       "      <td>598</td>\n",
       "      <td>chinmaykolhatkar</td>\n",
       "      <td>Done</td>\n",
       "      <td>docker/build.sh</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30719 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sl     Project  pullNumber            author  \\\n",
       "0          1        beam       16917            yeandy   \n",
       "1          2       flink       13648            curcur   \n",
       "2          3   seatunnel        4683       sunxiaojian   \n",
       "3          4  bookkeeper        1225       reddycharan   \n",
       "4          5       flink        3621          dawidwys   \n",
       "...      ...         ...         ...               ...   \n",
       "30714  30715   apex-core         568          sandeshh   \n",
       "30715  30716   apex-core         568          sandeshh   \n",
       "30716  30717   apex-core         569      sanjaypujare   \n",
       "30717  30718   apex-core         569      sanjaypujare   \n",
       "30718  30719   apex-core         598  chinmaykolhatkar   \n",
       "\n",
       "                                                 comment  \\\n",
       "0      Renamed `PytorchModel` to `PytorchModelSpec` s...   \n",
       "1      But I can think of a possible case that might ...   \n",
       "2      > Please add this to `pom.xml` not in submodul...   \n",
       "3                                               changing   \n",
       "4                                                   done   \n",
       "...                                                  ...   \n",
       "30714                    Not required, changing it back.   \n",
       "30715                                               Done   \n",
       "30716                                              fixed   \n",
       "30717                                              fixed   \n",
       "30718                                               Done   \n",
       "\n",
       "                                                    path  label data_type  \n",
       "0            sdks/python/apache_beam/ml/inference/api.py      1     train  \n",
       "1      flink-runtime/src/main/java/org/apache/flink/r...      1     train  \n",
       "2      seatunnel-engine/seatunnel-engine-storage/imap...      1     train  \n",
       "3      bookkeeper-server/src/test/java/org/apache/boo...      0     train  \n",
       "4      flink-libraries/flink-cep/src/main/java/org/ap...      0     train  \n",
       "...                                                  ...    ...       ...  \n",
       "30714  engine/src/main/java/com/datatorrent/stram/Str...      0     train  \n",
       "30715  bufferserver/src/main/java/com/datatorrent/buf...      0     train  \n",
       "30716  engine/src/test/java/com/datatorrent/stram/cli...      0     train  \n",
       "30717  engine/src/test/java/com/datatorrent/stram/cli...      0     train  \n",
       "30718                                    docker/build.sh      0     train  \n",
       "\n",
       "[30719 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cbef260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>sl</th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>19230</td>\n",
       "      <td>19230</td>\n",
       "      <td>19230</td>\n",
       "      <td>19230</td>\n",
       "      <td>19230</td>\n",
       "      <td>19230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>3394</td>\n",
       "      <td>3394</td>\n",
       "      <td>3394</td>\n",
       "      <td>3394</td>\n",
       "      <td>3394</td>\n",
       "      <td>3394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "      <td>6881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "      <td>1214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          sl  Project  pullNumber  author  comment   path\n",
       "label label data_type                                                    \n",
       "0     0     train      19230    19230       19230   19230    19230  19230\n",
       "            val         3394     3394        3394    3394     3394   3394\n",
       "1     1     train       6881     6881        6881    6881     6881   6881\n",
       "            val         1214     1214        1214    1214     1214   1214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['label', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f648da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3385828",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
    "                                          do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e602c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Renamed `PytorchModel` to `PytorchModelSpec` since we renamed the old `ModelSpec` to `ModelLoader`. What do you think @ryanthompson591 ?',\n",
       "       'But I can think of a possible case that might have a problem:\\n\\nThread1: create view\\nThread2: release view, create view\\nThread1: release view (the release is way too slow)\\n\\nLet me think of this tonight. In the worst case, we can always release view before create a new one.',\n",
       "       '> Please add this to `pom.xml` not in submodule pom please.\\n\\nMove to where?',\n",
       "       ..., 'fixed', 'fixed', 'Done'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.data_type=='train'].comment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0df3d667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl                                                        13411\n",
       "Project                                                   flink\n",
       "pullNumber                                                 8468\n",
       "author                                                walterddr\n",
       "comment       I think the special case can be put outside of...\n",
       "path          flink-table/flink-table-planner-blink/src/main...\n",
       "label                                                         1\n",
       "data_type                                                   val\n",
       "Name: 13410, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[X_val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "276489e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sl                                                            2\n",
       "Project                                                   flink\n",
       "pullNumber                                                13648\n",
       "author                                                   curcur\n",
       "comment       But I can think of a possible case that might ...\n",
       "path          flink-runtime/src/main/java/org/apache/flink/r...\n",
       "label                                                         1\n",
       "data_type                                                 train\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[y_val[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed3df50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13410"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "87735a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/mdr614/anaconda3/envs/toxic_gru/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 6 - Data Type: train, Message: It isn't usually necessary to pass this in when run_benchmarks is called, as the default suffices for all existing CI use cases.  I've now improved it to detect the current repo using `git remote get-url origin` rather than hardcoding `apache/geode`.  Does this resolve your concern?, Label: 1\n",
      "Processing row 7 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 8 - Data Type: val, Message: I am not sure if client delta put will generate region version less than current local cache version. However, use \">\" might be more clear in this case. , Label: 1\n",
      "Processing row 9 - Data Type: train, Message: uh, nope... I was just guarding against the NPE that was happening..., Label: 0\n",
      "Processing row 10 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 11 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 12 - Data Type: train, Message: host and port can be set via system properties.\n",
      "In this change all that I have done is made the transport explicit. I don't think there is anything wrong with exposing that there is a Transport and what kind of transport is being used.\n",
      "\n",
      "What is incorrect is having multiple options on a Builder that if you incorrectly pick will cause failure, rather than an intuitive Builder where differences from \"normal\"  are handled as optional and there is a happy case., Label: 1\n",
      "Processing row 13 - Data Type: train, Message: This is true, but I feel expressly setting them is more clear. If they were expressly set to false in the parent class as a default that would be different, but just allowing the compiler to default their values to false kind of hides the fact that this is an intentional value. Our message class will use these values (albeit in methods defined by its parent) and it's important that they're set to false, otherwise we run the risk of improperly processing the message., Label: 1\n",
      "Processing row 14 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 15 - Data Type: train, Message: Due to previous solution, sender thread did not detect release of connection. So this is the reason why this exception did not appear in test logs. , Label: 0\n",
      "Processing row 16 - Data Type: train, Message: fixed. , Label: 0\n",
      "Processing row 17 - Data Type: train, Message: It's not used. , Label: 0\n",
      "Processing row 18 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 19 - Data Type: train, Message: typo, Label: 0\n",
      "Processing row 20 - Data Type: train, Message: see above, Label: 0\n",
      "Processing row 21 - Data Type: train, Message: deleting this test from this PRâ€¦, Label: 0\n",
      "Processing row 22 - Data Type: train, Message: We can double check this with Charlie, but the new command 'clear' has no way to remove specific entries, while the remove command does. We don't want to deprecate the whole remove command or we would be eventually losing that functionality., Label: 0\n",
      "Processing row 23 - Data Type: train, Message: hmm - I'll check into that.  Thanks Ernie, Label: 0\n",
      "Processing row 24 - Data Type: train, Message: Ok, the method is not involved in the receiver failover, I was wrong. So, you are right about the behavior of the method. And in the case of configuring same host and port for all the receivers it doesn't seem to be an issue., Label: 1\n",
      "Processing row 25 - Data Type: train, Message: I tried that but await isn't available in core. , Label: 0\n",
      "Processing row 26 - Data Type: train, Message: There are other tickets aimed at testing concurrent operations with overflow, persistence, etc. Adding more region types should be done as part of the other tickets (that's why I set the `RegionShortcut` to be configurable through parameters), not this one., Label: 0\n",
      "Processing row 27 - Data Type: train, Message: @gesterzhou : I still don't understand what these tests have to do with the fact that a `clear` operation should take less than 5 seconds. The ticket is to purely verify that `clear` can be executed while other cache operations are being executed at the same time on the same region, shouldn't we create an extra ticket to test the scenario you're talking about?., Label: 1\n",
      "Processing row 28 - Data Type: train, Message: Any reason for that?. I can certainly do it, just wondering what's the actual reasoning behind the request., Label: 1\n",
      "Processing row 29 - Data Type: train, Message: The method asserts that the data is consistent across VMs by tacking a snapshot of the region per VM and comparing it against the other running VMs, it doesn't check primaries vs secondaries.\n",
      "\n",
      "```\n",
      "    vms.forEach(vm -> vm.invoke(() -> {\n",
      "      final Map<String, String> thisSnapshot = waitForSilenceAndGetRegionSnapshot();\n",
      "      assertThat(thisSnapshot).isEqualTo(vm0Snapshot);\n",
      "      thisSnapshot.forEach((key, value) -> assertThat(value).isEqualTo(\"Value_\" + key));\n",
      "    }));\n",
      "\n",
      "```, Label: 0\n",
      "Processing row 30 - Data Type: val, Message: I just wanted on easy way to be able to change the value of SLASH and have all the tests use it. I was curious about other special characters, Label: 0\n",
      "Processing row 31 - Data Type: train, Message: No it did not. It gave the entire uri. This was in the context of the RestAccessControllerTest, Label: 0\n",
      "Processing row 32 - Data Type: train, Message: Another thing that did not do what was expected was \"request.getContextPath()\". It returned an empty string. I found an example that expected it to be the first part of the URL up to the start of {region}. , Label: 0\n",
      "Processing row 33 - Data Type: train, Message: fixed.\n",
      ", Label: 0\n",
      "Processing row 34 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 35 - Data Type: train, Message: You are right, the code is very similar (just as it happens with the peek method) but the structures on which they operate are different:\n",
      "On the SerialGatewaySenderQueue it operates on a set of transactionIds while on the ParallelGatewaySenderQueue it operates on a map of <TransactionId, bucketId>.\n",
      "\n",
      "Besides, the difference between the Serial queue and the parallel queue makes it different the access to them. On the parallel you need to pass the bucketId and the partition region. On the serial one, you need to pass the last accessed key so that you do not go through the same elements over and over because those are not removed immediately when peeked from the queue as it happens with the parallel queue.\n",
      "\n",
      "As a consequence I did not find an easy way to reuse code that did not end up making things more complex., Label: 0\n",
      "Processing row 36 - Data Type: train, Message: I finally figured out that it was not needed to change the dtd files. But I had to change \n",
      "CacheXmlGenerator so that the group-transaction-events attribute was not added to the gateway sender in case the cache.xml version was older than Geode 1.0. Without this change, the following test cases were failing:\n",
      "```\n",
      "org.apache.geode.cache.CacheXml80GatewayDUnitTest > testGatewaySenderWithSubstitutionFilter FAILED\n",
      "    org.apache.geode.cache.CacheXmlException: While reading Cache XML file:/tmp/junit10230339244221650502/XML_8_0/CacheXml80GatewayDUnitTest_testGatewaySenderWithSubstitutionFilter.xml. Error while parsing XML, caused by org.xml.sax.SAXParseException; lineNumber: 4; columnNumber: 458; Attribute \"group-transaction-events\" must be declared for element type \"gateway-sender\".\n",
      "\n",
      "org.apache.geode.cache.CacheXml70GatewayDUnitTest > testParallelGatewaySender FAILED\n",
      "    org.apache.geode.cache.CacheXmlException: While reading Cache XML file:/tmp/junit5316048290838435700/XML_7_0/CacheXml70GatewayDUnitTest_testParallelGatewaySender.xml. Error while parsing XML, caused by org.xml.sax.SAXParseException; lineNumber: 4; columnNumber: 422; Attribute \"group-transaction-events\" must be declared for element type \"gateway-sender\".\n",
      "\n",
      "org.apache.geode.cache.CacheXml70GatewayDUnitTest > testSerialGatewaySender FAILED\n",
      "    org.apache.geode.cache.CacheXmlException: While reading Cache XML file:/tmp/junit13002812494872484215/XML_7_0/CacheXml70GatewayDUnitTest_testSerialGatewaySender.xml. Error while parsing XML, caused by org.xml.sax.SAXParseException; lineNumber: 4; columnNumber: 423; Attribute \"group-transaction-events\" must be declared for element type \"gateway-sender\".\n",
      "```, Label: 0\n",
      "Processing row 37 - Data Type: train, Message: It was waiting a very small amount and setting the poll delay was not working., Label: 0\n",
      "Processing row 38 - Data Type: train, Message: Despite the name of the method `clientName()`, the value really, really, really does name the provider. If you look at the `ClientRegistration` code (line 561), you'll see that the default value for \"client name\" is `registrationId` (aka provider id).\n",
      "\n",
      "Given that, we have some options:\n",
      "\n",
      "1. Name the property pulse.oauth.clientName. I think this name is very confusing for whoever writes the properties file.\n",
      "2. Name the property pulse.oauth.providerName. This name is clearer for whoever writes the properties file, and is a bit of a puzzle for a Geode developer reading the `OAuthSecurityConfig` code. We could add a comment explaining the puzzle.\n",
      "3. Name the property pulse.oauth.providerName, but name the field `clientName`. Then this method call becomes clearer. But then a Geode developer may wonder why the field name differs from the property name. Again, we could explain with a comment.\n",
      "\n",
      "Which do you prefer?, Label: 1\n",
      "Processing row 39 - Data Type: val, Message: ugh, Label: 0\n",
      "Processing row 40 - Data Type: train, Message: I set it to the default from awaitility.  I'll double check with the team though.  For some reason I remember us having to set it really high, but it may not be necessary for Persist., Label: 0\n",
      "Processing row 41 - Data Type: train, Message: Just put an underscore before the data types and updated the key and value names.  Does that help in distinguishing?, Label: 1\n",
      "Processing row 42 - Data Type: train, Message: There's only one test in this class.  No need for the ClassRule, though we could standardize on using it if we want.  The SingleServer test expects the same content to be in the server cache for each test, so I don't think it would be appropriate to add this test to it without addressing that.  I would rather keep this class and have it focus on subscriptions., Label: 0\n",
      "Processing row 43 - Data Type: train, Message: Some \"framework\" type classes shared between the two. The \"correct\" approach is to create a shared sub module but it's one class. We could iterate on it. The goal wasn't to solve all the worlds problems today., Label: 0\n",
      "Processing row 44 - Data Type: train, Message: @jujoramos Implementing tests I realized this writeReply here is duplicated, `pingCorrectServer` is already calling it when the ping is forwarded. So this should be the cause for the error you saw about an unexpected REPLY message., Label: 0\n",
      "Processing row 45 - Data Type: train, Message: Im not sure if it can be done. The `ClientHealthMonitor` object is obtained using a static method, which cannot be mocked., Label: 1\n",
      "Processing row 46 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 47 - Data Type: train, Message: Agree., Label: 0\n",
      "Processing row 48 - Data Type: train, Message: @jujoramos if the entry is `null`, we can't tell whether it is because the disk store is removed, or somebody invokes `unlockDiskStore` before `lockDiskStore`. We don't want to throw an exception, when the entry is `null` because the disk store is removed. I would  prefer not throwing an exception when the entry is `null`., Label: 0\n",
      "Processing row 49 - Data Type: train, Message: I am not sure which exception you are talking about. I don't see `parallelStream()` and `forEach()` introduce new exception, based on the Javadoc.\n",
      "\n",
      "For test coverage, there are quite a few existing tests that already cover the single thread or multiple disk stores cases. We don't have to add new tests for that.\n",
      "\n",
      "For multi-thread test, it is a very tricky one. The purpose of this pull request is to introduce parallel disk recovery and improve the performance. We can assert that the stream should be parallel using `isParallel()`. Or we can scan the logs and make sure there are multiple thread IDs that recover the disk stores. But it doesn't serve the purpose of testing performance improvement. It doesn't guarantee that disk recovery is parallel, even if we can assert that the stream is parallel or there are multiple threads that recover the disk store. For example, if we keep the synchronized block in `DiskStoreFactoryImple` line 147, the disk stores recovery will be sequential, even though there are multiple threads recovering the disk stores., Label: 0\n",
      "Processing row 50 - Data Type: train, Message: I had thought about using `ExecutorServiceRule`. However, the return value of `doLockDiskStore()` is non-deterministic. I can't assert the return value of individual thread. I can only count and assert the number of returning values when all threads are done. I am not sure how `ExecutorServiceRule` will serve this test case., Label: 1\n",
      "Processing row 51 - Data Type: train, Message: The only reference to polyfill, which I tracked down from the email thread you shared, is in https://github.com/apache/geode-site/blob/master/website/content/js/respond.min.js\n",
      "\n",
      "Since we don't distribute geode-site in source form as part of Geode releases, do we still need it in the Geode LICENSE?, Label: 1\n",
      "Processing row 52 - Data Type: train, Message: I think gradle treats .war and .jar files as equivalent for applying this clause.  Maybe @rhoughton-pivot can offer some more insight.  I confess my understand of what NOTICE goes where is not as clear as my understanding of LICENSE..., Label: 1\n",
      "Processing row 53 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 54 - Data Type: train, Message: The exception was caught here, but the exception is itself being ignored. Seems that this was particularly changed to ignore in a previous checkin. Does this needs to change back definitely?, Label: 1\n",
      "Processing row 55 - Data Type: train, Message: Is that a particular reason set should not be mocked? It is not being iterated through, just used as a placeholder. I would like to know the reason for the requested change so that I may gain some new knowledge., Label: 1\n",
      "Processing row 56 - Data Type: val, Message: I'll have to look at why that changed- I definitely didn't change any comments intentionally, Label: 1\n",
      "Processing row 57 - Data Type: val, Message: Removed., Label: 0\n",
      "Processing row 58 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 59 - Data Type: train, Message: no good reason...reverted., Label: 0\n",
      "Processing row 60 - Data Type: train, Message: ideally, i think we can remove the key from the `RedisSetCommands` interface.  I think that's a more OO approach where the key is the identity of the object and not something you can pass in.  Right now the `RedisSetCommands` interface is more like a bag of functions.  What do you think?  \n",
      "\n",
      "I think that change is a little bit down the road, though, once all the set commands are   moved over., Label: 1\n",
      "Processing row 61 - Data Type: val, Message: It does not affect PR., Label: 0\n",
      "Processing row 62 - Data Type: train, Message: At the moment, with only one value contained, there is not a compelling reason to need a setter. But I assume it will be expanded in the future to contain other context parameters for SSL, and that users will not want to pass (n) number or arguments into the constructor. Thus, a setter. Or we can over-engineer (IMO) and create a builder for a class containing one value.\n",
      "\n",
      "That said, maybe the setter at this stage is also over-engineering., Label: 1\n",
      "Processing row 63 - Data Type: train, Message: Updated!, Label: 0\n",
      "Processing row 64 - Data Type: train, Message: Beats me why the toString is there - I didn't add it.  I do want to see the full call stack when triaging a problem like this.  Maybe it has to do with alert listeners wanting one-liners?, Label: 1\n",
      "Processing row 65 - Data Type: train, Message: You are right. What do you think? Maybe it would make sense to enable it if any redis option is specified?, Label: 1\n",
      "Processing row 66 - Data Type: val, Message: I used serializable in the name because the class is basically a copy of an existing one with the serializability being a distinguishing feature. This is one of those points of question where, should I just modify the RegionRedundancyStatus class to make it serializable?\n",
      ", Label: 1\n",
      "Processing row 67 - Data Type: train, Message: Separated the PRCacheListenerDistributedTest, Label: 0\n",
      "Processing row 68 - Data Type: train, Message: Redis groups it with other Server commands: https://redis.io/commands#server\n",
      "Should we use the same grouping as Redis?, Label: 1\n",
      "Processing row 69 - Data Type: train, Message: pulled this logic apart-  thanks, Label: 0\n",
      "Processing row 70 - Data Type: train, Message: dead code, Label: 0\n",
      "Processing row 71 - Data Type: train, Message: I wonder if it used to have fromData/toData and now does not? why else would it have showed up in this file previously?, Label: 1\n",
      "Processing row 72 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 73 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 74 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 75 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 76 - Data Type: train, Message: Nope it is failing... It doesn't like the objects in the satisfiedregion lists., Label: 0\n",
      "Processing row 77 - Data Type: train, Message: sorry hash maps., Label: 0\n",
      "Processing row 78 - Data Type: train, Message: We currently have two log messages. One says \"starting\" and shows the requested configuration. The other says \"started\" and show the actual host and port. It seems like both are worth having. Does that resolve this conversation?, Label: 1\n",
      "Processing row 79 - Data Type: train, Message: Yes, Label: 0\n",
      "Processing row 80 - Data Type: train, Message: How do I check it?, Label: 1\n",
      "Processing row 81 - Data Type: train, Message: Do you have an example from other part of the code where it is done as you are suggesting?\n",
      "Do you mean executing the function once for each member or having a function that executes on all members (the latter would seem more convenient)?, Label: 1\n",
      "Processing row 82 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 83 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 84 - Data Type: train, Message: @jinmeiliao I did not want to extend CliFunction because I intended this function to be used by users of the Java API as @gesterzhou was after.\n",
      "\n",
      "In a new commit:\n",
      "\n",
      "- I have simplified the function a bit because the first level try/catch was already taking care of any exception.\n",
      "\n",
      "- I have also changed the name of the setter/flag from setMustQueueDroppedEvents to setAllInstancesStopped. I think it is a more understandable name without knowing the low level details about the dropped events.\n",
      "\n",
      "@gesterzhou Would this solution be acceptable for you having fixed the problem in gfsh and at the same time having a function that could be called by Java API users?, Label: 1\n",
      "Processing row 85 - Data Type: train, Message: @jinmeiliao Any idea why org.apache.geode.internal.cache.wan.wancommand.StopGatewaySenderCommandDUnitTest > testStopGatewaySender_Group tests are failing?, Label: 1\n",
      "Processing row 86 - Data Type: train, Message: Do you mean `InternalDistributedMember` when you talk about `DistributedID`? I was using the `InternalDistributedMember` as the type for `locator` field. But it is a large object with many fields. We only need to identify the locator, so a String type of a member's ID should be good., Label: 1\n",
      "Processing row 87 - Data Type: train, Message: Good point!, Label: 0\n",
      "Processing row 88 - Data Type: train, Message: I need somehow to makes difference between servers, one on which cq is register and others on which it will process registerCq. The server on which cq is registered doing also incrementing active activeCqCount, but while closing or stopping it decrements on all, but with this check it will decrement just on the one server where it is incremented. I'm not sure if this is a good check but it works, and I asked on dev list for a help to differentiate on which decrement is needed, but It is concluded that this is a bug but without any idea how to differentiate it., Label: 1\n",
      "Processing row 89 - Data Type: train, Message: Sorry, I don't understand the question.  We want to decrement the node count once, but this method will be invoked multiple times for the same departing node.  If we restrict the decrement to view-changes it will only be decremented once because we only notify memberDeparted once for a member that's left the view., Label: 1\n",
      "Processing row 90 - Data Type: val, Message: If I move it out of the `if` statement it will log the departure on every invocation of this method, and I don't want to do that.  I think it will be confusing., Label: 1\n",
      "Processing row 91 - Data Type: train, Message: I updated this, but I'm wondering if we'll have access to the JAVA_TEST_PATH variable in this script?  Attempting to check it now..., Label: 1\n",
      "Processing row 92 - Data Type: train, Message: I think we wanted to leave this to be bounded. No?, Label: 1\n",
      "Processing row 93 - Data Type: train, Message: I can't tell what change you are asking for.  This PR gets the remote version first, because there would be no reason to try to get remote serialization version if that fails.  \n",
      "\n",
      "Getting the local properties (version and geodeSerializationVersion) is not prone to failure, so can be gotten exactly where needed..., Label: 0\n",
      "Processing row 94 - Data Type: train, Message: this ordering was requested by a previous review comment.  many orderings are possible but I happen to like this one because the checks are ordered from simplest and most common first to trickiest edge case last, while keeping indentation and flow control to a minimum., Label: 0\n",
      "Processing row 95 - Data Type: train, Message: some books on this subject advise against the temptation to factor out \"duplicated\" code in unit tests.  you could argue, perhaps, that we don't need as many of the mock-base tests now that the shouldConnect logic is factored out and tested separately..., Label: 1\n",
      "Processing row 96 - Data Type: train, Message: In a sense, yes. The warning was being generated because checking if `value` was null here implied that it could be null before/after this check, and that calling methods on it could produce an NPE. However, when examining the code path, `value` should never be null at this point, so the check was redundant., Label: 0\n",
      "Processing row 97 - Data Type: train, Message: Switched method synchronization to synchronize on `channel`, Label: 0\n",
      "Processing row 98 - Data Type: train, Message: How could I know if the cache is closing from inside the stop method of the ParallelGatewaySender? Is there a way?, Label: 1\n",
      "Processing row 99 - Data Type: train, Message: Running these tests on both replicate and partitioned region was one of the acceptance criteria added to this story. While technically some of these tests are covered for replicated regions in other files there are some cases in this test which covers behavior that isn't captured by existing GII tests (such as the P2P GII during clear example)., Label: 0\n",
      "Processing row 100 - Data Type: train, Message: I would prefer to just remove the magic numbers from the comment.  I don't think the method rename is warranted., Label: 1\n",
      "Processing row 101 - Data Type: train, Message: Not using += anymore., Label: 0\n",
      "Processing row 102 - Data Type: train, Message: > I think a notification includes only those stats whose values have changed. If that's correct, what we're summing here is only the _changed_ GC stats, not _all_ of the GC stats. This will work only if we're absolutely certain that every stat will change on every sample.\n",
      "> \n",
      "> See `ValueMonitor.monitorStatistics()`, which builds the notification only from updated stats.\n",
      "> \n",
      "> See `SampleCollector.sample()`, which adds a stats to the updated stats list only if the value of the stat changed from the previous sample.\n",
      "\n",
      "then what would those count/time mean though. It's not right to report just a single one of them. It's not right to sum them up either then...., Label: 1\n",
      "Processing row 103 - Data Type: val, Message: I see your point. I think it is very valid and worth changing. How about ServerVersionException or MemberVersionException?  , Label: 1\n",
      "Processing row 104 - Data Type: train, Message: Or perhaps VersionMismatchException, Label: 1\n",
      "Processing row 105 - Data Type: train, Message: I have changed the exception to ServerVersionMismatchException(members, feature name) it now produces a message \"A server's [oldMember] version was too old for : Partitioned Region Clear\", Label: 0\n",
      "Processing row 106 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 107 - Data Type: train, Message: nope that was a rebase error., Label: 0\n",
      "Processing row 108 - Data Type: train, Message: If several receivers are sharing the same ip and port, the connection will be assigned randomly by an external proxy or load balancer. Its true that using this fix value is not the best option... If for example we have 5 receivers, we could spend all the connection retries without reaching the desired receiver.\n",
      "Maybe I could increment the value of `maxAttempt` when a connection to a wrong receiver is obtained and its the first time we reach that wrong receiver. This will cause that `maxAttempt` value is dependent on the number of receivers., Label: 0\n",
      "Processing row 109 - Data Type: val, Message: > This PR changes way too many files. I didn't look at all of them. But it should have only changed 2 or 3.\n",
      "> I'm not sure I like this change because now we have the parameters in two places. We still have the switch statement in InfoExecutor that checks for each one, but now we also have a list of them in another place (ALLOWED_INFO_COMMANDS). The other confusing thing is that the INFO command does allow other keywords it just ignores them. In native redis \"INFO foobar\" does not give an error but just returns nothing. But by adding a RestrictedInputValuesParameterRequirements to INFO it makes me think that any other params would cause an error.\n",
      "\n",
      "I'll double check, but the large number of files changed should be the result of my moving the RedisConstants class into a new subdirectory (because there is now another constants files to hold specifically allowed parameters , and it seemed to  make sense to group them together).    To be addressed below,  I did forget to make the change to allow an error mesg for the class to be passed in as a parameter.  As you say, for info, the error mesg will just be an empty string, but other commands can pass in other other err msgs as is appropriate to match native  redis behavior.    \n",
      "\n",
      "I still like having the logic for the commands in the executor for now.  I see your point about the list of allowable commands being in 2 places.  Ultimately I would like to use a singleton  enum, but wasn't able to figure out how to make that work without some more playing around (let me know if you have thoughts) , Label: 1\n",
      "Processing row 110 - Data Type: train, Message: Also, I left the commit history, in an attempt to make it easy to see that a lot of files were changed when I moved the redisConstants class.  Is there a better way to communicate/show that in PRs?  just a separate PR? , Label: 1\n",
      "Processing row 111 - Data Type: train, Message: So the reason I did this, was to allow the list of a parameters to exist as a constant, and allow that constant to be passed in when the command type is declared.  Didn't seem to work with the variable arg option (but that is how I had it before introducing the constant list of params), Label: 0\n",
      "Processing row 112 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 113 - Data Type: train, Message: changed back, Label: 0\n",
      "Processing row 114 - Data Type: train, Message: Because I forgot, while we were pairing.\n",
      ", Label: 0\n",
      "Processing row 115 - Data Type: train, Message: @kohlmu-pivotal Can we get consensus on these remove statements before converting this draft to a final PR?, Label: 0\n",
      "Processing row 116 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 117 - Data Type: train, Message: We pause gw sender to prevent any interference with running processes. This was one of comments on RFC. And I am not sure that internal handling in command execution is documented for users. But if everyone agrees that this is needed, I can add., Label: 1\n",
      "Processing row 118 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 119 - Data Type: train, Message: The reason is the same as previous one., Label: 1\n",
      "Processing row 120 - Data Type: train, Message: The reason is the same as previous one., Label: 1\n",
      "Processing row 121 - Data Type: train, Message: fixed. , Label: 0\n",
      "Processing row 122 - Data Type: train, Message: This is a `private` method. We know, in this method, that if `usages == 0` that `destruct()` has been called (in the past), since: the constructor started us with `counter.get() == 1` and `addReference()` is called for every `alias` call.\n",
      "\n",
      "Because we know `destruct` has been called we know that `isClosed.get()` is already true., Label: 0\n",
      "Processing row 123 - Data Type: train, Message: This suggestion seems intuitive enough, however, where this is called from `Connection.readAck()` we rely on the current \"no-op\" behavior. If we were to throw here then it would break `readAck()` using the `NioPlainEngine`.\n",
      "\n",
      "The only other place we call `getUnwrappedBuffer()` is from `clearSSLInputBuffer()` and in that case we know we are dealing with the `NioSslEngine` (not the `NioPlainEngine`.) We considered moving this method from the interface to the (`NioSslEngine`) implementation (and leaving it off `NioPlainEngine` entirely.) That would have been fine for `clearSSLInputBuffer` but would have left us with ugliness in the `readAck()` call site., Label: 0\n",
      "Processing row 124 - Data Type: train, Message: done!, Label: 0\n",
      "Processing row 125 - Data Type: train, Message: The `close()` method is a critical section. And after a thread has exited that critical section, the next thread entering it will skip all the actual close logic.\n",
      "\n",
      "There is no possible interference between the close logic and e.g. `wrap()`, specifically in their use of the output buffer a.k.a. `myNetData` (the `ByteBuffer` managed by `outputSharing`) because both `wrap()` and `close()` acquire a reference to that buffer via `ByteBufferSharingImpl.open()` and `ByteBufferSharingImpl.open(long time, TimeUnit unit)` respectively. Those methods call `lock()`/`tryLock(long time, TimeUnit unit)` on the `ReentrantLock` before returning.\n",
      "\n",
      "Does that help?, Label: 1\n",
      "Processing row 126 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 127 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 128 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 129 - Data Type: train, Message: good catch- not sure if that was a merge error?  weird  , Label: 1\n",
      "Processing row 130 - Data Type: val, Message: will do, Label: 0\n",
      "Processing row 131 - Data Type: val, Message: Can ExecutorService be used in a server vm? I tried using the ExecutorService but was failed as the rule not applied in a server vm., Label: 1\n",
      "Processing row 132 - Data Type: train, Message: It definitely couldn't hurt to add it.  I feel like this test needs something more, but I'm not sure what.  The intent was mainly to show that `processProfilesQueuedDuringInitialization()` wouldn't result in an `ArrayIndexOutOfBoundsException` when given the serials that would be returned if `buckets` were `null` when `getBucketSerials()` is called.  What do you think?, Label: 1\n",
      "Processing row 133 - Data Type: val, Message: I just added that verification!, Label: 0\n",
      "Processing row 134 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 135 - Data Type: val, Message: We can give it another name, like Timer? This is an internal interface made accessible for testing purposes, so I am not too concerned about the naming or break it into another interface., Label: 0\n",
      "Processing row 136 - Data Type: val, Message: It is meant to cover both time values, but if you think it's readable otherwise...., Label: 0\n",
      "Processing row 137 - Data Type: train, Message: I think I get your point, we already wasted some time, why don't we give it another try? It all boils down to what you think is right or tolerable., Label: 1\n",
      "Processing row 138 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 139 - Data Type: train, Message: Functionally it's the same. I agree with LGTM that it's technically redundant... but I think it's marginally more readable, making clear to a human reading it what the intent is. Perhaps we could add a comment instead?, Label: 1\n",
      "Processing row 140 - Data Type: train, Message: I had the same thought. I was even concerned about constantly adding and removing from the concurrent map. We could just use the frequency of the monitor thread to do the time work. For example if it finds an AbstractExecutor in the map that it has not seen before then the monitor thread could set the time it first saw it. If later monitor samples see it again it could use this time (i.e. the one the monitor set) to determine if it is stuck. This could even be done without timestamps. Just a simple counter the monitor incs and the p2p reader thread clears. If the monitor thread is waking up at a fixed interval then you know the thread has been stuck for at least that much time. I like your idea of having custom code in P2PReaderExecutorGroup for this. When I was thinking about it I thought I would need to change the behavior of all the existing threads being monitored. Thanks for the feedback!, Label: 0\n",
      "Processing row 141 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 142 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 143 - Data Type: train, Message: ok, maybe it makes most sense to wait wait until 5278 is pull merged, and then adapt off that.  @kirklund, Are you expecting to have time to get that through in the near future?   , Label: 1\n",
      "Processing row 144 - Data Type: train, Message: Same logic as in basicHandlePrimaryEntry, Label: 0\n",
      "Processing row 145 - Data Type: train, Message: It would bee nice to run a full regression with this change to see if it will cause another hang. Right now I don't think I am fully qualified to explain to you on that., Label: 1\n",
      "Processing row 146 - Data Type: train, Message: done!, Label: 0\n",
      "Processing row 147 - Data Type: train, Message: fixed. , Label: 0\n",
      "Processing row 148 - Data Type: train, Message: Fixed. , Label: 0\n",
      "Processing row 149 - Data Type: val, Message: Hi @DonalEvans , first thanks for your comments. Related to this comment, I haven't made the conversion, because I have created new TC for rollback where this variable is used. Hope this is ok?, Label: 0\n",
      "Processing row 150 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 151 - Data Type: train, Message: I think I just did this in the HVALS PR, Label: 0\n",
      "Processing row 152 - Data Type: train, Message: If it is redundant it is noise., Label: 0\n",
      "Processing row 153 - Data Type: train, Message: Yes, seems odd we track the number. I wonder if there is really any savings by this complexity. Outside my scope but at least now it is obvious what this counter is for., Label: 1\n",
      "Processing row 154 - Data Type: train, Message: Yes, it's not to ensure the clear will happen during the createIndex, it's just to increase the possibility. The test's was originally created to reproduce the issue fairly reliably, and it has served that purpose. Me and Kirk tried to find a way to make it a definite failure, but we found out it's not gonna be easy. So now the test is actually not relying on the race condition to happen (even though it will happen in most cases). It's actually asserting on the fact that the member received the right messages. , Label: 0\n",
      "Processing row 155 - Data Type: train, Message: is it wrong to use 2? I want to have secondary members to also store data., Label: 1\n",
      "Processing row 156 - Data Type: val, Message: will do, Label: 0\n",
      "Processing row 157 - Data Type: train, Message: will do -  thanks-  not sure how that got changed... , Label: 1\n",
      "Processing row 158 - Data Type: val, Message: will move them, Label: 0\n",
      "Processing row 159 - Data Type: train, Message: this was the CI failure that confused me. it took a minute to figure out what was going on, Label: 1\n",
      "Processing row 160 - Data Type: val, Message: Thanks, I didnt know that plugin!, Label: 0\n",
      "Processing row 161 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 162 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 163 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 164 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 165 - Data Type: train, Message: yes!  done!, Label: 0\n",
      "Processing row 166 - Data Type: train, Message: the downside to doing it with the queue is that it makes it essentially synchronous, Label: 0\n",
      "Processing row 167 - Data Type: train, Message: >.< oops. I think I'll go ahead and merge it and fix it in my next PR. don't want to send it back through CI, Label: 0\n",
      "Processing row 168 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 169 - Data Type: train, Message: I think that test case is not realistic. Is it realistic that locator at restart will change its name. But if this is the case, and also if we are now storing member name, then in that case we should store new member name. I can change this, so test case passes, but this will be inconsistent behavior., Label: 1\n",
      "Processing row 170 - Data Type: train, Message: I think you are right. There is trouble with the != queries.\n",
      "Shouldn't they not use the index?\n",
      "According to the documentation, indexes are not used in expressions that contain NOT(https://geode.apache.org/docs/guide/19/developing/query_index/indexing_guidelines.html) . I think the same could be done for queries using != which is very similar to using NOT.\n",
      "Nevertheless, when I checked the code, it seems that queries with NOT also used the indexes., Label: 1\n",
      "Processing row 171 - Data Type: train, Message: I have pushed a new commit with some test cases to compare the results of queries with the indexes and without them.\n",
      "As you can see, the tests when indexes are used fail.\n",
      "The funny thing is that these test cases also fail if run against the latest code in development. So I think there is something not working right with the indexes, with or without my change., Label: 1\n",
      "Processing row 172 - Data Type: val, Message: Thank you for the comment!\n",
      "\n",
      "Currently, `CreateGatewaySenderCommand` can only manipulate with the initial state of gateway-sender by using deprecated `--manual-start` parameter (default value is false). This parameter does not update the new `state` parameter.\n",
      "\n",
      "As you suggested, we could also add `--state` parameter in `create gateway-sender` command. We could maybe then completely remove the depreciated `--manual-start` parameter, since `--state` will do the same thing (and even more considering \"paused\" state) as `--manual-start` parameter. As it is now, these two parameters have functional conflict which is currently resolved as described in RFC under \"Solution\" chapter: https://cwiki.apache.org/confluence/display/GEODE/Persist+gateway-sender+state+within+Cluster+Configuration?moved=true\n",
      "\n",
      "What do you think? Do you see benefit in having --state parameter in create gateway-sender command?, Label: 1\n",
      "Processing row 173 - Data Type: train, Message: Actually these should not be there. I pulled them... Too much task switching sorry., Label: 0\n",
      "Processing row 174 - Data Type: train, Message: That is the problem we are seeing. The customer is having timestamps far into the future. That is why we are putting this change in... So once we subtract now from oldest.getVersionTimeStamp() the number is far greater than EXPIRY_TIME. This is intended to catch that condition..., Label: 0\n",
      "Processing row 175 - Data Type: train, Message: Yup, I lost the comments some how, so I am putting them in now. I agree this abates the symptom. I don't prefer this approach, but at the same time, this will help people with their problem that should not be happening. We were suspicious this had to do with clock time adjustments, but we are still theorizing. This will keep their system from locking up though for a condition we can safely handle in this part of the system with sanity checking. Otherwise intervention is required when this problem arises. Also to be blunt, the current approach while fast is lacking in fault tolerance., Label: 0\n",
      "Processing row 176 - Data Type: train, Message: They are only public for test. Other than that, I am not sure let me look at it., Label: 1\n",
      "Processing row 177 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 178 - Data Type: train, Message: What did you mean by this logic to determine the expected behaviour of the query based on the Geode version?  In versions before Lucene is upgraded, the test(always doing the upgrade to the newest version) is not changed and it works. Maybe you think that we need this change for the future version of Geode when Lucene format will be the same, and test between that versions should work as before this changes? Or you mean something else?, Label: 1\n",
      "Processing row 179 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 180 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 181 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 182 - Data Type: val, Message: Done!, Label: 0\n",
      "Processing row 183 - Data Type: train, Message: I added such a thread - maybe not entirely elegantly yet - and altered fillMemory() in a couple ways. First, it does multiple forceGC() calls, to help ensure that we're filling the memory with our Redis data. Secondly, it loops multiple times with progressively smaller chunks of data, to help ensure every nook and cranny is filled.\n",
      "\n",
      "Haven't seen it fail YET, but I have to admit I'm still worried about flakiness., Label: 1\n",
      "Processing row 184 - Data Type: val, Message: fillMemory() has been significantly restructured since this, but point taken!, Label: 0\n",
      "Processing row 185 - Data Type: train, Message: Yeah, that was iffy, but it's yanked now., Label: 0\n",
      "Processing row 186 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 187 - Data Type: train, Message: added back.  thanks, Label: 0\n",
      "Processing row 188 - Data Type: train, Message: wilco\n",
      ", Label: 0\n",
      "Processing row 189 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 190 - Data Type: train, Message: Actually, the test without the changes is flaky. If you run it several times you will see it failing a certain percentage of times., Label: 0\n",
      "Processing row 191 - Data Type: train, Message: Unfortunately, I have not found a way.\n",
      "The flakyness has to do with some randomness in the implementation of the `ConcurrentSkipListMap::putIfAbsent()` method invoked from `MemoryIndexStore::updateMapping()` on the `valueToEntriesMap` member that seems to traverse the Map in different order in different executions.\n",
      "With the bug in the Comparator, when adding an entry with `UNDEFINED` key to the `valueToEntriesMap`, when there was already an entry with that key in the Map, sometimes that was not detected (an entry with `NullToken` was found first and that prevented looking for the `UNDEFINED` key in another entry) and several entries with the `UNDEFINED` key ended up in the Map., Label: 0\n",
      "Processing row 192 - Data Type: val, Message: Made it fixed, Label: 0\n",
      "Processing row 193 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 194 - Data Type: train, Message: there was a merge conflict when I did the cherry-pick originally.  I guess I didn't resolve the conflict right the firth time.  I just re-did the cherry-pick. and re-pushed.  Hopefully this is happier  , Label: 0\n",
      "Processing row 195 - Data Type: train, Message: this pr didn't seem to pick up the changes (probably because I deleted the branch and re-created it).  opened the new cherry pick in a new pr https://github.com/apache/geode/pull/6127.  will close this one, Label: 0\n",
      "Processing row 196 - Data Type: train, Message: I agree with you. The order should matter and `containsExactlyInAnyOrder` seems to disregard this. Given that this file has only cosmetic changes (who knows why the formatting changed now, given that spotless is always applied) and no code changes have been made in this file, I would hope the review would be as such.\n",
      "\n",
      "I would love to fix all problems in all files that I touch, but in all honesty, I don't have time to fix them all., Label: 1\n",
      "Processing row 197 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 198 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 199 - Data Type: train, Message: There already was a conversation about the bucket number. It was switched away from being a ^2., Label: 0\n",
      "Processing row 200 - Data Type: train, Message: Ditto, Label: 0\n",
      "Processing row 201 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 202 - Data Type: train, Message: Due to the change in the order of parameters in `ChangeLogLevelCommand`, the memberId is returned in second position by the parser, so I had to modify the array index from 0 to 1. , Label: 0\n",
      "Processing row 203 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 204 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 205 - Data Type: train, Message: Yes, sorry.., Label: 0\n",
      "Processing row 206 - Data Type: train, Message: I don't want to change \"nodes\" to show the number of \"servers\".\n",
      "How it works by now?\n",
      "If we have 2 locators and 2 servers the VisibleNodes attribute has the following values:\n",
      "```\n",
      "Locator 1: 2 (count Server 1 and Server 2)\n",
      "Locator 2: 2 (count Server 1 and Server 2)\n",
      "Server 1: 3 (count Server 2, and twice Server 1)\n",
      "Server 2: 3 (count  Server 1, and twice Server 2)\n",
      "```\n",
      "\n",
      "With my changes it will count every member without itself:\n",
      "```\n",
      "Locator 1: 3 (count Locator 2, Server 1, and Server 2)\n",
      "Locator 2: 3 (count Locator 1, Server 1, and Server 2)\n",
      "Server 1: 3 (count Locator 1, Locator 2, and Server 2)\n",
      "Server 2: 3 (count Locator 1, Locator 2, and Server 1)\n",
      "```\n",
      "What do you mean by the number of \"peer-to-peer\" processes in the cluster? \n",
      "Is that include both locators and servers?, Label: 1\n",
      "Processing row 207 - Data Type: train, Message: In the description of this attribute state the following:\n",
      "`The current number of nodes in this distributed system visible to this member.`\n",
      "\n",
      "What are nodes there, both locators and servers or just servers?\n",
      "Also, should the current server be visible to itself?\n",
      "\n",
      "If we go with @jinmeiliao proposal we should change the description to be more clear.\n",
      "`The current number of servers in this distributed system visible to this member.`\n",
      ", Label: 1\n",
      "Processing row 208 - Data Type: train, Message: I can add-  is there an agreed upon existing verbage? or should I just write one? , Label: 1\n",
      "Processing row 209 - Data Type: train, Message: and since we are already using a superscript for slowlog, I would assume another superscript for INFO (as opposed to asterick)?\n",
      " , Label: 1\n",
      "Processing row 210 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 211 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 212 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 213 - Data Type: train, Message: Cool!, Label: 0\n",
      "Processing row 214 - Data Type: train, Message: done!, Label: 0\n",
      "Processing row 215 - Data Type: train, Message: from discussion with @ringles: it seems like writing it over the wire would save us some time recomputing the value. as the data set gets bigger, that could take us a good chunk of time. Is there a disadvantage to serializing it that we are not aware of?, Label: 1\n",
      "Processing row 216 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 217 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 218 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 219 - Data Type: train, Message: It does not adequately track the original host name.  There is a unit test that failed after setting a bind address of 127.0.0.1 and InetSocketAddress somehow converted that to \"localhost\"., Label: 1\n",
      "Processing row 220 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 221 - Data Type: train, Message: Interesting. Intellij didn't note the other issue. I just fixed the one spelling error., Label: 0\n",
      "Processing row 222 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 223 - Data Type: train, Message: My understanding is that this is an external interface. I have changed nothing regarding precision. I just moved the decision of precision loss down to the interface. The core of stats went away from ints a long time ago., Label: 0\n",
      "Processing row 224 - Data Type: train, Message: I left the int because I didn't want to change the external interface., Label: 0\n",
      "Processing row 225 - Data Type: train, Message: Also by mistake! Thanks!, Label: 0\n",
      "Processing row 226 - Data Type: train, Message: By mistake! Thanks!, Label: 0\n",
      "Processing row 227 - Data Type: val, Message: Thi test checks that it is impossible to do lucene query with different version of the servers. It will failed in ` void verifyLuceneQueryResults(String regionName, int expectedRegionSize)` while doing the following assertion:\n",
      "`    assertTrue((Boolean) luceneService.getClass()\n",
      "        .getMethod(\"waitUntilFlushed\", String.class, String.class, long.class, TimeUnit.class)\n",
      "        .invoke(luceneService, INDEX_NAME, regionName, 60, TimeUnit.SECONDS));`\n",
      "I'm not sure how to change this assertion in the test to verify this assertion will failed., Label: 1\n",
      "Processing row 228 - Data Type: train, Message: The problem with this is on older versions before getDistributionManager is introduced, and it failed with NoSuchMethodError. For the newer version(after 1.5.0) it throws NullPointerException in the same place., Label: 0\n",
      "Processing row 229 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 230 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 231 - Data Type: train, Message: Removing this error response return would require returning `null` which just doesn't look right to me (although functionally it will never get hit). However I've chosen to remove the subcommand check from the param validator in favor of keeping this code. This also means there is just one place to update when subsequent subcommands are added., Label: 0\n",
      "Processing row 232 - Data Type: train, Message: I didn't want to take a chance on an NPE since hasSeenEvent can be called with a null event in the case that Naba mentioned. One of the other cases that don't use the event posDup can still apply., Label: 0\n",
      "Processing row 233 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 234 - Data Type: train, Message: because I need to make sure processChunk is called. If I did not move out of the loop, if the entryCount is 0, the testHook will not be called. I don't want to introduce another testHook. \n",
      "\n",
      "I care if processChunk is call more than if there's any data in chunk. , Label: 0\n",
      "Processing row 235 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 236 - Data Type: val, Message: And _testcontainers_ errors out if they are left in place..., Label: 0\n",
      "Processing row 237 - Data Type: train, Message: I could narrow it down, but it was very surprising to me that a \"read\" operation would throw a WriteAbortedException and I wanted to cover all the bases., Label: 1\n",
      "Processing row 238 - Data Type: val, Message: I have refactored the assertion about the setter and getter names as:\n",
      "```\n",
      "String attrNameInGetterSignature = getter.getName().substring(3);\n",
      "assertThat(setter.getName()).contains(attrNameInGetterSignature);\n",
      "```\n",
      "I think now its easier to understand what it is being checked there., Label: 1\n",
      "Processing row 239 - Data Type: train, Message: the removal of the keyword 'this' does not make code any cleaner... in actual fact, it makes it harder to read, as we are spoilt with IDE's that indicate fields and properties in different colors. As for reading this as text, makes it evident that we are referring to the field defined on the CommandManager., Label: 0\n",
      "Processing row 240 - Data Type: train, Message: removed the check, Label: 0\n",
      "Processing row 241 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 242 - Data Type: train, Message: ok., Label: 0\n",
      "Processing row 243 - Data Type: train, Message: ok., Label: 0\n",
      "Processing row 244 - Data Type: val, Message: Hmm. Less than 10 will always be true. This test is basically unnecessary if a fast machine can result in 0 nanoseconds. I find it hard to believe though that a machine can do a clear in 0 nanoseconds. Is that really the case?, Label: 1\n",
      "Processing row 245 - Data Type: train, Message: I would get a failure from stress new test when starting up a server, complaining that a server could not be started because the port was in use. Stopping the servers after the tests completed appears to have resolved that. This follows the pattern I saw in other tests for example HScanDUnitTest, Label: 0\n",
      "Processing row 246 - Data Type: train, Message: ~As discussed earlier, the failure in HashesAndCrashes was due to a redis server binding to a port that was already claimed by the locator. Grabbing the port from getRandomAvailableTCPPorts after the locator was started appears to have resolved this failure. Thanks!~\n",
      "\n",
      "The failure still exists, Label: 0\n",
      "Processing row 247 - Data Type: train, Message: Leftover from some debugging - now gone., Label: 0\n",
      "Processing row 248 - Data Type: train, Message: Arg. Sorry, forgot to push, Label: 0\n",
      "Processing row 249 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 250 - Data Type: train, Message: But now it's back again because ... java doesn't like it on a line that isn't a declaration ðŸ¤· , Label: 0\n",
      "Processing row 251 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 252 - Data Type: train, Message: Actually it assumes that members (nodes) have at least one bucket. I'd prefer to have just one data structure that handles both slots:nodes and nodes:slots but I can't figure out how to avoid a bunch of redundancy. , Label: 1\n",
      "Processing row 253 - Data Type: train, Message: I thought the RETURNS_DEEP_STUBS should do the trick, but the test runs failed:\n",
      "https://concourse.apachegeode-ci.info/teams/main/pipelines/apache-develop-pr/jobs/StressNewTestOpenJDK11/builds/1902, Label: 0\n",
      "Processing row 254 - Data Type: train, Message: Deleted., Label: 0\n",
      "Processing row 255 - Data Type: val, Message: Yes this makes sense. In this case If I understood correctly we would have to extend TXCommitMessage message with notificationOnly list of servers. Is this correct? This seems like better solution, and I think it is manageable. Also I have posted comment  https://github.com/apache/geode/pull/6477#issuecomment-848723153 with another alternative which would require impact only on receiver side (adjunct member). Could you please take a look and comment?, Label: 0\n",
      "Processing row 256 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 257 - Data Type: train, Message: Working on it now..., Label: 0\n",
      "Processing row 258 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 259 - Data Type: val, Message: Ahh-- I do see that this allows to not have to cast the channels in the calling method though... I take it back, I like it better returning the ChannelSubscription..., Label: 0\n",
      "Processing row 260 - Data Type: train, Message: thanks-  for some reason I didn't find that file when I looked for it-  thought maybe it had been removed.  \n",
      "\n",
      "as far as the \"help\" bit, yeah, when/if we implement help I think we should add that bit back to message.  It's not in the group of stories currently pointed.  I think leaving it off the error message until we implement help makes the most sense?    at that point, I think, it would make sense to genericize all the subcommands error messages....   , Label: 1\n",
      "Processing row 261 - Data Type: train, Message: babar the elephant, Label: 0\n",
      "Processing row 262 - Data Type: train, Message: I had a hard time interpreting that too. My thought on it was that things will get expired every 3 minutes, as long as their expiration has been reached, at a resolution of 1 second. If you read the line before that, it says that the active expiration is accurate to the ms, but there's no guarantee it will be called every 1 ms or anything.\n",
      "Do you think there's a better way to say this? It shouldn't be this difficult to parse, Label: 1\n",
      "Processing row 263 - Data Type: train, Message: The issue I see with the above methods is that each thread loop on the same member in order. The second thread always trying to remove the first thread just removed (understandably it is how we use the synchronization to prevent concurrent modification on the sorted set)., Label: 0\n",
      "Processing row 264 - Data Type: train, Message: yeah I thought I had deleted them already. must have messed up the rebase, Label: 0\n",
      "Processing row 265 - Data Type: val, Message: added!, Label: 0\n",
      "Processing row 266 - Data Type: train, Message: lol I already forgot about it since we talked about it 10 minutes ago ðŸ˜… wilco, Label: 0\n",
      "Processing row 267 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 268 - Data Type: train, Message: Yes, depending on how we filter out invalid floats. We could add it to the members map, then fault out adding it to the scoreSet. Swapping the order of which one we add _should_ avoid that., Label: 0\n",
      "Processing row 269 - Data Type: train, Message: I'm so tired of doing rebases. this is the kind of stuff that git always messes up, Label: 0\n",
      "Processing row 270 - Data Type: train, Message: RIP, Label: 0\n",
      "Processing row 271 - Data Type: train, Message: Thanks for the observations, Bill! Right before the `\"Failed to send message...\"` log in `DistributionImpl.directChannelSend()`, we perform the following check:\n",
      "```\n",
      " if (!membership.hasMember(member) || (th instanceof ShunnedMemberException)) {\n",
      "          continue;\n",
      "  }\n",
      "```\n",
      "...which effectively skips the log for those cases.  The `ShunnedMemberException` is the one we encountered here.  We could log before checking those cases or log something different within that if block and remove the log we added to `ClusterDistributionManager`.  What do you think is appropriate?\n",
      "\n",
      "Regarding the \"result processor\"-specific message, that is a good question.  The \"result processor\" in this context is `ReplyProcessor21` (so perhaps that should say `reply processor` instead).  I think that's a good call out though, we probably shouldn't assume that if a message is sent there is always a reply processor involved.  It seems like we should remove this log anyway in favor of logging in `DistributionImpl`, so maybe we could just stick with the `\"Failed to send message...\" log there., Label: 1\n",
      "Processing row 272 - Data Type: train, Message: I've removed the log from `ClusterDistributionManager` and moved the `DistributionImpl` log before the if block.  Let me know if y'all think this is the right approach. @jdeppe-pivotal @Bill , Label: 0\n",
      "Processing row 273 - Data Type: train, Message: It is being called in doZAddIncrForAllMembers(increment1, increment1);, Label: 0\n",
      "Processing row 274 - Data Type: train, Message: The boolean value hitJedisClusterIssue2347 needs to be referenced by to the caller. There does not seems to be a clean way to do it. , Label: 0\n",
      "Processing row 275 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 276 - Data Type: val, Message: May I ask why? For this test in particular, the use of soft assertions is helpful in determining in one run what's going wrong with the sizing, as if we just failed on the first assertion, it wouldn't be clear if the size was off by a constant amount or if there was a compounding error in the calculation., Label: 1\n",
      "Processing row 277 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 278 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 279 - Data Type: train, Message: Agreed, I tweaked the assertions., Label: 0\n",
      "Processing row 280 - Data Type: train, Message: Gone., Label: 0\n",
      "Processing row 281 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 282 - Data Type: train, Message: Yes. As a dunit, this test isn't doing anything more than the regular integration test is doing., Label: 0\n",
      "Processing row 283 - Data Type: val, Message: The problem is, where would that list of threads be kept? It could be in a static variable but it does not look like the cleanest solution.\n",
      "If we open the door to using static variables to identify the command to cancel we could also explore a solution I considered in the past that did not require to run the copy region code in a new thread in order to be able to cancel it later. We could have a static variable that would be used to specify an execution to be canceled (identified by senderId and region) and the function could check after each batch is sent if that variable indicates that the function should be canceled.\n",
      "This way the identification of the command to cancel would be more efficient than what we are doing currently and we would get rid of the new thread to execute the code.\n",
      "\n",
      "Anyway, I am not sure which alternative is better., Label: 1\n",
      "Processing row 284 - Data Type: train, Message: @kirklund Thanks for the advice. The problem here is that you could have several instances of this function running and you may want to stop one of them. How could you access the specific instance from a command in order to call the shutdown() method of the `ExecutorService`?\n",
      "In order to use a more usual way to cancel the threads, I have added static fields to the function class with the `ExecutorService` to be used by any instance of this function and the current executions (`Futures`) so that, if one of them is required to be canceled, you can identify the execution by the senderId and region, get the Future and then invoke cancel on it.\n",
      "You could also cancel all executions by invoking shutdownNow() on the executor as you suggested. Nevertheless, if you do that, you would not be able to create new executions.\n",
      "\n",
      "I do not like using static variables but I have not found any better way., Label: 1\n",
      "Processing row 285 - Data Type: train, Message: thank you-  yes, simpler!, Label: 0\n",
      "Processing row 286 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 287 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 288 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 289 - Data Type: val, Message: Removed, Label: 0\n",
      "Processing row 290 - Data Type: train, Message: I'm not sure about that, but I'd prefer to keep all the error messages together., Label: 1\n",
      "Processing row 291 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 292 - Data Type: val, Message: Doh!, Label: 0\n",
      "Processing row 293 - Data Type: train, Message: Does this work?\n",
      "```\n",
      "          \"The pdx field \" + pf + \" is an array whose component type \"\n",
      "              + value.getClass().getComponentType()\n",
      "              + \" can not be converted to JSON.\");\n",
      "```\n",
      "I'm not sure I like trusting that the caller made sure that value.getClass().isArray() was true though., Label: 1\n",
      "Processing row 294 - Data Type: train, Message: I will leave it as it was as I did not know that the method could take a Throwable as a second parameter., Label: 0\n",
      "Processing row 295 - Data Type: train, Message: Actually, that method is invoked from `WANTestBase::createSender()` when `groupTransactionEvents` is `true`.\n",
      "I added it to be able to use a high value for the parameter to avoid flakyness in test cases that have `groupTransactionEvents` set to true. Setting this parameter for test cases using a System Property would not be very convenient.\n",
      "For uses other than test cases, I think that having the System Property would be enough., Label: 0\n",
      "Processing row 296 - Data Type: train, Message: \"Incredibly pedantic\" is my favourite kind of review :P, Label: 0\n",
      "Processing row 297 - Data Type: train, Message: Yeah, I agree. I saw all that and said nope! , Label: 0\n",
      "Processing row 298 - Data Type: train, Message: Even more so, it was wrong code. Notice the original max constant was off by 1. , Label: 0\n",
      "Processing row 299 - Data Type: train, Message: Any call that pulls the DS or Cache out of the ether should be deprecated. I am not scoping this these cleanups to try and resolve all of that at this time. There is a very old Geode addressing that issue., Label: 1\n",
      "Processing row 300 - Data Type: train, Message: I see ZRANGE calling it with true. In general, operations that read data update stats, operations that change data do not. So zadd, zrem, zincrby change data and therefore don't update stats., Label: 0\n",
      "Processing row 301 - Data Type: train, Message: Hope the new one is the kind of thing you have in mind..., Label: 0\n",
      "Processing row 302 - Data Type: train, Message: Got a few of them earlier, all done now!, Label: 0\n",
      "Processing row 303 - Data Type: train, Message: Also corrected!, Label: 0\n",
      "Processing row 304 - Data Type: train, Message: Currently, the exception thrown here will ultimately get handled in `ExecutionHandlerContext.getExceptionResponse()` where it will result in an error message returned to the client with the message \"The server had an internal error please try again\". This definitely doesn't seem correct, since trying again will just result in the same error, but none of the currently existing error responses we have seem right either, and I'm having a hard time find a list of existing Redis error messages to see if any of them would be a better fit. It's also not practical to test what Redis actually does in this situation, given that would require a Redis hash with over a billion entries. I'll have a look at the Redis source and see if I can figure out what the behaviour would be in this situation., Label: 1\n",
      "Processing row 305 - Data Type: train, Message: I changed the int to AtomicInteger. In every VM, there is only one AuthInit object that gets created and used. I tried to make it an instance field, but since there is no easy way to get this object out of the cache and examine its attributes, I made this a static field, Label: 0\n",
      "Processing row 306 - Data Type: train, Message: what's a detached javadoc?, Label: 1\n",
      "Processing row 307 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 308 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 309 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 310 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 311 - Data Type: train, Message: I'm not sure I follow your reasoning here. 1.13.1 released with ordinal 120. 1.13.2 released with ordinal 121.\n",
      "\n",
      "The problem here is that the name of this constant is wrong. It should be called GEODE_1_13_2_ORDINAL, because that is the release in which this ordinal was used.\n",
      "\n",
      "I guess there is a question of whether some external code is using this constant, since there will no longer be a constant named GEODE_1_13_1_ORDINAL. However this is an internal class, so it can be expected to change - in fact this whole class was renamed in 1.14. The most likely project to use these internal constants would be spring data geode, but that project does not use this internal class., Label: 1\n",
      "Processing row 312 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 313 - Data Type: train, Message: @ringles Could you point me at the methods you're referring to?, Label: 0\n",
      "Processing row 314 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 315 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 316 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 317 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 318 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 319 - Data Type: train, Message: I think that GeodeAwaitility is used only for the test (as states in the description).\n",
      "\n",
      "```\n",
      "/**\n",
      " * Utility to set consistent defaults for {@link org.awaitility.Awaitility} calls for all Geode\n",
      " * tests.\n",
      " */\n",
      "public class GeodeAwaitility {\n",
      "\n",
      "```\n",
      "Also, I cannot find any usage instead of tests., Label: 0\n",
      "Processing row 320 - Data Type: train, Message: The mock implementation is not serializable. Another fix would be to change the declaration to `transient`., Label: 0\n",
      "Processing row 321 - Data Type: train, Message: The reason for the java assert is not to test something but to get rid of a warning in the gutter. I assume that this is a valid use of java asserts?, Label: 1\n",
      "Processing row 322 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 323 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 324 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 325 - Data Type: train, Message: these static byte arrays came straight from the jdk so our old code was already using them when it called String.valueOf(long) which called Long.toString(long) which ended up in this code. Even the other code you commented on was for the most part from the jdk and was using '0' and '-'. So either the old code was already broken or the new code is okay., Label: 0\n",
      "Processing row 326 - Data Type: train, Message: After looking at the code here, I did a bit of refactoring and broke things up in a (hopefully) more logical way, so we no longer have this method., Label: 0\n",
      "Processing row 327 - Data Type: val, Message: Good point. I realized these names are fine but in this case we should be doing \"fastWhileEachValue\" instead of \"fastWhileEach\". We don't need the keys from members only the values since each value has both its member and score. After changing to fastWhileEachValue the names now make sense., Label: 0\n",
      "Processing row 328 - Data Type: train, Message: You may be right about this but I think I'll not include that in this pr. I'm actually okay with how this class currently does it because the return type is not ArrayList., Label: 0\n",
      "Processing row 329 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 330 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 331 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 332 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 333 - Data Type: train, Message: Agree., Label: 0\n",
      "Processing row 334 - Data Type: train, Message: Generally, I don't expect the MBeanServer to be null for `jmxConnectorServer`. The MBeanServer is from line 369 and put in the `jmxConnectorServer` constructor in 416. This `if` statement is a guard in case some other code path leads to a null MBeanServer in `jmxConnectorServer`, then we still need to set the MBeanServer for the `controller`. However, we don't want to set MBeanServer twice for the `controller`, which is the original bug., Label: 0\n",
      "Processing row 335 - Data Type: val, Message: Agree., Label: 0\n",
      "Processing row 336 - Data Type: train, Message: I think I addressed this, but let me know if I didn't., Label: 1\n",
      "Processing row 337 - Data Type: val, Message: this is in geode-junit, I thought it's test code, is it product apii?, Label: 1\n",
      "Processing row 338 - Data Type: train, Message: Yes, that's the reason.\n",
      "\n",
      "Let me see if I can change the rule ..., Label: 1\n",
      "Processing row 339 - Data Type: val, Message: one is to test single user mode, the other is to test multi-user mode. I changed methods name and added more comment to clear out the confusion., Label: 0\n",
      "Processing row 340 - Data Type: train, Message: I think what all the executors want from Command in regards to the List<byte[]> is the arguments. Most all of them probably never look at the first element of the list returned from getProcessedCommand() since it is always the name of the command which if you cared about you could get by calling Command.getCommandType. So I decided to add a method on Command named getCommandArguments. I didn't change anything else about Command but the nice thing about getCommandArguments is it uses List.subList which on an ArrayList does not make a copy of the array. I'll submit a future improvement store that we should try to remove getProcessedCommand and then we could change the internals of Command to just keep a reference to the sublist. Does that sound good?, Label: 1\n",
      "Processing row 341 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 342 - Data Type: train, Message: Good catch. I cannot think why no keystore would be provided and it seems like a misconfiguration. You *need* a keystore if you want to use SSL/TLS. To that end I think it's OK to throw an exception in that case. WDYT?, Label: 1\n",
      "Processing row 343 - Data Type: train, Message: And... now I've added it back since it seems that the `createClient` can also sometime fail (I have a feeling it's platform or JDK specific). But if the client is created, then this ping will definitely fail., Label: 0\n",
      "Processing row 344 - Data Type: val, Message: The top level exception is always `JedisConnectionException` and the ones here are somewhere in the stack but not even the root cause. That's why I'm just looking at the message since that always contains one of these. I also have a strong suspicion that different plaforms and/or JDK produce slightly different messages or exception stacks. This seems to be one way to cover all bases., Label: 1\n",
      "Processing row 345 - Data Type: train, Message: I started down that road but I'm not sure how to best go about it. I started playing with some code I found that probes the port and tries to set various SSL options, but it seems a bit fragile since the JDKs are always adjusting their supported security. Any other ideas? , Label: 1\n",
      "Processing row 346 - Data Type: train, Message: I was able to verify manually, but that doesn't help., Label: 1\n",
      "Processing row 347 - Data Type: train, Message: I can add javadoc for this method. \n",
      "Maybe the method name can be changed to setPossibleShutdownCauseToForceDisconnectException(shutdownCause)\n",
      "\n",
      "The method signature is from the refactoring above. Since the original code expects to convert throwable into ForceDisconnectionException, thus this setShutdownCause() should return a Throwable. \n",
      "\n",
      "From listener point of view, we don't need to return anything. We did this way is only to avoid duplicated code. \n",
      "\n",
      "Of cause, I can complete revoked the code changes in ClusterDistributionManager.java, then I can change to void setShutdownCause(Throwable t) here, because in GMSMembership.java, we don't need setShutdownCause() to return anything.  \n",
      "\n",
      "However, in our code, there will be 2 places with very similar code, one in ClusterDistributionManager, one in GMSMembership.  That's what we want to avoid. \n",
      "\n",
      "Conceptually, the whole fix's idea is to move setShutdownCause() a little earlier in force disconnect case. So it makes sense to do the refactoring in ClusterDistributionManager.DMListener into a method, then let listener to make use of this method. , Label: 0\n",
      "Processing row 348 - Data Type: train, Message: Yes. By the way, I also updated the README file as I had missed that., Label: 0\n",
      "Processing row 349 - Data Type: train, Message: Not anymore., Label: 0\n",
      "Processing row 350 - Data Type: train, Message: Good point. Done.\n",
      "In `testSuccessfulCancelCommand()` I had to create an instance of `GfshCommandRule` to run the canceling of the command while an execution was ongoing. Using the same instance (the member instance) did not work in this case because the output of both commands did not come always in the same order. However I did not have to explicitely close the created instance because the member rule would close it (closes all) when the method finished.\n",
      "Using two member rules did not work because there was a double close that provoked some `NullPointerException`., Label: 0\n",
      "Processing row 351 - Data Type: train, Message: unable to do this, multiple exit points, Label: 0\n",
      "Processing row 352 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 353 - Data Type: train, Message: Oh, no, accidental change., Label: 0\n",
      "Processing row 354 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 355 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 356 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 357 - Data Type: train, Message: It doesn't do it right for my test. I have been down that road., Label: 0\n",
      "Processing row 358 - Data Type: train, Message: The diskdir rule does, but it doesn't interact consistently with the ClusterStartupRule., Label: 0\n",
      "Processing row 359 - Data Type: train, Message: It is necessary because I cannot use DistributedDiskRule with ClusterStartupRule and have it behave consistently., Label: 0\n",
      "Processing row 360 - Data Type: train, Message: The test is disabled. I chose not to modify it., Label: 0\n",
      "Processing row 361 - Data Type: train, Message: additional pieces required., Label: 0\n",
      "Processing row 362 - Data Type: train, Message: Variable changes that were required., Label: 0\n",
      "Processing row 363 - Data Type: train, Message: No, this is not production code. `ExpirableSecurityManager` is a test security manager in `geode-junit` module. Geode product doesn't provide any implementation of `SecurityManager`, Label: 0\n",
      "Processing row 364 - Data Type: train, Message: No, Iterator.next() throws a NoSubElementException when there isn't a next element, which we subsequently catch and send a syntax error as the response. Does that seem sufficient?, Label: 1\n",
      "Processing row 365 - Data Type: train, Message: I get that native redis doesn't have the same behavior, but in Java positive infinity plus negative infinity results in NaN, not 0, Label: 1\n",
      "Processing row 366 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 367 - Data Type: train, Message: OK., Label: 0\n",
      "Processing row 368 - Data Type: val, Message: > I think you meant to use `org.assertj.core.api.AssertThat` instead\n",
      "\n",
      "Good catch!, Label: 0\n",
      "Processing row 369 - Data Type: train, Message: Whoops, thought I'd done that!, Label: 0\n",
      "Processing row 370 - Data Type: val, Message: yes, Label: 0\n",
      "Processing row 371 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 372 - Data Type: train, Message: The unit tests we have don't use Jedis and use mocked Regions. I'm not sure if setting up a Jedis cluster with real regions is a good idea for unit tests, and I'm also not sure using a mocked region with these concurrency tests for stripes is a good idea either -- maybe these should be a dunit test?, Label: 1\n",
      "Processing row 373 - Data Type: train, Message: Ah yes, of course..., Label: 0\n",
      "Processing row 374 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 375 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 376 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 377 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 378 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 379 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 380 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 381 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 382 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 383 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 384 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 385 - Data Type: train, Message: I was discussing this with Jens as well. There is no technical reason for Geode to require that the keys be all hashed to the same slot, which is why there is just the bucketId check. I'm not sure its entirely obvious that we should throw an error here if they are not in the same slot just because Redis does. Is it a product mandate that we always return an error when Redis does?, Label: 1\n",
      "Processing row 386 - Data Type: val, Message: This was just copied from `MSetDUnitTest`, and I'm not clear why this is needed either, Label: 1\n",
      "Processing row 387 - Data Type: train, Message: Yup. Nice simplification!, Label: 0\n",
      "Processing row 388 - Data Type: train, Message: Yup. Nice simplification!, Label: 0\n",
      "Processing row 389 - Data Type: train, Message: I was just copying the above `setupCache(String username, boolean withSecurityManager)` method, but you're right that it's unecessary, Label: 0\n",
      "Processing row 390 - Data Type: train, Message: but a negative timeout doesn't make any sense. and a zero timeout would cause it to check constantly, which would have some interesting performance impacts. and the problem with doing a helper method in RedisProperties is the validation of >/>= 0, Label: 1\n",
      "Processing row 391 - Data Type: train, Message: Isn't the above the intended approach of Java? It is the optimized form according to intellij, Label: 1\n",
      "Processing row 392 - Data Type: train, Message: You cannot do that because CacheSerializableRunnable throws a CacheException\n",
      "\n",
      "`  @Override\n",
      "  public void run() {\n",
      "    try {\n",
      "      run2();\n",
      "    } catch (CacheException exception) {\n",
      "      String message = \"While invoking \\\"\" + this + \"\\\"\";\n",
      "      throw new CacheSerializableRunnableException(message, exception);\n",
      "    }\n",
      "  }\n",
      "`, Label: 0\n",
      "Processing row 393 - Data Type: train, Message: Lettuce just cares that an error is returned. There doesn't seem to be any benefit in adding more detail to the error response at this point., Label: 0\n",
      "Processing row 394 - Data Type: val, Message: yes, Label: 0\n",
      "Processing row 395 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 396 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 397 - Data Type: train, Message: I think that this is not possible., Label: 1\n",
      "Processing row 398 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 399 - Data Type: train, Message: yes., Label: 0\n",
      "Processing row 400 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 401 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 402 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 403 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 404 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 405 - Data Type: train, Message: I was always torn between both ways: split into multiple tests or put them in one and have less code. If test fails, which line it fails definitely tells you what exactly the problem is.  This way, it seems very concise and provide a stream line of the stepping further down the code. , Label: 0\n",
      "Processing row 406 - Data Type: train, Message: It could be done but I don't think it should. The DeltaInfo name should describe what they contain. It is possible for the same DeltaInfo class to be used by multiple operations so even though, currently, this one is only used by SADD I think its current name is good: it is a DeltaInfo that contains one or more \"add\" operations. The ones with plural names can contain more than one item., Label: 1\n",
      "Processing row 407 - Data Type: train, Message: How do you see an intellij complaint? I don't see any warnings. Do you have some non-default warnings enabled?\n",
      "\\, Label: 1\n",
      "Processing row 408 - Data Type: train, Message: @kirklund Thanks a lot for the suggestion. I finally have not needed to modify `GfshCommand`.\n",
      "Nevertheless, I had to inject the command delegate and the `findMembers` test behavior using the constructor.\n",
      "The outcome has not been very clean (I was not able to just chain the constructors). If you have any suggestions to make it cleaner, please let me know.\n",
      "\n",
      "Given that `findMembers` is not a static method, I could not pass it when calling the last constructor. Instead, I had to set it after I called it.\n",
      "Something similar happened when trying to inject the delegate to the command., Label: 0\n",
      "Processing row 409 - Data Type: train, Message: I'm not sure a mock can do all that this implementation does. It's used to collect test data which is used for verification., Label: 1\n",
      "Processing row 410 - Data Type: train, Message: @DonalEvans I agree with that but unfortunately the code is such that I have not been able to come up with an alternative approach., Label: 0\n",
      "Processing row 411 - Data Type: train, Message: At this point a `cache` object is not in scope and given that the issue we're addressing here is related to race conditions with cache requests on the one hand, and cache being either gone or in the process of being shut down on the other, I don't know if it's worth adding the functionality of bringing it in scope and checking its state., Label: 1\n",
      "Processing row 412 - Data Type: train, Message: No. This check is absolutely necessary. Because in the case you have a two servers in the same zone with a copy of the bucket and redundancy set to one, as soon as you mark the bucket as being overredundant one of the copies will go away, immediately leaving you with a low redundancy. Hence the reason, we are adding to both. The method that clears overredundancy doesn't check for lowredundancy., Label: 1\n",
      "Processing row 413 - Data Type: val, Message: Hmm. Intellij is not showing me warnings for those lines. What setting do you have turned on that is showing a warning and what is the warning?, Label: 1\n",
      "Processing row 414 - Data Type: train, Message: We have created the following test cases (for more information please check comments in test cases):\n",
      "\n",
      "1. Recovery of single region after cache is restarted (`testCompactorRegionMapDeletedForOnlyDrfOplogAfterCompactionAndRecoveryAfterCacheClosed`)\n",
      "\n",
      "2. Recovery of single region after region is closed and then recreated (`testCompactorRegionMapDeletedForOnlyDrfOplogAfterCompactionAndRecoveryAfterRegionClose`)\n",
      "\n",
      "In all cases all data have been successfully recovered from Oplog files, and loaded into the cache memory. It seems that this counter in only used to skip compaction of Oplog file (.crf file) when all region that use Oplog (.crf file) didn't yet recover (e.g. region were closed). All orphaned/only .drf files that reference older .crf Opolg cannot be deleted until older .crf Oplog are deleted. So having `unrecoveredRegionCount` on .crf also prevents deleting any newer .drf file that could contain destroy references to it's entries. We could not find the case were not marking .drf only Oplog as unrecovered during close could cause some issues. Could you please share exact steps for the case that you think it will cause problem and I will try to create it?\n",
      "\n",
      "During these tests we have found another problem in design base (not introduced by this PR) when region is closed and then recreated to start the recovery. If you inspect this code in close() function you will notice that it doesn't make any sense:\n",
      "\n",
      "```\n",
      "void close(DiskRegion dr) {\n",
      "  // while a krf is being created can not close a region\n",
      "  lockCompactor();\n",
      "  try {\n",
      "    if (!isDrfOnly()) {\n",
      "      addUnrecoveredRegion(dr.getId());\n",
      "      DiskRegionInfo dri = getDRI(dr);\n",
      "      if (dri != null) {\n",
      "        long clearCount = dri.clear(null);\n",
      "        if (clearCount != 0) {\n",
      "          totalLiveCount.addAndGet(-clearCount);\n",
      "          // no need to call handleNoLiveValues because we now have an\n",
      "          // unrecovered region.\n",
      "        }\n",
      "        regionMap.get().remove(dr.getId(), dri);\n",
      "      }\n",
      "    }\n",
      "  } finally {\n",
      "    unlockCompactor();\n",
      "  }\n",
      "}\n",
      "private void addUnrecoveredRegion(long drId) {\n",
      "  DiskRegionInfo dri = getOrCreateDRI(drId);\n",
      "  if (dri.testAndSetUnrecovered()) {\n",
      "    unrecoveredRegionCount.incrementAndGet();\n",
      "  }\n",
      "}\n",
      "\n",
      "```\n",
      "Please notice that `addUnrecoveredRegion()` marks `DiskRegionInfo` object as `unrecovered` and increments counter `unrecoveredRegionCount`. This `DiskRegionInfo` object is contained in `regionMap` structure. Then afterwards it removes `DiskRegionInfo` object (that was previously marked as `unrecovered`) from the `regionMap`. This doesn't make any sense, it updated object and then removed it from map to be garbage collected. As you will see later on this will cause some issues when region is recovered.\n",
      "\n",
      "Please check this code at recovery:\n",
      "```\n",
      "\n",
      "/**\n",
      " * For each dri that this oplog has that is currently unrecoverable check to see if a DiskRegion\n",
      " * that is recoverable now exists.\n",
      " */\n",
      "void checkForRecoverableRegion(DiskRegionView dr) {\n",
      "  if (unrecoveredRegionCount.get() > 0) {\n",
      "    DiskRegionInfo dri = getDRI(dr);\n",
      "    if (dri != null) {\n",
      "      if (dri.testAndSetRecovered(dr)) {\n",
      "        unrecoveredRegionCount.decrementAndGet();\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "```\n",
      "The problem is that geode will not clear counter `unrecoveredRegionCount` in Oplog objects after recovery is done. This is because `checkForRecoverableRegion` will check `unrecoveredRegionCount` counter and perform `testAndSetRecovered`. The `testAndSetRecovered` will always return false, because non of the `DiskRegionInfo` objects in region map have `unrecovered` flag set to **true** (all object marked as `unrecovered` were deleted by close(), and then they were recreated during recovery.... see **note** below). The problem here is that all Oplogs will be fully recovered with the counter incorrectly indicating `unrecoveredRegionCount>0`. This will later on prevent the compaction of recovered Oplogs (the files that have .crf, .drf and .krf) when they reach compaction threshold.\n",
      "\n",
      "**Note:** During recovery `regionMap` will be recreated from the Oplog files. Since all `DiskRegionInfo` objects are deleted from `regionMap` during the `close()`, they will be recreated by using function `initRecoveredEntry` during the recovery. All `DiskRegionInfo` will be created with flag `unrecovered` set to false.\n",
      ", Label: 1\n",
      "Processing row 415 - Data Type: train, Message: Like a key that is used for another data structure type. IE. a key that is in sorted sets?, Label: 0\n",
      "Processing row 416 - Data Type: train, Message: Thank you for the review! I executed mentioned test case multiple times with reverted changes and test case failed every time. It was always the case that first five Oplogs were not compacted as expected. It is possible that this test case is flaky in some way, but I cannot reproduce it or see anything suspicious. Could you please send me logs from test case execution where it pass after you revert the changes?, Label: 0\n",
      "Processing row 417 - Data Type: train, Message: The question is how we can tell the cache is already closed or is in the process of closing, before recreating the region. There is some subtle difference. `GemFireCacheImpl.isClosed()` returns `true`, even when the bug occurs. So we can't depend on the flag `GemFireCacheImpl.isClosed()`. I have also tried to check if the cache is `null`. Not a good idea either. I probably have to do something similar to `cancelInProgress`., Label: 1\n",
      "Processing row 418 - Data Type: val, Message: After a look at it I'm wondering if it wouldn't be better to use the flag in deciding how to write the response. If at some point in the future the flag changes we'd also still have to change the code downstream if we don't read the flag when deciding how to write the exception., Label: 1\n",
      "Processing row 419 - Data Type: train, Message: Don't know. It is out of scope for this current change., Label: 1\n",
      "Processing row 420 - Data Type: val, Message: You fill find lots of places in the old tests where the combinations of mocks and return values used for `DataPolicy` actually created mutually exclusive combinations but it didn't matter for the sake of the test. For the changes here I tried to match up what the test was actually expecting for the correct combinations that aligned to an enum value., Label: 0\n",
      "Processing row 421 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 422 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 423 - Data Type: train, Message: Interesting. I didn't see that before. The GlobalSerialFilterConfigurationFactory impl is already setting setValidateSerializableObjects to true before starting the locator. So this is redundant (and obviously wrong as well)., Label: 1\n",
      "Processing row 424 - Data Type: train, Message: The 2nd test is missing `.set(JMX_MANAGER, \"true\")`, Label: 0\n",
      "Processing row 425 - Data Type: train, Message: Do we want to avoid passing null because of the NPE?\n",
      "Also, MemberMap has to take in a size, so far I set it as the keyweights size. Would that be the route to go or should it be set to something else? , Label: 1\n",
      "Processing row 426 - Data Type: train, Message: Is this supposed to be when the source and destination key do map to the same slot? (Use the same key for destination and source?), Label: 1\n",
      "Processing row 427 - Data Type: train, Message: Nope accident. , Label: 0\n",
      "Processing row 428 - Data Type: val, Message: Should I rename the other local variables in the class to follow that format., Label: 0\n",
      "Processing row 429 - Data Type: train, Message: PR #7288 , Label: 0\n",
      "Processing row 430 - Data Type: train, Message: I changed it to just \"Add an additional server\". Is this ok?, Label: 1\n",
      "Processing row 431 - Data Type: train, Message: Interesting thing about English punctuation rules (I had to look it up) is that the final `s` in the `'s` for possessives is only dropped after _plural_ nouns that end in an `s`. So `native Redis's behavior` is the correct spelling., Label: 0\n",
      "Processing row 432 - Data Type: train, Message: So at the moment we just return the same output as the positive cursor and that is okay?, Label: 0\n",
      "Processing row 433 - Data Type: train, Message: Right. , Label: 0\n",
      "Processing row 434 - Data Type: train, Message: `SSLParameters` is basically a POJO for holding properties of the `SSLEngine`. If you look at the `SSLEngine::getSSLParameters` it just constructs a new object with values from the `SSLEngine`. If you look at the `SSLEngine::setSSLParameters` it sets the values back on the `SSLEngine`. The issue in the original codes was the interleaving of values set on `SSLParameters` and `SSLEngine` between the `getSSLParameters` and `setSSLParameters`, effectively wiping out all the direct `SSLEngine` settings., Label: 0\n",
      "Processing row 435 - Data Type: train, Message: I think I have the documented in one place but not here. Good eye!, Label: 0\n",
      "Processing row 436 - Data Type: train, Message: It could be. That is the problem with system level upgrade tests, how do you name them and what package. In this case I chose the name of the thing I was directly changing to fix this bug. The test them implies to me, \"does SocketCreator do the right thing on upgrades?\", Label: 1\n",
      "Processing row 437 - Data Type: train, Message: Not planning on a path for 1.11 and older., Label: 0\n",
      "Processing row 438 - Data Type: val, Message: Test has been updated to support 1.12.1 and newer. 1.12.0 is too broken., Label: 0\n",
      "Processing row 439 - Data Type: train, Message: It only adds the index if it isn't spop. When it does spop there is an indexUsed set, but nothing gets added so it is a waste., Label: 0\n",
      "Processing row 440 - Data Type: train, Message: By just calling that method or assertThatThrownBy(() ->RedisCommandArgumentsTestHelper.assertAtMostNArgs()).hasMessageContaining(ERROR_SYNTAX);\n",
      "\n",
      "When I was using RedisCommandArgumentsTestHelper.assertAtMostNArgs() on it's own it failed both the native and integration test.\n",
      ", Label: 0\n",
      "Processing row 441 - Data Type: val, Message: The load factor is 3/4, so I believe it would be null 1/4 of the time. I used this method to get set members from the backing array, because of Darrel's comment on not copying over the member set. I do think this check is necessary for the implementation I have now, but I could change the way I am doing it if it can be stuck here infinitely.\n",
      "\n",
      "I could be wrong, but I don't think it would be stuck in the loop infinitely. In SPOPEXECUTOR there is a check to make sure that the set size is greater than 0, and in spop there is a check before this that makes sure the count is less than the size of the set. So when entering this loop there would be some members in the set, and it would remove an amount that is less than the total size of the set. I guess it could loop infinitely if spop is called outside SPOPEXECUTOR, but I could move the 0 size check in this method., Label: 0\n",
      "Processing row 442 - Data Type: train, Message: What if I refactored the sadd and srem methods to not modify the list? That sort of side effect feels a bit risky to me to begin with, and it's not necessary if we just iterate the list and add to the delta as we go rather than creating the delta after doing all the adds/removes. The only real performance difference is that if we do an SADD or SREM that ends up not adding or removing anything, now we would be creating a single `DeltaInfo` that we weren't previously, which isn't too expensive., Label: 0\n",
      "Processing row 443 - Data Type: train, Message: I removed this section as it did not feel as though it was the best place or way to compare this implementation vs OSS Redis., Label: 0\n",
      "Processing row 444 - Data Type: train, Message: Perhaps when the server has previously crashed there may not be keys hosted there anymore. Maybe Jens can comment on this as well if there's more to it than this., Label: 1\n",
      "Processing row 445 - Data Type: val, Message: @agingade, let me try to explain why this is not an bug in the command but a problem with timing in the test case.\n",
      "\n",
      "At the beginning, the test puts 50000 entries whose keys are in the range of 0-49999.\n",
      "\n",
      "Then, the wan-copy region command is executed and, in parallel, other puts and deletes are done. The keys for these entries puts/deleted are in the range of 50000-52000 (no intersection with the first entries put).\n",
      "\n",
      "The test tries to verify that only the entries put at the beginning are copied (none of the entries put while the command is running). It does so by verifying that the number of entries copied is exactly 50000 as reported by the command. If any entry put while the command is running is copied by the command, we should see that the number of entries copied is greater than 50000, which is what we see when the test fails (50001). But the test needs to make sure that the puts for the 50000-52000 range are done after the copy command has started and not before. Otherwise, we could get a failure of the test (which is what we see sometimes).\n",
      "\n",
      "The way to make sure that the second group of puts starts after the command has started is by means of the `await()` you mention. But when the `await()` returns, it only guarantees that the `Callable` that will execute the command has been submitted to the pool (see `WanCopyRegionFunctionService.execute()`) although the command may not have effectively started.\n",
      "\n",
      "At that point, random operations (puts and deletes) can be started. Let's say at t=x, entry with key=50000 is put.\n",
      "\n",
      "The time at which the Callable object that in turn calls the `WanCopyRegionFunctionDelegate.wanCopyRegion()`is executed depends on the scheduling. Let's say it executes its first line at t=x + 1. At that point, the current time is recorded as (`functionStartTimestamp`). and a sleep of 500ms will be done before entries are started to be copied.\n",
      "\n",
      "Then the command starts to copy entries. Any entry with a timestamp greater than `functionStartTimestamp` will not be copied. In this case, the timestamp for entry with key=50000 is x and given that `functionStartTimestamp` is x+1, the entry will be copied. This would not point to an bug in the command. Rather, that the entry with key=50000 was put before the command was started.\n",
      "\n",
      "With the 100ms extra added to the wait we can be more certain that second group of puts will be started after the `functionStartTimestamp` is recorded and therefore, the timestamp for the entries of the second group of puts will be higher than the `functionStartTimestamp`.\n",
      ", Label: 0\n",
      "Processing row 446 - Data Type: train, Message: @agingade Did my explanation answer your concerns?, Label: 1\n",
      "Processing row 447 - Data Type: train, Message: This TODO comment was actually some leftover cruft and just needed to be deleted., Label: 0\n",
      "Processing row 448 - Data Type: train, Message: Yes., Label: 0\n",
      "Processing row 449 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 450 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 451 - Data Type: train, Message: Or were you referring to just where in the file this entry appears?, Label: 1\n",
      "Processing row 452 - Data Type: val, Message: Seems like if I do that the `textId` just ends up being empty., Label: 0\n",
      "Processing row 453 - Data Type: train, Message: Removed this ternary check., Label: 0\n",
      "Processing row 454 - Data Type: train, Message: Now passing in both category and type., Label: 0\n",
      "Processing row 455 - Data Type: train, Message: See my comment above. I'm not sure if you were thinking something else or I'm missing something., Label: 1\n",
      "Processing row 456 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 457 - Data Type: train, Message: Yes, I wanted to, but since I also have this \"General\" category (which only exists to satisfy the stat naming and isn't a real Category) I opted to use String as the key. Perhaps you have a suggestion on how to do this better?, Label: 1\n",
      "Processing row 458 - Data Type: train, Message: Yes!, Label: 0\n",
      "Processing row 459 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 460 - Data Type: train, Message: Skip waiting for `RegionAdvisor.preInitQueue`. Because only `BucketProfileUpdateMessage` and `AllBucketProfilesUpdateMessage` are actually adding bucket profiles to the queue. And the recipients of these two kinds of messages are based on the `DistributionAdvisor`. The advisor doesn't return a member that is still in the process of creating a partitioned region. Therefore, `BucketProfileUpdateMessage` and `AllBucketProfilesUpdateMessage` don't add bucket profiles to the `preInitQueue` for a member that is still in the process of creating a partitioned region. It is not necessary to wait on the queue on such member. , Label: 0\n",
      "Processing row 461 - Data Type: train, Message: will fix, Label: 0\n",
      "Processing row 462 - Data Type: train, Message: Hi @pivotal-jbarrett , thanks for the review. Upgrading this test to JUnit 5 would be tricky because it uses **Rule** annotation, which is replaced by **ExtendWith** annotation. It would be necessary to implement the new interfaces (AfterEachCallback and BeforeEachCallback) to GfshCommandRule and ClusterStartupRule classes. I think that this should be a part of a separate ticket since this is not just a minor adjustment. What do you think?, Label: 1\n",
      "Processing row 463 - Data Type: train, Message: With the commands that are currently implemented, the only remove is lpop, which removes one element from the head. So I added only one element. I could change it so I add more then just a for loop to pop multiple added elements. \n",
      "\n",
      "When you add to the list it gets added to the head, so I checked the 0 index for the difference. If I checked the last element then for one of the cases it could be out of range. , Label: 0\n",
      "Processing row 464 - Data Type: train, Message: Woops! Yes, Label: 0\n",
      "Processing row 465 - Data Type: train, Message: yeah that might be nice. we should make a ticket to do something about the editing. seems like everyone dislikes the current method., Label: 0\n",
      "Processing row 466 - Data Type: train, Message: Yanked, Label: 0\n",
      "Processing row 467 - Data Type: train, Message: Mais oui!, Label: 0\n",
      "Processing row 468 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 469 - Data Type: train, Message: Take a look at what I did - I just passed a callback to the listener that will allow it to be cancelled. I'm not sure if that creates additional 'synthetics' that are an unnecessary overhead. , Label: 1\n",
      "Processing row 470 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 471 - Data Type: train, Message: Since fault reproduction is timing issue, we can not make assertion stronger., Label: 1\n",
      "Processing row 472 - Data Type: train, Message: I have added a test case to make sure that when the maximum limit is reached the new command will wait for a thread to be free.\n",
      "I am not sure if it is really necessary or is it worth to add a cap for max threads., Label: 1\n",
      "Processing row 473 - Data Type: val, Message: Looking at the code again, when `serials.length == 1`, the `bucketId` might not necessarily be `0`. Therefore, we still need the `if` and `else`., Label: 1\n",
      "Processing row 474 - Data Type: train, Message: If `buckets` is `null`, which means `initializeRegionAdvisor()` and `processProfilesQueuedDuringInitialization()` are not called yet. At this time, as long as `RegionAdvisor` constructor is called, `preInitQueue` is not `null`. It will enqueue the bucket profile and `return` in the `if (preInitQueue != null)` block line 441., Label: 0\n",
      "Processing row 475 - Data Type: train, Message: If we do get to this line, then `preInitQueue` has to be `null`, which means `processProfilesQueuedDuringInitialization()` is called. And `initializeRegionAdvisor()` is called before `processProfilesQueuedDuringInitialization()` to initialize the `buckets` array. So I don't think `buckets` is `null`. Maybe I am missing something?, Label: 1\n",
      "Processing row 476 - Data Type: train, Message: Yeah, I know. I resisted the urge to refactor these files as this is going into 1.15, Label: 0\n",
      "Processing row 477 - Data Type: train, Message: Changes in this method and `close()` are the meat of the fix for this bug., Label: 0\n",
      "Processing row 478 - Data Type: train, Message: I fixed this comment., Label: 0\n",
      "Processing row 479 - Data Type: train, Message: There is the possibility for the `queueConnections` to be null during teardown of `CacheClientNotifierDUnitTest`. While the cache is closing and everything is being freed, the `RedundancySatisfierTask` continues to check `queueConnections` whenever it is referenced (because it is volatile). So if the `RedundancySatisfierTask` thread is slow to close and is still checking the `queueConnections` after it has been freed, it could cause an NPE.\n",
      "\n",
      "Do you think that a test for that situation would be valuable? I worry that it will just be forcing weird timing, and would probably be flaky., Label: 1\n",
      "Processing row 480 - Data Type: train, Message: Ok I think I did what you described, but please let me know if I misunderstood what you were suggesting. I think it should be safe to remove the null check that I previously added, but since it's hard to test I'm not sure. Thoughts?, Label: 1\n",
      "Processing row 481 - Data Type: train, Message: > Should the return be in this block?\n",
      "Yes, it is needed as the method should return a boolean.\n",
      "> \n",
      "> Do you want to set a specific amount of time for the await here based on the idea that you have an expectation of time?\n",
      "Not really. I am just checking that it did not hang forever.\n",
      ", Label: 1\n",
      "Processing row 482 - Data Type: val, Message: Because the reference for the RedisString is changing in the implementation. I was not able to get that exception being thrown that way after performing the MSET. That is why the check now makes sure it's not the same object reference after the mset happens. I am happy to know if there is any mechanism to get the exception thrown., Label: 1\n",
      "Processing row 483 - Data Type: train, Message: @jinmeiliao I could not find other API which took the index, version and the rule operator. This was the only option on the ClusterStartupRule., Label: 0\n",
      "Processing row 484 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 485 - Data Type: train, Message: Yeah, if it's junit4, I would use that. Not sure how to use that in Junit5., Label: 1\n",
      "Processing row 486 - Data Type: val, Message: Tweaked., Label: 0\n",
      "Processing row 487 - Data Type: train, Message: Expanded., Label: 0\n",
      "Processing row 488 - Data Type: train, Message: Yes, that isn't good. I think I've found a better way to fix this bug without doing this., Label: 1\n",
      "Processing row 489 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 490 - Data Type: train, Message: One is \"gemfire.\" and the other is \"geode.\". So if we changed  this one, for example, to GEODE_PREFIX we would break anyone using the old sys prop name. So although the constant is internal it's value is part of the external contract we have with users., Label: 0\n",
      "Processing row 491 - Data Type: train, Message: NotPrimary is intended to used for early return (if there is no colocated regions for this bucket), we only need to check once once notPrimary is set to false. I think to use same variable may cause confusion., Label: 0\n",
      "Processing row 492 - Data Type: train, Message: Not sure if we definitely can hit the race issue in the unit test. Is there any suggestion for this?\n",
      ", Label: 1\n",
      "Processing row 493 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 494 - Data Type: val, Message: These numbers were contradictory to the required record count because key 0 should not have been there to be counted., Label: 0\n",
      "Processing row 495 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 496 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 497 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 498 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 499 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 500 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 501 - Data Type: train, Message: I commented out this code to reduce logging. I want to leave it for whomever wanted it there in the first place because I am assuming I am stepping on someone's toes., Label: 0\n",
      "Processing row 502 - Data Type: train, Message: Not sure what you mean here. I think this is pretty clear. The line below that does the assertJ., Label: 1\n",
      "Processing row 503 - Data Type: train, Message: Thanks a lot, Kirk. I didn't know we had this rule. I just add the exception to the DistributedErrorCollector like this, right?\n",
      "```\n",
      "} catch (Exception e) {\n",
      "  errorCollector.addError(e);\n",
      "}\n",
      "```, Label: 0\n",
      "Processing row 504 - Data Type: train, Message: I think these transient allocations are a drop in the bucket compared to the total number of transient allocations we have for each cache operation. And these transient instances are very small. I don't think it was worth using an internal JDK feature which is subject to change in any jdk release to avoid this transient., Label: 1\n",
      "Processing row 505 - Data Type: train, Message: because we obtains it from the BufferPool. Additional refactoring could be done to not obtain it from BufferPool (the heap buffer are not actually pooled so why do we ask BufferPool for one) but that seemed outside the scope of this PR which was to not export sun.nio.ch, Label: 0\n",
      "Processing row 506 - Data Type: train, Message: As we agreed in the above comments, using Status.IGNORABLE for some type of the exceptions will solve the problem, the user will get the correct output, that index is successfully created on all members, and the status command is a success.\n",
      "In the output, if an exception occurs it will print in the status section of the command output IGNORED. Why is this ok?\n",
      "The index will be created on that servers too, but the create request comes from other servers, and if the request from the locator(from the command) comes later it will say that the index already exists and the command will be a success(before this change the command failed, but index created on all members and cluster config is not updated).\n",
      "Another thing is when the user runs the create index command multiple times, the command will be successful, but in the printout, the user will see that the index already exists in members, and the status is IGNORED., Label: 1\n",
      "Processing row 507 - Data Type: train, Message: releasePrimaryLock() will release the distributed lock on parent region. Now any node (including the one trying to become primary) can get that lock and becomes primary. And operation can be generated on the new primary on parent region. This change will guarantee that all colocated buckets deposed primary before another server can become new primary for any colocated buckets.\n",
      "\n",
      "You are also right that node with original primary colocated buckets should be blocked on operations on the colocated regions. Even though new primary is being acquired by another server, the original old primary will not allow any new operations on the colocated child buckets. I guess only one is needed., Label: 0\n",
      "Processing row 508 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 509 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 510 - Data Type: train, Message: fixed. , Label: 0\n",
      "Processing row 511 - Data Type: train, Message: `InternalLocator.attemptReconnect()` doesn't care about the return boolean, for `GemFireCacheImpl.waitUntilReconnected()`, I am not sure how it's using the return boolean. I need this `IDS.isReconnecting()` here specifically because `locator.waitToStop()` as the method name indicate, can't return unless the locator truly stops. So the call to the `IDS.waitUntilReconnected()` can't return false, thus it needs this call there to prevent that., Label: 1\n",
      "Processing row 512 - Data Type: train, Message: Reduced the number of locators, Label: 0\n",
      "Processing row 513 - Data Type: train, Message: Refactored the name, Label: 0\n",
      "Processing row 514 - Data Type: train, Message: Instant class, newly introduced in Java 8. If it is the same as currentTimeMillis(), should not matter which one we use right?, Label: 1\n",
      "Processing row 515 - Data Type: train, Message: Not seen problems in sever side., Label: 0\n",
      "Processing row 516 - Data Type: train, Message: My bad, this is now removed., Label: 0\n",
      "Processing row 517 - Data Type: train, Message: This only checks for PARQUET-251, where min and max aren't the actual min and max values for some String columns. It doesn't check, for example, that the correct sort order was used or that the min and max for numeric columns are valid. Because it is limited to checking for PARQUET-251, I'd leave the name as it is., Label: 0\n",
      "Processing row 518 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 519 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 520 - Data Type: train, Message: Another point: it's far more expensive to copy, which happens fairly often in the current read path because everything is based on byte arrays and not byte buffers. I think the copy here isn't significant enough to worry about in comparison., Label: 1\n",
      "Processing row 521 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 522 - Data Type: val, Message: Without this configuration change on the objectMapper three tests in parquet-cascading3 fail with the following error:\n",
      "\n",
      "  testReadPattern(org.apache.parquet.cascading.TestParquetTupleScheme): [namecp] could not build flow from assembly: [java.io.IOException: Could not read footer: java.lang.RuntimeException: org.codehaus.jackson.map.JsonMappingException: No serializer found for class org.apache.parquet.schema.LogicalTypeAnnotation$StringLogicalTypeAnnotation and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationConfig.Feature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: org.apache.parquet.hadoop.metadata.ParquetMetadata[\"fileMetaData\"]->org.apache.parquet.hadoop.metadata.FileMetaData[\"schema\"]->org.apache.parquet.schema.MessageType[\"fields\"]->java.util.ArrayList[0]->org.apache.parquet.schema.PrimitiveType[\"logicalTypeAnnotation\"])]\n",
      "\n",
      "The reason is: the logical types are no longer represented as enum, but a classed, and Jackson can't serialize empty classes because FAIL_ON_EMPTY_BEANS feature is enabled by default., Label: 0\n",
      "Processing row 523 - Data Type: train, Message: I think MapKeyValue is here only for backward compatibility, but Interval should be supported in the future. Since these factory methods are defined on an interface, I can't easily change the visibility to private/package protected. Should I change it to an abstract class?, Label: 1\n",
      "Processing row 524 - Data Type: train, Message: lets leave this as is. the changes are minor, and most likely will never be used. \n",
      "from the link above - \n",
      "\"If you supply a larger-than-12-bytes IV then it needs to be \"hashed\" allowing collisions to happen and raising the risk for (devastating) IV reuse unnecessarily high\"\n",
      "and CTR doesn't really need an IV prefix, can be fully random. plus, like with GCM, most/all IVs are hidden anyway., Label: 0\n",
      "Processing row 525 - Data Type: train, Message: Looked at this class yesterday, for this very reason :) Unfortunately, seems to be unsuitable: the `equals`  uses `Arrays.equals`, which compares object refs, instead of obj contents. I'm using `Arrays.deepEquals`, which works fine. Should I modify `org.apache.parquet.hadoop.metadata.ColumnPath` accordingly? How will it affect the existing Parquet code? (Also, how did the existing code work till now, given this problem?)., Label: 1\n",
      "Processing row 526 - Data Type: train, Message: Good question. Can't think of any scenario where having two version (one for protobuf dependency and one for protoc plugin) would be beneficial., Label: 1\n",
      "Processing row 527 - Data Type: train, Message: I didn't change this because I already made a lot of \"irrelevant\" changes, like whitespace formatting etc. Anyway, I can rename the variable, but in that case I'd prefer a meaningful name like logicalType instead., Label: 0\n",
      "Processing row 528 - Data Type: train, Message: Unfortunately it seems that classes in parquet-hive module use this new constructor, that's why the Travis build failed. Reverted the constructor public., Label: 0\n",
      "Processing row 529 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 530 - Data Type: train, Message: This method is inside a private static class called ParquetType, therefore I don't think it is backward incompatible., Label: 1\n",
      "Processing row 531 - Data Type: train, Message: I think it should be rather part of #513 no?, Label: 1\n",
      "Processing row 532 - Data Type: train, Message: I'm not sure we need to test the label `UNKNOWN_ENUM_VALUE_*`, it is generated only when calling protobuf reflection API, and we are interested mainly in being able to get the number back.\n",
      "It should be a test for protobuf reflection API that tests by passing an unknown number to an enum field, we can get a label `UNKNOWN_ENUM_VALUE_*` by using protobuf reflection API. Less relevant to test it here., Label: 1\n",
      "Processing row 533 - Data Type: train, Message: Yes, It's better, but it's a little bit long, I think if we just need to handle NonFatal exceptions, there should be a NonFatal(Customed exception) exception which can match all non-fatal concrete exceptions rather than list all  them all.\n",
      "I know scala can do this, I'm not sure whether java can do this also. , Label: 1\n",
      "Processing row 534 - Data Type: train, Message: Jim's comments: [https://github.com/apache/parquet-mr/pull/521#discussion_r228761288](url)\n",
      "\n",
      "Just get some time for this. JMeter seems not suit for showing the memory layout for java heap. I wrote a example application and use jmap to dump the heap.   The code snippet is like: \n",
      "```java\n",
      "        byte [] bitset = new byte[1024*1024];\n",
      "        IntBuffer intBuffer = ByteBuffer.wrap(bitset).asIntBuffer();\n",
      "        ByteBuffer byteBuffer = ByteBuffer.allocate(1024*1024);\n",
      "        byte[] bitset2 = new byte[1024*1024];\n",
      "```\n",
      "\n",
      "The Eden space in heap dumps after every sentence are: \n",
      "\n",
      "Eden Space:                                                                                                                                                                                                 \n",
      "   capacity = 66060288 (63.0MB)                                                                                                                                                                             \n",
      "   used     = 3691032 (3.5200424194335938MB)                                                                                                                                                                \n",
      "   free     = 62369256 (59.479957580566406MB)                                                                                                                                                               \n",
      "   5.587368919735863% used    \n",
      "\n",
      "Eden Space:\n",
      "   capacity = 66060288 (63.0MB)\n",
      "   used     = 3691032 (3.5200424194335938MB)\n",
      "   free     = 62369256 (59.479957580566406MB)\n",
      "   5.587368919735863% used\n",
      "\n",
      "Eden Space:\n",
      "   capacity = 66060288 (63.0MB)\n",
      "   used     = 4739624 (4.520057678222656MB)\n",
      "   free     = 61320664 (58.479942321777344MB)\n",
      "   7.17469472733755% used\n",
      "\n",
      "Eden Space:\n",
      "   capacity = 66060288 (63.0MB)\n",
      "   used     = 5788216 (5.520072937011719MB)\n",
      "   free     = 60272072 (57.47992706298828MB)\n",
      "   8.762020534939236% used\n",
      "\n",
      "The Eden space does not increase when we call the wrap API of ByteBuffer.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 535 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 536 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 537 - Data Type: val, Message: This is true, but with the try-with-resource, we don't have a reference after closing the stream. Please note that the `.close()` on the `ByteArrayOutputStream` doesn't have any effect: https://docs.oracle.com/javase/7/docs/api/java/io/ByteArrayOutputStream.html#close()\n",
      "The important thing here is that the `ObjectOutputStream` and `GZIPOutputStream` are flushed (and closed)., Label: 0\n",
      "Processing row 538 - Data Type: train, Message: Nice catch, since it wasn't using a property before, I didn't really look for it., Label: 0\n",
      "Processing row 539 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 540 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 541 - Data Type: train, Message: removed this. from aesMode, Label: 0\n",
      "Processing row 542 - Data Type: train, Message: removed the javadoc comments. this is not a public api., Label: 0\n",
      "Processing row 543 - Data Type: val, Message: @gszadovszky Thanks for your response.\n",
      "\n",
      "I forgot about Mac ...\n",
      "I don't have it now. Could anyone check this on Mac?\n",
      "\n",
      "> Why assumeFalse? \n",
      "\n",
      "The reason why it uses assumeFalse, `org.apache.hadoop.fs.Path.initialize` throws IllegalArgumentException depending on the condition. \n",
      "\n",
      "| Path Style |  Linux Style  |  Windows Style |\n",
      "| ---- | ---- | ---- |\n",
      "| on Linux |  OK  |  IllegalArgumentException |\n",
      "| on Windows |  OK  |  OK  |\n",
      "\n",
      "For testing on Linux OS, I changed the code to not execute the Windows Path Style tests. \n",
      "\n",
      "> I think, it would be cleaner to execute tests on an actual OS even if some are not covered (e.g. Mac).\n",
      "\n",
      "I agree. Should I eliminate test code that depends on OS?, Label: 0\n",
      "Processing row 544 - Data Type: train, Message: @gszadovszky Thanks for your comment. I fix the test code. Could you review it again?, Label: 0\n",
      "Processing row 545 - Data Type: train, Message: The `parquet-hadoop` actually depends on the `fastutil` package, without this package I was unable to test the project in isolation., Label: 0\n",
      "Processing row 546 - Data Type: train, Message: Not release yet., Label: 0\n",
      "Processing row 547 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 548 - Data Type: train, Message: Added it. , Label: 0\n",
      "Processing row 549 - Data Type: train, Message: I think I addressed this in all places., Label: 0\n",
      "Processing row 550 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 551 - Data Type: train, Message: Changed to Double.BYTES everywhere instead of introducing a new name., Label: 0\n",
      "Processing row 552 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 553 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 554 - Data Type: train, Message: Fixed. , Label: 0\n",
      "Processing row 555 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 556 - Data Type: train, Message: Yes you are right, I was thinking of keeping it this way here(like in ColumnChunkPageWriteStore ) so the message can be clearer to the caller of what failed, Label: 0\n",
      "Processing row 557 - Data Type: train, Message: Statistics should be smaller than the bloom filter. but the bloom filter size is not that large according to computation. I 'm ok to remove this., Label: 0\n",
      "Processing row 558 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 559 - Data Type: train, Message: This is used in filtering logic, it is supposed to be called only when doing predicate., Label: 0\n",
      "Processing row 560 - Data Type: train, Message: Isn't it already using same StringBuilder?, Label: 1\n",
      "Processing row 561 - Data Type: train, Message: @shangxinli \n",
      "Could you please check the new message here #770 ?, Label: 0\n",
      "Processing row 562 - Data Type: train, Message: Done! , Label: 0\n",
      "Processing row 563 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 564 - Data Type: train, Message: @ggershinsky, can you make comments about what to be used by this field? Our implementation doesn't need it so far. , Label: 0\n",
      "Processing row 565 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 566 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 567 - Data Type: train, Message: changed to ratio, Label: 0\n",
      "Processing row 568 - Data Type: train, Message: is there a requirement in the code formatting rules in this community to keep comments in separate lines?, Label: 1\n",
      "Processing row 569 - Data Type: train, Message: In cryptography, plaintext is an opposite of ciphertext (the result of plaintext encryption). , Label: 0\n",
      "Processing row 570 - Data Type: train, Message: The background discussion is here,\n",
      "https://github.com/apache/parquet-mr/pull/776#discussion_r427743861\n",
      "\n",
      "In the case of pages, encryption becomes an order (or two orders) of magnitude slower if the pages are small. Basically, the hardware acceleration does not kick in with small pages (and there are additional problems). This is another reason not to allow more than 32K pages in a chunk., Label: 0\n",
      "Processing row 571 - Data Type: train, Message: The default value equals to 8MB here: https://github.com/apache/parquet-mr/blob/d00b2f105f9f732e310ed43c7bfb318213e1ac81/parquet-hadoop/src/main/java/org/apache/parquet/hadoop/ParquetWriter.java#L55\n",
      "\n",
      "I should also change the comment above to `Default: 8388608`, Label: 0\n",
      "Processing row 572 - Data Type: train, Message: I set breakpoint and checked it. But I don't know how to get back the level/workers at the MR job. Any ideal how to do that? I also verified it in the standalone Spark application. Do you think that is sufficient?, Label: 1\n",
      "Processing row 573 - Data Type: train, Message: Since your change removed page statistics, when ColumnIndex is not null, then page statistics must be null, and vice versa(for older version). So the order to check which one shouldn't matter to the result. Correct? , Label: 0\n",
      "Processing row 574 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 575 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 576 - Data Type: train, Message: `out` in this case is wraps `arrayOut`, and it has no buffering, so it does not need to be explicitly closed, or better, in the future, `out` should be closed only and `arrayOut` will be closed implicitly.  Anyway, I came to this conclusion because this is how `close()` is implemented in a couple of other Writer classes as well., Label: 0\n",
      "Processing row 577 - Data Type: train, Message: I remove this static import for consistency with the logical types in my changes. I do find qualifying the type with `LogicalTypeAnnotation.` improves readability.\n",
      "\n",
      "If we prefer a set of discrete static imports to importing the larger class I can certainly do that instead. My motivation was more concise imports and readability., Label: 0\n",
      "Processing row 578 - Data Type: train, Message: GlobalMetadata uses Map<String, Set \\<String\\>> https://github.com/apache/parquet-mr/blob/master/parquet-hadoop/src/main/java/org/apache/parquet/hadoop/metadata/GlobalMetaData.java#L41. So merge method takes in same argument.\n",
      "\n",
      "Do you think it makes sense to change GlobalMetadata to track items in List<String>? I'm not sure if it would be backward compatible and if there are use cases expecting this to be Set.  \n",
      "\n",
      "Without changing GlobalMetadata#keyValueMetaData, it may not be useful to change this interface. Let me know what you think., Label: 1\n",
      "Processing row 579 - Data Type: train, Message: My bad. Fixed. Thanks, Label: 0\n",
      "Processing row 580 - Data Type: train, Message: yeah yeah,  thx for your review, i am sorry, please forgive me. Do you mean we can fix it like this:\n",
      "```\n",
      "            ...\n",
      "            } finally {\n",
      "              if (freader != null) {\n",
      "                freader.close();\n",
      "                // reset current reader is null, avoid closing a reader twice\n",
      "                freader = null;\n",
      "              }\n",
      "            }\n",
      "```\n",
      "or\n",
      "```\n",
      "try(ParquetFileReader freader = \n",
      "    new ParquetFileReader(conf, meta.getFileMetaData(), inpath, rblocks, columns)){\n",
      "    // do something where the freader is really needed.\n",
      "}\n",
      "```\n",
      "is right ?, Label: 0\n",
      "Processing row 581 - Data Type: train, Message: @Fokko thanks for your suggestion, can you review it again?, Label: 0\n",
      "Processing row 582 - Data Type: train, Message: I think using BlockMetaData is better as it is similar to the existing getDictionaryReader(BlockMetaData). For the filtered row group, we need the index to access the RowRanges and ColumnIndexStore.\n",
      "\n",
      "https://github.com/apache/parquet-mr/pull/871/commits/453a6cc9ef6bda9bd963fab05e59ab6f51389dfa#diff-8da24c84aef62e6e836d073938f7843d289785baaeddf446f3afeae6d4ef4b10R983\n",
      "\n",
      "https://github.com/apache/parquet-mr/pull/871/commits/453a6cc9ef6bda9bd963fab05e59ab6f51389dfa#diff-8da24c84aef62e6e836d073938f7843d289785baaeddf446f3afeae6d4ef4b10R994\n",
      "\n",
      "What do you think is the better approach?\n",
      "Accept BlockMetaData and find the index in the list.\n",
      "-or-\n",
      "Change the other method signatures to also use indexes., Label: 0\n",
      "Processing row 583 - Data Type: train, Message: I don't think so. With the fix, it should've already fallback to PLAIN encoding during `writeBytes` before getting here., Label: 1\n",
      "Processing row 584 - Data Type: train, Message: Changed. Thanks!, Label: 0\n",
      "Processing row 585 - Data Type: train, Message: Changed. Thanks!, Label: 0\n",
      "Processing row 586 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 587 - Data Type: train, Message: Removed toString comparison, Label: 0\n",
      "Processing row 588 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 589 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 590 - Data Type: train, Message: In case of  encrypted files with wongly setted file_offset, i have no idea how to fix it when alignment padding take place.\n",
      "If no padding, then we can just use the calculated index.\n",
      "I didn't find any footer meta about padding position or something else indicating padding or not., Label: 1\n",
      "Processing row 591 - Data Type: val, Message:  @ggershinsky, your proposal sounds perfect to me.Looking forward to your patch, or shall I update commit following your proposal?, Label: 0\n",
      "Processing row 592 - Data Type: train, Message: Make sense!, Label: 0\n",
      "Processing row 593 - Data Type: val, Message: sure, Label: 0\n",
      "Processing row 594 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 595 - Data Type: train, Message: yeah, fixed , Label: 0\n",
      "Processing row 596 - Data Type: train, Message: I have splitted different types with different parameter, I am not sure if is suitable., Label: 1\n",
      "Processing row 597 - Data Type: train, Message: If the BloomFilter to be merged is not empty, there is a small probability that the two BloomFilters will be inconsistent when judging whether there is a hash value (I added random value).\n",
      "\n",
      "But if the BloomFilter to be merged is empty in the beginning, the result from these two BloomFilter should be always the same.\n",
      "\n",
      "I add two different test cases, I am not sure if I need to add some more., Label: 1\n",
      "Processing row 598 - Data Type: train, Message: > Actually it does not matter what the data type is. We can simplify the test by writing two lists of hash values to create two BFs. Then we are pretty sure the test result of each value. What do you think?\n",
      "\n",
      "Good idea, I removed the random number logic~, Label: 0\n",
      "Processing row 599 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 600 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 601 - Data Type: train, Message: The reflection logic here is all based on the existing Avro behavior for its model cache: https://github.com/apache/avro/blob/release-1.11.1/lang/java/avro/src/main/java/org/apache/avro/specific/SpecificData.java#L76-L86\n",
      "\n",
      "btw, I'm not sure if `AvroRecordConverter` is the best place for this method -- maybe it would be better as part of `SpecificDataSupplier` or in either `AvroReadSupport` or `AvroWriteSupport` ?, Label: 1\n",
      "Processing row 602 - Data Type: train, Message: hi @gszadovszky ! Is there anything I can do to improve this PR?, Label: 0\n",
      "Processing row 603 - Data Type: train, Message: From where it's called in the code, `schema` should never be null -- but I guess it would be safest to add a null-check here to future-proof it a bit. Added!, Label: 0\n",
      "Processing row 604 - Data Type: train, Message: the declared `mockito.version` in the root `pom.xml`, `1.10.19`, is incompatible with Powermock 2.0.x.... but I can't downgrade Powermock to 1.x without the test throwing some scary objenesis errors, so I think Powermock 2.x is the lowest we can go., Label: 0\n",
      "Processing row 605 - Data Type: train, Message: @wgtmac thanks for your suggestions. Do you mean to read the indexes column by column to reduce memory footprint? The suggested way should have less memory usage. The indexes are stored as the following from my understanding:\n",
      "```\n",
      "// column index\n",
      "block1_col1_column_index\n",
      "...\n",
      "block1_coln_column_index\n",
      "block2_col1_column_index\n",
      "...\n",
      "block2_coln_column_index\n",
      "...\n",
      "\n",
      "// offset index\n",
      "block1_col1_offset_index\n",
      "...\n",
      "block1_coln_offset_index\n",
      "block2_col1_offset_index\n",
      "...\n",
      "block2_coln_offset_index\n",
      "...\n",
      "\n",
      "// bloom index\n",
      "block1_col1_bloom_index\n",
      "...\n",
      "block1_coln_bloom_index\n",
      "block2_col1_bloom_index\n",
      "...\n",
      "block2_coln_bloom_index\n",
      "...\n",
      "```\n",
      "\n",
      "So the problem would be we still need to do random seek for a single rowgroup(3 * number of columns). The async I/O should be helpful for the random seek performance. With this PR, we only need 3 times random seek (except the column pruning) for a single rowgroup. \n",
      ", Label: 0\n",
      "Processing row 606 - Data Type: train, Message: Disabled by default to keep existing behaviors., Label: 0\n",
      "Processing row 607 - Data Type: train, Message: Corrected, Label: 0\n",
      "Processing row 608 - Data Type: val, Message: I think it's worth to keep it (just in case for http transport connector). Thoughts ?, Label: 1\n",
      "Processing row 609 - Data Type: train, Message: Hmm good point, my brain didn't catch that as my first pass was assuming spring looked at the actual variable names.\n",
      "edit: xbean, Label: 0\n",
      "Processing row 610 - Data Type: train, Message: I did a 'find references' search and yeah, you're right @mattrpav. I think this is also relevant in the discussion about active/passive/standby. It seems reasonable in the scope of this change rather than renaming to actually remove those methods/concepts. Then there is no need to consider the 'existing' terminology., Label: 0\n",
      "Processing row 611 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 612 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 613 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 614 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 615 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 616 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 617 - Data Type: val, Message: The issue I was facing was that the actual query needs to be different because we are trying to get the latest file for each Urn and the Urn is part of the name.  So, unless we do it in the query, we need to get all files, group by the Urn, and take the latest.\n",
      ", Label: 0\n",
      "Processing row 618 - Data Type: val, Message: Sure, Label: 0\n",
      "Processing row 619 - Data Type: train, Message: changed\n",
      ", Label: 0\n",
      "Processing row 620 - Data Type: train, Message: changed\n",
      ", Label: 0\n",
      "Processing row 621 - Data Type: train, Message: Each action can have its own `SelectionPolicy` of several `SelectionPolicies`. This give more flexibility for the the action itself to decide what to do with all the versions.\n",
      "\n",
      "Another approach would have been that the dataset calls `RetentionAction.getSelectionPolicy`, filters versions using this policy and then calls `RetentionAction.execute` on them. This does not work well with `MultiAccessControlAction` as there it has multiple `SelectionPolicy` and permission combination. \n",
      ", Label: 0\n",
      "Processing row 622 - Data Type: train, Message: If we go the exception approach, we should create a new exception class called say `RetentionActionNotApplicableException`. Only this exception should be caught, other exceptions should be rethrown. \n",
      "@chavdar what are your thoughts on this?\n",
      ", Label: 1\n",
      "Processing row 623 - Data Type: train, Message: Fixed\n",
      ", Label: 0\n",
      "Processing row 624 - Data Type: train, Message: Fixed\n",
      ", Label: 0\n",
      "Processing row 625 - Data Type: train, Message: This is used in `ConcurrentBoundedPriorityIterable` to make requests that are equal according to the prioritizer still different according to the internal `TreeMap`. The probability of collision is ridiculously small (long is 64 bits, even with 1million requests, the probability of collision is 2.7e-8, obviously assuming the RNG is good enough).\n",
      ", Label: 0\n",
      "Processing row 626 - Data Type: train, Message: It is used to parse the max bytes to copy in a distcp job. It should be useful in general. Will change the name.\n",
      ", Label: 0\n",
      "Processing row 627 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 628 - Data Type: train, Message: Is there a benefit to doing that? If not I will leave it this way. \n",
      ", Label: 1\n",
      "Processing row 629 - Data Type: train, Message: Fixed.\n",
      ", Label: 0\n",
      "Processing row 630 - Data Type: val, Message: Done\n",
      ", Label: 0\n",
      "Processing row 631 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 632 - Data Type: val, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 633 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 634 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 635 - Data Type: train, Message: should we cache it as class variable?\n",
      ", Label: 1\n",
      "Processing row 636 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 637 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 638 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 639 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 640 - Data Type: val, Message: done\n",
      ", Label: 0\n",
      "Processing row 641 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 642 - Data Type: train, Message: do you mean the fallback object? The cached object is a private field created by the `CachingJobCatalog`, so the `CachingJobCatalog` is the only object that can be responsible for starting/stopping it.\n",
      ", Label: 1\n",
      "Processing row 643 - Data Type: train, Message: Fixed.\n",
      ", Label: 0\n",
      "Processing row 644 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 645 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 646 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 647 - Data Type: train, Message: `public SI convertSchema` does't really make sense for the object store use case. This class exists to that every operation converter don't need to implement `public SI convertSchema`\n",
      ", Label: 0\n",
      "Processing row 648 - Data Type: val, Message: Didn't use it because resolveTemplate cannot support nulls, but added null support there\n",
      ", Label: 0\n",
      "Processing row 649 - Data Type: train, Message: Not right now. \n",
      ", Label: 0\n",
      "Processing row 650 - Data Type: val, Message: Added `HiveBaseExtractor` as a parent method for both extractors. However it is kind of awkward to try to reuse code in the constructors since there are several differences. Do you think it's worth adding several one line helper methods (e.g. for getting `HiveWorkUnit`) to avoid reusing code?\n",
      ", Label: 1\n",
      "Processing row 651 - Data Type: train, Message: Fixed\n",
      ", Label: 0\n",
      "Processing row 652 - Data Type: train, Message: Added\n",
      ", Label: 0\n",
      "Processing row 653 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 654 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 655 - Data Type: train, Message: Fixed\n",
      ", Label: 0\n",
      "Processing row 656 - Data Type: train, Message: This LOG.info won't be called often, maybe 4~5 times per market per day. And the information is kind of valuable for now. Instead, I've removed logging in doQuery() at GoogleWebmasterDataFetcherImpl. They are too trivial to keep.\n",
      ", Label: 0\n",
      "Processing row 657 - Data Type: val, Message: This is not an exhaustive list. In reality, only prefix + \"%\" is enough. Checking for the exhaustive list is too expensive, so I only checked four most likely characters. I may need to think about a different way and rewrite the whole piece here.\n",
      ", Label: 1\n",
      "Processing row 658 - Data Type: train, Message: Good point. Fixed.\n",
      ", Label: 0\n",
      "Processing row 659 - Data Type: train, Message: An example of the filter in the configuration file is Country.USA, where Country is GoogleWebmasterFilter.Dimension, USA is the value for the Country Dimension. Not quite sure what do you mean by GoogleWebmasterFilter.Dimension[DimensionValue]\n",
      ", Label: 1\n",
      "Processing row 660 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 661 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 662 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 663 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 664 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 665 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 666 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 667 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 668 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 669 - Data Type: train, Message: According to the documentation, http://gobblin.readthedocs.io/en/latest/user-guide/Configuration-Properties-Glossary/\n",
      "The description for this configuration is File location of the private key used for key based authentication. But it's for SFTP connection. Do you want me to add a new key in ConfigurationKeys.java?, Label: 0\n",
      "Processing row 670 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 671 - Data Type: train, Message: I tried to use the helper method, however, it doesn't support customized error/warning message for logs. So I cannot use it here., Label: 0\n",
      "Processing row 672 - Data Type: train, Message: As before, ExecutorUtils doesn't seem to provide fixed daemon thread pool. , Label: 1\n",
      "Processing row 673 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 674 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 675 - Data Type: train, Message: see comment about how generic we want this to be., Label: 0\n",
      "Processing row 676 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 677 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 678 - Data Type: val, Message: Switched to using injection instead of a factory., Label: 0\n",
      "Processing row 679 - Data Type: train, Message: Changed, Label: 0\n",
      "Processing row 680 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 681 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 682 - Data Type: train, Message: This is to include two jars to use ADL FileSystem in runtime. Do we want to place it in different process?, Label: 1\n",
      "Processing row 683 - Data Type: train, Message: I think it's just two different pattern for caller:\n",
      " a) config = resolveEncrypted(config, Optional.fromNullable(val))\n",
      "     or config = resolveEncrypted(config, Optional.absent())\n",
      " b) if (val != null) { config = resolveEncrypted(config); }\n",
      "\n",
      "I chose a, but don't have strong preference. Thoughts?\n",
      ", Label: 1\n",
      "Processing row 684 - Data Type: train, Message: Yes, it supposed to pick it up in runtime without this configuration, but it's not working with AdlFileSystem. I looked at their jar and they seemed misplaced service information under \"META-INF/org.apache.hadoop.fs.FileSystem\", not in \"META-INF/services/org.apache.hadoop.fs.FileSystem\", Label: 1\n",
      "Processing row 685 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 686 - Data Type: val, Message: will add, although I thought the synchronized block around getKeyRecords() means we don't need to make it volatile? , Label: 1\n",
      "Processing row 687 - Data Type: train, Message: Good point - I just tend to mark everything as immutable out of habit, but agree that it doesn't make sense here., Label: 0\n",
      "Processing row 688 - Data Type: val, Message: I think the pattern is useful just so people aren't typing the same code out all the time, yeah - I thought about trying to add that as part of this change but didn't want things to snowball too much. \n",
      "\n",
      "I suspect it won't matter much performance wise  - the cost of JSON parsing, Base64 encoding etc far dominates the instanceof/cast checks from what I've seen., Label: 0\n",
      "Processing row 689 - Data Type: train, Message: Same as above, Label: 0\n",
      "Processing row 690 - Data Type: train, Message: Same as above, Label: 0\n",
      "Processing row 691 - Data Type: train, Message: Sure. I will correct it. It reminded of chavdar., Label: 0\n",
      "Processing row 692 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 693 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 694 - Data Type: train, Message: Done\n",
      ", Label: 0\n",
      "Processing row 695 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 696 - Data Type: train, Message: Abstract class is there only to make sure that all the different HivePartitionVersionsPolicies will have the same constructor so that invoking different policies will be easy.\n",
      "I am trying to use state at as many places as possible because state has some nice inbuilt functions. Also it's being used at every place in the gobblin codebase. \n",
      "This policy's use is to shortlist the HivePartitionVersions. Exposing dataset might not be needed., Label: 0\n",
      "Processing row 697 - Data Type: train, Message: Why wouldn't it? The idea is that you shouldn't instantiate a ConfigParser of these as the API is all static methods, Label: 1\n",
      "Processing row 698 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 699 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 700 - Data Type: train, Message: Nice!, Label: 0\n",
      "Processing row 701 - Data Type: train, Message: change to renamingRequired, Label: 0\n",
      "Processing row 702 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 703 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 704 - Data Type: train, Message: Not reading magic byes, but now verifying that SerDe class is as expected., Label: 0\n",
      "Processing row 705 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 706 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 707 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 708 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 709 - Data Type: train, Message: True. Changed it., Label: 0\n",
      "Processing row 710 - Data Type: train, Message: NOT IN is not equivalent to left join/NULL. Handling of null fields is different. , Label: 0\n",
      "Processing row 711 - Data Type: train, Message: One major difference is the granularity level i.e. partition and table. , Label: 0\n",
      "Processing row 712 - Data Type: train, Message: Sorry I forgot after making changes, Label: 0\n",
      "Processing row 713 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 714 - Data Type: train, Message: Two reasons: it is slightly harder to make it thread-safe (requires some locks), and this is intended as a high performance class, locks / synchronized blocks reduce performance., Label: 1\n",
      "Processing row 715 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 716 - Data Type: train, Message: Fixed by renaming `buildQuery()` to `buildDataQuery()` and change return type to `String`\n",
      "I don't know why `updatedQuery` was named in this way.\n",
      "By tracing code, `updatedQuery` is used in `getDataMetadata()`, which will prepare query that is used to call GET command and get data from source.\n",
      "Therefore I rename to data query in both method name and log.\n",
      "However I can't rename `updatedQuery` to  `dataQuery` since it will affect subclass of `RestApiExtractor`\n",
      ", Label: 1\n",
      "Processing row 717 - Data Type: train, Message: Yes. Wrong splitter used here. , Label: 0\n",
      "Processing row 718 - Data Type: train, Message: There's already tableProps exists which represent the static table properties obtained from .job file, if any. \n",
      "\n",
      "Here there are some table props obtained from runtime. May be `runtimeTableProps` is better?, Label: 1\n",
      "Processing row 719 - Data Type: train, Message: `State` here comes from constructor and `WorkUnitState` comes from `publishData`'s parameters. Is that necessary they both contain job state? Is the task state automatically inherit all props from job state? , Label: 1\n",
      "Processing row 720 - Data Type: train, Message: I think it should work because the getIntervals is already a synchronized method. What do you think?\n",
      ", Label: 1\n",
      "Processing row 721 - Data Type: train, Message: Fixed in other classes as well., Label: 0\n",
      "Processing row 722 - Data Type: train, Message: Removed the synchronized, and yes, I am using the gobblin code style here https://gobblin.readthedocs.io/en/latest/developer-guide/files/codestyle-intellij-gobblin.xml\n",
      ", Label: 0\n",
      "Processing row 723 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 724 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 725 - Data Type: train, Message: This was actually only there for debugging. Removed it., Label: 0\n",
      "Processing row 726 - Data Type: train, Message: Is there a disadvantage to creating a new instance? Given the class is stateless, this reduces cache management., Label: 1\n",
      "Processing row 727 - Data Type: train, Message: Removed. Earlier Orchestrator was listener to both Flow and Topology Catalog creating a situation where it cannot distinguish between a Flow and Topology URI - hence no way of knowing if missing Spec runtime exception are really an issue or not. \n",
      "However, with recent changes Orchestrator only listens to Topology Catalog. So it is not needed anymore., Label: 0\n",
      "Processing row 728 - Data Type: train, Message: Removed schedule while compiling in compiler, because I think its more of a property of compiler to decide if the schedule should be passed along in the JobSpec or not. Any contrary thoughts?, Label: 1\n",
      "Processing row 729 - Data Type: train, Message: That was left behind mistakenly, removed it. \n",
      "I was simulating restart tests by not cleaning up previous state, ignoring 'already exists' exceptions and running same tests multiple times :) , Label: 0\n",
      "Processing row 730 - Data Type: train, Message: Seems to be passing on Travis for now. But we can disable it if starts failing transiently? , Label: 0\n",
      "Processing row 731 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 732 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 733 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 734 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 735 - Data Type: train, Message: I'll treat `3xx` as client error per https://www.webnots.com/3xx-http-status-codes/. This behavior can be overridden., Label: 0\n",
      "Processing row 736 - Data Type: train, Message: Right. Fixed., Label: 0\n",
      "Processing row 737 - Data Type: train, Message: As per the WIMD team request, I added Hive metastore information in PartitionDropSucceed and TableDropSucceed events only.\n",
      "Isn't hive metastore information deduced from source and target URIs? As per my understanding, it is a one-to-one mapping., Label: 1\n",
      "Processing row 738 - Data Type: train, Message: Fixed. But why does CopySource use daemon thread factory on purpose?, Label: 1\n",
      "Processing row 739 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 740 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 741 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 742 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 743 - Data Type: train, Message: `ConfigBasedCopyableDatasetFinder.findDatasets` in `ConfigBasedCleanabledDatasetFinder.java` cannot be parallelized with executors since there could be race condition for accessing trash folder. What about the current change ? , Label: 1\n",
      "Processing row 744 - Data Type: train, Message: instead of relying on the table's newAvroSchemaURL, I am now calculating newAvroSchemaURL for every partition. The reason is every partition has its own schema file, though they all might be same., Label: 1\n",
      "Processing row 745 - Data Type: train, Message: ditto, Label: 0\n",
      "Processing row 746 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 747 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 748 - Data Type: val, Message: I just realized that metadata keys can be overridden here. Bringing eventSubmitter out of handleResponse()...\n",
      "\"gobblin.http\" will be a suitable namespace?, Label: 1\n",
      "Processing row 749 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 750 - Data Type: train, Message: Since the handler is not necessary to do hive registration, does it make sense to keep this conf. for specifying the handler is actually handling hive registration ? , Label: 1\n",
      "Processing row 751 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 752 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 753 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 754 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 755 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 756 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 757 - Data Type: train, Message: Sorry, I missed those but I fixed them now.\n",
      "I also extended empty as null to treat string which only contains whitespaces as empty.\n",
      "I still think there is value in having null string and empty as null separate as there can be usecase where people have a specific null string like '-' or 'null' but they would like to treat strings which only contains whitespaces or no character as null. \n",
      "The idea is pretty similar like here: http://docs.aws.amazon.com/redshift/latest/dg/copy-parameters-data-conversion.html#copy-emptyasnull and in our environment are using this option and the null string one as well separately.\n",
      "If you guys still don't see the value, I'm happy to remove it but I think it is useful and even it could be useful at the csv converter.\n",
      "What do you think?, Label: 1\n",
      "Processing row 758 - Data Type: train, Message: Sorry, I didn't get it fully., Label: 0\n",
      "Processing row 759 - Data Type: train, Message: The childclass can always overwrite this method as needed. Here is just a default implementation of the method., Label: 0\n",
      "Processing row 760 - Data Type: train, Message: I need to call the closer here and both empty is valid so ^ won't work., Label: 0\n",
      "Processing row 761 - Data Type: val, Message: ðŸ‘ , Label: 0\n",
      "Processing row 762 - Data Type: val, Message: Parquet only has primitive types. For building complex types such as map or an array, repeatable property and groups can be used on primitive types. The JSON schema is provided by the user in the source.schema property. In this way, the data types supported by the underlying data format is abstracted away from the user. The user provides schema and complex data types are built by the converter. This kind of data types abstraction can be seen in other converters as well. However, if a type defined in source.schema is not supported by the converter it will throw UnsupportedOperationException., Label: 0\n",
      "Processing row 763 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 764 - Data Type: train, Message: It's an interesting comment. My thought is that this is a bit easier to use, you can do\n",
      "`tableCopyWorkUnit(dataset, destinationTable, \"part=part123\")`\n",
      "or\n",
      "`tableCopyWorkUnit(dataset, destinationTable, partition.getName())`\n",
      "\n",
      "The first one does not require doing a lookup in the Hive metastore, while if you have the partition object you can always use the second method.\n",
      "\n",
      "The main motivation for doing it this way, though, is that it was done this way before the refactoring. I have no problem refactoring even more to make users pass a partition if necessary., Label: 0\n",
      "Processing row 765 - Data Type: train, Message: Distinguishing inclusive/exclusive is not required for correctness here and would complicate the logic for no real gain., Label: 0\n",
      "Processing row 766 - Data Type: train, Message: Added a comment., Label: 0\n",
      "Processing row 767 - Data Type: train, Message: I started with that only; but realized that TopologyCatalog also uses the same methods.\n",
      "https://github.com/apache/incubator-gobblin/blob/master/gobblin-runtime/src/main/java/org/apache/gobblin/runtime/spec_catalog/TopologyCatalog.java#L257\n",
      "and topologies do not have group directory.\n",
      "Maybe we should write separate method for TopologyCatalog., Label: 0\n",
      "Processing row 768 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 769 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 770 - Data Type: train, Message: Why do we not want TaskExecutor#execute() along submit() ?\n",
      "Both methods were present since the beginning.\n",
      "taskExecutor#execute() is not being used in gobblin anywhere, and can be removed safely. But there is a possibility some forked branch is using it., Label: 1\n",
      "Processing row 771 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 772 - Data Type: train, Message: I am trying to increase the window time between a failure of copying and a retry for a specific file. I can refactor it if it is not necessary in this case. \n",
      "\n",
      "By \"add a check for file size\", does that mean we are not only checking the file existence but compare the file size when we decided that copy is not necessary for a file?  Does this check mainly to avoid jar file being corrupted ? It doesn't seem to be necessary since we have disable the overwrite flag. , Label: 1\n",
      "Processing row 773 - Data Type: train, Message: If break, line 423 and 424 will still be executed. Is that OK in this case ? , Label: 1\n",
      "Processing row 774 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 775 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 776 - Data Type: val, Message: The major reason is that this is a factory method, it is not tied with any specific metric type., Label: 1\n",
      "Processing row 777 - Data Type: train, Message: How is it enforced? \n",
      "I used intellij's import organization feature. It's inefficient to enforce this convention without automation., Label: 1\n",
      "Processing row 778 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 779 - Data Type: train, Message: Maybe,\n",
      "I just moved the existing code. I would prefer not to make this change for this PR., Label: 0\n",
      "Processing row 780 - Data Type: train, Message: It's just because our internal sensor/ingraph doesn't work well with counter type. It doesn't mean the num** variable should be a gauge type. But I agree the name can be more descriptive., Label: 1\n",
      "Processing row 781 - Data Type: train, Message: It is not of much use. Only Class (extending KafkaSchemaRegistry) and accepts an Avro schema for the registry is KafkaAvroSchemaRegistry., Label: 0\n",
      "Processing row 782 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 783 - Data Type: train, Message: I think this is at outer level. If I would be sorting inside loadPullFilesRecursivelyHelper(), it would have been 'at each recursion level'. Right?, Label: 1\n",
      "Processing row 784 - Data Type: train, Message: @htran1 do we have total query limits? I think each bucket is a single query, if we have total limits for querying count, we can set this bucket number., Label: 1\n",
      "Processing row 785 - Data Type: train, Message: We cannot, as the encryptor password cannot be changed once used for encryption/decryption. Only way I found was to change the encryptor itself., Label: 0\n",
      "Processing row 786 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 787 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 788 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 789 - Data Type: train, Message: changed back., Label: 0\n",
      "Processing row 790 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 791 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 792 - Data Type: train, Message: Yes that is correct! In fact, I had it as synchronized. I think I may have forgotten to do a git push after the change. , Label: 0\n",
      "Processing row 793 - Data Type: val, Message: I don't see the necessity to always load configurations under `gobblin.broker`. It also enforces extra knowledge to use gobblin, reducing usability., Label: 0\n",
      "Processing row 794 - Data Type: train, Message: It's hard for me to figure out what's the right auto scope as a `EventProducer` can be used just within a task or different tasks of a job. I would prefer whoever uses it specifies an explicit scope., Label: 1\n",
      "Processing row 795 - Data Type: train, Message: I had removed it for debugging purposes. Forgot to uncomment it back. , Label: 0\n",
      "Processing row 796 - Data Type: train, Message: Changed the comment to make it more clear. Removed the reference to \"parent\"., Label: 0\n",
      "Processing row 797 - Data Type: train, Message: Sure. One follow up question here is why do we have a copy instead of returning a reference to thunk container. Any specific use case for that? , Label: 1\n",
      "Processing row 798 - Data Type: val, Message: done now... but in a different place (tryAppend), not hasRoom. , Label: 0\n",
      "Processing row 799 - Data Type: train, Message: It is added automatically by Intellij. Is it usually the case for interface method implementation to have `@Override` annotation?, Label: 1\n",
      "Processing row 800 - Data Type: train, Message: Is there a reason to use typesafe config instead of directly using a `Map<String, Object>` that Grape.resolve needs?, Label: 1\n",
      "Processing row 801 - Data Type: train, Message: yea, but 'runImmediately' is a part of Schedule, so we need it.\n",
      "Should we make the job runImmediately if Schedule is absent?, Label: 1\n",
      "Processing row 802 - Data Type: train, Message: Yes. I am aware of that, thank you. I used it in another connector I developed.  But it doesn't\n",
      "1. Provide customized log message supported by API.\n",
      "2. The wait strategy is not as flexible, only fixed, or Fibonacci.\n",
      "I would rather not refactor it for this case.\n",
      ", Label: 0\n",
      "Processing row 803 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 804 - Data Type: train, Message: I added the check there because updateStatisticsForCurrentPartition is called from the close method, which I think happens after the currentPartitionIdx goes out of bounds, although now that I think about it, it seems like this call from close wouldn't be doing anything useful..., Label: 0\n",
      "Processing row 805 - Data Type: train, Message: Existing code has a fallback to treating the implementation name as a class name and instantiating the class using the name. The implementation names here are aliases to the class name., Label: 0\n",
      "Processing row 806 - Data Type: train, Message: `allowDifferentOrder` is allowing different record order in record iterator. \n",
      "`allowDifferentSchema` is allowing different schema in record comparison. This is useful in some Avro cases that two records are the same in terms of contents, but could have different doc in schema for example. \n",
      "\n",
      "They are not in Orc now. `allowDifferentOrder` makes sense to be added in Orc, but `allowDifferentSchema`, maybe not., Label: 0\n",
      "Processing row 807 - Data Type: val, Message: Hi, @autumnust, with this change, It will become valid. I am targeting to combine all services and commands together because the config, logging and other mgmt. logics are done differently for each script, which makes hard for new user to understand how to consistently run all services and commands with same experience. \n",
      "btw, gobblin is just soft link to gobblin.sh, it only changes the command signature than the functionality. \n",
      "Following becomes the new way of using gobblin script for various activities.\n",
      "`gobblin.sh  <command> <params>`\n",
      "`gobblin.sh  <service-name> <start|stop|status>`\n",
      "\n",
      "commands values: `admin, cli, statestore-check, statestore-clean, historystore-manager`\n",
      "service values: `standalone, cluster-master, cluster-worker, aws, yarn, mr, service`\n",
      ", Label: 0\n",
      "Processing row 808 - Data Type: train, Message: @autumnust , does that make sense ?, Label: 1\n",
      "Processing row 809 - Data Type: train, Message: ok sure, it requires log of doc changes, and some reorganization, which i can take care of but can we get #2586 merged? otherwise i ll have lot of conflicts., Label: 0\n",
      "Processing row 810 - Data Type: val, Message: ok , sure.\n",
      "is `gobblin admin <args>` fine ?\n",
      "is your comment only about `gobblin cli run <args>`? then i can bring the `run`, `watermarks`, `passwrodManager`, etc commands to gobblin.sh level so that the command signature wont change and it will remain `gobblin run <args>`. make sense?\n",
      ", Label: 1\n",
      "Processing row 811 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 812 - Data Type: val, Message: being called from a test class, Label: 0\n",
      "Processing row 813 - Data Type: train, Message: Since this config is specific to cluster jobs, I added the GOBBLIN_CLUSTER_PREFIX to the config. Maybe, gobblin.cluster.job.cancelRunningOnDelete?, Label: 0\n",
      "Processing row 814 - Data Type: val, Message: Ack., Label: 0\n",
      "Processing row 815 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 816 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 817 - Data Type: val, Message: It doesn't check that the outputSchema is indeed the merge of the inputSchema and the additional fields. , Label: 1\n",
      "Processing row 818 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 819 - Data Type: train, Message: Yes, name collisions can also happen in the sequential case if the task is reassigned in the same job execution. There is also lack of isolation for the task staging and task output in Helix execution mode since there is no task attempt guid, so the task staging and task output directories.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 820 - Data Type: val, Message: SpecProducer interface just mentions Future...\n",
      "though many producer's return CompletedFuture.\n",
      "Note that CompletedFuture is different that CompletableFuture., Label: 0\n",
      "Processing row 821 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 822 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 823 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 824 - Data Type: train, Message: Will remove the getKey and getValue methods. Not using them anymore. , Label: 0\n",
      "Processing row 825 - Data Type: train, Message: Its not on every event but every new instance of the reporter. So it's probably the order of mappers than number of messages sent out which is probably in the order of thousands. , Label: 1\n",
      "Processing row 826 - Data Type: train, Message: This should not happen. The set of files to copy in each iteration does not have duplicates. Further, each iteration finishes only when all copy tasks complete. So we should not have a situation where two or more threads to copy the same file., Label: 0\n",
      "Processing row 827 - Data Type: train, Message: It is there in minutes, just did not create the key..., Label: 0\n",
      "Processing row 828 - Data Type: val, Message: Because most of the logic are the same, ie. checking the key value size and use lock to call add_partition method. The only different is after it found the partition has already existed., Label: 0\n",
      "Processing row 829 - Data Type: train, Message: Just for using zookeeper lock, this will be used to create a path, that's why I use \"/\" , Label: 0\n",
      "Processing row 830 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 831 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 832 - Data Type: train, Message: Kafka 0.10.1.0 consumer supports offsetsForTimes. I am exploring on how can I have same functionality for lower kafka versions. I will remove this from this PR and create a new PR with time based lookup. Could you please suggest on how should we incorporate support for new kafka client versions (kafka09+) ?, Label: 1\n",
      "Processing row 833 - Data Type: val, Message: You are right! There is no wait! I copied the retry logic from **fetchResultBatchWithRetry**  and didn't look into it.\n",
      "I have another thought - Since the gobblin would re-execute the workUnit again anyway when the workUnit fails, we can just remove the retry. \n",
      "how do you think of?\n",
      ", Label: 1\n",
      "Processing row 834 - Data Type: train, Message: The TaskRunnerSuiteBase is an abstract class with two implementations, process model and thread model. Wanted to leave getServices() in TaskRunnerSuiteBase as an abstract method so as not to change the contract of the class., Label: 0\n",
      "Processing row 835 - Data Type: train, Message: Yeah - thought about it. Even if we cache the metric name mappings, we need to compute the key for the map every time. It seems like the key needs to be derived off of metric group, metric name and tags to make the metric unique, which is essentially the canonical representation of the kafka metric., Label: 0\n",
      "Processing row 836 - Data Type: train, Message: I am quite sure this warning must have got logged in the original-place-of-failure. What do you think?, Label: 1\n",
      "Processing row 837 - Data Type: train, Message: That's a good point actually. In the other `SpecProducers` they throw a runtime exception as well, would it affect anything?, Label: 1\n",
      "Processing row 838 - Data Type: train, Message: Addressed, Label: 0\n",
      "Processing row 839 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 840 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 841 - Data Type: train, Message: Do we want to remove this method? Or we do the update on columns and column.types? Since I'm not sure whether this method is called in other projects, Label: 1\n",
      "Processing row 842 - Data Type: train, Message: Haha no probs , Label: 0\n",
      "Processing row 843 - Data Type: train, Message: Oh I forgot to remove this from a previous comment that pointed out its not needed, good catch, Label: 0\n",
      "Processing row 844 - Data Type: train, Message: Hmm. I can, but is there a significant benefit to using auto-generated hashCode? The only change I am making here is to cache the hashCode to avoid re-computing it every time., Label: 1\n",
      "Processing row 845 - Data Type: train, Message: Huh I'm not sure why git says I removed the line, I only removed the newline after it because it shows up on the other side of the diff. Probably the lack of a newline? The volume is still there.\n",
      "I removed the service underneath it to move it to a new file to better separate the yamls, Label: 1\n",
      "Processing row 846 - Data Type: val, Message: Requirement changed to add a flag called update_operation=new_files_added. should that be added here or in gobblin-kafka?, Label: 1\n",
      "Processing row 847 - Data Type: train, Message: No problem. The code already has a dependency on commons lang3 (I checked the `build.gradle` of the `gobblin-core` module) but I do agree regarding consistency.\n",
      "\n",
      "One more thing: I had to make a tiny change to line #162 in `JsonElementConversionWithAvroSchemaFactory.java` because the code wasn't picking the enum name correctly. It was retrieving the type name instead, which is always `enum`. So, now the exception message reads as follows\n",
      "```\n",
      "PURPLE is not one of the valid symbols for the org.apache.gobblin.test.Colors enum: [RED, GREEN, BLUE]\n",
      "```, Label: 0\n",
      "Processing row 848 - Data Type: train, Message: Will do!, Label: 0\n",
      "Processing row 849 - Data Type: train, Message: Yes. Record Create time is a little tricky since we have not control over record creation and SLA misses based on create time may result in false positives. Having said that, I think it would be useful to have another metric to track the average delay between record creation time and extract time. Can be a separate PR., Label: 1\n",
      "Processing row 850 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 851 - Data Type: train, Message: removed the check and related test cases, Label: 0\n",
      "Processing row 852 - Data Type: train, Message: Sounds good, I realized later it still kept the issue as well, Label: 0\n",
      "Processing row 853 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 854 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 855 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 856 - Data Type: train, Message: I don't think it's necessary since if there's no flow executions, it already will throw a wrapped rest exception when sending the request in the line before., Label: 0\n",
      "Processing row 857 - Data Type: train, Message: FileIdVO: I was trying to say \"Value Object\". it is a plain object for data transfer.\n",
      "fileIdVoList: since fileIdVOList doesn't look smart, I made the O lower case., Label: 0\n",
      "Processing row 858 - Data Type: train, Message: Hmm. I was not sure if we should make close exceptions fatal. I am propagating the exception per the suggestion. Just curious if there are strong reasons we want to make close exceptions fatal., Label: 1\n",
      "Processing row 859 - Data Type: train, Message: replaced it with with WhitelistBlacklist, which internally uses java.util.regex patterns, Label: 0\n",
      "Processing row 860 - Data Type: train, Message: I am using Hadoop's GlobPattern instead of java.util.regex, because I could not find any API in java.util.regex which tells if the string is a plain string or contains special characters. Do you know any API in java.util.regex? or should I put this reason in comment?, Label: 1\n",
      "Processing row 861 - Data Type: train, Message: Same ERROR_MESSAGE is printed when the validation is false in the getFilter() method. \n",
      "\n",
      "<code>\n",
      "  log.error(LookbackPartitionFilterGenerator.class.getName()\n",
      "          + \" requires the following properties \" + Arrays.toString(new String[]{PARTITION_COLUMN, LOOKBACK, DATETIME_FORMAT}));\n",
      "<code>, Label: 0\n",
      "Processing row 862 - Data Type: train, Message: Originally was thinking to have all heavy-lifting work in constructor ( and also make retry more meaning ful there) I don't have strong opinion on this though.. , Label: 1\n",
      "Processing row 863 - Data Type: val, Message: Added. Thanks!, Label: 0\n",
      "Processing row 864 - Data Type: train, Message: One. Do we want multiple?, Label: 0\n",
      "Processing row 865 - Data Type: train, Message: It is a global map since I made it static right? Or are you saying it shouldn't be global?, Label: 1\n",
      "Processing row 866 - Data Type: train, Message: Is it necessary to add another lock here? I've added a lock in the flowgraphmonitor (which is where it gets read/set to false), and there is already a lock in this class on when it's set to true., Label: 1\n",
      "Processing row 867 - Data Type: train, Message: Hmm okay that's what I was thinking but I'm a bit confused what the concurrency issue is then. I guess the problem is that this variable could be modified from both git monitor and catalog at the same time?\n",
      "\n",
      "In that case it should work to modify the `setShouldRefreshFlowGraph` in catalog to acquire the same rwlock right?, Label: 1\n",
      "Processing row 868 - Data Type: train, Message: my concern is that will make the change not backward compatible, and most converter will not erase the schema prop, how about your thoughts?, Label: 1\n",
      "Processing row 869 - Data Type: train, Message: Will address, Label: 0\n",
      "Processing row 870 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 871 - Data Type: train, Message: The intent was to avoid a state where the HelixManager is in an inconsistent state where the underlying ZkClient is connected but there is a failure later. By disconnecting before retrying, we ensure any partial state during the previous connect attempt is cleaned up. \n",
      "\n",
      "The reason we are instantiating a new HelixAdmin instance (separate from HelixManager) is that getClusterManagementTool() requires HelixManager to be connected first. , Label: 0\n",
      "Processing row 872 - Data Type: train, Message: Changed it to return void. The dropInstanceIfExists method is intended to swallow HelixException that can only occur due to instance path not being present i.e instance does not exist. , Label: 0\n",
      "Processing row 873 - Data Type: train, Message: This is meant to be random duration as well. \n",
      "This kind of failure will be retried only limited times. \n",
      "User wouldn't know how long to set up. \n",
      "Only way to find a better duration is test and get an optimal value. However this is not a critical value. we don't have to really find out the most optimal value., Label: 0\n",
      "Processing row 874 - Data Type: train, Message: Oh, that is not done intentionally, after making this class implement DatasetStateStore, I forgot to to make its child class to not implement DatasetStateStore, Label: 0\n",
      "Processing row 875 - Data Type: train, Message: I don't think it actually matters? They are both pointing to originalflowconfig, so it will just replace requester list with itself, it won't lose it.\n",
      "\n",
      "Either way moved it., Label: 1\n",
      "Processing row 876 - Data Type: train, Message: I think making this configurable in the first place is a mistake - the extension should always stay consistent with the extension that you specified as part of compaction job. I get the point of decouple the configs, but they are needed in different places and that's why it is public static. ( If strict decoupling is applied then anything should be private or package-private static, which is not realistic, Label: 1\n",
      "Processing row 877 - Data Type: train, Message: Helix throws an IllegalStateException (which is a RuntimeException) when the underlying ZkClient is closed. Since it is an unchecked exception, I added a clause to catch the generic Exception. \n",
      "It is hard to determine the exact cause why the zkclient is closed in the first place. One possibility is a temporary N/W glitch which might cause the container to loose connectivity with Zk. Another possibility is a Zk session expiry, which if not properly handled by the underlying client (i.e does not restablish a connection with server) may cause the client to be closed. The logic here is to ensure that we refresh the Helix manager in these scenarios. , Label: 1\n",
      "Processing row 878 - Data Type: train, Message: The benefit is during the sorting phase and MR is going to compare key, the comparison is down to a much shortened object instead of the whole object (and we get rid of complex column like array , map, etc.).  This is improving map throughput quite a bit, and on the reducer side we are not doing much more if the shuffle key is selected properly: We chose uuid + header.time and chances for two different records to collide on this pair is pretty low. , Label: 1\n",
      "Processing row 879 - Data Type: train, Message: A side note: I think this actually could be the reason on why we are seeing one schema evolution failure in complex-nested schema on ORC reader. , Label: 1\n",
      "Processing row 880 - Data Type: train, Message: This if block is not throwing any exception, I do not understand why it was inside the try block earlier., Label: 1\n",
      "Processing row 881 - Data Type: train, Message: Yea, these configs are only for transition period, will be removed later.\n",
      "\n",
      "Do we want to always write to both the columns and one day stop writing to old column?\n",
      "\n",
      "similarly do we want to start reading from the new column immediately?\n",
      "\n",
      ", Label: 1\n",
      "Processing row 882 - Data Type: val, Message: We could, the reason I didn't want to is it would be kind of misleading right now since sometimes that will have unrelated missing config messages. I guess for now I could just add it and say \"it may be due to these errors\"., Label: 0\n",
      "Processing row 883 - Data Type: train, Message: The challenge is that if a flow doesn't compile it's hard to know why because we don't know what was the intended path. It could be because of missing edges/nodes, or unresolved config keys. It's something that could be improved upon still, but most users of gaas self-serve should be using edges we've already defined so probably shouldn't have this problem anyway., Label: 1\n",
      "Processing row 884 - Data Type: train, Message: The reason could be a couple things:\n",
      "\n",
      "1. No path found. This could be due to: the edges don't have the paths they are using, there are no edges between those nodes, the nodes or edges were not added on gaas startup due to an error, etc.\n",
      "\n",
      "2. There is an unresolved config. We do have a field that stores whatever errors we encountered with unresolved config.\n",
      "\n",
      "The problems are:\n",
      "- If it fails due to 1, there isn't really any way to know exactly what went wrong since we don't know what the intended path was.\n",
      "- Even if it fails due to 1, we may have encountered some unresolved config on a separate unintended path. So it would be pretty confusing to include an error that some config was unresolved when the real reason was that the path.\n",
      "\n",
      "If anything maybe the best message for now would just be \"This could be because no path is found, or because of X unresolved config\"?, Label: 1\n",
      "Processing row 885 - Data Type: train, Message: a separate util class is preferred over util methods, to keep util methods cleanly separate.\n",
      "a nested util class instead of an outer class is just a coding style preference., Label: 0\n",
      "Processing row 886 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 887 - Data Type: train, Message: the runOnce job's existence is difficult to check because it can instantly be deleted. hence i am checking that it eventually get deleted., Label: 0\n",
      "Processing row 888 - Data Type: train, Message: For backward-compatibility, I have added default value of USER_DEFINED_STAGING_DIR_FLAG as false, also, in disctp template the value for the above flag is false, Label: 0\n",
      "Processing row 889 - Data Type: train, Message: Actually I think a bit more into the accessTime, it might makes more sense to set this to -1 since the preservation of ModTime is actually breaking the semantics already (we preserve it for special use cases only) and it doesn't make sense to keep the original access time either. , Label: 0\n",
      "Processing row 890 - Data Type: train, Message: Right, it's not a codahale metric name. Can you suggest a right place? The current class (AbstractJobLauncher) ?, Label: 1\n",
      "Processing row 891 - Data Type: train, Message: Actually both recompaction and compaction will write to this directory if recompaction.write.to.new.folder is enabled. The daily foler will looks like /daily/2020/09/12/compaction_1 (output of first run of compaction) /daily/2020/09/12/compaction_2(output of re-compaction), so i think the COMPACTION_DIRECTORY_FORMAT will be accurate. What's your thoughts?, Label: 1\n",
      "Processing row 892 - Data Type: val, Message: Will address, Label: 0\n",
      "Processing row 893 - Data Type: train, Message: Will address, Label: 0\n",
      "Processing row 894 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 895 - Data Type: train, Message: I do not intend to just catch and throw the Throwable. I wanted to log the exception in gobblin's log. This method is called from helix class and I do not want to depend on helix code on exception handling., Label: 0\n",
      "Processing row 896 - Data Type: train, Message: the method signature does not throw any exception. RuntimeException is Unchecked exception and can be thrown without changing the signature. Throwable is not Unchecked exception., Label: 0\n",
      "Processing row 897 - Data Type: train, Message: Yes. It looks like the default Log level for tests is WARN, and this may be dependent on the specific logger implementation. But I observed flakiness running this test locally, due to the log level sometimes being set to WARN by default., Label: 1\n",
      "Processing row 898 - Data Type: train, Message: Do you think it's better to keep it backwards compatible? These configs were not required in the past, I didn't want block gaas from starting up if the version is bumped without adding these configs., Label: 1\n",
      "Processing row 899 - Data Type: val, Message: I added this in the description. Do you want me to create a separate PR for this?, Label: 0\n",
      "Processing row 900 - Data Type: train, Message: I like the idea of an admin mode! Would the admin mode just be another flow configuration parameter? How would we authenticate that?, Label: 1\n",
      "Processing row 901 - Data Type: val, Message: It's a good idea to deprecate the LI-specific implementations. I'm just using them during tests. \n",
      "\n",
      "In the meantime, could you please tell me what avro serde do we normally use? I couldn't find a better implementation in our codebase., Label: 1\n",
      "Processing row 902 - Data Type: train, Message: Yeah, it's a newly added method which will be called in kafkaStreamingExtractor.shutdown(), and the kafkaStreamingExtractor.shutdown() method did not call super.shutdown(), so I did not add it here as well. Also super.shutdown is meaning to check it's a decorator, which is not applied to this case as well., Label: 0\n",
      "Processing row 903 - Data Type: train, Message: Will fix, Label: 0\n",
      "Processing row 904 - Data Type: train, Message: Actually it looks like that test also deletes the original group (testGroup1), which was causing some confusing behaviour, and I think could affect the already existing tests as well depending on what order they run in. I made that one depend on all the ones that rely on that group being there., Label: 0\n",
      "Processing row 905 - Data Type: train, Message: Doesn't this have the issue that the test will pass if no exception is thrown? (Unless you do something like `throw new RuntimeException(\"Shouldn't reach here\")` after the point you expect it to fail). Probably better to use the `expectedExceptionsMessageRegExp` mentioned by Alex above., Label: 1\n",
      "Processing row 906 - Data Type: train, Message: I couldn't think of a good way since it is modifying files that were used by other tests in the same class (this could have been a problem even before this PR).\n",
      "\n",
      "I decided to refactor and move this test to a separate class. I'm not sure why it was even in this class in the first place, since it seems to be testing that `LocalGroupOwnershipService` is able to pick up changes to the file, which is unrelated to flowConfig client. (And in this class there is already tests that group ownership is working while calling flowConfig client)., Label: 1\n",
      "Processing row 907 - Data Type: train, Message: Forgot to remove the method after refactoring. Fixed it., Label: 0\n",
      "Processing row 908 - Data Type: train, Message: This is a bit confusing, but it's not really a single backslash when in the schema file, it's a double backslash.\n",
      "\n",
      "Basically if you are looking at the schema file directly (without java escaping), the original is replacing `\\\"` with `\\\\\\\"`, and the part I added is replacing `\\\\` with `\\\\\\\\`. So no, the quote case is not covered by this., Label: 0\n",
      "Processing row 909 - Data Type: train, Message: Is there anything worth testing here? The only actual logic is calling PasswordManager, and based on PasswordManagerTest, it seems like we can't even enable tests that use that due to flakiness., Label: 1\n",
      "Processing row 910 - Data Type: train, Message: So the logic of verifier is if any of the verifier fail the dataset, the compaction will not run. In this case, if gmce verifier say it needs to re compact but threshold verifier say it does not need to be compacted, then the dataset will be skipped. That's the reason I embedded the logic here. , Label: 0\n",
      "Processing row 911 - Data Type: train, Message: I needed this originally for testing purposes and potentially for extensibility but realized that I can mock the name of the expected listener instead, Label: 0\n",
      "Processing row 912 - Data Type: val, Message: It's not a part of the user-facing API, just an internal class. It should be instantiated by dependency injection framework, so even if new dependencies are added, they should be injected automatically.\n",
      "\n",
      "So, I don't think backward compatibility is important here., Label: 1\n",
      "Processing row 913 - Data Type: train, Message: same as above, Label: 0\n",
      "Processing row 914 - Data Type: train, Message: This refinery logic will be significantly rebuilt in future PRs. What we have today is just a stub., Label: 0\n",
      "Processing row 915 - Data Type: train, Message: Looks like SLF4j does not have an ability to configure appenders. From their docs: \n",
      "\n",
      "> SLF4J is only a facade, meaning that it does not provide a complete logging solution. Operations such as configuring appenders or setting logging levels cannot be performed with SLF4J. Thus, at some point in time, any non-trivial application will need to directly invoke the underlying logging system. \n",
      "\n",
      "http://www.slf4j.org/faq.html#when , Label: 0\n",
      "Processing row 916 - Data Type: train, Message: Each call to consume() returns an iterator over a new batch of records. Let's say the returned records are R1, R2, R3, and further, only R2 is null-valued. If we use a single while loop, we would end up calling consume() the moment we encounter R2, resulting in R3 being skipped. With the current implementation, R2 will be skipped because it is null and the next iteration of the while loop will correctly return R3, causing the outer while loop to be exited.\n",
      "\n",
      "In theory, we can make it work with a single while loop and if conditions inside the while loop to handle the null-valued records as a special case. I am not sure if it would add more clarity than what the current implementation does., Label: 1\n",
      "Processing row 917 - Data Type: train, Message: Yeah I was trying to do that. Several reasons here: \n",
      "1. AvroOrcSchemaConverter is now defined in gobblin-orc module, I don't think it make sense for us to introduce new dependency for hive registration module.\n",
      "2.  It's doable to transfer TypeDescription to TypeInfo, but it's the same way that we need to use OrcUtils to create one objectInspector and get typeInfo there. As we are using the writer schema to get orcSchema, I think the two results should be the same? I verified one table and it looks good to me.\n",
      "What do you think?, Label: 1\n",
      "Processing row 918 - Data Type: train, Message: \"connection\".  would you like me to update to write fully?, Label: 0\n",
      "Processing row 919 - Data Type: train, Message: Yes, Fs state store does not accept add/update watermark into an existing store now, but in our case, we need to continually publish new file and update watermark so I change the behavior to make it able to overwrite existing state file.  Do you have any concern for this change? i.e we have pipeline that rely on this feature? If so, I can also make this behavior configurable, Label: 1\n",
      "Processing row 920 - Data Type: train, Message: I don't understand this comment. Do you mean to move this to a separate class?, Label: 1\n",
      "Processing row 921 - Data Type: train, Message: We want to emit GTE only when the actual watermark moves. it's either in the flush() method where watermark in state store move or we successfully commit one snapshot so that the high watermark in the iceberg table property moves. That's why the condition here is meetException is false as this means we successfully commit once for this table after we met exception. Another place we will emit GTE is at the end of the flush() (not flush(db,table)) method. , Label: 0\n",
      "Processing row 922 - Data Type: train, Message: it's named after its purpose/function, to read clearly when used; e.g. from the unit test:\n",
      "```\n",
      "    Config config = ConfigBuilder.create()\n",
      "        .addPrimitive(ConfigurationKeys.METRICS_ENABLED_KEY, \"true\")\n",
      "        .addPrimitive(MysqlJobCatalog.DB_CONFIG_PREFIX + \".\" + ConfigurationKeys.STATE_STORE_DB_URL_KEY, testDb.getJdbcUrl())\n",
      "...\n",
      "```\n",
      "what do you think?, Label: 1\n",
      "Processing row 923 - Data Type: train, Message: same comment as below, Label: 0\n",
      "Processing row 924 - Data Type: train, Message: tid is an iceberg concept with namespace and name rather than db and table. Namespace can be dbName or a multilevel name like hivedb.dbname which could lead to errors. Other option is to pass tableSpec (which has db and table name) to addFiles method. Parsing db and table name everytime we need is not ideal., Label: 0\n",
      "Processing row 925 - Data Type: train, Message: The place I could provide the boolean param for the ctor looks to be in the constructor for `JdbcWriterCommands`. It does not have much logic other than choosing which class to instantiate. There doesn't seem to be a large benefit from translating the config to a boolean one step earlier so I'll leave as is. , Label: 0\n",
      "Processing row 926 - Data Type: train, Message: Whoops yeah I meant to change that but forgot, Label: 0\n",
      "Processing row 927 - Data Type: train, Message: fromPath is a dir, because it is a .getParent() of some path. toPath is a calculated destination path, which may not exist yet, so cannot be tested to be a dir, Label: 0\n",
      "Processing row 928 - Data Type: train, Message: Okay, I removed that comment. They might not be the same if we are using prefixReplacement., Label: 1\n",
      "Processing row 929 - Data Type: train, Message: I think a scenario where the paths match exactly but fail when using `resolvePath()` should never happen, since resolvePath in this scenario would just be validating their FS is equivalent (logical vs physical paths). If it fails the `resolvePath()`, there should still be some noticeable difference in the paths such that the user can discern some sort of meaning., Label: 1\n",
      "Processing row 930 - Data Type: train, Message: Would there be any case we can run into an issue where we do ignore the schema? I guess we'd be under the assumption that the user specified fs.uri is at least consistent with the hive provided fs.uri, that there isn't any bad actors that can provide a poorly formed fs.uri, Label: 1\n",
      "Processing row 931 - Data Type: train, Message: Good catch. Yes it can throw a RuntimeException, but because instance init is called everytime a flow is compiled and it is eventually caught; and will not stop the service. I can catch it sooner and throw a PathFinderException also.... what do you say?\n",
      "I actually prefer passing a Config, or State, or Properties, so it can be used for future use cases and we do not need to change the method signature again. opinion?\n",
      ", Label: 1\n",
      "Processing row 932 - Data Type: train, Message: This is only to ensure the container size is within the range of max and min container size read from config. Originally the resource requirement was universal for all containers. Since we have different resource requirement for different helix tag, I'm not sure there's any better way., Label: 1\n",
      "Processing row 933 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 934 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 935 - Data Type: train, Message: Mocking static method. Need to use this to mock the GobblinConstructorUtils and the FileSystem static calls, Label: 0\n",
      "Processing row 936 - Data Type: train, Message: After a failure we call `writer.reset` which I think should clear this state anyway right?, Label: 0\n",
      "Processing row 937 - Data Type: train, Message: I didn't put this case into consideration: if the desiredContainerCount is smaller than requestedContainerCount, the logic wouldn't update the requestedContainerCount. So need to use desiredContainerCount instead., Label: 1\n",
      "Processing row 938 - Data Type: train, Message: I'm worried about the edge case if there are multiple flows with a 128 character-sized flowgroup, or maybe the first 200 characters even could be identical compared to their naming scheme :/ hence using the hash after flowgroup. If there are conflicts then they could be deleting each other's work directory., Label: 1\n",
      "Processing row 939 - Data Type: train, Message: Ends up we don't need this, Label: 0\n",
      "Processing row 940 - Data Type: train, Message: try catch. Don't fail loudly, Label: 0\n",
      "Processing row 941 - Data Type: train, Message: Doesn't throw IO Exception anymore, Label: 0\n",
      "Processing row 942 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 943 - Data Type: train, Message: Because the mysql based user quota store is shared and is a persistent store, so nothing lost to re-initialize during service restart, right?, Label: 1\n",
      "Processing row 944 - Data Type: train, Message: Unfortunately it's due to the implementation of the file listener, it was originally written for Gobblin pipelines and thus it uses the Hadoop Path references instead of Java's nio.file.path Path class. There are a lot of usages of Hadoop Path objects in GaaS that I find unnecessary, especially because doing so requires GaaS to stay on outdated versions of Java. Hence I try to avoid having new classes rely on the Hadoop Path library but for compatibility it seems hard to avoid., Label: 0\n",
      "Processing row 945 - Data Type: train, Message: I'll change the other functions to be synchronized as well, but I was under the impression it would be safe since those other functions are dependent on checkAndNotify, and since only 1 function execution can run at once, then the others shouldn't be able to modify the check at the same time?, Label: 0\n",
      "Processing row 946 - Data Type: train, Message: Oops ðŸ˜… , Label: 0\n",
      "Processing row 947 - Data Type: train, Message: comment is not about all the nodes, only about the start nodes., Label: 0\n",
      "Processing row 948 - Data Type: train, Message: Probably yes, but it was not being done together in InMemory version also.\n",
      "Do you want me to change both?, Label: 0\n",
      "Processing row 949 - Data Type: train, Message: I was thinking that as well because we do not one turned on without the other. However neither the `warmStandbyEnabled` or `specStoreChangeMonitorEnabled` terms encapsulate all the multi-leader mode changes as a whole. I can create a configuration key `multiLeaderModeEnabled` which we can use in both places. What do you think? , Label: 1\n",
      "Processing row 950 - Data Type: train, Message: it should be \"insert\", \"update\", \"delete\" for the mysql actions and they correspond to \"create\", \"update\", \"delete\" respectively. fixing the mismatch, Label: 0\n",
      "Processing row 951 - Data Type: train, Message: yeah, I was thinking the same, but without this commit, unit test just fails and seems add operation does not take effect. , Label: 0\n",
      "Processing row 952 - Data Type: train, Message: Not sure if we should have some sort of timeout in case the API takes a long time to respond. Currently this a blocking call and I wonder if this call fails we could block containers from being allocated in the YarnService (leading to starvation).\n",
      "\n",
      "But adding a timeout adds a potential bug / risk where we timeout and then helix starts purging instances while we are allocating new instances (bad bug with nondeterministic behavior), Label: 1\n",
      "Processing row 953 - Data Type: val, Message: The exception that could be caught is if `Integer.parseInt` tries to parse a string, or any errors resulting from `Integer.parseInt`, Label: 0\n",
      "Processing row 954 - Data Type: val, Message: ~~It should return false because if the datePath has non-numerical characters (excluding `/`), then it should not keep traversing as it is not in the right dateTime format~~, Label: 0\n",
      "Processing row 955 - Data Type: train, Message: Yea I also thought this was strange, adding., Label: 0\n",
      "Processing row 956 - Data Type: train, Message: It seems like Helix does not automatically register the participant as an instance config if it joins as a participant. We may need to call `setInstanceConfig` and double check our assumptions., Label: 1\n",
      "Processing row 957 - Data Type: train, Message: Yes that's a good point, if it is yarn specific it should lie in the `GobblinYarnTaskRunner` perhaps. However, we _can_ technically run gobblin-cluster in _non-standalone_ mode and which would rely on this code. Afaik we don't actually use that and best practice may be to use the child class instead however I don't want to change anything too drastically for the current fix. , Label: 0\n",
      "Processing row 958 - Data Type: train, Message: The helix assigned participant check will cause the task to fail when you return false. It will then go through all of the procedures we do when there is a container / pre commit check failure. \n",
      "\n",
      "In this case, it won't silently fail anyways. Do you still think it's better to throw an exception immediately?, Label: 1\n",
      "Processing row 959 - Data Type: train, Message: Yes, this means that the finally got to execute in a normal way, so shutdown hook should not double try to close again.\n",
      "Did that answer your comment?, Label: 1\n",
      "Processing row 960 - Data Type: train, Message: this is done already, perhaps you're looking at just the first commit?, Label: 0\n",
      "Processing row 961 - Data Type: train, Message: Oops I was debugging something and it got caught ðŸ˜‚ , Label: 0\n",
      "Processing row 962 - Data Type: train, Message: It could be a submission failure currently, so it's hard to differentiate. I'm going to put that logic in a different PR I think to break this up, Label: 0\n",
      "Processing row 963 - Data Type: val, Message: I think it's impossible for a state to flip flop because of the way how we perform `mergeState`, which follows an ordered execution status of \n",
      "```\n",
      "  private static final List<ExecutionStatus> ORDERED_EXECUTION_STATUSES = ImmutableList\n",
      "      .of(ExecutionStatus.COMPILED, ExecutionStatus.PENDING, ExecutionStatus.PENDING_RESUME, ExecutionStatus.PENDING_RETRY,\n",
      "          ExecutionStatus.ORCHESTRATED, ExecutionStatus.RUNNING, ExecutionStatus.COMPLETE,\n",
      "          ExecutionStatus.FAILED, ExecutionStatus.CANCELLED);\n",
      "```\n",
      "I think there is a risk if there is a COMPLETE event followed by a FAILED or CANCELLED event but I believe the first \"final\" event state we run into is the one we want users to accept., Label: 1\n",
      "Processing row 964 - Data Type: train, Message: Our main concern with measuring the delays here is to flag if there's a big timing difference between the tx occurring in the store versus us being able to consume the event. I suspect the delay will more likely be on the tx occurring to brooklin producing rather than us being slow as consumers. I don't see why partition delay would actually not be uniform because if we're performing poorly overall it would be on all partitions rather than one in particular. I don't want to overcomplicate this calculation as it's just to give us a ballpark on the delay, when the more important one is the eventToProduceDelay which I will measure in another location. , Label: 1\n",
      "Processing row 965 - Data Type: val, Message: non optional uniontypes in avro are represented as a [\"type1\", \"type2\", ...] where the first type is the default. See https://avro.apache.org/docs/1.10.2/spec.html#Unions, Label: 0\n",
      "Processing row 966 - Data Type: val, Message: Maybe the wording here is confusing. What I am trying to convey is that Existence of the table when making this call still returns true. What do you think of the following wording instead?\n",
      "\n",
      "> If the table existed before calling this method, the method will still return true\n",
      "\n",
      "The reason I even chose to add this wording is because the underlying call is `createTableIfNotExists`, which returns false if the table already existed.\n",
      "```\n",
      "  /**\n",
      "   * Create a Hive table if not exists.\n",
      "   *\n",
      "   * @param table a {@link HiveTable} to be created.\n",
      "   * @return true if the table is successfully created; false if the table already exists.\n",
      "   * @throws IOException\n",
      "   */\n",
      "  public abstract boolean createTableIfNotExists(HiveTable table)\n",
      "      throws IOException;\n",
      "``` , Label: 0\n",
      "Processing row 967 - Data Type: train, Message: These aren't used, Label: 0\n",
      "Processing row 968 - Data Type: train, Message: Putting the depends on groups here allows the class to be run on its own, but also be thread safe with the other hive metastore tests.\n",
      "\n",
      "Adding per method depends makes it so I cannot run the Iceberg tests without running all of the hive tests first (setting a break point in underlying code then becomes a pain), Label: 0\n",
      "Processing row 969 - Data Type: val, Message: In hindsight, does this value really matter? We can just return allowedDatasets as-is. \n",
      "\n",
      "But to answer your question. We can never return null from this method. We always throw an exception or allowedDatasets is overwritten by datasets (which cannot be null), Label: 1\n",
      "Processing row 970 - Data Type: val, Message: Actually. I don't think we need this. There is no transitive on mockito-all dependency in the latest iteration (maybe there was when I was drafting the PR). I am going to remove this, Label: 0\n",
      "Processing row 971 - Data Type: val, Message: In reality there's almost no case people will schedule in advance of more than a month out, maybe some monthly flow or weekly but more likely it's daily. Majority of these flows should actually be either years out (2050) or well within this time frame. What do you think about that?, Label: 1\n",
      "Processing row 972 - Data Type: train, Message: My intention is to make this map an in-memory transient object. I feel we shouldn't expose this as a config key that users can access and set externally. WDYT?, Label: 0\n",
      "Processing row 973 - Data Type: val, Message: Yeah, if we just use whatever in the `state` as is, then we will miss publishing the completion event for 2-7 am. But I think we can have a way to maintain the previously completed partition in the state for jasper to compute the delta, so upon the 8 am watermark, jasper can publish the completion event for 2-8 am altogether. Or, do you think we have a better alternative approach to this?\n",
      "\n",
      "But this will mean a huge SLA delay for downstream, does gobblin guarantee a SLA on the watermark?, Label: 1\n",
      "Processing row 974 - Data Type: train, Message: @arjun4084346 I just modified the existing dependency from an older version. I can define it under `gradle/scripts/dependencyDefinitions.gradle`. I wasn't sure why it was defined this way earlier, Label: 1\n",
      "Processing row 975 - Data Type: train, Message: the local Metastore is now started by the parent class: `HiveMetastoreTest` with the upgrade, since they now added `@BeforeClass` annotation for `startMetastore()`. Here's the [Junit api doc](https://junit.org/junit4/javadoc/latest/org/junit/BeforeClass.html) for the same. Thus, we do not need to start again for our unit tests otherwise we would run into this issue:`AlreadyExistsException(message:Database hivedb already exists)`. Alternative would be to try starting again on our side and catch the above exception and handle it., Label: 0\n",
      "Processing row 976 - Data Type: train, Message: I set it earlier to make sure when line 171 \"this.task.run();\" finishes, it can see the flag to be set already. \n",
      "As cancel and run are two method runs in different threads, so want to avoid race conditions here. \n",
      "If we set it earlier, the worst case is even task finish successfully, as long as we tried to call cancel, we will return as cancel. I think it's acceptable, but let me you WDYT., Label: 0\n",
      "Processing row 977 - Data Type: train, Message: actually in the code this is an enum, but I did not think to encode the enum in the avro schema. Overall, I see benefits of including this as an enum here. Replacing with an enum. , Label: 0\n",
      "Processing row 978 - Data Type: val, Message: How does the `@Data` annotation help here? That is for generating constructor/setter/getter right. I am noticing that the DagActionValues will include all the actions that FlowActionType will too so I am wondering if they should reuse the same enum.  , Label: 1\n",
      "Processing row 979 - Data Type: train, Message: You're right actually using `getDagAction` doesn't make sense anymore since the action is part of the primary key. Instead it may be useful to have `getDagActions(flow identifiers)` to get all pending actions associated with a flow right now. We don't have any explicit use case at the moment so I will remove this method. \n",
      "\n",
      "Any method now with the store needs all columns that comprise the primary key, so we can actually pass `DagAction` to any of these functions but looking at how the functions are used we will end up creating a new `DagAction` object then pass to the function then unpack those values anyway so I am not certain that changing the signature is that beneficial unless we care more about encapsulating the idea that the PK is needed for all of these actions and that `DagAction` is PK. , Label: 1\n",
      "Processing row 980 - Data Type: train, Message: this is a typo, it should be multiActiveScheduler enabled. These two configs are separate. , Label: 0\n",
      "Processing row 981 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 982 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 983 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 984 - Data Type: train, Message: Default is provided by GobblinClusterConfigurationKeys.DEFAULT_HELIX_JOB_SCHEDULING_THROTTLE_ENABLED_KEY in the config file, which is set to false. Should I add an additional default proof in this part?, Label: 1\n",
      "Processing row 985 - Data Type: train, Message: The endTime setting is based on the original testNewJobAndUpdate approach. Maybe I should add a comment here to explain this hardcoded time is the period we allow workflowIdMap to fetch workflowIdMap before timeout?, Label: 1\n",
      "Processing row 986 - Data Type: train, Message: Fun fact: verify without a parameter verifies the method is called exactly once! ðŸ˜ƒ, Label: 0\n",
      "Processing row 987 - Data Type: train, Message: For example, we always clean up the Gobblin state at the end of the job in the finally block. It's not like there's a point to keeping this helix job around. In the edge case scenario this Helix flow runs, we will cause issues with ZK / Helix, Label: 0\n",
      "Processing row 988 - Data Type: train, Message: I had a different idea in mind since I only wanted to check if the `FlowTriggerHandler` gets different types of statuses or not. But I guess initializing at class level and `inc()` the counter will help gauge if the traffic distribution is happening uniformly between the hosts or not!, Label: 0\n",
      "Processing row 989 - Data Type: train, Message: With lots of nesting it becomes hard to tell at which points we may have exited the code block, I'd prefer early return since I end up adding a few more checks that must pass before we submit to the dagManager., Label: 0\n",
      "Processing row 990 - Data Type: train, Message: Yes good point, I missed that it would cause a null failure there. Instead of always returning false, I changed the checks themselves to handle null properly, that seems safer in case the map is incomplete for some reason.\n",
      "`if (!results.getOrDefault(KafkaAuditCountVerifier.CompletenessType.ClassicCompleteness, false))`, Label: 0\n",
      "Processing row 991 - Data Type: train, Message: `FlowExecutionUtil` is stateless to be used by `Orchestrator` and `DagManager` so these classes are initialized to pass to the Util class. I can make the util class stateful but it doesn't end up removing these fields from the `Orchestrator` so I instead added to `DagManager`. , Label: 0\n",
      "Processing row 992 - Data Type: val, Message: I want to be clear that this is a failure that occurs related to handling all `dagAction` related code changes and easily find them when they may originate from `dagActionStoreMonitor`, `dagManager`, or other locations. We also don't use a `dagManager` prefix for other `dagManager` metrics for some reason, Label: 1\n",
      "Processing row 993 - Data Type: train, Message: Yes we do, the timestamp within `leaseObtainedStatus` is the agreed upon time that is synchronized across all hosts while the following param, `eventTimeMillis` (later called) `triggerEventTimeMillis` is local to the host and is only used for logging purposes to show us that we switch from local trigger to the synchronized trigger. Here we are just changing where it's being stored not the fact that we do update it.  , Label: 0\n",
      "Processing row 994 - Data Type: train, Message: tried to reword lmk what u think, Label: 0\n",
      "Processing row 995 - Data Type: train, Message: For the other interval I used milliseconds because everything else was millisecond level precision anyway, I don't think it's necessary in this case. Both can be generalized to seconds if that's what you're suggesting unifying, but I was trying to avoid confusion of changing the units we use in regards to everything else in `MysqlMultiActiveLeaseArbiter`. They are slightly different statements anyway do they really need to be unified? , Label: 1\n",
      "Processing row 996 - Data Type: train, Message: I intentionally added it to document what blocked the refactoring I wished to do, to be a forewarning to any future maintainer, who might also regard the change as desirable, but at first might not grasp the challenge, Label: 0\n",
      "Processing row 997 - Data Type: train, Message: those are both used, Label: 0\n",
      "Processing row 998 - Data Type: train, Message: Catching and throwing the exception will fall the service health check so the service deploy/startup will fail if we encounter NPE. Previously it would silently fail initialization is the issue. , Label: 0\n",
      "Processing row 999 - Data Type: train, Message: The other optionals used in this class are the guava one and reliant on intertwined `Orchestrator/DagManager` code. I want to avoid the inconsistency in this class for now., Label: 0\n",
      "Processing row 1000 - Data Type: train, Message: I tried to test this case and realized the `dagNode` creation util does not actually set the right `flowExecutionId` key (using `ConfigurationKeys` as opposed to `TimingEvent.FlowEventConstants.FLOW_EXECUTION_ID_FIELD)`https://github.com/apache/gobblin/blob/315d9599e08521dd71ae6dccb09b7f7254961564/gobblin-service/src/test/java/org/apache/gobblin/service/modules/orchestration/DagTestUtils.java#L81 I don't think it's worth creating duplicate method to set the key in a test util then test extracting it. The above tests are probably sufficient since it's testing extracting map keys and putting if absent. , Label: 1\n",
      "Processing row 1001 - Data Type: train, Message: not sure how I did that... good eye. , Label: 1\n",
      "Processing row 1002 - Data Type: train, Message: Are you sure this spelling will work? QAQ\n",
      "\n",
      "Should it be `3.1*` ?, Label: 1\n",
      "Processing row 1003 - Data Type: val, Message: soga, Label: 0\n",
      "Processing row 1004 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1005 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1006 - Data Type: train, Message: At present, some configurations do not support annotations `dubbo:metrics`, Label: 0\n",
      "Processing row 1007 - Data Type: train, Message: Because of https://github.com/apache/dubbo/issues/11766, Label: 0\n",
      "Processing row 1008 - Data Type: train, Message: å·²ç»å¤„ç†, Label: 0\n",
      "Processing row 1009 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 1010 - Data Type: train, Message: yes, unfortunately it does:\n",
      "```\n",
      "$ ./gradlew -Pruntime.java.home=/home/rmuir/Downloads/jdk-16 compileJava\n",
      "...\n",
      "> Task :lucene:core:compileJava FAILED\n",
      "Exception in thread \"main\" java.lang.IllegalAccessError: class com.google.errorprone.ErrorProneJavacPlugin (in unnamed module @0x31610302) cannot access class com.sun.tools.javac.api.BasicJavacTask (in module jdk.compiler) because module jdk.compiler does not export com.sun.tools.javac.api to unnamed module @0x31610302\n",
      "        at com.google.errorprone.ErrorProneJavacPlugin.init(ErrorProneJavacPlugin.java:38)\n",
      "        at jdk.compiler/com.sun.tools.javac.api.BasicJavacTask.initPlugin(BasicJavacTask.java:255)\n",
      "        at jdk.compiler/com.sun.tools.javac.api.BasicJavacTask.initPlugins(BasicJavacTask.java:229)\n",
      "        at jdk.compiler/com.sun.tools.javac.main.Main.compile(Main.java:292)\n",
      "        at jdk.compiler/com.sun.tools.javac.main.Main.compile(Main.java:176)\n",
      "        at jdk.compiler/com.sun.tools.javac.Main.compile(Main.java:64)\n",
      "        at jdk.compiler/com.sun.tools.javac.Main.main(Main.java:50)\n",
      "```, Label: 0\n",
      "Processing row 1011 - Data Type: train, Message: refs:\n",
      " https://download.java.net/java/early_access/jdk16/docs/api/jdk.incubator.vector/jdk/incubator/vector/FloatVector.html#fromByteArray(jdk.incubator.vector.VectorSpecies,byte%5B%5D,int,java.nio.ByteOrder)\n",
      "\n",
      "https://download.java.net/java/early_access/jdk16/docs/api/jdk.incubator.vector/jdk/incubator/vector/FloatVector.html#fromByteBuffer(jdk.incubator.vector.VectorSpecies,java.nio.ByteBuffer,int,java.nio.ByteOrder), Label: 0\n",
      "Processing row 1012 - Data Type: train, Message: more cases of warnings that were enabled before by default in the IDE, I turned them on because they aren't failing anything., Label: 0\n",
      "Processing row 1013 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1014 - Data Type: train, Message: It can work to apply permissions to jars, but only if they invoke the privileged methods using `AccessController.doPrivileged` (possibly checking their own custom permission first or something).\n",
      "\n",
      "Given that it seems openjdk plans to deprecate SecurityManager (https://openjdk.java.net/jeps/411), I wouldn't optimize our current setup any more?, Label: 1\n",
      "Processing row 1015 - Data Type: train, Message: Well, anything making this easier to use would be great! \n",
      "\n",
      "I really wanted the help documentation to show two phases:\n",
      "1. instrumented test execution (must be opt-in with some parameter)\n",
      "2. report generation\n",
      "\n",
      "But it made things too confusing: e.g. say you make this mistake:\n",
      "```console\n",
      "$ gradlew -Ptests.coverage=true test\n",
      "$ gradlew jacocoTestReport\n",
      "```\n",
      "\n",
      "In that case jacoco plugin is never applied and so you get a crazy error message for missing task `jacocoTestReport`. You must also add `-Ptests.coverage=true` to this secondary reporting task, or it won't work., Label: 0\n",
      "Processing row 1016 - Data Type: train, Message: Ah right this doesn't handle the per-field case correctly, I'll just remove!, Label: 0\n",
      "Processing row 1017 - Data Type: train, Message: reverted in 75339d6; yeah, this was an incidental change; serves no purpose in this PR, and iirc was not essential to the Solr-side changes either (not that that's necessarily relevant here, but still). Thanks for pointing out #192, that had escaped my notice., Label: 0\n",
      "Processing row 1018 - Data Type: train, Message: Yeah ecj is complaining that :( I haven't dived too deep into why the `randomRegexp` generates invalid `RegExp`, maybe I'll just open another issue to fix that behavior?, Label: 1\n",
      "Processing row 1019 - Data Type: train, Message: @dsmiley Is there a way to run the checks again on the code? I see that 1/3 checks failed. The failure was due to `socket hang up`. I wonder if retrying might work., Label: 1\n",
      "Processing row 1020 - Data Type: train, Message: @dsmiley ah yes you are right. Thanks for rerunning the tests.\n",
      "\n",
      "Does the new builder class look right to you? Is it expected to remove all setters from this class? This would mean I'll have to modify all their references in other classes and unit tests and replace them with builders., Label: 1\n",
      "Processing row 1021 - Data Type: train, Message: NPE?, Label: 0\n",
      "Processing row 1022 - Data Type: train, Message: There is a functional change piggybacked in the last commit - javadoc and source jars no longer receive automatic module name. I consider it a fix of something that wasn't right (these JARs are not modules)., Label: 0\n",
      "Processing row 1023 - Data Type: train, Message: Artifact rename is mentioned in migration:\n",
      "```\n",
      "## Rename of binary artifacts from '**-analyzers-**' to '**-analysis-**' (LUCENE-9562)\n",
      "```\n",
      "\n",
      "So... what should I do about module names then?... I'm not sure what the outcome of the discussion is. Perhaps we should do this - tweak the names in a way you like it and commit (or provide a change suggestion)?\n",
      ", Label: 1\n",
      "Processing row 1024 - Data Type: val, Message: ECJ's code is quite terrible... It does wonderful things but under the hood... oh, God. \n",
      "\n",
      "Separately from this, I gave up a long time ago on having my user home folder with a space inside... It just brings too much stress to life.\n",
      "\n",
      "> Do we still need to list all files since we removed the module-info.java excludes?\n",
      "\n",
      "ecj still has a bug which will prevent the Lucene code from compiling multi-release jars. It's trappy as hell. Now that log4j is gone it may work without the explicit file list - didn't check - but it also may not (because of that _other_ bug mentioned in bugzilla)., Label: 0\n",
      "Processing row 1025 - Data Type: train, Message: Ok, I see it now:\n",
      "```\n",
      "new VerifyTestClassNamingConvention(\n",
      "                    \"org.apache.lucene\", Pattern.compile(\"(.+\\\\.)(Test)([^.]+)\")))\n",
      "```\n",
      "so it in fact allows non-leading Test... Darn. This does complicate the exclusion patterns., Label: 0\n",
      "Processing row 1026 - Data Type: train, Message: I guess -1 could work but it would be a bit weird since outputs are supposed to form a semiring with `NO_OUTPUT` being the identity, ie. we'd be using -1 as a way to represent 0.\n",
      "\n",
      "I think it works correctly because the only requirement is that whenever an operation returns 0 then the same instance is returned so that it can be compared with `==`. We don't seem to require that this instance of 0 must be different from other instances of 0., Label: 0\n",
      "Processing row 1027 - Data Type: train, Message: This would be unintuitive indeed. I pushed a commit that removes the helper., Label: 0\n",
      "Processing row 1028 - Data Type: train, Message: You verified it is fine, so I will disable. Why are you always reacting so angry?, Label: 1\n",
      "Processing row 1029 - Data Type: train, Message: If you look at the other changes to me this was shocking. We had tests that converted longs to floats and compared them with an epsilon. To me this is a bug.\n",
      "\n",
      "The tests were passing because numbers in tests are small., Label: 0\n",
      "Processing row 1030 - Data Type: train, Message: committed., Label: 0\n",
      "Processing row 1031 - Data Type: train, Message: definitely, I had misread the collector used by count, I will clarify., Label: 1\n",
      "Processing row 1032 - Data Type: val, Message: I meant match count, but count is fine too., Label: 0\n",
      "Processing row 1033 - Data Type: train, Message: Unfortunately, we can't call/delegate to other `this()` from the old constructor. A kind of chicken-egg problem is there -  `getClass()` in it -  this is needed to delegate to the newly added constructor that takes input streams, but it's a constructor so `getClass()` can't be invoked before `this()`.\n",
      "\n",
      "Instead, we can retire the old constructor and call `this()` or new `super()` in the implementation classes without changing public APIs. Anyway, it's not great to have the if-else for resource switching and the current `super()` call to delegate class resources loading; I think it is okay to remove the old constructor in the abstract `BinaryDictionary` right now?\n",
      "https://github.com/apache/lucene/pull/643/commits/9c2c971fae0cba6762fbbb0a7c62d1115e50b33d, Label: 0\n",
      "Processing row 1034 - Data Type: train, Message: I didn't notice there is `o.a.l.util.IOSupplier`. It's confusing to have two interfaces with the same signature.\n",
      "\n",
      "Also, there are other functional interfaces in `o.a.l.util.IOUtils` corresponding to Java stdlib's Consumer and Function.\n",
      "I think it might be better to move all functional interfaces in `o.a.l.util.IOUtils` to top-level interfaces? @uschindler \n",
      ", Label: 1\n",
      "Processing row 1035 - Data Type: train, Message: It seems there is a bit of disagreement in the API design. I think we'd need to solve this inconsistency in the core util's API to proceed with LUCENE-10400, I will open an issue., Label: 1\n",
      "Processing row 1036 - Data Type: train, Message: HI @romseygeek, thanks for the reply, ok for everything!\n",
      " I'll work on that, regarding the interface implementation split, that I agree it's more clear, How you suggest to let user select the implementattion? Keeping the readonly flag in MonitorConfiguration and instantiating the correct on in Monitor, should be enough?, Label: 1\n",
      "Processing row 1037 - Data Type: train, Message: I'm trying to wrap my head around it and tried few things, but from what I understand search methods cannot be isolated from cache population, so without a middle abstract class I'll end up with a lot of duplicate code.\n",
      "I don't like to have  `Interface -> BaseAbstract` and two implemtation hierarchy so much. We could skip the interface, but still I don't like it.\n",
      "\n",
      "Maybe I'm missing something, but Monitor.search seems very coupled with loading in memory all stored queries in `ConcurrentMap<String, QueryCacheEntry> queries` so I have to replicate all query cache releated code.\n",
      "\n",
      "Am I wrong?, Label: 1\n",
      "Processing row 1038 - Data Type: train, Message: yes better, Label: 0\n",
      "Processing row 1039 - Data Type: val, Message: Yes, it all goes to the `MonitorQueryCollector` that relies on the in-memory query  cache, and it is an internal class of WritableQueryIndex.\n",
      "\n",
      "Are you suggesting to decouple `ReadonlyMonitorQueryCollector` as a lazy query parser,  outside Readonly Monitor ?\n",
      "Am I getting it right? @romseygeek , Label: 1\n",
      "Processing row 1040 - Data Type: train, Message: Ok it's more clear now.\n",
      "I can do it that way, but The readonly monitor would need a way to repopulate the cache too, assuming there are other writer that insert and delete on the same index, the readonly would never get the delta untile it gets re-instantiated to populate its Map. \n",
      "This way would not be so useful., Label: 1\n",
      "Processing row 1041 - Data Type: train, Message: What do you think if I keep all the in-memory cache things along with the purgeExecutor in the abstract QueryIndex class and let the readonly monitor use it too, closing this round of improvements.\n",
      "Then open another changeset to implement the lazy parsing.\n",
      ", Label: 0\n",
      "Processing row 1042 - Data Type: train, Message: Yes.\n",
      "@romseygeek Do you think it could make sense using the purge executor here too?, Label: 1\n",
      "Processing row 1043 - Data Type: train, Message: `indexSort.getSort()[0].getMissingValue() == null`\n",
      "It indeed seems too aggressive, Thanks., Label: 0\n",
      "Processing row 1044 - Data Type: train, Message: it's another day, I can no longer confirm nor deny, but Uwe's explanation makes sense to me :) If we keep this change, I'd be fine with the resource naming too, although it does have that classpath connotation? , Label: 1\n",
      "Processing row 1045 - Data Type: train, Message: ++ï¼Œat [commits(ebcbd...)](https://github.com/apache/lucene/blob/ebcbdd05fbf114ca15d04cd4a9172eb51fab9a1a/lucene/core/src/java/org/apache/lucene/codecs/lucene90/compressing/Lucene90CompressingStoredFieldsWriter.java#L249) i fixed it, Label: 0\n",
      "Processing row 1046 - Data Type: val, Message: ++ ï¼Œat [commits(ebcbd)](https://github.com/apache/lucene/blob/ebcbdd05fbf114ca15d04cd4a9172eb51fab9a1a/lucene/core/src/java/org/apache/lucene/codecs/lucene90/DeflateWithPresetDictCompressionMode.java) i removed it, Label: 0\n",
      "Processing row 1047 - Data Type: train, Message: In the 1st version, i try to use doc values check compressing and decompressing, and i founded it is same as `TestLucene90DocValuesFormat` testcase. \n",
      "at commits [8c59d03](https://github.com/apache/lucene/pull/987/commits/8c59d035c504c9f51c8991a804f73d6ce7074449) i deleted `testSortedSetVariableLengthBigStoredFields`. \n",
      "\n",
      "the compressing test case would using `TestDeflateWithPresetDictCompressionMode` and `TestLZ4WithPresetDictCompressionMode`\n",
      "\n",
      "and i added readNBytes test case in `TestByteBuffersDataInput`, Label: 0\n",
      "Processing row 1048 - Data Type: train, Message: > Move it to the 9.4 section?\n",
      "\n",
      "DONE, Label: 0\n",
      "Processing row 1049 - Data Type: train, Message: there are not test failures caused by this but I have been wondering if this is acceptable., Label: 1\n",
      "Processing row 1050 - Data Type: val, Message: returning null here does not feel great, yet I did not find a better way that fits in the existing code. I tried the empty array but it required changes in how the return value is consumed., Label: 0\n",
      "Processing row 1051 - Data Type: train, Message: That's true, but is there ever a case where we would have two directories open for some reason or another? Then we'd have to think about this a bit more if we want to merge the write amplification factors or not., Label: 1\n",
      "Processing row 1052 - Data Type: train, Message: Since this is just a wrapper that we need to hold another `IndexOutput` (and instantiate so abstract classes won't work here), I'm not really sure how we could change this., Label: 1\n",
      "Processing row 1053 - Data Type: train, Message: Hmm, I think if those methods get overridden though, that would break this implementation cause it would use the wrapped `IndexOutput#writeBytes` in which case we won't be tracking the bytes anymore I think?, Label: 1\n",
      "Processing row 1054 - Data Type: val, Message: My understanding is that the real time metric would track partially completed flushed and merges, so it wouldn't be the \"true\" write amplification factor of all completed flushes and merges. I'm not sure if there are any cases where a flush or merge would get cancelled before it's completed though to be honest., Label: 1\n",
      "Processing row 1055 - Data Type: train, Message: +1 I had intended to do this (already hit port already in use while testing) -- so many things to do here!, Label: 0\n",
      "Processing row 1056 - Data Type: val, Message: I guess that's OK. ssh tunneling is always an option for ad hoc users (what I expect the main use case is ?), Label: 1\n",
      "Processing row 1057 - Data Type: train, Message: They sure can be. It does seem like a common pattern to NOT make fields `private`.\n",
      "\n",
      "At least the class itself is `private` :), Label: 0\n",
      "Processing row 1058 - Data Type: train, Message: Yeah, we could add a `reset` field to the `PackedInts` reader iterator. I opted for separation for clarity, but since the implementation is almost EXACTLY the same, it does seem redundant., Label: 0\n",
      "Processing row 1059 - Data Type: train, Message: I am storing these offsets (non-cumulative) as `int`. This is mainly to reduce heap usage when writing a larger graph (with many nodes). \n",
      "\n",
      "For this to be larger than an `int` `M` would need to be close to `Integer.MAX_VALUE / 2`. This is an unrealistic, and I would think unsupported scenario. It effectively means that every node is directly connected to every node in the graph. I think they would run out of memory before getting to this point as we eagerly allocate `int[M]` for EVERY node already..., Label: 0\n",
      "Processing row 1060 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 1061 - Data Type: train, Message: I realized I don't totally understand this suggestion. We have three `ints` and we want to compute the product as a `long`. It's totally fine if the calculated data size exceeds `Integer.MAX_VALUE`.\n",
      "\n",
      "Are you suggesting something like this?\n",
      "\n",
      "```java\n",
      "long numBytes = Math.multiplyExact(Math.multiplyExact((long) fieldEntry.size, dimension), byteSize);\n",
      "```, Label: 1\n",
      "Processing row 1062 - Data Type: train, Message: Thanks! I'm all about paranoia now after tracking down this issue ðŸ˜… , Label: 0\n",
      "Processing row 1063 - Data Type: train, Message: > I've no idea why that plugin triggers all test tasks to be included in the execution graph. Looked at the code but it's beyond me. It's wrong though, shouldn't be happening.\n",
      "\n",
      "probably [this line](https://gitlab.com/barfuin/gradle-jacoco-log/-/blob/master/src/main/java/org/barfuin/gradle/jacocolog/JacocoAggReportConfigAction.java#L67)? Where it forces the aggregation task to run after all test task it can find. , Label: 1\n",
      "Processing row 1064 - Data Type: train, Message: Im not sure on this. For random insertion for the graph, I think a BST would be better. \n",
      "\n",
      "However, the insertion pattern for merge typically wont be random. It will be more like first, nodes [15-73] are inserted, and then nodes [0-14] and then nodes [74-100]. This assumes that the MergedVectorValues are a concatenation of the segments to be merged vectors. For this, I added the small optimization of the \"lastAddedPosInLayer\" list, which will skip binary search during locally ordered insertion.\n",
      "\n",
      "That being said, I am not sure that the \"concatenation\" property is guaranteed, specifically in the case when the mergeState.needsIndexSort == true. Given this case, it seems like insertion pattern might be more random.\n",
      "\n",
      "All that being said, do you think it would be better to build for the concatenation pattern or more random insert pattern?, Label: 1\n",
      "Processing row 1065 - Data Type: train, Message: > but still because in L156 we need to copy the rest of array again and again as long as that is a non-appending action\n",
      "\n",
      "Right, this could be expensive for out of order insertion. I can try switching the nodeByLevel int array to a TreeSet and compare performance to https://github.com/apache/lucene/issues/11354.\n",
      "\n",
      "One complication with this approach is that the NodesIterator expects an int array: https://github.com/apache/lucene/blob/main/lucene/core/src/java/org/apache/lucene/util/hnsw/HnswGraph.java#L134. Given this is a public interface, we might need to either convert the treeset to an int array every time [getNodesOnLevel](https://github.com/apache/lucene/blob/main/lucene/core/src/java/org/apache/lucene/util/hnsw/OnHeapHnswGraph.java#L165) gets called, or alter the NodesIterator interface to support both an int array and an Iterator produced from the TreeSet.\n",
      "\n",
      "@zhaih What do you think of this approach? Is there better way to do this?, Label: 0\n",
      "Processing row 1066 - Data Type: train, Message: That makes sense. This shouldnt be a big problem., Label: 0\n",
      "Processing row 1067 - Data Type: train, Message: I cant think of a good way to do this. HnswGraphBuilder  already uses generics and requires that the same generic be passed in for the RandomVectorValues. So I think some branching logic will be required no matter what. Did you have an idea for this?, Label: 1\n",
      "Processing row 1068 - Data Type: train, Message: Yes, this is a good point. What about WrappedNodesIterator?, Label: 1\n",
      "Processing row 1069 - Data Type: train, Message: Yeah I was struggling with this as well. The reason I put it like this is that I feel like the `IllegalStateException` here is quite important so I don't want to throw it away, but if I put it into say `fileDeleter.clean()`, then it does not always make sense too. , Label: 0\n",
      "Processing row 1070 - Data Type: train, Message: LOL yes a mistype, Label: 0\n",
      "Processing row 1071 - Data Type: train, Message: Ah forgot that, will add!, Label: 0\n",
      "Processing row 1072 - Data Type: train, Message: I wanted to preserve the original functionality of the testcase: Checking for illegal arguments\n",
      "If we only check for the outer class, it may be possible that some other exception was thrown inside (maybe `RuntimeException(NullPointerException)`), but the test still passed?, Label: 1\n",
      "Processing row 1073 - Data Type: train, Message: Hi @rmuir, thank you for notice it.\n",
      "Actually the BoostAttribute is already used in the DelimitedBoostTokenFilter: https://github.com/apache/lucene/blob/475fbd0bdde31c6a2ae62c59505cf9e8becd50e4/lucene/analysis/common/src/java/org/apache/lucene/analysis/boost/DelimitedBoostTokenFilter.java#L39\n",
      "How about if we do some refactoring (and update the documentation) to use the BoostAttribute in both cases?, Label: 1\n",
      "Processing row 1074 - Data Type: train, Message: When we use the library DL4J to train a model and we export it, we obtain a compressed zip file.\n",
      "This zip contains multiple files but we are only interested in file `syn0`. The exception is thrown if the passed zip does not contain any `syn0` file.\n",
      "I guess `IllegalArgumentException` would fit, Label: 0\n",
      "Processing row 1075 - Data Type: train, Message: > Could you move it under Lucene 9.6?\n",
      "\n",
      "moved with 4efae16f93, Label: 0\n",
      "Processing row 1076 - Data Type: train, Message: Can you explain why this should be private?, Label: 1\n",
      "Processing row 1077 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 1078 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1079 - Data Type: train, Message: Initially, we had separate implementations for byte and float vectors. The change in approach can be seen in the commit [cb4b77c9f72551cb014d155586e399365fbcba5d](https://github.com/apache/lucene/pull/12253/commits/cb4b77c9f72551cb014d155586e399365fbcba5d). We made the decision to explore the possibility of abstracting over the vector encoding to create a simpler API for the caller.\n",
      "\n",
      "There were two main reasons for pursuing this change:\n",
      "\n",
      "- Code duplication: Having separate implementations resulted in duplicate code for byte and float vectors.\n",
      "\n",
      "- Difficulty in using float[] and byte[] vectors interchangeably: The knn vectors, whether byte or float, essentially represented the same field. The difference lay in the underlying encoding and the precision used to store the vectors. The decision to use the byte vector format over the float vector format was primarily driven by non-functional aspects such as space occupancy and performance.\n",
      "\n",
      "The proposed approach strikes a good balance in terms of abstraction level for both types of vectors.\n",
      "\n",
      "If there are compelling reasons for not proceeding with this approach, we could consider reverting to the point where the two implementations were separate.\n",
      ", Label: 1\n",
      "Processing row 1080 - Data Type: train, Message: fix it, Label: 0\n",
      "Processing row 1081 - Data Type: val, Message: Rolled back, although I feel like `static` does not add to expliicitness here considering that interfaces never can be non-static; also, most code seems to omit `static` on inner `interface`s: 23 without it VS 4 with it (including this one)., Label: 0\n",
      "Processing row 1082 - Data Type: train, Message: insert and insertDiverse are the public api of the class, i don't think there's a reason to lock it down to package only, Label: 1\n",
      "Processing row 1083 - Data Type: train, Message: to clarify -- this is about graph connectedness.  all graph ANN algorithms will break (in the sense of returning terrible results) if the graph isn't connected, because there's literally no way to get from partition A of the graph to partition B.  (I believe that hnsw construction doesn't *guarantee* connectedness but it makes it a very highly likely outcome.)\n",
      "\n",
      "the problem is that when you consider in-progress candidates together with the natural candidates you end up with a much lower level of connectivity, because you potentially get to see high-diversity neighbors \"from the future\" that stop the natural neighbors from being added.  in other words the diversity check will remove neighbors that would have been present in the graph if the nodes had been added serially, which in the worst case as illustrated in this example can actually result in a partitioned graph.\n",
      "\n",
      "(beam width is about \"are we searching far enough to find good candidates,\" so it has no special relevance to the concurrency issue here.), Label: 1\n",
      "Processing row 1084 - Data Type: train, Message: I have moved it. Is this the correct position?, Label: 1\n",
      "Processing row 1085 - Data Type: train, Message: I removed the sleep and added a CountDownLatch that acts to wait until all exceptions have been thrown before the `scorer` methods that are NOT throwing Exceptions have to wait before they increment the `callsToScorer` counter.\n",
      "\n",
      "With the original implementation of `TaskExecutor#invokeAll` this test fails about 80% of the time on my machine (I ran it about 100 times), whereas it always passes with the new impl of `invokeAll`. I don't see how to make it fully deterministically fail with the old `invokeAll` since we need the Exception to always get thrown by the \"Exception case\" scorers _before_ the non-Exception-case scorers finish.  You could put in a latch that the test waits upon that gates the non-Exception-case scorers (don't finish until the test has caught the Exception from invokeAll) - that would deterministically fail with the old version of `invokeAll`, but would never pass with the new code (it would hang indefinitely).\n",
      "\n",
      "Let me know if you see a clean way to make it deterministic with both impls of `invokeAll`., Label: 1\n",
      "Processing row 1086 - Data Type: train, Message: Using a single threaded executor would make the test more repeatable, but it also passes with the original implementation of `TaskExecutor#invokeAll`, so it doesn't really test the core change of the ticket.\n",
      "\n",
      "It passes with the existing `invokeAll` functionality because that method calls the `task.run()` on all tasks (Callables now) _before_ moving to the second part of the method where it cycles through the Futures and calls `get`. The key aspect of the test is that it needs to ensure that all threads have finished before `invokeAll` returns in a truly concurrent multi-threaded scenario.\n",
      "\n",
      "What we really want is a way to check that all `future.get` methods have been called in invokeAll before it returns, but I couldn't find a way to do that.\n",
      "\n",
      "So you either need a probabilistic test like I currently have or we would need some trick to sort of test what we want with a single threaded executor, such as:\n",
      "\n",
      "always throw at least two exceptions (except for tests where only one task is created by random chance) - and make sure that one of those exceptions is thrown by the last task to be processed. Then you would prove that the invokeAll method is waiting for all tasks to finish even when exceptions are thrown by \"intermediate\" tasks. I can try implementing that model, but it would require some documentation for maintainers to see what needs to be done to ensure the test is actually testing the key feature of the ticket., Label: 0\n",
      "Processing row 1087 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1088 - Data Type: train, Message: There are some common bits. I have moved those to `VectorSimilarityValuesSource` now. Let me know if this looks more better or cleaner?, Label: 1\n",
      "Processing row 1089 - Data Type: train, Message: I am aware of some of the subtleties of thread locals. I started with a solution that did not use them but all in all it would do the same that thread locals do :)  (e.g. keeping track of which thread runs what in a map).\n",
      "\n",
      "I think that if we make sure that a single task executor is created, which is currently the case, we should be ok?\n",
      "\n",
      "I am happy to address the naming as suggested, I was also not super happy with it.\n",
      "\n",
      "I will play with the counter idea, though I don't think that allowing multiple levels of parallelism is required? Is that necessary in your opinion?\n",
      "\n",
      "> Would it not be better to pass around the Task instance and the task instance has a method to spawn a subtask? \n",
      "\n",
      "I spent quite some time debating this with myself as well. The problem is that invokeAll does not have the current task. It may or may not be executed as part of a task. It looks like making the task available (without using thread locals!) would mean carrying the task around in many places, unless I am missing another way.\n",
      "\n",
      "\n",
      "Thanks for all the feedback Uwe!\n",
      ", Label: 1\n",
      "Processing row 1090 - Data Type: train, Message: I am not entirely sure: one aspect is that I'd like to make sure that there is a single instance of TaskExecutor, which IndexSearcher creates. All other usages should go through the existing instance retrieved from the IndexSearcher. Does that seem like a reasonable expectation?, Label: 1\n",
      "Processing row 1091 - Data Type: train, Message: which public methods require changing? As far as I understand visibility of TaskExecutor needs to become publkic from package private, but that's not a breaking change?, Label: 1\n",
      "Processing row 1092 - Data Type: train, Message: This tries to cover for leaves that have a lazy `numDocs` impl. I added a comment., Label: 0\n",
      "Processing row 1093 - Data Type: train, Message: Ah, I see it now. Sure, I'll move it.  Out of curiosity - what's going to happen if an exception is thrown from here (it's before the synchronization block)?\n",
      "```\n",
      "        // Must not hold IW's lock while closing\n",
      "        // mergeScheduler: this can lead to deadlock,\n",
      "        // e.g. TestIW.testThreadInterruptDeadlock\n",
      "        IOUtils.closeWhileHandlingException(mergeScheduler);\n",
      "```, Label: 0\n",
      "Processing row 1094 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 1095 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1096 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 1097 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1098 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1099 - Data Type: train, Message: I think when mpacks are defined the stack property should be ignored. Another option is to validate that one of the mpack declarations point to the stack.\n",
      "\n",
      "Do you want to remove the reference to stack?, Label: 1\n",
      "Processing row 1100 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1101 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 1102 - Data Type: val, Message: @adoroszlai for HDP stack the challenge is version 2.6.5 will not support the feature as initially expected (kafka version will still be current version and not 0.10.2 or higher).  What is the best way to ensure that feature will not be enabled for that version of this stack yet ensure code is in place for other stacks that may be able to leverage it? , Label: 1\n",
      "Processing row 1103 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1104 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1105 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 1106 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 1107 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 1108 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1109 - Data Type: train, Message: At some point I ran into an error where `smoke_user` was not being created, but I think the role-command order workaround addresses it, too.  So we don't need this anymore., Label: 0\n",
      "Processing row 1110 - Data Type: train, Message: You are right. I copied and wrote,but forgot to update the name., Label: 0\n",
      "Processing row 1111 - Data Type: train, Message: I did not write the description of this bug clearly. At this time, temporarily we only support one mpack per servicegroup, but finally each servicegroup must have one or more mpacks when multiple mpacks support code is implemented. Again, I will add more clearer errmsg here., Label: 0\n",
      "Processing row 1112 - Data Type: train, Message: Did not you tell, that it should be backward compatible?, Label: 1\n",
      "Processing row 1113 - Data Type: train, Message: @ncole no, actually same as previous implementation  (popen didn't use ambari_sudo or sudo command)\n",
      "\n",
      "It is another kind of problem which would need to be solved via sudo.py..., Label: 0\n",
      "Processing row 1114 - Data Type: train, Message: It is rare situation that yum hangs. Most likey it can slowly download package by holding lock. Ambari able to check package manager lock and retry package installation over time. However if some serious problem happen, what cause yum to hang, manual user debugging is needed anyway.\n",
      "\n",
      "It is lesser evil, than killing it in the middle of the work and then screw the whole system., Label: 0\n",
      "Processing row 1115 - Data Type: train, Message: Yes looks like i changed in AmbariManagementControllerImpl but not in AmbariManagementController. Thanks!, Label: 0\n",
      "Processing row 1116 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 1117 - Data Type: train, Message: I'm OK with this change...but this generates another question: shall we then remove/rename the one we already have for sync-ldap?, Label: 1\n",
      "Processing row 1118 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1119 - Data Type: train, Message: I don't think writing ambari in a fully component or stack agnostic way is possible (we already have lots of switch cases on service or component names). This feature is about handling a component specific setup. We need to know if the namenode is in federated mode and we only know this based on a component specific config file. This class represents a real domain concept and it just makes easier to extract this information from the config. Do you have a concrete idea how could we extract this info in a more dynamic way?\n",
      ", Label: 1\n",
      "Processing row 1120 - Data Type: train, Message: This makes sense but I think this is out of scope now. Anyways most of these properties were already there, I've just modified the way we parse one of them (in federation mode one can contain comma separated ids) and moved them to a separate class. How about making a jira about this improvement?, Label: 1\n",
      "Processing row 1121 - Data Type: train, Message: At begining, I thought to reuse HostResourceProvider, but I found they are totoally different resource provider: \n",
      "(1) HostResourceProvider focuses on create, update and delete Host, but HostInfoSummaryResourceProvider is a read-only provider\n",
      "(2) HostResourceProvider is only on single host, but the latter will aggregate info from all hosts in cluster or accross clusters\n",
      "So I think it is more clear to separete these two kinds of host resource providers., Label: 1\n",
      "Processing row 1122 - Data Type: train, Message: Not necessary at this time., Label: 0\n",
      "Processing row 1123 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1124 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1125 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1126 - Data Type: train, Message: Agreed it could be improved. The reason why I made this change is that the original code was swallowing exceptions and I could only see an NPE thrown elsewhere and had to spend time debugging what was actually happening., Label: 0\n",
      "Processing row 1127 - Data Type: train, Message: OK., Label: 0\n",
      "Processing row 1128 - Data Type: train, Message: Good catch.  This logic was intermixed with another kind of property validation that needed to loop over all configs.  When separating the two validations I didn't notice this one could be simplified., Label: 0\n",
      "Processing row 1129 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 1130 - Data Type: train, Message: Hm..just reading Nate's comment below and he is right too. We already have the kerberos xsi:security condition in `nonrolling-upgrade-3.0.xml` so that we can simply remove this check here. Any objection?, Label: 0\n",
      "Processing row 1131 - Data Type: train, Message: Hi,\n",
      "We have to remove hard-coded services from UI code. I will not be closing the jira after this fix so that refactoring can be done as a separate task for this jira. As for the Yarn & Mr being co-selected, it is still in discussion. cc @jayush , Label: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 1132 - Data Type: train, Message: yes, fixed, Label: 0\n",
      "Processing row 1133 - Data Type: train, Message: I'm not seeing any Alert related information in this class, only URI-s and http(s) related configuration. Even MetricsUri sounds too specific if we consider what's inside., Label: 1\n",
      "Processing row 1134 - Data Type: val, Message: It has the same structure as for blueprints. For blueprints it is modelled by the BlueprintMpackInstanceEntity, BlueprintServiceEntity, BlueprintMpackConfigEntities. \n",
      "\n",
      "Currently we are interested in the stack id's only, later also in configurations and service descriptors associated with mpacks (I saw configs are already dumped as json too).\n",
      "\n",
      "Do you think it is worth normalizing? (would mean 3 more tables, later maybe more) This information wouldn't be used outside of the scope of the replayed request., Label: 1\n",
      "Processing row 1135 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1136 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1137 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1138 - Data Type: train, Message: Fixed; could you please review again?, Label: 0\n",
      "Processing row 1139 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 1140 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1141 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1142 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1143 - Data Type: train, Message: this is the basic place where we can get a version, however we have a second one `repositoryVersionHelper.get().getRepositoryVersionEntity(cluster, cluster.getService(\"KAFKA\").getServiceComponent(\"KAFKA_BROKER\")).getRepositoryXml().manifests`, which feels better. I choosed first one as the change apply 2.3+ stacks, which may not have any vdf (not sure), Label: 1\n",
      "Processing row 1144 - Data Type: train, Message: thx, Label: 0\n",
      "Processing row 1145 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1146 - Data Type: train, Message: Now there is no get_all_properties() in execution_command module. Of course I can add it. However, there it seems different from your comment. Based on my understand, the configurations return from this call is a dict object:\n",
      "\n",
      "original code:\n",
      "configurations=params.config['configurations']['core-site']\n",
      "If we use \"module_configs.get_all_properties(params.module_name, 'core-site') which should return all core-site properties.\", does that mean the return is a list of attributes?, Label: 1\n",
      "Processing row 1147 - Data Type: train, Message: This method simply transforms a map with a lambda that is only 3 statements. I don't think further decomposition should be needed., Label: 1\n",
      "Processing row 1148 - Data Type: val, Message: I broke it up to smaller methods. I don't think it improves testing (the algorithm should be tested as a whole), on the other hand it hopefully improves readability., Label: 1\n",
      "Processing row 1149 - Data Type: train, Message: Powermock is needed because of the static call to AmbariServer.getController(), not because this method is private., Label: 0\n",
      "Processing row 1150 - Data Type: val, Message: thx, Label: 0\n",
      "Processing row 1151 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1152 - Data Type: train, Message: thx, Label: 0\n",
      "Processing row 1153 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1154 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1155 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1156 - Data Type: train, Message: We need Guice anyway...either the field would be injected or the constructor...how else would you get `TopologyHolder`? Please note this a Singleton scoped Guice bean., Label: 1\n",
      "Processing row 1157 - Data Type: train, Message: @adoroszlai  can you please provide reproduce of this?, Label: 0\n",
      "Processing row 1158 - Data Type: train, Message: removed the tests, Label: 0\n",
      "Processing row 1159 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1160 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1161 - Data Type: val, Message: We want SG name to be unique across cluster, as the name is the only thing distinguishable from API perspective. CC @jayush , Label: 0\n",
      "Processing row 1162 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1163 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1164 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1165 - Data Type: train, Message: Makes sense. Atlas does have a truststore property truststore.file; however, it only uses jceks to store the password for it. Do you guys know a way in python to extract the password from JCEKS?, Label: 1\n",
      "Processing row 1166 - Data Type: train, Message: Is logging as an error or warning would be enough?, Label: 1\n",
      "Processing row 1167 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1168 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1169 - Data Type: train, Message: Even though this is a check for AMS-hadoop sink version, it entirely relies on Ambari Server infrastructure to perform this check. Hence, I had to keep the class in ambari-server. , Label: 0\n",
      "Processing row 1170 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1171 - Data Type: train, Message: I've seen another example making such methods public. The drawback with making it public is that it will bypass authentication. On the other hand, it makes sense to call the object oriented methods of resource managers internally instead of calling the tedious hashmap based ones. @rnettleton @adoroszlai what do you think? , Label: 1\n",
      "Processing row 1172 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1173 - Data Type: val, Message: These are not overrides, but necessary implementations of interface methods.  I'm not sure they are used at all during request replay.\n",
      "\n",
      "Changed the hard-coded values to `null`., Label: 1\n",
      "Processing row 1174 - Data Type: train, Message: I added the missing javadocs, but I still think it's not just unnecessary but also harmful to enforce javadoc at private method level because it encourages people to write large methods without factoring out anything (not to mention the usual problems like extra maintenance cost and going out of sync with the code)., Label: 0\n",
      "Processing row 1175 - Data Type: train, Message: > should not preclude someone from writing concise methods.\n",
      "\n",
      "One of the reason why people like writing small methods is to eliminate the need of writing a bunch of comments. No one will do it if they need to write those comments anyway.\n",
      "\n",
      "If someone implements some logic using one big method and an other person implements the same using 10 smaller methods then the amount of required comments will be completely different (1 versus 10), even if the logic is the same. So, this rule makes the amount of required comments highly style dependent.\n",
      "\n",
      "Depending on the coding style, either people will complain about the missing comments even if the code is readable without them or they'll be completely fine with one unreadable \"God method\".\n",
      "\n",
      "> Documentation is always better than none.\n",
      "\n",
      "I disagree. It's a cost/benefit tradeoff. Comments need to be written and maintained and still they'll unavoidably go out of sync eventually, misleading the reader.\n",
      "\n",
      "Many times they don't add any extra value (like most of the comments on getter/setters) or they're untrue or the method is so simple than reading the code doesn't take longer than reading the comment. \n",
      ", Label: 1\n",
      "Processing row 1176 - Data Type: train, Message: @jayush From programming point of view, indent is useless, it is only used to display readable output for the user, if we choose tree like output, the indent will be removed. instance_manager.py::build_json_output() only returns a python dict, I do not think indent  can be used here, I assume  indent can only apply to json.dumps., Label: 0\n",
      "Processing row 1177 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 1178 - Data Type: val, Message: Removed., Label: 0\n",
      "Processing row 1179 - Data Type: val, Message: Removed, Label: 0\n",
      "Processing row 1180 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 1181 - Data Type: train, Message: really.. I was thinking that the was the only logging we really needed since it was an unexpected or undesired scenario. , Label: 0\n",
      "Processing row 1182 - Data Type: train, Message: Do we have serviceType in command.json? I cannot find it any more, could you give me a latest command.json which includes this entry? Thanks., Label: 0\n",
      "Processing row 1183 - Data Type: train, Message: This should be 'advanced'. Just like the one before (collision behavior); let me change it..., Label: 0\n",
      "Processing row 1184 - Data Type: val, Message: I think this is from an intermediate commit., Label: 1\n",
      "Processing row 1185 - Data Type: train, Message: Ok., Label: 0\n",
      "Processing row 1186 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 1187 - Data Type: val, Message: Added, Label: 0\n",
      "Processing row 1188 - Data Type: train, Message: This is true - `kerberosKeytabController.getFilteredKeytabs` finds both service and user principals - only if the given service has any components requiring the user principal on that host.\n",
      "I can reproduce this issue with 2.7.1.0-163 (see description above)\n",
      "\n",
      "This was not the case in the cluster where QE found the issue: they created the cluster with BP - topology validation was switched off - with a host group where `Druid Historical` was present but no `HDFS Client`, Label: 0\n",
      "Processing row 1189 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 1190 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 1191 - Data Type: train, Message: This patch is focusing on the warning labels\n",
      "<img width=\"520\" alt=\"screen shot 2018-10-15 at 9 09 10 am\" src=\"https://user-images.githubusercontent.com/33458261/47013099-5e9c0800-d146-11e8-8d2a-9f51626ed36e.png\">\n",
      "and the Config warning page:\n",
      "<img width=\"1370\" alt=\"screen shot 2018-10-15 at 9 09 32 am\" src=\"https://user-images.githubusercontent.com/33458261/47013213-b0449280-d146-11e8-85f5-5584066e0efe.png\">\n",
      "\n",
      "The label in the slider was changed by this PR #2399 \n",
      "I checked that the ticker labels and the slider has the attribute `white-space: nowrap;`, Label: 0\n",
      "Processing row 1192 - Data Type: train, Message: It's just leftover from my previous approach to filtering.  Removed., Label: 0\n",
      "Processing row 1193 - Data Type: train, Message: ExportBlueprintRequest seemed the  place to handle it.  But some conversion logic is only possible in BlueprintConfigurationProcessor, so I added it there, too.  It turns out that ExportBlueprintRequest no longer needs to filter, so I removed it from there., Label: 0\n",
      "Processing row 1194 - Data Type: val, Message: originally i wanted it in a different patch, but it's not really a problem if it goes with this one, Label: 0\n",
      "Processing row 1195 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1196 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 1197 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1198 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1199 - Data Type: train, Message: However, given that we need to update the upgrade class too I'd change it like set the length in Postgres to 4k too.\n",
      "\n",
      "Any objection?, Label: 1\n",
      "Processing row 1200 - Data Type: train, Message: Fixed now, Label: 0\n",
      "Processing row 1201 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1202 - Data Type: train, Message: Remove added character, Label: 0\n",
      "Processing row 1203 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 1204 - Data Type: train, Message: Addressed, Label: 0\n",
      "Processing row 1205 - Data Type: train, Message: @hapylestat @dlysnichenko @jonathan-hurley  could you please help me trigger a build for this PR?, Label: 0\n",
      "Processing row 1206 - Data Type: val, Message: Ok, Label: 0\n",
      "Processing row 1207 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1208 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 1209 - Data Type: train, Message: Thanks @chrismattmann. Should I change the path of all the .py files here to tika/dl too?, Label: 0\n",
      "Processing row 1210 - Data Type: train, Message: @thammegowda \n",
      "Yes. That sounds good. How about moving the apiBaseUri into config.xml?, Label: 0\n",
      "Processing row 1211 - Data Type: train, Message: please see,\n",
      "https://github.com/ThejanW/tika/blob/master/tika-parsers/src/main/java/org/apache/tika/parser/captioning/tf/TensorflowRESTCaptioner.java#L77-L84\n",
      "\n",
      "https://github.com/ThejanW/tika/blob/master/tika-parsers/src/main/java/org/apache/tika/parser/recognition/tf/TensorflowRESTRecogniser.java#L79-L86\n",
      "\n",
      "https://github.com/ThejanW/tika/blob/master/tika-parsers/src/main/java/org/apache/tika/parser/recognition/tf/TensorflowRESTVideoRecogniser.java#L71-L72, Label: 0\n",
      "Processing row 1212 - Data Type: train, Message: But how can we fix [TIKA-2100](https://issues.apache.org/jira/browse/TIKA-2100) without touching XHTMLContentHandler ? , Label: 1\n",
      "Processing row 1213 - Data Type: train, Message: So the answer is no, I do not need other attributes of the `<html>` tag., Label: 0\n",
      "Processing row 1214 - Data Type: train, Message: Yes, I saw that too late, sorry :) fixing it now., Label: 0\n",
      "Processing row 1215 - Data Type: val, Message: removed, Label: 0\n",
      "Processing row 1216 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 1217 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1218 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1219 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1220 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1221 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1222 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1223 - Data Type: train, Message: When compensation set retries less than or equal to 0, it will be set default value.\n",
      "This is the logic that was there, I have not changed it.\n",
      ", Label: 0\n",
      "Processing row 1224 - Data Type: train, Message: As we just get the transactionContext from business object, we need to pass them into next invocation as the omega transport does. Any thoughtï¼Ÿ, Label: 1\n",
      "Processing row 1225 - Data Type: train, Message: @zhfeng  I think what I mentioned here is nested local tx not nested saga though , Label: 1\n",
      "Processing row 1226 - Data Type: train, Message: > Why did you change the log file name?\n",
      "\n",
      "Sometimes we need to start multiple processes in the same location, so we can distinguish by the port number in the log name., Label: 1\n",
      "Processing row 1227 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1228 - Data Type: train, Message: ```java\n",
      "    invocation.next(response -> {\n",
      "      if (invocation.getOperationMeta().getSchemaQualifiedName().equals(\"server.splitParam\")) {\n",
      "```\n",
      "the judgement logic has been changed like above. Is this what you mean?, Label: 1\n",
      "Processing row 1229 - Data Type: train, Message: ```yaml\n",
      "servicecomb:\n",
      "  rest:\n",
      "    servlet:\n",
      "      urlPattern: /*\n",
      "```\n",
      "I guess you mean the configuration above should be deleted, right?, Label: 1\n",
      "Processing row 1230 - Data Type: train, Message: accept, Label: 0\n",
      "Processing row 1231 - Data Type: train, Message: accept, Label: 0\n",
      "Processing row 1232 - Data Type: train, Message: accept, Label: 0\n",
      "Processing row 1233 - Data Type: train, Message: é€šè¿‡æŸ¥çœ‹æºä»£ç å’Œä½¿ç”¨æ­¥éª¤æ¥çœ‹ï¼ŒSignature æ˜¯æœ‰çŠ¶æ€çš„ã€‚, Label: 0\n",
      "Processing row 1234 - Data Type: val, Message: deleted RestTemplate, Label: 0\n",
      "Processing row 1235 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1236 - Data Type: train, Message: deleted, Label: 0\n",
      "Processing row 1237 - Data Type: train, Message: deleted, Label: 0\n",
      "Processing row 1238 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1239 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1240 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1241 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1242 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1243 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1244 - Data Type: val, Message: yes, Label: 0\n",
      "Processing row 1245 - Data Type: train, Message: in mavenVersionFor's source codeï¼Œit need to read pom.properties,\n",
      "public static Version mavenVersionFor(ClassLoader classLoader, String groupId, String artifactId) {\n",
      "    InputStream pomPoperties = classLoader.getResourceAsStream(\"META-INF/maven/\" + \n",
      "        groupId.replaceAll(\"\\\\.\", \"/\") + \"/\" + artifactId + \"/pom.properties\");, Label: 0\n",
      "Processing row 1246 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1247 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1248 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1249 - Data Type: train, Message: Metricã€MetricNodeå’ŒMetricLoaderæ˜¯å·¥å…·ç±»ç”¨äºŽåˆ†æžä»ŽpublishèŽ·å–çš„metricsç»“æžœMap<String,Double>ï¼Œå¦‚æžœä»Žservoçš„configèŽ·å–ä¼šæ›´ç®€å•ä¸€ç‚¹ï¼ŒçŽ°åœ¨ä»ŽString id parse æ¯”å¦‚servicecomb.invocation(operation={operationName},role={role},stage={stage},statistic={statistic},status={status},unit={unit})ä¹Ÿæ˜¯æœ‰å¿…è¦çš„ï¼Œæˆ‘ä¼šåœ¨æ–°çš„PRå¢žåŠ ä½ è¯´çš„å†…å®¹, Label: 0\n",
      "Processing row 1250 - Data Type: train, Message: æˆ‘ä¼šåœ¨æ–°çš„PRå¢žåŠ ä»ŽMonitorConfigåˆ›å»ºMetricï¼Œä¸å¿…parse, Label: 0\n",
      "Processing row 1251 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1252 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 1253 - Data Type: train, Message: deleted., Label: 0\n",
      "Processing row 1254 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1255 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1256 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 1257 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1258 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1259 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1260 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1261 - Data Type: train, Message: Not sure whether this `isNull()` is actually needed. In `ReapetedMapReaderImpl` it is used in `SingleLikeRepeatedMapReaderImpl` (to check if it `isSet()`) which has  `ReapetedMapReaderImpl` as delegate.\n",
      "\n",
      "Regarding using ternary operator - it is OK, but I find current implementation cleaner (with respect to readability), because second value (`maxOffset - currentOffset - 1`) uses 3 operands., Label: 1\n",
      "Processing row 1262 - Data Type: train, Message: Removed the method., Label: 0\n",
      "Processing row 1263 - Data Type: train, Message: It was kind of a bug. Yes, this code wasn't reached by other functions (at least those I am aware of)., Label: 1\n",
      "Processing row 1264 - Data Type: train, Message: @vdiravka I have removed the `conffiles` and `control` files from drill root directory pom.xml file https://github.com/apache/drill/compare/c4feef490301f2b9e0f28a1b18dead7117cc3da8..28e617cc8b556e4adadb81379a31cdaa72a13d56 let me know if I am missing anything. , Label: 0\n",
      "Processing row 1265 - Data Type: val, Message: Lines above this are setting this to false explicitly, so to keep it consistent I set it to false. But sure, I can change it. Do I also change others to remove the explicit false assignment?, Label: 1\n",
      "Processing row 1266 - Data Type: train, Message: I don't think isEmpty() method exists for SqlNodeList class., Label: 1\n",
      "Processing row 1267 - Data Type: train, Message: Changed to use isEmptyList(), Label: 0\n",
      "Processing row 1268 - Data Type: train, Message: We have three scenarios here:\n",
      "Refresh metadata for all the columns -  allColumns - true, fieldList - []\n",
      "Refresh metadata for subset of columns - allColumns -false, fieldList - [c1,c2,..]\n",
      "Refresh metadata and don't collect column metadata - allColumns - false, fieldList - []\n",
      "Since we have three scenarios we can't represent all three by using just one variable., Label: 0\n",
      "Processing row 1269 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1270 - Data Type: val, Message: Yes. Thank you for catching this. I was having it in my mind and that is the reason I used List. But I think I lost that thought and I missed it., Label: 0\n",
      "Processing row 1271 - Data Type: train, Message: Thanks, it looks better.\n",
      "Also I have dropped usage of `base_response` local variable., Label: 0\n",
      "Processing row 1272 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 1273 - Data Type: val, Message: Changed, Label: 0\n",
      "Processing row 1274 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 1275 - Data Type: train, Message: I'm not sure which JDK issue references this specific problem, but I put a link to the one from the email chain. , Label: 1\n",
      "Processing row 1276 - Data Type: train, Message: I can't use this because the `rowcount` might be in the scientific format, resulting in a partial extraction., Label: 1\n",
      "Processing row 1277 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1278 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1279 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1280 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1281 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1282 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1283 - Data Type: train, Message: Changed the name to the `key()` and added validations, thanks!, Label: 0\n",
      "Processing row 1284 - Data Type: train, Message: Yeah, much negation... Changed the body of the method - didn't want to introduce the new `isComplex()`., Label: 0\n",
      "Processing row 1285 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1286 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1287 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1288 - Data Type: train, Message: I didn't change the behavior. \n",
      "What do you suggest? Tests are executed by JUnit, so in case of an exception they will fail just as well, but with a less clear message (because BaseTest would fail to initialize). , Label: 1\n",
      "Processing row 1289 - Data Type: train, Message: We're doing patching both in tests and in production (see Drillbit class). \n",
      "This is actually quite extensive topic. We already have shaded Guava that is used by Drill. The problem is: some of libraries we're using have transitive dependencies to different Guava versions. In total we have 3 or 4 versions we should make friends with. So shading is not the way. I guess we can do some playing with classloaders, but it'll be tricky and additionally we'll have bloated jars.\n",
      "As for your last paragraph, this would definitely be great if every library had the same dependencies versions or if Guava was fully backward compatible... Sadly, there is nothing we can do on this account., Label: 0\n",
      "Processing row 1290 - Data Type: train, Message: @vvysotskyi, not sure I can explain this. I got a runtime exception that some code could not create an instance. The error message appeared to indicate that the code was called via introspection, with the above signature. Adding the above code made the problem disappear.\n",
      "\n",
      "I should have noted the test that failed when run in Eclipse.From the comment, it seemed to be from some of the Hive tests I ran. But, today, those tests run fine without this addition. So, I removed it., Label: 1\n",
      "Processing row 1291 - Data Type: train, Message: For most of the cases yes and we build, we cannot build it for the case when recursive named record types are present (I believe it's a rare use-case but Avro supports this)., Label: 0\n",
      "Processing row 1292 - Data Type: train, Message: Well, most of the scalar type still have their own logic so left those that can be replaced with setObject with casts for visibility. Having some casts implicitly, others not might be - a little confusing., Label: 1\n",
      "Processing row 1293 - Data Type: train, Message: Well, I suppose if I won't set it, varchar type will be used anyway. Do you suggest to remove the assigment? Or use something else., Label: 1\n",
      "Processing row 1294 - Data Type: train, Message: @paul-rogers, let me explain: Dict stores `key` and `value` `ColumnMetadata`s in `TupleSchema` - the way Map's members are stored - but there's a validation for each of the fields (name, type). Dict does not contain a Map, it stores its `key` and `value` in its `TupleSchema schema` field.\n",
      "\n",
      "When `TupleMetadata` is constructed for Parquet table as part of table metadata, we loop over each Parquet field's `SchemaPath` representation (leaf fields, e.g. `` `mapcol`.`map`.`key` ``, `` `structcol`.`b` `` with the last field in schema being a primitive). Such named segments are treated as either a (Drill's) `MAP` or `DICT`, depending on parent segment type.\n",
      "\n",
      "(Parquet's) `MAP` is represented as a group (note, that nested group's name, `key_value` below, can be different, based on the system which produced the Parquet file):\n",
      "```\n",
      "<map-repetition> group <name> (MAP) {\n",
      "  repeated group key_value {\n",
      "    required <key-type> key;\n",
      "    <value-repetition> <value-type> value;\n",
      "  }\n",
      "}\n",
      "```\n",
      "and before changes in the PR, when `TupleMetadata` was being created for the table, if `DICT` column was encountered, it included a nested `key_value` group as Drill's `MAP` which then contained `key` and `value` fields. Thus, there is a need to skip this segment if we know that its parent's type is `DICT` to have correct `ColumnMetadata` for the `DICT` field., Label: 0\n",
      "Processing row 1295 - Data Type: train, Message: @paul-rogers Question... this code was cut/pasted from all the new EVF plugins.  Did I miss something here?, Label: 1\n",
      "Processing row 1296 - Data Type: train, Message: I don't think it's worth creating whole class just to reuse what amounts to basically 2 lines of code.  Maybe something for another day., Label: 1\n",
      "Processing row 1297 - Data Type: train, Message: Is that a new requirement ?  Most of the examples above use indentation, like this one.  It is formatted the same as three ticks., Label: 1\n",
      "Processing row 1298 - Data Type: train, Message: This code is full of such abbreviations. Out of scope to fix in this go-round., Label: 0\n",
      "Processing row 1299 - Data Type: train, Message: Could you please clarify it a little bit?\n",
      "Are you proposing to create one more test conf file with these configs or updating one of the existing ones?\n",
      "In the first case, I'm afraid we can face up with the problem connected with the order of reading conf files: the same config values would depend on the order of reading config files.\n",
      "In the second case, it may affect other tests., Label: 1\n",
      "Processing row 1300 - Data Type: train, Message: That could be an interesting bit of future work for someone - I'm not up for it personally., Label: 0\n",
      "Processing row 1301 - Data Type: train, Message: Hmm ... maybe ?  This might be beyond my drill budget right now, though., Label: 1\n",
      "Processing row 1302 - Data Type: val, Message: When I parse the form the inputs are all strings, but when the input comes from JSON they can be mixed types.  I think it is better this way despite the apparent duplication., Label: 0\n",
      "Processing row 1303 - Data Type: val, Message: I'm not exactly sure what an unknown type is - the switch/case is exhaustive for that enum currently:\n",
      "\n",
      "```\n",
      "public enum Kind {\n",
      "    BOOLEAN, LONG, STRING, DOUBLE\n",
      "  }\n",
      "```\n",
      "\n",
      "I have added a default clause anyway., Label: 1\n",
      "Processing row 1304 - Data Type: train, Message: I think I have long exceeded my budget for this task ... is this a hard requirement?, Label: 1\n",
      "Processing row 1305 - Data Type: train, Message: yes , Label: 0\n",
      "Processing row 1306 - Data Type: train, Message: One more answer to this question, to current SpoolingRawBatchBuffer, though it could spill to disk, but when to spill is still not memory safe. The reason is still we could not control the parallel receiver nodes one drillbit.  \n",
      "\n",
      "I also find a bug to its implementation. It calculates the memory usage of one batch by calling the `RawFragmentBatchWrapper.getBodySize()` .  That method would always return 0. As the Drillbuf's writerIndex and readerIndex are all zero at that time.\n",
      "\n",
      "\n",
      ", Label: 1\n",
      "Processing row 1307 - Data Type: train, Message: agree, Label: 0\n",
      "Processing row 1308 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 1309 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1310 - Data Type: train, Message: I know Double checked locking, I was just confused about 'DCL'., Label: 0\n",
      "Processing row 1311 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1312 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1313 - Data Type: val, Message: The list of field names is essentially static., Label: 1\n",
      "Processing row 1314 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1315 - Data Type: train, Message: The `getCoreProperties()` unfortunately is not in the `Workbook` class.  I'm remembering now that was why I had to make that cast. , Label: 0\n",
      "Processing row 1316 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1317 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1318 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1319 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1320 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 1321 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1322 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1323 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1324 - Data Type: train, Message: It might work.\n",
      "\n",
      "The underlying logparser works on the idea of a type. The useragent parser hooks to the \"HTTP.USERAGENT\" type and allows dissecting anything of that type, regardless of the name. \n",
      "\n",
      "Practically speaking:\n",
      "The logparser code only maps the request header \"user-agent\" to field \"request.user-agent\" with type \"HTTP.USERAGENT\"\n",
      "So unless someone uses the type remapping to extract the useragent from a different field this is the only naturally occurring place.\n",
      "\n",
      "If you do it that way you are working under an assumption about the name of the column instead of the internal types.\n",
      "\n",
      "You then also have to take into account that these do not need the extra step:\n",
      "\n",
      "    request_user-agent\n",
      "    request_user-agent_last\n",
      "\n",
      "and these do\n",
      "\n",
      "    request_user-agent_operating__system__version__major\n",
      "    request_user-agent_last_operating__system__version__major\n",
      "\n",
      "So what I think is that you can activate it automatically if someone does `*` or asks for something as mentioned above.\n",
      "Yet I do think that if any type remapping is done it should also be activated if something is mapped to the input type of the UserAgentDissector.\n",
      "\n",
      "If there are cases where you activate the plugin when it is not needed then the only downside of this is that you'll have extra startup time and extra memory usage.\n",
      "\n",
      "The actual parsing speed is not affected because the logparser will simply not do any of the Yauaa code if it not needed.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1325 - Data Type: train, Message: Yes, sorry. I thought it would break the link., Label: 0\n",
      "Processing row 1326 - Data Type: train, Message: Here I already put some documentation about the builtin formats. Is this enough?, Label: 1\n",
      "Processing row 1327 - Data Type: train, Message: It was added in the scope of from DRILL-7701, so I'm not sure about the intention, perhaps some random name that may be also used in some tests.\n",
      "Or this name is used intentionally if we also have Alice somewhere in the code ðŸ™‚, Label: 1\n",
      "Processing row 1328 - Data Type: val, Message: I thought to do it too. But this info can be useful for any other library shade, can't it be?, Label: 1\n",
      "Processing row 1329 - Data Type: train, Message: Here is a build at Travis that fails due to the old JNA version in that branch:  https://travis-ci.com/github/apache/drill/jobs/504592762, Label: 0\n",
      "Processing row 1330 - Data Type: train, Message: JNA comes as a transitive dependency of:\n",
      "- org.kohsuke:libpam4j in drill-java-exec and drill-jdbc-all\n",
      "- testcontainers/docker-java-api in all modules which use TestContainers (i.e. MySQL, Mongo, Splunk, Cassandra and Java Exec\n",
      "\n",
      "I think defining it in the root pom is the best!, Label: 0\n",
      "Processing row 1331 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 1332 - Data Type: train, Message: @luocooong Let's wait for a successful TravisCI build. It just failed due to some problem with TestContainers-Ryuk. I've updated TestContainers-Vault to 1.15.3.\n",
      "\n",
      "This comment is documenting what is .cnf file. But I will remove it!, Label: 0\n",
      "Processing row 1333 - Data Type: train, Message: same as above, Label: 0\n",
      "Processing row 1334 - Data Type: train, Message: There are more simplifications like this for Jersey and Jackson, Label: 0\n",
      "Processing row 1335 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 1336 - Data Type: train, Message: It is better to place it here, because this can be used for any other datasource event now. It is easy to add that for any of them this functionality. But since the implementation for any of them is specific and requires test cases, I didn't add changes for other plugins connections.\n",
      "Therefore it is a common config for all plugins, like `enabled`, Label: 0\n",
      "Processing row 1337 - Data Type: train, Message: 1. The main reason is:\n",
      "In the runtime we don't use the constructor for instantiating PluginConfigs. We deserialize them from JSON.\n",
      "So right now the tests and `SplunkTestSuite.initSplunk()` reflects this too.\n",
      "2. The other reason not all configs can be specified via constructor., Label: 0\n",
      "Processing row 1338 - Data Type: train, Message: What about placing in the beginning of the config?, Label: 1\n",
      "Processing row 1339 - Data Type: train, Message: See above, Label: 0\n",
      "Processing row 1340 - Data Type: train, Message: See above, Label: 0\n",
      "Processing row 1341 - Data Type: train, Message: Thanks, but as it is not included in the current version of calcite used in drill, so I will need to do a cherry pick on DrillCalcite1.21.0 of https://github.com/vvysotskyi/drill-calcite.git and update to 1.21.0-drill-r4, right?, Label: 0\n",
      "Processing row 1342 - Data Type: train, Message: What should the description be for the config param on line 360?, Label: 1\n",
      "Processing row 1343 - Data Type: train, Message: Would this be a proper definition for reverse: 'true if reversed, otherwise false'?, Label: 1\n",
      "Processing row 1344 - Data Type: train, Message: Okay, thank you. Should I also add descriptors to any empty Javadoc return statements?, Label: 1\n",
      "Processing row 1345 - Data Type: train, Message: This is a comment for lines 94, 290, and 366. There is a typo in the function name: loadPageIfNeeed(). I would like to fix it but do not want to mess up any other files as a result. If I change the name in all 3 cases, is it safe to fix?, Label: 1\n",
      "Processing row 1346 - Data Type: train, Message: This comment is for line 128. The link '#release(QueueLease)' throws an error. Does anyone have an idea what the replacement should be?, Label: 1\n",
      "Processing row 1347 - Data Type: train, Message: Thank you for checking into this. So, what would you recommend I replace the link with, or should I just delete the link?, Label: 1\n",
      "Processing row 1348 - Data Type: val, Message: I didn't see the response.  \n",
      "@vvysotskyi would it be possible to merge https://github.com/apache/calcite/pull/1568 to the Drill calcite?, Label: 1\n",
      "Processing row 1349 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1350 - Data Type: train, Message: @dzamo \n",
      "This is a good question.  What is supposed to happen is that inserts actually happen in batches.   Any suggestions as to how to test?  Do you think I should just generate a CSV file with 1M records and see what happens?, Label: 1\n",
      "Processing row 1351 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 1352 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 1353 - Data Type: train, Message: Fixed.  Here and elsewhere., Label: 0\n",
      "Processing row 1354 - Data Type: train, Message: As a side note, What is the difference between `opUserName` and `queryUserName`?\n",
      "```java\n",
      "opUserName = scan.getUserName();\n",
      "queryUserName = negotiator.context().getFragmentContext().getQueryUserName();\n",
      "```, Label: 1\n",
      "Processing row 1355 - Data Type: val, Message: The original plan was to delete it before merging the PR, but now I have deleted it., Label: 0\n",
      "Processing row 1356 - Data Type: train, Message: @paul-rogers Thank you very much. Does it mean that the \"sql\" character can be removed?, Label: 1\n",
      "Processing row 1357 - Data Type: train, Message: @vvysotskyi I thought the same thing in an earlier version, but I now don't think it would work.  The switch expression evaluates `pageHeader.getType()`, and the DICTIONARY_PAGE case *modifies* pageHeader because after loading the dictionary it loads another page.  So if we fell through from DICTIONARY_PAGE we'd need the switch expression to reevaluate `pageHeader.getType()` and I don't think it will do that?  I.e. I'd think switches only evaluate their expression once..., Label: 1\n",
      "Processing row 1358 - Data Type: val, Message: @vvysotskyi these two methods were already in the interface, I didn't add them.  But I agree that, unfortunately, they are not helpful because v2 rep and def level decoding requires special treatment anyway.  So should I remove them from the interface?, Label: 1\n",
      "Processing row 1359 - Data Type: train, Message: @luocooong Oh interesting.  Is it okay if I test with Drill 1.18 for the old version?  And use storage configs in files stored by drill-embedded, instead of ZooKeeper?  The drill-embedded of the new Drill version will go and look for the config files in the same location..., Label: 0\n",
      "Processing row 1360 - Data Type: train, Message: I'm hesitant to mess with this too much.  Lombok does both and this function already had a `hashcode` function. , Label: 0\n",
      "Processing row 1361 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1362 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1363 - Data Type: train, Message: @vdiravka, thanks I will do this.  My first question here is whether I should even introduce a new test class here.  I don't think there is any other test class in Drill that only contains a single test of whether format config options are present in the query plan?, Label: 1\n",
      "Processing row 1364 - Data Type: train, Message: @vdiravka I followed `ParquetProperties#WriterVersion`, that's where `PARQUET_1_0` and `PARQUET_2_0` come from.  I agree it's clunky, but on the plus side I did not have to introduce any new version format strings or case statements.  Which do you think is preferable?, Label: 1\n",
      "Processing row 1365 - Data Type: train, Message: @vdiravka maybe we should put something about a new options manager which completely handles the different priorities into the Drill v2 ideas wiki page?, Label: 0\n",
      "Processing row 1366 - Data Type: train, Message: @vdiravka do you mean a switch statement could be easier to read than this new ternary conditional?, Label: 1\n",
      "Processing row 1367 - Data Type: train, Message: It is enabled by default. So what is temporary here?, Label: 1\n",
      "Processing row 1368 - Data Type: train, Message: What changes?, Label: 1\n",
      "Processing row 1369 - Data Type: train, Message: Spaces? Could you point me what cleanup do you mean?, Label: 1\n",
      "Processing row 1370 - Data Type: val, Message: I'm not sure why this happened.  I did bump the version of `okhttp3` to 4.9.1 or whatever the latest version is, but there are no new dependencies. , Label: 1\n",
      "Processing row 1371 - Data Type: train, Message: @vvysotskyi Fixed!, Label: 0\n",
      "Processing row 1372 - Data Type: train, Message: You are correct... :-), Label: 0\n",
      "Processing row 1373 - Data Type: train, Message: Dropped., Label: 0\n",
      "Processing row 1374 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1375 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1376 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1377 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1378 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1379 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1380 - Data Type: val, Message: Fixed. Here and elsewhere. , Label: 0\n",
      "Processing row 1381 - Data Type: train, Message: > Sigh, 1-based indexing. I think the logic you chose in this PR for non-positive index values is the best we can do, considering.\n",
      "@jnturton Hi James, anything wrong here?, Label: 1\n",
      "Processing row 1382 - Data Type: train, Message: I don't _think_ so, just that Windows users are stuck on 2.0.36.Final., Label: 0\n",
      "Processing row 1383 - Data Type: train, Message: @vdiravka I did not shrink jdbc-all by that anything like that much in the end.  I did not realise that I had removed some things that are real runtime dependencies., Label: 0\n",
      "Processing row 1384 - Data Type: train, Message: @vdiravka do you mean _increase_ slightly?  So heap = 2000, direct = 2700?, Label: 1\n",
      "Processing row 1385 - Data Type: train, Message: @vdiravka no - this change is not specific to H2.  I noticed while debugging H2 test failures that the new JDBC writer code maps Drill's FLOAT4 AND FLOAT8 to the JDBC data type NUMERIC (a vardecimal type).  Apparently the idea was to try to avoid inconsistent float support across databases, but I don't think this is a good idea.  Vardecimal columns have a fixed precision and scale, making them fixed point rather floating point, and introducing the potential for data conversion problems.\n",
      "\n",
      "For example, in `TestJdbcWriterWithH2#testBasicCTASWithDataTypes` if you just change a test value by one decimal place the unit test fails:\n",
      "```\n",
      "--- \"CAST(3.0 AS FLOAT) AS float4_field,\" +\n",
      "+++ \"CAST(30.0 AS FLOAT) AS float4_field,\" +\n",
      "```\n",
      "because it has tried to convert a FLOAT4 to a DECIMAL(38,37) which can only represents numbers smaller than 10.  Since I found this while trying to upgrade H2, I decided to try to fix it too.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1386 - Data Type: val, Message: @vdiravka I must still go and make the same test change in the other JDBC writer tests..., Label: 0\n",
      "Processing row 1387 - Data Type: val, Message: @vvysotskyi Thanks for the response.  I'm trying to get the `UserSession` into the constructor, but it's a little tricky with all the reflection.  Would that be better?, Label: 1\n",
      "Processing row 1388 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1389 - Data Type: train, Message: @vdiravka it was selected for an extremely memory constrained environment and regular Drill users with such memory constraints are well-advised to make the same selection.  Will revert for now..., Label: 0\n",
      "Processing row 1390 - Data Type: train, Message: Here we have a cycle... any ideas how i could solve this without moving everything to java-exec ?, Label: 1\n",
      "Processing row 1391 - Data Type: train, Message: No, I don't know what this code is for., Label: 1\n",
      "Processing row 1392 - Data Type: val, Message: The URL encoding came from copying the link to specific text on the page. Would you rather me remove the encoding and have the URLs point to the general page instead?, Label: 0\n",
      "Processing row 1393 - Data Type: train, Message: @vvysotskyi I don't think Docker is meant to duplicate data across layers this way.   I think that each layer is supposed to be stored as a delta from the previous layer (even though it may be reported as having the cumulative size of the layers up to that point).  So the layer ordering should not affect the size of the final image.  Neverthess I have moved everything that I could above the COPY in the Dockerfile and I do still worry about a size blowup because when I list images I see 1.47GB for the image from this Dockerfile, while pulling apache/drill:1.20.0-openjdk-8 gives me an image smaller than 1GB.  \n",
      "\n",
      "```\n",
      "apache/drill               snapshot-openjdk-8   57306e5337db   3 minutes ago    1.47GB\n",
      "apache/drill               1.20.0-openjdk-8     7479402ba1b3   6 days ago       983MB\n",
      "```, Label: 0\n",
      "Processing row 1394 - Data Type: train, Message: sure!  Do you think I should rename the other one 'http_get' because that is only a simple http get?, Label: 0\n",
      "Processing row 1395 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 1396 - Data Type: val, Message: @paul-rogers Hi Paul, I am sorry that I dragged this PR out too long. I replaced hard-code to FixtureClient, but UT failed due to the Error:  \n",
      "`java.lang.AssertionError: unexpected exception type thrown; expected:<org.apache.drill.common.exceptions.UserException> but was:<java.lang.IllegalStateException>\n",
      "\tat org.apache.drill.exec.impersonation.TestInboundImpersonation.invalidProxy(TestInboundImpersonation.java:186)\n",
      "Caused by: java.lang.IllegalStateException: \n",
      "org.apache.drill.common.exceptions.UserRemoteException: PERMISSION ERROR: Cannot change option exec.impersonation.inbound_policies in scope SESSION`  \n",
      "I think the two clients cannot exist at the same time, so I changed back to the hard-code way., Label: 0\n",
      "Processing row 1397 - Data Type: val, Message: You can sort of do that now.  The issue I ran into with the `TupleMetadata` representation is that it gets very complicated when you have nested fields.  The current implementation allows you to either use the simplified implementation or you can pass a serialized `TupleMetadata` object., Label: 0\n",
      "Processing row 1398 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1399 - Data Type: train, Message: Done!  , Label: 0\n",
      "Processing row 1400 - Data Type: val, Message: There was a bunch of logic that was getting difficult to do with all the full paths, and it was really hard to debug., Label: 0\n",
      "Processing row 1401 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1402 - Data Type: val, Message: I don't know.  Patch files are supposed to be excluded by the .gitignore.  What happened was I reapplied Drill's `.gitignore` and it deleted that patch file.   I would assume this file should not be included. , Label: 1\n",
      "Processing row 1403 - Data Type: train, Message: @vvysotskyi One more question about moving converting rule to physical phase, I need to add physical agg rel node, so needs to add both hash(distribute by all keys/single key) and stream agg, right?, Label: 1\n",
      "Processing row 1404 - Data Type: train, Message: For some reason CI tests fail with hadoop-2 profile, but pass fine locally. Seems like some issue with MiniKdc., Label: 0\n",
      "Processing row 1405 - Data Type: train, Message: @vvysotskyi I've made use of a query option, how do things look now?, Label: 1\n",
      "Processing row 1406 - Data Type: train, Message: Maybe after plugin auto disabling has happened I should set a flag somewhere like QueryContext to record that it has happened. Then this code doesn't need to try to tell what happened from the exception type, it can look at the flag and see that it should not try to sync the function registry and convert the query again because a needed plugin was broken and is now disabled?, Label: 0\n",
      "Processing row 1407 - Data Type: train, Message: @vvysotskyi do you think that some new variable in UserException or UserExceptionContext which indicates that a plugin was disabled as a result of the underlying error would be preferable? This exception is visible in all of the needed places and seems like a pretty natural home for this information..., Label: 1\n",
      "Processing row 1408 - Data Type: train, Message: @vvysotskyi so do we keep auto disabling but drop retry here? We've seen JDBC plugins that point to an unresponsive remote DB fail with the first exception coming from rule collection (because, unlike most plugins, JDBC already tries to contact the remote DB for this operation). And of course before DRILL-8234, JDBC plugins not even involved in a query could cause it to fail during rule collection. , Label: 1\n",
      "Processing row 1409 - Data Type: train, Message: > Good point regarding splitting the logic. I would propose to move it instead of UDF to another place, before the `http_request` is evaluated, for example to `RexToDrill.getDrillFunctionFromOptiqCall` (or another location), so it could have a consistent behavior for regular aliases and aliases for this function when query plans contain actual storage name instead of the aliases.\n",
      "\n",
      "I like the idea.  I was almost thinking of doing it in the `StoragePluginRegistry`.  What do you think?   Could we make that a separate JIRA as I imagine that is considerably more complex?\n",
      "\n",
      "I should mention that this will still work if there are no aliases.  The order is first check to see if there is a user alias, if not, then check to see if there is a public alias, and finally if neither, use the actual text.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 1410 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 1411 - Data Type: train, Message: fixed.   Not sure how that appeared., Label: 1\n",
      "Processing row 1412 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1413 - Data Type: train, Message: @jnturton I removed the extra UDF.  I haven't messed with the convertlet logic before, but my initial digging seemed to imply that it was only for SQL keywords as defined by Calcite.  Do you know where in Drill I might add this?, Label: 1\n",
      "Processing row 1414 - Data Type: val, Message: My thinking with that is that `null` tends to break secondary functions.  Returning a default value would prevent that.  This is a debate that Paul Rogers and I have had many times.  Is it better to return null, a default or error out. , Label: 1\n",
      "Processing row 1415 - Data Type: train, Message: @jnturton I'm a little stuck here.  I did a bunch of experimentation, and right now, if the input is `null`, the function will return `null`.   However, if the input is unparsable, then the output is Jan 1, 1970 because the value of the `TimestampHolder` is `0`.   My goal is to make it so that if the input is not parsable, it will also return `null`, however I can't seem to get it to do that.\n",
      "\n",
      "I've tried using a `NullableTimestampHolder` as output and simply setting the value to `null` or not setting it at all. but When I do that, the function does not work at all.   Meaning that in the unit tests, ALL results come back as `null`.  \n",
      "\n",
      "@vvysotskyi Any suggestions?, Label: 1\n",
      "Processing row 1416 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1417 - Data Type: train, Message: Renamed..., Label: 0\n",
      "Processing row 1418 - Data Type: val, Message: @jnturton We don't have `year()` and `week()` functions unfortunately.  I do plan on adding those as well as `quarter()` and a few others.  It is possible now to do some of that but the syntax is really non-intuitive., Label: 0\n",
      "Processing row 1419 - Data Type: val, Message: Yes, I think `element` keyword usage is not common., Label: 1\n",
      "Processing row 1420 - Data Type: train, Message: It uses stats files that Drill creates (currently, only parquet format is supported), so for the case of the Delta plugin, I'm not sure whether it is a good idea to create extra files there., Label: 1\n",
      "Processing row 1421 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1422 - Data Type: train, Message: @jnturton \n",
      "I was able to replace this in the Dropbox reader, however the Box reader did not work.   Since there is additional work planned in Drill-8367, is it ok to leave this as is and we will fix it in the context of Drill-8367?, Label: 0\n",
      "Processing row 1423 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 1424 - Data Type: train, Message: I think it is unlikely that it would be reused., Label: 1\n",
      "Processing row 1425 - Data Type: val, Message: the problem with global object mappers, writers and readers is that if they are public, then someone can modify their config - exactly the issue I found in our test code\n",
      "\n",
      "I opened https://issues.apache.org/jira/browse/DRILL-8431 to look at wrapping the Jackson classes to create immutable instances that can be more safely shared. So far, that looks like a lot of work and the benefits may not be worth it., Label: 0\n",
      "Processing row 1426 - Data Type: train, Message: Oops... Nope., Label: 0\n",
      "Processing row 1427 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 1428 - Data Type: train, Message: ffs, Label: 0\n",
      "Processing row 1429 - Data Type: train, Message: I don't know if you saw what I wrote in the initial post of this PR, but the problem is that those steps expect a `Function` in Java which is also implemented by enums like `T`. So, when we restrict them to something like `ILambda` in .NET then they can't take enum values anymore as enums can't implement interfaces in .NET., Label: 1\n",
      "Processing row 1430 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1431 - Data Type: train, Message: The constructor for `IdleStateHandler` is seconds but all Gremlin Server time settings are milliseconds so i had to convert: https://netty.io/4.0/api/io/netty/handler/timeout/IdleStateHandler.html#IdleStateHandler-int-int-int-, Label: 0\n",
      "Processing row 1432 - Data Type: train, Message: Adding some general logging that explains the conversion:\n",
      "\n",
      "```text\n",
      "[INFO] GremlinServer - idleConnectionTimeout was set to 500 which resolves to 0 seconds when configuring this value - this feature will be disabled\n",
      "[INFO] GremlinServer - keepAliveInterval was set to 0 which resolves to 0 seconds when configuring this value - this feature will be disabled\n",
      "```, Label: 0\n",
      "Processing row 1433 - Data Type: train, Message: damn\n",
      ", Label: 0\n",
      "Processing row 1434 - Data Type: val, Message: I don't quite understand your first point - `__.repeat(out()).times(3)` is the first entry in the array and I believe this did fail before the `hashCode()` fix.\n",
      "\n",
      "Good point about the collision. \n",
      "Maybe I could use the same method the emit first and until first use? ie:\n",
      "```\n",
      "@Override\n",
      "    public int hashCode() {\n",
      "        int result = super.hashCode() ^ (this.repeatTraversal.hashCode() << 1);\n",
      "        result ^= Boolean.hashCode(this.untilFirst);\n",
      "        result ^= Boolean.hashCode(this.emitFirst) << 1;\n",
      "        if (this.loopName != null)\n",
      "            result ^= this.loopName.hashCode();\n",
      "        if (this.untilTraversal != null)\n",
      "            result ^= this.untilTraversal.hashCode();\n",
      "        if (this.emitTraversal != null)\n",
      "            result ^= this.emitTraversal.hashCode();\n",
      "        return result;\n",
      "    }\n",
      "```, Label: 0\n",
      "Processing row 1435 - Data Type: train, Message: This comment combined with the one from @FlorianHockmann is troublesome because GLVs don't have `ConnectedComponentVertexProgram` so the Gremlin won't work.  I think that's why I wrote the docs this way. Maybe I need to move `COMPONENT` to `ConnectedComponent` and then allow GLVs to have access. I'll do it that way. \n",
      "\n",
      "@dkuppitz do you have a similar issue with this?\n",
      "\n",
      "https://github.com/apache/tinkerpop/pull/882/files#diff-36e52ac0c49a08a7f3e6ee54b60a3745R73, Label: 1\n",
      "Processing row 1436 - Data Type: train, Message: Ugh, I was going to remove this piece as I mentioned previous versions in the comments above., Label: 0\n",
      "Processing row 1437 - Data Type: train, Message: I thought that period as with the script `g.inject()` was being treated as a delimiter for Apache Configuration, but I can't get the test to fail anymore, so I must have been mistaken in what I was seeing. changing it., Label: 1\n",
      "Processing row 1438 - Data Type: train, Message: i thought i fixed that!, Label: 0\n",
      "Processing row 1439 - Data Type: train, Message: So, a counter that breaks out of the loop after like 10 retries and `Task.Delay(TimeSpan.FromMilliseconds(5))` before the `continue`?, Label: 0\n",
      "Processing row 1440 - Data Type: train, Message: Good catch. Maybe a try-finally where we just `Dispose()` all `createdConnections` in the `finally` block?\n",
      "\n",
      "I think if a connection establishment fails then we should just let the exception be raised to the user as we can't really handle that.\n",
      "(Maybe it makes sense later to add a retry here, but we should probably have a logger for cases like that so users can notice such problems.)\n",
      "\n",
      "Or what do you think?, Label: 1\n",
      "Processing row 1441 - Data Type: train, Message: thanks for the reference with that blog post. amazing how many \"versions\" .net has. wow. i opted to remove the two elements., Label: 0\n",
      "Processing row 1442 - Data Type: train, Message: wow - i keep missing the template reference. thanks for noticing that. i suppose that my changes here get rid of the ability to do SNAPSHOT style releases to nuget. it doesn't appear as though we've ever done one and I'd venture to say that we never will. We would only ever do an \"rc\" version and we do that by way of a tag in git to capture the commit id from which we release that from (and we don't even bother to commit/push with the pom.xml updated to reflect the \"rc\"). \n",
      "\n",
      "I think that by not worrying about SNAPSHOTs we can do as you say and remove that \"template\" code in the \"deploy\" segment of the pom. In place of that \"template\" code I've added something to stop the build if the version is in SNAPSHOT. That approach does put it at odds with other GLVs which can support a form of SNAPSHOT but for now I don't think that's a problem., Label: 0\n",
      "Processing row 1443 - Data Type: val, Message: I changed the way it's currently working. I'll add the top level comment in this PR but it's no longer complicated enough to warrant a specific comment aside from the docstring on the method itself., Label: 0\n",
      "Processing row 1444 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1445 - Data Type: val, Message: I think, for now anyways, the two tests are rather self contained and already complex. Keeping them as is makes them easier to understand, and I don't think there will be a reduction in complexity or even lines of code to refactor it right now.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 1446 - Data Type: train, Message: Remove this, Label: 0\n",
      "Processing row 1447 - Data Type: train, Message: I am confused as to what is being proposed here.\n",
      "\n",
      "This is more or less the way the existing logic is written. The ticket was created with the acceptance criteria to avoid the duplication of the checking in scenario 2 and 3, where now it is combined into a single point of checking in `waitForConnection`. \n",
      "\n",
      "Whilst I agree that it is now less readable, unfortunately this is the result. \n",
      "\n",
      "I will add some comments to make it more clear what is happening., Label: 1\n",
      "Processing row 1448 - Data Type: train, Message: I've updated the name to follow the existing pattern. Unfortunately because the user agent itself is being used as the final part of the metric name, that portion of it will not match the existing format., Label: 0\n",
      "Processing row 1449 - Data Type: train, Message: On further inspection I'm less sure that any test of this nature would be useful. Since the user agent is sent as an http header during the handshake, it is by definition only sent once per connection. Once the handshake is done and the connection established, there isn't really anywhere to check for a user agent being sent again., Label: 1\n",
      "Processing row 1450 - Data Type: train, Message: yes, i think my previous comment addresses that. `MessageTextSerializer` really isn't a necessary anymore., Label: 1\n",
      "Processing row 1451 - Data Type: train, Message: ok. modified..., Label: 0\n",
      "Processing row 1452 - Data Type: val, Message: since this is a nested class, I can't make it static., Label: 0\n",
      "Processing row 1453 - Data Type: train, Message: I have checked my code.\n",
      "My implementation creates a new LoginContext (in SASLBookieAuthProvider/SaslServerState) for every incoming connection so there is no need to perform a TGT renewal, in fact I'm not running in such a problem in \"staging\".\n",
      "I see it can be a performance/resource problem, in by staging env I have a limited number of clients (10 to 100) and I have never got into problems.\n",
      "\n",
      "The same happens at the client-side.\n",
      "\n",
      "@revans2 \n",
      "do you think we must cache the TGT as ZooKeeper ? , Label: 1\n",
      "Processing row 1454 - Data Type: train, Message: @revans2 \n",
      "Do you have any suggestion ? maybe we can validate the principal and force it to be bookkeeper@XXXX and for the server side something like bookie@XXXX (for Kerberos case)\n",
      "\n",
      "I can't find any validation code in ZooKeeper (SaslServerCallbackHandler), Label: 0\n",
      "Processing row 1455 - Data Type: train, Message: this has to be, \n",
      "\n",
      "hasEntry(firstEntryIter, thisBookieIndexInCurrentEnsemble) \n",
      "\n",
      "not\n",
      "\n",
      "hasEntry(lastEntryId, thisBookieIndexInCurrentEnsemble) , Label: 0\n",
      "Processing row 1456 - Data Type: train, Message: @sijie, Sure, but I don't really understand what is the different between writing a todo with a message and writing a todo with a link to an issue., Label: 1\n",
      "Processing row 1457 - Data Type: train, Message: I am not sure if we need use '=='. equals has more readability and consistency in java world than ==., Label: 1\n",
      "Processing row 1458 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1459 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1460 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 1461 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1462 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1463 - Data Type: val, Message: @sijie  for instance I have a custom policy, which implements only old methods like the one in:\n",
      "LegacyCustomDefaultEnsemblePlacementPolicyTest.java \n",
      "\n",
      "this is a real example:\n",
      "https://github.com/diennea/herddb/blob/master/herddb-core/src/main/java/herddb/cluster/PreferLocalBookiePlacementPolicy.java\n",
      "\n",
      "this example does not even extends DefaultEnsamblePlacementPolicy, so my current patch will not work :-(\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1464 - Data Type: train, Message: I'd prefer not mentioning it at all, because it is not `secure` at all., Label: 1\n",
      "Processing row 1465 - Data Type: train, Message: installing kerberos is somehow out of the scope of this documentation, no? this is just giving an example. what are you suggesting here?, Label: 1\n",
      "Processing row 1466 - Data Type: train, Message: @ivankelly Could you add an example of which test is flaky?, Label: 1\n",
      "Processing row 1467 - Data Type: train, Message: I will remove this method. we don't define the binary backward compatibility for bookkeeper admin, and I doubt people depends on bookkeeper admin programmatically. , Label: 1\n",
      "Processing row 1468 - Data Type: train, Message: Maybe the best option is to use an integer, it will be more simple to handle this in the future.\n",
      "@sijie  @ivankelly  What do you think ?\n",
      ", Label: 1\n",
      "Processing row 1469 - Data Type: train, Message: sorry, @sijie \n",
      "\n",
      "SYNC_REQUIRED_WITH_JOURNAL, SYNC_DEFERRED_WITH_JOURNAL\n",
      "or\n",
      "FSYNC_REQUIRED, FSYNC_DEFERRED ?\n",
      "\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1470 - Data Type: val, Message: @ivankelly  Sorry, I can't understand your comment here, Label: 0\n",
      "Processing row 1471 - Data Type: train, Message: it was because I did not want to mark this as \"internal use only\", anyway I have just dropped it, Label: 0\n",
      "Processing row 1472 - Data Type: train, Message: dropped, Label: 0\n",
      "Processing row 1473 - Data Type: train, Message: done, renamed to \"SYNC\", is is not a problem that is it the same name as SYNC_OP?, Label: 1\n",
      "Processing row 1474 - Data Type: train, Message: Yes, Label: 0\n",
      "Processing row 1475 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1476 - Data Type: train, Message: isn't \"The technical details of this release are summarized below\" enough ?, Label: 1\n",
      "Processing row 1477 - Data Type: train, Message: I don't understand the comment here. can you explain more?, Label: 1\n",
      "Processing row 1478 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1479 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 1480 - Data Type: train, Message: well, the bug was introduced because the sequence was reorder, at that time, the logic was pretty simple. I don't see the bug was related to the branches. The biggest problem of the existing code is about the sequence of validation. This patch enforces the sequence and leaves the main validation logic untouched.\n",
      "\n",
      "The problem I have with branches - if you took at the code, there were two almost-same validation logic, one for storage expansion, the other one doesn't. but they look almost same, it is really hard to figure out what exactly is the difference between them. \n",
      "\n",
      "the way why you think you need branches is the misuse of newEnv flag. line 507- 537 are needed for both newEnvironment and oldEnvironment. the only difference is newEnv doesn't have to throw exception when there are dirs missing cookies, but it also has to throw exception with nonEmptyDir. I will change this a bit. let's see if you are okay with that., Label: 1\n",
      "Processing row 1481 - Data Type: train, Message: I don't understand what do you expect here. , Label: 1\n",
      "Processing row 1482 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1483 - Data Type: val, Message: we do not have checkstyle in this package, sorry, Label: 0\n",
      "Processing row 1484 - Data Type: train, Message: this enables checkstyle only for \"impl\" and \"api\"\n",
      "anyway now checkstyle passes for me locally, Label: 0\n",
      "Processing row 1485 - Data Type: train, Message: Maybe this is why I was seeing the shading problem also., Label: 1\n",
      "Processing row 1486 - Data Type: train, Message: I assumed ls would lexically sort by default, but I guess that would make ls very expensive on large directories. In any case, I think I'll either check that there's a version before the \".jar\" or maybe directly use the shaded. This may fix #773 also., Label: 1\n",
      "Processing row 1487 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1488 - Data Type: train, Message: empty repo though :), Label: 0\n",
      "Processing row 1489 - Data Type: train, Message: this should be done in a separate task to make LedgerMetadata implementation immutable. This change is more about interfacing existing class. I would prefer not changing any implementation., Label: 0\n",
      "Processing row 1490 - Data Type: train, Message: this should be done in a separate task to make LedgerMetadata implementation immutable. This change is more about interfacing existing class. I would prefer not changing any implementation., Label: 0\n",
      "Processing row 1491 - Data Type: train, Message: again my concern is allocation. It is nothing about trivial. also again this is `LimitedPrivate`, I don't see any reason why you want to push a change that is going to change in future., Label: 0\n",
      "Processing row 1492 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 1493 - Data Type: train, Message: Ya, the casts suck. I don't understand why the linter isn't complaining., Label: 1\n",
      "Processing row 1494 - Data Type: train, Message: Even if only one method is `synchronized`, still we need to have only 1 single thread calling the method at a time. \n",
      "\n",
      "The reason is that the `forEach()` iterates over the entries in order (by ledgerId, entryId), thus it needs to convert the hashmap into a sorted array of pair of longs. The array used is a member variable of the instance (`long[] sortedEntries`). \n",
      "\n",
      ", Label: 0\n",
      "Processing row 1495 - Data Type: train, Message: Very good point. I absolutely cannot remember why is this not a `>> 32`. Need to think about it., Label: 1\n",
      "Processing row 1496 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 1497 - Data Type: train, Message: This is making a copy of the cache buffers for each segment (just the ByteBuf shell objects) so that we can play with the `readerIdx` and `writerIdx` and pass on always the same `ByteBuf` instance to the iteration consumer. See later: \n",
      "\n",
      "```java\n",
      "ByteBuf entry = entrySegments[segmentIdx];\n",
      "entry.setIndex(localOffset, localOffset + (int) length);\n",
      "consumer.accept(ledgerId, entryId, entry);\n",
      "```, Label: 0\n",
      "Processing row 1498 - Data Type: train, Message: I've added the comment to clarify why that's not possible in current code., Label: 0\n",
      "Processing row 1499 - Data Type: val, Message: I think that using the default system timezone is ok, the user configure the specified time  period using their default system timezone usually.\n",
      "What does you mean that explicitly configure a timezone?  Adding a new field to timezone in config file?, Label: 1\n",
      "Processing row 1500 - Data Type: train, Message: Sorry, will drop. It is a netbeans empty folder, Label: 0\n",
      "Processing row 1501 - Data Type: train, Message: Sorry, will drop. It is a netbeans empty folder, Label: 0\n",
      "Processing row 1502 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1503 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1504 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1505 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1506 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1507 - Data Type: train, Message: It's a different project, different copyright years., Label: 0\n",
      "Processing row 1508 - Data Type: train, Message: Because flush failure is only relative to SortedLedgerStorage, so I just changed the SortedLedgerStorage to avoid much changes. Do you think that adding a common listener interface to LedgerStorage is ok? @sijie @eolivelli , Label: 1\n",
      "Processing row 1509 - Data Type: train, Message: Ah, it passed because there were no \"normal\" gc tests where either the iterator or the ledger manager weren't corrupted with that option enabled.  Enabling it for testGcLedgersWithLedgersInSameLedgerRange catches this bug., Label: 0\n",
      "Processing row 1510 - Data Type: train, Message: maybe this should be 'volatile', Label: 1\n",
      "Processing row 1511 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 1512 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1513 - Data Type: train, Message: @merlimat @sijie \n",
      "There's a potential thorny BC issue here. On yahoo branch, RECOVERY_READ is 2.https://github.com/yahoo/bookkeeper/blob/165971209f933e0bcefaac997db8e75c8776f942/bookkeeper-server/src/main/proto/BookkeeperProtocol.proto#L83\n",
      "\n",
      "@merlimat are any any the yahoo clients using protobufs? Or are they all on V2? If so it may not be a problem., Label: 1\n",
      "Processing row 1514 - Data Type: train, Message: I think this definitely needs to be BC tested. The question is whether we block this change to do it, or just make it a blocker on the 4.7.0 release., Label: 1\n",
      "Processing row 1515 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1516 - Data Type: train, Message: @sijie @jvrao @merlimat Trying to get back the context on this again. Any objection to reusing the fencing thread pool for the recovery reads/adds?, Label: 1\n",
      "Processing row 1517 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1518 - Data Type: train, Message: oh, seems we're shortcutting those too. hmm., Label: 0\n",
      "Processing row 1519 - Data Type: train, Message: MockBookKeeperTestCase just has an ensemble create methods, any suggestions to change ensemble quickly like `killBookie` and `startNewBookie` in BookKeeperClusterTestCase?, Label: 1\n",
      "Processing row 1520 - Data Type: train, Message: the empty object can't achieve the goal. when the `LedgerHandle` call `handleBookieFailure`, the null of `disableEnsembleChangeFeature ` will cause NullPointerException., Label: 0\n",
      "Processing row 1521 - Data Type: train, Message: good, fixed, Label: 0\n",
      "Processing row 1522 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 1523 - Data Type: train, Message: I am moving TLS_XYZ from ServerConfiguration and ClientConfiguration to the common class AbstractConfiguration and just use one set of config params (no clientXYZ params anymore). So, effectively this is a dead code. What I am doing here is to keep just one set of config params so both bookie and client config params names are same.\n",
      "\n",
      "AutoRecovery can still use the same set of params as bookies to configure the bookkeeper client.\n",
      "\n",
      "Only config param names are changing, but the variable name still remains the same as TLS_XYZ. Do you still think its a BC issue?, Label: 1\n",
      "Processing row 1524 - Data Type: train, Message: @eolivelli Ok, how about this version?, Label: 0\n",
      "Processing row 1525 - Data Type: train, Message: @ivankelly Ah, right.  Doing that means that there is no longer an abstract method, so it no longer works as a FunctionalInterface, so lambda expressions don't work.  That would break some existing users., Label: 0\n",
      "Processing row 1526 - Data Type: train, Message: Not sure.  Perhaps there is value in emulating the size overhead?  @jvrao Thoughts?, Label: 1\n",
      "Processing row 1527 - Data Type: train, Message: I don't think reads vs writes matter in this case.\n",
      "Writes wait for full WQ (i.e. if when any 1 out of 3 not writable), reads wait one (i.e. when 3 out of 3 not writable) so they should not be affected by wait that much. Writes have a chance to recover with ensemble change but we don't want frequent ensemble changes; reads will simply fail. \n",
      "Combined with netty's L/H water mark configs this really should happen in extreme cases only.\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1528 - Data Type: train, Message: `ledgerMangerType` is already deprecated long time ago. it doesn't make any sense to leave it here. we used the wrong parameter here so I don't see a reason to have it though. for people who is new to bookkeeper, he should be knowing less settings as possible., Label: 0\n",
      "Processing row 1529 - Data Type: train, Message: I think I forgot to add the unload interfaces. However since we also use this pattern on dlog namespace driver, I don't see a real need to unload drivers. \n",
      "\n",
      "Also This only caches the class information when the drivers are included in the classpath, it doesn't contain any real resources that we are using. , Label: 0\n",
      "Processing row 1530 - Data Type: train, Message: what do you mean \"etcd\" here?, Label: 1\n",
      "Processing row 1531 - Data Type: train, Message: Our api shouldn't be evolving in a way that simple stuff becomes less clear. I'll happily change to builder if and when the builder is as easy to use as the direct zookeeper constructor, but this isn't the case now., Label: 0\n",
      "Processing row 1532 - Data Type: val, Message: changed., Label: 0\n",
      "Processing row 1533 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1534 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1535 - Data Type: train, Message: this changes the logging behavior though. the logging message is added after `put`, that is to handle concurrent puts. the change you are proposing here doesn't do that. , Label: 0\n",
      "Processing row 1536 - Data Type: val, Message: any issues you are seeing not construct `metadataServiceUri`? I am not sure what to fix here?, Label: 1\n",
      "Processing row 1537 - Data Type: train, Message: would prefer having an explicit flag on controlling this, Label: 0\n",
      "Processing row 1538 - Data Type: train, Message: you can't do simply do that, because left or right can be null and it needs to take the flag into account., Label: 0\n",
      "Processing row 1539 - Data Type: train, Message: I can't. because it is not an interface.  I've used closures whenever I can and my ide will ask me to do that. If I don't do it, that means it can't be., Label: 0\n",
      "Processing row 1540 - Data Type: train, Message: this is not true.\n",
      "\n",
      "1) in FileInfoCache, FileInfo is not trasient, it deals with persistence. However in here, TransientLedgerInfo doesn't deal with persistence. that makes the difference. \n",
      "2) I make it explicit \"Transient\", to make the difference with FileInfo and also `LedgerData` in LedgerMetadataIndex. Otherwise, \"LedgerInfo\" and \"LedgerData\" sound too close to each other., Label: 0\n",
      "Processing row 1541 - Data Type: train, Message: no. I have kept the cache as simple and the loading will never throw any exceptions. If I move the getEntry as part of loader, it complicates error handling in cache loading, which I don't want to., Label: 0\n",
      "Processing row 1542 - Data Type: train, Message: Bookie doesn't implements AutoCloseable, Closeable to use with try-with-resources. But again, I'm just following Bookie instances is used in other testcases., Label: 0\n",
      "Processing row 1543 - Data Type: val, Message: changing, Label: 0\n",
      "Processing row 1544 - Data Type: val, Message: fixing that, Label: 0\n",
      "Processing row 1545 - Data Type: train, Message: flushInternal just flushes writeBuffer to fileChannel (doesn't persists and moreover it is private method). forceWrite just forces filechannel (persists data written to filechannel so far, doesn't touches writeBuffer), flush calls flushInternal and provides option to whether do forceWrite or not.\n",
      "\n",
      "So each method has different purpose. replacing flushinternal with flush is not correct thing to do from its expectations. And if user wants to do both flushing writeBuffer and forcewrites the filechannel, then calling just forceWrite is not right thing to do.\n",
      "\n",
      "But again I don't see point in complicating things by changing the signatures of this commonly used methods and touch all the callers of them. It is extraneous., Label: 0\n",
      "Processing row 1546 - Data Type: train, Message: 1) it is returning void/null.\n",
      "2) its return value is not used anywhere.\n",
      "3) MockExecutorController doesn't support controlSubmitCallable. , Label: 0\n",
      "Processing row 1547 - Data Type: train, Message: removed it., Label: 0\n",
      "Processing row 1548 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1549 - Data Type: train, Message: The current state of \"multiple journals\" is very broken, since the bookie most likely fails to restart (since the last mark is can be pointing to a txn log that doesn't exist for a particular journal instance). I don't think it has ever been used for anything else than PoC perf testing at this point (or at least I hope no one was depending on this :) ). , Label: 1\n",
      "Processing row 1550 - Data Type: val, Message: First of all Iâ€™m not sure, why this is added with this commit https://github.com/apache/bookkeeper/commit/81cbba3cf620f2a6df48c0da6ee1ac019de24fbc. SortedLedgerStorage.checkpoint should be called from onSizeLimitReachedâ€™s scheduler. In onSizeLimitReachedâ€™s scheduler, memtable is flushed completely and if entrylog has reached its capacity then it will roll log. So here by the time startCheckpoint for the checkpoint cp is called all the entries must be flushed from memtable to entry log and the entry log must be rolled. So in this checkpoint method, the entries which come before checkpoint cp are already added to entry log and rolled over. So I donâ€™t see the need of this extra rollLog call.\n",
      "\n",
      "Mainly I removed rollLog method, instead I introduced rollLogsIfEntryLogLimitReached, which is not appropriate here., Label: 0\n",
      "Processing row 1551 - Data Type: val, Message: i kept the logic related to newlog creation and flush logs with in EntryLogger. So it should be here., Label: 0\n",
      "Processing row 1552 - Data Type: val, Message: I don't think we should change the signature to throw unchecked io exception. checked exception is well handled in the whole path, but not unchecked exception. \n",
      "\n",
      "The logic here is just to getting around this interface doesn't throw checked exception, so I am able to throw checked exception. there is no really matter it is unchecked execution exception or unchecked io exception., Label: 0\n",
      "Processing row 1553 - Data Type: train, Message: Pretty sure I saw issues without the duplicate, but can't test now since pulsar master seems broken on OrderedExecutor stuff. Removed., Label: 0\n",
      "Processing row 1554 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1555 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1556 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 1557 - Data Type: train, Message: I was looking for it when I first wrote this. Seems to not exist. Added., Label: 0\n",
      "Processing row 1558 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1559 - Data Type: train, Message: moved, Label: 0\n",
      "Processing row 1560 - Data Type: train, Message: here we are logging exception also, I don't think there is any overloaded log.error method to do {}, Label: 0\n",
      "Processing row 1561 - Data Type: val, Message: changed synchronization logic to use Phaser, Label: 0\n",
      "Processing row 1562 - Data Type: train, Message: This \"transfers the specified source buffer's data to this buffer\". The source is \"data\", our payload, and the destination is \"sendBuffer\", the buffer containing header, checksum, and payload. Am I missing something?\n",
      "\n",
      "But I think we can replace the entire block by\n",
      "sendBuffer.writeBytes(data);\n",
      "\n",
      "It will figure out the offset/length itself. The distinction isn't necessary indeed., Label: 1\n",
      "Processing row 1563 - Data Type: train, Message: Okay, Label: 0\n",
      "Processing row 1564 - Data Type: train, Message: Okay, Label: 0\n",
      "Processing row 1565 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 1566 - Data Type: train, Message: reverted, Label: 0\n",
      "Processing row 1567 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 1568 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 1569 - Data Type: train, Message: Make sense. These 2 methods were doing more work before but they have no need to be there now. Changed., Label: 0\n",
      "Processing row 1570 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 1571 - Data Type: train, Message: Yes, that's how it was earlier in this PR. The problem is that close() gets called twice on the active write channel when entrylogger gets shutdown. Let me try to rethink that \n",
      ", Label: 1\n",
      "Processing row 1572 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1573 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1574 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1575 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1576 - Data Type: train, Message: How about StorageType? , Label: 1\n",
      "Processing row 1577 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 1578 - Data Type: train, Message: renamed to newLac, it is clearer, thanks, Label: 1\n",
      "Processing row 1579 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 1580 - Data Type: train, Message: changed., Label: 0\n",
      "Processing row 1581 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 1582 - Data Type: train, Message: @merlimat please look at the unit tests that I added\n",
      "specifically assert for refcount https://github.com/apache/bookkeeper/pull/1585/files#diff-d168699d534345c67678296447f8375cR1344\n",
      "has to pass (refcount after add == 0).\n",
      "Otherwise it means that:\n",
      "- whoever created ByteBuf has to deal with its release, despite netty's guidelines.\n",
      "- if not released we risk memleak. , Label: 0\n",
      "Processing row 1583 - Data Type: val, Message: There'll be a big comment on the ReadOnlyLedgerHandle implementation. The whole class hierarchy here is broken. LedgerHandle should derive from ReadOnlyLedgerHandle, not vice versa. ReadOnlyLedgerHandle shouldn't do recovery. Recovery should be a separate operation that occurs before the ledger handle is even created. However, currently this is a big change because of the lack of separation between the *Op classes and LedgerHandle. This getCurrentEnsemble() is the ugliness I was referring to on dev@ when I said the solution isn't nice. The add op has to call back to the ledger handle to get the new ensemble after a failure. It would be better if, when an ensemble change occurs, all outstanding pending add ops are passed the new ensemble **by** the ledger handle. I might actually change it do that. The ops shouldn't depend on LedgerHandle. The objects they require should be passed in as parameters. There's so much janky stuff in this code, it can be painful to not fix it all at once., Label: 0\n",
      "Processing row 1584 - Data Type: train, Message: 1. changed, though slightly different to what you suggested, as we need the write promise, it's the promise returned from thenCompose that is added to outstanding.\n",
      "\n",
      "2. outstanding is a concurrenthashmap, wrapped in a set. the stream will be generated from an iterator on the ConcurrentHashMap, which is a view of the contents at or after the point of the iterator creation. These are safe from concurrentmodificationexception. At the point stream() is called, nothing new will be added to the set, though entries may be removed. This is fine, because remove will only remove a completed future, which is what we're waiting for anyhow. I'm not even sure how I could use CountDownLatch here, and we would end up having some messy rubbish to get any thrown error out., Label: 1\n",
      "Processing row 1585 - Data Type: train, Message: I disagree, and this is of the things that annoys me about callbacks. \n",
      "\n",
      "When reading code, it makes most sense that the action occur in the order they occur on the page. By putting readLedgerMetadata at the end, you are breaking that order. Consider how this would look if instead of taking a promise, readLedgerMetadata would return a future (something I've been thinking about doing)., Label: 1\n",
      "Processing row 1586 - Data Type: train, Message: I suspect that it's not actually important for the test, but I've changed it to the exact original behaviour in any case., Label: 1\n",
      "Processing row 1587 - Data Type: val, Message: Great, Label: 0\n",
      "Processing row 1588 - Data Type: train, Message: the format is different, because v1 doesn't have scope, v2 have scope., Label: 0\n",
      "Processing row 1589 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 1590 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 1591 - Data Type: val, Message: Removed., Label: 0\n",
      "Processing row 1592 - Data Type: train, Message: Added a comment., Label: 0\n",
      "Processing row 1593 - Data Type: train, Message: UTF_8 added. \n",
      "\n",
      "Order changed. It's super annoying how junit and testng have different orders., Label: 0\n",
      "Processing row 1594 - Data Type: val, Message: changed., Label: 0\n",
      "Processing row 1595 - Data Type: val, Message: Out of scope for this PR, but I was thinking something similar while I was writing this., Label: 0\n",
      "Processing row 1596 - Data Type: train, Message: > add messages in the help messages of the tool\n",
      "\n",
      "I think we need to pick up your effort to revamp the the tools, and 1) move them all into the same framework, 2) add tests & 3) add docs for each one. \n",
      "\n",
      "Right now, bookie shell is a mess. There's even multiple tools that do exactly the same thing., Label: 0\n",
      "Processing row 1597 - Data Type: val, Message: mmm I lost the count..\n",
      "Maybe we can drop the line at all ?\n",
      "\n",
      "@sijie , Label: 0\n",
      "Processing row 1598 - Data Type: train, Message: Good catch, fixed. I left the original IOException and BookieException as they were. We can argue they should be on the future as well, though that's unrelated with this PR., Label: 1\n",
      "Processing row 1599 - Data Type: train, Message: it should be working as fine. \n",
      "\n",
      "alternatively we can use grpc InprocessChannel. I didn't go to that route, because I think loopback is probably much reliable than using InprocessChannel. since using InprocessChannel we have to consider the sequence on constructing service and the client, which can be tricky. So I would prefer using loopback as for now, and change it if it turns out to be a bottleneck., Label: 0\n",
      "Processing row 1600 - Data Type: train, Message: The comment is already there, no? It was set to a wrong flag. , Label: 0\n",
      "Processing row 1601 - Data Type: train, Message: changed interface/method name, Label: 0\n",
      "Processing row 1602 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 1603 - Data Type: train, Message: @sijie Fixed, Label: 0\n",
      "Processing row 1604 - Data Type: train, Message: same as above, Label: 0\n",
      "Processing row 1605 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1606 - Data Type: train, Message: good point, fixed, Label: 0\n",
      "Processing row 1607 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1608 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1609 - Data Type: train, Message: @ivankelly \n",
      "\n",
      "we don't do this for other cli tools. so I would prefer just keeping the behavior consistent. I don't want to pollute the output with such logging, if we omitting output file., Label: 0\n",
      "Processing row 1610 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1611 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1612 - Data Type: train, Message: @eolivelli Does this answer the question?, Label: 1\n",
      "Processing row 1613 - Data Type: val, Message: Ya, I'm going to change any place I have instanceof to getExceptionCode. The CompletionException stuff is too unclear., Label: 1\n",
      "Processing row 1614 - Data Type: train, Message: There weren't any other users and I found this to be clearer.  I don't feel strongly about it and could be convinced otherwise., Label: 1\n",
      "Processing row 1615 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 1616 - Data Type: train, Message: Ok., Label: 0\n",
      "Processing row 1617 - Data Type: train, Message: Not really, the isDeleted() concept came in with this patch.  It's there to deal with the inevitability of the consistency checker holding an LEP reference as the corresponding ledger is deleted., Label: 0\n",
      "Processing row 1618 - Data Type: train, Message: there is no simple way to hide this in shell script, or in order to do, it will make the script to complicated. so I leave the command in the script and have an error message to tell people to use 'localbookie <n>' instead of 'standalone'., Label: 0\n",
      "Processing row 1619 - Data Type: train, Message: it is hard to check $?, because we are using `set -e`.  that's why I end up using the string as the result., Label: 0\n",
      "Processing row 1620 - Data Type: train, Message: Not sure where it would fit, so leaving it here for now. We have too many of these conversions though. We should push them all into a DigestConvertor class at some point, but I don't want to do that in this patch as it would mean touching other classes which are completely unrelated., Label: 0\n",
      "Processing row 1621 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 1622 - Data Type: train, Message: Spot bugs 3.1.8 is not happy, Label: 0\n",
      "Processing row 1623 - Data Type: train, Message: Spot bugs 3.1.8  is not happy , Label: 0\n",
      "Processing row 1624 - Data Type: train, Message: @sijie \n",
      "I am re-thinking about disabling this rule only on JDK11+....\n",
      "I feel it is not worth such complication. We should have two different findbugs configuration files, and with JDK11+ the problem will stay forever.\n",
      "\n",
      "In Apache Kafka they have disabled it at all\n",
      "https://github.com/apache/kafka/pull/5943/files\n",
      ", Label: 0\n",
      "Processing row 1625 - Data Type: val, Message: So, this is something that we need to decide when we push the PR which bumps the version. Should new clusters default to version 3 or default to version 2. I'm inclined to think they should default to version 2 for a couple of versions anyhow, but have version 3 available. , Label: 1\n",
      "Processing row 1626 - Data Type: val, Message: All these duplicates are on purpose. For example, if we add a state in future, but the max metadata version is 2, and we are using shared code, it will happily write the new state to the metadata and break clients that can only read V2. It's ugly, but it's here defensively., Label: 0\n",
      "Processing row 1627 - Data Type: val, Message: umm.. if no one calls `ctx.done = true; ctx.notifyAll();` at line#238 then `ctx.wait(timeout)` will throw `InterruptedException` and `ctx.done will be true;` at line#249 which takes out thread out of while loop. So, it will not keep waiting but exit. right?, Label: 0\n",
      "Processing row 1628 - Data Type: train, Message:  OK, Label: 0\n",
      "Processing row 1629 - Data Type: train, Message: This patch only added it to Version 3 which afaict is using the normal protobuf format, so old clients should ignore it.  Is that right?, Label: 1\n",
      "Processing row 1630 - Data Type: val, Message: @sijie ^ ?, Label: 0\n",
      "Processing row 1631 - Data Type: val, Message: Oh, I think I added my comment without reloading the page.  Sorry!, Label: 0\n",
      "Processing row 1632 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 1633 - Data Type: train, Message: yeah, fixed, Label: 0\n",
      "Processing row 1634 - Data Type: train, Message: I think It's impossible that password is null. If you don't specify the password, it will be an empty string. And then it will prompt you input a password. Right? @sijie , Label: 0\n",
      "Processing row 1635 - Data Type: val, Message: @eolivelli yes, Label: 0\n",
      "Processing row 1636 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 1637 - Data Type: val, Message: Sure, Label: 0\n",
      "Processing row 1638 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1639 - Data Type: val, Message: @reddycharan \n",
      "I switched this log line from `DEBUG` to `INFO` since I believe that this is an important event to be logged. However given that we use ELPL, which flushes every 10 seconds, is this a problem?, Label: 1\n",
      "Processing row 1640 - Data Type: train, Message: Modifying., Label: 0\n",
      "Processing row 1641 - Data Type: train, Message: Removing this section., Label: 0\n",
      "Processing row 1642 - Data Type: train, Message: As per our discussion not sure this is the right approach, but doing these changes nevertheless., Label: 1\n",
      "Processing row 1643 - Data Type: train, Message: Adding., Label: 0\n",
      "Processing row 1644 - Data Type: train, Message: Modifying., Label: 0\n",
      "Processing row 1645 - Data Type: val, Message: reverted, Label: 0\n",
      "Processing row 1646 - Data Type: train, Message: If we don't catch the exception here, I think that the following for loop is interrupted at that time.\n",
      "https://github.com/apache/bookkeeper/blob/b2e099bbc7b13f13825fe78ab009ca132cb3a9ba/bookkeeper-server/src/main/java/org/apache/bookkeeper/bookie/GarbageCollectorThread.java#L441-L465\n",
      "In our case, there is a problem with a particular entry log, so this loop will always stop when `GarbageCollectorThread` try to compact that log. Because of that, I think that the subsequent entry logs are not compacted every time., Label: 0\n",
      "Processing row 1647 - Data Type: train, Message: thanks for the comment. The change was reverted, but I don't see how this formatting can help without any arguments , Label: 1\n",
      "Processing row 1648 - Data Type: train, Message: `certRefreshTime` gets initialized only once at `init` method. and `certLastRefreshTime` is a volatile which gets updated only in `updateServerContext()` which is `synchronized` and thread-safe. So, it seems we don't have to make `getSSLContext()` synchronized. right?, Label: 1\n",
      "Processing row 1649 - Data Type: train, Message: > We'd have to at least release the buffers when the ReadCache/WriteCache are closed\n",
      "\n",
      "shouldn't releasing buffers always be done when closing ReadCache/WriteCache. It is always be good to clean up  the resources even they are not used anymore. I didn't still get the point why there are benefits using unpooled buffers.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 1650 - Data Type: train, Message: > I would avoid the tracking of these buffers by the allocator. The overhead might be minimal, OTOH there's no advantage from the allocator either.\n",
      "\n",
      "the intention is to make sure all the memory allocation is consistent across the bookie server and leverage whatever changes we made in our allocator, unless there are a very strong reason to not do so. \n",
      "\n",
      "since there is no advantages and also no disadvantages, why not just to make things consistent and easier to maintain?, Label: 0\n",
      "Processing row 1651 - Data Type: train, Message: @eolivelli even I've mixed opinions about this null thing. In retrospect, instead of passing ConcurrentSet it would be better if I pass function (callback) to the bottom of stack and call this function incase of read failure. So callers can decide what they want to have in their callback logic. Here instead of passing null, it can pass no-op function., Label: 0\n",
      "Processing row 1652 - Data Type: val, Message: yes, as we discussed it would be shared instance.\n",
      "\n",
      "> multiple of them can fail at the same time, causing the hook to trigger\n",
      "\n",
      "\n",
      "All we should care about is 'atleast-once' semantics. As long as 'shutdownHookThread' is executed once we should be fine. Anyhow in `LifecycleComponentStack.start` Components are started sequentially, so multiple of them failing at the same time is not going to happen., Label: 0\n",
      "Processing row 1653 - Data Type: train, Message: `getFirstStoredEntryId(bookieIndex)` doesn't return null. It either returns valid 'firstEntry' or LedgerHandle.INVALID_ENTRY_ID. So we wouldn't run into this situation. , Label: 0\n",
      "Processing row 1654 - Data Type: train, Message: sorry, already change, Label: 0\n",
      "Processing row 1655 - Data Type: train, Message: I tried that but it seems too brittle a check for depending on the error message., Label: 0\n",
      "Processing row 1656 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1657 - Data Type: train, Message: > Please add a command line option.\n",
      "> \n",
      "> Otherwise with this change we are introducing unexpected behaviour and possibly a security issue.\n",
      "\n",
      "Use the command-line option `env`, What do you think?, Label: 0\n",
      "Processing row 1658 - Data Type: train, Message: I don't know about this class, I checked the code and it doesn't seem to be there.., Label: 1\n",
      "Processing row 1659 - Data Type: train, Message: Ok!, Label: 0\n",
      "Processing row 1660 - Data Type: train, Message: > Please move this class to the tests sources.\n",
      "> This is not intended to be used\n",
      "\n",
      "done, Label: 0\n",
      "Processing row 1661 - Data Type: train, Message: I would like, but in current 4.11 we are using the presence of shell to detect jdk11 and it is not present in the.\n",
      "\n",
      "We should fix that problem, then we can use the jre.\n",
      "\n",
      "Btw I don't know a good way to detect jdk11+, Label: 1\n",
      "Processing row 1662 - Data Type: val, Message: removed , Label: 0\n",
      "Processing row 1663 - Data Type: train, Message: thanks @lhotari \n",
      "fixed, Label: 0\n",
      "Processing row 1664 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1665 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1666 - Data Type: train, Message: This line returns \"2.7\"\n",
      "\n",
      "I tried to move to pip3, but I need pip 2.7 because we need to install zookeeper-shell and with pip3 it fails, Label: 0\n",
      "Processing row 1667 - Data Type: train, Message: Abosolutely.!, Label: 0\n",
      "Processing row 1668 - Data Type: train, Message: Let me see if I can add some clarity.\n",
      "* Restore code get the list of files from the `metadata` file (which is the first file we restore). All files other than SST files are stored under the checkpoint directory. SST files however are stored under common \"ssts\" directory. The code uses the extension of the file to determine if the the file is SST or nor. If it is a SST file, it will copy it from common \"ssts\" folder. If we add checksum to names of file added to `files` field in metadata, this code will fail and will not be able to copy the files from the checkpoint store.\n",
      "* Now we can work around the above by prefixing the checksum (e.g 00009.sst -> {checksum}_00009.sst). The code will correctly detect this as a SST file and copy it from the common \"ssts\" folder. These files however would still need to be renamed ({checksum}_00009.sst -> 00009.sst) locally. This is the files that rocksdb will be looking for. Since there is no code in the previous version that can do that, it will not work.\n",
      ", Label: 0\n",
      "Processing row 1669 - Data Type: train, Message: I don't think that will help here., Label: 1\n",
      "Processing row 1670 - Data Type: train, Message: Yeal, I try to restore this configuration and update the dependency license files. And now I get a problem about `TestTLS`., Label: 0\n",
      "Processing row 1671 - Data Type: train, Message: This was a typo. Thanks for point it out. we should not use nar because the signature issue., Label: 0\n",
      "Processing row 1672 - Data Type: train, Message: the message is like this\n",
      "`1)      03:32:11.130 [BookieReadThreadPool-OrderedExecutor-0-0] ERROR org.apache.bookkeeper.proto.ReadLacProcessorV3 - IOException while trying to read last entry: 2\n",
      "org.apache.bookkeeper.bookie.Bookie$NoEntryException: Entry -1 not found in 2\n",
      "`, Label: 0\n",
      "Processing row 1673 - Data Type: train, Message: RootRange reads from local storage. The getStreamProps service call fails in the base impl. I tried that first. :)\n",
      "\n",
      "I'll delete the cache. CHM would protect against corrupting the internals bit potentially overwrite one reference with another equivalent one.  Since I didn't avoid concurrent RPC due to the unlikelihood once we get to the put it's hard to care.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1674 - Data Type: train, Message: what's the problem?, Label: 1\n",
      "Processing row 1675 - Data Type: train, Message: I made a change, only  one field  `averageEntrySize` keeped., Label: 0\n",
      "Processing row 1676 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 1677 - Data Type: val, Message: Configure dnsResolver where it is created/before passing it to downstream components.\n",
      "This may be a better way fixing the issue.  But I am not sure it will be accepted, cause too many code changes,, Label: 1\n",
      "Processing row 1678 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1679 - Data Type: train, Message: The default zk client timeout is 10s, if set to 2 * zkTimeout, it will be 20s. \n",
      "However, in the replicas check process, it use `REPLICAS_CHECK_TIMEOUT_IN_SECS=120` as maxConcurrentSemaphore tryAcquire timeout.\n",
      "So i doubt whether put `openLedgerNoRecoverySemaphoreWaitTimeoutMSec` in to `bk_server.conf` or just hard code to `2 * zkTimeout` and the default value set to 120s or not. \n",
      "@dlg99  Would you please give me some ideas? , Label: 1\n",
      "Processing row 1680 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1681 - Data Type: train, Message: Thanks @eolivelli, yes in fact this is a package benefiting from the previous transitive import of the log binding related to `bookkeeper-server`. Once removed from `bookkeeper-server`, I was not getting the bindings in the distribution. I have specifically added these bindings in the `build.gradle` (the bindings were already defined in the `pom.xml`). Now there are no changes in this License file., Label: 0\n",
      "Processing row 1682 - Data Type: val, Message: Fixed. PTAL, Label: 0\n",
      "Processing row 1683 - Data Type: train, Message: Done with the latest fix, Label: 0\n",
      "Processing row 1684 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1685 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1686 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1687 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1688 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1689 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1690 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1691 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1692 - Data Type: train, Message: no. the naming/layering is confusing.\n",
      "\n",
      "1. newDirectWriter() -> construct DirectWriter, write empty header\n",
      "2. WritingDirectCompactionEntryLog constructor -> construct DirectWriter, pass to WriterWithMetadata constructor which then writes the empty header.\n",
      "\n",
      "the way the log file name is calculated is different in the two code paths, and there are other side effects.\n",
      "\n",
      "had the result of newDirectWriter() been used to construct WriterWithMetadata, the header would be written twice but at offset zero both times.\n",
      "\n",
      "\n",
      ", Label: 1\n",
      "Processing row 1693 - Data Type: train, Message: i only overrided the name to avoid getting tripped up by the log4shell owasp regex.  in general, we don't include `org.apache.bookkeeper-` in the jar file names, or even bother to rename rather generic ones like `stream/clients/java/kv/build/libs/kv.jar`\n",
      "\n",
      "```\n",
      "ephemeral ~/src/bookkeeper-directio |> ls **/*.jar | wc -l\n",
      "      40\n",
      "ephemeral ~/src/bookkeeper-directio |> ls **/*.jar | fgrep org.apache\n",
      "ephemeral ~/src/bookkeeper-directio |>\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 1694 - Data Type: train, Message: it doesn't look like it.  i'll move `bufferToFlush` inside of the conditional block as well.  what i'm not going to change yet but am thinking about: can the allocation of a new buffer be moved to where `nativeBuffer` is set to null now?  potentially we can exit this method with a null `nativeBuffer` if `addOutstandingWrite` raises an exception., Label: 1\n",
      "Processing row 1695 - Data Type: train, Message: > `moveToNewLocation` is not expected the be in deleted state at all during the rename\n",
      "\n",
      "\n",
      "It is only correct in ideal situation. Could this operation happen cross filesystems or even devices ? I think this method make no assumption about this. From my side, `delete` in `moveToNewLocation` is more like a conservative operation than solely `Files.delete()`(which throw exception on deletion failure). After failure of `FileInfo.delete`, `FileInfo` is unusable as `FileInfo.fc` is closed and `FileInfo.lf` is not guaranteed to exist.\n",
      "\n",
      "I have no preference over approaches:\n",
      "* Current: `FileInfo.delete()` and throws exception on failure.\n",
      "* Alternative: `FileInfo.lf.delete()` and mark `deleted` and throws exception on failure.\n",
      "\n",
      "I think they are identical., Label: 0\n",
      "Processing row 1696 - Data Type: train, Message: it's necessary to change, for the finally code using it @Shoothzj \n",
      "<img width=\"868\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42990025/150113268-b5232afe-4459-4e1e-b6c9-c03e2dea1c3b.png\">\n",
      ", Label: 0\n",
      "Processing row 1697 - Data Type: train, Message: > I didn't see the `finally` cause refer the entrySize variable. Can you explain more detail? thanks\n",
      "\n",
      "I add the code picture, Label: 0\n",
      "Processing row 1698 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1699 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1700 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1701 - Data Type: val, Message: > Why are we ohtting this code in the 'finally' block?\n",
      "\n",
      "to shrink when we go below a certain threshold. @eolivelli , Label: 0\n",
      "Processing row 1702 - Data Type: train, Message: I agree to add a new configuration autoShrink to control whether to shrink or not. @eolivelli \n",
      "\n",
      "Then we have to solve a problem: when autoShrink=false, even if the map has a lot of space, the expansion will be triggered frequently, because the condition of our expansion is not to see the actual use size of the map., Label: 0\n",
      "Processing row 1703 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 1704 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 1705 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 1706 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1707 - Data Type: train, Message: Pulsar contains GrowableArrayBlockingQueue too, https://github.com/apache/pulsar/blob/master/pulsar-common/src/main/java/org/apache/pulsar/common/util/collections/GrowableArrayBlockingQueue.java . I picked this fix to the BK version of GrowableArrayBlockingQueue when comparing the classes. \n",
      "\n",
      "I didn't see an explicit test., Label: 0\n",
      "Processing row 1708 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1709 - Data Type: train, Message: Good catch. I'm considering how to avoiding creating new object. \n",
      "The `BufferedReadChannel.read` method is synchronized, we should use throttle in the read method to block it when throttled, otherwise, it will block other threading calling.  I still have no good idea about it., Label: 1\n",
      "Processing row 1710 - Data Type: train, Message: Whether we will enter major or minor compaction is controlled by \n",
      "```\n",
      "((isForceMajorCompactionAllow && force) || (enableMajorCompaction\n",
      "                    && (force || curTime - lastMajorCompactionTime > majorCompactionInterval)))\n",
      "                    && (!suspendMajor)\n",
      "```\n",
      "That is:\n",
      "1. `isForceMajorCompactionAllow && force` or `(enableMajorCompaction && (force || curTime - lastMajorCompactionTime > majorCompactionInterval)`\n",
      "2. suspendMajor\n",
      "\n",
      "We must meet above both conditions.\n",
      "\n",
      "The if and else is different code path controlled by `isForceMajorCompactionAllow && force` and `(enableMajorCompaction && (force || curTime - lastMajorCompactionTime > majorCompactionInterval)`, Label: 0\n",
      "Processing row 1711 - Data Type: train, Message: make sense, Label: 0\n",
      "Processing row 1712 - Data Type: train, Message: Yes, it can only be guaranteed by `EntryLogManagerForSingleEntryLog`, Label: 0\n",
      "Processing row 1713 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1714 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 1715 - Data Type: train, Message: Hi, I've thought of doing that, but if someone adds MD files to another dir, that may result in frequent maintenance of this directory (most times. people probably forget to do this).\n",
      "\n",
      "It's a simple CI, so I'd rather run it for every PR, WDYT?, Label: 0\n",
      "Processing row 1716 - Data Type: train, Message: I didn't notice before that there is such a way to determine the file type ðŸ¤£ , Label: 1\n",
      "Processing row 1717 - Data Type: train, Message: oh, sorry, my bad :( fixed, Label: 0\n",
      "Processing row 1718 - Data Type: val, Message: If the knownBookies didn't hold bookie, it will thown NPE. Can't resolve it., Label: 0\n",
      "Processing row 1719 - Data Type: train, Message: And the logic is a little bit strange, if we want to resolve bookie, the bookie must exist in the newest writeable bookies or history bookies. If there is a bookie exist in old ledger's ensembles, the bookie maybe not exist in  the newest writeable bookies or history bookies, so I can't resolve the network location. It's unacceptable., Label: 1\n",
      "Processing row 1720 - Data Type: train, Message: @StevenLuMT Renamed to \"getBookieAddressResolverEnable**d**\". What do you think?, Label: 1\n",
      "Processing row 1721 - Data Type: val, Message: It maybe.If a ledger fragment is `data_loss` and `not _adhere_placement_policy` together, we can't fix it once. \n",
      "Example: There are four bookies, 1(rack1), 2(rack1), 3(rack2), 4(rack3).\n",
      "There a fragment ensemble is (1, 2, 3), the min rack is 3, and bookie3 data losss.\n",
      "Only (1,3,4) or (2,3,4) can adere placement policy. We should fix data_loss firstly., Label: 0\n",
      "Processing row 1722 - Data Type: train, Message: What is `If all ensembles are missing` meaning?, Label: 1\n",
      "Processing row 1723 - Data Type: train, Message: good suggestion. ðŸ‘, Label: 0\n",
      "Processing row 1724 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1725 - Data Type: train, Message: @hangc0276  set zkRetryBackoffMaxRetries to Integer.MAX_VALUE is ok, I have changed it ,thanks\n",
      "<img width=\"2496\" alt=\"image\" src=\"https://user-images.githubusercontent.com/42990025/176818886-0a47bd6b-ceb0-4c5c-b60c-fcd430930c7e.png\">\n",
      ", Label: 0\n",
      "Processing row 1726 - Data Type: train, Message: It makes sense to me. I have addressed your comment. PTAL., Label: 0\n",
      "Processing row 1727 - Data Type: val, Message: > \n",
      "\n",
      "Is there any better implementation to replace guava cache? @merlimat , Label: 1\n",
      "Processing row 1728 - Data Type: train, Message: finished, Label: 0\n",
      "Processing row 1729 - Data Type: train, Message: ðŸ‘, Label: 0\n",
      "Processing row 1730 - Data Type: train, Message: `deletedEntries=0` is a bug in the log, we have fixed it in the master branch., Label: 0\n",
      "Processing row 1731 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1732 - Data Type: train, Message: the ```computePut```  is similar to ``` computeIfAbsent``` ,  computePut is currently only used for testing. \n",
      "\n",
      "\n",
      "> Found another bug, when the onlyIfAbsent of `org.apache.bookkeeper.util.collections.ConcurrentLongHashMap.Section#put` is false, the following unit test fails, I will fix it together: ![image](https://user-images.githubusercontent.com/39521534/208384700-2a617d23-32a4-440b-8e38-959e2625d793.png)\n",
      "> \n",
      "> ![image](https://user-images.githubusercontent.com/39521534/208384650-b7be917b-a00c-40fd-a90b-ec65b4303cbb.png)\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1733 - Data Type: train, Message: @StevenLuMT I have considered the 1-to-1 situation you mentioned, but I think that in this tool, it does not care whether it is 1-to-1, but only focuses on whether the number of ledgerDirs and indexDirs and whether the absolute paths are the same., Label: 1\n",
      "Processing row 1734 - Data Type: train, Message: If you are worried about the existence of duplicate directories, resulting in multiple executions, then we can use the Set collection, but the original implementation did not consider whether JournalDirs and LedgerDirs are duplicated? Also, 1 vs 1 doesn't make a difference here., Label: 1\n",
      "Processing row 1735 - Data Type: train, Message: okay., Label: 0\n",
      "Processing row 1736 - Data Type: train, Message: addressed, Label: 0\n",
      "Processing row 1737 - Data Type: train, Message: addressed, Label: 0\n",
      "Processing row 1738 - Data Type: train, Message: addressed, Label: 0\n",
      "Processing row 1739 - Data Type: train, Message: addressed, Label: 0\n",
      "Processing row 1740 - Data Type: train, Message: > It is common to get here when phase is ALLOCATED see here\n",
      "> \n",
      "> https://github.com/apache/bookkeeper/blob/e6722848e0a599f215e68e1340196c9dfe8e906e/stream/distributedlog/core/src/main/java/org/apache/distributedlog/bk/SimpleLedgerAllocator.java#L432\n",
      "> \n",
      "> or you can get to here from this path\n",
      "> \n",
      "> https://github.com/apache/bookkeeper/blob/e6722848e0a599f215e68e1340196c9dfe8e906e/stream/distributedlog/core/src/main/java/org/apache/distributedlog/bk/SimpleLedgerAllocator.java#L287\n",
      "> \n",
      "> maybe it is clearer to not use \"!=\" but to explicitly enumerate the \"phases\" in which you are allowed to transition to `HANDING_OVER` .\n",
      "> \n",
      "> Could you please change the condition to a \"positive\" condition ? also we could add assertions and fail in case we reach to this point in an unexpected case\n",
      "> \n",
      "> if using the phase is not enough to discriminate the reason why to set HANDING_OVER maybe we could change the signature of this method and pass the expected \"nextPhase\" or something like that\n",
      "\n",
      "https://github.com/apache/bookkeeper/blob/e6722848e0a599f215e68e1340196c9dfe8e906e/stream/distributedlog/core/src/main/java/org/apache/distributedlog/bk/SimpleLedgerAllocator.java#L287\n",
      "Do you feel this piece is weird?\n",
      "ERROR, HANDLING_OVER, HANDED_OVER will lead to exception, so only ALLOCATING  and ALLOCATED will pass the check, then the **completeAllocation(allocatedLh);**, will change the ALLOCATING/ALLOCATED to HANDLING_OVER.\n",
      "\n",
      "I'm not familiar with the codes, but is the state machine buggy? Normally, I feel should be like this:\n",
      "HANDLING_OVER > HANDED_OVER > ALLOCATING > ALLOCATED, all these 4 states can point to ERROR. But when i went through the codes, seems it is not, just as I mentioned.\n",
      "\n",
      "\n",
      "Are you suggesting to a big changes? (mine is too simple) , Label: 0\n",
      "Processing row 1741 - Data Type: train, Message: > If the `readAheadCacheBatchBytesSize` must smaller than `maxReadAheadBytesSize`, maybe we could change like this:\n",
      "\n",
      "The logic is not inherited, it cannot be changed like this, thanks, Label: 0\n",
      "Processing row 1742 - Data Type: train, Message: I caught all the `fullRead` throw exceptions., Label: 0\n",
      "Processing row 1743 - Data Type: train, Message: In fact I do not. I used a bit older version as a base for my version, and this was still in charge. \n",
      "Removing now, from all *Row classes., Label: 0\n",
      "Processing row 1744 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 1745 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 1746 - Data Type: train, Message: I do not understand what do you exactly mean., Label: 1\n",
      "Processing row 1747 - Data Type: train, Message: Now I have removed comment marks.\n",
      "But I want to know is there a common method for displaying sheets in console in POI. If there is one, I'd like to use that instead of my writeSheetToLog() method. If there is not, would you like me to create it (it should be a bit more subtle than writeSheetToLog()) ?, Label: 1\n",
      "Processing row 1748 - Data Type: val, Message: for some reason the id might be null - the code should now throw up on this. The patch catches the original problem further up the code hierarchy but it took me to find out because of the null pointer exceptions further down the hierarchy., Label: 0\n",
      "Processing row 1749 - Data Type: train, Message: I just noticed `setRef` is already exposed as `XSSFTable.setCellReferences`, so I'll use that.\n",
      "\n",
      "I also had to use CTTable and CTTableColumn near line 143 though, to get the correct column index. Now I saw that I could have used `XSSFTable.findColumnIndex(String columnHeader)` instead of calculating the column index myself, but it seems I would still have to use `CTTableColumn` to get the column header name. \n",
      "\n",
      "I didn't want to make any API changes before, but I guess in this case it would be useful if `XSSFXmlColumnPr` exposes the column header name and maybe also provides its column index. That would avoid using any CT* classes. What do you think?, Label: 1\n",
      "Processing row 1750 - Data Type: val, Message: Sorry, that was a hack to avoid that the test is terminated to early while debugging. I forgot to change it back. I know that JUnit Timeout rules can be deactivated while in debug mode, but I didn't find any way to do the same for timeouts defined in the annotation., Label: 0\n",
      "Processing row 1751 - Data Type: train, Message: I hit a type erasure issue with using multiple appendIfPresent methods that took Optional<T> (T - String, Date, etc.) I can use different names for the private methods., Label: 0\n",
      "Processing row 1752 - Data Type: train, Message: moved constant variable code from XWPFChart TO XDDFChart, Label: 0\n",
      "Processing row 1753 - Data Type: val, Message: abstract methods to update series id and order id, Label: 0\n",
      "Processing row 1754 - Data Type: train, Message: Yes, but then the codePointAt() method will not receive the correct index. I switched to using the codePoints iterator, which does not seem to have a big performance impact., Label: 0\n",
      "Processing row 1755 - Data Type: train, Message: Done. Could you explain what analyze() does and why it is useless for DF?, Label: 1\n",
      "Processing row 1756 - Data Type: train, Message:  can i return in this case an empty polygon?, Label: 1\n",
      "Processing row 1757 - Data Type: train, Message: I still do not know why PyPi gave the project name as geo-pyspark instead of geo_pyspark. That is the reason behind different names in pip install geo-pyspark and pip install from wheel file. Everywhere I am using geo_pyspark, so it is trange to me why did PyPi do that., Label: 1\n",
      "Processing row 1758 - Data Type: train, Message: Sure. There is one logistical matter we need to think about though: when submitting this R package to CRAN, there will be an email from CRAN to the maintainer's email address containing a confirmation link, and someone will need to click that link each time. Would dev@sedona.apache.org work for that purpose?, Label: 1\n",
      "Processing row 1759 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 1760 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1761 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 1762 - Data Type: train, Message: ofc , Label: 0\n",
      "Processing row 1763 - Data Type: train, Message: didnt know that, thanks, Label: 0\n",
      "Processing row 1764 - Data Type: val, Message: sure, Label: 0\n",
      "Processing row 1765 - Data Type: train, Message: Saving null would be a better approach to go about I think. Though the default implmentation of the geotools returns an empty array. But I feel we should also support null types. I had the same confusion when I was implementing this. , Label: 1\n",
      "Processing row 1766 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 1767 - Data Type: train, Message: Doesn't \n",
      "```\n",
      "run: if [ ${SPARK_VERSION:0:1} == \"3\" ]; then mvn -q clean install -Dscala=${SCALA_VERSION:0:4} -Dspark=3.0 ; else mvn -q clean install -Dscala=${SCALA_VERSION:0:4} -Dspark=2.4 ; fi\n",
      "```\n",
      "already handle that? It looks like that test did run with scala 2.13 in the actions (I see deprecation warnings). Also, since the patch version is ignored in the tests should the scala version just be set to the minor version in the matrix?, Label: 1\n",
      "Processing row 1768 - Data Type: train, Message: As per POSTGIS `getCollapsedClusterIds` will set the cluster id only for indexes that are part of isInCluster or all the indexes if isInCluster is empty.\n",
      "@jiayuasu Is this the expected behavior?, Label: 1\n",
      "Processing row 1769 - Data Type: train, Message: Is it possible to find the CRS from the coordinates or geometry object in java or scala programming?, Label: 1\n",
      "Processing row 1770 - Data Type: train, Message: Updated. Couldn't find a way to set SRID using flink methods. This test case tests scenario when SRID isn't present. Is that Okay ?, Label: 1\n",
      "Processing row 1771 - Data Type: train, Message: Removed the statement, Label: 0\n",
      "Processing row 1772 - Data Type: train, Message: Removed the statement, Label: 0\n",
      "Processing row 1773 - Data Type: val, Message: Just did the right commit. Should be good now. Sorry about that. IntelliJ was causing that issue., Label: 0\n",
      "Processing row 1774 - Data Type: train, Message: Am I supposed to make any changes in this file and commit again?, Label: 1\n",
      "Processing row 1775 - Data Type: train, Message: Alright. I gave this a shot. Let me know if it isn't what you were hoping for.\n",
      "\n",
      "Also: I don't know what the proper etiquette is on github. Do I click the \"Resolve Conversation\" button when I think I did it or do the folks requesting code changes do that when they are satisfied?, Label: 1\n",
      "Processing row 1776 - Data Type: train, Message: Assertions for expressions with optional parameters looks strange since all parameters will receive their arguments before evaluation. This assertion became unnecessary since the function builder registered to the catalog will emit error messages for function calls with invalid number of parameters:\n",
      "\n",
      "```\n",
      "SELECT ST_Point(1)\n",
      ">>> function ST_Point takes at least 2 argument(s), 1 argument(s) specified\n",
      "```\n",
      "\n",
      "For expressions with optional parameters like `ST_Point` we cannot simply assert `inputExpressions.size == 3` since there's one weird behavior in the implementation of the function builder: when 2 arguments were passed to `ST_Point`, it will construct a `ST_Point` object using these 2 arguments first, then call its `inputTypes` method to acknowledge that it actually has 3 parameters, so that it will construct the final `ST_Point` object with 2 user specified arguments and one default argument.\n",
      "\n",
      "There're [better ways](https://github.com/apache/spark/blob/master/sql/catalyst/src/main/scala/org/apache/spark/sql/catalyst/analysis/FunctionRegistry.scala#L110) to support optional parameters without constructing intermediate invalid expressions, however that may introduce huge changes, so I'd like to live with it for now., Label: 0\n",
      "Processing row 1777 - Data Type: train, Message: I could not figure out how to easily implement other combinations, Label: 1\n",
      "Processing row 1778 - Data Type: val, Message: Yes, Label: 0\n",
      "Processing row 1779 - Data Type: train, Message: outsidePoint? it's used at row 321\n",
      "```Long outsideCell = Functions.s2CellIDs(outsidePoint, 10)[0];```, Label: 0\n",
      "Processing row 1780 - Data Type: train, Message: Thank you for reviewing. Here is the point I want to discuss.If we don't plot centroid point, it will be hard for us to find the shape, so I keep it.\n",
      "\n",
      "If we want to do better, we can choose whether to display the center point marker based on the zoom level, but implementing this will be more complicated.\n",
      "\n",
      "Which solution do you prefer?, Label: 1\n",
      "Processing row 1781 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1782 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 1783 - Data Type: val, Message: Added, Label: 0\n",
      "Processing row 1784 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 1785 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1786 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1787 - Data Type: train, Message: This was an accident while merging with master.\n",
      "I have reverted this, Label: 0\n",
      "Processing row 1788 - Data Type: train, Message: Our function can return POINTM for POINT with XYZM coordinates. But it seems that PostGIS can't return that: \n",
      "```\n",
      "postgres=# SELECT GeometryType(ST_GeomFromText('POINTM(0 0 1 0)'));\n",
      "ERROR:  can not mix dimensionality in a geometry\n",
      "HINT:  \"POINTM(0 0 1 0)\" <-- parse error at position 20 within geometry\n",
      "```\n",
      "Should I need to add test for this file?, Label: 0\n",
      "Processing row 1789 - Data Type: train, Message: OK, but I'm a little confused. Though it could work. I search it but can't find any usage about geometry collections. XD, Label: 0\n",
      "Processing row 1790 - Data Type: train, Message: Yeah, I think so. Here we can keep Sedona implementation. Should we use the keep the function name the same as PostGIS like 'ST_ReducePrecision '? Or we can revert to the old name 'ST_PrecisionReduce ', which doesn't exsit in PostGIS., Label: 0\n",
      "Processing row 1791 - Data Type: train, Message: I was going to reuse nDims() func but I wasn't sure about coding standards., Label: 1\n",
      "Processing row 1792 - Data Type: train, Message: Do you want me to remove the coordDim func entirely or have it, and call the nDims function in this file?, Label: 1\n",
      "Processing row 1793 - Data Type: train, Message: I didn't, it must have happened when IDEA was Indexing or the auto-inserts., Label: 1\n",
      "Processing row 1794 - Data Type: val, Message: Can you please elaborate on what you mean? I can't understand., Label: 1\n",
      "Processing row 1795 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 1796 - Data Type: val, Message: I cannot work with config as that would require me to create config objects for the map everytime I add a new df. As this bug only affects when adding the same dataset twice, I believe getting around this by adding a copy of the dataset is okay for these tests?, Label: 0\n",
      "Processing row 1797 - Data Type: train, Message: common/src/test/java/org/apache/sedona/common/FunctionsTest.java over here?, Label: 0\n",
      "Processing row 1798 - Data Type: train, Message: Fixing it., Label: 0\n",
      "Processing row 1799 - Data Type: train, Message: Moved, Label: 0\n",
      "Processing row 1800 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1801 - Data Type: train, Message: Sorry about that, pushed, Label: 0\n",
      "Processing row 1802 - Data Type: train, Message: I think so as nodata is not always 0, it can be -9999. Refer: https://desktop.arcgis.com/en/arcmap/latest/manage-data/raster-and-images/nodata-in-raster-datasets.htm#:~:text=NoData%20is%20stored%20as%20a,common%20value%20for%20storing%20NoData., Label: 0\n",
      "Processing row 1803 - Data Type: train, Message: My bad. I thought I had removed it., Label: 0\n",
      "Processing row 1804 - Data Type: train, Message: No, to define the pixel type of the raster. Is there another way to define it?, Label: 1\n",
      "Processing row 1805 - Data Type: train, Message: I've added a test testing other band for a test raster. The real test rasters I have are too huge and I cannot hardcode an expectedValue into the test., Label: 0\n",
      "Processing row 1806 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 1807 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1808 - Data Type: train, Message: Got it. I didn't know., Label: 1\n",
      "Processing row 1809 - Data Type: train, Message: Have kept `RS_Value (raster: Raster, point: Geometry)` signature and reverted changes to R tests.\n",
      "\n",
      "Note: \n",
      "- Only Point geometry variant of RS_Value and RS_Values can take band as optional parameter\n",
      "- Same currently not possible for the integer variant because of conflicting function signatures as shown below,\n",
      "`RS_Value (raster: Raster, colX: Integer, colY: Integer)`\n",
      "`RS_Value (raster: Raster, point: Geometry, band: Integer)`, Label: 0\n",
      "Processing row 1810 - Data Type: train, Message: Sorry for taking long, I got confused. As there is another function called `convertCRSIfNeeded` in RasterUtils, which does exactly what we wanted, that is to convert the CRS of given geometry to raster's CRS. I was using the `convertCRSIfNeeded` in `RasterPredicates.java`., Label: 0\n",
      "Processing row 1811 - Data Type: train, Message: No, it doesn't affect the current `RS_AsRaster` function. This refactoring was done to remove the pixel coordinate translation and use the output from the `AsRasterWithRasterExtent` function instead. We talked about it in our tag-up last Thursday to improve performance.\n",
      "\n",
      "It is related to Zonal statistics., Label: 0\n",
      "Processing row 1812 - Data Type: train, Message: https://github.com/apache/sedona/blob/ac788aeeede5d2f1185437ae1eba337ae38c1a41/common/src/main/java/org/apache/sedona/common/raster/RasterBandAccessors.java#L253-L257\n",
      "\n",
      "It is just a placeholder value to remove the pixels that aren't under the given geometry `roi`, Label: 0\n",
      "Processing row 1813 - Data Type: train, Message: This is hypervisor specific code and each hypervisor is achieving it differently. To me it doesn't make sense to put it in lib or something like that as it will unnecessarily add complexity without achieving much.\n",
      ", Label: 0\n",
      "Processing row 1814 - Data Type: val, Message: No. There is no file open operation involved here.\n",
      ", Label: 0\n",
      "Processing row 1815 - Data Type: train, Message: If its just a file then else part will take care. And I don't understand how does socket file is involved here.\n",
      ", Label: 1\n",
      "Processing row 1816 - Data Type: train, Message: Here if it is a file then I am copying it directly as can be seen in else block but if it is a directory then I am listing files and then copying files individually as the library which we are using elsewhere in CloudStack doesn't support copying directories. \n",
      ", Label: 0\n",
      "Processing row 1817 - Data Type: train, Message: I got your point but I don't understand how will that make any difference here\n",
      ", Label: 1\n",
      "Processing row 1818 - Data Type: train, Message: @wido numeric ids in logs are easy to understand/debug than uuids. names might me more readable but ids are unique and hence no ambiguity. \n",
      "The current pool-id is already logged and the pool-id of the the volume would help me see if the volume is moving across pools. Thats the information I was looking for while debugging this issue and was hard to find given nothing was logged before.\n",
      ", Label: 0\n",
      "Processing row 1819 - Data Type: train, Message: as i said before, looking at the earlier logs will give you the context. what more are you looking for? please suggest.\n",
      ", Label: 1\n",
      "Processing row 1820 - Data Type: train, Message: @rafaelweingartner  addressed, Label: 0\n",
      "Processing row 1821 - Data Type: val, Message: @jburwell I didn't consider it because configuration will be added and it will be present unless it is explicitly deleted from db. Anyways, I can add `Preconditions.checkState(globalNfsVersion != null)` do you agree?\n",
      ", Label: 0\n",
      "Processing row 1822 - Data Type: val, Message: Looks good @karuturi . Thanks for the PR. Can you open it against my branch (syed/cloudstack:xenserver7) so that I can merge it in this PR? , Label: 0\n",
      "Processing row 1823 - Data Type: train, Message: @jburwell  VirtualNetworkApplianceManagerImplTest.java has all tests commented out. are there any other place having tests covering this?\n",
      ", Label: 1\n",
      "Processing row 1824 - Data Type: train, Message: @rhtyd, since sr is unique on a pool, adding hostname to its path does not give any advantage. Usually MS will go thru the pool master so effectively it will end up the pool master uuid to sr name.\n",
      "This could have avoided the race condition by probably introducing redundant SRs, but now that the race condition is dealt with we really donot need the host uuid qualification of SR name., Label: 0\n",
      "Processing row 1825 - Data Type: val, Message: Addressed this, Label: 0\n",
      "Processing row 1826 - Data Type: train, Message: formatted , Label: 0\n",
      "Processing row 1827 - Data Type: val, Message: In CitrixresourceBase StringUtils is used from the  com.cloud.utils.StringUtils. So using  StringUtils from java.lang will be ambiguous.\n",
      ", Label: 0\n",
      "Processing row 1828 - Data Type: val, Message: Corrected, Label: 0\n",
      "Processing row 1829 - Data Type: train, Message: @wido I was thinking of other ways but could not find. Do you have any idea?\n",
      "We can remove this change and ask users to execute \"cloudstack-setup-management --tomcat7\" after each upgrade. It seems not wise.\n",
      "\n",
      "I have tested the upgrade from 4.7.1 to 4.9.3.0-SNAPSHOT on ubuntu 12.04 and 16.04 without any issue.\n",
      "I did not test the os upgrade or tomcat upgrade., Label: 0\n",
      "Processing row 1830 - Data Type: train, Message: I agree with you. I changed it to `removeDomainWithNoAccountsForCleanupNetworksOrDedicatedResources`. I think is quite more descriptive but still long, Label: 0\n",
      "Processing row 1831 - Data Type: val, Message: One doubt here, if user is allowed why need to allow admin explicitly., Label: 1\n",
      "Processing row 1832 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1833 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1834 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 1835 - Data Type: train, Message: I don't find any double quote in the mentioned section. Can you please check again., Label: 0\n",
      "Processing row 1836 - Data Type: val, Message: @rajesh-battala / @sowmyakrishn: Can you please explain this one., Label: 0\n",
      "Processing row 1837 - Data Type: train, Message: Here, we don't check for a collection. node.getServicePackage() is a single string., Label: 0\n",
      "Processing row 1838 - Data Type: train, Message: Actually, we followed the existing approach. The scenario you told is also valid but I wonder if anyone would really be using a PR branch in production without community approval., Label: 1\n",
      "Processing row 1839 - Data Type: train, Message: The delete operation requires searching for an entry in the op_dc_ip_address_alloc table based on a particular IP address. It checks if that IP is allocated to anyone before deleting. \n",
      "It cannot be implemented in one method because the other usages search for a range in a DC or in a POD. Hope this clarifies!!, Label: 0\n",
      "Processing row 1840 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 1841 - Data Type: train, Message: @rhtyd, I am not getting how can we modify our case with try-with-resources statement. Can you suggest the change? Basically we need to release the lock (_podDao.releaseFromLockTable(podId)).\n",
      "Btw, Do you think there is any advantage of using try-with-resources statement instead of try-finally?, Label: 1\n",
      "Processing row 1842 - Data Type: train, Message: isn't that exactly what it says or am I having a complete brainfart here???\n",
      "\n",
      "(DEFER_CONFIG is set and vm_dhcp/vm_metadata) || finish_config()\n",
      ", Label: 1\n",
      "Processing row 1843 - Data Type: train, Message: isn't that exactly what it says or am I having a complete brainfart here???, Label: 1\n",
      "Processing row 1844 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1845 - Data Type: train, Message: this is not the usual pattern on API classes. I am adhering to the general practice in this case, Label: 0\n",
      "Processing row 1846 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 1847 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 1848 - Data Type: train, Message: I am not sure, but I think you are free to do so in your plugin, aren't you?, Label: 1\n",
      "Processing row 1849 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 1850 - Data Type: train, Message: and another one, Label: 0\n",
      "Processing row 1851 - Data Type: train, Message: I moved it to static constant in this file. Do you want me to add it to some config files?, Label: 0\n",
      "Processing row 1852 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1853 - Data Type: train, Message: corrected the description, Label: 0\n",
      "Processing row 1854 - Data Type: val, Message: Will add the space after ,\n",
      "Why to remove the constants  for default value and multiplier?\n",
      ", Label: 1\n",
      "Processing row 1855 - Data Type: train, Message: This part of the code is executed at SSVM where we can not read the DB. So the value read from ConfigKey is set in context and here it isread from context. If the value in the context is null then a default value is read as constant value of DEFAULT_VM_OVA_PACKAGE_TIMEOUT..\n",
      "\n",
      "I do not understand what is expected when you say use the value dynamically. Do you mean read the value from DB? but DB which could not be accesses from systemvm, Label: 1\n",
      "Processing row 1856 - Data Type: train, Message: @wido unrelated code is removed from PR., Label: 0\n",
      "Processing row 1857 - Data Type: train, Message: @svenvogel java_home is a local variable that i have defined in import_jvm_cacerts.  \n",
      "\n",
      "@karuturi cloud-agent script contains a code snippet as \"export JAVA_HOME\", but I don't think it initializes JAVA_HOME environment variable., Label: 1\n",
      "Processing row 1858 - Data Type: train, Message: I'm not sure I understand what you mean here, @DaanHoogland. Do you mean the indentation under line 1373? Perhaps you are referring to line 1374 being blank? If it's 1374 being blank, I guess I just lean toward using empty lines as a way to not cram all the code together into one, unreadable block., Label: 1\n",
      "Processing row 1859 - Data Type: train, Message: I have a question about that. I have this config key (and corresponding logic to use it) implemented in a custom version of 4.6 for a customer and this customer is looking to migrate to 4.11. If I change this from being in Config to being in ConfigKey, will that cause problems for them when they migrate to 4.11?, Label: 1\n",
      "Processing row 1860 - Data Type: train, Message: Hi @rhtyd \n",
      "yes we can do it as fix for 4.10. no problem. is it clear that 4.11 will use the old path and for longer time or do we need a more ultimate fix?\n",
      "\n",
      "Sven, Label: 1\n",
      "Processing row 1861 - Data Type: train, Message: how we can change that to 4.10?, Label: 1\n",
      "Processing row 1862 - Data Type: val, Message: shall we leave this as is until debian9 changes get merged?, Label: 0\n",
      "Processing row 1863 - Data Type: train, Message: done \n",
      ", Label: 0\n",
      "Processing row 1864 - Data Type: train, Message: tags is incompatible with CollectionUtils.isEmpty. Ignore this hint., Label: 0\n",
      "Processing row 1865 - Data Type: train, Message: @rafaelweingartner Actually, when I'm looking at the proposed code, I find is less obvious than current one. As I see, you prefer more discrete logic approach, but a lot of people feel difficult reading these things. I would like to avoid changing this code, because it makes it less expressive., Label: 0\n",
      "Processing row 1866 - Data Type: train, Message: @yvsubhash It's original implementation. I haven't changed it. I suppose it's the subject for other improvement PR. Also, It might be that it's intended. Suppose that user expects that there are tags \"A\" and \"B\" and they should be removed. If there is \"A\" but not \"B\", currently the code fail and tags are in place, otherwise it silently work even if \"B\" is absent. @yvsubhash what do you think?\n",
      "  , Label: 1\n",
      "Processing row 1867 - Data Type: train, Message: I, honestly, don't like it and have never used it like this, but wanted to follow the same pattern in the code base., Label: 0\n",
      "Processing row 1868 - Data Type: train, Message: @marcaurele : Changed the code as per your suggestion. Now added a code for using global lock along with volume id added in the lock name.\n",
      "Can you please review the new code ?, Label: 0\n",
      "Processing row 1869 - Data Type: train, Message: @rhtyd so, I have to move these into the conditions otherwise they may be null right?, Label: 0\n",
      "Processing row 1870 - Data Type: train, Message: this change is breaking things. We need to look at it. @rafaelweingartner CAManagerImpl.java needs the boolean. should we take this to 4.12? I'm not taking the time now., Label: 1\n",
      "Processing row 1871 - Data Type: train, Message: Yes, there were more changes than the renaming. These other files were not compiling at all. The method `getTextContent` does not exist anymore in XML-APIs. So, this looks like a problem that was ignored during dependencies upgrade. Just to make things clear... I am not upgrading these dependencies with this PR, this was already there when I started fixing the classes that were moved to wrong directories.\n",
      "\n",
      "The same happens in the code where I had to update the use of `VolumeVO` and `SnapshotVO`. Someone seems to have changed the signature of the method, but did not fix it everywhere.\n",
      "\n",
      "A similar problem is found for `DirectAgentManagerSimpleImpl.java`, it was not implementing all of the methods from one of its interfaces.\n",
      "\n",
      "And in `VmSnapshotDaoTest.java`, there is something that would never compile. Someone changed the `VMSnapshotDetailsVO` signature, but did not change all of the places that use it. Therefore, there was an instantiation where the third variable was receiving something called `display`. This `display` is not a variable in that context. It is something auto-generated by Eclipse.\n",
      ", Label: 0\n",
      "Processing row 1872 - Data Type: train, Message: I have no idea why sometimes it compiles. It should not per Java specs. You cannot have a `package` declaration in `x.y.z` and then put this same class in a folder structure as `x.y.z.z`. \n",
      "\n",
      "The thing called `display` there is nothing. It is not a variable, it is nothing... We need a boolean variable/value here. This looks like something that eclipse generated when using the refactor feature., Label: 1\n",
      "Processing row 1873 - Data Type: train, Message: I was under the impression that there was a hard requirement. Anyways, I only found the problem because of Eclipse. It was complaining about these files that were in the wrong folder structure., Label: 0\n",
      "Processing row 1874 - Data Type: train, Message: Correct. Shouldn't we update packaging job to have _correct_ flags rather than changing package.sh script to be able to tolerate _incorrect_ flags?, Label: 0\n",
      "Processing row 1875 - Data Type: train, Message: Where in wiki? The only place I could find that references `setnextversion.sh` is https://cwiki.apache.org/confluence/display/CLOUDSTACK/Release+Procedure ., Label: 1\n",
      "Processing row 1876 - Data Type: train, Message: @DaanHoogland I changed it!, Label: 0\n",
      "Processing row 1877 - Data Type: train, Message: There is no displayname parameter in VirtualMachine.java. Also hostName refers to name parameter only, Label: 0\n",
      "Processing row 1878 - Data Type: train, Message: Sorry for the delayed response, i have been out of town for the last week.  Yea, i'm OK with a global parameter.  i'd just have to sit down and determine how to do that.  I could likely just make it a parameter passed to the script..., Label: 0\n",
      "Processing row 1879 - Data Type: train, Message: Agreed, not sure how that got missed here., Label: 1\n",
      "Processing row 1880 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1881 - Data Type: train, Message: I removed it because it was extraneous.  A similar but more detailed log entry is performed for every case that the host is in Disconnected.  Itâ€™s just a little hard to see that while reading through the changes., Label: 0\n",
      "Processing row 1882 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1883 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1884 - Data Type: train, Message: Thanks, how about now?, Label: 0\n",
      "Processing row 1885 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1886 - Data Type: train, Message: The problem is that I do not have a CIDR. The network CIDR (at least in the basic network) is null. I like the idea of isIp6InNetwork, but I will need to ignore CIDR at this stage and use only ipv4 range., Label: 0\n",
      "Processing row 1887 - Data Type: train, Message: I'm not an expert about it but, as I understand, it's a Xen feature which speeds up Windows guests by providing some hyperV extensions. Viridian was the codename of HyperV., Label: 0\n",
      "Processing row 1888 - Data Type: train, Message: Right, it's my mistake. This line should not be changed., Label: 0\n",
      "Processing row 1889 - Data Type: train, Message: doesn't that make it part of the javadoc rendering? it seems weird to include only part of the parameter list in the javadoc., Label: 1\n",
      "Processing row 1890 - Data Type: val, Message: String.format() should not be called for a string we are not logging anyway, so yes, Label: 0\n",
      "Processing row 1891 - Data Type: train, Message: I'm happy for you to work that out, I'm just trying to get a set of tests that aren't constantly throwing false positives, which make them useless. I don't have time to figure out all cases., Label: 0\n",
      "Processing row 1892 - Data Type: val, Message: @rhtyd the timeout is used to set the `GetVolumeStatsCommand` `wait` variable. However, I was not able to find any piece of code using the `wait` value, neither on `LibvirtGetVolumeStatsCommandWrapper` nor `CitrixGetVolumeStatsCommandWrapper`., Label: 0\n",
      "Processing row 1893 - Data Type: train, Message: Yes. Unfortunately, another ugly legacy., Label: 0\n",
      "Processing row 1894 - Data Type: train, Message: Mainly I just couldn't throw a NoTransitionException because it would create a circular dependency.  CloudRuntimeException would work though, since as you say that's ultimately what ends up happening in the one place this gets called (for now).  I have no problem making this change., Label: 0\n",
      "Processing row 1895 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 1896 - Data Type: train, Message: This isn't my code, but I'm not entirely sure how to even test things in backupSnapshotExecutor.  That is inited by the config() method, and that's not called from the existing unit tests.  Any thoughts?, Label: 1\n",
      "Processing row 1897 - Data Type: train, Message: The idea behind Sorting by capacity was that the imagestore with the most available capacity will always be on the top of the list hence selected first.\n",
      "I thought about checking if imagestore has enough capacity but that would mean that I compare the image size vs remaining capacity of the image store, that of course would mean that I introduce another parameter to this `getImageStore` method, perhaps Image id or something, to check for size of image. Not sure how this will go down with the consumers of `getImageStore`. , Label: 1\n",
      "Processing row 1898 - Data Type: train, Message: @GabrielBrascher @andrijapanic moved the JAVA_PID here so users can't change/mess it around. The systemd variable referencing is limiting, the fix was to use the `${VAR}` syntax and not `$VAR` syntax. Can you believe it! https://www.freedesktop.org/software/systemd/man/systemd.service.html#Command%20lines, Label: 0\n",
      "Processing row 1899 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 1900 - Data Type: train, Message: I looked the code, I think I decided to hard-code because the enums are defined in VirtualEthernetCardType (vmware-base) and using the enum will add dependency hell as `api` should not depend on `vmware-base`. I  looked at other options as well, they all have this same problem, there is no easy way (without code-base wide refactoring) to find out what options are available for a detail/key., Label: 0\n",
      "Processing row 1901 - Data Type: train, Message: @anuragaw could this cause regression or issues, this is always picking up the first account in the list; should it be something like - if user is root admin, then all enable/permit for all accounts matching the name using something like `accountIds.add(permittedAccount.getId());` in the if block; and refactor suitably?, Label: 1\n",
      "Processing row 1902 - Data Type: train, Message: Should this find account using name and domain?, Label: 1\n",
      "Processing row 1903 - Data Type: train, Message: Can you rectify the description to reflect the general use-case of the config key @anuragaw ?, Label: 1\n",
      "Processing row 1904 - Data Type: val, Message: Ok, how about now?, Label: 0\n",
      "Processing row 1905 - Data Type: train, Message: yup fixed. wasn't sure why state was mapped to ObjectInDataStoreStateMachine.State and not Snapshot.State .., Label: 1\n",
      "Processing row 1906 - Data Type: train, Message: The idea is that it shouldn't be., Label: 1\n",
      "Processing row 1907 - Data Type: train, Message: @rhtyd @DaanHoogland \n",
      "this is same as viewDetails in ListVMsCmd and ListHostsCmd.java\n",
      "In some other API, details are in key/value pairs.\n",
      "\n",
      "I agree 'view' or 'listdetails' make more sense.\n",
      "I am afraid of backward compatibility.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 1908 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1909 - Data Type: train, Message: These existed before. Leaving them as is., Label: 0\n",
      "Processing row 1910 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 1911 - Data Type: train, Message: Do you mean ` if( network.getTrafficType()....` should be reformatted to ` if (network.getTrafficType()....`?, Label: 1\n",
      "Processing row 1912 - Data Type: val, Message: @rhtyd Throwing an exception or returning null for Image store can fail this. This might not be needing a sec store for writing. Maybe need to handle this separately?, Label: 1\n",
      "Processing row 1913 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1914 - Data Type: train, Message: This file is removed. It seems also that it was a type or some case.\n",
      "\n",
      "It was unused, so that's why this PR removes it., Label: 0\n",
      "Processing row 1915 - Data Type: train, Message: Not being used indeed. Dead variable which was never called, Label: 0\n",
      "Processing row 1916 - Data Type: train, Message: based on #3111 I thought we can push it back to 4.9, should I switch it to 4.13?, Label: 0\n",
      "Processing row 1917 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 1918 - Data Type: val, Message: Thought its okay, because it ensures the boundaries remain within range. Regarding the info that could be withheld? what did you have in mind?, Label: 1\n",
      "Processing row 1919 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1920 - Data Type: train, Message: @rhtyd I see your point. I understand that we need to avoid such surprises when upgrading. Do you know a way to update it without surprising users? I ask this because, from my perspective, such parameter should be set to true as default for system VMs.\n",
      "\n",
      "Just to provide some context on why this PR has been created. These changes are tackling an issue regarding cases as the following:\n",
      "\n",
      "1. each pod requires a VR for a network 'A';\n",
      "2. network 'A' has been restarted and all VRs of that network have been re-deployed;\n",
      "3. VRs fail to be deployed on disabled Pods (that still running production VMs);\n",
      "4. network restarting fails for disabled Pods and cannot update network configurations that we had expected to be updated on the VR.\n",
      "5. production VMs running on disabled Pods have no longer the VR services.\n",
      "\n",
      "The idea is that we should, by default, keep deploying such VMs to provide all the services also for legacy environments.\n",
      "\n",
      "I see a disabled resource as a legacy environment where one shall not deploy new production VMs; however, such an environment still need to provide the basic services for VMs that have not been destroyed/migrated. Thus, system VMs (CCPVM, SSVM, VRs) are still necessary to be deployed/re-deployed to keep serving the VMs that have not yet been migrated from the disabled resource.\n",
      "\n",
      "Said that, if you still think that this should be set to false by default, I can add info at error messages that point to this parameter when system VMs are not deployed on disable resources. At least making the user/admin aware of this option., Label: 0\n",
      "Processing row 1921 - Data Type: train, Message: Yes, this is for hosts which are already existed in CloudStack.  Auto discover Uefi capability for existing host is planned as part enhancement to this feature. Can be addressed later. Hence it's set false in initial version of implementation. , Label: 0\n",
      "Processing row 1922 - Data Type: train, Message: I don't see any problem on having maximum iops for write and read separately if this makes sense on a practical way. What do you think @wido?, Label: 1\n",
      "Processing row 1923 - Data Type: val, Message: i'll test, but i think not :(, Label: 0\n",
      "Processing row 1924 - Data Type: train, Message: anticipation. I'm not against moving it but it is a very specific ldap related term, so leaving it for now., Label: 0\n",
      "Processing row 1925 - Data Type: train, Message: yes, i didn't have headspace to think on testing this, yet., Label: 0\n",
      "Processing row 1926 - Data Type: train, Message: not sure if this is the place to check for validity of user names. Why do you think we could encounter a blank here?, Label: 1\n",
      "Processing row 1927 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 1928 - Data Type: train, Message: @weizhouapache yes, since it's a java string I've to use the double slash `\\\\`.\n",
      "It would run this: (note the `\\\\S` in the string vs `\\S` that it runs on bash)\n",
      "`ip route | grep default | head -1 | grep -Po '(?<=dev )(\\S+)'`, Label: 0\n",
      "Processing row 1929 - Data Type: train, Message: @wido @DaanHoogland while the `/proc` subsystem is stable enough, I've used iproute now - how about now ^^ ?, Label: 0\n",
      "Processing row 1930 - Data Type: train, Message: Thanks @wido for the comments!\n",
      "We will check what will be needed for the patch, and we will start working on it. We will ask for help, if we get stuck somewhere.\n",
      "Could you please give me and example why \"executing commands is just not reliable enough\"? And if there are a problems with commands execution whether there will be the same with execution of virsh in helper scripts?  , Label: 1\n",
      "Processing row 1931 - Data Type: train, Message: I have to check in which cases is used isDynamic, I was following the implementation of the rest of the configurations in SnapshotManager class, no other motivations. It's better to be dynamic or?, Label: 1\n",
      "Processing row 1932 - Data Type: train, Message: removed the new state and events related to it, Label: 0\n",
      "Processing row 1933 - Data Type: train, Message: ah, yes right thanks!, Label: 0\n",
      "Processing row 1934 - Data Type: train, Message: What is the benefit to declare this constants into the implementation class, especially there is only one specific implementation?, Label: 1\n",
      "Processing row 1935 - Data Type: train, Message: I think thats happened during the merge. My IntelliJ sorts the imports differently, for whatever reason.., Label: 1\n",
      "Processing row 1936 - Data Type: train, Message: I think thats happened during the merge. My IntelliJ sorts the imports differently, for whatever reason.., Label: 1\n",
      "Processing row 1937 - Data Type: train, Message: you mean, move it to a method?, Label: 1\n",
      "Processing row 1938 - Data Type: train, Message: I have moved it outside of the if block. I had left it there initially because only in this loop will there be a loop and and a counter but no pb., Label: 0\n",
      "Processing row 1939 - Data Type: train, Message: Yes that is what I mean, Label: 0\n",
      "Processing row 1940 - Data Type: train, Message: this is in sync with existing default roles with id (1,2,3,4). Shall I prepend all these role names with \"Default\" ? , Label: 0\n",
      "Processing row 1941 - Data Type: val, Message: > Should the `rule` here be `list*` or `get*` etc.? Or was `rule` declared somewhere I missed ?\n",
      "\n",
      "the 'list*' and 'get*' rules for the User role are added for read-only user, Label: 1\n",
      "Processing row 1942 - Data Type: train, Message: > nit - Can you improve the exception message?\n",
      "\n",
      "Updated, Label: 0\n",
      "Processing row 1943 - Data Type: train, Message: @rhtyd do I need to add this to support default CentOS template or will this just be a workaround at the runtime?, Label: 1\n",
      "Processing row 1944 - Data Type: train, Message: Hi @rhtyd I believe yes, some changes will be necessary on Cloud-Primate\n",
      "I will take a look on this project, but i'm not familiarized with VUE.js, Label: 0\n",
      "Processing row 1945 - Data Type: train, Message: You can run the integration test cases using `nosetests --with-marvin --marvin-config=<cfg file> test_reset_configuration_settings.py`, Label: 0\n",
      "Processing row 1946 - Data Type: train, Message: Thanks, this needs to be public - TODO, Label: 0\n",
      "Processing row 1947 - Data Type: train, Message: thanks for the hint, I did not know about this other specific use case., Label: 1\n",
      "Processing row 1948 - Data Type: train, Message: there's a check that volume is in fact detached  with this : ```volume.getVmName()``` hence, vmMo under such a scenario will only point to the worker VM. To be safer, will destroy workerVMMo instead. Thanks!, Label: 0\n",
      "Processing row 1949 - Data Type: val, Message: @weizhouapache That could be a bigger issue since rfb.js is used to communicate with the host. Did destroying and recreating the console proxy help ? Also could you check whether the customer has tweaked the novnc code in the cpvm ? Or any issue with the systemvm.iso itself ?, Label: 1\n",
      "Processing row 1950 - Data Type: train, Message: is moved ;), Label: 0\n",
      "Processing row 1951 - Data Type: train, Message: Jepp, but on vmware side they are called hard disks. but i agree that hard disk suggests otherwise, Label: 1\n",
      "Processing row 1952 - Data Type: train, Message: @shwstppr Good point, But how realistic is it to say that we have a volume with a position and without a controller id.? I talked with my administration and network colleagues and other controller types like NVME and SATA have also a controller id.\n",
      "Therefore I think about it to add an exception in the else condition? What do you think?, Label: 1\n",
      "Processing row 1953 - Data Type: val, Message: @rhtyd damn, your are right, that was to quick from my side, the catch block catch all exceptions :(. \n",
      "\n",
      "Hmm ... is it ok to remove the catch block ? \n",
      "\n",
      "In my opinion the ingest process should be canceled if not all volumes ingestible. What do you think @rhtyd @shwstppr ? , Label: 1\n",
      "Processing row 1954 - Data Type: val, Message: @shwstppr ahh ok you have two controller(ide, lsilogic), But in my opinion it makes no sense that you have one disk on one controller on position one. Also should increment the controller id, when you use more the one controller. And for this reason works this feature not correct. I think you found a other bug., Label: 0\n",
      "Processing row 1955 - Data Type: val, Message: IÂ´m a little bit confused, because the behaviour of adding/not adding (32-bit) is inconsistent already in this single db-schema upgrade file - for example:\n",
      "\n",
      "---\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L593\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L594\n",
      "\n",
      "---\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L620\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L631\n",
      "\n",
      "---\n",
      "and opposite\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L718\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L729\n",
      "\n",
      "---\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L749\n",
      "\n",
      "https://github.com/apache/cloudstack/blob/015bb20caaabd82774fa3fb261787ef4be9ee90d/engine/schema/src/main/resources/META-INF/db/schema-41400to41500.sql#L760\n",
      "\n",
      "\n",
      "\n",
      "So, what should I use as template?, Label: 0\n",
      "Processing row 1956 - Data Type: train, Message: @shwstppr actually the api `listPhysicalNetworks` never gets called and hence the value `this.formSelectedPhysicalNetwork` is not populated . Typically there should be atleast 1 physical network. so i dont much of an issue here, Label: 0\n",
      "Processing row 1957 - Data Type: train, Message: Addressed, Label: 0\n",
      "Processing row 1958 - Data Type: train, Message: Addressed, Label: 0\n",
      "Processing row 1959 - Data Type: train, Message: To my knowledge, this setting is not used through garbage collection, it is checked when an instance is destroyed. I'm not sure if there is some kind of garbage collection that would destroy a VR, if there is, then I suppose this will also apply., Label: 1\n",
      "Processing row 1960 - Data Type: val, Message: Adding `isrecursive` will display the subdomain accounts, but when updating permission for those accounts, an error will arise. So I don't think it's necessary. What do you think?\n",
      "![image](https://user-images.githubusercontent.com/13766648/111583323-cca0f980-87ee-11eb-9e5b-9cd80109917c.png)\n",
      "![image](https://user-images.githubusercontent.com/13766648/111583375-e3475080-87ee-11eb-9a47-c04d07c856fe.png)\n",
      "![image](https://user-images.githubusercontent.com/13766648/111583447-07a32d00-87ef-11eb-928a-20e662d6a3f1.png)\n",
      "ping @shwstppr , Label: 0\n",
      "Processing row 1961 - Data Type: train, Message: @DaanHoogland Why this should initiate with a capital letter?, Label: 1\n",
      "Processing row 1962 - Data Type: train, Message: @shwstppr thnx, the mkdir was missing fixed., Label: 0\n",
      "Processing row 1963 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1964 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 1965 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1966 - Data Type: val, Message: No, Label: 0\n",
      "Processing row 1967 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 1968 - Data Type: train, Message: @nvazquez I think I did not get it :grimacing:, could you explain me better?, Label: 1\n",
      "Processing row 1969 - Data Type: val, Message: No, currently I only hard fix the width for ipad, tablet screens and below. Do you feel it is ok or do you need to follow the percentage of the screen?, Label: 1\n",
      "Processing row 1970 - Data Type: train, Message: @weizhouapache ehhhh what ? this was my first solution, What is with idem potent?  , Label: 1\n",
      "Processing row 1971 - Data Type: train, Message: Hi @nvazquez, is deleted. Is cames not from me, I guess it was a little mistake during the merge., Label: 0\n",
      "Processing row 1972 - Data Type: train, Message: but what the hell, Label: 1\n",
      "Processing row 1973 - Data Type: train, Message: It is cleaned @DaanHoogland but at a later stage, as first the networks need to be cleaned up. As the tests failed with such  errors - `Can't delete the project yet because it has 1 Network to clean up` , Label: 0\n",
      "Processing row 1974 - Data Type: train, Message: I could not found any usage for this label, but from context, it should be `\"Removendo regra do balanceador de carga....\"`, Label: 1\n",
      "Processing row 1975 - Data Type: train, Message: @wido \n",
      "It seems monitor with ipv6 address is not suported in this PR.\n",
      "\n",
      "what is currently supported and any issue in following scenarios ?\n",
      "- ipv6 addr without port\n",
      "- ipv6 addr with port\n",
      "I do not have a ceph env with ipv6 address , it is difficult to verify., Label: 1\n",
      "Processing row 1976 - Data Type: train, Message: with the new code, the priorities are number (positive, negative or 0), not HIGH/LOW/NORMAL\n",
      "examples can be found at http://qa.cloudstack.cloud/docs/WIP-PROOFING/pr/291/adminguide/virtual_machines.html#determine-destination-host-of-vms-with-non-strict-affinity-groups, Label: 0\n",
      "Processing row 1977 - Data Type: val, Message: Not sure if it makes sense to add 4.18 here as it is not a new API just an additional Admin class for adding some params for admin account, Label: 1\n",
      "Processing row 1978 - Data Type: train, Message: @DaanHoogland I am afraid the below code may not work as cmd will be an instance of `ListVMsMetricsCmdByAdmin` and not `ListVMsCmdByAdmin` , Label: 0\n",
      "Processing row 1979 - Data Type: val, Message: discussed it offline, Label: 0\n",
      "Processing row 1980 - Data Type: train, Message: @rohityadavcloud For vmware, should we add `otherLinux64Guest` for OS which doesn't return ID? I tried to log guest OS descriptors for VMware 7u3 and can't find some of the OSes.\n",
      "[vmware-guestos-descriptors.txt](https://github.com/apache/cloudstack/files/10371810/vmware-guestos-descriptors.txt)\n",
      "\n",
      "But could see them listed here, https://www.vmware.com/resources/compatibility/search.php?deviceCategory=software\n",
      "\n",
      "For XCP-ng/Xen, I don't see any EL9 distro here, https://docs.citrix.com/en-us/citrix-hypervisor/system-requirements/guest-os-support.html, Label: 1\n",
      "Processing row 1981 - Data Type: train, Message: ```suggestion\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'AlmaLinux 9', 'VMware', '7.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Oracle Linux 9', 'VMware', '7.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Red Hat Enterprise Linux 9', 'VMware', '7.0', 'rhel9_64Guest,');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Rocky Linux 9', 'VMware', '7.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'AlmaLinux 9', 'VMware', '7.0.1.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Oracle Linux 9', 'VMware', '7.0.1.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Red Hat Enterprise Linux 9', 'VMware', '7.0.1.0', 'rhel9_64Guest,');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Rocky Linux 9', 'VMware', '7.0.1.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'AlmaLinux 9', 'VMware', '7.0.2.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Oracle Linux 9', 'VMware', '7.0.2.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Red Hat Enterprise Linux 9', 'VMware', '7.0.2.0', 'rhel9_64Guest,');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Rocky Linux 9', 'VMware', '7.0.2.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'AlmaLinux 9', 'VMware', '7.0.3.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Oracle Linux 9', 'VMware', '7.0.3.0', 'otherLinux64Guest');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Red Hat Enterprise Linux 9', 'VMware', '7.0.3.0', 'rhel9_64Guest,');\n",
      "CALL ADD_GUEST_OS_AND_HYPERVISOR_MAPPING (1, 'Rocky Linux 9', 'VMware', '7.0.3.0', 'otherLinux64Guest');\n",
      "```\n",
      "@weizhouapache would this make sense?\n",
      "I've removed CentOS9 as that doesn't show up in the compatibility matrix, https://www.vmware.com/resources/compatibility/search.php?deviceCategory=software&details=1&partner=272&releases=448&page=1&display_interval=10&sortColumn=Partner&sortOrder=Asc&testConfig=16\n",
      "cc @rohityadavcloud @DaanHoogland , Label: 0\n",
      "Processing row 1982 - Data Type: train, Message: @DaanHoogland @nvazquez @rohityadavcloud \n",
      "\n",
      "I forgot to mention it in the description. My idea while implementing this way was to extend it in the future to store more data (when/which user generated the console session, when/which IP consumed it, and so on - indeed, `console_session` would be a better name), to allow operators to track the console sessions; And the entries would be marked as removed/used instead of being deleted. \n",
      "\n",
      "As gathering those data would require a more accurate analysis of the console session workflow, I first implemented this way to handle the situation; then I would improve the feature. \n",
      "\n",
      "What do you think?\n",
      "\n",
      "\n",
      "\n",
      ", Label: 1\n",
      "Processing row 1983 - Data Type: train, Message: On principle, I would rather not create a constructor for informing the object properties, as the more properties it has, the longer the constructor would get, becoming harder to read/interpret the code. For Python, that supports keyword arguments, this approach works fine, though., Label: 0\n",
      "Processing row 1984 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 1985 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1986 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 1987 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 1988 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1989 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1990 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 1991 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 1992 - Data Type: train, Message: sorry, I do not give this pr proper tlc (bit detached fromit), Label: 0\n",
      "Processing row 1993 - Data Type: train, Message: Yes., Label: 0\n",
      "Processing row 1994 - Data Type: train, Message: I don't think we will need them. Can you think of a specific use case for it?, Label: 1\n",
      "Processing row 1995 - Data Type: train, Message: At this point, we don't have an implementation that supports custom collating sequences, so I'm hesitant to be very prescriptive about identifying them. The implementation I envision is allowing callers to pass a Comparator and an identifier String, without the Parquet library controlling sorting. If that's something we can agree on, then this shouldn't be an area where we need to impose requirements., Label: 0\n",
      "Processing row 1996 - Data Type: train, Message: I think sorting columns may need a separate update. These identifiers could potentially be used there, but I don't think the ordering (or direction) is currently stored., Label: 1\n",
      "Processing row 1997 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 1998 - Data Type: train, Message: The comments of hash say take plain encoding of content. We don't have to explain endianness here again, since algorithm itself is endianness irrelevant., Label: 1\n",
      "Processing row 1999 - Data Type: train, Message: It has a statement outside enumeration that hash function take plain encoding of value as input. Do we still need specify byte order? In parquet, plain encoding uses little endian of value. \n",
      ", Label: 1\n",
      "Processing row 2000 - Data Type: train, Message: 1. I encrypted the compressed page using a fixed encryption algorithm(for the time being) based on an opinionated way like column starting with \"encrypted_\" will be encrypted in this way.\n",
      "(I also think that the encryption status should come in the schema itself, but I was unable to add a field into the schema because of the lack of knowledge in that project.)\n",
      "2. Since our page header is still not encrypted I think we can have the predicate push down(correct me if not). \n",
      "3. Since we are encrypting the compressed page I think it will act independently.\n",
      "4. Currently I'm not specifying the algorithm details in the meta. If we can provide the same through the schema do we need it in the meta ?, Label: 1\n",
      "Processing row 2001 - Data Type: train, Message: Yes, Label: 0\n",
      "Processing row 2002 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2003 - Data Type: train, Message: Do you have a suggestion what to add so it becomes more clear?, Label: 1\n",
      "Processing row 2004 - Data Type: train, Message: I didn't use markdown, because I couldn't find a way to merge cells. Do you know how to do it?, Label: 1\n",
      "Processing row 2005 - Data Type: train, Message: Two sentence after it is mentioned, that in fact LogicalType have an older representation called ConvertedType. Isn't it enough to mention it there?, Label: 1\n",
      "Processing row 2006 - Data Type: train, Message: Thanks, we are citing a kind of well-known hash which is widely used in hive, orc, guava and etc..  It just like codec definition above we don't have implementation detail document. In the project hive, orc, and guava, I don't see they have implementation document., Label: 0\n",
      "Processing row 2007 - Data Type: train, Message: Oops. I think I forgot to use `git add` before `git commit --amend`., Label: 0\n",
      "Processing row 2008 - Data Type: train, Message: I don't think so, since this is the only BF algorithm in the spec right now., Label: 1\n",
      "Processing row 2009 - Data Type: train, Message: I do not think we do. I think that was probably overkill in the first place. While it's possible to explain what \"optimal\" means for some definition of \"optimal\", that adds unnecessary complexity., Label: 1\n",
      "Processing row 2010 - Data Type: train, Message: Exactly. While eight bits are **set** each time an item is inserted, that doesn't mean that the fraction `bits_of_space / number_of_distinct_items_inserted` is eight. I attempted to convey this by adding the modifier \"of space\"., Label: 1\n",
      "Processing row 2011 - Data Type: train, Message: Yes, there isn't one. I'd hesitate to say it is \"better\" to overfill than underfill. They're just different tradeoffs., Label: 1\n",
      "Processing row 2012 - Data Type: train, Message: I think shorter is better here. I'm not adverse to this coming in a follow-on patch, maybe even after the release, since such a note would be advisory or commentary, not normative., Label: 0\n",
      "Processing row 2013 - Data Type: train, Message: It certainly can theoretically happen. It's not the task of this PR to write an implementation, though., Label: 0\n",
      "Processing row 2014 - Data Type: train, Message: @wgtmac @gszadovszky can you please take a look at current changes ?, Label: 0\n",
      "Processing row 2015 - Data Type: train, Message: @wgtmac @gszadovszky is anything more needed to merge this ?, Label: 1\n",
      "Processing row 2016 - Data Type: train, Message: Yes, I have noticed that. But I think there is no \"org.apache.runtime\" package..., Label: 1\n",
      "Processing row 2017 - Data Type: train, Message: what about thisâ€œ//Protocol layer requester description//â€?, Label: 1\n",
      "Processing row 2018 - Data Type: train, Message: > We need to throw an Exception if the clusterGroup is empty?\n",
      "> And in your code, it seems the `totalWeight` cannot <= 0?\n",
      "\n",
      "I add a not empty check in the constructor.\n",
      "totalWeight equals 0 is acceptable, it will make the sameWeightGroup true.\n",
      "totalWeight less than 0 maybe not possiable in the context, the IP_PORT_WEIGHT_PATTERN can not match a negative weight., Label: 0\n",
      "Processing row 2019 - Data Type: train, Message: I have no idea how to set different exporter.What should I do?, Label: 1\n",
      "Processing row 2020 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2021 - Data Type: val, Message: changed, Label: 0\n",
      "Processing row 2022 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2023 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2024 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2025 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2026 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2027 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2028 - Data Type: train, Message: I have no idea how to define 'a Trace class'., Label: 1\n",
      "Processing row 2029 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2030 - Data Type: train, Message: > add a shutdown hook twice, then it throws an exception\n",
      "\n",
      "the shutdown hook is already added in the `zipkinTraceService.init();`, thus it throws exception in test as expected.\n",
      "\n",
      "It ensures the `addShutdownHook` is called in the `init()` method, and the `Thread(sdkTracerProvider::close)` is added there. If someone change the behavior of that (e.g. remove the whole line `Runtime.getRuntime().addShutdownHook(new Thread(sdkTracerProvider::close));`), the unit test would fail.\n",
      ", Label: 0\n",
      "Processing row 2031 - Data Type: train, Message: Do you mean change the modifier of these member variable from private to `protected` ?\n",
      "That makes sense to me, the test code located in the same package of `ZipkinTraceService `, which makes the protected member variable also accessible., Label: 1\n",
      "Processing row 2032 - Data Type: train, Message: also make sense to me, seems the `eventmesh-example` uses that only for log. it's not necessary to export to the users of `eventmesh-sdk-java`\n",
      "https://github.com/apache/incubator-eventmesh/blob/c055e8324fd6b0c67055b2f4c6731f386acdb5a4/eventmesh-examples/src/main/java/org/apache/eventmesh/http/demo/sub/controller/SubController.java#L42\n",
      "https://github.com/apache/incubator-eventmesh/blob/c055e8324fd6b0c67055b2f4c6731f386acdb5a4/eventmesh-examples/src/main/java/org/apache/eventmesh/http/demo/sub/controller/SubController.java#L56, Label: 0\n",
      "Processing row 2033 - Data Type: val, Message: Token supportï¼Ÿ, Label: 0\n",
      "Processing row 2034 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2035 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2036 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 2037 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2038 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2039 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2040 - Data Type: train, Message: So. should I keep it the same as before? Since I just did it as the issue told.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 2041 - Data Type: train, Message: Merged both the Cases., Label: 0\n",
      "Processing row 2042 - Data Type: train, Message: Reverted back the changes (Removed few white spaces)., Label: 0\n",
      "Processing row 2043 - Data Type: train, Message: The second argument is on the same line but when I tried to put all the 3 arguments in the same line, I got the warning as shown below:\n",
      "<img width=\"320\" alt=\"image\" src=\"https://github.com/apache/eventmesh/assets/124816912/acd33f5d-66eb-4e58-ac9b-dbe86cfece39\">\n",
      ", Label: 0\n",
      "Processing row 2044 - Data Type: val, Message: You want me to use my docker creds for my repo and than check if the image is pushed. Is my assumption correct?, Label: 1\n",
      "Processing row 2045 - Data Type: train, Message: The subscription logic is in `RedisConsumer` and is called by Consumer API. I don't think it is needed here., Label: 1\n",
      "Processing row 2046 - Data Type: train, Message: So since Redis does not need to create it first, we can leave it this way. Am I right? @Pil0tXia , Label: 0\n",
      "Processing row 2047 - Data Type: val, Message: https://github.com/redisson/redisson/wiki/6.-distributed-objects#671-topic-pattern\n",
      "\n",
      "We can only use pattern to get the topic since we don't know what's the topic exactlly. I haven't found a way to do this more efficiently., Label: 1\n",
      "Processing row 2048 - Data Type: train, Message: Yes, the original port was mistaking., Label: 1\n",
      "Processing row 2049 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2050 - Data Type: train, Message: In prometheus source connector ,I read data from prometheus server with time range, and use recordOffset to save completed timestamp for each query. Is that necessary?, Label: 1\n",
      "Processing row 2051 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2052 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 2053 - Data Type: val, Message: No, the options in the context are all log options., Label: 0\n",
      "Processing row 2054 - Data Type: val, Message: Drop empty dose not throw exception..., Label: 0\n",
      "Processing row 2055 - Data Type: val, Message: How to write failure tests in ITCase? These should exist in `GlobalCommitterOperatorTest`?, Label: 1\n",
      "Processing row 2056 - Data Type: train, Message: Why useless? It is needed as an argument of `ProjectionCodeGenerator.generateProjection`., Label: 0\n",
      "Processing row 2057 - Data Type: train, Message: > there is no call order\n",
      "\n",
      "If we put the adjusting and validation in `#withXXX` method, how to make sure the `rowType` has been specified already?, Label: 1\n",
      "Processing row 2058 - Data Type: train, Message: > Why we need schema? We can just show index in exception without schema.\n",
      "\n",
      "because index adjusting needs to be computed based on the physical schema. If we throw an exception, does this approach against that the builder pattern doesn't impose call order? How could we call this a builder pattern?, Label: 1\n",
      "Processing row 2059 - Data Type: train, Message: It's weird that `TableStore` must be first specified with schema then specified with pk and partitions, why do we impose the order?, Label: 1\n",
      "Processing row 2060 - Data Type: train, Message: > I don't get it. In my understanding, this is only index adjustment, why must need schema.\n",
      "\n",
      "So in your understanding, index adjustment is based on what?  Below is the current index adjusting in `TableStoreFactory`\n",
      "\n",
      "```java\n",
      "primaryKeys =\n",
      "                    schema.getPrimaryKey().get().getColumns().stream()\n",
      "                            .mapToInt(rowType.getFieldNames()::indexOf)\n",
      "                            .toArray()\n",
      "```\n",
      "\n",
      "without schema, how could `mapToInt` be accomplished?, Label: 1\n",
      "Processing row 2061 - Data Type: train, Message: > It is better to use List, because primary key and partition both have the order.\n",
      "\n",
      "I think only after pk and partition pass through the sanity check, the order makes a difference. \n",
      "When checking the super/subset relationship, the order doesn't matter., Label: 0\n",
      "Processing row 2062 - Data Type: train, Message: > `sqlPattern.endsWith(\"_\")` what it is mean?\n",
      "\n",
      "match one or more characters, Label: 1\n",
      "Processing row 2063 - Data Type: train, Message: > I think you want to support like '=%%' escape '='. This scene is very, very little\n",
      "\n",
      "Yes, the test case is `like '=%%' escape '='`\n",
      "\n",
      "---\n",
      "\n",
      ">  and the following two conditions I can not understand, and I am not sure there is no bug.\n",
      "\n",
      "What about we do not support the complex situation, Label: 1\n",
      "Processing row 2064 - Data Type: train, Message: CI failed caused by \"native lz4 library not available\", i'm inspecting the problem :), Label: 1\n",
      "Processing row 2065 - Data Type: train, Message: I found that the codes in flink-parquet module has showed that default compression is snappy, given the consistency experience of users, maybe we could make snappy default compression in parquet formats.  I have submitted new commit, PTAL, thanks!\n",
      "```\n",
      "FlinkParquetBuilder#createWriter()\n",
      "return new ParquetRowDataBuilder(out, rowType, utcTimestamp)\n",
      "                    .withCompressionCodec(\n",
      "                            CompressionCodecName.fromConf(\n",
      "                                    conf.get(\n",
      "                                            ParquetOutputFormat.COMPRESSION,\n",
      "                                            CompressionCodecName.SNAPPY.name())))\n",
      "```, Label: 0\n",
      "Processing row 2066 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2067 - Data Type: train, Message: Very good point!\n",
      "\n",
      "I take a look to Hive, Spark, Iceberg. Hive and Spark use `warehouse.dir`. Iceberg use `warehouse`.\n",
      "\n",
      "I think we can change `root-path` to `warehouse`.\n",
      "\n",
      "- `warehouse` for managed table. I think we can adjust this to `warehouse/${database}.db/${tableName}`.\n",
      "- `warehouse` for catalog. `root-path/${database}.db/${tableName}`.\n",
      "- `path`: table path.\n",
      "\n",
      "What do you think?\n",
      ", Label: 1\n",
      "Processing row 2068 - Data Type: val, Message: Make tests compiled with Flink 1.14 is very very hard..., Label: 0\n",
      "Processing row 2069 - Data Type: train, Message: I thought about it, but it was too simple and didn't feel necessary, Label: 0\n",
      "Processing row 2070 - Data Type: train, Message: `speeds up the` looks good to me.\n",
      "But for `the query filters should form`, I think it is not a `should`, it is just an optimization., Label: 0\n",
      "Processing row 2071 - Data Type: train, Message: When I take a look to https://dev.mysql.com/doc/refman/5.7/en/multiple-column-indexes.html\n",
      "We don't have to add space here., Label: 0\n",
      "Processing row 2072 - Data Type: train, Message: Read data will fail in this PR. I found this issue [FLINK-27846](https://issues.apache.org/jira/browse/FLINK-27846) before I fixed FLINK-27847. Should we fix read data in FLINK-27847 or in FLINK-27846? What do you think of it? HTX, Label: 1\n",
      "Processing row 2073 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2074 - Data Type: train, Message: My initial idea is that some file systems (such as s3) do not support rename operation, so I did not add the file system rename operation.\n",
      "\n",
      "I see that the latest interface(`org.apache.flink.table.store.fs.FileIO#rename`) adds the rename operation, so I also add the file system catalog rename operation. If some filesystem does not support the rename operation,  rename table will fail., Label: 0\n",
      "Processing row 2075 - Data Type: train, Message: Can share memory for multiple writes.\n",
      "I will delete this method, it is wrong., Label: 0\n",
      "Processing row 2076 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2077 - Data Type: train, Message: I think let it non-null to throw exception., Label: 0\n",
      "Processing row 2078 - Data Type: val, Message: ok , Label: 0\n",
      "Processing row 2079 - Data Type: train, Message: have been modified\n",
      " , Label: 0\n",
      "Processing row 2080 - Data Type: train, Message: I'm afraid there is no good solution yet.\n",
      "https://github.com/diffplug/spotless/issues/649.  Perhaps it is more appropriate now, thanks for help and i will close this pr . @zhuangchong \n",
      "\n",
      ", Label: 0\n",
      "Processing row 2081 - Data Type: val, Message: I think that if there are multiple tasks writing to this database, after modifying the database name, all tasks need to re-designate the database. Is there any way to make the writing task aware of the database name change?, Label: 1\n",
      "Processing row 2082 - Data Type: train, Message: Hive does not support rename database., Label: 0\n",
      "Processing row 2083 - Data Type: train, Message: Can we use skipStatField instead? This might be more generic in FieldStatsArraySerializer ,FieldStatsArraySerializer  may don't need care the default value concept  of table., Label: 0\n",
      "Processing row 2084 - Data Type: train, Message: hi, @yuzelin , do you mean \n",
      "```code\n",
      "action = DropPartitionAction(xx)\n",
      "action.run()\n",
      "```\n",
      "\n",
      "But in this case, we need to parse the parameters for DropPartitionAction construct method. This might cause some duplicated code and some complicated cases., Label: 0\n",
      "Processing row 2085 - Data Type: train, Message: enen,I will modify to avoid reuse manager.earliestSnapshotId() and  manager.latestSnapshotId().And  any thing elase?, Label: 0\n",
      "Processing row 2086 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2087 - Data Type: train, Message: I reverted this change to assertNull, Label: 0\n",
      "Processing row 2088 - Data Type: train, Message: Sorry, what objects? both `exchangeId` and `nextInterval` already exist. SLF4J will only send the log message to the underlying framwork if debug is actually enabled. From my understanding `is..Enabled()` is redundant here. Am I wrong?, Label: 1\n",
      "Processing row 2089 - Data Type: val, Message: @ok2c This change looks good to me, at better than my code ;-)\n",
      "Shall we document that the retry interval is ignored? I would add it to the class Javadoc., Label: 0\n",
      "Processing row 2090 - Data Type: train, Message: * I have opted to normalize to `execCount` since this is called in an `ExecChainHandler`. Both name parts are consistent now.\n",
      "* It likely could, as far as I understand `HttpContext` it shall contain information through entire execution chain. `execCount` is scoped to one single chain handler.\n",
      "* You are obviously referring to `org.apache.hc.core5.http.protocol.HttpCoreContext.HTTP_REQUEST`. I can't make any statement here. I see that several exec chain handler pass the `HttpRequest`. I have no opinion/expertise here., Label: 1\n",
      "Processing row 2091 - Data Type: train, Message: That's a private class, consider it like a record or value class. I see no benefit., Label: 0\n",
      "Processing row 2092 - Data Type: val, Message: Separately (with a separate ticket), I'd like to consider replacing instance loggers with static loggers to avoid paying a penalty on instantiation. This would result in slightly different (and arguably better) behavior when classes are extended, as the logger origin would reflect the location that produced logging, not the subclass that happened to extend it. For example, if I want to debug hc5, I might set the `org.apache.hc` origin to `TRACE` level and add it to a separate appender. If I've extended a component it won't appear with my httpclient logs using the `getClass()` approach.\n",
      "Thoughts on this proposal?, Label: 1\n",
      "Processing row 2093 - Data Type: train, Message: This line is to avoid GGSSchemeBase throwing MalformedChanllengeException. The token is not in the negociate reponse header \"WWW-Authenticate: Negotiate\".\n",
      "\n",
      "I suggest to remove the null check on GGSSchemeBase. What do you think?, Label: 1\n",
      "Processing row 2094 - Data Type: train, Message: Agree! Ideally we can just hardcode it in the code like what v4.5 does. This code is written just in case there's a plan to support other type. Please suggest. \n",
      "\n",
      "Kerberos/SPNego works with these changes. Otherwise, not, Label: 0\n",
      "Processing row 2095 - Data Type: train, Message: > I actually meant `DEFAULT_CONN_KEEP_ALIVE`. Which did you mean?\n",
      "\n",
      "I was referring to DEFAULT_CONNECTION_REQUEST_TIMEOUT\n",
      ", Label: 1\n",
      "Processing row 2096 - Data Type: train, Message: Perhaps the code could be clearer if we only collected either IP or DNS entries depending on the HostNameType?, Label: 1\n",
      "Processing row 2097 - Data Type: train, Message: Changed.\n",
      "ty\n",
      "but I meant. the IDE should show a warning here because there are using a deprecated method. But in any case.  Changed.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2098 - Data Type: train, Message: idem above. but I can changed.  Please let me what do you prefer. , Label: 0\n",
      "Processing row 2099 - Data Type: train, Message: Changed. TY, Label: 0\n",
      "Processing row 2100 - Data Type: train, Message: Although `BinaryDecoder.decode` declares this exception, the Base64 subclasses did not actually ever throw the exception. I've left the handling in place as a reminder of how invalid inputs can be handled. , Label: 0\n",
      "Processing row 2101 - Data Type: train, Message: @michael-o Why?, Label: 1\n",
      "Processing row 2102 - Data Type: train, Message: > This assumption cannot be done here.\n",
      "\n",
      "@michael-o Why is that? An NT principal is just a composite of domain and user name. Anyhow, I removed the principal from `BearerToken`. So, forget it., Label: 1\n",
      "Processing row 2103 - Data Type: train, Message: @michael-o Why would not principal make sense here? Credentials are always associated with a particular security principal of some sort. Whether or not we can parse out the principal out of the token itself is a whole different story., Label: 1\n",
      "Processing row 2104 - Data Type: train, Message: @michael-o What do you mean? They do not know what they are doing? HTTP requests are no farts. They do not happen once of a sudden and for no reason. They are always executed by some agent for a specific means. There is always at least the application with an application id of some sort., Label: 1\n",
      "Processing row 2105 - Data Type: train, Message: mmmm @ok2c  would you mind give me an example? had chased some many time this  method , Label: 0\n",
      "Processing row 2106 - Data Type: train, Message: @ok2c \n",
      "This is the only part that I'm not sure about. I don't think these conditions will ever happen. Otherwise, they would be controlled by the previous one., Label: 1\n",
      "Processing row 2107 - Data Type: train, Message: its already cover here,\n",
      "we really not need that validations\n",
      "`   @Test\n",
      "    public void testParseCookieEmptyValue() {\n",
      "        final Header header = new BasicHeader(\"Cache-Control\", \"max-age=;\");\n",
      "        assertThrows(MalformedCookieException.class, () -> parser.parse(header));\n",
      "    }`, Label: 0\n",
      "Processing row 2108 - Data Type: val, Message: remove it, Label: 0\n",
      "Processing row 2109 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 2110 - Data Type: train, Message: I made some changes to avoid creating an additional Tokenizer.Cursor, but I'm not completely certain if it's what you're looking for..\n",
      "\n",
      ", Label: 1\n",
      "Processing row 2111 - Data Type: train, Message: my bad. changed., Label: 0\n",
      "Processing row 2112 - Data Type: train, Message: > You can first check if the sizes of the maps are equal. \n",
      "\n",
      "@arturobernalg Makes sense.\n",
      "\n",
      "> Then I would use allMatch function\n",
      "\n",
      "I am not sure I know what you mean. Is this a matcher?, Label: 1\n",
      "Processing row 2113 - Data Type: train, Message: @arturobernalg I disagree. This is really a matter of taste. I personally find a utility method with 4 arguments much uglier than 5 repetitive trivial lines.   , Label: 0\n",
      "Processing row 2114 - Data Type: train, Message: Agreed, pushed a revised version thanks. However, it is strange that cqlsh does not represent things this way, but the way I had done it before...\n",
      ", Label: 0\n",
      "Processing row 2115 - Data Type: train, Message: Initially the schema was like this: https://gist.github.com/newkek/4a0cbe91577886383aaa9ef89701cf03\n",
      "I changed it to this version after a discussion with @adutra, I think it kind of represents more \"the concept\" even though it's not the exact memory representation. I don't mind changing it back as I believe it is rather subjective. Also noticing that I updated the schema without updating the explanation so actually currently both don't match.\n",
      ", Label: 0\n",
      "Processing row 2116 - Data Type: train, Message: Yes. There's nothing blocking or compute-intensive on that path anymore: if the pool is busy or the keyspace needs to be changed, that will be handled asynchronously via the future returned from borrow. So I figured the extra indirection wasn't worth it anymore.\n",
      ", Label: 0\n",
      "Processing row 2117 - Data Type: train, Message: removed\n",
      ", Label: 0\n",
      "Processing row 2118 - Data Type: train, Message: When this exception is encountered a `DriverInternalError` is raised, which causes the connection to be defuncted and the request retried on the next host, which will also be defuncted.  Is this the right behavior?  It might be better to fail the request, closed the connection (nor not?) and not try on the next host.\n",
      ", Label: 1\n",
      "Processing row 2119 - Data Type: train, Message: I think I can work around the first problem by doing the following:\n",
      "1. After the first message, we assume the version of all frames will be the same on the same connection.  This way we don't have to parse version every time.\n",
      "2. Check the opcode after creating the frame.  The Frame body is not parsed until later anyways, so this should be ok, the disadvantage of this is that we may fail later on in the process. I.E. if the payload is malformed and the full frame length is never received, the request would just time out instead.  That might not be too bad if the data is bad anyways.\n",
      ", Label: 0\n",
      "Processing row 2120 - Data Type: train, Message: Needed because we can't be sure the protocol version the server is using until we actually get something from it.  Although I'm not sure an `AtomicReference` is necessary here, i'd expect `decode` will only called one at a time and from the same i/o thread, wdyt?  In general could there be a better approach than this?\n",
      ", Label: 1\n",
      "Processing row 2121 - Data Type: train, Message: That will work in the general case, the main reason for restricting to one `DecoderForStreamIdSize` is that if you reach the frame length limit, the `DecoderForStreamIdSize` instance tracks the remaining bytes to consume and discards them until remnant of the frame is discarded.  Although in general you should only expect frames sharing the same protocol version, and if that didn't happen the code I have here would fail in unexpected ways anyways, so maybe the best solution is to do as you suggest.\n",
      ", Label: 0\n",
      "Processing row 2122 - Data Type: train, Message: One difference w/ previous implementation was it previously parsed the opcode before calling `super.decode`, this wouldn't work if you were in the middle of discarding a frame because the previous frame bytes would have already been discarded.   This would explain why you previously would get an exception like:\n",
      "\n",
      "```\n",
      "io.netty.handler.codec.DecoderException: com.datastax.driver.core.exceptions.DriverInternalError: Unknown response opcode XX\n",
      "```\n",
      "\n",
      "after a `TooLongFrameException` because the opcode bytes would have been previously discarded.\n",
      "\n",
      "This means that if you get an invalid opcode, it now won't defunct the connection until we've received the whole frame.  I don't think that is a problem, but thought I'd point out the difference.\n",
      ", Label: 1\n",
      "Processing row 2123 - Data Type: train, Message: I agree 100% with you there, it is very convoluted and this was the part of the change I was least comfortable with.   I didn't even catch the detail that `TooLongFrameException` was a subclass of `DecoderException` so it is even stranger than I had thought :).\n",
      ", Label: 1\n",
      "Processing row 2124 - Data Type: train, Message: As discussed offline, I agree that we could use `*Service` interfaces, and `instanceof` checks and casts internally to access the queues.\n",
      "I don't see any value in exposing the Guava wrappers. Implementations may choose to return them, when we call `MoreExecutors.listeningDecorator` internally it will be a no-op.\n",
      ", Label: 0\n",
      "Processing row 2125 - Data Type: train, Message: I'm a bit wary of \"expert use\" comments in general. It implies that we divide users into two groups, but how does someone know if they have the \"expert\" badge?\n",
      "I'd rather say something along the lines of \"things will break badly if this is misconfigured\".\n",
      ", Label: 1\n",
      "Processing row 2126 - Data Type: train, Message: Yeah, i'll change it.\n",
      "I'm actually re-thinking that whole PR, these entire parts ([1](https://github.com/datastax/java-driver/blob/41d3d72c23f149b13303074046f72877461a3cd7/driver-mapping/src/main/java/com/datastax/driver/mapping/MappingManager.java#L82), [2](https://github.com/datastax/java-driver/blob/41d3d72c23f149b13303074046f72877461a3cd7/driver-mapping/src/main/java/com/datastax/driver/mapping/MappingManager.java#L96), etc...) may not work.\n",
      "\n",
      "I think the safest tweak will be to go back to the [original ](https://github.com/datastax/java-driver/blob/3.x/driver-mapping/src/main/java/com/datastax/driver/mapping/MappingManager.java#L37) implementation and add\n",
      "`final Object lock = new Object()`  for each of those maps and synchronize them when constructing. Less pretty, but less error prone i guess.\n",
      "What do you think?, Label: 0\n",
      "Processing row 2127 - Data Type: train, Message: I initially tried to as i wrote in my first comment, but it broke some other places within the mapper (i can look them up although i can't recall right now) that were expecting lower cases not to be quoted., Label: 0\n",
      "Processing row 2128 - Data Type: train, Message: So we can remove setters and `enable`, `disable` methods.\n",
      "One thing is design how should users disable naming strategy all together (in case they have their cassandra column names exactly like their java fields). As you suggested below we probably want to define a NamingStrategy singleton to bypass naming. Only question is whether this is a trivial approach for the user, i.e.:\n",
      "\n",
      "`config.setNamingStrategy(NamingStrategy.PASS_THROUGH);`\n",
      "\n",
      "What do you think?, Label: 1\n",
      "Processing row 2129 - Data Type: train, Message: Discussion for system properties is on the `consistentTestVersioning-adu` branch didn't want to address that here., Label: 0\n",
      "Processing row 2130 - Data Type: train, Message: Hrmm it doesn't look like cluster name is even part of the builder anymore since this is randomly generated, so maybe that comment isn't relevant anymore?, Label: 1\n",
      "Processing row 2131 - Data Type: val, Message: 1) They are only deprecated in OSS driver\n",
      "2) Not sure if, because some method is deprecated, it should not be tested., Label: 1\n",
      "Processing row 2132 - Data Type: train, Message: Sorry I don't get it, how could it have made it to the 3.1.x branch if it isn't merged in 3.0.x yet?, Label: 1\n",
      "Processing row 2133 - Data Type: train, Message: You've certainly fixed the issue as reported in JIRA, thanks for that.  My only feedback would be that when the person writing code against the querybuilder doesn't know exactly what the end user is going to give them as a query, not accepting an empty list of orderings can make for some ugly builder code:\n",
      "\n",
      "https://gist.github.com/podnov/b67f7e57cf702df579b68b67dde839c7\n",
      "\n",
      "I'm sure there are other ways to write this, but the ones immediately apparent to me don't seem terribly straight forward., Label: 1\n",
      "Processing row 2134 - Data Type: train, Message: It's more complicated... The dilemma with ExecutionInfo is that it's updated concurrently, so it boils down to how much info we want to provide vs the overhead of tracking this info., Label: 1\n",
      "Processing row 2135 - Data Type: train, Message: Needed to remove `frozen` from return type (which isn't valid), Label: 0\n",
      "Processing row 2136 - Data Type: train, Message: I was unsure if maintaining the topographical order in `KeyspaceMetadata.userTypes` was important or not.  If it's not it would simplify some code / remove some semi-duplication, if agree I'll remove it., Label: 1\n",
      "Processing row 2137 - Data Type: train, Message: There already isn't a consistent ordering in the collection itself depending on the order of UDT creation (if created within the same Cluster instance), but they are always ordered topologically (just not consistently).  I think it is not important for it to be sorted at that time, but only when exporting it to cql.  I'll add a separate commit that backs that out, but we can always remove that commit if we want to keep it.   I think the order isn't significant (nor is it documented) for the actual collection members, but it is significant when exporting as a cql string because if it's not ordered correctly it's not valid., Label: 1\n",
      "Processing row 2138 - Data Type: train, Message: One oddity, if you set the keyspace flag and using protocol v4, C* 4.0+ will fail since it will still attempt to parse the keyspace.   Because of this figured i'd add a check here to not add the flag if protocol is less than v5., Label: 0\n",
      "Processing row 2139 - Data Type: train, Message: I wonder if we should consider differentiating between keyspace provided with `BuildStatement` (i.e. what comes from `insertInto(keyspace, table)` and otherwise in some way, as it is redundant to send the keyspace with the statement if it's already set in the query., Label: 1\n",
      "Processing row 2140 - Data Type: train, Message: I see what you are saying now, that makes complete sense to me.  `setKeyspace` is not really something used within the driver itself (afaict), so there's really no need to be part of `RegularStatement`.  Instead it is only used by client APIs, who have a more concrete implementation, like `BuiltStatement` for example., Label: 0\n",
      "Processing row 2141 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 2142 - Data Type: train, Message: Should I remove the condition that checks if the keyspaces are different?  Maybe we should also throw an exception when using `setKeyspace` at < V5?, Label: 1\n",
      "Processing row 2143 - Data Type: train, Message: This seems very unlikely now that we check before sending the query., Label: 1\n",
      "Processing row 2144 - Data Type: train, Message: That is the preference for the last 2 options (ignore case wrapper vs hashes in primitive int map from netty-common)?, Label: 1\n",
      "Processing row 2145 - Data Type: train, Message: `CqlSession` used to be in the `cql` package, but since it's now the main entry point to the driver, I thought it would be more appropriate for it to be in the root package. I should at least add an implementation comment to explain that.\n",
      "As for `CqlSessionBuilder`, it's true that it seems a bit weird to keep it in another package, I don't have strong feelings either way., Label: 0\n",
      "Processing row 2146 - Data Type: val, Message: Yes, there will be a method for each metric type: `markMeter`,  `updateTimer`, `incrementCounter`, etc.\n",
      "The caller is expected to know what type of metric each enum constant corresponds to. A mistake is very unlikely because it's all driver code, and the same person will add a metric and add the code to update it. And if a mistake does happen the error should be pretty obvious.\n",
      "\n",
      "The problem with something like `NodeMetric#update` is that `NodeMetric` couldn't be an enum anymore (because it would need a reference to the `Meter`, which is created at runtime, and also because there could be multiple instances for separate sessions). Then the list of metric names wouldn't be known statically, we'd probably need a `NodeMetricRegistry` in order to validate the configuration, etc. The (very low) risk of a mistake does not justify all that complexity IMO., Label: 1\n",
      "Processing row 2147 - Data Type: train, Message: They relate to connections while the others are more specifically for requests, so maybe I should have two sub-categories., Label: 1\n",
      "Processing row 2148 - Data Type: train, Message: I saw this warning in the comments of `buildContext` and had to do the same for this method. I think it is a code smell that indicates that we should rather extract an interface from this class and keep the implementation details in an internal class., Label: 0\n",
      "Processing row 2149 - Data Type: train, Message: This factory method wasn't really bringing any value, this class is internal so the constructor can be public., Label: 0\n",
      "Processing row 2150 - Data Type: train, Message: Just unnecessary (according to IntelliJ)., Label: 0\n",
      "Processing row 2151 - Data Type: train, Message: As you pointed out below, we might want to enrich this interface with more info than just the GAV coordinates, which is why I chose the word \"Info\"., Label: 0\n",
      "Processing row 2152 - Data Type: train, Message: It is included in the line below (199)., Label: 0\n",
      "Processing row 2153 - Data Type: train, Message: was following the logic in `encode` which checks the protocol version, should we change that to?, Label: 1\n",
      "Processing row 2154 - Data Type: train, Message: This references Dropwizard classes. This means that if someone were to integrate another metrics framework, they would have to make `session.getMetrics` return `Optional.empty()`,  and find another way to expose that framework's equivalent of the registry.\n",
      "I don't want to go further than that, because any other solution would have to manifest at a higher level in the API (e.g. `CqlSession<DropwizardMetrics>`, `CqlSession<MicrometerMetrics>`, etc). Ultimately I think switching metrics framework is a very rare edge case, so I'd rather keep the API simpler for the 99.9% regular ones., Label: 0\n",
      "Processing row 2155 - Data Type: train, Message: > people would have to cast to DefaultMetrics\n",
      "\n",
      "That's what I meant by \"would have to manifest at a higher level in the API\". Requiring a cast for a default feature is really bad IMHO. I'd rather not punish the 99.9%, and instead cause a minor inconvenience to the 0.1% that might want to change the metrics framework. Frankly the fact that this is even possible is a cherry on top of the cake already., Label: 0\n",
      "Processing row 2156 - Data Type: train, Message: Based on my reply to your other comment, I think we should avoid specialized `Metrics` subinterfaces, so this wouldn't apply., Label: 0\n",
      "Processing row 2157 - Data Type: val, Message: The only goal of this method is to be exposed as `Session.getMetrics()`. In what scenario would `? extends Metric` be more useful for a client application?\n",
      ", Label: 1\n",
      "Processing row 2158 - Data Type: train, Message: This is far from \"safe\", i.e. the following compiles and runs just fine:\n",
      "\n",
      "```\n",
      "  TypeCodec<Number> codec = unsafeCast(TypeCodecs.TEXT);\n",
      "  System.out.println(codec);\n",
      "  // prints com.datastax.oss.driver.internal.core.type.codec.StringCodec@ea30797\n",
      "``` \n",
      "\n",
      "The only benefit of having this method imo si to reduce the scope of the `@SuppressWarnings` annotation to the minimum, but the name is misleading., Label: 1\n",
      "Processing row 2159 - Data Type: train, Message: Fair enough, my apologies. And besides, I need this method exposed publicly so my argument in favor of moving it doesn't hold anymore., Label: 0\n",
      "Processing row 2160 - Data Type: train, Message: Sorry man I this is what I get when I constantly switch from python to java., Label: 0\n",
      "Processing row 2161 - Data Type: val, Message: I didn't find better class than this to expose these utility methods.., Label: 1\n",
      "Processing row 2162 - Data Type: train, Message: Yes initially there wasn't a DriverContext in the methods parameters, only protocol version and codec registry, then I realized it wasn't good without the DriverContext / ProtocolVersionRegistry so I added it. Didn't think it was worth it to make that check but I guess since DriverContext is there now why not, Label: 1\n",
      "Processing row 2163 - Data Type: train, Message: d'oh, will fix, Label: 0\n",
      "Processing row 2164 - Data Type: train, Message: Does your [earlier comment](https://github.com/datastax/java-driver/pull/1016#discussion_r192770854) make this one obsolete?, Label: 1\n",
      "Processing row 2165 - Data Type: train, Message: One idea I had for profiles which would be feasible would be to have a way for user a to create a `DriverConfigProfile` and then have a `withProfile(DriverConfigProfile profile)` method in here.  That would reduce the duplicated methods.   The one downside of that is that you could not use these`DriverConfigProfile` objects when working with the driver, but we could probably find a way to throw an early runtime exception if someone tries that.    What do you think of this idea?, Label: 1\n",
      "Processing row 2166 - Data Type: val, Message: nevermind, found a way around it., Label: 0\n",
      "Processing row 2167 - Data Type: train, Message: There was a risk of NPE in the previous version:\n",
      "```\n",
      "    return (codec instanceof PrimitiveByteCodec)\n",
      "        ? ((PrimitiveByteCodec) codec).decodePrimitive(getBytesUnsafe(i), protocolVersion())\n",
      "        : get(i, codec);\n",
      "```\n",
      "The unboxing of `get(i, codec)` will throw NPE if that method returns `null` (which can happen depending on which codec has been selected)., Label: 0\n",
      "Processing row 2168 - Data Type: val, Message: Thee is no automatic tool to generate or suggest where to place annotations to my knowledge. IntelliJ can however suggest to propagate annotations from interfaces to implementations, but otherwise I've been crawling the entire codebase. , Label: 0\n",
      "Processing row 2169 - Data Type: train, Message: I agree with you actually, this line somewhat was annotated differently from all the others., Label: 1\n",
      "Processing row 2170 - Data Type: train, Message: On my side IntelliJ warns me that an equals comparison is being performed on incompatible types in such situations., Label: 0\n",
      "Processing row 2171 - Data Type: train, Message: I guess the problem with `initCond` is that `initCond` is an `Object` so I had no warnings from IntelliJ., Label: 0\n",
      "Processing row 2172 - Data Type: val, Message: Yes, it is not advised to store `Optional` instances as instance fields, mainly because `Optional` is not serializable., Label: 0\n",
      "Processing row 2173 - Data Type: train, Message: I don't believe that views can be virtual at this time, just keyspaces and tables, Label: 1\n",
      "Processing row 2174 - Data Type: train, Message: I confess I didn't fully understand this TODO so I left it intact., Label: 0\n",
      "Processing row 2175 - Data Type: val, Message: I've wavered back and forth on this, my current line of thinking is if the user opts in using  `allowHostPortDiscovery`, they are intending to depend on the presence of the peers_v2 table to tell them what ports to use.  In absence of that table, I think failing is the right thing to do.  Whereas with java driver 4.x, we always check this table first, so in that case it makes sense to downgrade to the peers table., Label: 1\n",
      "Processing row 2176 - Data Type: train, Message: I was erring on the side of caution by making this an 'opt-in' feature.  If you don't see that as too risky, I will revert it back to my initial implementation which mirrors the approach we took with 4.x.    With regards to not falling back to `system.peers`, my thought process was that if you explicitly opted in using `allowHostPortDiscovery()`, it didn't seem the backing off to peers was the best idea, since you are expressing that you want to utilize the capability which is not being provided by the server.  If i revert to not making this opt-in that point is moot though.\n",
      ", Label: 1\n",
      "Processing row 2177 - Data Type: val, Message: I had considered adding a `WhiteListPolicy(LoadBalancingPolicy childPolicy, Collection<String> hostnames)` but that doesn't work because of type erasure.  Having a static method seems reasonable in any case., Label: 0\n",
      "Processing row 2178 - Data Type: train, Message: I ended up implementing Andy's initial solution. Moving the check into the constructor caused other issues, namely how we would inform the caller of the constructor that there was an issue, and abort.\n",
      "\n",
      "Everything should be routed through the execute method now, which should provide a single point to check. I also removed the superfluous check on the parent cluster., Label: 0\n",
      "Processing row 2179 - Data Type: train, Message: I'm pretty sure the directory will be empty. It seems that when the tests finish, they execute a `ccm remove` that cleans up everything in the directory, just not the directory itself. I did try to setup a shutdown hook to clean up the directory, but it seems to cause issues where the ccm process hangs at the completion of the test., Label: 0\n",
      "Processing row 2180 - Data Type: val, Message: Yes, I forgot about this from my last PR. I need to break my old habit of test method names., Label: 0\n",
      "Processing row 2181 - Data Type: val, Message: ðŸ‘ makes sense, Label: 0\n",
      "Processing row 2182 - Data Type: train, Message: I don't like having done this. However, some of the integration tests generate a bunch of warnings like this:\n",
      "```\n",
      "ERROR io.netty.util.ResourceLeakDetector - LEAK: HashedWheelTimer.release() was not called before it's garbage-collected. See http://netty.io/wiki/reference-counted-objects.html for more information.\n",
      "```\n",
      "I am calling `timer.stop` in the `onClose()` method below, but that does not seem to get called in certain ITs. After investigating the test and finding one that caused the warning, it seems that it happens when you attempt to create a new session with a misconfigured DriverConfigLoader. Doing so will:\n",
      "1) create a DriverContext that has a lazy reference to an instance of NettyOptions, then\n",
      "1) dereference the DriverContext's NettyOptions, which\n",
      "1) calls the constructor for DefaultNettyOptions, which\n",
      "1) creates the Timer instance (line above this one)\n",
      "\n",
      "However since the test expects the session creation to fail, there is nothing left to invoke `onClose()`, so the Timer's resources are never released, as the warning indicates. The only way I was able to eliminate the warning was to add this shutdown hook.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2183 - Data Type: train, Message: For the tasks we schedule on the timer, the Timeout argument to the `run()` call in the tests doesn't matter (it could be `null`). But that is only because the TimerTasks we schedule in the Handlers simply don't reference the Timeout in the runnable block of code. If that runnable block of code ever does, then passing `null` here could potentially throw an NPE, so I opted to pass in a known non-null reference.\n",
      "But yes, it was (and still looks) weird., Label: 1\n",
      "Processing row 2184 - Data Type: train, Message: I guess we could, however the reason this is here is that without it, it defaults to 1.5 (I think). But the code actually need to be at least 1.7 in order to compile due to language features that didn't exist before 1.7. It's also hard-coded in the compiler config for the Java driver project itself. I don't think we want to let them change it to something lower accidentally and then have to explain that it needs to be at least 1.7., Label: 0\n",
      "Processing row 2185 - Data Type: train, Message: I can open-end it so there is no upper bound. (i.e. `[4.0.0-beta1,]`\n",
      "Or, do you want the _default_ value to be that itself, as opposed to `latest` having a special meaning?, Label: 1\n",
      "Processing row 2186 - Data Type: train, Message: `TokenFactory` doesn't have any nullability annotations yet. Did we ever come up with a rule for internal stuff? I can add it in a separate commit., Label: 1\n",
      "Processing row 2187 - Data Type: train, Message: \"simplified\"? ðŸ˜‰ \n",
      "More seriously, I had also considered:\n",
      "```java\n",
      "    return session()\n",
      "        .getMetadata()\n",
      "        .getTokenMap()\n",
      "        .map(\n",
      "            tokenMap -> {\n",
      "              assertThat(tokenMap.getPartitionerName()).isEqualTo(expectedPartitionerName);\n",
      "              return tokenMap;\n",
      "            })\n",
      "        .orElseThrow(() -> new AssertionError(\"Expected token map to be present\"));\n",
      "```\n",
      "which has a bit more of a \"functional\" flavor but I still find it about as ugly as the imperative version.\n",
      "I'm often disappointed by `Optional` code, without algebraic types or pattern matching you can't fully take advantage of it., Label: 0\n",
      "Processing row 2188 - Data Type: train, Message: I ended up having to parameterize it with 4 types: the source and target iterables, and the source and target element types, and there were still unchecked casts.\n",
      "Indeed your implementation looks simpler. I noticed your `fetchNextPage` doesn't return a covariant future, not sure if this has an impact or not. Maybe I just over-complicated things.\n",
      "\n",
      "But since we agree that a self-type is not desirable (the `?` in the caller code is the worst aspect IMO), I won't dig into it further., Label: 1\n",
      "Processing row 2189 - Data Type: val, Message: I really like to have this here. It's the most natural thing that users might want to do with a result set, so it makes sense to have a shortcut for it. Also it will be super convenient in the object mapper.\n",
      "\n",
      "As I said in JIRA, I think we should stay minimal and not try to implement other functional operators. They don't necessarily work well with the concept of page boundaries., Label: 0\n",
      "Processing row 2190 - Data Type: train, Message: > it's already trivial to obtain a Java 8 stream from `currentPage()` and call `map()` on it\n",
      "\n",
      "If you work with async result sets, you still have to write the logic to rewrap every subsequent page, which incurs a bit of boilerplate.\n",
      "If you use synchronous ones, you can indeed map the iterator, but you lose the paging methods (`isFullyFetched`, `getAvailableWithoutFetching`).\n",
      "\n",
      "What's nice with `map()` is that you get all of that for free.\n",
      "\n",
      "> write a custom wrapper (similar to `AsyncPagingIterableWrapper`)\n",
      "\n",
      "Yes, that's pretty easy to write. But we're going to need it for the mapper anyway, so why not make it available?\n",
      "\n",
      "> register a custom request processor\n",
      "\n",
      "That's the nuclear option ðŸ˜‰ , Label: 0\n",
      "Processing row 2191 - Data Type: train, Message: We can't predict in advance the number of rows, or even the size each row will take in memory, so it's more the latter IMHO.\n",
      "This method is already present in 3.x so users should be familiar with the pitfalls., Label: 0\n",
      "Processing row 2192 - Data Type: train, Message: The reason I am not using the ExectionInfo instance here is that the warnings may not have been set on it at this point. It seems that ExecutionInfo instance is updated with the warnings during processing of the callback. If I want to use the ExecutionInfo directly here, I believe I would have to wait for the callback Future to complete., Label: 1\n",
      "Processing row 2193 - Data Type: train, Message: whoops, copy-paste error on my part., Label: 0\n",
      "Processing row 2194 - Data Type: val, Message: @adutra You commented in #1178 that the QueryLogger should be made static to avoid object instantiation on the hot path. I believe this RequestLogFormatter is on a similar hot path here. However, I'm not sure if there is an easy way to avoid it as the RequestLogFormatter needs an instance of DriverContext, which is only set when this request handler is instantiated. Ideas?, Label: 1\n",
      "Processing row 2195 - Data Type: val, Message: It is possible to change the log level of a given logger in client code (I don't think any of the driver code currently does this). I'm not sure how often, if ever, it is done in production though., Label: 1\n",
      "Processing row 2196 - Data Type: train, Message: Good idea - taking into account the fact `Void` and `Prepared` is extending `Result`.\n",
      "But the question is: do we want to treat `SchemaChange` and `SetKeyspace` as successes here as well? (both are extending `Result`). I think that we can, wdyt?\n",
      ", Label: 1\n",
      "Processing row 2197 - Data Type: val, Message: This was my initial approach however what you will find is the validation that needs to be done is for the most part divorced from the parameter type, and that the code we create in each handel method would be just as convulted and complex as what we have now., Label: 0\n",
      "Processing row 2198 - Data Type: train, Message: Forgot to remove this after testing with it. , Label: 0\n",
      "Processing row 2199 - Data Type: val, Message: thx, I was also not sure that It can be in production code. Changed, Label: 1\n",
      "Processing row 2200 - Data Type: train, Message: ok, thx, Label: 0\n",
      "Processing row 2201 - Data Type: train, Message: After checking again the `codec` can be null because it proxy that into the `literal`. And `literal` is taking `codec` that is `@Nullable`:\n",
      "```\n",
      "literal(@Nullable T value, @Nullable TypeCodec<T> codec)\n",
      "```\n",
      "This is a case when the `value` that is passed to the `json` is `null`. Then the logic is:\n",
      "```\n",
      "value, (value == null) ? null : codecRegistry.codecFor(value)\n",
      "```, Label: 0\n",
      "Processing row 2202 - Data Type: train, Message: Good idea. But I see one problem here:\n",
      "https://github.com/datastax/java-driver/pull/1194/files#diff-ec647efb880ba814afddcf79eaa95570R402\n",
      "`@Nullable Object value` can be null but next, we are doing assert `value != null`.\n",
      "Then there is a possiblity in this line:\n",
      "https://github.com/datastax/java-driver/pull/1194/files#diff-ec647efb880ba814afddcf79eaa95570R412\n",
      "that it will cause NPE, isn't it?\n",
      "Shouldn't the logic be:\n",
      "```\n",
      "  throw new IllegalArgumentException(\n",
      "          String.format(\n",
      "              \"Could not inline literal of type %s. \"\n",
      "                  + \"This happens because the driver doesn't know how to map it to a CQL type. \"\n",
      "                  + \"Try passing a TypeCodec or CodecRegistry to literal().\",\n",
      "              (value == null) ? null : value.getClass().getName()),\n",
      "          e);`\n",
      "```\n",
      "I will make it llike this in the `json()` `DefaultInsert`. Let me know wdyt. I can update logic in a `QueryBuilder` accordingly, Label: 1\n",
      "Processing row 2203 - Data Type: train, Message: The two files are merged, the order of precedence is undefined.\n",
      "\n",
      "There is no reason for a client application to do that. One valid case where it might happen is if another dependency is using Typesafe config, but in that case the options won't collide thanks to the `datastax-java-driver` prefix., Label: 1\n",
      "Processing row 2204 - Data Type: train, Message: > a generic method that takes a supplier function\n",
      "\n",
      "That would work if it's a private helper (we don't want to leak `Config` through the public API). The only thing is that we can't have private methods in an interface, so it would have to live somewhere else. It's just a few lines of code duplicated so I thought it was not worth it., Label: 0\n",
      "Processing row 2205 - Data Type: train, Message: I would, but both `Insert` and `UpdateStart` inherit from different super interfaces already, and neither of those should have `usingTtl` added to them., Label: 0\n",
      "Processing row 2206 - Data Type: train, Message: I see your point. I modeled this after the code for `timestamp`, as it supports a literal value and a BindMarker as well. For `ttlInSeconds`, I believe the literal can be an `Integer` or a `String` in this case, so long as it is a whole number. It could be a `Long` as well, as long as the value isn't larger than what is supported in Cassandra. In fact, it could be any Object that has a `toString()` implementation that returns a whole number between 0 and whatever the max is in Cassandra. \n",
      "\n",
      "We could be a little permissive and only throw the Exception if we can't parse an Integer value from the Object:\n",
      "```\n",
      "try {\n",
      "  Integer ttlValue = Integer.parseInt(ttlInSeconds.toString());\n",
      "  if (ttlValue.compareTo(0) < 0) {\n",
      "    throw new IllegalArgumentException(\"Provided ttlInSeconds value can not be negative\");\n",
      "  }\n",
      "  // add  USING TTL clause\n",
      "} catch (NumberFormatException nfe) {\n",
      "  throw new IllegalArgumentException(\"Provided ttlInSeconds is not a valid value\");\n",
      "}\n",
      "```\n",
      "I guess there is value in failing to build the Builder just prior to trying to have the Builder build the CQL. That would be the only benefit to failing at this point., Label: 0\n",
      "Processing row 2207 - Data Type: train, Message: fails in this test are related to this line:\n",
      "https://github.com/datastax/java-driver/pull/1235/files#diff-75706beabe9b72dbf270c073d07d201fR61\n",
      "To set all columns for Update we need to get all non PKs columns: `entityDefinition.getRegularColumns`.\n",
      "If there is a case (like in this test) that the Entity for which we are generating update prepared statement has only one column and that column is PK the generated Update statement is incorrect.\n",
      "(The WHERE clause in Update is mandatory and it cannot contains `PK`). Because of that, the generated update statement will be incorrect. I am not sure how should we handle such a situation: maybe we should not generate update code path if the entity has only PK? But if the user is annotating the method with `@Update` for such entity it will be confusing for end-user: so other solution will be to throw an exception that we cannot generate update for the entity with only one column. Wdyt?\n",
      "\n",
      "To make this test pass I can just add one additional non-PK key to `protected static final TypeSpec ENTITY_SPEC =` in the DaoMethodGeneratorTest but I am not 100% sure why in this test the Mapper tries to auto-generate  \n",
      "```\n",
      "@Override\n",
      "  public UpdateWithAssignments update() {\n",
      "```, Label: 1\n",
      "Processing row 2208 - Data Type: train, Message: Yes, I was also considering that. Implemented in this commit:\n",
      "https://github.com/datastax/java-driver/pull/1235/commits/95f96621ed26dab04a2bd7f7ce904be9ff9758a3\n",
      "I've added tests and `BOOLEAN` as a supporter return type. \n",
      "What is not clear to me how it was handled automatically - I thought that I will need to add mapping logic (from results set to BOOLEAN) but it worked out of the box.\n",
      "Could you tell me where is that mapping logic?, Label: 1\n",
      "Processing row 2209 - Data Type: train, Message: I am not sure if we should support `USING TTL ?` syntax in the `customUsingClause`. \n",
      "I think we don't need it since we are binding parameters from the method arguments using named parameters, Label: 1\n",
      "Processing row 2210 - Data Type: train, Message: I think you mean add a static builder() method?, Label: 1\n",
      "Processing row 2211 - Data Type: train, Message: I'm only using `Transient` here because that was what we used in 3.x., Label: 0\n",
      "Processing row 2212 - Data Type: train, Message: @olim7t should we handle primitive types?\n",
      "Primitive types cannot have null value so I think null handling strategy does not apply, Label: 1\n",
      "Processing row 2213 - Data Type: train, Message: Yes, I was also thinking about it but as Olivier mentioned - it is processed on a different level., Label: 0\n",
      "Processing row 2214 - Data Type: train, Message: Was a little easier to do that than i originally anticipated (6b24969), Label: 0\n",
      "Processing row 2215 - Data Type: train, Message: You mean just to validate that an exception is thrown if the user provided query does not match the expectation of what the result alias should be?, Label: 1\n",
      "Processing row 2216 - Data Type: train, Message: This is code responsible for finding out if the `nullSavingStrategy` value was explicitly set on the `@Update` annotation using `AnnotationMirror`. It looks a bit complex, @olim7t do you know if there is a way to create `ExecutableElement` using java-poet for the purpose of this test?, Label: 1\n",
      "Processing row 2217 - Data Type: train, Message: If we will set it to `null` we will still need to interpret is somehow for a case where \n",
      "`@DefaultNullSavingStrategy` on the `@Dao` level is not a set AND the method level `nullSavingStrategy` property for example on `@Update` will not be set. \n",
      "In such case that null needs to become `DO_NOT_SET` or `SET_TO_NULL`. I think that it is better to have that default logic embedded within the annotation default:\n",
      "`NullSavingStrategy nullSavingStrategy() default NullSavingStrategy.DO_NOT_SET;`\n",
      "instead of adding another case to handle when the value is null. \n",
      ", Label: 0\n",
      "Processing row 2218 - Data Type: train, Message: I am not sure if we want to apply cqlNameGenerator on the `defaultKeyspace`.\n",
      "If someone is adding explicit `@Entity(defaultKeyspace =\"a\")` I am hesitating about transforming it to other ks name using `cqlNameGenerator` in this case. @tolbertam @olim7t wdyt?, Label: 1\n",
      "Processing row 2219 - Data Type: train, Message: I think that the main question is: do we want to have parity between examples in nodejs and java. Currently, the nodejs example is doing it using ranges and existing java example does the same. I like @adutra example because is more java idiomatic but still there is a problem of throttling requests - if we will have unbounded `Queue` there could be an out of memory error.\n",
      "This line: \n",
      "```\n",
      "  for (int i = 0; i < TOTAL_NUMBER_OF_INSERTS; i++) {\n",
      "    statements.add(pst.bind().setUuid(\"id\", UUID.randomUUID()).setInt(\"value\", i));\n",
      "  }\n",
      "```\n",
      "still is not solving that problem of out of memory on statements.\n",
      " , Label: 0\n",
      "Processing row 2220 - Data Type: train, Message: @adutra Looking at your example I think that it is almost the same as existing: `LimitConcurrencyCustom`. Both are using `SEMAPHORE` to limit `IN_FLIGHT` and both are using     \n",
      "`ExecutorService executor = Executors.newFixedThreadPool(CONCURRENCY_LEVEL);` to limit number of concurrent requests. There is only one difference - in your example, you are using intermediate `Queue`.\n",
      "My suggestion is like this:\n",
      "- I can add a `Queue` to the `LimitConcurrencyCustom` example to make a clearer distinction between consumer and producer - this will be java idiomatic way OR add the 3rd example with a Queue.\n",
      "- keep `LimitConcurrencyCustomAsync` according to @jorgebay suggestion to also have an example that is showing the throttling of produced queries (and is one to one with `NodeJs` example).\n",
      "Wdyt?\n",
      ", Label: 0\n",
      "Processing row 2221 - Data Type: val, Message: Concerning `threads` I agree (changed).\n",
      "Concerning `insertCounter` I think it is beneficial to have that information in a log to see an actual number of inserts that succeeded.\n",
      "For `LimitConcurrencyRequestThrottler` we have `List<CompletableFuture<?>> pending ` list to get that info. Here to assert that all records were properly inserter we need some additional counter. (I moved the incrementing logic after the execute call)\n",
      "https://github.com/datastax/java-driver/pull/1256/commits/704ac8e626e00df0387d79fee52a70254c72c843\n",
      "wdyt?, Label: 0\n",
      "Processing row 2222 - Data Type: train, Message: I don't think that's the right way to distribute the tests. The attribute, attribute statement tests all leverage a specific configuration and setup in simulacron. Replicating this setup in the other various unit tests would be costly IMHO. , Label: 1\n",
      "Processing row 2223 - Data Type: train, Message: The statementAttributesParam should definitely override the Attributes set at compile time, provided they are being explictly set. As Olivier mentioned above right now we have  aproblem where the defaults of statementAttributesParam will override ones that are explictly set by Attributes, which is the real problem here.  \n",
      "\n",
      "\n",
      "Here is how I think it should work.\n",
      "1. Attributes are applied, if they aren't specific defaults are used.\n",
      "2. statementAttributes are applied... their defaults should not override Specific Attributes that are set. \n",
      ", Label: 0\n",
      "Processing row 2224 - Data Type: train, Message: This worked, it occurred to me to use The DeclaredType to match the TypeArguments of the function, but I didn't understand that isSame would would with the element but not with TypeMirror., Label: 1\n",
      "Processing row 2225 - Data Type: train, Message: This Could also be folded into the normal PlainTextAuthProvider if appropriate. That's what I did initially, but with the introduction of the PlainTextAuthProviderBase, it seemed appropriate to have a separate class., Label: 0\n",
      "Processing row 2226 - Data Type: train, Message: > Don't add those methods to EntityHelper\n",
      "\n",
      "You know, it didn't occur to me that generated code used the implementations instead of declaring things as `EntityHelper`.  In this case, there is no reason to add something to the interface, so I agree this seems like a good course of action.\n",
      "\n",
      "It looks like the only place (currently) that `EntityHelper` is used as an interface in other code is in `QueryProvider` and in `DaoBase`, where it's more used for setting/getting fields.\n",
      "\n",
      "Since this method is used for query generation, I suppose it's probably fine to not put directly in `EntityHelper`.\n",
      "\n",
      "But I do wonder if we should just consider removing all the query-generation based methods from `EntityHelper` now if we see no utility.  What do you think?, Label: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 2227 - Data Type: val, Message: That's right.  It's not legal to not provide the full primary key and use a custom if clause.\n",
      "\n",
      "So there's possibly the case where enough parameters are provided to fulfill the number of primary key parameters, but some of those parameters were meant for the custom if clause.  In this case it's likely it won't match the primary key definition and you'll get an error which explains that he parameters don't match the primary key, which is technically correct.  If they do somehow match, there's not much we can do at compile time (I think?).  In any case, you'll get an error at run time, which is similar to what would happen if you don't provide enough parameters to match the query bind markers., Label: 1\n",
      "Processing row 2228 - Data Type: train, Message: should we add `warn` for that case or fail-silently?, Label: 1\n",
      "Processing row 2229 - Data Type: train, Message: There were some failures of https://jenkins-drivers.build.dsinternal.org/job/datastax.java-driver.java2263_rebase.default/lastCompletedBuild/testReport/ `DefaultKeyspaceId`, it reported that the table is not present (it fails only on jenkins) I suspect that there is some kind of race condition in metadata and this is related to your comment:\n",
      ">keyspace name present but metadata is out of date\n",
      "\n",
      "I don't know how can we alleviate that problem - maybe we could refresh the schema explicitly?\n",
      "If not, I think the viable solution is to `log.warning`:\n",
      "`warn if there are is keyspace.table for defined entity - it means that table is missing, or schema it out of date.`\n",
      "instead of throwing an exception and fail fast if we cannot be sure if the schema was out-dated., Label: 1\n",
      "Processing row 2230 - Data Type: train, Message: There is a new method `Bytes.erase` since JAVA-2306, but I'm not sure if it's worth including it here since it's pretty trivial and I doubt it's very useful in terms of manipulating BLOB values., Label: 1\n",
      "Processing row 2231 - Data Type: train, Message: Yes, those cases will be handled correctly (and the last one is impossible indeed).\n",
      "\n",
      "Check out `DefaultEntityFactory` and `DaoImplementationGenerator`. In both cases, we get all the parent types as a flat structure. What matters is the class we are currently processing (`processedClass`), and the type where we are inheriting the member from (`declaringType`). How many types there are in between has no impact on the algorithm used here., Label: 1\n",
      "Processing row 2232 - Data Type: val, Message: I'm not sure, I just reused the KillrVideo data model as-is, and it's how they do it. Maybe they wanted to support legacy versions that don't have `date`., Label: 1\n",
      "Processing row 2233 - Data Type: train, Message: `TupleCodec` and `UdtCodec` already handle null values.\n",
      "\n",
      "UDT field names don't appear in the encoded representation. And there's no way they can ever be null anyway., Label: 0\n",
      "Processing row 2234 - Data Type: val, Message: Deprecating this constructor is the best way I've found to address the fact that it calls an overridable method. 3.x didn't have a way to pass user codecs to the constructor so I don't think it's a big deal to drop that., Label: 1\n",
      "Processing row 2235 - Data Type: train, Message: Unlike `CachingCodecRegistry`, I didn't preserve backward compatibility for this class's constructors. It's much less likely that someone extended it.\n",
      "\n",
      "One catch is that the last argument of `DefaultCodecRegistry(String, TypeCodec<?>[])` now corresponds to primitive codecs (vs. user codecs in 4.2.0). But if someone runs into that things will blow out pretty fast, there's no risk that it goes undetected., Label: 0\n",
      "Processing row 2236 - Data Type: train, Message: A unit test for a property setter on a builder is (arguably) overkill... especially since there was no existing test for other builder functionality.  That said, I had a pseudo-integration test for confirming that everything worked as expected.. so switching that over to a unit test was pretty trivial.\n",
      "\n",
      "I'm good with scrapping this if it's judged to be unnecessary, but it shouldn't be... harmful really., Label: 0\n",
      "Processing row 2237 - Data Type: train, Message: With the conversion of this test to the new constructor there are only a few integration tests continuing to use the old (deprecated) constructor.  I'm happy to change those tests to use the new constructor (and remove the old constructor entirely) as part of this PR if that's judged to be useful.... I don't have enough context to know if that's a Good Idea :tm: or not., Label: 1\n",
      "Processing row 2238 - Data Type: train, Message: You're thinking of... the built-in JUnit support for parameterized tests @tomekl007 ?  Yeah, I think that could be made to work... but there are some things I'm not super fond of there:\n",
      "\n",
      "* The reliance on test state (via either the constructor usage or injection) isn't super-awesome\n",
      "* The inability to mix and match parameterized vs. other tests in the same class seems problematic\n",
      "\n",
      "Seems like the only way to address that last problem would be to create a distinct test just for these two cases... and that seems like an increase in complexity.\n",
      "\n",
      "Or were you thinking of something more along the lines of https://github.com/Pragmatists/JUnitParams?  That addresses both concerns above with a much simpler API.  I could get behind that... is it a big issue to add that as another dep?, Label: 1\n",
      "Processing row 2239 - Data Type: train, Message: This is feeling more and more like a case for an enum.  There used to be such an enum in 3.x.... did we move away from that for a reason?, Label: 1\n",
      "Processing row 2240 - Data Type: train, Message: This is a holdover from the original impl.  Seems like there might be merit in explicitly providing something here even if the current impl of provides a sane default.  Either way, it seems like the usage here should match what we do for withLocalDatacenters() and withNodeFilters(); seems like we should rely on builder defaults for none or all three, does it not?, Label: 1\n",
      "Processing row 2241 - Data Type: train, Message: I don't have a strong opinion either way I guess.  I'm sympathetic to the argument for randomized testing (to potentially catch data-driven oddness).  I'm also sympathetic to the argument for predictable testing to catch regressions.\n",
      "\n",
      "If there's a preference for a fixed value here I can make that change as well., Label: 1\n",
      "Processing row 2242 - Data Type: train, Message: rv = return value.  I use it quite a bit in cases like this, although my preference would be to avoid the variable declaration all together and just return the result of the expression. That's pretty hard to do with a conditional application such as this, though., Label: 0\n",
      "Processing row 2243 - Data Type: train, Message: Sure, although the block syntax is common even throughout the existing code base.  I personally prefer it (I find the double-slash syntax visually very distracting) but I don't care enough to go to the mat for it., Label: 0\n",
      "Processing row 2244 - Data Type: train, Message: I am not sure about the keyspace actually. It was said at some point that users would have access to just one keyspace. Not sure if this is valid still. But it doesn't hurt to specify a keyspace anyways, so I would leave it that way. @emerkle826 do you know by chance if a keyspace is required for cloud?, Label: 1\n",
      "Processing row 2245 - Data Type: train, Message: The event received is now DOWN because of the changes in the NodeRefreshRequestDeliveryCallback logic. I don't know how to fix it., Label: 1\n",
      "Processing row 2246 - Data Type: train, Message: That makes sense, since the primary goal of this feature it to give you the bound statement to do what you will with it later. It's just a bonus that you can also use conditionals etc too if you choose. With how it's documented now it's slightly confusing in that you could only use this if you where using a conditional., Label: 0\n",
      "Processing row 2247 - Data Type: train, Message: Compatibility with Netty < 4.1.7 is much trickier, so I preferred to stop here., Label: 0\n",
      "Processing row 2248 - Data Type: train, Message: You mean, create a utility class exposing a static method `PromiseCombiner newPromiseCombiner()`? I think I disagree with you for two reasons: 1) the creation of that utility class requires the same amount of lines of code than the current situation so it doesn't bring concision; and 2) I bet we would forget to use this utility class and keep instantiating `PromiseCombiner` by simply doing `new PromiseCombiner()`..., Label: 1\n",
      "Processing row 2249 - Data Type: train, Message: Not wrapping the cause in an `ExecutionException` because `Promise.get()`  already does so., Label: 0\n",
      "Processing row 2250 - Data Type: train, Message: Hrmm not sure if I follow, the boolean is flipped only once at the end of init, how could it prevent double delivery?, Label: 1\n",
      "Processing row 2251 - Data Type: val, Message: Do you want me to create a new ticket for this, or address it in this PR?, Label: 1\n",
      "Processing row 2252 - Data Type: train, Message: I'm following the established pattern of proposing 2 constants and 1 method for groups of related timestamp codecs:\n",
      "\n",
      "1. Constant for system default zone: `FOO_SYSTEM`\n",
      "2. Constant for UTC: `FOO_UTC`\n",
      "3. Factory method for other zones: `fooAt`\n",
      "\n",
      "Following this logic the constant `TIMESTAMP` should have been named `TIMESTAMP_SYSTEM` but it's too late for that., Label: 1\n",
      "Processing row 2253 - Data Type: train, Message: I find it a bit disappointing that javadocs for codecs are not published. They contain very valuable information. Don't you think we should start publishing javadocs for internal classes as well?, Label: 1\n",
      "Processing row 2254 - Data Type: train, Message: I find it a bit disappointing because moving this to the examples module would require users to copy-paste code. I would like to see something more straightforward. I'm tempted to re-introduce the \"extras\" module for everything related to Json., Label: 0\n",
      "Processing row 2255 - Data Type: train, Message: I'm proposing one single `JsonCodec` using Jackson. I think this will satisfy 90% of the users. I therefore removed the `JacksonJsonCodec` classes from the query-builder and examples modules, and made these modules use this one instead.\n",
      "\n",
      "The examples module has another Json codec using JSR-353. I left that codec there because 1) I think there is no real demand for that and 2) it drags a lot of new dependencies., Label: 0\n",
      "Processing row 2256 - Data Type: train, Message: Moved this codec here since he was alone in its old package and there was no reason why we wouldn't include it here along with the examples that use it., Label: 0\n",
      "Processing row 2257 - Data Type: val, Message: But we already provided this in driver 3.x, do you think we should remove this functionality then?, Label: 1\n",
      "Processing row 2258 - Data Type: train, Message: @olim7t I'm overall ðŸ‘ on the new class but why did you change the name of this field and not the others below?, Label: 1\n",
      "Processing row 2259 - Data Type: train, Message: typo, Label: 0\n",
      "Processing row 2260 - Data Type: train, Message: I renamed a few private variables:\n",
      "`READ_REPAIR` to `READ_REPAIR_CHANCE`\n",
      "`DCLOCAL_READ_REPAIR` to `DCLOCAL_READ_REPAIR_CHANCE`\n",
      "`LOCAL_READ_REPAIR` to `LOCAL_READ_REPAIR_CHANCE`\n",
      "so that I could introduce `READ_REPAIR`.\n",
      "\n",
      "Luckily the public access methods were already `getXYZchance()`, Label: 0\n",
      "Processing row 2261 - Data Type: train, Message: Actually, I intended \"here\" to not be part of the link, but either way I've got it twice which was not the intent., Label: 0\n",
      "Processing row 2262 - Data Type: train, Message: There's a _slight_ difference in behaviour from the old impl here.  We've moved both calls into the jnr-posix orbit but don't maintain discrete vals for the validation of each discrete call; we just validate the whole thing by confirming that we can call _both_ native functions.  Logically this means that we could find ourselves in a situation where getpid() succeeded but gettimeofday() didn't, and in that case we'd prevent users from subsequent calls to _either_ syscall when (in theory) we could allow them to call getpid() and just throw on gettimeofday() calls.\n",
      "\n",
      "Note that gettimeofday() \"failing\" above means throwing an exception (i.e.a failure in the Java infrastructure) not just a non-zero return val (which indicates that the syscall was made and something went wrong within the kernel).\n",
      "\n",
      "I kinda like this idea even in the abstract; if we can't validate that your POSIX instance can do _everything_ we expect it's in an untrustworthy state and we don't allow you to do anything.  More practically, it seems _extremely_ unlikely that we'd get a Java exception with one syscall but not another; the whole point of POSIX is that we expect syscalls with these names and params to be available.  If one is there and another isn't we've got some kind of very odd libc we shouldn't trust much anyway., Label: 0\n",
      "Processing row 2263 - Data Type: val, Message: Because OptionalLong and OptionalInt do not subclass Optional; they are their own type hierarchy.  As a result the map/flatMap ops off Optional<POSIX> can't generate these types., Label: 0\n",
      "Processing row 2264 - Data Type: train, Message: One more thing I hadn't caught previously: it's easier to do this in `DaoBase`., Label: 0\n",
      "Processing row 2265 - Data Type: train, Message: This is not strictly necessary; the try/catch block below will catch the NPE in cases where stateTypeCodec is null from deserialization.  I added the explicit case here only to avoid adding messages at WARN to the logging infrastructure... DEBUG seemed like a more reasonable level for this (admittedly probably rare in practice) case., Label: 0\n",
      "Processing row 2266 - Data Type: train, Message: Looks like it's Gremlin's fault:\n",
      "\n",
      "```\n",
      "[INFO] +- org.apache.tinkerpop:gremlin-core:jar:3.4.5:compile\n",
      "[INFO] |  +- org.apache.tinkerpop:gremlin-shaded:jar:3.4.5:compile\n",
      "[INFO] |  +- commons-configuration:commons-configuration:jar:1.10:compile\n",
      "[INFO] |  |  \\- commons-lang:commons-lang:jar:2.6:compile\n",
      "[INFO] |  +- commons-collections:commons-collections:jar:3.2.2:compile\n",
      "[INFO] |  +- org.apache.commons:commons-lang3:jar:3.8.1:compile\n",
      "[INFO] |  +- org.yaml:snakeyaml:jar:1.15:compile\n",
      "[INFO] |  +- com.carrotsearch:hppc:jar:0.7.1:compile\n",
      "[INFO] |  +- com.jcabi:jcabi-manifests:jar:1.1:compile\n",
      "[INFO] |  |  \\- com.jcabi:jcabi-log:jar:0.14:compile\n",
      "[INFO] |  +- com.squareup:javapoet:jar:1.11.1:compile\n",
      "[INFO] |  +- net.objecthunter:exp4j:jar:0.4.8:compile\n",
      "[INFO] |  \\- org.slf4j:jcl-over-slf4j:jar:1.7.25:compile\n",
      "```\n",
      "\n",
      "I love that the same artifact brings in both commons-lang2 (via a transitive dep) and commons-lang3 directly. :rage: , Label: 0\n",
      "Processing row 2267 - Data Type: val, Message: It shouldn't result in incomplete classpath errors, but you do raise an interesting point @tomekl007 ... it's quite possible my sample app isn't doing build-time initialization of any of the native classes.  Which means we might not be exercising everything we need for testing here.\n",
      "\n",
      "Yup, looks like that might be the case.  Quarkus does apparently trigger build-time init of these classes (via Uuids) which leads us to the following:\n",
      "\n",
      "```\n",
      "Error: Class initialization of com.datastax.oss.driver.api.core.uuid.Uuids failed. Use the option --initialize-at-run-time=com.datastax.oss.driver.api.core.uuid.Uuids to explicit\n",
      "ly request delayed initialization of this class.                                                                                                    \n",
      "Detailed message:                                                      \n",
      "                                                                                                \n",
      "com.oracle.svm.core.util.UserError$UserException: Class initialization of com.datastax.oss.driver.api.core.uuid.Uuids failed. Use the option --initialize-at-run-time=com.datastax\n",
      ".oss.driver.api.core.uuid.Uuids to explicitly request delayed initialization of this class. \n",
      "Detailed message:                                                                                  \n",
      "                                                                                              \n",
      "        at com.oracle.svm.core.util.UserError.abort(UserError.java:75)                     \n",
      "        at com.oracle.svm.hosted.FallbackFeature.reportAsFallback(FallbackFeature.java:221)                                                                                               at com.oracle.svm.hosted.NativeImageGenerator.runPointsToAnalysis(NativeImageGenerator.java:736)\n",
      "        at com.oracle.svm.hosted.NativeImageGenerator.doRun(NativeImageGenerator.java:530)                                                                                       \n",
      "        at com.oracle.svm.hosted.NativeImageGenerator.lambda$run$0(NativeImageGenerator.java:445)                                                                                \n",
      "        at java.util.concurrent.ForkJoinTask$AdaptedRunnableAction.exec(ForkJoinTask.java:1386)                   \n",
      "        at java.util.concurrent.ForkJoinTask.doExec(ForkJoinTask.java:289)                                                                                                       \n",
      "        at java.util.concurrent.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:1056)                                                                                           \n",
      "        at java.util.concurrent.ForkJoinPool.runWorker(ForkJoinPool.java:1692)               \n",
      "        at java.util.concurrent.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:157)                                                                                          \n",
      "Caused by: com.oracle.graal.pointsto.constraints.UnsupportedFeatureException: Class initialization of com.datastax.oss.driver.api.core.uuid.Uuids failed. Use the option --initial\n",
      "ize-at-run-time=com.datastax.oss.driver.api.core.uuid.Uuids to explicitly request delayed initialization of this class.                                                          \n",
      "Detailed message:                                                                                                                                                                \n",
      "                                                                                                                                                                                 \n",
      "        at com.oracle.graal.pointsto.constraints.UnsupportedFeatures.report(UnsupportedFeatures.java:126)                                                                        \n",
      "        at com.oracle.svm.hosted.NativeImageGenerator.runPointsToAnalysis(NativeImageGenerator.java:733)\n",
      "        ... 7 more                                                        \n",
      "Caused by: java.lang.UnsatisfiedLinkError: com.datastax.oss.driver.internal.core.os.GraalGetpid.getpid()I\n",
      "        at com.datastax.oss.driver.internal.core.os.GraalGetpid.getpid(Native Method)                                                                                            \n",
      "        at com.datastax.oss.driver.internal.core.os.GraalLibc.getpid(GraalLibc.java:36)                                                                                          \n",
      "        at com.datastax.oss.driver.internal.core.os.Native.getProcessId(Native.java:82)  \n",
      "        at com.datastax.oss.driver.api.core.uuid.Uuids.getProcessPiece(Uuids.java:193)        \n",
      "        at com.datastax.oss.driver.api.core.uuid.Uuids.makeNode(Uuids.java:163)             \n",
      "        at com.datastax.oss.driver.api.core.uuid.Uuids.makeClockSeqAndNode(Uuids.java:226)                                              \n",
      "        at com.datastax.oss.driver.api.core.uuid.Uuids.<clinit>(Uuids.java:116)      \n",
      "        at sun.misc.Unsafe.ensureClassInitialized(Native Method)            \n",
      "...\n",
      "```\n",
      "\n",
      "Looks like Uuids attempt to get at the PID is leading to a build-time attempt to access the native code which likely isn't available yet.\n",
      "\n",
      "I've got an idea for how to work around this, need to do some more testing., Label: 0\n",
      "Processing row 2268 - Data Type: train, Message: I was considering adding a config option that would allow the user to disable this functionality even for Graal VM apps if they desired.  A user might want to do something like this if they don't want to install the LLVM toolchain for some reason (I'm not sure why that would be an issue but let's assume it is) or they don't want to rely on a newer feature.\n",
      "\n",
      "Is this worthwhile?  I can see pretty clear arguments for and against... and the more I think about it the more it seems like it might not be worth it., Label: 1\n",
      "Processing row 2269 - Data Type: train, Message: I was pondering adding a warning in the javadocs.\n",
      "\n",
      "The feature works and I think it's good to have for completeness, but still it feels pretty convoluted., Label: 0\n",
      "Processing row 2270 - Data Type: train, Message: I guess it's a matter of interpretation, but the way I see it is that if something has dynamic parts and static parts, then the thing as a whole is still dynamic. Kind of like a dynamic web page, you wouldn't instruct the browser to cache it indefinitely because some of the resources are static., Label: 1\n",
      "Processing row 2271 - Data Type: train, Message: The client should not register a `MutinyMappedReactiveResultSet<Fruit>`, but instead a producer that can handle a reactive result set of _any entity_. See `CustomResultTypeIT.SingleEntityListenableFutureProducer` for an example.\n",
      "\n",
      "The idea is that we would provide those Mutiny producers out of the box with the Quarkus extension, users should not have to implement them.\n",
      "\n",
      "PS:  There's not any good way to make the interface generic, and at the end of the day it all happens at runtime anyway, there would always be an unchecked cast somewhere., Label: 0\n",
      "Processing row 2272 - Data Type: train, Message: I was meant as \"a result produced by the mapper\".\n",
      "Maybe `MapperResultProducer` would be a better name. I'll give it more thought, I wasn't completely satisfied with naming., Label: 1\n",
      "Processing row 2273 - Data Type: train, Message: The order is not formally defined by the `ServiceLoader` javadocs.\n",
      "\n",
      "In practice, the Oracle JDK implementation parses the lines and puts them in a list, so they come out in the original order. But to play devil's advocate, it's not unrealistic to imagine another implementation that would use a hash set in order to eliminate duplicates (which are supposed to be skipped). \n",
      "\n",
      "So just to err on the safe side I think it's better to keep the top-level service interface, it doesn't add much complexity., Label: 0\n",
      "Processing row 2274 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2275 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2276 - Data Type: train, Message: `buildDefaultSessionAsync` is final, but I don't see why it should be; and making this method final would make revapi angry., Label: 1\n",
      "Processing row 2277 - Data Type: train, Message: Agreed, my brain was in \"exception message\" mode, but we don't have a stacktrace for that log., Label: 0\n",
      "Processing row 2278 - Data Type: train, Message: I think at one point I was also referencing Micrometer's `Metrics` class and already had that imported. So one of them was going to need to be fully qualified. It doesn't look like I am referencing Micrometer's class any more, so I can change this now., Label: 1\n",
      "Processing row 2279 - Data Type: val, Message: This was just the pattern I followed from what we did with the quarkus extension. I can remove it. Just to clarify, removing this would result in metrics paths going from something like:\n",
      "```\n",
      "cassandra.s0.cql-requests\n",
      "```\n",
      "to something like:\n",
      "```\n",
      "s0.cql-requests\n",
      "```, Label: 0\n",
      "Processing row 2280 - Data Type: train, Message: It is to the extent that a user application can override the Session name. But this implementation is just a fixed static prefix of \"cassandra\"., Label: 0\n",
      "Processing row 2281 - Data Type: train, Message: It is a bit problematic for contact points because it fails with:\n",
      "```\n",
      " Multiple entries with same key: default=dc1 and default=dc-ignored\n",
      "```\n",
      "It is using the \n",
      "`\n",
      "private ImmutableMap.Builder<String, String> localDatacentersBuilder = ImmutableMap.builder();\n",
      "`\n",
      "underneath and it does not support removing. Are we ok with changing this?, Label: 1\n",
      "Processing row 2282 - Data Type: train, Message: nice, thx, Label: 0\n",
      "Processing row 2283 - Data Type: val, Message: This prop was set in a few other Fallout runs using Timeseries_(Read|Write) so I preserved it here for sake of continuity.  I don't think it's required by any means., Label: 0\n",
      "Processing row 2284 - Data Type: train, Message: That was actually my first version of this snippet :-) But the implementations felt clumsy to me as both would start with a `if (dse) return false;` statement that seemed disconnected from the rest. Anyways, it doesn't matter much, there is no version of DSE as of today that support these config options., Label: 0\n",
      "Processing row 2285 - Data Type: train, Message: The implementation does not need a fully-qualified classname for implementations that exist in `com.datastax.oss.driver.internal.core.metrics`. Remove `fully-qualified` from the javadoc., Label: 0\n",
      "Processing row 2286 - Data Type: val, Message: Will do!, Label: 0\n",
      "Processing row 2287 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2288 - Data Type: val, Message: I need it because those two lines don't work for my test case\n",
      "```\n",
      "mainSubscriber.awaitTermination();\n",
      "assertThat(mainSubscriber.getError()).isNull();\n",
      "```\n",
      "\n",
      "`mainSubscriber.awaitTermination()` does not throw any exception if after timeout there is still data in publisher.  In this regard, the question, is it correct behaviour that `mainSubscriber.awaitTermination()` does not throw exception after timeout ?\n",
      "\n",
      ", Label: 1\n",
      "Processing row 2289 - Data Type: train, Message: It is all implemented by MapMakerInternalMap, cannot just the value is weak or strong references., Label: 0\n",
      "Processing row 2290 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2291 - Data Type: train, Message: This and the similar change below address some minor fallout from https://github.com/datastax/java-driver/pull/1571, Label: 0\n",
      "Processing row 2292 - Data Type: train, Message: State object + builder is a bit more convoluted than I'd like but it has the effect of nicely isolating changes required for an individual test.  Without this class I found myself passing around multiple config options (all of which were either related or similar to each other) in order to setup a given test.  Introducing this class had the effect of making the intent of a single test case above very clear., Label: 0\n",
      "Processing row 2293 - Data Type: train, Message: This is also a holdover that prolly doesn't make sense anymore.  The third bit originally referred to system.local, but as discussed above we have to _always_ prime system.local now.\n",
      "\n",
      "It also probably does make sense to just switch to booleans now.  With three vals it seemed worth encapsulating everything in a single data structure... but by the time you add in static flags for each name the benefit is somewhat lost., Label: 0\n",
      "Processing row 2294 - Data Type: train, Message: We have checks around the [encode](https://github.com/datastax/java-driver/blob/cep-vsearch/core/src/test/java/com/datastax/oss/driver/internal/core/type/codec/CqlVectorCodecTest.java#L43) and [decode](https://github.com/datastax/java-driver/blob/cep-vsearch/core/src/test/java/com/datastax/oss/driver/internal/core/type/codec/CqlVectorCodecTest.java#L50) functions for null values.  Were you thinking of something else here?, Label: 1\n",
      "Processing row 2295 - Data Type: train, Message: Note that encode/decode above represent something of a compromise.  There's no correlation between the number of floats we try to read or write and the number that are actually expected according to the type.  We do extract the expected number of dimensions for a given vector and we do store it in a CqlVectorType instance but that information isn't available to the encode/decode impls above.  This isn't a huge surprise; in the past parameterized types have been used exclusively to indicate subtypes, not meta-information about a type.\n",
      "\n",
      "The really robust answer is probably to expand this API so that the underlying type is provided to encode() and decode().  In most cases that type will be ignored, but in this case we'd use it to see how many floats we should expect to read and write.  In the interest of time I avoided this larger-scale refactoring and settled on the compromise above.  I'm open to a follow-up ticket which would do things the right way., Label: 0\n",
      "Processing row 2296 - Data Type: train, Message: I tried this, but the generic parameter broke it, as there is no bound on T which makes it a CharSequence. , Label: 0\n",
      "Processing row 2297 - Data Type: train, Message: noted, Label: 0\n",
      "Processing row 2298 - Data Type: train, Message: Bringing default Cassandra version used in testing to be same 4.0 one used by Jenkins.\n",
      "\n",
      "This is why this test passed locally but not in 4.0/3.11 in Jenkins.\n",
      "\n",
      "Happy to remove if this change is too disruptive., Label: 0\n",
      "Processing row 2299 - Data Type: train, Message: It should indeed... good catch @hhughes!, Label: 0\n",
      "Processing row 2300 - Data Type: train, Message: Yup, this one too!, Label: 0\n",
      "Processing row 2301 - Data Type: train, Message: I'm not super-happy with the way this language came out.  If anybody has any suggestions on a way to say all this in something that sounds more like English I'm all ears., Label: 0\n",
      "Processing row 2302 - Data Type: train, Message: Eventually yes, but for now the code isn't released in any Cassandra or DSE version.  It will be available in Astra but nowhere else yet.\n",
      "\n",
      "So eventually yeah, we'll prolly need to add more detailed information regarding dependencies... but I don't think we're there yet., Label: 1\n",
      "Processing row 2303 - Data Type: train, Message: It's not strictly necessary.  I added it here to show that v implements Iterable and can be used in anything expecting that interface.  The other obvious way to do that was to iterate over it in a for loop but it wasn't clear to me that that would be a useful exercise for a vector., Label: 0\n",
      "Processing row 2304 - Data Type: train, Message:  Yes. because too many metrics, none of the walmart teams are enabled the metrics.\n",
      "As i understand correctly, you would like two config one for \"publish local percentiles\" and another one for \"\"publish aggregable histogram\"\n",
      "i am ok to that.. correct me if I am wrong.\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2305 - Data Type: train, Message: Another general clarification i would like to see that is this going to be merged before handing to over apache foundation?, Label: 1\n",
      "Processing row 2306 - Data Type: train, Message: removed boxing, Label: 0\n",
      "Processing row 2307 - Data Type: train, Message: Dito, Label: 0\n",
      "Processing row 2308 - Data Type: train, Message: missing `final`, Label: 0\n",
      "Processing row 2309 - Data Type: train, Message: missing `static final`, Label: 0\n",
      "Processing row 2310 - Data Type: train, Message: Looked into the interface but it seems, that slf4j doesn't have it , Label: 1\n",
      "Processing row 2311 - Data Type: train, Message: This view is outdated., Label: 1\n",
      "Processing row 2312 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2313 - Data Type: train, Message: ok, change to UNKNOWN, Label: 0\n",
      "Processing row 2314 - Data Type: train, Message: ok, change to UNKNOWN, Label: 0\n",
      "Processing row 2315 - Data Type: train, Message: ok, change to UNKNOWN, Label: 0\n",
      "Processing row 2316 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2317 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2318 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2319 - Data Type: train, Message: no need, Label: 0\n",
      "Processing row 2320 - Data Type: val, Message: Moved, Label: 0\n",
      "Processing row 2321 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2322 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 2323 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2324 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2325 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2326 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2327 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2328 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2329 - Data Type: train, Message: ok , Label: 0\n",
      "Processing row 2330 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2331 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2332 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2333 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2334 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2335 - Data Type: train, Message: My bad, forget to change this one, Label: 0\n",
      "Processing row 2336 - Data Type: train, Message: I have to restore into extrParam, and this fieldInfo is needed because I don't want to relate this module to Moudle-Dao to use sink_field directly, Label: 0\n",
      "Processing row 2337 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 2338 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2339 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2340 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2341 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2342 - Data Type: train, Message: comment error, Label: 0\n",
      "Processing row 2343 - Data Type: val, Message: clickhouse don's support upsert, jdbc relay on primary key to support upsertï¼Œso here we should not define clickhouse table a primary key., Label: 0\n",
      "Processing row 2344 - Data Type: train, Message: not necessary, groupStatus will influence stream operate and inverse not;, Label: 0\n",
      "Processing row 2345 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2346 - Data Type: val, Message: > Can regular matching be used here?\n",
      "\n",
      "There is more info on this on the [PR1678](https://github.com/apache/infrastructure-puppet/pull/1678) that implemented this cool feature. The regular matching is not supported now., Label: 1\n",
      "Processing row 2347 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2348 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2349 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2350 - Data Type: train, Message: The main reason is that the e.getMessage() method cannot see the abnormal link, and the abnormal information is not enough., Label: 1\n",
      "Processing row 2351 - Data Type: train, Message: resolve, Label: 0\n",
      "Processing row 2352 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2353 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2354 - Data Type: train, Message: resolve, Label: 0\n",
      "Processing row 2355 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2356 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2357 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2358 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2359 - Data Type: train, Message: doone, Label: 0\n",
      "Processing row 2360 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2361 - Data Type: train, Message: i don't know.It delete it and add it but in fact nothing has changed. should i force push it?, Label: 1\n",
      "Processing row 2362 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2363 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2364 - Data Type: val, Message: resolve, Label: 0\n",
      "Processing row 2365 - Data Type: val, Message: resolve, Label: 0\n",
      "Processing row 2366 - Data Type: train, Message: resolve, Label: 0\n",
      "Processing row 2367 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2368 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2369 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2370 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2371 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2372 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2373 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2374 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2375 - Data Type: train, Message: DONE, Label: 0\n",
      "Processing row 2376 - Data Type: train, Message: DONE, Label: 0\n",
      "Processing row 2377 - Data Type: train, Message: the default value for inlong-es-connector , Label: 0\n",
      "Processing row 2378 - Data Type: train, Message: @gong OK, Label: 0\n",
      "Processing row 2379 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2380 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2381 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2382 - Data Type: val, Message: fixed, thx, Label: 0\n",
      "Processing row 2383 - Data Type: val, Message: fix it, Label: 0\n",
      "Processing row 2384 - Data Type: train, Message: fix it, Label: 0\n",
      "Processing row 2385 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2386 - Data Type: val, Message: Removed., Label: 0\n",
      "Processing row 2387 - Data Type: train, Message: \n",
      "Preconditions currently use the Guava library. There is no checknotEmpty method, so I can only change it like this:\n",
      "```\n",
      "Preconditions.checkArgument(StringUtils.isNotEmpty(scanSpecificOffsets), \"scanSpecificOffsets is empty\");\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 2388 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2389 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2390 - Data Type: train, Message: sorry, foget to uncomment it., Label: 0\n",
      "Processing row 2391 - Data Type: train, Message: Thanks for your review, I have fixed it. :D, Label: 0\n",
      "Processing row 2392 - Data Type: train, Message: But this init() method is not AgentMetricSingleton, but the AgentMetricHandler class\n",
      "However, the init() here is a bit redundant and can also be removed, Label: 0\n",
      "Processing row 2393 - Data Type: train, Message: has been deleted, Label: 0\n",
      "Processing row 2394 - Data Type: train, Message: There are several modes for prometheus registration, such as collector and Gauge. The agent used Gauge before. There are registrations under AgentPrometheusMetricHandler.\n",
      "<img width=\"456\" alt=\"ä¼ä¸šå¾®ä¿¡æˆªå›¾_56982797-03c4-434f-9640-b0a8252d4910\" src=\"https://user-images.githubusercontent.com/20356765/182146332-bc8b622e-9c5e-4aa4-aedc-a3af15589d77.png\">\n",
      "<img width=\"624\" alt=\"ä¼ä¸šå¾®ä¿¡æˆªå›¾_5fb68c05-359f-412e-aeac-f187d00483a3\" src=\"https://user-images.githubusercontent.com/20356765/182146348-51752520-dd6a-406d-a33e-de57f9ef7191.png\">\n",
      ", Label: 0\n",
      "Processing row 2395 - Data Type: train, Message: has been deleted, Label: 0\n",
      "Processing row 2396 - Data Type: train, Message: It was added at the beginning, but the checkstyle is abnormal\n",
      "![image](https://user-images.githubusercontent.com/20356765/182333107-82942099-3a8c-465f-b0a1-b0449d90f760.png)\n",
      ", Label: 0\n",
      "Processing row 2397 - Data Type: train, Message: not necessary, Label: 0\n",
      "Processing row 2398 - Data Type: train, Message: not necessary, Label: 0\n",
      "Processing row 2399 - Data Type: train, Message: i personally wouldn't, Label: 0\n",
      "Processing row 2400 - Data Type: train, Message: JsonTypeDefine is used in child class, this is used in parent class, what do you mean?, Label: 1\n",
      "Processing row 2401 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2402 - Data Type: train, Message: OK, fixed, Label: 0\n",
      "Processing row 2403 - Data Type: val, Message: OK, fixed, Label: 0\n",
      "Processing row 2404 - Data Type: train, Message: I see that most Test class without Java doc, do I need to add Java doc in test class?\n",
      ", Label: 0\n",
      "Processing row 2405 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2406 - Data Type: train, Message: modify JosonUtils, Label: 0\n",
      "Processing row 2407 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2408 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2409 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2410 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2411 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2412 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2413 - Data Type: train, Message: What does the original file look like? I don't know where it's moved, I don't want to change it, Label: 1\n",
      "Processing row 2414 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2415 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2416 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2417 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2418 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2419 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2420 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2421 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2422 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2423 - Data Type: train, Message: Get it., Label: 0\n",
      "Processing row 2424 - Data Type: val, Message: fixed, thx, Label: 0\n",
      "Processing row 2425 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2426 - Data Type: train, Message: has moved, Label: 0\n",
      "Processing row 2427 - Data Type: val, Message: changed, Label: 0\n",
      "Processing row 2428 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 2429 - Data Type: train, Message: topicname is a nonnull parameter, so this must not be null, Label: 0\n",
      "Processing row 2430 - Data Type: val, Message: PowerMock will interfere with the execution of the local test method testSQLServerReader. In the TestSQLServerReader class, AgentDbUtils  is mocked class. It cannot really connect to the SQLServer database., Label: 0\n",
      "Processing row 2431 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2432 - Data Type: train, Message: You mean ` @GetMapping(value = \"/group/listTopics/{clusterTag}\")` ?\n",
      "Maybe it will be confused with the method to list all topics by groupId?, Label: 1\n",
      "Processing row 2433 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2434 - Data Type: train, Message: No, it doesn't., Label: 1\n",
      "Processing row 2435 - Data Type: train, Message: done , Label: 0\n",
      "Processing row 2436 - Data Type: train, Message: Agree, Label: 0\n",
      "Processing row 2437 - Data Type: train, Message: Agree, Label: 0\n",
      "Processing row 2438 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 2439 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2440 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 2441 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2442 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2443 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 2444 - Data Type: train, Message: This is an exception of PulsarAdmin, not all of them are displayed on this change page, Label: 1\n",
      "Processing row 2445 - Data Type: train, Message: This doesn't need to be set, it doesn't get thrown out., Label: 0\n",
      "Processing row 2446 - Data Type: val, Message: removed, Label: 0\n",
      "Processing row 2447 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2448 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2449 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2450 - Data Type: train, Message: Fix., Label: 0\n",
      "Processing row 2451 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2452 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2453 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2454 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2455 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2456 - Data Type: val, Message: > Where are these cluster types used?\n",
      "\n",
      "used in this place\n",
      "![image](https://github.com/apache/inlong/assets/88174078/b85aa113-21cf-4e69-b9d6-7a089ef74946)\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2457 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2458 - Data Type: val, Message: > Why not just call it `NodeFactory`, or `NodeProvider`? Producer more likes a concept in MQ.\n",
      "\n",
      "\n",
      "It has been modified, Label: 1\n",
      "Processing row 2459 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2460 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2461 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2462 - Data Type: train, Message: no need, fix it  , Label: 0\n",
      "Processing row 2463 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2464 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2465 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2466 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2467 - Data Type: val, Message: fixed, thx, Label: 0\n",
      "Processing row 2468 - Data Type: train, Message: fixed, thx, Label: 0\n",
      "Processing row 2469 - Data Type: val, Message: fixed, thx, Label: 0\n",
      "Processing row 2470 - Data Type: train, Message: create a new issue to fix it, Label: 0\n",
      "Processing row 2471 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2472 - Data Type: train, Message: Whooops... it can be thrown away, goot catch ðŸ‘ , Label: 0\n",
      "Processing row 2473 - Data Type: val, Message: According to below [1], still like to delete?, Label: 1\n",
      "Processing row 2474 - Data Type: train, Message: ðŸ‘ thank you!, Label: 0\n",
      "Processing row 2475 - Data Type: train, Message: Yes I see but it seems your above mechanism works in core only. I could not make it works:\n",
      "With `@Inject(JSONConstants.JSON_WRITER)` I always get:\n",
      "```text\n",
      "No mapping found for dependency [type=org.apache.struts2.json.JSONWriter, name='struts.json.writer'] in public void org.apache.struts2.json.JSONUtil.setWriter(org.apache.struts2.json.JSONWriter).\n",
      "```\n",
      "independent to have or not have `<constant name=\"struts.json.writer\" value=\"?\" />`.\n",
      "\n",
      "Without that but with name `struts` I get same message but looks for name `default`. With name `default` it works but I then could not override DefaultJSONWriter :)\n",
      "\n",
      "I learnt my previous mechanism from convention plugin. If you have no idea about above errors? then I can keep it as is., Label: 0\n",
      "Processing row 2476 - Data Type: train, Message: This is a fix for that issue which I discussed at [dev list](https://www.mail-archive.com/dev@struts.apache.org/msg43544.html). I suspected it should be wrong because this `else if` then does not require ` || tc.rule() == ConversionRule.KEY || tc.rule() == ConversionRule.COLLECTION` because it's always true when `tc.rule() != ConversionRule.ELEMENT`! Also, this `else if` was handling all `tc.rule() != ConversionRule.ELEMENT` and execution never reached it's next else if, `tc.rule() == ConversionRule.KEY`.\n",
      "\n",
      "So i asked at dev list and your reply directed me that this code is copied from [DefaultConversionFileProcessor.java#78](https://github.com/apache/struts/blob/29b29a9c64aa4700b0f3c52f250ef27a9dc67516/core/src/main/java/com/opensymphony/xwork2/conversion/impl/DefaultConversionFileProcessor.java#L78). Please see there that a NOT is applied to all statement but the copier of code removed the NOT but did not applied on all but only on first. This is that second issue which is fixed here side by side WW-4906 :), Label: 0\n",
      "Processing row 2477 - Data Type: train, Message: I afraid if user e.g. has a spring bean with name \"java.lang.String\" but with another type than string. In such cases, `converterCreator.createTypeConverter(\"java.lang.String\")` and `converterCreator.createTypeConverter(java.lang.String.class)` will have different results :), Label: 0\n",
      "Processing row 2478 - Data Type: train, Message: Thanks! You're right. Please replace `java.lang.String` with `com.opensymphony.xwork2.conversion.TypeConverter` in my above comment. This is an odd thing :) but please consider a spring bean with name `\"com.opensymphony.xwork2.conversion.TypeConverter\"` and that bean type is `me.yasser.MyTypeConverter`. In such case,  `converterCreator.createTypeConverter(\"com.opensymphony.xwork2.conversion.TypeConverter\")` and `converterCreator.createTypeConverter(com.opensymphony.xwork2.conversion.TypeConverter.class)` will have different results.\n",
      "\n",
      "At bottom, I think this was not working already before these and previous changes. Because [DefaultObjectTypeDeterminer.getKeyClass](https://github.com/apache/struts/blob/6e96f11debc4fa52c65a12b28fea82b514b96abd/core/src/main/java/com/opensymphony/xwork2/conversion/impl/DefaultObjectTypeDeterminer.java#L96) always casts it to `Class` and will fail at this case when it's `TypeConverter`., Label: 0\n",
      "Processing row 2479 - Data Type: train, Message: if i add the Default.class to the default value in the Annotation (ValidationGroup), it becomes a depencies to the javax.validation package. Is this a good practise?, Label: 1\n",
      "Processing row 2480 - Data Type: val, Message: facepalm :-), Label: 0\n",
      "Processing row 2481 - Data Type: train, Message: I think that's good, calling this function in `Object` is a bad idea anyway., Label: 0\n",
      "Processing row 2482 - Data Type: train, Message: `findAnnotations` does not return `null` also I don't want to scan above `Object` as it doesn't make sense, Label: 0\n",
      "Processing row 2483 - Data Type: train, Message: > the my fix\n",
      "\n",
      "Did you mean WW-3442? Or WW-4741?, Label: 1\n",
      "Processing row 2484 - Data Type: val, Message: the explicit version was missing at all, Label: 0\n",
      "Processing row 2485 - Data Type: train, Message: Hello @sepe81 .\n",
      "\n",
      "This PR copies the equivalent code from previous PR#261 (into 2.6/master), and in both cases I had not considered using additional imports/libraries for the Windows OS check.  If you think using `SystemUtils.IS_OS_WINDOWS` from `commons-lang3` is preferable that is certainly doable (in which case it should probably also be done for the same tests in 2.6/master).  \n",
      "\n",
      "I'm not sure if it's cleaner to incorporate the fix as-is (to mirror 2.6/master more closely), and then follow-up with an \"improve/cleanup\" version for 2.5.x and master branches.\n",
      "\n",
      "Please let me know what you think.  :), Label: 1\n",
      "Processing row 2486 - Data Type: val, Message: In terms of the remaining items in the tests (most was removed when the limiter logic was removed) most is just convenient structure/configurations for some \"standard\" configuration combinations that may still be useful for future tests.  :)\n",
      "\n",
      "I also had to amend my last commit because I missed one statement (now all three have been fixed).  :) :), Label: 0\n",
      "Processing row 2487 - Data Type: val, Message: `container.inject(clazz)` will do the same, I mean it will instantiate an object and inject all the internal dependencies. Those won't happen when using Spring or CDI, that's why leaving this up to the given factory is a good idea.\n",
      "\n",
      "There is at least one implementation out of the Apache Struts control - Guice connector - and refactoring those methods can affect this plugin. We can annotate it as deprecated but I'm not sure if this is a good approach anyway., Label: 1\n",
      "Processing row 2488 - Data Type: val, Message: Because with use this fake implementation in tests and now `ObjectFactory` will use `Container#inject()` to instantiate a new object. Instead I've got `nulll`s., Label: 0\n",
      "Processing row 2489 - Data Type: train, Message: I think the `invocation.getInvocationContext().getSession()` can be `null` in some cases, can't it? And we need it to put locale., Label: 1\n",
      "Processing row 2490 - Data Type: train, Message: I'm not sure if I could understand well but URI doesn't have getRef method while URL has which means URI has included ref (i.e. what is after \"#\") in path. My added unit tests verify this., Label: 1\n",
      "Processing row 2491 - Data Type: train, Message: No, previously it was mixed up both cases also so it is same as previous in this behavior. The only difference for it is: Now it is outside of the loop. Being inside of the loop is a bug. I discovered it in #357 - For example `OgnlValueStack.findValue(expr: \"someProp\", throwExceptionOnFailure: true)` always fail when top of stack doesn't have `someProp` property while it must check also other objects in stack and fail if none of them had this property.\n",
      "\n",
      "> Also, shall we consider break the loop at the point we threw MethodFailedException?\n",
      "\n",
      "I think no. AFAIK it must try on all of objects in stack., Label: 1\n",
      "Processing row 2492 - Data Type: train, Message: Now, it doesn't break the loop but previously it did, and I thought it was an issue when `throwExceptionOnFailure` is set true because of casual failed tests #357 - for example it accidentally uncovered that `XWorkConverter.getConversionErrorMessage` seems fails when user set `throwExceptionOnFailure` to true, I think.  right?\n",
      "\n",
      "I just found all usages of `OgnlValueStack.THROW_EXCEPTION_ON_FAILURE` and found all of them outside loop except here. Thanks for heads up for `reason != null`, it makes sense! But now I'm surprised if `reason != null` is a good decision to distinguish between `property not found` and `user app exception` then why #357 tests fail?! (see prev para) In #357 everything is same as before except `throwExceptionOnFailure` which is hard-coded to true., Label: 1\n",
      "Processing row 2493 - Data Type: train, Message: We should because with that following test fails. I tested and even Struts 2.5 (5/5/2016) with no change also fails on this test: https://github.com/apache/struts/blob/a50af87644320a3ca85283ccab7bc72822cb230b/core/src/test/java/com/opensymphony/xwork2/ognl/OgnlValueStackTest.java#L982\n",
      "but this is and was a wrong behavior., Label: 0\n",
      "Processing row 2494 - Data Type: val, Message: > Was the old logic intentionally limiting the loop to 1 iteration (unless the exception reason was `null` ) ?\n",
      "> Previously it would seem things would _only succeed_ if the method was defined on the object at the top of the stack.\n",
      "\n",
      "In case of `throwExceptionOnFailure=true`, Yes, but it is a wrong behavior. Please see my test at https://github.com/apache/struts/blob/d4dd3386cc02833fa7113a496092b2e09a53c9e4/core/src/test/java/com/opensymphony/xwork2/ognl/OgnlValueStackTest.java#L958 which fails on Struts 2.5 (5/5/2016) on L#975.\n",
      "\n",
      "> Will \"walking the whole valuestack\" potentially introduce a different issue (unexpectedly) ?\n",
      "\n",
      "No, it is already current behavior in case of `throwExceptionOnFailure=false`., Label: 1\n",
      "Processing row 2495 - Data Type: train, Message: ðŸ‘ fixed, Label: 0\n",
      "Processing row 2496 - Data Type: val, Message: ðŸ‘ fixed, Label: 0\n",
      "Processing row 2497 - Data Type: train, Message: ðŸ‘ fixed, Label: 0\n",
      "Processing row 2498 - Data Type: train, Message: ðŸ‘ fixed, Label: 0\n",
      "Processing row 2499 - Data Type: train, Message: AFAIK Struts didn't use to operate like that. It fails in such conditions with fatal BadConfException and compels user to fix it., Label: 0\n",
      "Processing row 2500 - Data Type: train, Message: Right, done!, Label: 0\n",
      "Processing row 2501 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 2502 - Data Type: train, Message: Hi.  It looks like this interceptor could produce a lot of logging output, to the point that it might flood the application's logs.\n",
      "Maybe the debug-level output is OK, since the developer can usually find the related forbidden (403) response in the access logs of the application server anyway ?\n",
      "Another option could be to use a `.info` level for the message instead (could still be suppressed if developers set minimum log level to warning, but easier to differentiate than debug-level).  What do you think ?, Label: 1\n",
      "Processing row 2503 - Data Type: train, Message: IntelliJ has a vertical line indicating suggested line length limit. I always press enter on it to not violate it. Do you want me to keep all in same line? I can if so :), Label: 0\n",
      "Processing row 2504 - Data Type: train, Message: thanks! fixed, Label: 0\n",
      "Processing row 2505 - Data Type: train, Message: I'm not sure, because only this method needs it - Again it's recommended by SonarLint to not repeat \"nameValue\" more than three times but only this method needs this constant!, Label: 1\n",
      "Processing row 2506 - Data Type: val, Message: IntelliJ has a vertical line indicating suggested line length limit. I always press enter on it to not violate it. Do you want me to keep all in same line? I can if so :), Label: 0\n",
      "Processing row 2507 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2508 - Data Type: val, Message: Moved., Label: 0\n",
      "Processing row 2509 - Data Type: train, Message: This class is constructed per request thread so I don't believe we need concurrency handling here, Label: 0\n",
      "Processing row 2510 - Data Type: train, Message: Using #computeIfAbsent here would change the exception handling semantics so I've forgone it, Label: 0\n",
      "Processing row 2511 - Data Type: train, Message: Fixed broken logging, Label: 0\n",
      "Processing row 2512 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2513 - Data Type: train, Message: I'll take a look - I actually meant to ask for help with this specifically.  This is pretty hacked together, but I fought with Angular for quite a while trying to pull the ticket= parameter out of the return URL and put it in the right place, and literally cutting it out and putting it at the right position ended up being the way I had to go.  I'll go back and review, but it seemed like I stumbled across a couple of limitations in Angular that prevented me from doing it in a more elegant way., Label: 0\n",
      "Processing row 2514 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2515 - Data Type: train, Message: Doh., Label: 0\n",
      "Processing row 2516 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2517 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2518 - Data Type: train, Message: Trusty VIM spell checker failed me...oh, wait, nevermind.  Even if it was there, it wouldn't like dereferencing, anyway.  Fixed., Label: 0\n",
      "Processing row 2519 - Data Type: train, Message: I'll look at a couple of other implementations of LDAP clients and see what they do for this type of behavior.  The \"finding\" and \"searching\" terms are a little strange to me - I think in the past I've usually run across either two or three objects - usually on, off, and maybe something in between.  Four is a little odd...I'll have to see what the more general consensus is among LDAP clients., Label: 1\n",
      "Processing row 2520 - Data Type: train, Message: Chose DereferenceAliasesMode., Label: 0\n",
      "Processing row 2521 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2522 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2523 - Data Type: train, Message: > I'm not sure whether one is better than the other at the moment, but I am curious.\n",
      "\n",
      "Well, since Java already has a URI class and is capable of parsing out the URI without the...colorful...regex, I think I might be leaning toward redoing it server-side.  JavaScript does have some basic parsing available through the DOM, and some external libraries available for it, but it doesn't seem nearly as robust as the Java library., Label: 1\n",
      "Processing row 2524 - Data Type: train, Message: That's probably reasonable - I'll work on moving this over to some sort of EncryptedGuacamoleProperty or something like that.  Preferences on naming??, Label: 1\n",
      "Processing row 2525 - Data Type: val, Message: This feels like reverting back to behavior advised against before, but I'm not sure the best way to get the Guacamole Home directory into this property to open up the file without doing this.  Suggestions?, Label: 1\n",
      "Processing row 2526 - Data Type: train, Message: And, you know how I said that the exceptions shouldn't kill the entire client, it should just result in the password not being available...well...I think all of this here killed that off..., Label: 0\n",
      "Processing row 2527 - Data Type: train, Message: So, I've redone most of this such that it throws the GuacamoleServerException.  There are two scenarios I can think of where having authentication succeed despite some error in the ClearPass decryption process would be desirable:\n",
      "- If the credentials object is provided by the CAS server, but the Guacamole admin has not configured a private key, I think authentication should still succeed.  Since, in many organizations, SSO is run by someone different than a VDI/Desktop/RemoteAccess person, it's conceivable that the CAS server may provide something we choose not to consume, and that should not cause an error.\n",
      "- Where the Guacamole admin has configured a PrivateKey, but CAS is not providing a value for the credential parameter.  Again, with the potential for CAS and Guacamole to be run by different admins/groups, or for different users within CAS to have different policies applied, it's conceivable that the GuacamoleAdmin configures a PrivateKey file for this purpose, but the attribute is blank/null.\n",
      "\n",
      "Is my logic sound there?, Label: 1\n",
      "Processing row 2528 - Data Type: train, Message: Taking a key argument and calling this a cipher property feels a little kludgy.  Kind of goes along with the question about how far the Cipher property should go or if that's even really a good name/function for it., Label: 1\n",
      "Processing row 2529 - Data Type: train, Message: Refactored as PrivateKey., Label: 0\n",
      "Processing row 2530 - Data Type: val, Message: This is not a javadoc comment and should not start with two asterisks. Checking the other license headers in the project, I found none that were written with two leading asterisks., Label: 0\n",
      "Processing row 2531 - Data Type: train, Message: Pulled it out so that the same logic could be reused by `ListenerFacade` rather than duplicating it., Label: 0\n",
      "Processing row 2532 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2533 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2534 - Data Type: train, Message: Well, that was fun.  Nested `try{}` blocks to correctly capture all of the possible exceptions.  I *think* this works out correctly...though it seems like you could still run into issues if you hit the IOException during the file close, but I can't really see any way to get around that., Label: 1\n",
      "Processing row 2535 - Data Type: train, Message: So, the problem I'm running into is that the `close()` operation can actually throw an `IOException`, which is why I have to nest the `try{}` statements.  Apparently with Java 7+ it gets a little easier, but 6 is a little onerous:\n",
      "\n",
      "https://stackoverflow.com/questions/156508/closing-a-java-fileinputstream, Label: 0\n",
      "Processing row 2536 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2537 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2538 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2539 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2540 - Data Type: train, Message: Oops, removed., Label: 0\n",
      "Processing row 2541 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2542 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2543 - Data Type: val, Message: Or perhaps code..., Label: 1\n",
      "Processing row 2544 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2545 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2546 - Data Type: train, Message: Wow, this is nasty.  Unfortunately the SAML client doesn't currently capture exceptions it generates, so we have to do it, here.\n",
      "\n",
      "Since one of the methods just throws `Exception`, which I have to capture here at the end, I could remove all of the other `catch()` statements and just capture it at the `Exception` level.  Is that acceptable, since it's actually specifically thrown by one of those methods, or should I stick with `catch`ing each one individually?, Label: 1\n",
      "Processing row 2547 - Data Type: val, Message: This works okay; however, this redirect tends to cause issues with header size in my testing - I'm using the CAS SAML IdP, and I had to bump up the maxHttpHeaderSize on Tomcat and then the proxy_buffer_size and proxy_busy_buffers_size parameter in Nginx to get this to work.  It does work reliably, but not sure if this is the best way to go, or if I should try to process the SAML response directly in here?, Label: 1\n",
      "Processing row 2548 - Data Type: val, Message: Unfortunately this option has no effect right now, because the OneLogin SAML client has not released the version that implements pulling settings from the IdP Metadata (it's implemented in the latest git master repo, just not released into Maven).  Hopefully it'll be out, soon, but the lead developer hasn't been very responsive., Label: 0\n",
      "Processing row 2549 - Data Type: train, Message: Not sure if I should use constants here??, Label: 1\n",
      "Processing row 2550 - Data Type: train, Message: Oops, wrong client..., Label: 0\n",
      "Processing row 2551 - Data Type: train, Message: Wrong SAML client., Label: 0\n",
      "Processing row 2552 - Data Type: train, Message: Commented., Label: 0\n",
      "Processing row 2553 - Data Type: val, Message: Objectified., Label: 0\n",
      "Processing row 2554 - Data Type: train, Message: Ops., Label: 0\n",
      "Processing row 2555 - Data Type: val, Message: Fxed., Label: 0\n",
      "Processing row 2556 - Data Type: train, Message: That should be better.  Is it worth keeping it in its own method, or better to just throw it in the toResponse() method?, Label: 1\n",
      "Processing row 2557 - Data Type: train, Message: Cleaned up this comment., Label: 0\n",
      "Processing row 2558 - Data Type: train, Message: Wow, not sure why I forgot that.  Documented., Label: 1\n",
      "Processing row 2559 - Data Type: train, Message: ðŸ ðŸ˜¢ , Label: 0\n",
      "Processing row 2560 - Data Type: train, Message: Not in practice, but it would make sense to do this. I'm not sure what this wasn't done in the first place., Label: 1\n",
      "Processing row 2561 - Data Type: train, Message: We could switch everything to 1.8 for the 1.0 release. If there are concerns there may be hidden things within MyBatis requiring 1.7+, and considering 1.0 is a major release, now might be the time.\n",
      "\n",
      "Well ... \"now\" as in a separate PR with a new JIRA issue associated with 1.0.0., Label: 0\n",
      "Processing row 2562 - Data Type: train, Message: Will fix., Label: 0\n",
      "Processing row 2563 - Data Type: val, Message: Hm... I'm not sure I know what you mean. What about the code seems that way?, Label: 1\n",
      "Processing row 2564 - Data Type: train, Message: Whoops. Will fix., Label: 0\n",
      "Processing row 2565 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2566 - Data Type: train, Message: It looks like Java `enum`s implement the `compareTo()` method, though, using the position of declaration of the enum value as the relative comparison between them.  So, I could leverage that, instead of a function like this, but is that something we really want to rely on?, Label: 1\n",
      "Processing row 2567 - Data Type: val, Message: Well, currently in the `GuacamoleClientInformation` class it is pre-initialized to an empty string.  I don't know if there was a particular reason I did this - I think I was trying to follow the pattern of the other config information, like the mimetypes, which are initialized to an empty list.  So, if anything, shouldn't it be only empty and skip the `null` check?, Label: 1\n",
      "Processing row 2568 - Data Type: train, Message: Yeah, I like this idea.  I'm guessing another enum (or class?) would be required to implement this?  Or is there a way that I should try to do it within the current enum?, Label: 1\n",
      "Processing row 2569 - Data Type: train, Message: Sounds good.  Is there any precedent to adding a link/URL within the JavaDoc for this to the Wikipedia article on tz database?, Label: 1\n",
      "Processing row 2570 - Data Type: train, Message: > Is there a reason supplying a default of this particular instance of this method is necessary or valuable? Won't the old implementations already be calling the other default method, without the `tokens` parameter?\n",
      "\n",
      "Some sort of default is necessary to bridge the implementations, as it's the webapp that ultimately calls `connect()`, and in this case will be calling the version which has `tokens`.\n",
      "\n",
      "In the general case, defaults are needed to bridge in both directions to allow extensions of different versions to interoperate. An older extension (compatible with 1.0.0) which decorates the connections of other extensions will need to be able to invoke `connect()`, even though it will be calling the older version. A newer extension and the webapp need the same ability but in the other direction.\n",
      "\n",
      "> And doesn't this introduce the possibility that an implementing class could end up recursively calling these parameters (if they don't actually implement either of them)?\n",
      "\n",
      "Yes, and that's definitely a bad thing. I think I may have a route around this., Label: 1\n",
      "Processing row 2571 - Data Type: train, Message: I've added e.resultCodeToString() to the warning in the logs which gives enough information but doesn't spam the admin. It's included in the latest version of the PR. Here's some example output:\n",
      "\n",
      "`00:33:34.844 [http-nio-8080-exec-1] WARN  o.a.g.auth.ldap.ObjectQueryService - Failed to process an LDAP search result. Error was: Sizelimit Exceeded`, Label: 0\n",
      "Processing row 2572 - Data Type: train, Message: Because CAPS is better than lowercase.\n",
      "\n",
      "Not really., Label: 1\n",
      "Processing row 2573 - Data Type: val, Message: So, for using `createObject()`, the only issue I can see is that the current implementation of it requires the input of an already authenticated user who is creating the object, and then checks that the user is an Administrator.  So, we could do one of a couple of things:\n",
      "* Tweak the `createObject()` code to factor in System-created users in this instance.\n",
      "* Create some sort of internal definition of a SYSTEM user that can be passed into the `createObject()` method and that is, by definition, an Administrator.\n",
      "\n",
      "Thoughts?, Label: 1\n",
      "Processing row 2574 - Data Type: train, Message: Okay, so, been taking a look at the options and trying some things out - I'm determined to figure this out...\n",
      "1. The first option - a wrapper class - seems like the least desirable to me, so I've been mostly ignoring this route.  Still a possibility, but the other two seem a little more elegant.\n",
      "2. The second option - an interface for permission gathering that can be implemented by `RemoteAuthenticatedUser` and `ModeledAuthenticatedUser` - seems like the best way to do this.  **Question: Is there any reason the interface to be implemented shouldn't be the `Permissions` interface, since it already contains the permissions-gathering methods?**\n",
      "3. I took a look at the third option - replacing `ModeledAuthenticatedUser` with `User`, and, while it probably would be feasible in the end, it isn't quite as simple as just swapping them out - particularly since `ModeledAuthenticatedUser.getUser()` passes a `ModeledUser`, not a plain `User`, which has some extra methods like `isAdministrator()` that have to be factored in.  So, either the `User` class (interface?) would have to have at least the `isAdministrator()` method defined (stubbed), or we'd have to do `ModeledUser` instead of `User`, but then this System user couldn't be defined in the `guacamole-ext` package, it would have to be in the `guacamole-jdbc-base` package, which may not be the best place for it.  Hopefully that makes sense.\n",
      "4. I guess this brings up a fourth option that is a combination of two and three - either add a handful of the permissions methods to the `User` interface, and replace `ModeledAuthenticatedUser` with `User` such that swapping out `ModeledAuthenticatedUser` with `User` would actually work., Label: 1\n",
      "Processing row 2575 - Data Type: val, Message: Yeah, probably a good point.  I could move it to the constructor for the `RadiusConnectionService` class, but not sure if that would still happen each time someone logged in, or would be a one-shot thing?\n",
      "\n",
      "> Is it known that no other auth protocols use MD4?\n",
      "\n",
      "I do not know one way or the other if others require it., Label: 1\n",
      "Processing row 2576 - Data Type: val, Message: Not seeing this in the current set of commits...were you looking at an earlier commit??, Label: 1\n",
      "Processing row 2577 - Data Type: val, Message: As with others, I think this is actually okay in the most recent code., Label: 0\n",
      "Processing row 2578 - Data Type: train, Message: Fixed now, Label: 0\n",
      "Processing row 2579 - Data Type: train, Message: YES! \n",
      "Here, \"s\" is added because it is in English as it is not translated into Japanese., Label: 0\n",
      "Processing row 2580 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2581 - Data Type: train, Message: Well, two things, here:\n",
      "* In order to get the \"Reply-Message = \" out of here, I need to split it.  Not sure how feasible this is with an `AttributeValue` type?\n",
      "* It ends up getting passed through the form on the Web side.  Is this going to play okay with using `AttributeValue` vs. `String`?, Label: 1\n",
      "Processing row 2582 - Data Type: train, Message: Null documented., Label: 0\n",
      "Processing row 2583 - Data Type: train, Message: Fixed this up., Label: 0\n",
      "Processing row 2584 - Data Type: train, Message: Present tensed., Label: 0\n",
      "Processing row 2585 - Data Type: train, Message: @necouchman \n",
      "You're right, but there is something else hidden. At first I just wanted to fix this js error so that I could choose Chinese localization. After fixing it, I found that the localization was incomplete, and then I completed it.\n",
      "\n",
      "This is a bug that I fixed that would cause an existing script error, I fixed it, and if I don't modify it here, my commit may not work.\n",
      "\n",
      "I did a simple test, it was fixed, and it worked fine.\n",
      "\n",
      "Unfortunately I don't have the ability to write unit tests for this modification at this time because it is beyond my ability to do so., Label: 0\n",
      "Processing row 2586 - Data Type: train, Message: I've left a comment below as to my reasoning.  If you agree, I'll leave it unchanged.  If you disagree, I will agree to disagree and change it.  :-), Label: 0\n",
      "Processing row 2587 - Data Type: train, Message: Fixing..., Label: 0\n",
      "Processing row 2588 - Data Type: train, Message: Is there any reason not to just loop through the `getAvailableIDs()` output and compare the string value we receive to the available IDs, and throw an error if don't match on that? It's probably a slightly expensive operation from a compute perspective, but probably not all that bad, and then we can just document that the value for the timezone property must be a valid Java TimeZone ID. Something like:\n",
      "```\n",
      "for (String tzStr : TimeZone.getAvailableIDs()) {\n",
      "    if (value.equals(tzStr))\n",
      "        return TimeZone.getTimeZone(value);\n",
      "}\n",
      "\n",
      "throw GuacamoleServerException(\"Invalid timezone specified.\");\n",
      "```\n",
      "\n",
      "It's not pretty or elegant, but it's fairly simple. Or is there some downfall I'm missing with that?, Label: 1\n",
      "Processing row 2589 - Data Type: val, Message: Wow, the Java `TimeZone` implementation is really awful.  Writing the `JUnit` tests is fun:\n",
      "* If you use the string \"GMT\" for the input, the ID you get back is \"GMT\" - okay, good so far.\n",
      "* If you use the string \"GMT+00:00\" for the input, the ID you get back is \"GMT+00:00\" - not ideal, but not the worst.\n",
      "* If you use the string \"GMT+0000\" for the input, the ID you get back is \"GMT+00:00\" - :exploding_head: \n",
      "\n",
      "So, cannot check that valid input strings generate an ID of \"GMT\", and cannot check that valid input strings generate an ID equal to the input string., Label: 0\n",
      "Processing row 2590 - Data Type: train, Message: So, are you good with the code as-is, or would you rather see a loop through `getAvailableIDs()` and put the RegEx back to requiring `GMT[+-]0`?, Label: 1\n",
      "Processing row 2591 - Data Type: train, Message: Correct, we can't do both, at least I did not find a way to do so.\n",
      "We could `chmod 777 webapps` directory at build time, but sounds like a security breach to me...\n",
      "IMO there's no way to support `WEBAPP_CONTEXT` as non-root user..., Label: 1\n",
      "Processing row 2592 - Data Type: train, Message: Finally solved with my last commit ðŸ‘ , Label: 0\n",
      "Processing row 2593 - Data Type: train, Message: Thank you for your review @manolan1 ðŸ‘\n",
      "\n",
      "> Why does the regex care about spaces before the closing tag?\n",
      "\n",
      "To be sure, in addition to the `^` anchor, to select the real closing tag, and not for example a comment.\n",
      "\n",
      "> And, if it does, shouldn't it use a generic whitespace pattern rather than a space?\n",
      "\n",
      "I used space because the .xml file uses spaces, but I've switched to `\\s`, even stronger. Thx., Label: 1\n",
      "Processing row 2594 - Data Type: train, Message: > What is the impact of configuring the Remote IP Valve with default options? I have only ever seen it with proxy filtering enabled.\n",
      "\n",
      "If you use (as you should) your Docker instance behind a (Apache) reverse proxy :\n",
      "- without the Remote IP Valve, you'll get the Docker interface IP in the Guacamole logs ;\n",
      "- with the Remote IP Valve, you'll get the correct client (public) IP in the Guacamole logs.\n",
      "\n",
      "If you use your Docker instance directly (strange as you won't provide SSL etc...) :\n",
      "- with or without the Remote IP Valve, you'll get the correct client (public) IP in the Guacamole logs. The only drawback is that a client with a **local** IP should be able to replace its IP by a fake one in Guacamole logs adding some headers (normally sent by the proxy) to his requests (`X-Forwarded-For`)., Label: 0\n",
      "Processing row 2595 - Data Type: train, Message: First, this line is due to the fact the user chosen to run the container may not have a home directory into the container, which would then not start.\n",
      "Note however that the `guacamole` directory, inside the `tmp` directory, is only reachable by the user running the container, as shown below, from a container running this PR :\n",
      "```\n",
      "$ ls -l /tmp/\n",
      "total 12\n",
      "drwx------ 5 1024 1024 4096 Mar  4 13:02 guacamole\n",
      "```\n",
      "\n",
      "> but what if the user decides to try to map through `/etc/guacamole` to a specific path?\n",
      "\n",
      "I also do this in my `docker-compose.yml` file, not an issue at all :\n",
      "```\n",
      "services:\n",
      "  guacamole:\n",
      "    image: guacamole/guacamole:1.1.0\n",
      "    volumes:\n",
      "      - ./etc:/etc/guacamole:ro\n",
      "```, Label: 0\n",
      "Processing row 2596 - Data Type: train, Message: I'm not sure because we would then set empty options in the configuration file.\n",
      "In the other sections, options are tested to always have a value., Label: 1\n",
      "Processing row 2597 - Data Type: train, Message: For sure, I just then pushed the required fix.\n",
      "Thank you @necouchman ðŸ‘, Label: 0\n",
      "Processing row 2598 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2599 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 2600 - Data Type: train, Message: You're right about the command/instruction thing, I missed it. The problem with `GuacamoleHandshakeException` is that it ties the error to the specific connection phase; an `error` instruction can occur at any time in any phase. I do believe it deserves special semantics to distinguish it from any other error condition, because that allows for very explicit and clear `catch` blocks - this was the original impetus for this PR.\n",
      "\n",
      "I honestly couldn't find a more descriptive, and semantically appropriate, name than `GuacamoleServerErrorInstructionException` (adjusting for your comment, of course). Considering any part of it:\n",
      "* Guacamole can be omitted since it's contextual and present in the package name, but then it won't follow the already-established convention;\n",
      "* Server can't really be omitted, as it's not denoted by the package and it's semantically important;\n",
      "* ErrorInstruction is, well, what it is;\n",
      "* and Exception can be omitted, but that would be against the preexisting convention in this codebase (and the Java ecosystem as a whole).\n",
      "\n",
      "I know at this point most people reading this think this is splitting hairs, sorry ladies and gentlemen :-) Serious though @mike-jumper, if you have any better names I'd be happy to take them. This one is a mouthful., Label: 1\n",
      "Processing row 2601 - Data Type: train, Message: Considering I no longer work for Strigo I don't really have a strong opinion or even a test harness. Feel free to do with this pull request as you will..., Label: 0\n",
      "Processing row 2602 - Data Type: val, Message: Wow. Yes., Label: 0\n",
      "Processing row 2603 - Data Type: train, Message: Renamed it to `purgeConfigParameters()` - if you have other ideas, I'm game, I was having a mental block coming up with something more apropos., Label: 0\n",
      "Processing row 2604 - Data Type: train, Message: Empty strings removed, Label: 0\n",
      "Processing row 2605 - Data Type: train, Message: yes, it's a typo error.\n",
      "\n",
      "Can or should I add a new commit to the branch?\n",
      "\n",
      "What should the commit description be [GUACAMOLE-1082: Add guacamole-auth-cas to docker Script - Cas 2 CAS typo ]?\n",
      "\n",
      ", Label: 1\n",
      "Processing row 2606 - Data Type: train, Message: Eep - will deleting this break RADIUS? I don't recall the string value being used for JRadius, but if that's the case, I should definitely put some of this back., Label: 1\n",
      "Processing row 2607 - Data Type: train, Message: Yep, because `AliasDerefMode` is part of an API outside of this extension and Guacamole. It's not within our power to add `@PropertyValue` annotations there., Label: 0\n",
      "Processing row 2608 - Data Type: train, Message: Totally good with this, just might need a little guidance on the best way to leverage this in a `Field` situation.  Based on the above note, the `redirectMsg` (now `redirectMessage`) variable is directly available in the scope.  But, if I move over to `Translatable` and `getTranslatableMessage()`, what's the best way to rework the AngularJS side such that this message will be properly displayed and run through the translation system?  I'm trying to follow examples in the existing code, so maybe I'll figure it out..., Label: 1\n",
      "Processing row 2609 - Data Type: train, Message: For some reason I remember that you worked on a way to do this in the base code.  I cannot remember where, but I'll try to dig up the JIRA issue for it..., Label: 1\n",
      "Processing row 2610 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2611 - Data Type: train, Message: Okay, I've worked through this - not entirely sure how well I've done. I hit some issues with the `List<? extends ConnectionRecord>` and converting that to `List<ConnectionRecord>`. I ended up with the loops you see, here, now - not sure if there's a more elegant way to do that translation from `? extends RecordType` to just `RecordType`? I tried various adjustments to the types of methods and such in the classes, and I couldn't really do much without breaking compatibility.\n",
      "\n",
      "Also, the `HistoryResource` class in `rest/history` pulls history from `UserContext`, whereas the `ConnectionResource` and `UserResource` classes in `rest/connection` and `rest/user` pull history from `Connection` and `User`, and I'm not sure if there are any modifications needed to the `HistoryResource` class or anything in the `UserContext` interfaces or classes that need to be tweaked to handle these changes?, Label: 1\n",
      "Processing row 2612 - Data Type: train, Message: > Can you point to the specific part of the code where you're encountering trouble? I don't think there should be any need to convert.\n",
      "\n",
      "See comment below: https://github.com/apache/guacamole-client/pull/546#discussion_r513709095\n",
      "\n",
      "> Are you referring to whether the code that pulls directly from UserContext needs to add special handling for GuacamoleUnsupportedException?\n",
      "\n",
      "Correct, or whether `UserContext` itself needs to take that into account at all., Label: 1\n",
      "Processing row 2613 - Data Type: train, Message: This is the area that I'm talking about in terms of the conversion.  So, what I initially tried to do was:\n",
      "```\n",
      "try {\n",
      "    return new ConnectionHistoryResource(connection.getConnectionHistory());\n",
      "}\n",
      "catch (GuacamoleUnsupportedException e) {\n",
      "    try {\n",
      "        return new ConnectionHistoryResource(new SimpleActivityRecordSet<ConnectionRecord>(connection.getHistory()));\n",
      "    }\n",
      "    catch (GuacamoleUnsupportedException ex) {\n",
      "        return new ConnectionHistoryResource(new SimpleActivityRecordSet<>());\n",
      "    }\n",
      "}\n",
      "```\n",
      "However, when I do that, I get a compile error:\n",
      "\n",
      "    incompatible types: List<CAP#1> cannot be converted to List<ConnectionRecord>\n",
      "\n",
      "This appears to be because the return type of `getHistory()` is `List<? extends ConnectionRecord>` whereas the input type of `SimpleActivityRecordSet()` is `ActivityRecord`.  For some reason that `? extends` causes it a bunch of heartache., Label: 0\n",
      "Processing row 2614 - Data Type: train, Message: Indentation fixed., Label: 0\n",
      "Processing row 2615 - Data Type: train, Message: I have used the same order that I found in English file for easier comparison. If order is important, all translations files need to be updated..., Label: 0\n",
      "Processing row 2616 - Data Type: train, Message: How large did the parameter need to be to run into that limit?, Label: 1\n",
      "Processing row 2617 - Data Type: train, Message: It can stack. For example, if you submit JSON like:\n",
      "\n",
      "```json\n",
      "{\n",
      "    \"username\" : \"guacadmin\"\n",
      "}\n",
      "```\n",
      "\n",
      "that would be sufficient for the database authentication to accept the user as \"guacadmin\".\n",
      "\n",
      "The JSON extension simply won't attempt to provide _data_ (a `UserContext`) for a user that it hasn't authenticated, as its data comes from the JSON. If there isn't any JSON, then the JSON extension has no data to provide., Label: 0\n",
      "Processing row 2618 - Data Type: val, Message: It's a lot less of a mind-bender if you start with the assumption that I made a typo and `==` should have actually been `&&` :rofl: , Label: 1\n",
      "Processing row 2619 - Data Type: train, Message: Right, removed., Label: 0\n",
      "Processing row 2620 - Data Type: train, Message: Good catch! That's copy-pasta. That `return` definitely should not be there., Label: 0\n",
      "Processing row 2621 - Data Type: train, Message: Oops., Label: 0\n",
      "Processing row 2622 - Data Type: train, Message: Whoopsies, Label: 0\n",
      "Processing row 2623 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2624 - Data Type: train, Message: i don't like that solution either because of the same security reasons you mentioned. \n",
      "\n",
      "To sum up my finding about java and ceritifcates:\n",
      "- Only a keystorefile can be used as a certificate source within java. \n",
      "- You can't load a single cert file into you application\n",
      "- Importing into default keystore file for unprivileged users is not possible by default\n",
      "\n",
      "A solution that only affects the container and provides sufficient security is not possible as far as I can assume: \n",
      "- You can't run multiple CMD/ENTRYPOINT-commands within a dockerfile with different users\n",
      "- Importing certifcates with RUN-Commands is nonsense since this would be done while building the image (and not starting a container)\n",
      "\n",
      "A possible solution would be:\n",
      "- create a new keystore file with all the necessary certs \n",
      "- make the file read only after creating and importing\n",
      "- merge it on the fly within the application with the system wide keystore (maybe with [https://github.com/1and1/CompositeJKS](https://github.com/1and1/CompositeJKS))\n",
      "\n",
      "But since this topic only affects containers and the approach above requires some changes to the application itself I don't know if it should be done like that.\n",
      "\n",
      "\n",
      ", Label: 1\n",
      "Processing row 2625 - Data Type: train, Message: Yes, I've hesitated too when doing the changes but I thought it may be less error-prone if everything is named postresql instead of postgres only for the link. I can revert this part if you prefer.\n",
      "What about the username variable ?, Label: 1\n",
      "Processing row 2626 - Data Type: train, Message: any comment @mike-jumper ?, Label: 0\n",
      "Processing row 2627 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 2628 - Data Type: train, Message: Oops, added!, Label: 0\n",
      "Processing row 2629 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2630 - Data Type: train, Message: Ack, sorry. I thought I had done that., Label: 0\n",
      "Processing row 2631 - Data Type: train, Message: Fixed!, Label: 0\n",
      "Processing row 2632 - Data Type: train, Message: That's fair - refactored to work that way instead. How does this look?, Label: 1\n",
      "Processing row 2633 - Data Type: train, Message: What do people think: should this be a `MultilineField` or a `TextField`? The base-64 encoded JSON configuration blob won't have any newlines in it, so this is what it looks like in practice:\n",
      "\n",
      "![image](https://user-images.githubusercontent.com/4633119/177383816-4c83ddfc-cf61-4c6f-97e7-8fd528fafdcd.png)\n",
      ", Label: 0\n",
      "Processing row 2634 - Data Type: train, Message: Should it? They're not required properties., Label: 0\n",
      "Processing row 2635 - Data Type: train, Message: How do these look?, Label: 1\n",
      "Processing row 2636 - Data Type: train, Message: Good catch on it not returning anything - I'll fix that.\n",
      "\n",
      "The entity is `entity` - the `Attributes` instance that's passed into `processAttributes()`. I thought that was relatively clear?, Label: 1\n",
      "Processing row 2637 - Data Type: train, Message: Is it still unclear?, Label: 1\n",
      "Processing row 2638 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 2639 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 2640 - Data Type: train, Message: I really wish that java would provide some syntactical sugary magic that would do this for me, but alas, it needs to be done.\n",
      "\n",
      "Not sure if this has the right name, or is in the right place? Thoughts?, Label: 1\n",
      "Processing row 2641 - Data Type: train, Message: I still don't get why that's needed, though. I mean, getting rid of that check just forces it to reload from the DB every time, which is what we want.\n",
      "\n",
      "That check is what `forceRefresh` existed to specifically disable, which is what's needed to get the user context to actually refresh when `updateUserContext` is called., Label: 1\n",
      "Processing row 2642 - Data Type: train, Message: It does not. Is that a problem? This usage of the `Map` data structure looks pretty well supported, including in IE11., Label: 1\n",
      "Processing row 2643 - Data Type: train, Message: gah the copypasta, Label: 0\n",
      "Processing row 2644 - Data Type: train, Message: What caller are you referring to, specifically?, Label: 1\n",
      "Processing row 2645 - Data Type: train, Message: Hmm, what specifically would you request that I add? All it means if this parameter is null is that it will fetch records for which the domain is null. It's just regular equality, nothing special., Label: 1\n",
      "Processing row 2646 - Data Type: train, Message: Because it can now throw a `GuacamoleException`, and you can't have a java lambda that throws a checked exception. My level of frustration with the whole java lambda ecosystem is quite high right now., Label: 0\n",
      "Processing row 2647 - Data Type: val, Message: Sure, Label: 0\n",
      "Processing row 2648 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2649 - Data Type: train, Message: I removed it. Rest seems fine yeah, Label: 0\n",
      "Processing row 2650 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 2651 - Data Type: val, Message: Err, yeah. I'm not sure what was going on when I tested that earlier., Label: 1\n",
      "Processing row 2652 - Data Type: train, Message: I don't really love having to call this everywhere, but I'm not sure of a better / more elegant way to do this., Label: 1\n",
      "Processing row 2653 - Data Type: train, Message: Ok, how does this look?, Label: 1\n",
      "Processing row 2654 - Data Type: val, Message: That makes sense - how does this look?, Label: 1\n",
      "Processing row 2655 - Data Type: train, Message: Missed that comment.\n",
      "Fixed.\n",
      ", Label: 0\n",
      "Processing row 2656 - Data Type: train, Message: ok\n",
      ", Label: 0\n",
      "Processing row 2657 - Data Type: val, Message: These also are inherited from \"guacamole-auth-sso-base\": https://github.com/apache/guacamole-client/tree/78c084be6568ae2ae8097daddb1cbf94903df060/extensions/guacamole-auth-sso/modules/guacamole-auth-sso-base/src/main/resources/translations, Label: 0\n",
      "Processing row 2658 - Data Type: train, Message: > Okay, if that's the accepted way, that's fine ...\n",
      "\n",
      "Well, it's the way that I determined `login.gov` was using, and the only way I can think of that would ensure there is no caching of credentials, but I have not found any documentation explicitly supporting that approach.\n",
      "\n",
      "The fact that you've not dealt with similar in your own use of X.509 auth, and that no other SSO system leveraging X.509 via the browser appears to be documented as doing the same, concerns me that I may have overengineered this ... but then again, I'm reasonably confident this is what `login.gov` is doing., Label: 1\n",
      "Processing row 2659 - Data Type: train, Message: Whoops. I got hyper focused on editing the clipboard directive and didn't check the client's id, Label: 0\n",
      "Processing row 2660 - Data Type: train, Message: Yep, Label: 0\n",
      "Processing row 2661 - Data Type: train, Message: I'm not sure if there is a better way to do this ... as it is you'd have to invoke it like\n",
      "`build-guacamole.sh \"/tmp/some-path\" \"/opt/guacamole\" \"\" -DskipTests=false` if you wanted to not pass anything for `$BUILD_PROFILE`, but still pass something for `$MAVEN_ARGUMENTS` - inserting a dummy argument to pad out the argument count to make sure the maven arguments get to the right place. \n",
      "\n",
      "Thoughts?, Label: 1\n",
      "Processing row 2662 - Data Type: train, Message: Changed this to only show for administrators, due to the wide variety of permissions actually required to do the import., Label: 0\n",
      "Processing row 2663 - Data Type: val, Message: Hmm, it seems to me that a failed attempt to update a record (even if it's because it doesn't exist), should trigger an UPDATE failure event. What do you think?, Label: 1\n",
      "Processing row 2664 - Data Type: train, Message: Sure, that works. How does this look?, Label: 1\n",
      "Processing row 2665 - Data Type: train, Message: Oops - fixed!, Label: 0\n",
      "Processing row 2666 - Data Type: train, Message: So to be clear - you're suggesting that we modify `seekToFrame` to either advance to the next frame _or_ increment `currentPosition` depending on whether `currentPosition + refreshInterval` >= the timestamp of the next frame? \n",
      "\n",
      "I think that could make sense. Let me see if it's simpler than what I have now., Label: 1\n",
      "Processing row 2667 - Data Type: train, Message: Or rather, not the `seekToFrame` function itself, but perhaps a wrapper function here., Label: 1\n",
      "Processing row 2668 - Data Type: train, Message: How do my latest changes look? That's more or less what I'm doing, though I didn't do do the multiple-of-`refreshInterval` thing, I just seek to the next `refreshInterval`, or the next frame, whichever is sooner., Label: 1\n",
      "Processing row 2669 - Data Type: train, Message: ~This change seems to have caused some weird jumping effects on pause/resume. Drafting while I investigate.~\n",
      "Problem fixed - undrafted. , Label: 0\n",
      "Processing row 2670 - Data Type: train, Message: Correct me, if I'm wrong: Would updating xmlsec to 2.3.0 not also mean to update woodstox-core to 6.2.6? That seems to be an even bigger change.\n",
      "\n",
      "The version 6.2.6 of woodstox-core furthermore contains the following vulnerabilities that version 5.4.0 does not:\n",
      "- CVE-2022-40156\n",
      "- CVE-2022-40155\n",
      "- CVE-2022-40154\n",
      "- CVE-2022-40153\n",
      "- CVE-2022-40152, Label: 1\n",
      "Processing row 2671 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 2672 - Data Type: train, Message: Does the exception also include methods from an interface?, Label: 1\n",
      "Processing row 2673 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 2674 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 2675 - Data Type: train, Message: > Yep. Reading through this, it occurred to me that what you have here is equivalent to:\n",
      "> \n",
      "> ```java\n",
      "> public MockConfigurationService(String... trustedNetworks) {\n",
      ">     this.trustedNetworks = Arrays.asList(trustedNetworks);\n",
      "> }\n",
      "> ```\n",
      "> \n",
      "> with the added benefit that you don't need to rely on string splitting.\n",
      "\n",
      "Unfortunately, I cannot confirm that., Label: 1\n",
      "Processing row 2676 - Data Type: val, Message: Oops, sure should. Odd that it seemed to work correctly in all my testing like this..., Label: 0\n",
      "Processing row 2677 - Data Type: train, Message: Oops, no., Label: 0\n",
      "Processing row 2678 - Data Type: train, Message: I don't see where that's happening. Can you be a bit more specific? , Label: 1\n",
      "Processing row 2679 - Data Type: train, Message: So currently the `KeyEventIntepreter` is documented to \"produce human readable text batches\". \n",
      "\n",
      "It sounds like you're advocating removing all of the rendering logic out of this service (i.e. everything that produces the `text` or `simpleValue` fields, modifier/shortcut tracking, probably even batch separation). This would be probably all move to a service in the webapp. \n",
      "\n",
      "I think that separation of concerns makes a lot of sense, though I was unsure how heavy handed I should be in changing the way the interpreter works., Label: 1\n",
      "Processing row 2680 - Data Type: train, Message: Yes!, Label: 0\n",
      "Processing row 2681 - Data Type: train, Message: Ah, right you are. It shouldn't be private., Label: 0\n",
      "Processing row 2682 - Data Type: train, Message: Oops, indeed it doesn't. Removed., Label: 0\n",
      "Processing row 2683 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 2684 - Data Type: train, Message: Yeah, there will be at most once, I was referring more to the number of timers that are scheduled while the mouse is moving. I don't want to be constantly cancelling and rescheduling new timers on every mouse movement. In practice it doesn't seem to cause excessive CPU / memory usage or anything, just seems wasteful., Label: 0\n",
      "Processing row 2685 - Data Type: train, Message: Cleared the extra space, Label: 0\n",
      "Processing row 2686 - Data Type: train, Message: ```suggestion\n",
      "        if ([contentMode isEqual: @\"mobile\"]) {\n",
      "```\n",
      "\n",
      "Guess not, Label: 0\n",
      "Processing row 2687 - Data Type: train, Message: Yeah , Looks like someone did some benchmarking and found system.nanoTime() is slower\n",
      "https://stackoverflow.com/questions/19052316/why-is-system-nanotime-way-slower-in-performance-than-system-currenttimemill/19052440, Label: 1\n",
      "Processing row 2688 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2689 - Data Type: val, Message: > If we are going to center on the Dropwizard metrics API, then I think the clearest thing to do is make it crystal clear how a user gets the MetricsRegistry object that they need to pass to any converter. Maybe that is more documentation than just code? e.g. If I wrote my own state machine, what method do I call to set up custom reporters?\n",
      "\n",
      "yes. I'll add this in the documentation. How to get dropwizard metricRegistry from Ratis MetricRegistry and link directing towards the Dropwizard documentation for how to configure different reporters., Label: 1\n",
      "Processing row 2690 - Data Type: train, Message: so \n",
      "\n",
      "1. Change state to pausing will (or at least should)  prevent, e.g. new AppendEntries.\n",
      "2. `synchronized (this)` will guarantee that for those operations which get lock before this pause code block, they should be able to finish.\n",
      "\n",
      "However my current thought is, there could be still be a race condition, when pause and other operations are competing this lock, and then pause wins, other operations will still be executed after pause, which is wrong.\n",
      "\n",
      "So the resolution can be adding an extra LifeCycle check after, e.g. AppendEntries, entering `synchronized (this)`, to make sure no other operations happen after a pause. \n",
      "\n",
      "WDYT?, Label: 0\n",
      "Processing row 2691 - Data Type: val, Message: Make sense!, Label: 0\n",
      "Processing row 2692 - Data Type: train, Message: At this moment, I am not sure how this server should handle exceptions when forwarding message to peers:\n",
      "1. Will there any exception be thrown? I have this question because existing request handling code seems does not throw any exception already.\n",
      "2. If this server fails to forward a message to a peer, what is the proper way to respond to client? Note that the client is sending a stream of message. So is failures happen in the middle means the client should retry from the failure point?, Label: 1\n",
      "Processing row 2693 - Data Type: train, Message: `startServer` is to start the stream server.  `startClientToPeers` means to build connections with other stream servers, which implies that other stream servers must be called `startServer` firstly.\n",
      "\n",
      "That's why I cannot call `startClientToPeers` in `startServer` because other stream servers might not start.\n",
      "\n",
      "Alternatively, we could lazy initialize the clients to peers, by checking whether connection is built when having first request. But I am not sure whether this is a good idea.\n",
      "\n",
      " `startServer` can be called without calling `startClientToPeers` afterwards, which means that this stream will not forward message to peers., Label: 1\n",
      "Processing row 2694 - Data Type: train, Message: yes. I was thinking whether we need a read API to verify that write is complete. I do need suggestion here: do we need a read API to have a better test? E.g. use read API to verify that all writes has succeed?, Label: 1\n",
      "Processing row 2695 - Data Type: val, Message: Might rename to `watch`?, Label: 1\n",
      "Processing row 2696 - Data Type: train, Message: Will `BlockingImpl` better?, Label: 1\n",
      "Processing row 2697 - Data Type: train, Message: @szetszwo updated to use `SupportedDataStreamType.DISABLED`. Can you take a look?, Label: 0\n",
      "Processing row 2698 - Data Type: val, Message: Thanks! \n",
      "\n",
      ":) somehow I thought this approach complicates the code too much but I was wrong. This approach encapsulates code much well thus simplify the code.  , Label: 0\n",
      "Processing row 2699 - Data Type: train, Message: Oops... I must have forgot to push my last local commit that fixes indents before going to sleep. Sorry :), Label: 0\n",
      "Processing row 2700 - Data Type: train, Message: Reverted., Label: 0\n",
      "Processing row 2701 - Data Type: train, Message: @szetszwo Thanks the suggestions, I have updated the patch. But this still can not address primary server won't call submitClientRequestAsync if there are no other peers. The problem is that: 1. If peer finish close stream, it must reply to primary success and can not call submitClientRequestAsync.  2. If primary finish close stream and received the success reply of peers, it call submitClientRequestAsync. So peer and primary's behavior when finish close stream is different, we must decide  whether current server is primary or peer, but if a single server without other peers, we can not decide whether it is primary or peer., Label: 1\n",
      "Processing row 2702 - Data Type: train, Message: @szetszwo \n",
      "\n",
      "I have rebased and I can see now that most of the group id pass through code is not needed. \n",
      "\n",
      "However, I am still seeing a problem here about Proxies. \n",
      "\n",
      "First of all, I think we expect to set a group id in [DataStreamClient](https://github.com/apache/incubator-ratis/blob/master/ratis-client/src/main/java/org/apache/ratis/client/impl/DataStreamClientImpl.java#L48).  So each client will include this group id in the RaftClientRequest in the header.\n",
      "\n",
      "However, in `NettyServerStreamRpc` we are doing `new Proxies(new PeerProxyMap<>(name, peer -> newClient(peer, properties)));`   So it leaves no place to pass in a group id to create DataStreamClient (e.g. `outs.add(map.getProxy(peer.getId()).stream());`) for peers.\n",
      "\n",
      "That is why I am changing here to `Map<RaftPeerId, Map<RaftGroupId, DataStreamClient>> map`. By doing so, My intention is at least allow when creating a new DataStreamClient, we can set the group id.\n",
      "\n",
      "Do you think whether this makes sense?\n",
      "\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2703 - Data Type: val, Message: @szetszwo Thanks the suggestions. I agree. Besides, I am not sure one thread is enough for all streams. So I create 4 ExecutorService, each has a single thread in the pool, and assign one of the 4  ExecutorService with the fewest tasks to the new stream.  Because one stream must use the same thread to write, so I can not create a ExecutorService with 4 threads, and all the streams share the same ExecutorService.  What do you think ?, Label: 1\n",
      "Processing row 2704 - Data Type: train, Message: Another thought is, with MiniRaftCluster based test, do we still need existing test cases? Can we migrate all tests to MiniRaftCluster based?, Label: 1\n",
      "Processing row 2705 - Data Type: val, Message: I will hold off if we need the `NULL` check for now because it is not related to test itself. \n",
      "\n",
      "\n",
      "Back to whether we need `MultiDataStreamStateMachine` for this MiniRaftCluster test, here is my question:\n",
      "\n",
      "If we enable `MultiDataStreamStateMachine` for MiniRaftCluster test, what is the difference between this MiniRaftCluster test and the existing `TestDataStreamNetty`? From the test coverage MiniRaftCluster will be a super set over `TestDataStreamNetty`, why we want to keep both?, Label: 1\n",
      "Processing row 2706 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 2707 - Data Type: train, Message: Should I get rid of `ServerConfig` class completely?  Doesn't seem to add much value after removing `equals()`: it only bundles 2 parameters for the `private GrpcService` constructor., Label: 1\n",
      "Processing row 2708 - Data Type: train, Message: I don't think we can move it after `serverBuilder.build()` call., Label: 0\n",
      "Processing row 2709 - Data Type: train, Message: Thanks for reviewing, @adoroszlai .\n",
      "\n",
      "I'm not familiar with the Sonar setup.  Does the project key need to be set up ahead of time somehow, or would it get activated on the first Sonar run under the new key?\n",
      "\n",
      "Ideally, I'd like to transition to \"apache-ratis\" and completely remove \"incubator\" for consistency., Label: 1\n",
      "Processing row 2710 - Data Type: train, Message: @szetszwo here is the BUG, in the original code, `dir` represents the newly created directory(name = UUID) for the group under the storageDir, not the storageDir itself, so it loops forever indeed under my test.\n",
      "So here I try to remove the exact storageDir, do you have a better way to write this line in Java?, Label: 0\n",
      "Processing row 2711 - Data Type: train, Message: OK., Label: 0\n",
      "Processing row 2712 - Data Type: train, Message: Hmmm..., but 'min' or 'required' does not match the meaning of this config? @szetszwo \n",
      "The space configured here is reserved for final snapshot usage,\n",
      "but 'min' or 'required' seems to configure some space for server to consume.\n",
      "|---------------for server to consume-------------------|     reserved     |, Label: 0\n",
      "Processing row 2713 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2714 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2715 - Data Type: train, Message: Sure.  Except for that double is more precise than float,  any major drawbacks of using float? , Label: 1\n",
      "Processing row 2716 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2717 - Data Type: train, Message: Done , Label: 0\n",
      "Processing row 2718 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2719 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2720 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2721 - Data Type: val, Message: I see, Label: 0\n",
      "Processing row 2722 - Data Type: train, Message: Yeah, Label: 0\n",
      "Processing row 2723 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2724 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 2725 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 2726 - Data Type: train, Message: I guess you mean we should't expose the printStream outside of `AbstractRatisCommand`? If so, it make sense., Label: 1\n",
      "Processing row 2727 - Data Type: train, Message: I have delete the code, PTAL again, thx!, Label: 0\n",
      "Processing row 2728 - Data Type: val, Message: down, Label: 0\n",
      "Processing row 2729 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2730 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2731 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2732 - Data Type: train, Message: Yean,  adding a data structure is really hard to keep it correct., Label: 0\n",
      "Processing row 2733 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2734 - Data Type: val, Message: I'm just wondering about your comment.\n",
      "FollowerInfo is in ratis-server-api project's leader package, and `notifyFollowerSlowness`, which is in `LeaderEventApi`, is called on a leader. Even though it is in this case, should it not appear in the StateMachine API?, Label: 1\n",
      "Processing row 2735 - Data Type: val, Message: > Sorry, this idea is incorrect. The RoleInfoProto is for leader. We should not change it.\n",
      "How about adding a RaftPeerId for the slow follower?\n",
      "\n",
      "I see. I think that RaftPeer is better than RaftPeerId. WDYT?, Label: 0\n",
      "Processing row 2736 - Data Type: train, Message: I'm not sure that keeping the deprecated method is okay. Please let me know if you have any opinions. It seems that `slownessInfo` is used in others.. so It can disturb the unit tests until removing the deprecated method., Label: 1\n",
      "Processing row 2737 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2738 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2739 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2740 - Data Type: train, Message: fix., Label: 0\n",
      "Processing row 2741 - Data Type: train, Message: fix., Label: 0\n",
      "Processing row 2742 - Data Type: train, Message: fix, Label: 0\n",
      "Processing row 2743 - Data Type: train, Message: fix, Label: 0\n",
      "Processing row 2744 - Data Type: train, Message: fix, Label: 0\n",
      "Processing row 2745 - Data Type: train, Message: Reverted., Label: 0\n",
      "Processing row 2746 - Data Type: train, Message: Good to know. I made the decision since `Objects.requireNonNull` throws `NullPointerException` while these methods throws `IllegalStateException`. Perhaps Guava's `Precondition.checkArgument` fits better XD, Label: 0\n",
      "Processing row 2747 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2748 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2749 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2750 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2751 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2752 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2753 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2754 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2755 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2756 - Data Type: val, Message: ðŸ˜‚Done., Label: 0\n",
      "Processing row 2757 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2758 - Data Type: train, Message: Got., Label: 0\n",
      "Processing row 2759 - Data Type: train, Message: Got., Label: 0\n",
      "Processing row 2760 - Data Type: train, Message: Close the comment now., Label: 0\n",
      "Processing row 2761 - Data Type: train, Message: welcome @szetszwo, I test several commands, `bash` is different from `sh`, their grammar is different.\n",
      "|  command   | result  |\n",
      "|  ----  | ----  |\n",
      "| /bin/bash ./bin/ratis  | ok |\n",
      "| /bin/bash ./bin/ratis -e | ok |\n",
      "| /bin/bash ./bin/ratis sh | ok |\n",
      "| /bin/sh ./bin/ratis sh | error |\n",
      "| /bin/sh ./bin/ratis -e | error |\n",
      "\n",
      "We should use `bash` as the same as the head in script files.\n",
      "\n",
      "![image](https://user-images.githubusercontent.com/95013770/184310774-67b00f61-0528-4d88-bc9b-4fb24ae4d4db.png)\n",
      "\n",
      "\n",
      "## The scripts somehow do not have execute again.\n",
      "\n",
      "I checked the assemble file, we alreadly set the fileMode `0755`, and my local evn is ok. \n",
      "Can you ask someone else check these files again?\n",
      "\n",
      "```\n",
      "$ls -l bin/\n",
      "total 8\n",
      "-rw-r--r--  1 szetszwo  staff  2152 Jan 22  2020 ratis\n",
      "$ls -l examples/bin/\n",
      "total 40\n",
      "-rw-r--r--  1 szetszwo  staff  1138 Jan 22  2020 client.sh\n",
      "-rw-r--r--  1 szetszwo  staff  1859 Jan 22  2020 common.sh\n",
      "-rw-r--r--  1 szetszwo  staff   921 Jan 22  2020 server.sh\n",
      "-rw-r--r--  1 szetszwo  staff  1598 Jan 22  2020 start-all.sh\n",
      "-rw-r--r--  1 szetszwo  staff   922 Jan 22  2020 stop-all.sh\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 2762 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2763 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2764 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2765 - Data Type: train, Message: I ignored `Daemon` threads created in `JvmPauseMonitor` and `TimeoutScheduler` because my intuition is even if they crash, the RaftServer can still live., Label: 0\n",
      "Processing row 2766 - Data Type: val, Message: I intended to force all threads to have a valid name (otherwise java Thread.init() will throw an exception anyways). Do you see use cases where the caller creates a Daemon and `setName()` later? WDYT?, Label: 1\n",
      "Processing row 2767 - Data Type: val, Message: > We should check if the requestTimeout is already set.\n",
      "\n",
      "How about the current change? Properties in `System` should have higher priority. It can cover the requestTimeout if we set it passed by `-D`, Label: 0\n",
      "Processing row 2768 - Data Type: val, Message: DOne, Label: 0\n",
      "Processing row 2769 - Data Type: train, Message: I am trying it as repository wrapper. What name should this class be named? Would it be NotificationMapperReadRepositoryWrapper?, Label: 1\n",
      "Processing row 2770 - Data Type: train, Message: I think I missed this case. Do I need to implement this now or can we add this later in another PR?, Label: 1\n",
      "Processing row 2771 - Data Type: train, Message: noted, Label: 0\n",
      "Processing row 2772 - Data Type: train, Message: A known issue in the previous version of data import tool and fixed by PR in the description, Label: 0\n",
      "Processing row 2773 - Data Type: train, Message: Ok., Label: 0\n",
      "Processing row 2774 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 2775 - Data Type: train, Message: I'll use a wrapper class, I just noticed that it is used for the Loan repository but there are some others that don't make use of it so it was a bit misleading., Label: 0\n",
      "Processing row 2776 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 2777 - Data Type: train, Message: It is not, consider it as gone., Label: 0\n",
      "Processing row 2778 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 2779 - Data Type: train, Message: @vorburger  using getInstance() method I'm reusing the logic of instantiating job parameter instance. Shall we keep this?, Label: 0\n",
      "Processing row 2780 - Data Type: val, Message: Thanks for your feedback. I updated all 3 of those files and added the license header. RAT seems fine with it. As far as the changes to build.gradle, if I leave the DB host as localhost, the docker images crashes on startup when Fineract runs the Flyway migration:\n",
      "\n",
      "FlywayException: Unable to obtain Jdbc connection from DataSource; for Tenant DB URL: jdbc:mysql:thin://localhost:3306/mifostenant-default, username: root\n",
      "\n",
      "I can dig into it a bit more, but appears that some part of the gradle build configuration is carried into the war file..., Label: 1\n",
      "Processing row 2781 - Data Type: train, Message: ```applyChargeToOverdueLoanInstallment``` won't ever return a null `overdueDTO` as the return itself is a constructor call. I can let it explode but the problem is this whole logic is inside a for loop for all loans that are overdue. Hence, if this explodes it will impact the normal flow for overdue penalty for other loans. Hence it had to be handled gracefully. I can let it explode with a `try catch block`, Label: 0\n",
      "Processing row 2782 - Data Type: train, Message: `applyChargeToOverdueLoanInstallment` is  creating a `LoanCharge` and returning `LoanOverdueDTO`. I want to avoid creating the `LoanOverdueInstallmentCharge` on certain conditions ( the amount is zero). As the function holds all the logic for loan charges and returns using a constructor, I had to `return null` to escape the logic of charge creation. \n",
      "\n",
      "Hence the null pointer check is due to my code changes inside `applyChargeToOverdueLoanInstallment`, Label: 0\n",
      "Processing row 2783 - Data Type: train, Message: `equals` won't work because it also takes into consideration the scale. I have changed it to use `compareTo == 0`, Label: 0\n",
      "Processing row 2784 - Data Type: train, Message: For swagger's API documentation, here is the way to add description \n",
      "@Api(tags = {\"Swagger Resource\"})\n",
      "@SwaggerDefinition(tags = {\n",
      "    @Tag(name = \"Swagger Resource\", description = \"Write description here\")\n",
      "})\n",
      "public class ... {\n",
      "}\n",
      "\n",
      "That is what i got from swagger github issues.\n",
      "does that mean i will have to unindent? I have not checked if that will work but right now, that description properly appears on the UI, Label: 1\n",
      "Processing row 2785 - Data Type: train, Message: > @kangbreder do you happen to remember why you had to add `apply plugin: 'java'` here? Does it work without it as well? I guess it's a bit strange to have a project use BOTH `apply plugin: 'java-library'` AND `apply plugin: 'java'` - it's either or the other.\n",
      "\n",
      "@vorburger I have not checking if it works without the plugin. My Ubuntu 18 has failed to boot and i have been trying to correct the problem. Because of that, I have not been able to check that yet, Label: 1\n",
      "Processing row 2786 - Data Type: train, Message: New version of spring-boot-starter-data-jpa uses HikariCP as default connection pool instead of tomcat-jdbc. So I need to add this dependency. Also I have excluded HikariCP in the latest commit., Label: 0\n",
      "Processing row 2787 - Data Type: train, Message: @EnableTransactionManagement is a replacement for <tx:annotation-driven /> . Without @EnableWebSecurity we need to configure additional spring security beans for example `org.springframework.security.config.annotation.ObjectPostProcessor`, Label: 0\n",
      "Processing row 2788 - Data Type: train, Message: > this looks suspicious, and worth of a closer investigation..\n",
      "\n",
      "Call to Builder() never passes accountNo, so setting the class var to itself makes no sense to me. Maybe, I am wrong. Advice? SpotBugs flags this as something to be removed. , Label: 1\n",
      "Processing row 2789 - Data Type: train, Message: @vorburger The AssertionError was thrown from LineNo 139  String importDocumentId = savingsAccountHelper.importSavingsTemplate(file); I enclosed it in a try catch block in the hope of seeing the stacktrace. However, I could not see it anywhere in the log. Numerous attempts to recreate the issue locally failed too. Would I able be to access the detail log from the build server in order to investigate the cause behind this? , Label: 1\n",
      "Processing row 2790 - Data Type: train, Message: alright, Label: 0\n",
      "Processing row 2791 - Data Type: train, Message: Is it better I just comment it out?, Label: 1\n",
      "Processing row 2792 - Data Type: train, Message: @singkara could you fix this issue. , Label: 0\n",
      "Processing row 2793 - Data Type: train, Message: @singkara , Label: 0\n",
      "Processing row 2794 - Data Type: train, Message: Ack., Label: 0\n",
      "Processing row 2795 - Data Type: train, Message: https://github.com/muellners/fineract/blob/38e19f73fcea5c9165d34d9c83a7be8bf6cec884/fineract-provider/src/main/java/org/apache/fineract/accounting/closure/service/GLClosureWritePlatformServiceJpaRepositoryImpl.java#L353\n",
      "\n",
      "Kinda of strange , in my repo I updated this, but does it not reflect here,, Label: 1\n",
      "Processing row 2796 - Data Type: train, Message: Thanks - that makes sense. I only added it to suppress an error message from Tomcat 9. But you're right that a better approach would be to disable the connector altogether. Will do that next. \n",
      "\n",
      "And the magical secret was reuse of the keystore password in the same config file :-) , Label: 0\n",
      "Processing row 2797 - Data Type: train, Message: @vorburger concerning org.apache.fineract.notification.domain.Notification.setActor(Long) error prone picked this up locally, Label: 0\n",
      "Processing row 2798 - Data Type: val, Message: @vorburger not sure the of the right format that was supposed to be on methods I added @SuppressWarnings(\"MisuedWeekYear\") please see https://errorprone.info/bugpattern/MisusedWeekYear\n",
      ", Label: 0\n",
      "Processing row 2799 - Data Type: train, Message: @vorburger or @awasum this looks like a test any idea why they are missing @Test., Label: 1\n",
      "Processing row 2800 - Data Type: val, Message: Yeah, Label: 0\n",
      "Processing row 2801 - Data Type: train, Message: Was doing some tests. Missed to revert that. , Label: 0\n",
      "Processing row 2802 - Data Type: train, Message: It is needed to enable weaving which eclipse requires inorder to be able to support OneToOne and ManyToOne LAZY fetchtype. You can refer here: https://docs.spring.io/spring/docs/5.2.5.RELEASE/spring-framework-reference/core.html#aop-aj-ltw-aop_dot_xml, Label: 0\n",
      "Processing row 2803 - Data Type: train, Message: I had some errors when I excluded the whole group. Seems hibernate and eclipse have some few dependencies in common., Label: 1\n",
      "Processing row 2804 - Data Type: train, Message: Unfortunately EclipseLink weaving makes some changes to classes which violate this particular spotbugs rule. Given that I can't fix this without disabling weaving/enhancement, I thought it best to just ignore., Label: 0\n",
      "Processing row 2805 - Data Type: train, Message: Another side effect of weaving, Label: 0\n",
      "Processing row 2806 - Data Type: train, Message: https://mvnrepository.com/artifact/com.itextpdf/itextpdf, Label: 0\n",
      "Processing row 2807 - Data Type: train, Message: yes!, Label: 0\n",
      "Processing row 2808 - Data Type: val, Message: I already tried doing that, it won't let us do it :( , Label: 0\n",
      "Processing row 2809 - Data Type: val, Message: Nope, it is all manual clean-up. Just that my IDE(vscode) does give a suggestion for this while writing code which makes it easier to spot. \n",
      "In this case, since I am removing the object I have \"no other option\" that making it static it throws out an error. , Label: 0\n",
      "Processing row 2810 - Data Type: val, Message: Yes!, Label: 0\n",
      "Processing row 2811 - Data Type: train, Message: This class is used for the serialisation only, hence was the carelessness on the name, Thanks for pointing out, Label: 0\n",
      "Processing row 2812 - Data Type: val, Message: done!, Label: 0\n",
      "Processing row 2813 - Data Type: train, Message: This is trying to retrieve a key from the memory. When there is no key available here (that is, when null is returned) the wrapper which calls this method is supposed to create a new key and store it.  do you really think an Exception throw and catch needed in this context? I don't., Label: 1\n",
      "Processing row 2814 - Data Type: train, Message: I was thinking that if we have scheduled jobs processing large quantities of accounts, we may not want to have the full stack trace for every account - one line per account with the account number and error message would be enough. But will change this to print the full cause..., Label: 0\n",
      "Processing row 2815 - Data Type: train, Message: ðŸ˜‚ðŸ˜‚ðŸ˜‚ Completely forgot., Label: 0\n",
      "Processing row 2816 - Data Type: train, Message: I wish it were but unfortunately it isn't. I tried without and it didn't work., Label: 0\n",
      "Processing row 2817 - Data Type: train, Message: Agreed! I did not understand do we really need a constructor though(or you mean something else here), an abstract class without any attributes and two static methods will do IMO. , Label: 1\n",
      "Processing row 2818 - Data Type: train, Message: @vorburger  made the change I am unsure though if is this is what you meant., Label: 1\n",
      "Processing row 2819 - Data Type: train, Message: it fails with ConstructorInvokesOverridable is not a valid checker name, Label: 0\n",
      "Processing row 2820 - Data Type: val, Message: Error Prone kept complaining java.util.Date equals() doesn't seem to work as expected. This is because from [this](https://docs.oracle.com/javase/6/docs/api/java/util/Date.html#equals(java.lang.Object)) two Date objects are equal if and only if the getTime method returns the same long value for both., Label: 0\n",
      "Processing row 2821 - Data Type: train, Message: I was actually going to point this on #1019, HideUtilityClassConstructor checks if it is utility class by its name, to do this(using non-private constructor) we would need to either suppress the warning for that checkstyle then or call this something that does not have Helper or util in its name. What do you suggest?\n",
      ", Label: 1\n",
      "Processing row 2822 - Data Type: train, Message: I removed the useless comments, that made it happen. \n",
      "Weird, we might need to change some spotless rules. \n",
      ", Label: 0\n",
      "Processing row 2823 - Data Type: train, Message: In the add Interest method principle was added to the total due instead of the interest. which is wrong, as the added interest must reflect in the total due.\n",
      ", Label: 0\n",
      "Processing row 2824 - Data Type: train, Message: no this is how it should be, the other variables are static finals (constant) and hence they are named like that. , Label: 0\n",
      "Processing row 2825 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 2826 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2827 - Data Type: train, Message: updated, I dont know what I was thinking at that time, probably a mistake., Label: 1\n",
      "Processing row 2828 - Data Type: train, Message: Not sure how to do it. Can you point to a refernce implementation? , Label: 1\n",
      "Processing row 2829 - Data Type: val, Message: There is one of the two implimentations of the interface \"LoanScheduleModelPeriod\" (Disbursement period and Repayment Period).  These methods are not significant for Disbursement Period and needed only in Repayment Period, hence they are marked dummy., Label: 0\n",
      "Processing row 2830 - Data Type: train, Message: There is one of the two implimentations of the interface \"LoanScheduleModelPeriod\" (Disbursement period and Repayment Period).  These methods are not significant for Disbursement Period and needed only in Repayment Period, hence they are marked dummy., Label: 0\n",
      "Processing row 2831 - Data Type: train, Message: @ptuomola I'm finally (7 weeks later, phew!) picking this up, and I'm struggling to understand how the `reportType: SMS` is intended to work... @vidakovic do you understand that? Can those be run on the `/runreports` API? I think what I'll do is just write a `DefaultReportingProcessService` with the current code to which this will delegate to for both `Table` and `SMS`.. I'll therefore make the `type` on `org.apache.fineract.infrastructure.report.annotation.ReportService` a multivalue. Does that sounds reasonable to you guys?, Label: 1\n",
      "Processing row 2832 - Data Type: val, Message: I'm not sure if I get this one? What's the problem here?, Label: 1\n",
      "Processing row 2833 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2834 - Data Type: train, Message: This is just to define the plugin dependencies. We could also do something like this:\n",
      "\n",
      "```\n",
      "...\n",
      "id 'org.openapi.generator' version '4.3.1' apply false\n",
      "...\n",
      "```\n",
      "\n",
      "Then this is really just declaring a dependency (much like the dependencyManagement section) and the respective plugins would only be activated with (same example):\n",
      "\n",
      "```\n",
      "apply plugin: 'org.openapi.generator'\n",
      "```, Label: 0\n",
      "Processing row 2835 - Data Type: train, Message: Yes, use BOMs. I went through that phase with my old projects already. Switching to BOMs makes life so much easier and ensures that mechanics (e. g. Spring - Spring Boot - Spring Cloud) are working well together. Nowadays a handful of BOMs cover 99.9% of all dependencies that you might ever use. And they are really up to date, even for the transitive dependencies. I used to have a weekly task that would list me everything that is new and then I would update that manually. Not worth it, BOMs are your friends., Label: 0\n",
      "Processing row 2836 - Data Type: train, Message: OKHttp doesn't generate anything, but we are still building the client JAR... so unless I'm missing something here seems to be normal to me...\n",
      "\n",
      "Before it was not defined in Fineract's dependency management section, because the build was driven by a totally independent - single project - Maven pom.xml that had no ties to the fineract project setup (in terms of dependencies).\n",
      "\n",
      "These dependencies are just a consequence of having fineract-client as a module., Label: 0\n",
      "Processing row 2837 - Data Type: train, Message: Yup, as expected was the license plugin configuration that just included a bit too much (\\*\\*/\\*.bat). Fixed., Label: 0\n",
      "Processing row 2838 - Data Type: val, Message: You tell me... I'm neither here nor their. Personally I tend more to explicitly providing generated clients like \"normal\" Java client, RxJava client, TypeScript client etc. (see SDK discussion). Otherwise people will start asking about their custom templates..., Label: 0\n",
      "Processing row 2839 - Data Type: train, Message: corrected!, Label: 0\n",
      "Processing row 2840 - Data Type: train, Message: @vorburger @vidakovic \n",
      "\n",
      "Is this line necessary?\n",
      "Is it easier to configure SSL certificate for JAR file instead of  Tomcat WAR?, Label: 1\n",
      "Processing row 2841 - Data Type: train, Message: Yuh. Your approach is ok @francisguchie . But instead of excluding that path, @ptuomola suggested to an exclusion for this particular dependency. I tried by adding it. But didn't work.\n",
      "\n",
      "```\n",
      "    implementation ('com.sun.activation:jakarta.activation:1.2.2') {\n",
      "        exclude group: 'jakarta.activation', module: 'jakarta.activation-api'\n",
      "        exclude group: 'javax.activation', module: 'javax.activation-api'\n",
      "    }\n",
      "```\n",
      "Am I missing something there ? @ptuomola , Label: 1\n",
      "Processing row 2842 - Data Type: train, Message: > As I mentioned in my original comment, I'd suggest excluding the dependency brought in by jakarta-xml.bind-api and keeping this package intact. Otherwise you might end up with incompatible api and impl\n",
      "\n",
      "```\n",
      "implementation ('com.sun.activation:jakarta.activation:1.2.2') {\n",
      "        exclude group: 'jakarta.activation', module: 'jakarta.activation-api'\n",
      "        exclude group: 'javax.activation', module: 'javax.activation-api'\n",
      "}\n",
      "```\n",
      "Can you verify this? Have I missed something?, Label: 1\n",
      "Processing row 2843 - Data Type: train, Message: ðŸ‘ done!, Label: 0\n",
      "Processing row 2844 - Data Type: train, Message: To fix to ` where status_enum =?`, Label: 0\n",
      "Processing row 2845 - Data Type: train, Message: Since we aren't pretty sure about fields in in datable and their can be multiple datatable too with different fields, that's why HashMap is used. \n",
      "\n",
      "For example, in below request we have `Client Beneficiary information` datatable associated with clients, similiary there can be multiple datable with different data fields based on client. So in order to meet that kind of design I have defined `HashMap<String, Object>` as data type of `data` field.\n",
      "```\n",
      "{\n",
      "\"officeId\": 2,\n",
      " \"fullname\": \"SDK Test Client 6 (No group)\",\n",
      " \"dateFormat\": \"dd MMMM yyyy\",\n",
      " \"locale\": \"en\",\n",
      " \"active\": false,\n",
      " \"activationDate\": \"28 July 2019\",\n",
      "\"datatables\": [\n",
      "     {\n",
      "       \"registeredTableName\": \"Client Beneficiary information\",\n",
      "        \"data\": {\n",
      "            \"FirstName\": \"First 1\",\n",
      "            \"LastName\": \"Last\",\n",
      "            \"Mobile Number\": \"831\",\n",
      "            \"locale\": \"en\"\n",
      "           }\n",
      "       }\n",
      "    ]\n",
      "}\n",
      "```, Label: 0\n",
      "Processing row 2846 - Data Type: train, Message: Changed the variable name, Label: 0\n",
      "Processing row 2847 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2848 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2849 - Data Type: train, Message: GLAccountNotFoundException is a more accurate exception rather than the one thrown by Optional (NoSuchElementException), Label: 0\n",
      "Processing row 2850 - Data Type: val, Message: ah... didn't see that... that stuff is not necessary at all, Label: 0\n",
      "Processing row 2851 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2852 - Data Type: train, Message: Hm, now that you mention it... actually no... I was starting with a different idea and then I guess I forgot to remove them. Good catch!, Label: 0\n",
      "Processing row 2853 - Data Type: train, Message: Yes, that's exactly what was the problem here. I additionally verified by doing the reverse (creating a `LocalDate` on `2015-09-15` and print it out on the console with pattern `dd MMMM yyyy` and it prints out exactly above string. Curious, but seems like someone tightened the screws in JDK17. I think it actually makes sense, `Sep` is an abbreviation vs. `September` is the full month name (which is exactly the same behavior for the other months., Label: 1\n",
      "Processing row 2854 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 2855 - Data Type: train, Message: Solved, Label: 0\n",
      "Processing row 2856 - Data Type: train, Message: Solved, Label: 0\n",
      "Processing row 2857 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2858 - Data Type: train, Message: There are three cases due three different databases, two are same length the third one has more data then is more longer, and in between the two similars the difference is the T\n",
      "Maybe you are right in terms to have a better solution reading the dates as dates, numbers as numbers instead of just strings, but It can to impact no just the API, can to impact the front end too, Label: 0\n",
      "Processing row 2859 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2860 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2861 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2862 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2863 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2864 - Data Type: train, Message: Map is not supporting serialization., Label: 0\n",
      "Processing row 2865 - Data Type: train, Message: Checking the alternative, Label: 0\n",
      "Processing row 2866 - Data Type: train, Message: I have turned it to OncePerRequestFilter, about the conditional bean, I am just thinking about to keep a similar \"pattern\" about the other Configuration elements., Label: 0\n",
      "Processing row 2867 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2868 - Data Type: train, Message: ok\n",
      ", Label: 0\n",
      "Processing row 2869 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 2870 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2871 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 2872 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2873 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2874 - Data Type: train, Message: Yes, the JPA doesn't support the 'Limit 1' keyword in the Query to fetch a single record, So, the alternative that I will be using now is Pageable Param, is there any other alternative you think would fix this part? or Pageable would be fine? @adamsaghy , Label: 0\n",
      "Processing row 2875 - Data Type: train, Message: Done! Removed, Label: 0\n",
      "Processing row 2876 - Data Type: train, Message: Done!\n",
      "\n",
      "<img width=\"1429\" alt=\"Screen Shot 2022-07-28 at 19 34 35\" src=\"https://user-images.githubusercontent.com/44206706/181659208-c25496e8-f275-4c13-9f08-2113b6d820a8.png\">\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2877 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2878 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2879 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2880 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2881 - Data Type: val, Message: MySQL 8 sends this exception in the `rs.getTimeStamp` method, so that was the reason\n",
      "\n",
      "<img width=\"1739\" alt=\"Screen Shot 2022-07-24 at 19 42 10\" src=\"https://user-images.githubusercontent.com/44206706/180820330-a6580466-4ca4-4b15-8537-7da8b7313df0.png\">\n",
      "\n",
      ", Label: 0\n",
      "Processing row 2882 - Data Type: train, Message: Done! Removed, Label: 0\n",
      "Processing row 2883 - Data Type: train, Message: Done!\n",
      "\n",
      "<img width=\"1444\" alt=\"Screen Shot 2022-07-27 at 13 10 30\" src=\"https://user-images.githubusercontent.com/44206706/181342641-7356ce55-1ec4-4258-9073-4d7f0079e089.png\">\n",
      ", Label: 0\n",
      "Processing row 2884 - Data Type: val, Message: Probably we will never compare against UTC or sending it back to UI, so i thought tenant timezone would be the most beneficial here. What do you think?, Label: 1\n",
      "Processing row 2885 - Data Type: train, Message: Probably we will never compare against UTC or sending it back to UI, so i thought tenant timezone would be the most beneficial here. What do you think?, Label: 1\n",
      "Processing row 2886 - Data Type: train, Message: Which by the way is not happening automatically (i mean the UTC), because the OffsetDateTime will use the system TZ when the date time got fetched from the DB..., Label: 0\n",
      "Processing row 2887 - Data Type: train, Message: Which by the way is not happening automatically (i mean the UTC), because the OffsetDateTime will use the system TZ when the date time got fetched from the DB..., Label: 0\n",
      "Processing row 2888 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2889 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2890 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2891 - Data Type: train, Message: Done! Removed, Label: 0\n",
      "Processing row 2892 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2893 - Data Type: val, Message: Done!, Label: 0\n",
      "Processing row 2894 - Data Type: val, Message: Done!, Label: 0\n",
      "Processing row 2895 - Data Type: val, Message: Done!, Label: 0\n",
      "Processing row 2896 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2897 - Data Type: train, Message: exactly so on my part I just changed it to the unique constraint name that was generated at the time I installed it but it seemed like the new changes had the unique constraint in another name., Label: 0\n",
      "Processing row 2898 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 2899 - Data Type: train, Message: undone this change., Label: 0\n",
      "Processing row 2900 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2901 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2902 - Data Type: train, Message: This only happens till the soft lock logic is not in place or it will be handled differently and for (for now) unknown reasons there will be no soft lock applied. We still need to put a lock if there was none (by mistake or by design).\n",
      "\n",
      "I think this way is more resilient. What do you think?, Label: 1\n",
      "Processing row 2903 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2904 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2905 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2906 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2907 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2908 - Data Type: train, Message: @galovics but 'status' is not there in the previous return statement. should I add it?, Label: 0\n",
      "Processing row 2909 - Data Type: train, Message: made changes, Label: 0\n",
      "Processing row 2910 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2911 - Data Type: train, Message: undone the change., Label: 0\n",
      "Processing row 2912 - Data Type: train, Message: undone the change., Label: 0\n",
      "Processing row 2913 - Data Type: val, Message: is there any api endpoint for effective date? @mdallos., Label: 1\n",
      "Processing row 2914 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2915 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2916 - Data Type: train, Message: Done! Remove, Label: 0\n",
      "Processing row 2917 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2918 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2919 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2920 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 2921 - Data Type: train, Message: replaced, Label: 0\n",
      "Processing row 2922 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2923 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2924 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2925 - Data Type: train, Message: It was solved in this way:\n",
      "\n",
      "```\n",
      "        updateLoanSummaryDerivedFields();\n",
      "        if (!doPostLoanTransactionChecks(chargebackTransaction.getTransactionDate(), loanLifecycleStateMachine)) {\n",
      "            loanLifecycleStateMachine.transition(LoanEvent.LOAN_CHARGEBACK, this);\n",
      "        }\n",
      "```\n",
      "Why? Because the Status is evaluated only for Overpaid or Repaid in Full, no other cases to support like Charge back\n",
      ", Label: 1\n",
      "Processing row 2926 - Data Type: train, Message: good point, naming the file is still open for discussion; do you think a file name as api-performance-enhancement or improvement can  have customer documentation on the best practices to work with api to get best performance? cc @edcable., Label: 1\n",
      "Processing row 2927 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2928 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2929 - Data Type: train, Message: any other idea? Stream.of(....)? List.of(....)? what is the question?, Label: 1\n",
      "Processing row 2930 - Data Type: train, Message: you made a change at 2022.02.22 putting a TODO comment in that service class:\n",
      "// TODO: Extract these types out of here\n",
      "`.put(\"text\", \"TEXT\").put(\"dropdown\", \"INT\").build();`\n",
      "Those strings could be also reused or extracted.\n",
      "Also there are countless occurrences of various column type names scattered in the code.\n",
      "If the scope of this ticket is to refactor the codebase from database specific column type names, I will gladly do it but I don't think now is the time, it does not bring any real value. Nobody will search the entire codebase in a approx ~423.000 line project for reusable texts for words like \"boolean\" and \"integer\"., Label: 0\n",
      "Processing row 2931 - Data Type: val, Message: I used the same syntax as before. There are numerous cases around the project., Label: 0\n",
      "Processing row 2932 - Data Type: train, Message: the problem with this is that the queryForRowSet method has 2 different signatures:\n",
      "public SqlRowSet queryForRowSet(String sql, Object[] args, int[] argTypes) \n",
      "public SqlRowSet queryForRowSet(String sql, @Nullable Object... args)\n",
      "if I omit the object array, it will resolve to the latter and it won't take the argTypes correctly, Label: 0\n",
      "Processing row 2933 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 2934 - Data Type: train, Message: corrected, Label: 0\n",
      "Processing row 2935 - Data Type: train, Message: @galovics @vidakovic @BLasan @thesmallstar one solution to remove this constructor is to get away with the `deriveDisplayName` function as well. We can just implement the contents of that function directly inside `setDisplayName` like this - `.setDisplayName(!StringUtils.isBlank(firstname) ? lastname + \", \" + firstname : lastname)`\n",
      "\n",
      "your suggestions around this?, Label: 1\n",
      "Processing row 2936 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 2937 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 2938 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2939 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2940 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2941 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2942 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2943 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 2944 - Data Type: val, Message: Removed, Label: 0\n",
      "Processing row 2945 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 2946 - Data Type: val, Message: suggestion seems logical, Label: 0\n",
      "Processing row 2947 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 2948 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 2949 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 2950 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 2951 - Data Type: train, Message: rather create 2 more unnecessary classes than simply pass a primitive int parameter?, Label: 1\n",
      "Processing row 2952 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 2953 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 2954 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 2955 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 2956 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 2957 - Data Type: val, Message: sure, Label: 0\n",
      "Processing row 2958 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 2959 - Data Type: train, Message: Thanks @vidakovic  I am fixing this. I am having a problem though, when I updated my local code with the last, on running gradle bootRun, I get this error: \"Caused by: java.sql.SQLSyntaxErrorException: (conn=988) Table 'batch_job_instance' already exists\". How do I get past it ?, Label: 1\n",
      "Processing row 2960 - Data Type: train, Message: Updared, Label: 0\n",
      "Processing row 2961 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 2962 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2963 - Data Type: val, Message: Removed, Label: 0\n",
      "Processing row 2964 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2965 - Data Type: train, Message: Done removed!, Label: 0\n",
      "Processing row 2966 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2967 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2968 - Data Type: train, Message: default null removed.., Label: 0\n",
      "Processing row 2969 - Data Type: train, Message: Done removed!, Label: 0\n",
      "Processing row 2970 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2971 - Data Type: train, Message: This was intentional. the class with ```GetLoansLoanIdTimeline``` is already existing and they were overriding each other. , Label: 0\n",
      "Processing row 2972 - Data Type: train, Message: True!, Label: 0\n",
      "Processing row 2973 - Data Type: train, Message: Follow up tickets... should i remove them?, Label: 0\n",
      "Processing row 2974 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2975 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2976 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2977 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2978 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 2979 - Data Type: train, Message: Fair point!, Label: 0\n",
      "Processing row 2980 - Data Type: val, Message: yes, Label: 0\n",
      "Processing row 2981 - Data Type: val, Message: Greater than 0, Label: 0\n",
      "Processing row 2982 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 2983 - Data Type: val, Message: we could, however, since COB places the lock on the account, the COB busines date made more sense to me., Label: 1\n",
      "Processing row 2984 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2985 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 2986 - Data Type: train, Message: After discuss, currently not changed, because used by another method., Label: 0\n",
      "Processing row 2987 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2988 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 2989 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 2990 - Data Type: train, Message: well, I am already sanitizing the inputs, it might save?\n",
      "tried to implement other more secured ways but getting stucked in passing paramList as calling other method eg: callFilteredPgSql, Label: 0\n",
      "Processing row 2991 - Data Type: train, Message: removed it, Label: 0\n",
      "Processing row 2992 - Data Type: train, Message: removed it, Label: 0\n",
      "Processing row 2993 - Data Type: train, Message: removed it, Label: 0\n",
      "Processing row 2994 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2995 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2996 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 2997 - Data Type: train, Message: Yes, Label: 0\n",
      "Processing row 2998 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 2999 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3000 - Data Type: train, Message: renamed it, Label: 0\n",
      "Processing row 3001 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 3002 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3003 - Data Type: val, Message: added, Label: 0\n",
      "Processing row 3004 - Data Type: train, Message: you mean multiple paramameters with the \"BusinessDate\" parameter name?, Label: 1\n",
      "Processing row 3005 - Data Type: val, Message: no, it can't, Label: 1\n",
      "Processing row 3006 - Data Type: train, Message: if 1 of them is COMPLETED, then we will never take it as a running one, because the inner query., Label: 0\n",
      "Processing row 3007 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3008 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3009 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3010 - Data Type: train, Message: No, none of the others filters by id and there is an error to compare bigint ansÂ¡d string, Label: 0\n",
      "Processing row 3011 - Data Type: train, Message: If we leave the original SQL we get an error when we use more than one resource why? because the column subEntityType (as you have viewed) in almost all the SQL uses null (the null is considered as string type by the RDBMS) and in the Savings SQL filter It has a value for the Savings attribute deposit_type_enum (int type) and that difference to the RDBMS generates tan error, so It is not possible to manage after run the SQL in the mapper\n",
      ", Label: 1\n",
      "Processing row 3012 - Data Type: val, Message: @marta-jankovics I planned to do this part in the next PR. This PR just introduces submittedOnDate and initializes it. This PR might become huge if we make changes to all places where submittedOnDate is consumed.\n",
      "\n",
      "What do you think?, Label: 0\n",
      "Processing row 3013 - Data Type: train, Message: because it is static, Label: 0\n",
      "Processing row 3014 - Data Type: train, Message: Spotless, Label: 0\n",
      "Processing row 3015 - Data Type: train, Message: spotless, Label: 0\n",
      "Processing row 3016 - Data Type: train, Message: What do you mean? A util class with 10 static methods, all search related is not complex., Label: 1\n",
      "Processing row 3017 - Data Type: train, Message: After a discussion we move to another way..., Label: 0\n",
      "Processing row 3018 - Data Type: train, Message: created, Label: 0\n",
      "Processing row 3019 - Data Type: val, Message: changed, Label: 0\n",
      "Processing row 3020 - Data Type: train, Message: renamed, Label: 0\n",
      "Processing row 3021 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 3022 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 3023 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 3024 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 3025 - Data Type: train, Message: It is not, because below that we turn every Exception into PlatformInternalServerException, but I didn't want to do this with this exception.\n",
      "Log has been added though, Label: 0\n",
      "Processing row 3026 - Data Type: train, Message: Done the tc\n",
      "\n",
      "<img width=\"1411\" alt=\"Screenshot 2023-08-29 at 23 33 44\" src=\"https://github.com/apache/fineract/assets/44206706/d80b5b1a-d533-4a4f-ad20-5e96fb8d0001\">\n",
      ", Label: 0\n",
      "Processing row 3027 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3028 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 3029 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3030 - Data Type: train, Message: yes, sorry, Label: 0\n",
      "Processing row 3031 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 3032 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3033 - Data Type: train, Message: Yes. There is a validation for this situation. I am checking if enableDownPayment is false then downPayment percentage element should not be passed.\n",
      "I am not setting that to null in db if that is so., Label: 0\n",
      "Processing row 3034 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3035 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3036 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3037 - Data Type: train, Message: Setting it to be false by default for both.\n",
      ", Label: 0\n",
      "Processing row 3038 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3039 - Data Type: train, Message: Still needed for the old codes., Label: 0\n",
      "Processing row 3040 - Data Type: train, Message: Since it is an Entity class, and the create method is not static, I should pass the `ExternalIdFactory` dependency as a method parameter, etc. So it won't be very pretty I think. Is it a business requirement? In the other cases, I'll implement your change request, only this case I'm a bit hesitant. , Label: 1\n",
      "Processing row 3041 - Data Type: train, Message: Set it to the logical order so I was able to follow the process. the name of the methods did not change., Label: 0\n",
      "Processing row 3042 - Data Type: train, Message: I will need some time to check in Eclipse why I used PNAME_NS. If I remember correctly, using COLON, JavaCC would find it ambiguous with some other character or rule? \n",
      ", Label: 1\n",
      "Processing row 3043 - Data Type: train, Message: Oh, when updating the branch (it was written when Jena was 2.x) I simply applied the same changes to master.jj and sparql_11.jj, and looked at other classes that I had patched, and looked for similar classes that looked like had to be updated as well.\n",
      "\n",
      "But maybe I added Should I revert this one line?\n",
      ", Label: 1\n",
      "Processing row 3044 - Data Type: train, Message: Not sure where else it could go. I copied (shamelessly) from an example I found online while re-reading about JavaCC. With this main method, you can run the grammar in Eclipse, and in the Eclipse Console it will be waiting for a String+LFLF (two break lines IIRC).\n",
      "\n",
      "Then it will use the grammar to parse the string and will output the QueryUnit. I found it useful for reviewing the changes without running some extra class with a main method, or Fuseki.\n",
      "\n",
      "What do you think? I'm OK with removing it, or moving it somewhere else. Just don't know where else it could go :-)\n",
      ", Label: 1\n",
      "Processing row 3045 - Data Type: train, Message: @afs added this one in order to be able to use the `Query` object in some tests..., Label: 0\n",
      "Processing row 3046 - Data Type: val, Message: @afs and here, Label: 0\n",
      "Processing row 3047 - Data Type: train, Message: @afs but here I didn't have a `Node`, only the `JsonValue`, and had to convert from `JsonValue` to `String`, Label: 0\n",
      "Processing row 3048 - Data Type: val, Message: Yeah, I meant to ask about that. That (copying/freezing) the context was causing tests to fail in [TestAuth](https://github.com/apache/jena/blob/master/jena-fuseki1/src/test/java/org/apache/jena/fuseki/TestAuth.java#L204), because those tests involve possibly retrieving a client from the context inside `QueryEngineHTTP`. (The old form was to retrieve an `HttpAuthenticator` from the context.) Those tests first built the query object and then put the config into the context, so it wasn't available at execution, because I made the retrieval of config from the context happen as late as possible, at query execution. Would you suggest having it happen earlier, at construction time for `QueryEngineHTTP`?\n",
      ", Label: 1\n",
      "Processing row 3049 - Data Type: train, Message: The comment in the code didn't really help at all. It told me what the code was doing, but not why. In fact, I still don't know why, so let me ask: why is it important to freeze the context?\n",
      ", Label: 1\n",
      "Processing row 3050 - Data Type: train, Message: I have no problem switching it back. I liked the clarity and concision of `getAndIncrement()` and `decrementAndGet()`, but maybe that's just me.\n",
      ", Label: 0\n",
      "Processing row 3051 - Data Type: train, Message: Right-- got to catch up with my own changes!\n",
      ", Label: 0\n",
      "Processing row 3052 - Data Type: val, Message: Okay.\n",
      ", Label: 0\n",
      "Processing row 3053 - Data Type: train, Message: Okay.\n",
      ", Label: 0\n",
      "Processing row 3054 - Data Type: train, Message: Ah, okay-- didn't see that.\n",
      ", Label: 0\n",
      "Processing row 3055 - Data Type: train, Message: Okay.\n",
      ", Label: 0\n",
      "Processing row 3056 - Data Type: train, Message: Okay.\n",
      ", Label: 0\n",
      "Processing row 3057 - Data Type: train, Message: Hmm, maybe I'm missing something obvious, but I need to pass the Context. I didn't find an easier way (all read methods in RDFDataMgr that take the Context as arg use the uri param to define what we read)., Label: 1\n",
      "Processing row 3058 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3059 - Data Type: train, Message: What is required is a builder that is based on another but isolated from it by cloning (or in some way) so that adding new builder settings only changes the clone, not also the original (the current active default in `HttpOp` in this case).`HttpClientBuilder` is a setter only style, you can't get settings from it (builder builder needed ?!). `RDFparserBuilder` has `clone()`.\n",
      ", Label: 0\n",
      "Processing row 3060 - Data Type: train, Message: Oh, fudge. Then we really can't have a default impl of this, can we?, Label: 0\n",
      "Processing row 3061 - Data Type: train, Message: I didn't do that at first because it felt like a bit of a conflict against the rest of the API for `Dataset`, which discusses models/graphs and not tuples. But if you're okay with it, it doesn't bother me., Label: 0\n",
      "Processing row 3062 - Data Type: train, Message: @afs  Better?, Label: 0\n",
      "Processing row 3063 - Data Type: train, Message: This being said, what would you rather see? This issue is titled _Jena master does not build under JDK10_ so I wonder if getting Jena to build under JDK 10 is the immediate response. Someone can then go and work on the underlying logging issue. Right now I have not investigated it enough or else I would have provided the fix. , Label: 1\n",
      "Processing row 3064 - Data Type: train, Message: Yeah that works great - I've just pushed the change.\n",
      "\n",
      "The previous implementation was left over from when I was doing that `/$/extras/*` stuff that's gone now, Label: 0\n",
      "Processing row 3065 - Data Type: train, Message: Changed :+1: , Label: 0\n",
      "Processing row 3066 - Data Type: train, Message: Changed :+1: , Label: 0\n",
      "Processing row 3067 - Data Type: train, Message: certainly a genuine mistake here. System.out.println and quick tests should have no place here., Label: 0\n",
      "Processing row 3068 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3069 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3070 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3071 - Data Type: train, Message: My experience is that ADD runs each time, presumably because it does not know whether the file at the URL has changed. If it was a local filesystem file, it has more to go on, e.g. file modification time, but for a URL that information isn't there.\n",
      "\n",
      "Maybe I was using it wrongly; I didn't chase it further because you are spot-on that it does not check the checksum, and with large files from maven.central I have had a partial download during a docker build.\n",
      "\n",
      "At Â£job, we run the process from `make`.  It is the `Makefile` that downloads and caches the file then docker `COPY`s from local filesystem into the docker container build. But that assumes a `make` setup so I put it the steps in the build stage of the Dockerfile.\n",
      "\n",
      "All that said, I don't use docker that much so advice on better practice is very welcome, especially if attached to a PR!\n",
      ", Label: 0\n",
      "Processing row 3072 - Data Type: train, Message: I was doing the same as it is being done in [JsonLdWriteContext](https://github.com/apache/jena/blob/master/jena-arq/src/main/java/org/apache/jena/riot/JsonLDWriteContext.java#L43). Why would it work for the writer and not for the reader? \n",
      "\n",
      "The only thing this class is doing is to forward the set method calls to the parent context. It is just a helper for people who wants to create a JsonLdReaderContext (same as right now with JsonLdWriterContext). But the class hierarchy here doesn't matter, Label: 1\n",
      "Processing row 3073 - Data Type: train, Message: Same argument goes here: I was trying to build it consistent to the [JsonLdWriter](https://github.com/apache/jena/blob/master/jena-arq/src/main/java/org/apache/jena/riot/writer/JsonLDWriter.java#L99).\n",
      "\n",
      "But I can keep it if you prefer. Right now I flagged it as deprecated., Label: 0\n",
      "Processing row 3074 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3075 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3076 - Data Type: train, Message: We must implement `ReportConstraint.visit(ConstraintVisitor)`, though. Empty implementation for minimal friction?, Label: 0\n",
      "Processing row 3077 - Data Type: train, Message: `JSON.parse` throws an error when calling it for `x` because the root type of the JSON returned is a list, not an object. I opted to not update the parser to handle lists because it seemed silly to update it for this one test., Label: 0\n",
      "Processing row 3078 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 3079 - Data Type: val, Message: The reason that I coded it this way is so that the following will both trigger a deletion: `http//url/?deleteOld` & `http//url/?deleteOld=true`. Since `deleteOld` is a boolean/flag parameter, its mere presence implies `true` if no explicit value is set. This is pretty common for boolean query params in my experience., Label: 0\n",
      "Processing row 3080 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3081 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3082 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3083 - Data Type: train, Message: The next line is :  \"result.add( t.getSubject(), RDF.type, type );\" --> so it was mutating the source of the iterator.\n",
      "That worked with GraphMem because its iterator was counting backwards. But I guess it would also have caused an error if the array needed to resize due to the .add() operation., Label: 0\n",
      "Processing row 3084 - Data Type: train, Message: I am not totally sure what setup you prefer here - the poms of which modules should be adjusted and how?\n",
      "\n",
      "The current functionality of the serviceenhancer extension works with fuseki without the need for a fuseki module - the java service loader of the serviceenhancer registers an assembler that can be used to construct a dataset that can be exposed via a fuseki service.\n",
      "That means that just adding the serviceenhancer plugin as a dependency to fuseki directly would so far be sufficient to enable configuration via assembler.\n",
      "\n",
      "There is another issue however which I am not sure how to tackle best: Execution of the `<java:org.apache.jena.sparql.service.enhancer.function.cacheInvalidate>` function should be restricted to only authorized users. Otherwise malicious agents could disrupt a service by constantly invalidating all caches. \n",
      "\n",
      ", Label: 1\n",
      "Processing row 3085 - Data Type: train, Message: What do you mean here concretely? Do you mean I should remove the unwrapping `((QueryExecutionBuilderAdapter)builder).getExecBuilder()` in `adapt()` or am I overlooking something else?, Label: 1\n",
      "Processing row 3086 - Data Type: train, Message: I cannot really defend this addition. @Aklakan can you?, Label: 0\n",
      "Processing row 3087 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3088 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3089 - Data Type: train, Message: Hm, the squashing breaks the code references... Anyway, the raiseException method now attempts to use the response charset and falls back to UTF8., Label: 0\n",
      "Processing row 3090 - Data Type: train, Message: Removed the if statement (I was incorrectly assuming there could be a return value of -1 like the read method on InputStream), Label: 0\n",
      "Processing row 3091 - Data Type: train, Message: > `ShexMap.Builder` is active code.\n",
      "\n",
      "Outright? without a depcrecation?\n",
      "If so, should I foce-push, #1584 and rebase the branches backing #1585 and #1586?, Label: 1\n",
      "Processing row 3092 - Data Type: train, Message: would that have any advantage over or be significantly differnt from QueryIterPlainWrapper(Iter.flatMap)? Note how both cases seem to involve a QueryIterPlainWrapper , Label: 1\n",
      "Processing row 3093 - Data Type: train, Message: so am I! fixed, Label: 0\n",
      "Processing row 3094 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3095 - Data Type: train, Message: In this case, the original exception will in the function called, not with a deeper stack. There isn't more context. The effect is to change the name of the exception to `FusekiConfiguration`., Label: 0\n",
      "Processing row 3096 - Data Type: val, Message: With respect to my comment below, if there is a limit, then we apply the rule, otherwise we do not (regardless of offset).\n",
      " I may have the wrong idea here, but based on my understanding of offset, all of the test cases pass as expected. Are the test cases I have laid out in CalciteIT what you would expect?\n",
      ", Label: 1\n",
      "Processing row 3097 - Data Type: train, Message: This does definitely have ripple effects throughout, but I had done this on the basis that SQL only allows an offset if their is an imposed limit.\n",
      "\n",
      "Hence, the design is constrained to the following 3 cases\n",
      "1. offset is null, limit not null;\n",
      "2. offset not null, limit is not null;\n",
      "3. offset and limit are both null;\n",
      ", Label: 1\n",
      "Processing row 3098 - Data Type: train, Message: @maryannxue added a commit to detect for any distinct calls that aren't of type COUNT. Thanks!, Label: 0\n",
      "Processing row 3099 - Data Type: train, Message: While that was my initial thinking, upon looking deeper I discovered a different source for the issue\n",
      "\n",
      "The reason a ServerProject was being created was because of visitCall(). It wasn't recursively checking for sequences. Therefore, when an operator like SqlKind.PLUS was present and the sequence was present, the sequence would be pushed down to a child operand and not be seen by visitCall()\n",
      "\n",
      "PhoenixConverterRules is designed so that a ServerProject does not get created if a sequence is present\n",
      "\n",
      " \n",
      " ```\n",
      "private static Predicate<LogicalProject> NO_SEQUENCE = new Predicate<LogicalProject>() {\n",
      "            @Override\n",
      "            public boolean apply(LogicalProject input) {\n",
      "                return !CalciteUtils.hasSequenceValueCall(input);\n",
      "            }            \n",
      "        };\n",
      "```, Label: 0\n",
      "Processing row 3100 - Data Type: train, Message: Per above I don't believe so, Label: 1\n",
      "Processing row 3101 - Data Type: train, Message: ok. , Label: 0\n",
      "Processing row 3102 - Data Type: train, Message: Agreed. Let us move this to another jira, which I will log and work on after Loadbalancer patch is accepted. Let me know if that make sense ? , Label: 0\n",
      "Processing row 3103 - Data Type: train, Message: If the interface is defined in phoenix-queryserver moduleand implementation in phoenix-Load-balancer module, will it not make loadbalancer module depend on phoenix-queryserver module for compile time ( via maven). Which bring us back to same issue ?, Label: 1\n",
      "Processing row 3104 - Data Type: train, Message: removed. , Label: 0\n",
      "Processing row 3105 - Data Type: train, Message: I think we don't need this change. So I didn't include this change in the new commit. What do you think?, Label: 1\n",
      "Processing row 3106 - Data Type: train, Message: I think this is correct because this variable is used as the first argument of ensureTableCreated method and it doesn't expect a physical table name but a phoenix table name.\n",
      "Also,  this variable is used by the following code but it expects a phoenix table name as well.\n",
      "\n",
      "```\n",
      "            ensureViewIndexTableCreated(\n",
      "                    SchemaUtil.getPhysicalHBaseTableName(tableName, isNamespaceMapped, tableType).getBytes(),\n",
      "                    tableProps, familiesPlusDefault, MetaDataUtil.isSalted(m, kvBuilder, ptr) ? splits : null,\n",
      "                            MetaDataUtil.getClientTimeStamp(m), isNamespaceMapped);\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 3107 - Data Type: train, Message: I added \"schemaName\" as an argument to this method.\n",
      "I think we need both schemaName and tableName to handle a table like \"AAA.BBB\" in default schema correctly, because if we have only the table name \"AAA.BBB\", we can't distinguish between \"AAA.BBB\" in the default schema and \"BBB\" in \"AAA\" schema.\n",
      "\n",
      "Also we don't need the \"type\" argument, so I deleted it.\n",
      ", Label: 0\n",
      "Processing row 3108 - Data Type: train, Message: As per this comment, the 4 methods (getPhysicalTableName, getPhysicalName) can return an unexpected value. \n",
      "I don't believe this situation has been seen in the wild as-of-yet, however users should be aware of this behaviour., Label: 1\n",
      "Processing row 3109 - Data Type: train, Message: Hi @joshelser,\n",
      "Is there a way to check if builder called withRemoteUserExtractor or not? I tried used \"equals\" but there will always be two new builder object to compare. Also there is no getRemoteUserExtractor method for HttpBuilder.\n",
      ", Label: 1\n",
      "Processing row 3110 - Data Type: train, Message: Done, also removed `maybeDemote`, Label: 0\n",
      "Processing row 3111 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3112 - Data Type: train, Message: @maryannxue I've changed the code here to use the `usePersistentCache` flag, but I'm not sure how to force a `HASH_BUILD_LEFT` strategy. The test I've put in the integration test file does not actually use that strategy. Do you know of an easy way to force a left table hash join?, Label: 1\n",
      "Processing row 3113 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3114 - Data Type: train, Message: ~~I'll give this one more shot in a bit~~\n",
      "deleted all references to kinit , Label: 0\n",
      "Processing row 3115 - Data Type: train, Message: Yes mini KDC will render a krb5.conf file, however it is useless on MAC OS as Heimdal seemingly decided to want to specify protocols as opposed to trying them all.  This has been fixed but Apple has not packaged it yet I guess, Label: 0\n",
      "Processing row 3116 - Data Type: train, Message: Do I need to add something like this?\n",
      "\n",
      "phoenix_opts= os.getenv('PHOENIX_OPTS', '')\n",
      "......\n",
      "if hbase_env.has_key('PHOENIX_OPTS'):\n",
      "    phoenix_opts= hbase_env['PHOENIX_OPTS']\n",
      ".....\n",
      "java_cmd = '%(java)s  ' + phoenix_opts + \\\n",
      "...., Label: 0\n",
      "Processing row 3117 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 3118 - Data Type: train, Message: @ankitsinghal  Sorry, I didn't update the PR with all my latest changes, I fixed this. Can you please review?, Label: 0\n",
      "Processing row 3119 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3120 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3121 - Data Type: train, Message: I will also soon add a test that disables these metrics as well.\n",
      "> I'd switch this around to iterate over your expectations, ensuring that they all exist.\n",
      "\n",
      "The reason why I didn't do it that way because I didn't wanted to iterate over the it for every expected metric. It doesn't really matter since its a test though. One approach can be to remove each entry from the map and check if the size is 0 at the end. How does that sound?, Label: 1\n",
      "Processing row 3122 - Data Type: val, Message: Actually I added this since this is going to be a part of PQS, where having these metrics would help. Should I cover this with a config parameter then?, Label: 1\n",
      "Processing row 3123 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3124 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3125 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3126 - Data Type: train, Message: @twdsilva Just for clarification. Do you mean to add a new column like\n",
      "`optional bytes viewIndexLongId = 13;`\n",
      "and then retire viewIndexId in the next version. \n",
      "This make sense but I only don't understand why the new property cannot be a optional int64? , Label: 1\n",
      "Processing row 3127 - Data Type: train, Message: @twdsilva @JamesRTaylor \n",
      "I just ran into this:\n",
      "https://developers.google.com/protocol-buffers/docs/proto#updating\n",
      "```\n",
      "int32, uint32, int64, uint64, and bool are all compatible â€“ this means you can change a field from one of these types to another without breaking forwards- or backwards-compatibility. If a number is parsed from the wire which doesn't fit in the corresponding type, you will get the same effect as if you had cast the number to that type in C++ (e.g. if a 64-bit number is read as an int32, it will be truncated to 32 bits)\n",
      "``` \n",
      "If I understand it correctly, we can just add the `indexType` column to the .proto wherever we have viewIndexId and change the `viewIndexId` type from `int32` to `int64` without any side effect for old clients and hence we won't need to add `viewIndexLongId` and PHOENIX-4838.\n",
      "Am I missing anything?, Label: 1\n",
      "Processing row 3128 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 3129 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3130 - Data Type: train, Message: @twdsilva Is this comment just to keep track of the fact that we need to remove this after all of splittable SYSCAT is implemented or is there anything specific to PHOENIX-4763?, Label: 1\n",
      "Processing row 3131 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 3132 - Data Type: train, Message: will do, Label: 0\n",
      "Processing row 3133 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 3134 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 3135 - Data Type: val, Message: Ok, Label: 0\n",
      "Processing row 3136 - Data Type: train, Message: I don't understand this is standard in this file see lines 105,262 etc.  And standard in the formatter. I believe this is the correct line for this comment because of the above., Label: 1\n",
      "Processing row 3137 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 3138 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 3139 - Data Type: train, Message: The entire test suite uses hard coded values. This test suite needs to be restructured so that these values are set using a formula. At this moment, this test suite is useless to me since the expected value is set to the actual value manually., Label: 0\n",
      "Processing row 3140 - Data Type: val, Message: Sure, Label: 0\n",
      "Processing row 3141 - Data Type: train, Message: Agree, Label: 0\n",
      "Processing row 3142 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3143 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 3144 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3145 - Data Type: train, Message: IndexToolIT also has arglist format. Shall I change it to parameter?, Label: 0\n",
      "Processing row 3146 - Data Type: train, Message: I am not sure if exponential backoff is necessary here. It doesn't take a lot of time to wait till indexes are build in the tests., Label: 1\n",
      "Processing row 3147 - Data Type: train, Message: This is auto generated. I don't think I can get rid of 'is' part, Label: 1\n",
      "Processing row 3148 - Data Type: train, Message: Also, I prefer isRebuildAll because this is just returning the boolean parameter. However, rebuildAll suggests a function name where you actually rebuild the index. It is harder to read the code that way., Label: 0\n",
      "Processing row 3149 - Data Type: train, Message: Please ignore this file. mistakenly got pushed. , Label: 0\n",
      "Processing row 3150 - Data Type: train, Message: I don't know more than using a parameterized framework. Do you have other suggestions?, Label: 1\n",
      "Processing row 3151 - Data Type: train, Message: Not that I am aware of, but I 'll find it if there is something like this, it will certainly benefit such a long list of parameters. \n",
      "\n",
      "Yes, it was overkill to fit transactions scenario also in the same test suite, plus my IDE would run out of memory in running more than 128 tests in a single program.  , Label: 0\n",
      "Processing row 3152 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3153 - Data Type: train, Message: ack, Label: 0\n",
      "Processing row 3154 - Data Type: train, Message: Will do, Label: 0\n",
      "Processing row 3155 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3156 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3157 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3158 - Data Type: train, Message: At this point the problem arose due to table name is being cached in tableCache variable at HBase level. Could not find a way to invalidate it, hence the RPC.  any suggestion? @gjacoby126 , Label: 0\n",
      "Processing row 3159 - Data Type: train, Message: @kadirozde Looks like the addendum patch didn't make it to 4.x branches? removing the repeated lines in my patch. , Label: 0\n",
      "Processing row 3160 - Data Type: train, Message: Should be fine, this class is only used in this file. Didn't involve any broader implications. , Label: 0\n",
      "Processing row 3161 - Data Type: val, Message: I tried, it didn't look good. :( , Label: 0\n",
      "Processing row 3162 - Data Type: train, Message: @twdsilva makes sense. I will handle that as part of PHOENIX-5544. Do the other changes to support creating/dropping a table look good?, Label: 1\n",
      "Processing row 3163 - Data Type: train, Message: For some reason, my IDE isn't marking these as unused imports so I must have missed them. Removing now, Label: 0\n",
      "Processing row 3164 - Data Type: train, Message: This and the previous exception are to catch \"impossible\" cases. Now that you asked, I want to check more time if they really cannot happen. Maybe logging error and skipping could be safer as you suggested., Label: 0\n",
      "Processing row 3165 - Data Type: train, Message: I would prefer waiting each time there is an immutable table if invalidating cache is not an option. what say?, Label: 1\n",
      "Processing row 3166 - Data Type: train, Message: The main part I could use a double-check on... Did I understand the purpose of SCAN_ACTUAL_START_ROW correctly?\n",
      "From looking at the code and going by the name it's the start row of the scan that we can use in Phoenix to restart the scan (and that can happen exactly when a split occurred and the scanner was restarted by HBase with the new region start key - assuming it fell into the second daughter region). If that is indeed the right interpretation that this should be correct., Label: 1\n",
      "Processing row 3167 - Data Type: val, Message: Hmm... Good point. Not sure how this test passes., Label: 1\n",
      "Processing row 3168 - Data Type: val, Message: @kadirozde ï¼Œ seems that I added your \n",
      "else {\n",
      "scan.setRaw(false);\n",
      "scan.setMaxVersions(1);\n",
      "}\n",
      "The ConcurrentMutationsIT.testDeleteRowAndUpsertValueAtSameTS1 is failed.\n",
      ", Label: 0\n",
      "Processing row 3169 - Data Type: train, Message: 1. Yes , we can guarantee that all cells in a mutation have the the same timestamp \n",
      "    because the previous IndexManagementUtil.flattenMutationsByTimestamp. I would add more comments for it.\n",
      "2. What the logic do you mean? the logic getMaxTimestamp here is not in \n",
      "    CachedLocalTable, do you mean the \n",
      "    mutation.getFamilyCellMap().values().iterator().next().get(0).getTimestamp() ?\n",
      "\n",
      ", Label: 1\n",
      "Processing row 3170 - Data Type: val, Message: @gjacoby126 Removed the check, thanks for explanation. Can you please re-review?, Label: 0\n",
      "Processing row 3171 - Data Type: train, Message: So that I can pass null. It does null check. With Integer you know it is not set. With int, you dont, Label: 0\n",
      "Processing row 3172 - Data Type: train, Message: I don't think we support nested arrays in Phoenix as a column type, Label: 1\n",
      "Processing row 3173 - Data Type: val, Message: Would you prefer this investigation and adding of tests be done under a separate JIRA? Or this one itself?, Label: 1\n",
      "Processing row 3174 - Data Type: train, Message: Changed the code. , Label: 0\n",
      "Processing row 3175 - Data Type: train, Message: We want to retry in case of interruption during sleep. And only try a finite number of times. I think for this corner case scenario, we are okay if we see any problem with cache incoherency. What say?, Label: 1\n",
      "Processing row 3176 - Data Type: train, Message: Is this one better, VERIFY_COUNT_ASSERT_MESSAGE?, Label: 1\n",
      "Processing row 3177 - Data Type: train, Message: Not sure how we can do that, Label: 1\n",
      "Processing row 3178 - Data Type: train, Message: This is an old version I guess. , Label: 0\n",
      "Processing row 3179 - Data Type: train, Message: this clock change has to happen before the target table is queried and hence the name, Label: 0\n",
      "Processing row 3180 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3181 - Data Type: train, Message: The logic was a little different from checking a cellTs directly, in the sense that it requires finding the max ts first amongst different cells in the put, just that the comparison part is common. Didn't feel very strongly about creating a different function for that., Label: 0\n",
      "Processing row 3182 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3183 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3184 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3185 - Data Type: train, Message: I got the calculateTheClosestNextRowKeyForPrefix method from HBase 3.0. When we start using HBase 3.0, we can remove this local copy. It seems Bytes.incrementBytes does something similar but not exactly the same, I think., Label: 1\n",
      "Processing row 3186 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 3187 - Data Type: val, Message: We do not know upfront if the family or column delete cell refers to exists in the mutation. It may or may not exist., Label: 1\n",
      "Processing row 3188 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3189 - Data Type: train, Message: The EmptyColumnIT tests do an exhaustive verification around that condition. Let me know if there is anything missing?, Label: 1\n",
      "Processing row 3190 - Data Type: train, Message: Nope!, Label: 0\n",
      "Processing row 3191 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 3192 - Data Type: train, Message: @priyankporwal @kadirozde @gjacoby126 @swaroopak , can you help to review when you get a chance. \n",
      "For some reason, it looks like I don't have permission to add reviewers., Label: 0\n",
      "Processing row 3193 - Data Type: train, Message: I know it's going to be false. , Label: 0\n",
      "Processing row 3194 - Data Type: train, Message: fixed\n",
      ", Label: 0\n",
      "Processing row 3195 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 3196 - Data Type: train, Message: which log line are you talking about? The comment says it is SCN query., Label: 1\n",
      "Processing row 3197 - Data Type: train, Message: Changing so is failing the tests that I added. We can pass this refactoring for followup if you would like?, Label: 0\n",
      "Processing row 3198 - Data Type: val, Message: Sure, Label: 0\n",
      "Processing row 3199 - Data Type: train, Message: We could but I'm not sure there is much benefit end client can't really act differently.  Is logging sufficient?, Label: 1\n",
      "Processing row 3200 - Data Type: train, Message: I was trying to leave this condition the same as before thus combining both connection counts.  This appears to me to be sequence handling for no connection open., Label: 1\n",
      "Processing row 3201 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3202 - Data Type: train, Message: Not currently, Label: 0\n",
      "Processing row 3203 - Data Type: train, Message: This is only used currently by the old index design. I would not want to invest on it. Also, because of ungroupedAggregateRegionObserver.checkForRegionClosing(), it cannot go into a util call., Label: 0\n",
      "Processing row 3204 - Data Type: train, Message: It is just a little optimization for run-time checking by mapping the empty map case to the null map case so we do not check both. This check is done for every cell scanned. This code is not introduced in this PR is just moved to here., Label: 0\n",
      "Processing row 3205 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3206 - Data Type: train, Message: Switched to \"ERROR\" to encompass both INVALID and MISSING., Label: 0\n",
      "Processing row 3207 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 3208 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 3209 - Data Type: train, Message: This check is during the createTable flow. Moreover the current code does not allow for easy client-side checks for TableProperty changes during alter command., Label: 0\n",
      "Processing row 3210 - Data Type: train, Message: Actually it is null in this case because for the test, rootCause is not provided here (BaseResultIterators):\n",
      "```\n",
      "    throw new SQLExceptionInfo.Builder(OPERATION_TIMED_OUT).setMessage(\n",
      "            \". Query couldn't be completed in the allotted time: \"\n",
      "                    + queryTimeOut + \" ms\").build().buildException();\n",
      "```\n",
      "However, I tested by manually adding rootCause and receiving on test side. Hence, it is working fine but since relevant source code does not add root cause, `e.getCause() != null` would not be true here., Label: 0\n",
      "Processing row 3211 - Data Type: train, Message: It's being used here also, hence kept it for simplicity:\n",
      "```\n",
      "                table = table.replace(QueryConstants.NAME_SEPARATOR,\n",
      "                    QueryConstants.NAMESPACE_SEPARATOR);\n",
      "```\n",
      "Is that fine keeping `table` as is? It might look simplified. Thought?, Label: 1\n",
      "Processing row 3212 - Data Type: train, Message: > This scenario is the same as returning null from the previous getSysMutexPhysicalTableNameBytes() method and then attempting to retrieve a null table.\n",
      "\n",
      "Basically, we are certain that either `SYSTEM.MUTEX` or `SYSTEM:MUTEX` exist at any point in time right? e.g if we are performing namespace upgrade (e.g MigrateSystemTablesToSystemNamespaceIT test), when SYSTEM.MUTEX no longer exists, if we call `HBaseFactoryProvider.getHTableFactory().getTable()`, it does return `Table` object, it doesn't return null as such. However, using that table object, we can't perform any operation because actual table would not exist.\n",
      "As for this comment, the scenario is not same as previous `getSysMutexPhysicalTableNameBytes()` because when we reach at this point, based on above `Admin.tableExists()` call, we would call `connection.getTable()` with correct table name only (I hope we never have situation where SYSTEM.MUTEX and SYSTEM:MUTEX both are dropped. Should we really worry about this case?)\n",
      ", Label: 1\n",
      "Processing row 3213 - Data Type: val, Message: On high level, `connection.getTable()` will never return `null`, it will return new `Table` object even for non existing tables, so we won't encounter NPE due to this for sure. However, I believe we should make just one API call `admin.tableExists()` so that we will know either `SYSTEM.MUTEX` or `SYSTEM:MUTEX` exist at any time. Sounds good?, Label: 1\n",
      "Processing row 3214 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3215 - Data Type: train, Message: I could find `UpgradeInProgressException`, `UpgradeNotRequiredException` and `UpgradeRequiredException`. Perhaps they don't fit well here? Thought?, Label: 1\n",
      "Processing row 3216 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3217 - Data Type: train, Message: I did not really change the behavior here and thus I did not change the comment. If there is no row in the table, we should still get a result object with the zero row count. This is all what the comment tries to communicate., Label: 0\n",
      "Processing row 3218 - Data Type: train, Message: UARO did not do anything. With this change, only the last page is repeated not the entire table region., Label: 0\n",
      "Processing row 3219 - Data Type: train, Message: It has a BOTH option which is not supported that is why I didn't want to use it., Label: 0\n",
      "Processing row 3220 - Data Type: train, Message: By default, we are going to use the data table as the source which is what the current behavior is. We have to return a string from which the appropriate enum is constructed. I am not sure what is the question here., Label: 1\n",
      "Processing row 3221 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 3222 - Data Type: train, Message: Is it possible to have a column with a column family name and a column qualifier name such that the byte array representation of these names map to empty byte array? I assume it is not possible. How do you even express that within a SQL statement? , Label: 1\n",
      "Processing row 3223 - Data Type: val, Message: Ok, Label: 0\n",
      "Processing row 3224 - Data Type: train, Message: @gjacoby126  Could you please advise whether should we add the attribute here ? This codepath is used when we drop the column which will in turn generate Delete Marker. , Label: 0\n",
      "Processing row 3225 - Data Type: val, Message: You cannot create a view with fixed with nullable pk. It returns error.\n",
      "\": PK columns may not be both fixed width and nullable: DATE_TIME2\", Label: 0\n",
      "Processing row 3226 - Data Type: train, Message: @bharathv creation was not an issue, I can plug it in easily, the problem was the cleanup part, which I was not able to figure out right spot to do that., Label: 0\n",
      "Processing row 3227 - Data Type: train, Message: @shahrs87 There were two levels of subdirectories getting created for snapshot restore on every scan: \n",
      "https://github.com/apache/phoenix/blob/55f1362fc52eeabed139728dae153518883743a5/phoenix-core/src/main/java/org/apache/phoenix/mapreduce/util/PhoenixMapReduceUtil.java#L185\n",
      "\n",
      "https://github.com/apache/phoenix/blob/55f1362fc52eeabed139728dae153518883743a5/phoenix-core/src/main/java/org/apache/phoenix/iterate/TableSnapshotResultIterator.java#L81\n",
      "\n",
      "I have removed those in the original flow so now the directory gets cleaned up every single scan and gets created again for the next scan with the same directory structure. \n",
      "\n",
      "I can assert here no existence of the restore directory in the original flow. , Label: 0\n",
      "Processing row 3228 - Data Type: train, Message: Okk I think we better let cluster shutdown happen the way it does today. We better use `finally` with catching storeFile refCount leak assertion catch so that not only we fail test but also let resources be freed up in individual test's `finally` block. I was thinking of taking care of cluster shutdown in `BaseTest` only as generic check, but now it seems better let individual test decide what they want to free up - cluster or just drop table or anything as per it's current behaviour.\n",
      "The only problem with current approach (generic freeup resource in `BaseTest`) is that if refCount leakage is encountered in one test and if we shutdown miniCluster in `@After`, other tests in that class will not run anyways.\n",
      "\n",
      "@stoty you are also fine with having `finally` in each test right?, Label: 0\n",
      "Processing row 3229 - Data Type: train, Message: For 4.x `Uninterruptibles` is in beta version based on guava version that we use so i used this: https://github.com/apache/phoenix/pull/1097/files#diff-d12329d4796498b9880a54bb4b6d681f7ee42b924536bf5247791f372329cd9fR61\n",
      "However, i feel using `Uninterruptibles.sleepUninterruptibly` more comfortably as we don't have to catch `InterruptedException` and it is not interruptible. But i agree with your point on not introducing more dependency so let me replicate same logic as 4.x., Label: 0\n",
      "Processing row 3230 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3231 - Data Type: train, Message: > In this case, we should rename the profile names, as 2.4 working with 2.4.0 instead of the latest version is counter-intuitive.\n",
      "\n",
      "Agree, sounds good.\n",
      "\n",
      "> The other soultion, that I originally had in mind was to map the profiles to the latest supported patch level, and only build official binaries for those.\n",
      "\n",
      "Hmm, although this is doable but for latest releases, it might not be in our best interest to make users stick to a particular patch release? \n",
      "On the other hand, we could make decisions on the basis of the what urgency does HBase patch release bring? For instance, 2.4.1 has some critical authorization fixes, which made 2.4.1 to come out way ahead of the schedule. For such urgent releases, it might be good to support them sooner, but for non-critical patch release that cause compatibility issues in Phoenix, we might want to wait little longer.\n",
      "\n",
      "Anyways, if you are fine with supporting first approach (new profile for 2.4.1), I will also raise another Jira to remove HBase 2.1 support in Phoenix 5.2. One less profile for 5.2 for now. WDYT?\n",
      "\n",
      "Moreover, I understand the pain with ever increasing profiles. As far as running tests are concerned in multibranch, perhaps, we could limit it to latest 4 profiles?, Label: 1\n",
      "Processing row 3232 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 3233 - Data Type: val, Message: removed, Label: 0\n",
      "Processing row 3234 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 3235 - Data Type: train, Message: There is no index defined yet. This change addresses the problem on the data table., Label: 0\n",
      "Processing row 3236 - Data Type: train, Message: Property multimap is formed with String and Pair as a key-value. Key for all properties pair is same \"\" but the value(pair of property key, value) is different. I had to stick to this to create a new CreateTableStatement. Not sure if I misunderstood your suggestion. LMK., Label: 0\n",
      "Processing row 3237 - Data Type: train, Message: That's a valid point, I am thinking to create a new Jira which will validate if the statements are valid on the mini-cluster (as parsing won't catch this and similar problem) and then only proceed for synthesis. Does that sound okay?, Label: 1\n",
      "Processing row 3238 - Data Type: val, Message: This dependency is removed because it is a duplicate of another one at line 125.\n",
      "Let me know if it should be in a separate PR!, Label: 0\n",
      "Processing row 3239 - Data Type: train, Message: This from_table_name can be actually a view or index table as well.\n",
      "https://github.com/apache/phoenix/blob/9b76bd51c86faea117d963b8fc033dbfef647d47/phoenix-core/src/main/antlr3/PhoenixSQL.g#L1129\n",
      "\n",
      "It is already working for views and for indexes as well. I added some tests to be sure.â€¨ Istvan was in the favour of naming this SHOW CREATE STATEMENT as it works for views and indexes as well.â€¨â€¨\n",
      "\n",
      "In case we chose to rename it to SHOW CREATE TABLE, should it work for views and indexes as well or Do you think those should be separate commands?, Label: 1\n",
      "Processing row 3240 - Data Type: train, Message: I wanted to handle the exception to minimise the effect of this change in case the optimize() throws an Exception.\n",
      "Even if we handle the exception here (in the DeclareCursorCompiler) later optimize() will be called on the CursorFetchPlan and the Exception would be thrown there so it doesn't really makes sense to handle it here probably., Label: 0\n",
      "Processing row 3241 - Data Type: train, Message: This is in the normal write path via PhoenixTransactionalIndexer, not the in the async index generation.\n",
      "\n",
      "Three-phase commit is not used in the normal TX write path, because the transactionality is taking care of the\n",
      "consistency, and accordingly it never updates the status to VERIFIED, and leaves the status as \"x\".\n",
      "\n",
      "The new parameter allows us to communicate the VERIFIED status to the actual mutation generating code a few calls down, which is used for every normal write path write by the old index implementation, without causing old-style tables set the VERIFIED status.\n",
      "\n",
      "The same basic problem pattern that BulkLoad had, and Async Indextool still has, but this one is in the normal write path.\n",
      "\n",
      "I should have called this change out explicitly, as admittedly this has the biggest impact in the patch, but forgot, sorry.\n",
      "\n",
      "This really should have been four patches (snapshot, Async VERIFIED, TX index status, and the directApi purge), but I got carried away as I kept finding the issues by the expanded test case.\n",
      ", Label: 0\n",
      "Processing row 3242 - Data Type: train, Message: Noted, Label: 0\n",
      "Processing row 3243 - Data Type: train, Message: Yes. Since java doesn't understand that it throws it every time, I put a return statement here. Will comment that it is impossible. Not needed though, Label: 0\n",
      "Processing row 3244 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 3245 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3246 - Data Type: train, Message: I think 902df17f7186b44bff48b6885a7ae60681f4088f contains this change too. , Label: 1\n",
      "Processing row 3247 - Data Type: train, Message: @stoty Can you eyeball it ?, Label: 0\n",
      "Processing row 3248 - Data Type: train, Message: @gjacoby126  Did we even release 5.0 ? I don't see it in tags here: https://github.com/apache/phoenix/tags, Label: 1\n",
      "Processing row 3249 - Data Type: train, Message: This is not quite the case here. This checks validates if every column has its qualifier. eg.\n",
      "`COL1 INTEGER, COL2 INTEGER COLUMN_QUALIFIER 13`\n",
      "In this case I don't think we can really figure out what the qualifier of COL1 should be. (it could be 11, 12), Label: 1\n",
      "Processing row 3250 - Data Type: train, Message: Actually, `updateCount` in `MutationState` gets reset when `connection.commit()` is called and since it gets called implicitly as part of `Statement.executeBatch()`, it will always be `0` if we check from this test. Do you have any idea on the appropriate location?, Label: 1\n",
      "Processing row 3251 - Data Type: val, Message: Isn't it harmless to call commit (a 2nd time) even `if (autocommit)`?, Label: 1\n",
      "Processing row 3252 - Data Type: train, Message: In this statement, a 'where' predicate, SEQUENCE_SCHEMA has already been parameterised. Can you please suggest which other predicate you are referring to?\n",
      ", Label: 1\n",
      "Processing row 3253 - Data Type: train, Message: Corrected the typo. \n",
      "\n",
      "I am reading the value of parameter from statement because my test is failing. \n",
      "I see that value of parameter is true in QueryOptimizer.addPlan,\n",
      "\n",
      "this.services.getProps().getBoolean(\n",
      "QueryServices.SERVER_MERGE_FOR_UNCOVERED_INDEX,\n",
      "QueryServicesOptions.DEFAULT_SERVER_MERGE_FOR_UNCOVERED_INDEX);\n",
      "\n",
      "despite setting it to\n",
      "\n",
      "props.setProperty(QueryServices.SERVER_MERGE_FOR_UNCOVERED_INDEX,\n",
      "    Boolean.toString(false));\n",
      "\n",
      "in the test. This is because there is nothing in the overriden values map.\n",
      "\n",
      "I verified another property USE_REVERSE_SCAN_ATTRIB and it shows the same behaviour. \n",
      "I could see appropriate value only when read from the â€˜statementâ€™ object.\n",
      "\n",
      "\n",
      "Failed Checks analysis:\n",
      "The checkstyle errors are not due to my code.\n",
      "I ran ParallelPhoenixConnectionFailureTest.testExecuteQueryChainFailure locally and it passed. \n",
      "Itâ€™s a flaky test.\n",
      ", Label: 0\n",
      "Processing row 3254 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3255 - Data Type: train, Message: Python doesn't have a ternary operator and this is the closest thing from the convenience point of view. In other words, this would be equivalent to (in java): `(! args.noconnect ? \" -u jdbc:phoenix:\" + phoenix_utils.shell_quote([zookeeper]) : \"\")`. This is not a Python expert level feature and there is nothing that is purposefully made to look cryptic., Label: 0\n",
      "Processing row 3256 - Data Type: val, Message: I made TermSource just implement AutoCloseable.  But I could make it implement SKVI instead\n",
      ", Label: 0\n",
      "Processing row 3257 - Data Type: train, Message: IOException? FileSKVIterator's override of close for AutoCloseable throws IOException...\n",
      ", Label: 0\n",
      "Processing row 3258 - Data Type: train, Message: After some discussion with @ctubbsii and @keith-turner, we were thinking of removing the \"throws Exception\".  We came to the conclusion that we don't want to assume that the close will throw an exception. This will require removing the IOException throws from FileSKVIterator.close and modifying its implementing classes to handle the IOException.  What do you think @joshelser ?\n",
      ", Label: 1\n",
      "Processing row 3259 - Data Type: val, Message: No they are not needed for compilation but since the code was failing quietly before, I didn't want to introduce an exception to classes that use FileUtil.\n",
      ", Label: 0\n",
      "Processing row 3260 - Data Type: train, Message: When I wrote that I thought it looked screwy, now I know why.\n",
      ", Label: 1\n",
      "Processing row 3261 - Data Type: train, Message: I agree it does give that connotation of planned.  Still struggling with how to write this concisely.  Suppose I could just add more words.\n",
      ", Label: 1\n",
      "Processing row 3262 - Data Type: train, Message: @ctubbsii maybe this class should not exist? Will the namespaceId every change?, Label: 1\n",
      "Processing row 3263 - Data Type: train, Message: It fails just like the previous `tool.sh` command as `accumulo-util hadoop-jar` is the same underlying logic., Label: 0\n",
      "Processing row 3264 - Data Type: train, Message: So you are not OK with the removal of `ACCUMULO_CONF_DIR + serverAccumuloConfDir`? Why do you need this? I am assuming the Accumulo installation has all server config in the default configuration directory.  We should be getting away from using `ACCUMULO_CONF_DIR` as it setting these env variables is very prone to errors. , Label: 1\n",
      "Processing row 3265 - Data Type: val, Message: re: POJO -> I was going to just use the AccumuloConfiguration and the custom properties for this. I'm not sure how a single BlockCacheConfiguration class would work across different BlockCache impls that have different configuration parameters., Label: 1\n",
      "Processing row 3266 - Data Type: train, Message: This is the one change which I'm not quite sure about.\n",
      "\n",
      "It having been there since the dawn of time and without comment, I'm really not sure what it was intended to do. This predates all of the Kerberos work -- the only thing I can think of would have been the old SecurityManager constraints (but, if memory serves, those were more around SKVI's, not reading data from HDFS).\n",
      "\n",
      "@billierinaldi, @keith-turner, @ericnewton, @scubafuchs: any guesses? :), Label: 1\n",
      "Processing row 3267 - Data Type: train, Message: Ahh, ok. Great. Not being able to attend that hackathon kept me in the dark, I guess :), Label: 0\n",
      "Processing row 3268 - Data Type: train, Message: Oh, no no no, that's not what I meant. I only meant that I didn't recall seeing you make that change. It happening at the hackathon simply explains why I missed it., Label: 1\n",
      "Processing row 3269 - Data Type: train, Message: > Are we certain we're not manipulating them in client-side javascript now? If we are, this will break that.\n",
      "\n",
      "I can double-check, but I'm not aware of that in 1.x. Not sure how the table sorting stuff works. It would be nice to quell these warnings in the future, but I may begrudgingly have to revert., Label: 1\n",
      "Processing row 3270 - Data Type: train, Message: RE: IntegrationTests which @Category class should this annotation point at?  SunnyDay?\n",
      "\n",
      "EDIT:  Also, presumably I will need to move it to the **accumulo-test** module.  I see things under src/main/java/... with test annotations in them and I see things under /src/test/java/... so which one does it go under, main or test?\n",
      "Thanks, Label: 1\n",
      "Processing row 3271 - Data Type: val, Message: I thought about this but it would require reflection or passing a pre-constructed instance object as a parameter to the method.  I wanted to avoid reflection since we lose some of the type safety. I also wanted to avoid created objects every time for parameters since they may not be needed if the map already contains the id.  \n",
      "\n",
      "Passing in a constructor object as a parameter may be a nice compromise but this introduces a bunch of potential exceptions:\n",
      "<pre>\n",
      "try {\n",
      "        id = constructor.newInstance(idString);\n",
      "      } catch (InstantiationException e) {\n",
      "        e.printStackTrace();\n",
      "      } catch (IllegalAccessException e) {\n",
      "        e.printStackTrace();\n",
      "      } catch (InvocationTargetException e) {\n",
      "        e.printStackTrace();\n",
      "      }\n",
      "      idHashMap.put(idString, new WeakReference<>(id));\n",
      "</pre>, Label: 0\n",
      "Processing row 3272 - Data Type: train, Message: I did see this happen while tinkering around with the Tests.  The keys were staying around but the WeakReference value was null., Label: 1\n",
      "Processing row 3273 - Data Type: train, Message: Cool never knew about this., Label: 0\n",
      "Processing row 3274 - Data Type: train, Message: Other than using the Function interface, this doesn't seem all that different from the reflection code that I just removed. , Label: 0\n",
      "Processing row 3275 - Data Type: train, Message: I was actually thinking how best to handle this.  It'd be an implementation error if the path to be removed wasn't in `pathModTimes`, since `deletedPaths` is a subset of `pathModTimes`.  Maybe check for existence and log an error if it doesn't exist?, Label: 1\n",
      "Processing row 3276 - Data Type: train, Message: IntelliJ gives me the suggestion: \"Modifier 'final' is redundant for interface fields\", Label: 0\n",
      "Processing row 3277 - Data Type: train, Message: Removed. Leftover from some previous incarnation of the code., Label: 0\n",
      "Processing row 3278 - Data Type: val, Message: @keith-turner I have a question concerning this. It's strightforward enough to create the new method and refactor the old. Perhaps I'm not completely versed on its usage yet, but wouldn't calling the method from NewTableConfiguration require instantiation of the TableOperationsImpl object? When I was playing around with it, this required a ClientConfiguration object which then required an Instance object,etc. It seemed to get messy attempting the call. Am I missing something obvious?, Label: 1\n",
      "Processing row 3279 - Data Type: train, Message: There is at least one more very similar instance of checkIteratorConflicts for namespaces as well. Would it make sense to create a new ticket to consolidate the various permutations of this method and perhaps place the new versions into  the iteratorUtil class where it could more easily be called by the various classes that need that check?, Label: 1\n",
      "Processing row 3280 - Data Type: val, Message: deleted., Label: 0\n",
      "Processing row 3281 - Data Type: train, Message: yes, Label: 0\n",
      "Processing row 3282 - Data Type: train, Message: no, its used for the following log message about the number of recovery logs removed, Label: 0\n",
      "Processing row 3283 - Data Type: train, Message: oh yeah, should be be 1.9.2.  Not exactly sure what you are looking for, can you give a code example?, Label: 1\n",
      "Processing row 3284 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 3285 - Data Type: train, Message: I like the simplicity of boolean but I guess I am spoiled by Intellij... When I look at a function I see: getAccumuloConfig(cryptoOn: true);\n",
      "\n",
      "In this case, keeping it a string would at least minimize the changes., Label: 0\n",
      "Processing row 3286 - Data Type: train, Message: Roger.  The link being \"REST\" OK for a name though?, Label: 1\n",
      "Processing row 3287 - Data Type: train, Message: Fixed in 0016dce1a80f7c8f8552252f148ba77f94da2725, Label: 0\n",
      "Processing row 3288 - Data Type: val, Message: Gotcha that would create the zooCache and workQueue but we would still need to assign them to a \"Mock\" version of it right?, Label: 0\n",
      "Processing row 3289 - Data Type: train, Message: Why remove the inheritance?  If we are keeping the class for backwards compatibility, removing the super class may still break existing code that uses it. \n",
      "\n",
      "Also looks like this class wasn't deprecated in 1.9: https://github.com/apache/accumulo/blob/1.9/core/src/main/java/org/apache/accumulo/core/client/ClientConfiguration.java#L61, Label: 0\n",
      "Processing row 3290 - Data Type: train, Message: Yeah I wasn't sure if we should but wanted to put this change out there for discussion.  I was trying to think of a scenario where adding this to the fluent API would break existing code..., Label: 1\n",
      "Processing row 3291 - Data Type: train, Message: Is this what you meant? 51afbce, Label: 1\n",
      "Processing row 3292 - Data Type: train, Message: Took the @code out and left the \"pre\" tags.  the @code did not really do anything useful., Label: 0\n",
      "Processing row 3293 - Data Type: train, Message: I would not expect `Map.equals()` to care about the insertion order., Label: 1\n",
      "Processing row 3294 - Data Type: train, Message: This method was unused - so I opted to remove it - the not setting to zero was an error on my part., Label: 0\n",
      "Processing row 3295 - Data Type: train, Message: I don't think the test needs more than one tserver., Label: 1\n",
      "Processing row 3296 - Data Type: train, Message: The looping seemed kinda sketchy to me, but I didn't look into it in detail., Label: 1\n",
      "Processing row 3297 - Data Type: train, Message: If on the first attempt it gets a TTransportException and on the 2nd attempt it succeeds then it seems like it could become non-null, right?  So maybe the looping is not so sketchy after all., Label: 1\n",
      "Processing row 3298 - Data Type: val, Message: Ah - I think the usage of the semicolon in my script was the reason the variable was not visible within the accumulo-service script. I guess I was going off the syntax in the [docs](https://accumulo.apache.org/docs/2.x/administration/in-depth-install#running-multiple-tabletservers-on-a-single-node) which has a semicolon between the ACCUMULO_SEVICE_INSTANCE variable and the accumulo script. I wonder now if that is a typo which needs to be addressed?, Label: 1\n",
      "Processing row 3299 - Data Type: train, Message: > This does not have to be deprecated because a new method was added. \n",
      "\n",
      "Hmm, I don't understand why adding a new method eliminates the need for deprecation. The idea here would be to remove the original `importTable(String, String)` at some point when it is safe to do so.\n",
      "\n",
      "Thanks for mentioning the Java 9 parameters. As such, I suspect the right annotation would be:\n",
      "```\n",
      "@Deprecated(since=\"2.1.0\",forRemoval=true)\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 3300 - Data Type: train, Message: > I was just thinking that adding the new method does not necessitate deprecating the existing one. The existing method is not broken in any way, it still satisfies its original functionality for anyone who invested the time to write code against it in the past.\n",
      "\n",
      "I'm happy to go either way. I suppose I'm in favor of keeping the number of public api methods to a minimum, but I don't feel strongly about leaving the existing method around if that's a better fit for the project., Label: 0\n",
      "Processing row 3301 - Data Type: train, Message: @ctubbsii @keith-turner - `Predicate.not` was added in Java 11 and I expected the build to fail when I used it, but it didn't. What runtimes are we supporting for 2.1.x?, Label: 1\n",
      "Processing row 3302 - Data Type: val, Message: This was done as part of an overall attempt take the builder interfaces in TabletsMetadata and move them to Ample, while leaving the implementation of the interfaces in TabletsMetadata.The readTablets() method in AmplImpl generates a TabletsMetadata builder object and assigns the AmpleImpl client to the public client in that builder object. This allows readTablets() to be called from a ClientContext. However, at this point, I think I should rethink the whole design because it breaks too many coding conventions (case in point, above)., Label: 1\n",
      "Processing row 3303 - Data Type: train, Message: Added UnsupportedOperationException., Label: 0\n",
      "Processing row 3304 - Data Type: train, Message: One issue with this is that there are ~15 classes that already use the pre-existing no-parameter constructor. Perhaps I should find a different way to pass the AmpleImpl Accumulo client into the TabletsMetadata builder object., Label: 0\n",
      "Processing row 3305 - Data Type: train, Message: I will add that. This is to ensure it actually grabs the port number, due to some change I made, `MasterRepairsDualAssignmentIT`fails because the portString contains more than just the port number. Example below:\n",
      "```\n",
      "38277[10005df00740005]\n",
      "```\n",
      "I'll take a look at the cause but this if statement does solve it temporarily. , Label: 0\n",
      "Processing row 3306 - Data Type: train, Message: That makes sense. I was told that was the case(only one assignment at a time) for all the stores even though we implemented it to be able to handle multiple assignments. Just to be clear, I should revert back to using collection<assignments> for these functions? , Label: 1\n",
      "Processing row 3307 - Data Type: train, Message: Thanks for pointing that out, that was something I didn't notice. I replaced with ` new Value(tServer.getLocation() + \"|\" + suspensionTime))` which more accurately matches `HostAndPort.toString()`. This also solves the issue I was facing with `MasterRepairsDualAssignmentIT` so I no longer need the if statement I added in the `HostAndPort` file.\n",
      "\n",
      "I don't fully understand your second paragraph. Are you suggesting I use the `SuspendingTServer.fromValue()` function in this mutation instead of doing the `new Value(tServer.getLocation() + \"|\" + suspensionTime))`?\n",
      ", Label: 1\n",
      "Processing row 3308 - Data Type: train, Message: Hit commit via ui, becuase - sure that's reasonable - and then decided to test - oops.  Anyway I don't think that works as intended - might be src is assumed?  Anyway, checking now..., Label: 1\n",
      "Processing row 3309 - Data Type: train, Message: Thanks for the feedback on the PR. I read back through the comments on #1086 and the comments above. My previous attempts were to create a code path through the existing objects that didn't retry instead of creating something new that also talks with ZK. It sounds as if you both might be leaning toward a solution that does not use ZooLock for the tablet server lock, but uses something else that does not retry and communicates directly with ZooKeeper. Is that correct?, Label: 1\n",
      "Processing row 3310 - Data Type: train, Message: @ctubbsii - did you want me to wait for #1459 to be completed before revisiting this?, Label: 0\n",
      "Processing row 3311 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 3312 - Data Type: train, Message: Now that you bring it up, I'm not sure that this needs to be synchronized., Label: 1\n",
      "Processing row 3313 - Data Type: train, Message: That is my mistake, this shouldn't be here. I used this to force it to hang. Forgot to remove it., Label: 0\n",
      "Processing row 3314 - Data Type: val, Message: I did find that when I CTRL-C in the middle of the help command, it does work properly. As in it throws the interrupt exception but doesn't exit the process. It only exits if I CTRL-C when just sitting in the shell. So this signal handle is at least needed for that, unsure on why it still exits when CTRL-C not during a command. , Label: 1\n",
      "Processing row 3315 - Data Type: train, Message: I am unsure if it would change anything since the terminal gets attached to the reader. We could just pass in \"terminal\" and then build the reader inside `Shell.java` so keep things consistent there. Not sure what that would gain ultimately. , Label: 1\n",
      "Processing row 3316 - Data Type: train, Message: Funny thing is, that is actually what I had originally but I changed it to mimic the parameters names for whatever reason. , Label: 0\n",
      "Processing row 3317 - Data Type: train, Message: I was trying to list only properties that are set in ZK. I couldn't find a better way to determine that, and modeled this after code in [ConfigCommand](https://github.com/apache/accumulo/blob/main/shell/src/main/java/org/apache/accumulo/shell/commands/ConfigCommand.java).\n",
      "In the case you mention, the ZK property is superfluous and really should be removed rather than renamed if it matches what's in site already, but I'm not doing that either.\n",
      "Is there another utility for retrieving ZK properties while ignoring the contents of the site file, command-line and env properties? Maybe I need to write something if not., Label: 1\n",
      "Processing row 3318 - Data Type: train, Message: I tried that, and it looks a little cleaner (and catches the edge case). In the next commit..., Label: 0\n",
      "Processing row 3319 - Data Type: train, Message: @keith-turner I'm wondering if you have any opinion on this change in particular. This change means a user would not be able to use the old property name when removing a property from zookeeper--they could only do that using the new property name. You had mentioned some concern about automation updating zookeeper properties, though setting a property using the old name is supported. Do you have any concerns here? The thinking is for a property removal it is more dangerous to assume the user meant to remove the new property name and used the old name., Label: 1\n",
      "Processing row 3320 - Data Type: train, Message: I'm in the camp of removing the replacement property if the deprecated property name is sent to remove. I've been looking at this change though we're telling users: \"Property X has been replaced by property Y, but in order to be less disruptive we are going to continue (for a short time) to allow you to use X and behind the scenes we'll replace it with Y. If you use X, it's as though you had used Y instead.\"\n",
      "\n",
      "Given that we will have documented that using X is a substitute for using Y, I'm struggling to come up with a good example where it is confusing or unexpected for the user if they use the deprecated property name with remove and we remove the replacement property (I'd say it's confusing not to do it). The only case I can come with is if the user chooses to immediately start using the new property names and then thinks they need to clean up zookeeper themselves and remove the old properties so they call remove on the old names. That usage is inconsistent with the documentation, and they'd figure it out quickly with the warning that we're removing the replacement property names instead. Are there other ways it could be confusing/unexpected for the user if we remove the replacement property when they attempt to remove the deprecated property?, Label: 1\n",
      "Processing row 3321 - Data Type: val, Message: I think that could be done. The main downside I can think of is that, when using the deprecated balancer, the params to getAssignments and balance would get converted to the new types in the master and then converted back to the thrift types in the implementation of the SPI TabletBalancer methods that then delegate to the deprecated TabletBalancer methods. I don't think the balancer methods are called often enough that we really need to worry about the performance hit, though., Label: 1\n",
      "Processing row 3322 - Data Type: train, Message: Its gone, Label: 0\n",
      "Processing row 3323 - Data Type: train, Message: Would you like me to modify the create-jshell.sh script to import all the classes from java.util.* into the jshell-init.jsh file or just go with the alternative solution?, Label: 0\n",
      "Processing row 3324 - Data Type: train, Message: Cool. I just pushed a commit to apply your double-startup option idea into the accumulo script file. Thanks for explaining the reasoning behind the --startup option. I did not consider the /reset case up until now. , Label: 0\n",
      "Processing row 3325 - Data Type: train, Message: I like the information symbol idea. I will look and see if our web deps already have an icon included. The unicode you used isn't showing up for me, Label: 0\n",
      "Processing row 3326 - Data Type: train, Message: I responded on #1940 but the short answer is no, it wouldn't make sense., Label: 1\n",
      "Processing row 3327 - Data Type: train, Message: That is what I was afraid of. Guess there isn't an easy way to guarantee validity. , Label: 1\n",
      "Processing row 3328 - Data Type: train, Message: Is there anything we should do for the default case? I currently have it verified to not be null. Not sure what else to add to the interface itself. , Label: 1\n",
      "Processing row 3329 - Data Type: train, Message: Nevermind. You are correct. I just realized the null gets thrown before reaching my validation check., Label: 0\n",
      "Processing row 3330 - Data Type: train, Message: I guess it was something on my end to create extra white space. I had what you committed before and the build failed., Label: 0\n",
      "Processing row 3331 - Data Type: train, Message: It was not clear to me that this class was immutable, since it contained multiple `setter` methods. I think a POJO with final members set in the constructor would be a lot more clear., Label: 1\n",
      "Processing row 3332 - Data Type: train, Message: I agree that this should be an IT. I was running into the issue that @Manno15 has outlined. I'm not sure what the best way to overcome this issue might be and am open to suggestions., Label: 1\n",
      "Processing row 3333 - Data Type: val, Message: ZooKeeperTestingServer does not implement auto-closable so it wont work in a regular try-with-resources block. I could either make the ZooKeeperTestingServer a member variable and use a try-finally to close it or, have a `@BeforeClass` and `@AfterClass` to initialize and then close it. Not sure which would be best in this case., Label: 1\n",
      "Processing row 3334 - Data Type: train, Message: I think the parts that have to match is the \"zlock#\" and then also end in a \"#\". The first part could definitely be placed in Constants. \n",
      "\n",
      "I guess the issue is the `CreateTable` command uses `ZooQueueLock` for creation and the `FateCommand` uses `ZooLock` for validation. , Label: 1\n",
      "Processing row 3335 - Data Type: train, Message: These changes were added to avoid spotbugs throwing  a \"Possible null pointer dereference\" error. It seems like adding the extra catch block for NPE is redundant and a single catch for `Exception` should be sufficient, however without it spotbugs will throw the mentioned error.\n",
      "\n",
      "I am wondering if it would be best to suppress spotbugs in this case and let the singular `Exception` catch block handle the NPE. I am open to suggestions on this., Label: 1\n",
      "Processing row 3336 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3337 - Data Type: train, Message: It is the same copy from: https://www.apache.org/foundation/policies/conduct. Do you say it by the title? Confusion of mine ..., Label: 1\n",
      "Processing row 3338 - Data Type: train, Message: > I don't see any reason to change the the markdown formatting to raw HTML, or change the layout/style of badges or the logo. \n",
      " \n",
      "The main idea is to make it look like this:\n",
      "![image](https://user-images.githubusercontent.com/23703592/116788862-aa202280-aab4-11eb-8e12-c4f93739098e.png)\n",
      "\n",
      "The only thing that has been modified is to make it look centered (and with that it would become an HTML format) the rest remains unchanged\n",
      "\n",
      "---\n",
      "> And, there definitely shouldn't be a change to link to vuejs's site. I assume that was copied/pasted from another project and is a mistake, but I don't think any of this should be changed at all.\n",
      "\n",
      "At the moment VueJs does not sponsor Apache ... Although I never know ... \n",
      "_This kind of 'slip' is my signature, my apologies!_\n",
      "It would be a matter of modifying the link .. :), Label: 0\n",
      "Processing row 3339 - Data Type: train, Message: Whoops !!! This change was mine in theory it should never have gotten on ..., Label: 0\n",
      "Processing row 3340 - Data Type: train, Message: Yes, Label: 0\n",
      "Processing row 3341 - Data Type: train, Message: Would this be best to do in a future PR?, Label: 1\n",
      "Processing row 3342 - Data Type: train, Message: >Also, need to handle the case that looking up the name fails, in case the table is deleted, but there is still metadata left in the metadata tablet\n",
      "\n",
      "Is there any way that I would easily be able to recreate this error in testing?, Label: 1\n",
      "Processing row 3343 - Data Type: val, Message: A single rfile will not work with RLI currently. It doesn't contain the finish marker which is looked for in rli.getFiles (that seems to be the only issue with it not working). Also, since LogReader usually deals with one directory/file at a time since it's looped through what the user passes in, I already am using a singleton list to read in that path. I could change the passed in files (opts.files in LogReader) to be a List \\<path> but it doesn't seem necessary. , Label: 0\n",
      "Processing row 3344 - Data Type: train, Message: This area of the code is still used for wal-info to read in a single wal file (just tested to confirm). I will add additional comments because I agree, it is confusing. , Label: 0\n",
      "Processing row 3345 - Data Type: train, Message: I couldn't find one and I see other parts of the code check against the extension like I did. , Label: 0\n",
      "Processing row 3346 - Data Type: train, Message: Made this change in me latest commit. , Label: 0\n",
      "Processing row 3347 - Data Type: val, Message: > Not sure from this what values are appropriate for \"args\". Are these just a list of FaTE transaction IDs to fail? The parameters to these methods could be more specific.\n",
      "\n",
      "Yes, Args will be the TiDs. Initially I was going to have it be more broad and include other things inside it. I can see how it is confusing now. Since I have parameters specifically for FilterTiDs for the print statement I could possibly combine the two parameters. , Label: 1\n",
      "Processing row 3348 - Data Type: train, Message: I was thinking that if someone specified `-Duse.qat`, then they were intending on using the device and expected it to work. The fact that it was not working in this case would be an error as maybe they have a configuration issue. Falling back to the default implementation and logging it is not honoring the users intent., Label: 1\n",
      "Processing row 3349 - Data Type: train, Message: I'd rather fail fast, rather than fail silently. From a deployment perspective, if I configure something to run a specific way, then I want it to do that or fail so I can fix it. It's not fun or easy to diagnose why something isn't working the way you expect it to. If you specify `-Xmx8g` for the JVM, you expect it to use up to that much memory. If the JVM can't allocate that much memory it doesn't fall back to allocating whatever it can. I'd rather throw an error here and move on., Label: 1\n",
      "Processing row 3350 - Data Type: train, Message: ReflectionUtils is public. The newInstance method actually catches all Exceptions and throws a RuntimeException. The CNFE exception here is being thrown from the Class.forName() call.\n",
      "\n",
      "```\n",
      "@InterfaceAudience.Public\n",
      "@InterfaceStability.Evolving\n",
      "public class ReflectionUtils\n",
      "```, Label: 0\n",
      "Processing row 3351 - Data Type: train, Message: @keith-turner, I tried incorporating your suggestions in a9c0f9b. Not too sure if they are what you had in mind., Label: 1\n",
      "Processing row 3352 - Data Type: train, Message: > I wish compaction-coordinators wasn't so lengthy. -coordinators is just so generic, when we're referring to a specific coordinator.\n",
      "\n",
      "In the context of ZooZap, it's designed to clean up things in ZooKeeper for all servers of a given type. I don't think you can use ZooZap to clean up entries for a specific tserver. Regarding the parameter name, we don't have anything else called a coordinator today. I'm not sure where the confusion would come to play., Label: 1\n",
      "Processing row 3353 - Data Type: train, Message: Are referring to that we just take a substring from the last index of : and that would do it?  If we have more than 2 that will be a problem, I can change the condition because anything  &gt; 2 should be split into two strings cf and qualifier. , Label: 0\n",
      "Processing row 3354 - Data Type: train, Message: so if we go the cf and cq route do we get rid of -c or keep it ?, Label: 1\n",
      "Processing row 3355 - Data Type: train, Message: I don't think that will work. The loop needs to be around the exceptions so it can retry in the event of a connection issue., Label: 1\n",
      "Processing row 3356 - Data Type: train, Message: There isn't necessarily a problem with the exception but it can be misleading, especially at first glance. Even with the additional warning, it is not clear that they are connected in any way. I do agree that returning `null` isn't the best solution which is part of the reason I wanted a review to get more ideas on what the ideal solution would be. , Label: 1\n",
      "Processing row 3357 - Data Type: train, Message: I spent way too much time getting the formatting to not be hideous so I hope you appreciate the double try-with-resources in 1f0bcd1 :stuck_out_tongue_winking_eye: , Label: 0\n",
      "Processing row 3358 - Data Type: train, Message: I just accepted the IDE suggested changes - looking at your suggestion, I can't find where adding the %n is necessary to add to the calling fmt string., Label: 1\n",
      "Processing row 3359 - Data Type: train, Message: I did miss it - corrected in #2390. , Label: 0\n",
      "Processing row 3360 - Data Type: train, Message: Regarding #2425, when I was looking at NativeMap, I was wondering why we first looked in `accumulo.native.lib.path` and then tried LD_LIBRARY_PATH as a fallback. It seems that this is another case where we are doing something non-standard. Why not just use LD_LIBRARY_PATH ?, Label: 1\n",
      "Processing row 3361 - Data Type: train, Message: Are you suggesting that something already exists for this, or that I should create it? I see where this is done in other tests. I don't see evidence of a utility., Label: 1\n",
      "Processing row 3362 - Data Type: train, Message: I disagree. See my other comment., Label: 1\n",
      "Processing row 3363 - Data Type: train, Message: I think it may already be the case that all `assert*()` methods are static imports, Label: 1\n",
      "Processing row 3364 - Data Type: val, Message: I'm not tied to the name, we can change it to whatever... Doesn't the currently named `fail` method actually cancel ? I was trying to stick with the current naming convention., Label: 1\n",
      "Processing row 3365 - Data Type: train, Message: > This should not accept the TemporaryFolder type\n",
      "\n",
      "Why? ZooKeeperTestingServer is a test class and this enforces that a TemporaryFolder is being used as part of the test.  I don't understand the logic here., Label: 1\n",
      "Processing row 3366 - Data Type: val, Message: Removed TemporaryFolder in f9ed9a8, Label: 0\n",
      "Processing row 3367 - Data Type: val, Message: > You could just create our own type for SPI and make all the Hadoop types internal private variables\n",
      "\n",
      "It's not clear to me how a plug-in would create an object and then we convert it to a Codec / Compressor / Decompressor in the internal code. Do you have an example where this is done elsewhere?, Label: 1\n",
      "Processing row 3368 - Data Type: train, Message: `CompressionAlgorithm` is really just the config. `DefaultCompressionAlgorithm` is the one, and currently only, implementation. There is no ability for a user to supply their own algorithm implementation, just the parameters/config for the algorithm. Maybe I need to change the class names to make that more clear, Label: 0\n",
      "Processing row 3369 - Data Type: train, Message: The static block is still needed for the other code in it, right?, Label: 1\n",
      "Processing row 3370 - Data Type: train, Message: I was just following what was there in the other Codes and hence.Let me fix it, Label: 0\n",
      "Processing row 3371 - Data Type: train, Message: I can do that. We are sorting this list and then comparing it with the encoded sorting to get an expected and actual. So how would an ordered list here help ? I think we should create an issue so that I can clean up the other coders also with the same code. , Label: 1\n",
      "Processing row 3372 - Data Type: train, Message: If we don't pass the comparator wouldn't it still use the default comparator which would still not give us want we want?  Shouldn't we write our Comparator? Because our encoder and decoder know how data is stored and would compare it correctly.  , Label: 1\n",
      "Processing row 3373 - Data Type: train, Message: @ctubbsii  Shall we have the LexiCoder implement the Comparator interface or write a different Comparator for BigDecimals? Thanks, Label: 0\n",
      "Processing row 3374 - Data Type: train, Message: With the code the way that it is, would it allow a user to put the class name in the client properties file? If so, then doing it this way would preclude that., Label: 1\n",
      "Processing row 3375 - Data Type: val, Message: Won't they still need a Cleaner in the case where the client is not closed?, Label: 1\n",
      "Processing row 3376 - Data Type: train, Message: I can move the `close()` calls up. Regarding lazy instantiation, what other thread pools were you referencing? The class javadoc says `Any state in this object should be available at the time of its construction.`, does that on mean configuration?, Label: 1\n",
      "Processing row 3377 - Data Type: train, Message: @dlmarion, sorry, my mistake. I thought it was under the Error pattern list vs the Warning pattern. I'll close this as not implemented. In a future PR related to some other EP related changes, I may consider moving the line beneath the 'warning' comment so keep separate Error patterns from Warning patterns. Would you have any objections to that re-arrangement?, Label: 1\n",
      "Processing row 3378 - Data Type: train, Message: I think GH does a pretty good job of showing you the changes in one line, but I'll change it for you. I wonder if this is something we can enforce at build time., Label: 1\n",
      "Processing row 3379 - Data Type: train, Message: I have a slight concern about this code.  It may matter that the start count is read before the completed count, not sure still thinking out it.  Thinking of replacing the two separate atomic longs with a single atomic reference to a counter object with two longs.  Then I don't have to worry about this issue., Label: 1\n",
      "Processing row 3380 - Data Type: train, Message: AMCC was for Accumulo Metadata Consistency Check.  I can add a comment for that.  Do you think it should be removed?  I added because I like to be able to easily grep for all related messages., Label: 0\n",
      "Processing row 3381 - Data Type: train, Message: > We don't want infinite timeouts by default, only if the user explicitly set it with `-Dtimeout.factor=0`.\n",
      "\n",
      "I don't think the timeout will be infinite by default. I think the only cases where the infinite timeout would be applied (before [c03f65e](https://github.com/apache/accumulo/pull/2580/commits/c03f65e720d08abd1341872295d7faaa241d3b93)) would be if the user explicitly set it with `-Dtimeout.factor=0`, or if `defaultTimeout()` was explicitly overridden to return a duration of zero., Label: 1\n",
      "Processing row 3382 - Data Type: val, Message: I tried creating an object, `IteratorTestParameters`, that wraps the input, output and test case for an individual test. This allows us to pass a list of `IteratorTestParameters` to the parameterized test rather than a list of `Arguments`(eliminating the reliance on JUnit specific types). Does this seem like it could be a good approach?, Label: 1\n",
      "Processing row 3383 - Data Type: val, Message: Ah, my editor must have changed this. Will fix, Label: 0\n",
      "Processing row 3384 - Data Type: train, Message: @ctubbsii In the Monitor, the Replication page already indicates \"Replication table is offline\". Is this sufficient?, Label: 1\n",
      "Processing row 3385 - Data Type: train, Message: I didn't see where the fake timer was actually being used *and* the test passes without it. I'm good with adding it back, but can you explain how/where it's being used? The only place where the fake timer is being used is [here](https://github.com/apache/accumulo/blob/main/test/src/main/java/org/apache/accumulo/test/conf/store/ZooBasedConfigIT.java#L282) and its not clear to me how that works with the test., Label: 1\n",
      "Processing row 3386 - Data Type: train, Message: I'll close this and submit a PR that updates the test documentation to include this. I was unclear on the reason for the test being constructed as it is. When adding / changing a command it is not obvious that the KeywordIT test must also be changed - well, at least until if fails, which is its purpose, but frustrating from a development perspective., Label: 1\n",
      "Processing row 3387 - Data Type: train, Message: I was thinking that we would not want to store the output of any crypt function. Instead, I was just capturing the fact that two pieces of information had returned a true result in the recent past, and using it to short circuit the method. Is there any benefit to recalculating whether the two hashes are equal?, Label: 1\n",
      "Processing row 3388 - Data Type: train, Message: For Caffeine, specifying a size turns the Cache into an LRU Cache (see https://github.com/ben-manes/caffeine/wiki/Eviction#size-based). As for the number 5, it was arbitrary. I don't know how many ZK's a ClientContext actually communicates with, it's probably 1. But a Cache of 1 didn't make sense. What's your thought?, Label: 1\n",
      "Processing row 3389 - Data Type: train, Message: > May want to look at what other properties are doing. I thought we had a replacement mechanism that other code had used.\n",
      "\n",
      "```\n",
      "serverConfig.resolve(Property.MANAGER_RENAME_THREADS, Property.MANAGER_BULK_RENAME_THREADS)\n",
      "```\n",
      "The property `MANAGER_BULK_RENAME_THREADS` seems to be undergoing deprecation in similar versions.\n",
      ", Label: 0\n",
      "Processing row 3390 - Data Type: train, Message: @ctubbsii \n",
      "https://github.com/apache/accumulo/pull/2712#discussion_r874805835\n",
      "Should I use this?, Label: 0\n",
      "Processing row 3391 - Data Type: train, Message: Nice!, Label: 0\n",
      "Processing row 3392 - Data Type: train, Message: I think I may have done this. I was trying to give context to the Version change since keeping track of serialized versions can be a pain. Maybe would be better to link with AccumloDataVersion or something else., Label: 1\n",
      "Processing row 3393 - Data Type: train, Message: The multiple lines are to improve the readability - it is much easier to see the files options by type than scanning a long line. If feel that it also makes it clearer what the following output may or may not contain because of user options.\n",
      "\n",
      "The use of the logger also clearly separates the text output from the command and will not appear in an output file (if specified) this makes follow-on processing easier if that is the user's end goal.\n",
      "\n",
      "At one point, I did have one log statement print multiple lines, but that seemed odd in the output., Label: 0\n",
      "Processing row 3394 - Data Type: train, Message: The metadataEntry will look like: `1;2cccccccccccccd1 srv:dir []   t-000003z`. So technically, the dirName is only part of the metadaEntry.\n",
      ", Label: 0\n",
      "Processing row 3395 - Data Type: train, Message: I think this needs an underscore and \"-\". We have the value \"default_tablet\" and tablet directories have a dash like:\n",
      "<pre>\n",
      "2;9 srv:dir []\tt-000009x\n",
      "2< srv:dir []\tdefault_tablet\n",
      "</pre>, Label: 0\n",
      "Processing row 3396 - Data Type: train, Message: I left those lines in by accident & will remove them.  I'm thinking of adding session.queries to a LinkedList<Pair<KeyExtent, List<Range>>> so that we can add to the back and remove from the front instead of using session.queries.iterator().next() when we're not really iterating.\n",
      "\n",
      "The fact that partScan/partNextKey/partNextKeyInclusive only report back one partial scan when there could be multiple partial scans still seems problematic, but that may be a topic for a subsequent issue,, Label: 1\n",
      "Processing row 3397 - Data Type: train, Message: I decided that adding Pair<KeyExtent, List<Range>> of an unfinished Range back to the front of the LinkedList ensures that it gets handled next.  That means that if the LookupTask ends due to time or result size then a record of the last partial scan will get returned.  If the unfinished ranges get fully scanned, then the KeyExtent will be recorded as a full scan and the record of a partial scan will be removed.  This seems to make the most sense. , Label: 1\n",
      "Processing row 3398 - Data Type: train, Message: @DomGarguilo - good catch, typo fixed. Is this good to merge or do you want to wait for @milleruntime to take a look too?, Label: 0\n",
      "Processing row 3399 - Data Type: val, Message: So the reason for the subclasses and the new API was @milleruntime mentioned not wanting to break the  thrift API which makes sense. Because new version is a client side scan only and doesn't need to make a server call I kept the thrift API alone and preserved the existing implementation. The other option would be I guess to move the metadata scan to the server and replace it so the thrift API call gets the new implementation but that seems unnecessary since you can do a client scan. Or I guess you could always have both, have it server wise in the API and also make it available in the client.\n",
      "\n",
      "Also the new API was created since more information is returned with the new call to support the new output. However this is not a big deal if we don't want to change the output as you indicated in your other comment.\n",
      "\n",
      "So mostly the issue is what to do about the existing server side API  that is public in thrift and what that should use and if we should keep the metadata scan only client  side., Label: 1\n",
      "Processing row 3400 - Data Type: train, Message: That's a good point, and looking at the stack trace, probably how this test failed in the first place.\n",
      "\n",
      "> Another strategy may be to pull the create / delete into functions that retry and pause a little a few times.\n",
      "\n",
      "This seems like a good idea. Also seems like a perfect place for the [`Wait.java`](https://github.com/cshannon/accumulo/blob/9d7a69d5ec4fb35c5f882a64596e7843ccbe886e/test/src/main/java/org/apache/accumulo/test/util/Wait.java#L28) test util that is part of #2799, added by @cshannon. I'm wondering if that could be broken into its own PR so it can be used elsewhere while #2799 is still under review.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 3401 - Data Type: train, Message: That makes sense, ill include this change., Label: 0\n",
      "Processing row 3402 - Data Type: train, Message: Do you think I should refactor all of the spots that are similar to this to reduce the number of times we iterate?, Label: 1\n",
      "Processing row 3403 - Data Type: train, Message: I made a top level comment about this., Label: 0\n",
      "Processing row 3404 - Data Type: train, Message: > I did something similar when we were working on external compactions to retry thift calls - [RetryableThriftCall](https://github.com/apache/accumulo/blob/main/server/base/src/main/java/org/apache/accumulo/server/compaction/RetryableThriftCall.java)\n",
      "\n",
      "We need something more general like that so we can reuse retry code.  Still scratching my head over the best way to handle checked exceptions though.  Like whats the most concise way to handle one operation that throws checked exception X and another that throws checked exception Y and these are checked exceptions that we want to pass up., Label: 1\n",
      "Processing row 3405 - Data Type: train, Message: Well, I can say that without this, things like DumpConfigIT, which use the Admin utility, failed., Label: 0\n",
      "Processing row 3406 - Data Type: train, Message: They are ordered in the most likely occurrence  - in general the number of tables > number of namespaces > system so it seemed rational to order the check so that what would (hopefully) be more common to be checked first., Label: 0\n",
      "Processing row 3407 - Data Type: train, Message: Addressed in ac8d0b8da8 - in this case, the ZooKeeper stat is also being used, so that should be another reliable check for the data length.  The NoNodeException likely was sufficient - but checking the stat does not seem to hurt., Label: 0\n",
      "Processing row 3408 - Data Type: train, Message: No, Label: 0\n",
      "Processing row 3409 - Data Type: train, Message: You can't remove this or it doesn't work. You have to grant ALTER_NAMESPACE to the default namespace or else when you use the config command as the root user on a table in the default namespace you get a permission error., Label: 0\n",
      "Processing row 3410 - Data Type: val, Message: Yup, indeed I do, oops., Label: 0\n",
      "Processing row 3411 - Data Type: train, Message: > Can we justify adding it in 2.1.1?\n",
      "\n",
      "I'm not sure we need to. There are plenty of examples of properties being added in a patch release, including 4 of them added in version 1.9.3.\n",
      "\n",
      "> Why not just always set it, and let it be cached when read?\n",
      "> Making it configurable give a an escape hatch for that.\n",
      "\n",
      "This is exactly my concern.  I think it may be safe to always do this, but I'm not 100% positive. The way that Hadoop implemented this, you can tell the OS via the FADVISE_DONTNEED flag that the OS can purge the file from the page cache when the read or write is done (in this case write). I read that this is done by setting that advice on the file descriptor and that each process (the DN in this case) has a file descriptor table. I don't know if re-opening the same file shortly after would re-use the same file descriptor number and I don't know if that advice may prevent caching of the file on a subsequent read operation. My guess is that it's safe to call it on the majc output file, but I don't know for sure., Label: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 3412 - Data Type: train, Message: > actually works as intended.\n",
      "\n",
      "I have no issue  with the testing you suggested. However, I don't know whether we will be able to tell if the file was *actually* purged from the OS page cache as the FADVISE directive is advice., Label: 1\n",
      "Processing row 3413 - Data Type: train, Message: That's fair, a better place for the defined Property is in [CompactionConfigurer](https://github.com/apache/accumulo/blob/main/core/src/main/java/org/apache/accumulo/core/client/admin/compaction/CompactionConfigurer.java). That's user-pluggable via a table [property](https://github.com/apache/accumulo/blob/main/core/src/main/java/org/apache/accumulo/core/conf/Property.java#L1007). I'm not sure why the CompactionConfigurer class isn't in the SPI package., Label: 1\n",
      "Processing row 3414 - Data Type: val, Message: I wonder if it is better to try and create some fake properties for the tests or something to check the resolve method vs leaving in stubs for non existent properties. Seems like if we want to check the resolve method we should create a test class specifically for that., Label: 1\n",
      "Processing row 3415 - Data Type: train, Message: @ctubbsii - Is there a good place to log a warning for this? I don't see an Upgrader class yet for 3.0 so is that something we should create in another PR?, Label: 1\n",
      "Processing row 3416 - Data Type: train, Message: IIRC from ZooKeeperInitializer:\n",
      "\n",
      "ZROOT -> ZooDefs.Ids.OPEN_ACL_UNSAFE\n",
      "ZROOT + ZINSTANCES -> ZooDefs.Ids.OPEN_ACL_UNSAFE\n",
      "ZROOT/IID/config -> ZooUtil.PRIVATE\n",
      "Everything else has ZooUtil.PUBLIC, Label: 0\n",
      "Processing row 3417 - Data Type: val, Message: Changed in e2c87e0815 - but junit didn't seem to care., Label: 0\n",
      "Processing row 3418 - Data Type: train, Message: Initially I was thinking about adding this to the MDC, but not all frameworks work with that.\n",
      ", Label: 0\n",
      "Processing row 3419 - Data Type: train, Message: I just want to prefix any msg with the userData. I don't see how creating a new method for each and every msg I want to log makes sense., Label: 1\n",
      "Processing row 3420 - Data Type: val, Message: Also in regards to your comment about it being useful for other tests, I think so too. Curiously when I was researching online about how to solve this no one really had any answers. Everyones answer was pretty much \"you can't do that\". I came up with the idea for the nested classes because initially I was thinking I was going to need to write a subclass for every single test which I didn't want to do and then the nested idea hit me., Label: 0\n",
      "Processing row 3421 - Data Type: train, Message: I agree, we should probably change the name to something else. The value can actually be anything you want. By default it would be a list of URIs because that's what the default factory would use to create a classloader but if a user plugs in their own class loader factory implementation then this value can be anything the user wants as long as their factory knows how to read it. So I think `contextValue` or something like that makes a lot more sense as `contextName` doesn't apply anymore., Label: 0\n",
      "Processing row 3422 - Data Type: train, Message: The purpose of Caffeine was so that the cache will remove old classloaders automatically when no longer needed but this could be re-worked if desired. \n",
      "\n",
      "In the current version there is a thread that runs to check for no longer needed contexts and will remove them. The idea of using Caffeine was that we can cache the Classloader but if it is no longer needed anymore after some period of time (nothing reads it because maybe the config was dropped, etc) we can then just remove it from the cache automatically. This seemed simpler than maintaining a GC thread., Label: 0\n",
      "Processing row 3423 - Data Type: val, Message: Changed in b3ca1d9b65, Label: 0\n",
      "Processing row 3424 - Data Type: train, Message: I thought a per table propery might be useful, but perhaps not.  I can go either way on this one., Label: 0\n",
      "Processing row 3425 - Data Type: val, Message: @ctubbsii Is there a reason so make this a _general_ property versus a _tserver_ property?  We are talking about tserver locations so that would have been be my first inclination., Label: 1\n",
      "Processing row 3426 - Data Type: train, Message: @ctubbsii Should this be a general property or a tserver property?, Label: 1\n",
      "Processing row 3427 - Data Type: val, Message: I agree that it's not a perfect solution, it's an attempt at doing something. There are other options that could be added, like only check for free memory if the length is over some size. The problem we run into is that the tablet server is running N scans concurrently, JVM memory is under pressure, and it doesn't know that the next K/V it's going to read is going to create a very large (500MB, 1GB) Value object., Label: 1\n",
      "Processing row 3428 - Data Type: train, Message: Previously it was checked in each upgrader - the check here fails faster and provided a clearer message than if the upgradeder fail the version checks - failing with a message that upgrader for data version X is accurate, but may not translate to the user how data versions and Accumulo versions correlate.  \n",
      "\n",
      "On the positive side - this provides a clear user message at the expense of needing to change the message if upgrades change - but that should be rare and I favored a better user experience., Label: 0\n",
      "Processing row 3429 - Data Type: train, Message: This is not so much new code as it is moving existing code to a different place.\n",
      "\n",
      "The code to upgrade to 2.1 included the check for ZooKeeper ACLs and with the deletion of that code, this check would not be performed.  Being that it is unclear how the invalid ACLs are occurring, it seemed like something that could be checked on each upgrade and not pegged to a specific upgrade version., Label: 1\n",
      "Processing row 3430 - Data Type: train, Message: @ctubbsii would this be okay? Seems long and not adding much - might just be better to include something in the release notes or in the upgrading section of the docs.\n",
      "\n",
      "```\n",
      "java.lang.IllegalStateException: This version of accumulo (3.0.0-SNAPSHOT) is not compatible with files stored using data version 8 see org.apache.accumulo.server.AccumuloDataVersion javadoc for historic version mapping\n",
      "        at org.apache.accumulo.server.ServerContext.ensureDataVersionCompatible(ServerContext.java:302) ~[accumulo-server-base-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at org.apache.accumulo.server.ServerContext.init(ServerContext.java:372) ~[accumulo-server-base-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at org.apache.accumulo.server.AbstractServer.<init>(AbstractServer.java:50) ~[accumulo-server-base-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at org.apache.accumulo.manager.Manager.<init>(Manager.java:412) ~[accumulo-manager-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at org.apache.accumulo.manager.Manager.main(Manager.java:406) ~[accumulo-manager-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at org.apache.accumulo.manager.ManagerExecutable.execute(ManagerExecutable.java:45) ~[accumulo-manager-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at org.apache.accumulo.start.Main.lambda$execKeyword$0(Main.java:122) ~[accumulo-start-3.0.0-SNAPSHOT.jar:3.0.0-SNAPSHOT]\n",
      "        at java.lang.Thread.run(Thread.java:829) ~[?:?]\n",
      "\n",
      "```, Label: 0\n",
      "Processing row 3431 - Data Type: train, Message: so you don't think I should make *any* changes to `bin/accumulo` ?, Label: 1\n",
      "Processing row 3432 - Data Type: train, Message: Running error prone explicitly (at the current level) says nothing.  I also was under the impression that we now run error prone by default, but I just did \n",
      "```\n",
      "mvn verify -Perrorprone -Dtest=blah -Dit.test=blah\n",
      "```\n",
      "to double check., Label: 0\n",
      "Processing row 3433 - Data Type: val, Message: If we elect to continue to use Uninterruptibles I would like to hear the need that we *must* sleep for the entire time, ignoring the interrupt.\n",
      "\n",
      "Running error prone at the next effort level, I do not see anything - it may be seeing that the interrupt flag is set as a side effect - but we fail pretty fast in core because of other (known) issues, so not really a strong test.\n",
      "\n",
      "If it does get flagged, I would advocate that we create a similar method `UtilWaitThread.sleepQuitely` or something so that we still break out of the sleep on interrupts., Label: 1\n",
      "Processing row 3434 - Data Type: train, Message: This logs and resets the interrupt flag.  Throwing an existing exception delegates to exception handling in place. Throwing InterruptException would require more changes., Label: 0\n",
      "Processing row 3435 - Data Type: train, Message: I was going off of the comment above these variables describing why `buffer` needs to be volatile and it seems like `max` would fall into the same boat. Both `max` and `buffer` **could** be final as they are both only set in the  constructor however I'm not sure if they should be or not., Label: 1\n",
      "Processing row 3436 - Data Type: train, Message: Also im not sure what going on with the build. Its passing locally for me., Label: 1\n",
      "Processing row 3437 - Data Type: train, Message: It looks like this is only used in one place.  `SeekableByteArrayInputStream.getBuffer()` is used in `CachableBlockFile.CachedBlockRead.getBuffer()` which is only called in `MultiLevelIndex.IndexBlock.readFields()`. There is a comment that says `this block is cached, so avoid copy` in `readFields()` so making a copy to avoid altering the original buffer might not be an option here. As far as I can tell though, the byte[] returned by `getBuffer()` is never altered, only read, so it might not be an issue in the current code. Would be nice to make it immutable but there is no immutable byte array in java.\n",
      "\n",
      "I'm not too sure how your concern should be addressed @ctubbsii. Do you have any ideas? If not do you think this PR is ready to merge?, Label: 1\n",
      "Processing row 3438 - Data Type: train, Message: There are tags - I'm trying to confirm that they are being set correctly as I look at Dave's other comments., Label: 1\n",
      "Processing row 3439 - Data Type: train, Message: > I think some of the logic might read better if there were fewer negations.\n",
      "\n",
      "I inverted this boolean in a new commit.\n",
      " \n",
      "> Also, what happens if these are the same, but both are null?\n",
      "\n",
      "The banner will be hidden when `managerState === null` is checked.\n",
      "\n",
      "> What happens if `getManager()` errors?\n",
      "\n",
      "We don't have much error handling anywhere in the monitor code but I could add a catch block in this case to `console.error` the error., Label: 1\n",
      "Processing row 3440 - Data Type: val, Message: Added an inner class., Label: 0\n",
      "Processing row 3441 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3442 - Data Type: train, Message: What determines when a tool should have a main method?  The javadoc in `KeywordExecutable` states how, if it is desired to have a \"redundant main method\" what it should look like.  Certainly using `accumulo tool-name` is convenient, but I do not know when someone might prefer using a main method, or which tools \"require\" a main method, other than the list in KeywordStartIT, which I think over time may be testing tools that \"have a main method\" vs. test tools that actually \"require\" a main main, but have one for convenience (or in my case added because of ignorance of the difference.)\n",
      "\n",
      "The Keyword and main support seems to mainly be boiler-plate between utilities and I was trying to maintain similar functionality between various tools so that would provide similar experiences rather than the user needing know tool-by-tool which options it would support,\n",
      ", Label: 1\n",
      "Processing row 3443 - Data Type: val, Message: I removed main in d11c27ea95 and I think the KeywordStartIT was updated correctly - the test passes, but unclear if this is how the test should be used for non-main tools., Label: 1\n",
      "Processing row 3444 - Data Type: train, Message: Allowing and id or a name was to ease using information if it was coming from a log file.  Often, the logs use id, not name.  Making the user dig out the name, potentially without the shell being available seemed like an unnecessary step when the tool could use either.  Internally, the code uses id and if given a name it takes effort to lookup the id, so just accepting the id that is needed anyway didn't seem to add more complexity., Label: 0\n",
      "Processing row 3445 - Data Type: train, Message: If you redirect the output to a file (say `| tee` ) - having the metadata / header along with the values is something that I (thinking as a user) could find handy for reference.  For example, take a snapshot \"before\", make the change and then get a second snapshot, having the date stamp and version number as metadata along with the values could help distinguish between the snapshots and persist with the file or act a a record of the users actions.\n",
      "\n",
      "Would an alternate character, `+`, `=` be friendlier for grep? I think that `#` has the same issue as `-`, Label: 1\n",
      "Processing row 3446 - Data Type: train, Message: Was already corrected?  (Change is reflected in 3ed08fc601), Label: 1\n",
      "Processing row 3447 - Data Type: train, Message: I'm not sure that makes sense here. This is done during Manager startup before clients can connect to it. The RecoveryManager is created and the value of `timeToCacheRecoveryWalExistence` is used in the RecoveryManager constructor to set the expiration time on the Caffeine CacheBuilder. This is only called once, not in a loop, and I don't think the Caffeine cache can be updated after construction., Label: 1\n",
      "Processing row 3448 - Data Type: train, Message: Removed the (hidden) columns from the .ftl files., Label: 0\n",
      "Processing row 3449 - Data Type: val, Message: I don't believe that an empty or null context name is valid. I don't think that a user can set that in the shell. I don't think that it can be set via the API either, but I would have to look to be sure. A null or empty context here could indicate a bug., Label: 1\n",
      "Processing row 3450 - Data Type: val, Message: Setting a table property via the shell or API ends up [here](https://github.com/apache/accumulo/blob/2.1/server/manager/src/main/java/org/apache/accumulo/manager/ManagerClientServiceHandler.java#L558). If `context` is null or empty, then there could be an issue with the Accumulo code., Label: 0\n",
      "Processing row 3451 - Data Type: train, Message: Based on my analysis in #3677 , an invalid context name could prevent any classes from being loaded, which could lead to the minor compaction thread for a tablet to die. From what I found, a minor compaction for a tablet will not occur again if the minor compaction thread dies, meaning that it can't be closed normally. I think the safest action when this occurs is a total restart of Accumulo.\n",
      "\n",
      "The changes in #3677 try to prevent the minor compaction thread from dying, but there could be other areas within Accumulo where something similar happens when an invalid context name is used. Given that, and that the recovery for this situation is a total restart, I would suggest that `true` not be the default answer. In fact, I don't think this should be a default method, I think we should force all implementations to provide an answer., Label: 1\n",
      "Processing row 3452 - Data Type: train, Message: So, we can't change the \"current\" LTM release?, Label: 1\n",
      "Processing row 3453 - Data Type: train, Message: Modified this in in 9272c0f such that a null classloader return variable is no longer checked in accordance with the existing javadoc. The method should either return a classloader or throw a RTE., Label: 0\n",
      "Processing row 3454 - Data Type: train, Message: Yeah, so I'm trying to add that right now and running into compilation issues. It's turning the resulting map into Map<Object,Object> vs Map<String,String>. Do you have something that works?, Label: 1\n",
      "Processing row 3455 - Data Type: train, Message: ```\n",
      "    Map<String,String> volumeHdfsConfigOverrides = \n",
      "        conf.getAllPropertiesWithPrefixStripped(Property.INSTANCE_VOLUME_CONFIG_PREFIX).entrySet()\n",
      "            .stream().filter(e -> e.getKey().startsWith(filesystemURI + \".\"))\n",
      "            .collect(Collectors.toUnmodifiableMap(Function.identity(), Function.identity()));\n",
      "```\n",
      "\n",
      "doesn't compile., Label: 0\n",
      "Processing row 3456 - Data Type: train, Message: My only concern with putting more into the `Cache.get` call is this in the javadoc:\n",
      "```\n",
      "   * Some attempted update operations on this cache by other threads may be blocked while the\n",
      "   * computation is in progress, so the computation should be short and simple, and must not attempt\n",
      "   * to update any other mappings of this cache.\n",
      "```, Label: 0\n",
      "Processing row 3457 - Data Type: train, Message: changed in a513d75, Label: 0\n",
      "Processing row 3458 - Data Type: train, Message: changed in a513d75.  Didn't see much harm or benefit in this change after making it., Label: 0\n",
      "Processing row 3459 - Data Type: train, Message: The rest of the class is using System.currentTimeMillis(), so I chose to use it here for consistency.  If a change were to be made to use nano time it should be done for the whole class.  That could be a follow on issue., Label: 0\n",
      "Processing row 3460 - Data Type: val, Message: > I would prioritize correctness over consistency.\n",
      "\n",
      "That's a good reason to update.  It was irksome to make it inconsistent, but I made the change in 66c6849 to make it correct.  Don't want to fix all the other places in this PR though., Label: 0\n",
      "Processing row 3461 - Data Type: val, Message: The class is very tightly coupled with the internal implementation and accesses private functions and instance variable of the containing class.  So to push it out would also require changing things to be non private.   I do not think that internal classes that are very tightly coupled with internal  implementation of the containing class need to be moved out.   Its only a class because its internal code that needs to be run in a another thread., Label: 0\n",
      "Processing row 3462 - Data Type: train, Message: IT fixed!, Label: 0\n",
      "Processing row 3463 - Data Type: train, Message: It should - but I wanted to avoid the assumption in case there was any chance of a concurrent test had / left something there - a very remote possibility. It just seemed more general to get the count. kill a server and wait for that count to increase., Label: 0\n",
      "Processing row 3464 - Data Type: train, Message: Within the context of the test it should not decrease - whatever would clean the dead server list would only have a narrow window (5 sec).  If it is shown to be a problem, then the check would need to be more complicated.  \n",
      "\n",
      "If somehow the \"same\" server was brought back to life, the remainder of the test might have issue too., Label: 1\n",
      "Processing row 3465 - Data Type: train, Message: I think I'm just going to add the `UTF_8` argument to the String constructor. By modifying this to call `Optional.map` twice we are incurring 2 calls to `Objects.requireNonNull`, `Optional.isPresent`, and `Optional.empty` vs one null-check and one call to `Optional.empty`. Your suggestion may reduce the lines of code, but it's not as efficient in achieving the same result., Label: 0\n",
      "Processing row 3466 - Data Type: train, Message: Changed in e8ae63227647 (along with other changes), Label: 0\n",
      "Processing row 3467 - Data Type: train, Message: Removed in 7fa8acabb7, Label: 0\n",
      "Processing row 3468 - Data Type: val, Message: Created JIRA for ARC: https://issues.apache.org/jira/browse/SYSTEMML-2165 ... I will have to think about loop-aware policies., Label: 0\n",
      "Processing row 3469 - Data Type: train, Message: In case of frequent evictions, doesn't AL preserve previously sorted list and hence make cost of sorting again O(n)., Label: 0\n",
      "Processing row 3470 - Data Type: train, Message: I'm unable to find a small code snippet for Kmeans function in R which runs without any error on Collab. I tried with a lot of examples. Most of the times there is a syntax error., Label: 0\n",
      "Processing row 3471 - Data Type: train, Message: Hi Attila, \n",
      "\n",
      "I'd like to leave these as is.\n",
      "\n",
      "I'd argue that these don't actually belong together, so it's not really code duplication but rather an accidental match.\n",
      "\n",
      "I added a new column to the sample data of the mysql configuration to cover an edge case. The expected result in Hive changed for this configuration, and, on the other hand this edge case does not make sense to be added to the SQL server tests.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 3472 - Data Type: train, Message: Actually, there is a method that defines extra mappings for hive types in OraOop:\n",
      "org.apache.sqoop.manager.oracle.OraOopConnManager#toHiveType \n",
      "\n",
      "So we need to keep the \"null\" return value here, in order to allow for that to work. \n",
      "\n",
      "I think it still makes sense to log a warning though.\n",
      "\n",
      "On the long run: it might make sense to refactor the ora oop connector, but I think it's out of the scope of this change., Label: 1\n",
      "Processing row 3473 - Data Type: train, Message: I learn something new every day :), removed., Label: 0\n",
      "Processing row 3474 - Data Type: train, Message: Nope., Label: 0\n",
      "Processing row 3475 - Data Type: train, Message: nope., Label: 0\n",
      "Processing row 3476 - Data Type: train, Message: Indeed! Removed lines above., Label: 0\n",
      "Processing row 3477 - Data Type: train, Message: Indeed!, Label: 0\n",
      "Processing row 3478 - Data Type: train, Message: I've added a different comment as the method doesn't start anything, making it clearer what the method returns., Label: 0\n",
      "Processing row 3479 - Data Type: val, Message: Sorry.\n",
      "\n",
      "I thought that a committer and the PR contributor are me.\n",
      "Which is my mistake, a committer or the PR contributor?\n",
      ", Label: 1\n",
      "Processing row 3480 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3481 - Data Type: train, Message: Good catch.  I've used it elsewhere but somehow missed it in the loops.  Its somewhat moot, however, since the two fillBuffer methods have been deleted., Label: 0\n",
      "Processing row 3482 - Data Type: train, Message: Same as above :-), Label: 0\n",
      "Processing row 3483 - Data Type: train, Message: Yes, it looks like IOUtils.read(InputStream, byte[]) and IOUtils.read(Reader, char[]) (without the optional arguments) should do exactly what I want.\n",
      "\n",
      "Thanks for the call out, I didn't realize those methods existed., Label: 0\n",
      "Processing row 3484 - Data Type: train, Message: I agree these tests are useful to improve code coverage.  But they are not directly related to the change, and previous changes to this code were permitted without adding these missing tests.  Could we create a new pull request or issue to improve the coverage of the test suite, to avoid blocking this pull request?, Label: 1\n",
      "Processing row 3485 - Data Type: train, Message: Maybe the other methods could be updated to use `Objects.requireNonNull` as well in a separate PR?, Label: 1\n",
      "Processing row 3486 - Data Type: train, Message: I was sticking to the style of the existing methods.\n",
      "\n",
      "Maybe those methods could have the same modifications applied as well?, Label: 1\n",
      "Processing row 3487 - Data Type: train, Message: > In general, you want to use hard coded dates in tests\n",
      "\n",
      "The files being tested seem to be created at the moment the test is run, so how should it be handled?\n",
      "\n",
      "> Yes, I've actually seen this happen (at work.)\n",
      "\n",
      "Wow., Label: 0\n",
      "Processing row 3488 - Data Type: train, Message: This Queue**Input**Stream method creates a Queue**Output**Stream instance. Just saying \"an instance\" might be confusing?, Label: 1\n",
      "Processing row 3489 - Data Type: train, Message: I feel that without deprecating the constructors, this PR adds no real value. People that currently use the constructors will keep doing so because they see no reason to change their code, and new users of the classes may only get confused if there are two ways to do the same thing. They'll probably end up using the constructors too because that's a character shorter (`new` vs `.wrap`).\n",
      "\n",
      "My thought was that deprecating the constructors will make current users think about whether or not they have closed the underlying streams, even if their IDEs don't warn them. New users will chose the wrapper method because the alternative is deprecated.\n",
      "\n",
      "The only downside to deprecating the constructors that I can see is that current users that don't have their IDEs setup to warn about unclosed streams will get warnings where there were none first, but as I said, perhaps they will think about whether or not their streams are properly closed somewhere else., Label: 1\n",
      "Processing row 3490 - Data Type: train, Message: Changed as suggested, Label: 0\n",
      "Processing row 3491 - Data Type: train, Message: Changed as suggested, Label: 0\n",
      "Processing row 3492 - Data Type: train, Message: @garydgregory This is a important one.\n",
      "In general: A single JavaDoc should not override global design principles. The SecurityManager has cross functional purpose. [Edit:] I agree that the missing documentation to throw a SecurityExcpetion is necessary. My fault, will correct that.\n",
      "\n",
      "UseCase A: One wants to configure the SecurityManager and grant permissions. Part of the application is to delete a file. If the permission is missing, cleaning does not work. The missing exception does not allow to recognize that.\n",
      "UseCase B: One has activated the SecurityManager. An attacker abuses the deleteQuietly method. The missing SecurityException hides this attempt, you're IDS can't alarm.\n",
      "UseCase C: One utilizes the SecurityManager to test the system, to ensure every property (like file location) is set properly. The missing SecurityException does not support this UseCase., Label: 0\n",
      "Processing row 3493 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3494 - Data Type: val, Message: This comment has nothing to do with the performance of this class. It is just noting that user's shouldn't think there is no need for buffering after using this class. In the example given, buffering is needed to improve the performance of the gzip compression in memory., Label: 0\n",
      "Processing row 3495 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3496 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 3497 - Data Type: train, Message: Seems like a holdover from legacy JUnit. Why bother when JUnit doesn't require it anymore?, Label: 1\n",
      "Processing row 3498 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3499 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 3500 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3501 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 3502 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 3503 - Data Type: train, Message: This file has a whole bunch of different local variables used for `new BufferedInputStream(...)`. There does not appear to be a remotely good reason for so many different ways to spell the same variable name in a single file, but only this one bothered me enough to change it.\n",
      "\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L94\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L112\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L143\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L162\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L172\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L216\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L230\n",
      "-- this is in the same scope as the previous one, but the previous one is effectively dead, so there's no reason not to recycle it as the next two sites do...\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L281\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L302\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L347\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L390\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L428\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L441\n",
      "https://github.com/apache/commons-io/blob/318645fd97d6c31cfbce6f5a7fa83d5350e87708/src/test/java/org/apache/commons/io/input/UnsynchronizedBufferedInputStreamTest.java#L461, Label: 0\n",
      "Processing row 3504 - Data Type: train, Message: Just stumbled over\n",
      "\n",
      "```\n",
      "        if (!SystemUtils.IS_OS_WINDOWS) {\n",
      "            final Set<PosixFilePermission> parentPerms = Files.getPosixFilePermissions(target.getParentFile().toPath());\n",
      "            final Set<PosixFilePermission> targetPerms = Files.getPosixFilePermissions(target.toPath());\n",
      "            assertEquals(parentPerms, targetPerms);\n",
      "        }\n",
      "```\n",
      "\n",
      "in line 862. So do you prefer such an condition in `testReadFileToByteArray_Errors()` instead of this conditional test? (But I'm not experienced enough in regards of filesystems: Is `!SystemUtils.IS_OS_WINDOWS` enough to rely on for the usage of `PosixFilePermissions`? `isPosixFilePermissionsSupported()` might be safer?) , Label: 1\n",
      "Processing row 3505 - Data Type: train, Message: what do you mean? you want  ln1468 changed to use `File.separatorChar` ? what would be the difference?, Label: 1\n",
      "Processing row 3506 - Data Type: train, Message: I agree - that feels like a premature optimization :smile: , Label: 0\n",
      "Processing row 3507 - Data Type: train, Message: done and done. I've added assertions to both tests that ensure the root path is the same as is reported by property `java.io.tmpdir`, Label: 0\n",
      "Processing row 3508 - Data Type: train, Message: same as above - what's the reasonable concern here? , Label: 1\n",
      "Processing row 3509 - Data Type: val, Message: I will first add everywhere some warnings where we can thing afterwards how PLC4J should behave in generall? or is there some doc about the general behavior of the API?, Label: 1\n",
      "Processing row 3510 - Data Type: train, Message: Every time decode is called it contains a new buffer, all buffers need to be collected until there is sufficient data to parse a message. The buffer needs to be retained the documentation specifies that after the function returns the buffer is released see https://netty.io/4.0/api/io/netty/handler/codec/MessageToMessageDecoder.html . By wrapping the buffers it is possible to keep using it as a buffer. Another option would be to copy the data to a buffer but that sounds less efficient., Label: 0\n",
      "Processing row 3511 - Data Type: train, Message: One can fill a Buffer by writing to it. However in this case you get a new buffer every time, at least I haven't found anything in the documentation about that buffer being filled if not used. It would also contradict the documentation about being able to pass through the buffer if an underlying layer would later modify that same buffer., Label: 0\n",
      "Processing row 3512 - Data Type: train, Message: The problem I got when writing to a BYTE, WORD or DWORD was that the PLC was sending me a \"Data Size mismatch\" error. To illustrate this:\n",
      "\n",
      "Writing a BYTE:\n",
      "ErrorCorde 0x07: [DATA]\n",
      "ResponseCode OK: [DATA][0][0][0][0][0][0][0]\n",
      "\n",
      "I don't understand where this comes from as it does not seem logic to me. This \"fix\" changes the size of the writeBuffer from (8/8) to (8 +0/8)  , Label: 1\n",
      "Processing row 3513 - Data Type: train, Message: Yes this one I forgot to remove, Label: 0\n",
      "Processing row 3514 - Data Type: train, Message: So if I have a short I want to write to the PLC, I should use SINT as memoryArea? And for an Integer  (since S7 INT is 2 bytes), Label: 1\n",
      "Processing row 3515 - Data Type: train, Message: I wasn't too sure about this because depending on the device they will list the Modbus address as 40001 or 400001. The extra 0 seems to have been added when the larger memory areas started to be used.\n",
      "\n",
      "In Proworx NXT when referencing Modbus addresses you can just type 41 and it will always take the first digit as the memory area, the rest will be the address. I wasn't sure about extending the format to this extent.\n",
      "\n",
      "It doesn't make sense to have more than 5 digits for the address though or values greater than 65536. I can fix this up., Label: 1\n",
      "Processing row 3516 - Data Type: train, Message: Hi Chris,\n",
      "\n",
      "Maybe I'm confused by what implicit and simple mean. I take them to mean:-\n",
      "Simple - Use the value that is included in the response.\n",
      "Implicit - Attempt to calculated the value based on the other fields in the response.\n",
      "\n",
      "As the length of the ModbusPDUReadFileRecordResponseItems is included in the response I changed it to simple instead of trying to calculate it from the data field., Label: 1\n",
      "Processing row 3517 - Data Type: train, Message: It really depends on order in which codecs are added - this was an extra fence I made while looking right place to add codec. So yeah, this `if` statement can be safely removed now., Label: 0\n",
      "Processing row 3518 - Data Type: train, Message: I have removed configuration handling from configurer cause now it is available to builder. Given above we now can have multiple builders which construct stack in different ways. One note, leaving `SingleProtocolStackConfigurer` with its initial class based approach will require us to introduce second type which will differ only by single lines. These lines will be calls to suppliers instead of reflection.\n",
      "\n",
      "Are you suggesting to revert `SingleSupplierProtocolStackConfigurer` and duplicate its functionality to other place?, Label: 1\n",
      "Processing row 3519 - Data Type: train, Message: I think we were planning to use it from Plc4xSourceRecordProcessor.. we could change it to protected?, Label: 1\n",
      "Processing row 3520 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3521 - Data Type: train, Message: In unit tests, all RPC interfaces involved in interacting with RocketMQ used mocks for data returnï¼Œand this two delete interface methods return void, Label: 0\n",
      "Processing row 3522 - Data Type: train, Message: I was thinking we could add to the address deletion policy options NO_QUEUES where it only deletes the address if all queues are deleted (e.g. it doesn't try delete the queues, it relies on logic before hand to remove the configured ones, and relies on consumers and other logic to remove auto gen'd (similar to auto-delete-addresses but it deletes address if not auto created) . \n",
      "\n",
      "So we then have OFF, NO_QUEUES, FORCE. \n",
      "\n",
      "Would this satisfy this concern?, Label: 1\n",
      "Processing row 3523 - Data Type: train, Message: Eg we want to control durable queues from broker xml. But we don't control non durable. , Label: 0\n",
      "Processing row 3524 - Data Type: train, Message: @clebertsuconic Going back to having extra policy, so that both cases can be covered what if we call yours force and we call ours kill, Label: 0\n",
      "Processing row 3525 - Data Type: train, Message: Please, would you be so patient and explain me, how to do this? I have implemented enum (in latest commit), but I don't think so it is what you intended., Label: 1\n",
      "Processing row 3526 - Data Type: train, Message: The StompTransaction is just a data holding acks/sends, the real transaction is delegated to core session. Using XA would be unnecessary as we are not dealing with global transactions., Label: 0\n",
      "Processing row 3527 - Data Type: train, Message: @michaelandrepearce I have used the same message as in another if-else condition. is it ok?, Label: 1\n",
      "Processing row 3528 - Data Type: train, Message: I can change it back but I was using -1 to figure out whether or not the value was set.  The issue is that if someone manually wants to set the client to the same value as that constant then it will always be overriden by the default from the server.  The idea is if the client sets the value that should be used instead....Not sure how to get around that without adding another flag to indicate the user overrode the value (or set it to null by default), Label: 1\n",
      "Processing row 3529 - Data Type: train, Message: BTW: Two CFs can still have different settings.. on the CF this is just altering the default. You can still switch independently on the CF. The default now comes from a system property instead of a constant variable.\n",
      "\n",
      "\n",
      "As of on the ActiveMQJMSClient, there's no way to alter the semantic without a system property. But users shouldn't be encouraged to use that class anyways. I'm considering to set it as deprecated., Label: 0\n",
      "Processing row 3530 - Data Type: train, Message: @michaelandrepearce \n",
      ">>> Also this will act as a broken window and encourage further set this way, further causing such issue.\n",
      "\n",
      "\n",
      "The system property should change defaults only. Only exception will be the AtiveMQJMSClient.\n",
      "\n",
      "I don't see any difference than getting a System.property on the class itself instead of encapsulating usage here., Label: 0\n",
      "Processing row 3531 - Data Type: train, Message: @michaelandrepearce The class is singleton. \n",
      "\n",
      "the reason I did not make it final was because of testcases where I can call init() to reload properties., Label: 0\n",
      "Processing row 3532 - Data Type: val, Message: I did not mean to change this class. accident! \n",
      "fixing it!, Label: 0\n",
      "Processing row 3533 - Data Type: train, Message: Now when I look at this again, this whole second loop in the _original code_ doesn't make sense - the only way execution could get here is when the ```interrupted``` flag was set to true, in which case we should exit immediately. The comment mentions \"deadlock exception\", but any exception in the first loop would terminate the method.\n",
      "\n",
      "I'm gonna remove this second loop altogether.\n",
      "\n",
      "Unfortunately history is not preserved..., Label: 0\n",
      "Processing row 3534 - Data Type: train, Message: The best wat I could think is to inject it as a constructor parameter similar to managementNotificationAddress; but advisory topics are just an OpenWire specific feature anyway, Label: 0\n",
      "Processing row 3535 - Data Type: train, Message: let me rewrite this, Label: 0\n",
      "Processing row 3536 - Data Type: train, Message: @michaelandrepearce I just wnated to show you an idea... but this is wrong now, Label: 0\n",
      "Processing row 3537 - Data Type: train, Message: it would always add the end, but I'm rewriting the logic now, Label: 0\n",
      "Processing row 3538 - Data Type: train, Message: You are right, it does not seem to fit properly in the MQTTSession, Label: 0\n",
      "Processing row 3539 - Data Type: train, Message: the log format is different. and the logging plugin serves a different purpose that auditing. (actually in amq5 they are totally different impls). and it brings in extra config.\n",
      "for hot path (actually so far there is only one sending message) I can use log level to easily control it.\n",
      "So I'd for the moment don't touch the logging plugin. \n",
      "wdyt?, Label: 0\n",
      "Processing row 3540 - Data Type: val, Message: Could you elaborate this? I thought FileChannel can only be created by FileInputStream/FileOutputStream/RandomAccessFile., Label: 1\n",
      "Processing row 3541 - Data Type: train, Message: Emm, i think we just need ChannelFuture of the last write(i.e. the file transfer here)?, Label: 1\n",
      "Processing row 3542 - Data Type: train, Message: We only get here for the InVM connection where we use in our test, so it doesn't matter with the performance? If needed, we can pass another parameter into constructor like fileChannel?, Label: 1\n",
      "Processing row 3543 - Data Type: val, Message: Do you mean we call write twice, first write buffer api, second new write file api in channel::send()? This way we will call netty channel::writeAndFlush twice, right?, Label: 1\n",
      "Processing row 3544 - Data Type: train, Message: Currently scheduledPool is used by:\n",
      "1) AMQPConnectionContext more time but one task at once for instance\n",
      "2) ActiveMQServerImpl one time and one task\n",
      "3) SharedNothingBackupQuorum one time and one task\n",
      "4) MessagePullHandler each time AMQConsumer.handleDeliver is called if prefetchSize = 0\n",
      "\n",
      "ScheduledPool is mostly used by AMQPConnectionContext (one for each amqp connection) and remove is called only on connection close, so the effort for the remove should not impact on the entire system scalability.\n",
      "Moreover GC should manage that unused objects until they are not removed from the scheduledPool.\n",
      "Finally WeakReference require deeper source change for ScheduleRunnable and TickerRunnable to avoid unpredictable behavior when GC delete AMQPConnectionContext before their execution.\n",
      "\n",
      "My concern is that to introduce unpredictable behavior to avoid paying a small computational cost., Label: 0\n",
      "Processing row 3545 - Data Type: train, Message: TBH, I can't reproduce the issue on JournalStorageManager/JournalImpl but in theory they should have the same issue of JDBCJournalStorageManager/JDBCJournalImpl. I think the issue on JournalStorageManager/JournalImpl is hidden by better performances., Label: 0\n",
      "Processing row 3546 - Data Type: train, Message: The getBodyBufferSize only retrieves the fileSize after opening file, and I assume this is only for reading. For this reason, I close it without flushing. I want to ask how you found files leaking? Are the leaking files large message ones?, Label: 1\n",
      "Processing row 3547 - Data Type: train, Message: The AddressSettings maybe persisted in disk, and if we change long to int, we would incorrectly decode it. Does it make sense?, Label: 1\n",
      "Processing row 3548 - Data Type: train, Message: > E.g. other sizes are quite happily long currently also. Why is this special\n",
      "\n",
      "I see in Page::write()/Page::read() all operations are limited to int range, such as PagingStoreImpl::currentPageSize, Page::size, and local variables like fileSize, processedBytes in Page::readFromSequentialFile(), etc.\n",
      "\n",
      "> This test, test the new change, but doesnt test for what we are protecting from. E.g whats the underlying issue being fixed\n",
      "\n",
      "I'm not sure what you mean. We're protecting page-size-bytes from being greater than Integer.MAX_VALUE(2147483647). So if we set page-size-bytes to 2147483648, the broker is expected to fail fast to throw exception , correct?\n",
      "\n",
      "\n",
      "\n",
      "\n",
      ", Label: 1\n",
      "Processing row 3549 - Data Type: train, Message: @michaelandrepearce I tried to explain the reasoning for the change as part of the Jira issue, have you read that already?, Label: 1\n",
      "Processing row 3550 - Data Type: train, Message: But is not faster according my tests...in one case we perform more comparisons... , Label: 0\n",
      "Processing row 3551 - Data Type: train, Message: > > > Send a message to the broker using OpenWire client\n",
      "> \n",
      "> Perhaps we could fix whatever conversion made that happen?\n",
      "\n",
      "Agree. I think the problem is located in the AMQP module but it needs more investigation. Can we create another Jira for that and release this fix?, Label: 0\n",
      "Processing row 3552 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3553 - Data Type: train, Message: I agree, and I raised that with you. but this is not part of my change here though. this could be a different PR., Label: 0\n",
      "Processing row 3554 - Data Type: train, Message: I am not sure it's safe to do that in case the encodeSize changed between the contruction and when getStoredSize is used.\n",
      "\n",
      "We can change this If you're sure it's safe. I wasn't bold enough., Label: 1\n",
      "Processing row 3555 - Data Type: val, Message: I didn't think it was final.. I thought I was going to have a setter when I wrote this.. changing it., Label: 0\n",
      "Processing row 3556 - Data Type: train, Message: PageReaderTest is from a different testsuite. IDEA may not like it., Label: 0\n",
      "Processing row 3557 - Data Type: val, Message: I am removing the clear on onAddedTaskifNotRunning, Label: 0\n",
      "Processing row 3558 - Data Type: train, Message: Ok, I tried with the mvn command from the automated build with the additional testing profiles and it fails on my laptop as well now. But I might just need to do a restart because it complains on CLI testcases where it complains about a process already using some file. That does not seem related to the patch.\n",
      "\n",
      "But is the fix correct in the sense there is a release missing on this buffer which needs to be added somewhere (maybe not here, but somewhere?\n",
      "\n",
      "We have been running this fix on an environment for a week and we have had no netty LEAK reports anymore (they started from version 2.11) and have noticed no issues related to data quality. But maybe we have a narrow case with very little coverage. If we remove this patch we get netty LEAK reports and the server crashed in around 6 hours because of no pooled direct buffer memory left to be used.\n",
      "\n",
      "So if the assumption of the release call is correct, we can maybe change it. Something like: give all the handlers their own view and let them release it themselves. Would something like that be an option?, Label: 0\n",
      "Processing row 3559 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3560 - Data Type: train, Message: it was really just for consistency, but this could be internal to the custom consumers structure as you suggested below, which would be simpler, Label: 0\n",
      "Processing row 3561 - Data Type: train, Message: I have reverted to just accessing the volatile and doing the logic inside a sync if necessary. The updater is no more., Label: 0\n",
      "Processing row 3562 - Data Type: train, Message: the crux of the problem here is that the queue address contains wildcards and those are not valid in for finding matching bindings or as the message address. you cannot send to a.#, you can only consume a.b from a.#, Label: 0\n",
      "Processing row 3563 - Data Type: train, Message: I don't think that will work with wildcards, b/c the queue can be bound multiple times, depending on what addresses it matches. Also a remote a/+ is a match for a local a/#, both match a message published to address a.b\n",
      ", Label: 0\n",
      "Processing row 3564 - Data Type: train, Message: true, that is not necessary. will fix. thanks! , Label: 0\n",
      "Processing row 3565 - Data Type: train, Message: it did handle groups before!, Label: 0\n",
      "Processing row 3566 - Data Type: train, Message: the reset on NO_MATCH I am not understanding. Does that make sense to you?, Label: 1\n",
      "Processing row 3567 - Data Type: train, Message: please ignore the remark about getClass().getSimpleName(). there are only very few internal classes that are not a sub of CoreMessage. so that problem is negligable., Label: 0\n",
      "Processing row 3568 - Data Type: train, Message: maybe I should squash to prevent confusion?, Label: 1\n",
      "Processing row 3569 - Data Type: train, Message: There are few ways to achieve the same effect.\n",
      "I am creating parent `RuntimeException` with `writableStackTrace = false`, see line below which also ensures stacktrace is not populated.\n",
      "\n",
      "I have extended the unit test to illustrate my point., Label: 0\n",
      "Processing row 3570 - Data Type: train, Message: I wouldn't know how to do that TBH, Label: 0\n",
      "Processing row 3571 - Data Type: val, Message: this will be null on tests only..., Label: 0\n",
      "Processing row 3572 - Data Type: val, Message: why?, Label: 1\n",
      "Processing row 3573 - Data Type: train, Message: @franz1981 Is this looking better?, Label: 1\n",
      "Processing row 3574 - Data Type: train, Message: Okay... I will try to get that working. Do I have to do anything in particular to be able to run the test classes from the integration-tests-suite? Might be an issue with my setup but I can't import: `org.apache.activemq.artemis.core.protocol.openwire.amq.AMQConsumerTest `\n",
      "straight up?, Label: 1\n",
      "Processing row 3575 - Data Type: train, Message: @gemmellr Like this?, Label: 1\n",
      "Processing row 3576 - Data Type: train, Message: I did consider placing this in the OpenWireProtocolManager instead but opted for this... Would you prefer I place it there and use setter/getter instead?, Label: 1\n",
      "Processing row 3577 - Data Type: train, Message: Yes, but since now there will only be one such calculation per new queue, (plus new ones if the cache is full) I figure that might be cheaper overall anyway? I changed it because this method has a lower risk of creating identical hashes for different values (from my testing at least)..., Label: 1\n",
      "Processing row 3578 - Data Type: train, Message: Not really... in previous versions this was just using ThreadLocal. (2.16.0 is using a regular ThreadLocal).\n",
      "\n",
      "in more recent versions we started using the FastThreadLocal, that's just a ThreadLocal with its own Map away. (there will be a single HashMap entry on the Thread.threadLocals.\n",
      "\n",
      "this is still an issue.. it should be static.\n",
      "\n",
      "\n",
      "I could still use the FastThreadlocal here. but I don't see a reason for., Label: 0\n",
      "Processing row 3579 - Data Type: train, Message: Ive changed this, Label: 0\n",
      "Processing row 3580 - Data Type: train, Message: I initially did that actually! but afaict there's something a little weird going on here where if the \"DISI supplier\" is built by the \"builder\" at the end of `getSegState(LeafReaderContext)`, it's actually building a seg-specific set that's ultimately retrieved via `setStates[context.ord]`, and passed a somewhat redundant `LeafReaderContext`. So I _think_ that for sets that get manually built in this way, they either need to be built as a single DocSet across all segs, or as a DocSet that pertains to a single segment only (if that's even a thing?). Both of those seem awkward, which is why I ended up sticking with the DocIdSet for this case. It's definitely a bit weird though, so I'm curious what you think of any alternatives., Label: 0\n",
      "Processing row 3581 - Data Type: val, Message: fwiw, I did intend this code to be (and am pretty sure it is) thread-safe. Because `cachedFloorDocs` is privately built in its entirety by a calling thread and set atomically, the worst-case scenario is that multiple threads end up building the same array, and the array that ends up being cached is arbitrary.\n",
      "Analogous to `cachedOrdIdxMap` in `SortedIntDocSet`, there are four options:\n",
      "1. accumulate the relevant information during collection and supply it as an arg to the ctor (feasible? given the different ways in which DocSets might be built?)\n",
      "2. eagerly compute the relevant information in the ctor (unnecessary work for DocSets that are only used at the global level -- i.e., never need to supply a per-segment iterator) \n",
      "3. compute (and cache) the relevant information on-demand the first time `DocSet.iterator(LeafReaderContext)` is called\n",
      "A fourth option (for `BitDocSet` anyway) is \"do nothing\", but given that DocSets are cached, and the optimization of returning `null` instead of empty iterators can be valuable to consumers, I do think it's worth the extra effort to do _something_ here ..., Label: 1\n",
      "Processing row 3582 - Data Type: train, Message: This is only within the `if (context.isTopLevel)` block -- my assumption was that makes this ok, no? I think the equivalent functionality on `Filter` in current master branch effectively [makes the same assumption](https://github.com/apache/solr/blob/7ada4032180b516548fc0263f42da6a7a917f92b/solr/core/src/java/org/apache/solr/search/BitDocSet.java#L254-L256)?, Label: 1\n",
      "Processing row 3583 - Data Type: train, Message: The only reason this was introduced was to continue to support explicit random access from [IntervalFacets.getCountString()](https://github.com/apache/solr/blob/7ada4032180b516548fc0263f42da6a7a917f92b/solr/core/src/java/org/apache/solr/request/IntervalFacets.java#L295-L304).\n",
      "But as you point out [here](https://github.com/apache/solr/pull/2#discussion_r593178464), I think you're right that [it's redundant](https://github.com/apache/solr/blob/7ada4032180b516548fc0263f42da6a7a917f92b/solr/core/src/java/org/apache/solr/request/IntervalFacets.java#L406-L409), since the `bits` instance is derived from the same source as the `disi`, so `bits.get(doc)` will _never_ be `false`.\n",
      "Nice, this can be removed then!, Label: 0\n",
      "Processing row 3584 - Data Type: train, Message: I would have liked to remove this entirely, but there are still a number of cases where the `Filter` returned from `DocSet.getTopFilter()` is used as a `Query`, rather than directly used to retrieve a per-segment `DocIdSetIterator`. Some of these cases go pretty deep, so I considered that use case to be a separate question, and left it alone for now.\n",
      "It's true that this might be more straightforward than I initially perceived it to be; but even if straightforward, I think it might involve a significant amount of refactoring (however rote), so I guess my inclination would be to make the \"Filter used as Query\" case its own issue?, Label: 1\n",
      "Processing row 3585 - Data Type: train, Message: Sorry, it was my turn to be out for a couple of days.\n",
      "\n",
      "I'm using 8.8.1 with the request that's shown in this PR:\n",
      "`http://localhost:8983/solr/gettingstarted/select?mlt.fl=name&mlt.mindf=0&mlt.mintf=0&mlt=true&q=author%3Amartin`\n",
      "\n",
      "If I add `mlt.interestingTerms=details` to that request I get the exact same output shown here, without an `interestingTerms` section.\n",
      "\n",
      "Is it possibly related to the field configuration? I indexed the exampledocs shipped with Solr for this, and the `name` field I'm using is stored but does not have termVectors enabled (despite the docs saying it should).\n",
      "\n",
      "When I change the query to `q=*:*`, I also do not get the interesting terms. And I tried taking off the `mindf` and `mintf` params and still don't get the interesting terms section., Label: 0\n",
      "Processing row 3586 - Data Type: train, Message: It seems no other collection properties are added into props. , Label: 0\n",
      "Processing row 3587 - Data Type: train, Message: Yes, I added a warning in HttpShardHandlerFactory#init() line 228. Is it what you thought of?, Label: 0\n",
      "Processing row 3588 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3589 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3590 - Data Type: train, Message: I don't understand this comment., Label: 1\n",
      "Processing row 3591 - Data Type: train, Message: I was unaware of SolrCoreAware, I'll go check it out. Thanks.\n",
      "\n",
      "The other larger change is to have circuit breakers only interrupt external requests and to not interrupt internal requests to shards. The current approach multiples failures. , Label: 1\n",
      "Processing row 3592 - Data Type: train, Message: An extra base class only for CPU actually makes the code base more complicated, not less. The other circuit breaker is a memory CB, so this cannot be shared with those.\n",
      "\n",
      "I can't think of another CPU breaker, so let's follow YAGNI and avoid introducing extra base classes \"just in case\".\n",
      "\n",
      "Some quick line counts show that the two files have 115 and 139 lines. A quick diff | wc shows 86 differences between the two files. So there isn't as much overlap as it might appear., Label: 0\n",
      "Processing row 3593 - Data Type: train, Message: We disagree about coding style.\n",
      "\n",
      "This fixes a bug. The existing CPU circuit breaker really is not usable because the inputs are limited to the wrong values., Label: 0\n",
      "Processing row 3594 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3595 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3596 - Data Type: train, Message: @noblepaul  when doing a GET request for V2, I found it to be a problem that we add this stream that is empty, resulting in an exception at some point about a blank Content-Type (as there is no content in the first place).  StandardRequestParser.parseParamsAndFillStreams checks !isPost and isV2 and then calls this raw impl.\n",
      "I could probably be more thorough here in detecting the presence of a stream.  Just because it's not a GET doesn't mean there is a stream!  Weirdly, req.getInputStream can return non-null for a GET which I observed in a test I added in this PR., Label: 0\n",
      "Processing row 3597 - Data Type: train, Message: _Maybe_... but I find it clearer to separate the two separate objectives rather than intertwine them., Label: 0\n",
      "Processing row 3598 - Data Type: train, Message: to remove intermediate `.` or `..` from absolute Path., Label: 0\n",
      "Processing row 3599 - Data Type: train, Message: I think I've done it, formatting is one of the things I hate the most, my opinion is that it shouldn't be the responsibility of single peers but it should be server side to avoid inconsistencies(which I often find also in Lucene/Solr and other Open Source code).\n",
      "Never really explored a solution for that either, so I hope, my changes are ok now :), Label: 0\n",
      "Processing row 3600 - Data Type: train, Message: done!, Label: 0\n",
      "Processing row 3601 - Data Type: train, Message: line 653 was wrong, Label: 0\n",
      "Processing row 3602 - Data Type: train, Message: Because it currently does not work with http2, though I have spun these fixes into: SOLR-15547, Label: 1\n",
      "Processing row 3603 - Data Type: train, Message: It probably should be. Was not sure I might do something a little more solid than hashing for preventing regen per iteration on a run., Label: 0\n",
      "Processing row 3604 - Data Type: train, Message: Lookis I am stuck with IOException, it won't let me specify SolrResourceNotFoundException., Label: 0\n",
      "Processing row 3605 - Data Type: train, Message: Done....    I don't know how you knew to set that however!   Wonder if there is a check that could have flagged this?, Label: 1\n",
      "Processing row 3606 - Data Type: train, Message: Reading through this again...   I see that we have decided that schema.xml can't be the managed schema file...    Which I guess is fine, but if you wanted it to be?   Is tehre a use case for being able to override the default managed schema name?   I was wondering if it could just be hardcoded to \"managed-schema.xml\" (wiht the legacy fall back to \"managed-schema\".   Is there ever a reason to have a different name?, Label: 1\n",
      "Processing row 3607 - Data Type: train, Message: hi @markrmiller, I encountered this logic, while moving these `bootstrap_confdir ` and `bootstrap_conf` properties to ConfigSetService. It seems to me (based on the comment) this logic is no longer valid and removed it.  Could you elaborate more on this logic if it is needed? , Label: 1\n",
      "Processing row 3608 - Data Type: val, Message: another concern: ZkCli.main() uses ConfigSetService.bootstrapConf(); although it is ZkConfigSetService, zkController is null. I tempted to do assertion `assert coreContainer.getZkContainer != null` in ConfigSetService.bootstrapConf(), but then I see zkController is not instantiated in ZkCli. Maybe edge case;, Label: 0\n",
      "Processing row 3609 - Data Type: train, Message: > We probably want to look at renaming some of the packages for the moved classes, since split packages are going to cause problems down the line anyway. Maybe ok to do this in a follow on issue if it ends up being too much here.\n",
      "\n",
      "Thanks for the review! \n",
      "\n",
      "@madrob, @dsmiley: Do you think it would make sense to include something like testfixture in the package name of the test fixture classes we put to the test framework? For example org.apache.solr.testfixture.handler.  That way all the fixtures we put into the test framework would be centralized as they would all be subpackages of the org.apache.solr.testfixture and that would also make it easier to relocate them once we fix the problem with gradle vs. test fixtures ( https://issues.apache.org/jira/browse/SOLR-14660?focusedCommentId=17409690&page=com.atlassian.jira.plugin.system.issuetabpanels%3Acomment-tabpanel#comment-17409690 ). , Label: 1\n",
      "Processing row 3610 - Data Type: train, Message: Heh; there isn't really a \"common pattern\" for doing solrcloud vs standalone -- if you can find a better example to pattern after I'm certainly open to alternatives. iiuc this is what [SOLR-11872](https://issues.apache.org/jira/browse/SOLR-11872) sets out to do. This would have been _far_ easier also if it weren't for the fact that we specifically need to exercise the non-javabin serialization formats, and inspect their output directly. So that's _part_ of what made this setup more complex., Label: 0\n",
      "Processing row 3611 - Data Type: train, Message: unrelated tweaks for hdfs tests since I was running them a fair bit when trying for jetty 11, Label: 0\n",
      "Processing row 3612 - Data Type: train, Message: Maybe, but unrelated to the jetty changes. , Label: 0\n",
      "Processing row 3613 - Data Type: train, Message: This should not be a change in this issue. , Label: 0\n",
      "Processing row 3614 - Data Type: val, Message: yup, Label: 0\n",
      "Processing row 3615 - Data Type: train, Message: I don't know if this is a good or bad practice., Label: 1\n",
      "Processing row 3616 - Data Type: val, Message: Fixed!, Label: 0\n",
      "Processing row 3617 - Data Type: train, Message: Was modelling this on `getStoredHighlightFieldNames()` above, any thoughts on changing that one also to `ArrayList` at the same time?, Label: 1\n",
      "Processing row 3618 - Data Type: train, Message: No, if both `hl.requireFieldMatch` and `hl.queryFieldPattern` are specified then only the former one is used and the latter is (silently) ignored., Label: 0\n",
      "Processing row 3619 - Data Type: train, Message: @sonatype-lift ignore, Label: 0\n",
      "Processing row 3620 - Data Type: train, Message: Yea I think thats fair. I did this in dd022238b06df8614a4bd52b2e6fee199b69c9a0, Label: 0\n",
      "Processing row 3621 - Data Type: val, Message: This is an existing code, not part of this PR, are you suggesting to change that too?, Label: 1\n",
      "Processing row 3622 - Data Type: val, Message: done!, Label: 0\n",
      "Processing row 3623 - Data Type: train, Message: I've dropped the 'TODO' I had here - haven't seen any way to trigger this `else` block but I think it'd useful to have the warning message, just in case. Happy to drop it!, Label: 0\n",
      "Processing row 3624 - Data Type: train, Message: Removed te if condition as you suggested, Label: 0\n",
      "Processing row 3625 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 3626 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 3627 - Data Type: val, Message: Fixed, Label: 0\n",
      "Processing row 3628 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 3629 - Data Type: train, Message: > Did you pick this because \"/cluster\" was already taken by the `getCluster` method down below? Or was there another reason?\n",
      "\n",
      "Yes that's the main reason, \"/cluster\" had already been mapped to a method.\n",
      "\n",
      "> For reasons that I don't quite understand, the v2 API has two endpoints that expose the \"List Collections\" functionality: `ClusterAPI.getCluster` which we see below uses the \"/cluster\" path, and `CollectionsAPI.getCollections` [here](https://github.com/apache/solr/blob/c99af207c761ec34812ef1cc3054eb2804b7448b/solr/core/src/java/org/apache/solr/handler/CollectionsAPI.java#L79) which uses the path \"/collections\".\n",
      "\n",
      "Exactly. It was a challenge understing the same while working on the issue.\n",
      "\n",
      "> There's absolutely no reason for that afaict, and \"cluster status\" is a very natural thing to expose at \"/cluster\". So IMO we should be safe to delete `getCluster` in this PR.\n",
      "\n",
      "Will do that, Label: 0\n",
      "Processing row 3630 - Data Type: train, Message: is this in order?, Label: 1\n",
      "Processing row 3631 - Data Type: train, Message: Oh, I haven't seen the other check, I've just applied my earlier changes. Now I wonder if this per-call granularity is necessary in this logic. I can see the advantage that retrying a shard split with this error does not require a restart with this parameter., Label: 0\n",
      "Processing row 3632 - Data Type: train, Message: Not sure if I was supposed to use CollectionParams   SOURCE_NODE and TARGET_NODE , Label: 1\n",
      "Processing row 3633 - Data Type: train, Message: I agree. Having targetNodeName in the path wasn't ideal, Label: 0\n",
      "Processing row 3634 - Data Type: val, Message: Sure, Label: 0\n",
      "Processing row 3635 - Data Type: train, Message: > Unless you had a particular reason for excluding this from your RequestBody POJO below and from this message-creation here, that should probably be added?\n",
      "\n",
      "Will add that\n",
      "\n",
      "\n",
      "> Also, mostly unrelated to this PR, I notice that the [REPLACENODE ref-guide docs](https://solr.apache.org/guide/8_11/cluster-node-management.html#replacenode-parameters) mention a few parameters (parallel, timeout, etc.) that I don't see used in the code (either with or without your PR). Are those docs just plain wrong? Or am I missing something?\n",
      "\n",
      "You are right, the docs is not in sync with the code.. To add them to the RequestBody POJO will we have to write code for their functionality e.g for parallel  parameter `If this flag is set to true, all replicas are created in separate threads`, Label: 0\n",
      "Processing row 3636 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 3637 - Data Type: train, Message: Oh gotcha, not a problem - The way I read your original comment, I thought we were going fully with the static approach first, I can take some blame for my interpretation. I think what you're laying out here makes sense and I hadn't considered the case of multiple Solr Contexts running on a single VM. I took a little bit of time to see how I would register the map/executor, but haven't made any code changes yet. I will attempt to work on it this weekend if you haven't already gotten to it.\n",
      "\n",
      "Would migrating the status map and executor into a class that can then be used by both the CoreAdminHandler and made injectable for the CoreAdminAPIBase work? That may save us from having to inject multiple things and could potentially get us closer to the future state of what async could look like., Label: 0\n",
      "Processing row 3638 - Data Type: val, Message: yeah, I think if folks agree with moving to immutable SolrClient then yes?, Label: 0\n",
      "Processing row 3639 - Data Type: train, Message: there is a \n",
      "```\n",
      "  @After\n",
      "  public synchronized void afterClass() throws Exception {\n",
      "    if (client != null) client.close();\n",
      "    client = null;\n",
      "  }\n",
      "```\n",
      "\n",
      "There doesn't appear to be any one pattern...  , Label: 0\n",
      "Processing row 3640 - Data Type: train, Message: i don't think so, as we generate a new client on line 236 with a fresh `XMLResponseParser`, and the test pasts.  However, the method `testUpdate` is giving me problems...., Label: 0\n",
      "Processing row 3641 - Data Type: train, Message: Actually hoping someone else can confirm that the changes I made still keep the test working \"as designed\", and that this commented out code can just be deleted...., Label: 0\n",
      "Processing row 3642 - Data Type: train, Message: Just scavenged some text from a patch file that @gerlowskija had written!, Label: 0\n",
      "Processing row 3643 - Data Type: train, Message: I was not aware I deleted this comment. Looking at it, it is kind of obvious, maybe a bit redundant, but if you think it has a purpose we can put it back., Label: 0\n",
      "Processing row 3644 - Data Type: val, Message: the line 1214 is checking if `end > 0` - which was just an expansion of the previous if statement that was there. Previously `end > 0` was checked before updating `answer` only and then the for loops would skip since i = 0 and end = 0 in that case. I wanted it to be clear - if `end <= 0` we don't need to do this whole block.\n",
      "\n",
      "The end > 1 here is to make sure we have 2 bitsets to work with?\n",
      "\n",
      "Unless I'm misunderstanding your comment., Label: 1\n",
      "Processing row 3645 - Data Type: train, Message: I think this comment can move down to just above line 1200, Label: 1\n",
      "Processing row 3646 - Data Type: val, Message: Fixed in 26754f8e2f8db5ad6a5535eb10cb73d43d4739d3, Label: 0\n",
      "Processing row 3647 - Data Type: train, Message: I want to fix this as part of SOLR-16590 to get teh same name everywhere..., Label: 0\n",
      "Processing row 3648 - Data Type: train, Message: Should I define getSolrClient() in EmbeddedSolrServerTestBase to return the client created in the test rule or I should revert to how it was defined initially?, Label: 1\n",
      "Processing row 3649 - Data Type: train, Message: are you suggesting the method look like \"public Builder setRetryExpiryTime(int secs, TimeUnit seconds)\", Label: 1\n",
      "Processing row 3650 - Data Type: train, Message: we do have the \"int secs\" or \"int connectionTimeoutMillis\" as parameters on various methods.   I wonder if we should have another JIRA to go through and make all timeunits on builders be the same????, Label: 1\n",
      "Processing row 3651 - Data Type: train, Message: Thank you for the review! I do understand your concern of extra log info, it's important for our use case as queries can sometimes be totally stuck hence timeout wouldn't get printed.\n",
      "\n",
      "I do agree that it's probably quite specific to our own scenarios (and we might not really seeing issues like that anymore), perhaps changing it to debug will be more suitable?, Label: 1\n",
      "Processing row 3652 - Data Type: train, Message: Thanks for the useful insight David! Is it any better now?, Label: 0\n",
      "Processing row 3653 - Data Type: train, Message: Ok,  now I remember this bit, I was initially (and I am still) not a fan of that boolean param (as I tend to forget what it means and the name also doesn't help).\n",
      "We discussed for a better name(we couldn't find) and the reason to put it that was was because that piece of code was shared across various Solr parts and other reviewers thought it was better to isolate it and move it to the queryUtils.\n",
      "\n",
      "Not sure of course, if it's still the best solution to be honest, Label: 0\n",
      "Processing row 3654 - Data Type: train, Message: I could get behind eliminating these....    It makes SolrTestCaseJ4 super long and busy....., Label: 0\n",
      "Processing row 3655 - Data Type: train, Message: Makes sense..   I went and looked, and they all pretty much were only used by 1 test method...   , Label: 0\n",
      "Processing row 3656 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3657 - Data Type: train, Message: argh, merge issue, Label: 0\n",
      "Processing row 3658 - Data Type: train, Message: I thought about putting it on 'ConfigSet' directly but ultimately opted to keep it here so all the logic remained together in one place.\n",
      "\n",
      "I was also a little leery of making a \"broader claim\" than necessary here.  This ID generation logic works perfect for our local needs in determining an \"effective configset\", but IMO it's totally plausible that other places in Solr might want to come up with configset IDs from some other criteria.  I didn't want to elevate this approach by putting it on ConfigSet., Label: 0\n",
      "Processing row 3659 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3660 - Data Type: train, Message: I'll need to think about this a bit more.\n",
      "\n",
      "I think we could trivially fix this by making JerseyAppHandlerCache.computeIfAbsent a synchronized method, but that seems like a bit of a blunt instrument that would do a good bit of over-locking.  Conversely we could create a different lock for each key (i.e. effective-configset ID) and do more fine-grained locking, but that feels complex for the risk and impact here., Label: 0\n",
      "Processing row 3661 - Data Type: train, Message: I must admit, I hadn't realized Java 11+ supported execution without compilation, I didn't pick up on that being used by gradlew. That's cool (even if it is limited to self contained source files)\n",
      "\n",
      "I will switch to that, that's much better.\n",
      "\n",
      "> My idea would be to modify this script/class (executed without compiling directly with java) to write the properties file.\n",
      "\n",
      "I see [WrapperDownloader takes an arg](https://github.com/apache/solr/blob/main/buildSrc/src/main/java/org/apache/lucene/gradle/WrapperDownloader.java#L48-L51) for the destination it downloads the gradle wrapper jar to.\n",
      "Do you think it's preferable to add this functionality to the WrapperDownloader and it just grows a little, or create a separate class and invoke it on its own?, Label: 1\n",
      "Processing row 3662 - Data Type: train, Message: Actually I suppose this one should be commented out. I assume `(custom paths)` isn't a special value, it's a placeholder?\n",
      "```suggestion\n",
      "#org.gradle.java.installations.paths=(custom paths)\n",
      "```, Label: 1\n",
      "Processing row 3663 - Data Type: train, Message: Or maybe `setHttp1_1`?    or `enableHttp_1_1()` and another `enableHttp_2()` that would flip taht flag?    This one felt a bit odd ot me too! , Label: 1\n",
      "Processing row 3664 - Data Type: val, Message: OMG...   For some reason I was locked into looking for red underlines from intellij, and never even thought about this.  In my other branch, I think I did the exact same thing again...   , Label: 0\n",
      "Processing row 3665 - Data Type: train, Message: Humm....    Good darn question...., Label: 0\n",
      "Processing row 3666 - Data Type: train, Message: IntelliJ told me the default is not actually ever used, it's always set..  so I removed it...   However, maybe I made a mistake/  Thanks for looking!   , Label: 1\n",
      "Processing row 3667 - Data Type: train, Message: i did a pass, but it looked a bit odd, and I'm worried about introducing a bug..  so I backed it out.  But it does point to do we need a pass through Solr codebase and try and get all our time handling variables names and initialization patterns to be the same?, Label: 1\n",
      "Processing row 3668 - Data Type: train, Message: Yeah, all the other functions seem to have `ensureOpen()` apart from `getTermVectors(int docID)` and `termVectors()` (of course I added this one).\n",
      "Should I add for both functions or should I add only for `termVectors()` and will take care of `getTermVectors(int docID)` in some other PR?, Label: 1\n",
      "Processing row 3669 - Data Type: val, Message: Hey @magibney, should we wait for his reply or should we add it back?, Label: 1\n",
      "Processing row 3670 - Data Type: train, Message: Changed, Label: 0\n",
      "Processing row 3671 - Data Type: val, Message: Removed, Label: 0\n",
      "Processing row 3672 - Data Type: val, Message: Same as above, Label: 0\n",
      "Processing row 3673 - Data Type: train, Message: I can't tell which way you are leaning here. are you suggesting I go for the new dependency and enable it for this api, or are you ok with leaving this as is and having a different PR for enabling annotation driven input validation for all existing apis that might need it? for me it works either way., Label: 0\n",
      "Processing row 3674 - Data Type: train, Message: @gerlowskija this might be a bug? I added some assertions to this older test and results are a bit surprising. my understanding is that setting value to null should remove it, but it doesn't. maybe I am reading it wrong., Label: 1\n",
      "Processing row 3675 - Data Type: val, Message: not sure I follow, could you clarify a bit?\n",
      "\n",
      "I have alias prop listing https://github.com/apache/solr/pull/1459/files#diff-2cc6e0ae57c6bf17247dd5a4386f98b3123544cb816a12fdb864068705970f00R670 and property level get https://github.com/apache/solr/pull/1459/files#diff-2cc6e0ae57c6bf17247dd5a4386f98b3123544cb816a12fdb864068705970f00R685, Label: 1\n",
      "Processing row 3676 - Data Type: val, Message: I do personally like the flexibility of the varargs, especially for most cases when there's no need for any args, then the invocation can just be `injectBreakpoint(\"mykey\")` instead of `injectBreakpoint(\"mykey\", null)`\n",
      "\n",
      "WDYT? ðŸ˜Š , Label: 0\n",
      "Processing row 3677 - Data Type: train, Message: yes let's change that to debug, i was a bit concerned if someone accidentally used different key names meant for the same Breakpoint for `injectBreakpoint` and `setImplementation`, so with this log message they can see whether the breakpoint is triggered.\n",
      "\n",
      "Though I guess this could be really noisy as you pointed out, and I assume the dev can search whether there's \"Breakpoint with key ... is triggered\" message instead and absence of that means either the execution path does not reach the breakpoint or the breakpoint has no implementation set, Label: 0\n",
      "Processing row 3678 - Data Type: val, Message: What I found was that the deprecated method setPollQueueTime is being used..  and that the logic iin the method needed to be preserved, so then I moved it...   I did want to have an extra set of eyes on it ;-).    WOuld you like me to cherry-pick the commit into a new PR???, Label: 0\n",
      "Processing row 3679 - Data Type: train, Message: Awesome!, Label: 0\n",
      "Processing row 3680 - Data Type: val, Message: Without it, I get these warnings:\n",
      "\n",
      "```\n",
      "> Task :solr:core:compileTestJava\n",
      "/Users/epugh/Documents/projects/solr-epugh/solr/core/src/test/org/apache/solr/cloud/TestRandomFlRTGCloud.java:180: warning: [rawtypes] found raw type: HashMap\n",
      "      Map<String, SolrClient> solrClientByWriterType = new <String, SolrClient>HashMap();\n",
      "                                                                               ^\n",
      "  missing type arguments for generic class HashMap<K,V>\n",
      "  where K,V are type-variables:\n",
      "    K extends Object declared in class HashMap\n",
      "    V extends Object declared in class HashMap\n",
      "/Users/epugh/Documents/projects/solr-epugh/solr/core/src/test/org/apache/solr/cloud/TestRandomFlRTGCloud.java:180: warning: [unchecked] unchecked conversion\n",
      "      Map<String, SolrClient> solrClientByWriterType = new <String, SolrClient>HashMap();\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 3681 - Data Type: train, Message: I don't think it uses the sql module..  it's just a straight up solr query, not a sql one...., Label: 0\n",
      "Processing row 3682 - Data Type: train, Message: I dug around, and never saw where `CODE` was referenced.....  BATS still ran....   Is there maybe a reason to set it that is global that you would want it?   , Label: 1\n",
      "Processing row 3683 - Data Type: train, Message: A quick google for \"bash and CODE\" didn't turn up anything like it's a well known global variable or anything.  it also isn't used by other tools..., Label: 0\n",
      "Processing row 3684 - Data Type: train, Message: since we don't have this on other packageTools, can we leave adding it in as a seperate PR?    I don't have a ton of confidence in my bash skills, so nervous about tacking on a new feature and not getting it working..., Label: 1\n",
      "Processing row 3685 - Data Type: train, Message: I've added https://issues.apache.org/jira/browse/SOLR-16794 to track properly doing Exit codes everywhere (and we'll want to bats test them!), so I'm going to call this PR good to go and merge it before it gets more stale?  Is that cool @risdenk ?, Label: 1\n",
      "Processing row 3686 - Data Type: train, Message: Hi Jason, thanks for the review! Glad most of it looks good.\n",
      "\n",
      "As for your comment on injecting the SolrCore, I'm not sure how this would be done in this API. The user specifies the `coreName` for which the API then uses to retrieve the SolrCore from the coreContainer. \n",
      "\n",
      "Maybe I need to read more on Solr's Jersey Injections, but how would you inject the SolrCore in the constructor without knowing what `coreName` the user was asking for that is specified in the URI path?, Label: 1\n",
      "Processing row 3687 - Data Type: train, Message: Swapped the arguments to correct assertion., Label: 0\n",
      "Processing row 3688 - Data Type: train, Message: Ah nice catch on the missed typo by me. Fixed, Label: 0\n",
      "Processing row 3689 - Data Type: train, Message: I was doing an experiment before this approach to try and pass all the necessary parameters, but I have found [here](https://github.com/apache/solr/blob/8089e6fc6a9d37299df9a63e5372ec5c235e4f9a/solr/core/src/java/org/apache/solr/schema/IndexSchema.java#L1643-L1647) that we would need at least 6 parameters. I considered it a bit too much to nicely handle so I went ahead and used the parameter injection instead. \n",
      "If you think 6 parameters is a viable option I can easily change it back to that approach. Let me know what you think!, Label: 0\n",
      "Processing row 3690 - Data Type: train, Message: It should be the same name as the one in parenthesis. Will change it!, Label: 0\n",
      "Processing row 3691 - Data Type: train, Message: I will change it to `Boolean`. Also,\n",
      "[Q] Should I set default value to 'true' here? Because, and also you mentioned, in `BackupCoreOp.java, If `incremental` is missing they set it to 'true'., Label: 1\n",
      "Processing row 3692 - Data Type: train, Message: `CoreSnapshotResponse` looks good because most of our JerseyResponse classes ends with 'Response' keyword. There is another class named `IncrementalBackupCoreResponse.java`. Should I change it to `IncrementalShardSnapshotResponse.java`., Label: 1\n",
      "Processing row 3693 - Data Type: val, Message: My bad, I thought I had deleted that. Will remove., Label: 0\n",
      "Processing row 3694 - Data Type: train, Message: That's a good catch. I only tested on localhost and https hosts. I think you're right, this would't work on http. \n",
      "What do you suggest? Keep it as it is and require https for this plugin, or change the code to support http?, Label: 1\n",
      "Processing row 3695 - Data Type: train, Message: I made the change to combine them in c486782d67f9c927809968105f21cc2ff78ab3af, and it ended up being a bit more intrusive then I expected.  All tests pass.  Can you give it a quick look?, Label: 0\n",
      "Processing row 3696 - Data Type: train, Message: We could...  @risdenk do you have an opinion?   , Label: 1\n",
      "Processing row 3697 - Data Type: train, Message: true, 'out' passed in to getFilesPosted is always 0 hence it does not need be past in. will fix it. thanks, Label: 0\n",
      "Processing row 3698 - Data Type: train, Message: It seemed to me that a word was missing here, but I'm not sure what that word needs to be - appreciate the help here., Label: 1\n",
      "Processing row 3699 - Data Type: train, Message: Here, I just updated the xml snippets - so if the text says `in this example showing BM25Similarity`, the example indeed uses the similarity directly and not the factory. I tried writing this snippet as\n",
      "```xml\n",
      "<similarity class=\"solr.BM25Similarity\"/>\n",
      "```\n",
      "at first - but it seems like if the similarity class is from Lucene, the `solr.` shorthand doesn't work.\n",
      "\n",
      "And the original xml snippet (that was using the similarity factory) now appears after the text that talks about similarity factories., Label: 0\n",
      "Processing row 3700 - Data Type: train, Message: @risdenk, @noblepaul  Do you agree with the above assumption, i.e. that a custom permission MUST have either a \"path\", \"method\" or \"params\" key? Perhaps the rule could be simplified to say it must have a \"path\" key?\n",
      "\n",
      "I.e. \n",
      "\n",
      "```java\n",
      "    } else if (!m.containsKey(\"path\")) {\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 3701 - Data Type: train, Message: Should I use `var` in place for `RenameCoreApi`?, Label: 1\n",
      "Processing row 3702 - Data Type: train, Message: Good catch @magibney ! I'm wondering if these 2 statements should just be placed in https://github.com/apache/solr/blob/d8902468b8b292cb37ee3e1ba8d1a724752ab9a8/solr/core/src/java/org/apache/solr/cluster/placement/plugins/OrderedNodePlacementPlugin.java#L516 directly?\n",
      "\n",
      "Perhaps I have overlooked some edge cases which using the AtomicBoolean hasReplica was necessary ?, Label: 1\n",
      "Processing row 3703 - Data Type: val, Message: After i read the code again, I'm not 100% about the original purpose of `hasReplica` flag. \n",
      "\n",
      "However, it does make the logic a bit more isolated and easier to follow - iterate the list first, figure out if the replica exists, if it does, deal with it AFTEr finishing the traversal. In a logical level, it's pretty clean and avoid any concurrent modification exception (though the map/list being iterated on is private field anyway).\n",
      "\n",
      "Hm...I simply move the allReplicas.remove to within the `if (reps.remove(replica))` block now, cause i do think it's the best if the operations (add/remove) on the 2 collections stay close to each other.\n",
      "\n",
      "Anyway, I think these are very minor concerns? ðŸ˜Š either ways are fine\n",
      ", Label: 0\n",
      "Processing row 3704 - Data Type: train, Message: As discussed, the current fix is to use the most defensive approach which does not modify the behavior at all. The minor concern with `unmodifableSet` was that the \"view\" could still mutate after this method returns and this could break certain expectation of the caller.\n",
      "\n",
      "Otherwise I don't have any objection using `unmodifableSet`. Perhaps @HoustonPutman can share some thoughts? ðŸ˜Š , Label: 0\n",
      "Processing row 3705 - Data Type: train, Message: this method did return negative values for UB before. It did not handle lgK > 12. I fixed that.\n",
      "I agree that returning negative is confusing, but changing that might break somebody's code. Perhaps it is fine now in Java since we are getting ready for a major release, but I am not sure how to approach this in C++, where we had a major release recently., Label: 0\n",
      "Processing row 3706 - Data Type: train, Message: At the moment, the GrokParser is limited to a single complied pattern that needs to match every incoming message. This works well for logs where the format is always the same (e.g. proxy logs, http access logs); however, falls short for devices with many different message types using different formats. ASAs are a good example of this as are standard Unix/Linux syslog messages.\n",
      "\n",
      "I'm not sure what the best approach would be to solve this issue, but, ideally the GrokParser would be able to parse disparate message types based on an input pattern file (or files). I played around with the pattern discovery feature of Grok when developing this parser. It works pretty well and could be an option but seemed to slow down overall processing. That's why I ultimately landed on a static map of possible ASA message patterns.\n",
      "\n",
      "I suppose another way would be to allow the user to specify as part of the configuration (1) a base message pattern (e.g. syslog) which should always match and then (2) an inner message pattern map which finds the best match and returns the results.\n",
      "\n",
      "What do you think?\n",
      ", Label: 0\n",
      "Processing row 3707 - Data Type: train, Message: It turns out the `ipValidator` function isn't adding any benefit here. The grok pattern being used on the raw message is already checking that it's a valid IP address (IPv4 or IPv6). Given that I'm going to simply remove that validation from the code as redundant.\n",
      ", Label: 0\n",
      "Processing row 3708 - Data Type: val, Message: Most of the code in the GrokService class handles reading and writing Grok statements from/to HDFS.  If we merge the PR to keep grok statements in Zookeeper this class can go away., Label: 0\n",
      "Processing row 3709 - Data Type: val, Message: 1. Define \"wrong window duration\"?  Can you give me an example of what you're thinking of?\n",
      ", Label: 1\n",
      "Processing row 3710 - Data Type: train, Message: Per (2)  That's a good thought.  I'm not ignoring it.  I just need to noodle on that a bit.  Hmm.\n",
      ", Label: 0\n",
      "Processing row 3711 - Data Type: train, Message: Unfortunately, the user does not get a reasonable error message.  It is a little bit of a sticky wicket.  I am sure its doable, but I just haven't thought of a way that I really like.\n",
      "\n",
      "A ProfilerClient uses a RowKeyBuilder along with the profile name, entity, period duration, and date range to construct a set of row keys that meet the user's query (see HBaseProfilerClient:100).  \n",
      "\n",
      "If there are no 'hits' for that set of row keys, then the user gets nothing back.  I'd need some way to distinguish between \"there is no data\" versus \"there is data, but it is written with a different period duration\".  \n",
      "\n",
      "I think it'd be a good bit of work to catch all the corner cases.  Although, I'm totally open to suggestions.  Maybe there is an easy way that I am not thinking about.\n",
      ", Label: 0\n",
      "Processing row 3712 - Data Type: train, Message: I think what you are saying makes total sense.  It is a good idea. We should have it.  I'd prefer to do it as a follow-on JIRA though.  Hey, maybe you could follow-on with your 'whomp'.  Ha.\n",
      "\n",
      "The one problem in doing it is due to the signature of PROFILE_GET.  It would be ideal to add the period duration, etc as arguments towards the end of the function.  That way the user can decide to pass in those additional args like duration or not.  I'd hate to require the user to pass it in.\n",
      "\n",
      "The problem is that the last argument is effectively a var arg of the group names.  That makes it difficult to do what you are asking.  How do you think we could work around that?\n",
      ", Label: 0\n",
      "Processing row 3713 - Data Type: train, Message: It's not really something that you'd want to specify on a live cluster.  It's only really useful when testing.  It allows you to throw in a mocked HBase table so you don't have to spin up an HBase mini cluster.  I questioned if I should even document it since a user will likely never use it.\n",
      ", Label: 0\n",
      "Processing row 3714 - Data Type: train, Message: I removed the line that pushes global config., Label: 0\n",
      "Processing row 3715 - Data Type: train, Message: For security reasons, Docker will not pull in any assets outside of the directory containing the Dockerfile.  You have to do that separately or provide a script.  \n",
      "\n",
      "We do have a script that copies in Metron dependencies at metron-docker/install-metron.sh.  Should we move the wait-for-it.sh script up to metron-docker and add steps to copy to images in install-metron.sh?, Label: 1\n",
      "Processing row 3716 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3717 - Data Type: train, Message: There are some diagrams. Think it's sufficient to link in the description, or should we consider embedding these images right into the README?, Label: 1\n",
      "Processing row 3718 - Data Type: train, Message: Yep, Label: 0\n",
      "Processing row 3719 - Data Type: train, Message: Heads up, I searched arxiv and  it doesn't appear that this paper is there., Label: 0\n",
      "Processing row 3720 - Data Type: train, Message: Added back in.  Didn't intend to drop them at all., Label: 0\n",
      "Processing row 3721 - Data Type: train, Message: @cestella Capability was left over from earlier testing.  Everything referred to the static instance anyway for precisely that reason.  Dropped it entirely and removed from the enum.\n",
      "\n",
      "@dlyle65535 There's not a geo specific bolt, it's an instance of GenericEnrichment. To the best of my knowledge (and correct me if I'm wrong), you can't grab global configs in the adapters.  This specific one gets dropped, but the prepare() method references the static INSTANCE Casey refers to.  Is there somewhere that could live?\n",
      "\n",
      ", Label: 1\n",
      "Processing row 3722 - Data Type: train, Message: I'm not even sure who we should talk to about how it should be handled.  I'm more than happy to adjust the changelog as needed, but I need to know how to change it first., Label: 1\n",
      "Processing row 3723 - Data Type: train, Message: This gets into the whole \"How do we manage configs discussion?\".  Unfortunately, it's in a really awkward spot.  I might be able to add a service action to sorta take care of it, but it still probably does the same end around of Ambari's management, except it's going through the UI. I don't know that there's a good solution to this until we unify our config management, which is the real answer here.\n",
      "\n",
      "Given that I don't think there was originally support for updating the db, I'm inclined to clean it up as part of unifying config management.  It's ugly and I don't like it, but I can't come up with a good, short-term, alternative that isn't ugly for other reason anyway., Label: 0\n",
      "Processing row 3724 - Data Type: train, Message: Is there a well defined expectation for what happens in cases like this?  I don't think I've seen anything, and on reflection I'm pretty sure I just based that off what other functions did.\n",
      "\n",
      "@cestella Can you shed some light on what perceptions/expectations exist for this case?  Or shame my reading comprehension by pointing me to where we have them documented, if we do?, Label: 1\n",
      "Processing row 3725 - Data Type: train, Message: There is no IP parsing. IPs are purely represented as strings in Metron, so this shouldn't be an issue. This would only be an issue at the validation stage, which is out of scope here., Label: 0\n",
      "Processing row 3726 - Data Type: train, Message: That sounds good to me, do you want me to revert these back to use `{name}` instead of `name` in anticipation of your fix?  Or I can leave this in and you can revert as a part of your fix.  Either way works for me, although I prefer the latter., Label: 1\n",
      "Processing row 3727 - Data Type: train, Message: Do you think adding a check for null as follows, would be the right way?\n",
      "\n",
      "```\n",
      " if(strings == null || strings.size() == 0) {\n",
      "    throw new IllegalArgumentException(\"[CHOP] missing argument: string to be chopped\");\n",
      "}\n",
      "```, Label: 1\n",
      "Processing row 3728 - Data Type: train, Message: Okay, thanks. I stand corrected about the URI/URL., Label: 0\n",
      "Processing row 3729 - Data Type: train, Message: But I think this actually turned out worse, than the alternative of just adding `RowKeyBuilder.setSaltDivisor` and polluting the interface., Label: 0\n",
      "Processing row 3730 - Data Type: train, Message: If I had some IoC-like functionality like Flux or Spring here, then this wouldn't be a problem at all., Label: 0\n",
      "Processing row 3731 - Data Type: train, Message: I chose to require a flux file change here because this is not something that any old user should just change.  This is only configurable to allow for backwards compatibility.\n",
      "\n",
      "In addition, the IoC-like functionality that Flux provides makes it easier to set whatever configuration values are needed by a `RowKeyBuilder` (like salt divisor) without polluting the `RowKeyBuilder` interface.\n",
      "\n",
      "There is no such convenient IoC-like functionality when trying to instantiate the `RowKeyBuilder` from the client-side in `GetProfile`., Label: 0\n",
      "Processing row 3732 - Data Type: train, Message: This basically sets the 'salt divisor' on any `RowKeyBuilder` that has a `saltDivisor` setter.  I really don't like this.  It is very hack-ish. I would love to use a simpler alternative., Label: 0\n",
      "Processing row 3733 - Data Type: train, Message: The downside of salting unfortunately is that doing a scan over a time range is tough.  While we don't do scans now, I think expanding the Profiler for more use cases will require us to do scans.  \n",
      "\n",
      "With a salt, you have to submit multiple scans, one for every possible salt value, and then merge what you get back.  \n",
      "\n",
      "That is why I was originally against using a salt.  But, of course, a salt has the advantage that @cestella outlined., Label: 0\n",
      "Processing row 3734 - Data Type: train, Message: @mattf-horton A 'length' the number of groups along with the size of each group name is encoded.  See the function `encodeGroup`.\n",
      "\n",
      "@cestella I would be fine with shorts instead of ints., Label: 0\n",
      "Processing row 3735 - Data Type: train, Message: Currently, it prepends each group with its length instead of using a delimiter. There are some unit tests that exercise this.   \n",
      "\n",
      "Were you thinking this did not work at all or were you suggesting a better way to do it?, Label: 1\n",
      "Processing row 3736 - Data Type: train, Message: I am sorry I don't know what you mean, Label: 1\n",
      "Processing row 3737 - Data Type: train, Message: I don't have that in my editor, do you have it in vim or something?  or is it just from what you see on the web?\n",
      "\n",
      "line 279?, Label: 1\n",
      "Processing row 3738 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3739 - Data Type: train, Message: Yup, Label: 0\n",
      "Processing row 3740 - Data Type: train, Message: It's definitely not cross-shell.  The shell scripts we have currently all shbang to bash on the first line for that reason., Label: 0\n",
      "Processing row 3741 - Data Type: train, Message: Extracting this logic into its own implementation class made it possible for me to test the new sort logic.  Just using mocks was not possible due to some of the key methods in the Elasticsearch API being declared final., Label: 0\n",
      "Processing row 3742 - Data Type: train, Message: Yes, I agree with your feedback.  I was just trying to refactor the column metadata logic and minimize other changes.  So in this case `.kibana` was already hard-coded in ElasticsearchDao.\n",
      "\n",
      "I would be totally open to making this improvement though.  I was just trying to walk the line of how much should I change when refactoring?  Considering that, what do you think?\n",
      "\n",
      ", Label: 0\n",
      "Processing row 3743 - Data Type: train, Message: Yeah, this confused me too.  There are a lot of paths through ConfigurationUtils.  Some paths worked, others didn't., Label: 1\n",
      "Processing row 3744 - Data Type: train, Message: Yes, I had the same thought and tried for a bit to refactor it.  I landed on this because the various other ways to do this either (1) seemed more complex and less obvious as to what we are actually doing here or (2) lead down a path of heavy refactoring of ConfigurationUtils.  Both of which i wanted to avoid, Label: 0\n",
      "Processing row 3745 - Data Type: train, Message: Sure, but this method signature already existed.  Do I need to fix that on this PR?, Label: 1\n",
      "Processing row 3746 - Data Type: train, Message: I'm not sure exactly what you're looking for.  Can you suggest some specific text?, Label: 1\n",
      "Processing row 3747 - Data Type: train, Message: Sure I can do that.  Since these settings are specific to the Alerts UI, should we include \"ui\" too?  Should the REST service also follow a similar pattern?, Label: 1\n",
      "Processing row 3748 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3749 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3750 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3751 - Data Type: train, Message: yeah, Label: 0\n",
      "Processing row 3752 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 3753 - Data Type: train, Message: Thanks for asking the question. That helped various random thoughts in my brain congeal into something at least a little useful.\n",
      "\n",
      "> We might want to consider watermarking as a more robust enhancement for solving this problem down the road. My +1 stands, thanks for the detailed explanation.\n",
      "\n",
      "We actually do use watermarking today.  That is what the Profiler's time lag setting is for.   When you increase the time lag, you are being more accomodating for late data, but at the expense of increased latency.  That's the watermark concept at work.\n",
      "\n",
      "Unfortunately a watermark doesn't stop time from being incorrectly advanced too far into the future, like my example.  It's only a mechanism to deal with late data.\n",
      "\n",
      "> https://databricks.com/blog/2017/05/08/event-time-aggregation-watermarking-apache-sparks-structured-streaming.html\n",
      "\n",
      "One difference between Spark's implementation over Storm, is that it has some limited ability to recalculate old windows.  But all that state has to be stored in memory, so it is not super useful.  \n",
      "\n",
      "I vaguely remember playing with that in a POC implementation of the Streaming Profiler in Spark and it didn't work out too well.  But we should definitely investigate it further.\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 3754 - Data Type: train, Message: Good point. I altered the `MessageRouterFunction` so that I don't create a new clock for each message.\n",
      "\n",
      "I tried to do this initially, but was running into some serialization issues.  And actually, I have found now that the serialization problems were tied to doing this with the `MessageRouter`, not with the `Clock`. This is fixed for the `Clock`, now trying to see if I can do something similar for the `MessagRouter`., Label: 0\n",
      "Processing row 3755 - Data Type: train, Message: The \"nimbus-jose-jwt\" dependency is the JSON web token implementation.  This is used to perform operations on the Knox token that is passed around the various services and UIs.\n",
      "\n",
      "I believe the \"jcip-annotations\" is included as a transitive dependency of the \"nimbus-jose-jwt\".  To be honest I'm not that familiar with JCIP annotations.  Should we try to exclude it?, Label: 1\n",
      "Processing row 3756 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3757 - Data Type: train, Message: This was preexisting.  I don't know the exact reason but I suspect it was a guard against setting the batch timeout to be greater than the tuple timeout.  @mmiklavc also brought up a question around default batch timeout and I'm not quite sure if what we have is correct or what the requirements are.  I know that the default batch timeout is 1/2 the tuple timeout when running in a bolt and 6 otherwise (test scenarios I think).  I also know the default batch timeout is only set once at the beginning and isn't tied to anything dynamically. \n",
      "\n",
      "How should default batch timeout work?  I think we need to keep the default to be 1/2 the tuple time in storm but what about other scenarios?  Should this setting be exposed in say global config?  Should we be able to change it at runtime?, Label: 1\n",
      "Processing row 3758 - Data Type: val, Message: The reason I did this is because of `batchTimeoutPolicy`.  There is a `BulkWriterComponent.setDefaultBatchTimeout` method and it's not obvious it's only used for testing (like clock is).  I didn't want to assume this can only be set at `BulkWriterComponent` creation time.  It looks like it's only set in the bolt prepare methods so I believe we can safely move it to the constructor like you're suggesting.  Do we want to make this assumption, that `batchTimeoutPolicy` is only set once?  I will make the clock change either way if you think it makes the code easier to follow., Label: 1\n",
      "Processing row 3759 - Data Type: train, Message: We should never have a dependency on `metron-enrichment`.  This causes all sorts of problems as a huge set of transitive dependencies get pulled in, and small dependency changes in seemingly unrelated places, can have a huge, ripple effect.  \n",
      "\n",
      "Projects like `metron-enrichment` and `metron-elasticsearch` that include deployable artifacts are the \"leafs\" of our dependency tree and nothing else should depend on them., Label: 0\n",
      "Processing row 3760 - Data Type: train, Message: I did not change this test, just moved it.  I imagine the test is ensuring correct parsing even when spaces are present., Label: 0\n",
      "Processing row 3761 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3762 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3763 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3764 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3765 - Data Type: train, Message: Took a bit of a fight with Intellij, but now done., Label: 0\n",
      "Processing row 3766 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 3767 - Data Type: train, Message: I am planning on adding the integration tests you requested.  Would that cover it?, Label: 1\n",
      "Processing row 3768 - Data Type: train, Message: Done.  Did I miss any places where we should use \"document ID\"?, Label: 1\n",
      "Processing row 3769 - Data Type: train, Message: Are you sure these are incorrect?  The shards are coming directly from the response so I would expect it to be accurate., Label: 1\n",
      "Processing row 3770 - Data Type: train, Message: This was a mistake.  I had to change it to 4.5.2 to get the tests to run in my IDE but the tests work fine otherwise with our global version.  I don't think our global version is correct here but will leave it for now as it's out of scope for this PR., Label: 0\n",
      "Processing row 3771 - Data Type: train, Message: I commented out the last bro document (line 152) and it failed all over the place., Label: 0\n",
      "Processing row 3772 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3773 - Data Type: train, Message: Not really, this is a left over from a half complete idea in the current product's CEF Tests, Label: 0\n",
      "Processing row 3774 - Data Type: val, Message: Again, this is an unclean leftover, will remove from both., Label: 0\n",
      "Processing row 3775 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3776 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3777 - Data Type: train, Message: Allows us to inject a `StellarFunction` instance into the set of resolved functions.  \n",
      "\n",
      "This is what solves the problem of how do we ensure that Stellar functions and code running in a Storm topology \"see\" the same underlying HBase data, without being able to run HBase and no longer having the mock HBase logic that existed previously., Label: 0\n",
      "Processing row 3778 - Data Type: val, Message: I need to revert this change - originally, I add Closeable to the TableProvider interface, which made lambdas unable to work as they currently do. I reverted that change, but haven't reverted the few lambda changes yet. This is partially contingent on how we land on the connection management logic, and whether it's reasonable to not explicitly close those connections., Label: 0\n",
      "Processing row 3779 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3780 - Data Type: train, Message: The code changes in this PR will not compile with 6.6.2.  I set all profiles to the new version in case people still want to submit PRs for other dependencies using the old profile.  I created a Jira to clean this up once all components have been upgraded.  In the end I donâ€™t see us having multiple profiles anyways., Label: 0\n",
      "Processing row 3781 - Data Type: train, Message: See my other comment., Label: 0\n",
      "Processing row 3782 - Data Type: val, Message: `json-simple` does pull in 4.10. I assume that was just getting hidden by a different version getting pulled in from who knows where. 4.12 is pulled in by the migration support for `@Rule`, so it's junit5 itself pulling it in (for now).\n",
      "\n",
      "I did dump 4.4 though, Label: 0\n",
      "Processing row 3783 - Data Type: train, Message: Probably. I thought about doing it, and just didn't because I originally intended to go more module by module. Then I got really sick of find/replace module by module.\n",
      "\n",
      "Particularly now that #1557 is in, it's probably safer to do this, but I'm a bit hesitant to do it here just because I'm slightly worried we'd see more of those issues and I mostly got lucky debugging that one.\n",
      "\n",
      "It might be easier/cleaner to do this as a follow-on or some more general maven cleanup?, Label: 1\n",
      "Processing row 3784 - Data Type: train, Message: IntelliJ really hated it, so I changed it, because it kept me from being able to run things.  Maven will apparently deal with it, but with so much shifting underneath it, IntelliJ started to fall apart a bit at times., Label: 0\n",
      "Processing row 3785 - Data Type: train, Message: Dropped it., Label: 0\n",
      "Processing row 3786 - Data Type: train, Message: ahh, I left that in, and forgot about it. That test actually throws on the first iteration of the loop anyway. I remember being surprised about it, because I wasn't really looking forward to figuring out how to fix it properly.\n",
      "\n",
      "Dropped it, and fixed the error message in the original class (it actually says it's double overflow instead of underflow), Label: 0\n",
      "Processing row 3787 - Data Type: train, Message: because it did not worked in master branch, and I have no time to fix that old bug, and all unit test did not pass.\n",
      "Too much time passed from PR..., Label: 0\n",
      "Processing row 3788 - Data Type: train, Message: Correct this, Label: 0\n",
      "Processing row 3789 - Data Type: train, Message: Actually, I would remove this set by default. But forcing everyone to tune it is not good., Label: 0\n",
      "Processing row 3790 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3791 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 3792 - Data Type: val, Message: I made some measurements year ago - there are no real performance difference in modern java with or without pre-compiled patterns - it is automatically optimized. However I find code with replaceAll more readable as with pattern. Can change it, but win is minimal. WDYT?, Label: 1\n",
      "Processing row 3793 - Data Type: train, Message: But perhaps it doesn't make sense to introduce separate setters for elements and headers, user can just put them in the same list. Any opinions?, Label: 1\n",
      "Processing row 3794 - Data Type: train, Message: Optional makes no sense anymore, stays from time, when maskSensitiveHelper was instantiated only by setter and wasn't final. Removed., Label: 0\n",
      "Processing row 3795 - Data Type: train, Message: removed from Message, Label: 0\n",
      "Processing row 3796 - Data Type: train, Message: moved, Label: 0\n",
      "Processing row 3797 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 3798 - Data Type: train, Message: replaced with constant, Label: 0\n",
      "Processing row 3799 - Data Type: train, Message: As long as nobody want's to access the file this works on Windows. A File instance does not validate the path when creating it. , Label: 0\n",
      "Processing row 3800 - Data Type: train, Message: ðŸ‘ oops, sorry, fixed, Label: 0\n",
      "Processing row 3801 - Data Type: train, Message: Isn't ttl-based expiry expected to be best-effort by users anyway?, Label: 1\n",
      "Processing row 3802 - Data Type: train, Message: Isn't ttl-based expiry expected to be best-effort by users anyway?, Label: 1\n",
      "Processing row 3803 - Data Type: train, Message: It's supposed to happen inside that app.init(). It's not finalized yet. So right now the app cannot use the stream creation inside the runner., Label: 0\n",
      "Processing row 3804 - Data Type: train, Message: It's supposed to happen inside that app.init(). It's not finalized yet. So right now the app cannot use the stream creation inside the runner., Label: 0\n",
      "Processing row 3805 - Data Type: train, Message: Currently, it calls the one from LocalizerResourceMapper and returns the localResourceMap for the context. \n",
      "There might be some legacy for package due to historical reason, and we plan to remove it later (TODO: SAMZA-1144 in the code), so I chose not to touch them now. \n",
      ", Label: 0\n",
      "Processing row 3806 - Data Type: train, Message: Currently, it calls the one from LocalizerResourceMapper and returns the localResourceMap for the context. \n",
      "There might be some legacy for package due to historical reason, and we plan to remove it later (TODO: SAMZA-1144 in the code), so I chose not to touch them now. \n",
      ", Label: 0\n",
      "Processing row 3807 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3808 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3809 - Data Type: train, Message: Thanks for clarifying the definition in SAMZA-1194 (PR:#92). I was under the impression that the two were interchangeable before that. , Label: 0\n",
      "Processing row 3810 - Data Type: train, Message: Thanks for clarifying the definition in SAMZA-1194 (PR:#92). I was under the impression that the two were interchangeable before that. , Label: 0\n",
      "Processing row 3811 - Data Type: train, Message: >> Also, should this be private/protected?\n",
      "\n",
      "Should be `public` since it overrides a method from `clusterSize()` from parent. Also, `bootstrapServers()` does not appear to follow the `getXXX()` pattern.\n",
      "\n",
      "All methods of these harness classes should be `protected` IMHO. Not sure what the scope for that is. Prefer to keep this `public` for now, and address it in a separate clean-up?, Label: 1\n",
      "Processing row 3812 - Data Type: train, Message: >> Also, should this be private/protected?\n",
      "\n",
      "Should be `public` since it overrides a method from `clusterSize()` from parent. Also, `bootstrapServers()` does not appear to follow the `getXXX()` pattern.\n",
      "\n",
      "All methods of these harness classes should be `protected` IMHO. Not sure what the scope for that is. Prefer to keep this `public` for now, and address it in a separate clean-up?, Label: 1\n",
      "Processing row 3813 - Data Type: train, Message: I blame code folding in IntelliJ.  \n",
      "Thanks ðŸ‘, Label: 0\n",
      "Processing row 3814 - Data Type: val, Message: I blame code folding in IntelliJ.  \n",
      "Thanks ðŸ‘, Label: 0\n",
      "Processing row 3815 - Data Type: train, Message: No excuse for this one. :), Label: 0\n",
      "Processing row 3816 - Data Type: val, Message: No excuse for this one. :), Label: 0\n",
      "Processing row 3817 - Data Type: train, Message: The invoking method. \n",
      "\n",
      "At LI, the control script will see this output and interpret it. \n",
      "\n",
      "For the record, I don't love this approach, but the only other idea I had was to encode meanings into a set of exit codes., Label: 0\n",
      "Processing row 3818 - Data Type: val, Message: The invoking method. \n",
      "\n",
      "At LI, the control script will see this output and interpret it. \n",
      "\n",
      "For the record, I don't love this approach, but the only other idea I had was to encode meanings into a set of exit codes., Label: 0\n",
      "Processing row 3819 - Data Type: val, Message: ðŸ‘ , Label: 0\n",
      "Processing row 3820 - Data Type: train, Message: ðŸ‘ , Label: 0\n",
      "Processing row 3821 - Data Type: train, Message: What do you suggest? There's currently no method in the scala SystemConfig to get the factories or the admins, only the names., Label: 1\n",
      "Processing row 3822 - Data Type: train, Message: What do you suggest? There's currently no method in the scala SystemConfig to get the factories or the admins, only the names., Label: 1\n",
      "Processing row 3823 - Data Type: train, Message: testLatchSizeNWithNParticipants may be more accurate here? , Label: 1\n",
      "Processing row 3824 - Data Type: val, Message: testLatchSizeNWithNParticipants may be more accurate here? , Label: 1\n",
      "Processing row 3825 - Data Type: train, Message: I agree we should do something to improve this TaskFactory mess. This part of the code looks pretty ugly., Label: 0\n",
      "Processing row 3826 - Data Type: train, Message: I agree we should do something to improve this TaskFactory mess. This part of the code looks pretty ugly., Label: 0\n",
      "Processing row 3827 - Data Type: train, Message: yeah, same as getSortedActiveProcessors() today. \n",
      "I am not sure it can be handled here. It requires handling at 'debounce' scheduler level., Label: 0\n",
      "Processing row 3828 - Data Type: train, Message: yeah, same as getSortedActiveProcessors() today. \n",
      "I am not sure it can be handled here. It requires handling at 'debounce' scheduler level., Label: 0\n",
      "Processing row 3829 - Data Type: train, Message: deleted., Label: 0\n",
      "Processing row 3830 - Data Type: train, Message: deleted., Label: 0\n",
      "Processing row 3831 - Data Type: train, Message: we don't needed. Removed., Label: 0\n",
      "Processing row 3832 - Data Type: train, Message: we don't needed. Removed., Label: 0\n",
      "Processing row 3833 - Data Type: val, Message: Makes sense. Changed. , Label: 0\n",
      "Processing row 3834 - Data Type: train, Message: Makes sense. Changed. , Label: 0\n",
      "Processing row 3835 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3836 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3837 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3838 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3839 - Data Type: train, Message: This is to formulate the type of Function that our internal class will depend on. Leaking the captured type parameter to internal functions leads to a whole lot changes over the full implementation stack, which does not seem to be necessary for the purpose (i.e. just allow relaxed type parameter from user-supplied functions)., Label: 0\n",
      "Processing row 3840 - Data Type: train, Message: This is to formulate the type of Function that our internal class will depend on. Leaking the captured type parameter to internal functions leads to a whole lot changes over the full implementation stack, which does not seem to be necessary for the purpose (i.e. just allow relaxed type parameter from user-supplied functions)., Label: 0\n",
      "Processing row 3841 - Data Type: val, Message: Same answer as earlier., Label: 0\n",
      "Processing row 3842 - Data Type: val, Message: Same answer as earlier., Label: 0\n",
      "Processing row 3843 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3844 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3845 - Data Type: train, Message: it is not easy to do here. Different tests require different setup parts. I will see what I can do, but no guarantees., Label: 0\n",
      "Processing row 3846 - Data Type: train, Message: it is not easy to do here. Different tests require different setup parts. I will see what I can do, but no guarantees., Label: 0\n",
      "Processing row 3847 - Data Type: train, Message: We could make the creator register it as an anonymous class. That way, non-creators don't have an option of even using this class. But in reality, it doesn't prevent anyone from subscribing to any of the znode paths. \n",
      "\n",
      "Since this is internal to this implementation of the barrier, I suspect the probability of non-creators becoming listeners is really low. , Label: 0\n",
      "Processing row 3848 - Data Type: train, Message: We could make the creator register it as an anonymous class. That way, non-creators don't have an option of even using this class. But in reality, it doesn't prevent anyone from subscribing to any of the znode paths. \n",
      "\n",
      "Since this is internal to this implementation of the barrier, I suspect the probability of non-creators becoming listeners is really low. , Label: 0\n",
      "Processing row 3849 - Data Type: train, Message: @sborya I removed the interface itself because it is not meant for any generic use. I didn't rename it. Can you explain what you think I have renamed :( , Label: 1\n",
      "Processing row 3850 - Data Type: train, Message: @sborya I removed the interface itself because it is not meant for any generic use. I didn't rename it. Can you explain what you think I have renamed :( , Label: 1\n",
      "Processing row 3851 - Data Type: train, Message: \"/\" is the chrooted root. So if it exists (with namespace) it means the namespace exists.\n",
      "This is where we got it wrong before :), Label: 0\n",
      "Processing row 3852 - Data Type: train, Message: \"/\" is the chrooted root. So if it exists (with namespace) it means the namespace exists.\n",
      "This is where we got it wrong before :), Label: 0\n",
      "Processing row 3853 - Data Type: train, Message: Replaced samza-container with job-coordinator., Label: 0\n",
      "Processing row 3854 - Data Type: train, Message: Replaced samza-container with job-coordinator., Label: 0\n",
      "Processing row 3855 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3856 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3857 - Data Type: train, Message: Yeah, this was on of the attempts to simulate ZK timeout.. Didn't work anyway., Label: 0\n",
      "Processing row 3858 - Data Type: train, Message: Yeah, this was on of the attempts to simulate ZK timeout.. Didn't work anyway., Label: 0\n",
      "Processing row 3859 - Data Type: train, Message: no, not really, it is called from a test which is in a different package..\n",
      ", Label: 0\n",
      "Processing row 3860 - Data Type: train, Message: no, not really, it is called from a test which is in a different package..\n",
      ", Label: 0\n",
      "Processing row 3861 - Data Type: train, Message: Going forward, we need to allow much more time for a container to shutdown. If the container shuts down before that - there is no impact. But for huge jobs 5 sec may be not enough., Label: 0\n",
      "Processing row 3862 - Data Type: train, Message: Going forward, we need to allow much more time for a container to shutdown. If the container shuts down before that - there is no impact. But for huge jobs 5 sec may be not enough., Label: 0\n",
      "Processing row 3863 - Data Type: train, Message: Nice catch. This is not needed here. , Label: 0\n",
      "Processing row 3864 - Data Type: train, Message: Nice catch. This is not needed here. , Label: 0\n",
      "Processing row 3865 - Data Type: train, Message: `samza-test` contains just integration tests based out on Task/AppRunner (public) api. \n",
      "\n",
      "There will no benefit in building locally samza-test if itâ€™s not going to be run locally (since it just contains tests, `doesn't have src files`). \n",
      "\n",
      "Moreover the plan is to build/run these tests in jenkins anyways as a part of every PR/nightly(The problems if any will be caught anyway).\n",
      "\n",
      "If we really want to build it locally, we can build by using that property. I donâ€™t understand what will having the granular separation buy/benefit us. \n",
      "\n",
      "Please share your thoughts., Label: 1\n",
      "Processing row 3866 - Data Type: train, Message: `samza-test` contains just integration tests based out on Task/AppRunner (public) api. \n",
      "\n",
      "There will no benefit in building locally samza-test if itâ€™s not going to be run locally (since it just contains tests, `doesn't have src files`). \n",
      "\n",
      "Moreover the plan is to build/run these tests in jenkins anyways as a part of every PR/nightly(The problems if any will be caught anyway).\n",
      "\n",
      "If we really want to build it locally, we can build by using that property. I donâ€™t understand what will having the granular separation buy/benefit us. \n",
      "\n",
      "Please share your thoughts., Label: 1\n",
      "Processing row 3867 - Data Type: train, Message: @navina\n",
      "\n",
      "When thereâ€™re multiple duplicate processors(P1,P2,P3..Pn) this marks processor with lowest sequential id as not duplicate, rest as duplicate.\n",
      "\n",
      "I donâ€™t think this  is synonymous to `Collection.contains` to rename(which should be symmetric for all processors). If we rename that way, it also conveys wrong meaning that we kill all duplicate processors (P1, P2, .. Pn). \n",
      "\n",
      "Naming to  `isValidRegisteredProcessor` if it's okay, Label: 0\n",
      "Processing row 3868 - Data Type: train, Message: @navina\n",
      "\n",
      "When thereâ€™re multiple duplicate processors(P1,P2,P3..Pn) this marks processor with lowest sequential id as not duplicate, rest as duplicate.\n",
      "\n",
      "I donâ€™t think this  is synonymous to `Collection.contains` to rename(which should be symmetric for all processors). If we rename that way, it also conveys wrong meaning that we kill all duplicate processors (P1, P2, .. Pn). \n",
      "\n",
      "Naming to  `isValidRegisteredProcessor` if it's okay, Label: 0\n",
      "Processing row 3869 - Data Type: train, Message: I think they are mostly the same., Label: 0\n",
      "Processing row 3870 - Data Type: train, Message: I think they are mostly the same., Label: 0\n",
      "Processing row 3871 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 3872 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 3873 - Data Type: train, Message: Renamed it to DistributedLock :), Label: 0\n",
      "Processing row 3874 - Data Type: train, Message: Renamed it to DistributedLock :), Label: 0\n",
      "Processing row 3875 - Data Type: train, Message: Removed the class., Label: 0\n",
      "Processing row 3876 - Data Type: train, Message: Removed the class., Label: 0\n",
      "Processing row 3877 - Data Type: train, Message: Right, null is easier to use. I used this constant internally to avoid null check in the watermark comparison. No need to force the user to use this value. Fixed., Label: 0\n",
      "Processing row 3878 - Data Type: train, Message: Right, null is easier to use. I used this constant internally to avoid null check in the watermark comparison. No need to force the user to use this value. Fixed., Label: 0\n",
      "Processing row 3879 - Data Type: train, Message: Let's discuss this offline.\n",
      "\n",
      "I'm not sure of benefits gained by replacing a lambda with anonymous inner class implementation., Label: 0\n",
      "Processing row 3880 - Data Type: train, Message: Let's discuss this offline.\n",
      "\n",
      "I'm not sure of benefits gained by replacing a lambda with anonymous inner class implementation., Label: 0\n",
      "Processing row 3881 - Data Type: train, Message: this should be fine. We always generate a new set of topics (appending the run.id so they are different from previous runs). I actually expect clearStreams not supported in many scenarios, where we might rely on retention to get the streams cleared., Label: 0\n",
      "Processing row 3882 - Data Type: train, Message: this should be fine. We always generate a new set of topics (appending the run.id so they are different from previous runs). I actually expect clearStreams not supported in many scenarios, where we might rely on retention to get the streams cleared., Label: 0\n",
      "Processing row 3883 - Data Type: train, Message: Thank you all for the review. I have update the code to address this issue.\n",
      "\n",
      "Currently we only need to start systemAdmin in SamzaContain beause this is the only class that may use KafkaSystemAdmin.deleteMessages(). Going forward we need to invoke systemAdmin.start() every time before we use systemAdmin. This can be done in a separate patch. Does this sound OK?, Label: 1\n",
      "Processing row 3884 - Data Type: train, Message: Thank you all for the review. I have update the code to address this issue.\n",
      "\n",
      "Currently we only need to start systemAdmin in SamzaContain beause this is the only class that may use KafkaSystemAdmin.deleteMessages(). Going forward we need to invoke systemAdmin.start() every time before we use systemAdmin. This can be done in a separate patch. Does this sound OK?, Label: 1\n",
      "Processing row 3885 - Data Type: train, Message: Since the states and the long-lasting client connections in SystemAdmin are only created when we call SystemAdmin.start(), then it should be OK as of this patch to only call SystemAdmin.start() when we start SamzaContainer, right?\n",
      "\n",
      "We can have a separate patch to go over all existing usage of SystemAdmin to manage them and call SystemAdmin.start() properly. By splitting the work into two patches, we can reduce the amount of rebase needed for this patch. Does this sound OK?, Label: 1\n",
      "Processing row 3886 - Data Type: train, Message: Since the states and the long-lasting client connections in SystemAdmin are only created when we call SystemAdmin.start(), then it should be OK as of this patch to only call SystemAdmin.start() when we start SamzaContainer, right?\n",
      "\n",
      "We can have a separate patch to go over all existing usage of SystemAdmin to manage them and call SystemAdmin.start() properly. By splitting the work into two patches, we can reduce the amount of rebase needed for this patch. Does this sound OK?, Label: 1\n",
      "Processing row 3887 - Data Type: train, Message: AdminClient can also be used to create topic, delete topic, list all topics, get topic metadata, etc.\n",
      "\n",
      "This is volatile because SystemAdmin.deleteRecords() and SystemAdmin.start() may potentially be called by different threads. Does this make sense?, Label: 1\n",
      "Processing row 3888 - Data Type: val, Message: AdminClient can also be used to create topic, delete topic, list all topics, get topic metadata, etc.\n",
      "\n",
      "This is volatile because SystemAdmin.deleteRecords() and SystemAdmin.start() may potentially be called by different threads. Does this make sense?, Label: 1\n",
      "Processing row 3889 - Data Type: train, Message: If we leave implementation part aside, why do we want to have a grouper which works for only one job coordinator and yet another grouper which is similar to the existing one but works with other coordinators ? As long as the behavior for passthru does not change, we should be ok, right ? Having too many groupers is also something that we want to avoid., Label: 1\n",
      "Processing row 3890 - Data Type: train, Message: If we leave implementation part aside, why do we want to have a grouper which works for only one job coordinator and yet another grouper which is similar to the existing one but works with other coordinators ? As long as the behavior for passthru does not change, we should be ok, right ? Having too many groupers is also something that we want to avoid., Label: 1\n",
      "Processing row 3891 - Data Type: val, Message: I have added a comment in the code. I looked around to see if there is a way to verify that but couldn't find any., Label: 0\n",
      "Processing row 3892 - Data Type: train, Message: I have added a comment in the code. I looked around to see if there is a way to verify that but couldn't find any., Label: 0\n",
      "Processing row 3893 - Data Type: train, Message: This documentation was based on the documentation of SystemConsumer.start(), which says \"Tells the SystemConsumer to connect to the underlying system, and prepare to begin serving messages when poll is invoked\".\n",
      "\n",
      "Sure, I updated the documentation of start() to \"Start up API for bringing up a single instance of SystemAdmin.\". And I updated the documentation of stop() to \"Shutdown API for shutting down a single instance of the SystemAdmin\". Does this look good?, Label: 1\n",
      "Processing row 3894 - Data Type: val, Message: This documentation was based on the documentation of SystemConsumer.start(), which says \"Tells the SystemConsumer to connect to the underlying system, and prepare to begin serving messages when poll is invoked\".\n",
      "\n",
      "Sure, I updated the documentation of start() to \"Start up API for bringing up a single instance of SystemAdmin.\". And I updated the documentation of stop() to \"Shutdown API for shutting down a single instance of the SystemAdmin\". Does this look good?, Label: 1\n",
      "Processing row 3895 - Data Type: train, Message: `systemAdmin` is started here because the `systemAdmin` is instantiated in `CoordinatorStreamSystemFactory.getCoordinatorStreamSystemConsumer()`. The caller of this method actually does not know about SystemAdmin. How about I change the constructor of `CoordinatorStreamSystemConsumer` to be `CoordinatorStreamSystemConsumer(config: Config, registry: MetricsRegistry)` and remove the existing class `CoordinatorStreamSystemFactory`?, Label: 1\n",
      "Processing row 3896 - Data Type: train, Message: `systemAdmin` is started here because the `systemAdmin` is instantiated in `CoordinatorStreamSystemFactory.getCoordinatorStreamSystemConsumer()`. The caller of this method actually does not know about SystemAdmin. How about I change the constructor of `CoordinatorStreamSystemConsumer` to be `CoordinatorStreamSystemConsumer(config: Config, registry: MetricsRegistry)` and remove the existing class `CoordinatorStreamSystemFactory`?, Label: 1\n",
      "Processing row 3897 - Data Type: train, Message: - Added a jitter percent, which controls the randomness that gets added to scheduling time.\n",
      "- SecureRandom is a strong random number generator where as Random is pseudorandom number generator. It's better and proven to provide a more uniform distribution of a random numbers in a interval. \n",
      "- Made it as a static constant., Label: 0\n",
      "Processing row 3898 - Data Type: train, Message: - Added a jitter percent, which controls the randomness that gets added to scheduling time.\n",
      "- SecureRandom is a strong random number generator where as Random is pseudorandom number generator. It's better and proven to provide a more uniform distribution of a random numbers in a interval. \n",
      "- Made it as a static constant., Label: 0\n",
      "Processing row 3899 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 3900 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 3901 - Data Type: train, Message: Certainly.  I waffle over naming variables all the time and am happy to\n",
      "take other people's suggestions.\n",
      "\n",
      "Somewhat related to a question from @xinyuiscool we could question why I\n",
      "even made this timeout configurable.  It did not expect anyone to set it to\n",
      "0 (although I did try that just to see the main loop peg one of the CPUs on\n",
      "my dev box), but, I suppose I could image a case where you had a box with a\n",
      "lot of CPUs and were willing to have one spin faster to minimize latency.\n",
      "The real reason I made in configurable was so it could play with it during\n",
      "testing without rebuilding my application.\n",
      ", Label: 0\n",
      "Processing row 3902 - Data Type: train, Message: Certainly.  I waffle over naming variables all the time and am happy to\n",
      "take other people's suggestions.\n",
      "\n",
      "Somewhat related to a question from @xinyuiscool we could question why I\n",
      "even made this timeout configurable.  It did not expect anyone to set it to\n",
      "0 (although I did try that just to see the main loop peg one of the CPUs on\n",
      "my dev box), but, I suppose I could image a case where you had a box with a\n",
      "lot of CPUs and were willing to have one spin faster to minimize latency.\n",
      "The real reason I made in configurable was so it could play with it during\n",
      "testing without rebuilding my application.\n",
      ", Label: 0\n",
      "Processing row 3903 - Data Type: train, Message: When there is an exception on callback, Only way to clear it is to recreate the system producer. Because it is possible that the connection is broken., Label: 0\n",
      "Processing row 3904 - Data Type: val, Message: When there is an exception on callback, Only way to clear it is to recreate the system producer. Because it is possible that the connection is broken., Label: 0\n",
      "Processing row 3905 - Data Type: val, Message: I added the comments, But i am not sure whether we need to be adding such comments if there is an abstract method.  compiler or IDE will give hints on what needs to be overridden. , Label: 1\n",
      "Processing row 3906 - Data Type: train, Message: I added the comments, But i am not sure whether we need to be adding such comments if there is an abstract method.  compiler or IDE will give hints on what needs to be overridden. , Label: 1\n",
      "Processing row 3907 - Data Type: train, Message: Renamed to convertRecordType(). Does this sound ok ?, Label: 1\n",
      "Processing row 3908 - Data Type: train, Message: Renamed to convertRecordType(). Does this sound ok ?, Label: 1\n",
      "Processing row 3909 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 3910 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 3911 - Data Type: val, Message: I think the code is small. Below should be the entirety:\n",
      "\n",
      "```java\n",
      "  private boolean isTable(RelNode relNode) {\n",
      "    // NOTE: Any intermediate form of a join is always a stream. Eg: For the second level join of\n",
      "    // stream-table-table join, the left side of the join is join output, which we always\n",
      "    // assume to be a stream. The intermediate stream won't be an instance of EnumerableTableScan.\n",
      "    return relNode instanceof EnumerableTableScan &&\n",
      "        sourceResolver.isTable(String.join(\".\", relNode.getTable().getQualifiedName()));\n",
      "  }\n",
      "\n",
      "  private Table loadLocalTable(boolean isTablePosOnRight, List<Integer> tableKeyIds, Serde keySerde, Serde relMsgSerde,\n",
      "      LogicalJoin join, TranslatorContext context) {\n",
      "    MessageStream<SamzaSqlRelMessage> inputTable =\n",
      "        isTablePosOnRight ?\n",
      "            context.getMessageStream(join.getRight().getId()) : context.getMessageStream(join.getLeft().getId());\n",
      "\n",
      "    // Create a table backed by RocksDb store with the fields in the join condition as composite key and relational\n",
      "    // message as the value. Send the messages from the input stream denoted as 'table' to the created table store.\n",
      "    Table<KV<SamzaSqlCompositeKey, SamzaSqlRelMessage>> table =\n",
      "        context.getStreamGraph()\n",
      "            .getTable(new RocksDbTableDescriptor(\"table_\" + joinId)\n",
      "                .withSerde(KVSerde.of(keySerde, relMsgSerde)));\n",
      "\n",
      "    inputTable\n",
      "        .map(m -> new KV(createSamzaSqlCompositeKey(m, tableKeyIds), m))\n",
      "        .sendTo(table);\n",
      "\n",
      "    return table;\n",
      "  }\n",
      "```, Label: 0\n",
      "Processing row 3912 - Data Type: train, Message: I think the code is small. Below should be the entirety:\n",
      "\n",
      "```java\n",
      "  private boolean isTable(RelNode relNode) {\n",
      "    // NOTE: Any intermediate form of a join is always a stream. Eg: For the second level join of\n",
      "    // stream-table-table join, the left side of the join is join output, which we always\n",
      "    // assume to be a stream. The intermediate stream won't be an instance of EnumerableTableScan.\n",
      "    return relNode instanceof EnumerableTableScan &&\n",
      "        sourceResolver.isTable(String.join(\".\", relNode.getTable().getQualifiedName()));\n",
      "  }\n",
      "\n",
      "  private Table loadLocalTable(boolean isTablePosOnRight, List<Integer> tableKeyIds, Serde keySerde, Serde relMsgSerde,\n",
      "      LogicalJoin join, TranslatorContext context) {\n",
      "    MessageStream<SamzaSqlRelMessage> inputTable =\n",
      "        isTablePosOnRight ?\n",
      "            context.getMessageStream(join.getRight().getId()) : context.getMessageStream(join.getLeft().getId());\n",
      "\n",
      "    // Create a table backed by RocksDb store with the fields in the join condition as composite key and relational\n",
      "    // message as the value. Send the messages from the input stream denoted as 'table' to the created table store.\n",
      "    Table<KV<SamzaSqlCompositeKey, SamzaSqlRelMessage>> table =\n",
      "        context.getStreamGraph()\n",
      "            .getTable(new RocksDbTableDescriptor(\"table_\" + joinId)\n",
      "                .withSerde(KVSerde.of(keySerde, relMsgSerde)));\n",
      "\n",
      "    inputTable\n",
      "        .map(m -> new KV(createSamzaSqlCompositeKey(m, tableKeyIds), m))\n",
      "        .sendTo(table);\n",
      "\n",
      "    return table;\n",
      "  }\n",
      "```, Label: 0\n",
      "Processing row 3913 - Data Type: train, Message: I thought the goal was to make the SamzaSQL intuitive/simple to use. So if we can tell from the source resolver that a source is a \"table\", why do we have to ask for the keyword? But I might not have enough context, so I'm open to adding the keyword if there are sufficient reasoning. , Label: 1\n",
      "Processing row 3914 - Data Type: train, Message: I thought the goal was to make the SamzaSQL intuitive/simple to use. So if we can tell from the source resolver that a source is a \"table\", why do we have to ask for the keyword? But I might not have enough context, so I'm open to adding the keyword if there are sufficient reasoning. , Label: 1\n",
      "Processing row 3915 - Data Type: val, Message: Thanks for the context. Regarding the naming though, here we're testing the ability to insert into a table so naming it testDb and testTable are clearer than calling it outputSystem, right? , Label: 1\n",
      "Processing row 3916 - Data Type: val, Message: Thanks for the context. Regarding the naming though, here we're testing the ability to insert into a table so naming it testDb and testTable are clearer than calling it outputSystem, right? , Label: 1\n",
      "Processing row 3917 - Data Type: val, Message: Adding metric is easy. But I'm afraid this is only going to put up some confusing metric out there. The purpose of partition key (https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-programming-guide#partition-key) is just for the senders to decide which partition to send the data to. By truncating the partition key we still guarantee the same partition key is sent to the same partition. Plus this only happens very rarely. So I think the value of having a metric there is very very trivial. We definitely should have metric for skipLargeMessage (which we do have), because that's actually dropping user data and that should be monitored. But for key truncation, I'm not entirely sure. , Label: 0\n",
      "Processing row 3918 - Data Type: train, Message: Adding metric is easy. But I'm afraid this is only going to put up some confusing metric out there. The purpose of partition key (https://docs.microsoft.com/en-us/azure/event-hubs/event-hubs-programming-guide#partition-key) is just for the senders to decide which partition to send the data to. By truncating the partition key we still guarantee the same partition key is sent to the same partition. Plus this only happens very rarely. So I think the value of having a metric there is very very trivial. We definitely should have metric for skipLargeMessage (which we do have), because that's actually dropping user data and that should be monitored. But for key truncation, I'm not entirely sure. , Label: 0\n",
      "Processing row 3919 - Data Type: train, Message: modified the configuration name, Label: 0\n",
      "Processing row 3920 - Data Type: train, Message: modified the configuration name, Label: 0\n",
      "Processing row 3921 - Data Type: train, Message: I think we should throw because this indicates a configuration problem, ie. app is expecting a RW table but only configured a RO table. Does this make sense? , Label: 1\n",
      "Processing row 3922 - Data Type: train, Message: I think we should throw because this indicates a configuration problem, ie. app is expecting a RW table but only configured a RO table. Does this make sense? , Label: 1\n",
      "Processing row 3923 - Data Type: train, Message: if key exists, get() would have returned already at line 71. If it's added after 71, it means it's a new key, assuming the TTL is not at usec level, I don't see how a key gets evited in the middle of the locker right? , Label: 1\n",
      "Processing row 3924 - Data Type: val, Message: if key exists, get() would have returned already at line 71. If it's added after 71, it means it's a new key, assuming the TTL is not at usec level, I don't see how a key gets evited in the middle of the locker right? , Label: 1\n",
      "Processing row 3925 - Data Type: train, Message: TableProvider.getTable is called once per tableId so I don't think we should reuse cache among different tables, right? , Label: 1\n",
      "Processing row 3926 - Data Type: train, Message: TableProvider.getTable is called once per tableId so I don't think we should reuse cache among different tables, right? , Label: 1\n",
      "Processing row 3927 - Data Type: train, Message: I think we should given each cache is associated with a distinct table. I don't see why we want to reuse caches among different tables (w/ might share the same key but diff values)., Label: 0\n",
      "Processing row 3928 - Data Type: train, Message: I think we should given each cache is associated with a distinct table. I don't see why we want to reuse caches among different tables (w/ might share the same key but diff values)., Label: 0\n",
      "Processing row 3929 - Data Type: train, Message: agreed!, Label: 0\n",
      "Processing row 3930 - Data Type: train, Message: agreed!, Label: 0\n",
      "Processing row 3931 - Data Type: train, Message: Agreed!, Label: 0\n",
      "Processing row 3932 - Data Type: train, Message: Agreed!, Label: 0\n",
      "Processing row 3933 - Data Type: train, Message: The problem was that the policy needed a handle on the listgauge, so it couldnt be created and set during the listgauge instantiation., Label: 0\n",
      "Processing row 3934 - Data Type: train, Message: The problem was that the policy needed a handle on the listgauge, so it couldnt be created and set during the listgauge instantiation., Label: 0\n",
      "Processing row 3935 - Data Type: train, Message: do you have some suggestion where to place this util method?, Label: 1\n",
      "Processing row 3936 - Data Type: train, Message: do you have some suggestion where to place this util method?, Label: 1\n",
      "Processing row 3937 - Data Type: train, Message: Yeah, it's currently only used in tests. There's no general pattern / central place for test utils in this code base so I put it here for discoverability. Do you think it's worth extracting to a single method StreamTestUtils? Does anyone else know of a better place for this?\n",
      "\n",
      "Agree that the String triple is confusing, but I didn't want to introduce a new holder type in the API just for this. StreamSpec could be used as that holder class but that would be undesirable since the intention here is to remove StreamSpec usage from these classes., Label: 1\n",
      "Processing row 3938 - Data Type: train, Message: Yeah, it's currently only used in tests. There's no general pattern / central place for test utils in this code base so I put it here for discoverability. Do you think it's worth extracting to a single method StreamTestUtils? Does anyone else know of a better place for this?\n",
      "\n",
      "Agree that the String triple is confusing, but I didn't want to introduce a new holder type in the API just for this. StreamSpec could be used as that holder class but that would be undesirable since the intention here is to remove StreamSpec usage from these classes., Label: 1\n",
      "Processing row 3939 - Data Type: val, Message: Re: StreamSpecManager and static functions in the planner, I'd prefer to stop at this amount of refactor to time bound it and make it easily reviewable. Once StreamSpec usage is restricted enough, we can consider further refactors like consolidating StreamSpec creation, making them immutable, removing StreamSpec from the SystemAdmin API, making other Planner objects (JobNode, JobGraph) etc. immutable and so on. Does that sound reasonable?, Label: 1\n",
      "Processing row 3940 - Data Type: train, Message: Re: StreamSpecManager and static functions in the planner, I'd prefer to stop at this amount of refactor to time bound it and make it easily reviewable. Once StreamSpec usage is restricted enough, we can consider further refactors like consolidating StreamSpec creation, making them immutable, removing StreamSpec from the SystemAdmin API, making other Planner objects (JobNode, JobGraph) etc. immutable and so on. Does that sound reasonable?, Label: 1\n",
      "Processing row 3941 - Data Type: train, Message: Will make this change!, Label: 1\n",
      "Processing row 3942 - Data Type: train, Message: Will make this change!, Label: 1\n",
      "Processing row 3943 - Data Type: train, Message: Added that, Label: 0\n",
      "Processing row 3944 - Data Type: train, Message: Added that, Label: 0\n",
      "Processing row 3945 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3946 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 3947 - Data Type: train, Message: moved, Label: 0\n",
      "Processing row 3948 - Data Type: train, Message: moved, Label: 0\n",
      "Processing row 3949 - Data Type: train, Message: Makes sense. Removed Context and switched to having `config` and `metricsRegistry` as parameters. \n",
      "\n",
      "I'm not sure if it's a good idea to fix string as key type. This will prevent us in the future from persisting non-string keys in the metadatastore(since majority of store API's offer byte[], byte[] contract, this will incur a unnecessary limitation) and reading/writing it across samza-job, custom tools etc. \n",
      "\n",
      ">> It'd be nice if the metadatastore offered atomic updates across keys.\n",
      "\n",
      "Not sure if it's a good idea to add this to interface contract and mandate this for every store implementation. For majority of scenarios in samza, a store implementation that persists the (key,value) through a synchronous remote call should be sufficient. \n",
      "\n",
      "Atomic updates through write-batch(or similar batch accumulation) is not supported by every store. Unless we have prevalent and concrete use-cases across different layers in samza, i think it's a good idea not to introduce it.  \n",
      "\n",
      ", Label: 0\n",
      "Processing row 3950 - Data Type: train, Message: Makes sense. Removed Context and switched to having `config` and `metricsRegistry` as parameters. \n",
      "\n",
      "I'm not sure if it's a good idea to fix string as key type. This will prevent us in the future from persisting non-string keys in the metadatastore(since majority of store API's offer byte[], byte[] contract, this will incur a unnecessary limitation) and reading/writing it across samza-job, custom tools etc. \n",
      "\n",
      ">> It'd be nice if the metadatastore offered atomic updates across keys.\n",
      "\n",
      "Not sure if it's a good idea to add this to interface contract and mandate this for every store implementation. For majority of scenarios in samza, a store implementation that persists the (key,value) through a synchronous remote call should be sufficient. \n",
      "\n",
      "Atomic updates through write-batch(or similar batch accumulation) is not supported by every store. Unless we have prevalent and concrete use-cases across different layers in samza, i think it's a good idea not to introduce it.  \n",
      "\n",
      ", Label: 0\n",
      "Processing row 3951 - Data Type: train, Message: `SamzaContainers` stores the container locality to `CoordinatorStream`(kafka topic) through `localityManager. writeContainerHostMapping` as a part of its startup sequence. \n",
      "\n",
      "`ContainerAllocator` thread in `JobCoordinator` uses `localityManager.readContainerLocality()` to get the container to preferred host mapping for requesting physical resources from the `ClusterResourceManager`(within linkedin it is `yarn`). \n",
      "\n",
      "If we refrain from storing this mapping in `SamzaContainer`(since it's not read within it), then we will break host affinity for stateful samza jobs., Label: 0\n",
      "Processing row 3952 - Data Type: val, Message: `SamzaContainers` stores the container locality to `CoordinatorStream`(kafka topic) through `localityManager. writeContainerHostMapping` as a part of its startup sequence. \n",
      "\n",
      "`ContainerAllocator` thread in `JobCoordinator` uses `localityManager.readContainerLocality()` to get the container to preferred host mapping for requesting physical resources from the `ClusterResourceManager`(within linkedin it is `yarn`). \n",
      "\n",
      "If we refrain from storing this mapping in `SamzaContainer`(since it's not read within it), then we will break host affinity for stateful samza jobs., Label: 0\n",
      "Processing row 3953 - Data Type: train, Message: Though I like this idea, but we've moved away from that extends inheritance hierarchy  pretty recently in all CoordinatorStream utility classes(LocalityManager, TaskAssignmentManager., etc) by a huge refactor.\n",
      "\n",
      "We're planning to migrate other classes to use metadatastore in followup patches(which will be sent soon after this). If we see the necessity for such an common abstraction which will simplify things, then i will be happy to do it.  \n",
      "\n",
      "I don't want to start it with that hierarchy initially itself., Label: 0\n",
      "Processing row 3954 - Data Type: train, Message: Though I like this idea, but we've moved away from that extends inheritance hierarchy  pretty recently in all CoordinatorStream utility classes(LocalityManager, TaskAssignmentManager., etc) by a huge refactor.\n",
      "\n",
      "We're planning to migrate other classes to use metadatastore in followup patches(which will be sent soon after this). If we see the necessity for such an common abstraction which will simplify things, then i will be happy to do it.  \n",
      "\n",
      "I don't want to start it with that hierarchy initially itself., Label: 0\n",
      "Processing row 3955 - Data Type: train, Message: We already log the partition count for all sources and sink in `updateExistingPartitions` which happens prior to traversal. Were you looking for something else or would that suffice?, Label: 1\n",
      "Processing row 3956 - Data Type: train, Message: We already log the partition count for all sources and sink in `updateExistingPartitions` which happens prior to traversal. Were you looking for something else or would that suffice?, Label: 1\n",
      "Processing row 3957 - Data Type: train, Message: I'm not sure using one of the existing Range classes (apache commons, guava) would be better, since their API is a lot more general. It'll probably be better to write our own simple implementation. Either way, the final validation still happens at runtime (in JavaTaskConfig), since we can't move validation logic from Config classes to Descriptors. Since there's not much validation benefit, and it's fairly clear from documentation what the expected value is, it feels slightly unnecessary to add a new class.\n",
      "\n",
      "I don't feel strongly about this. Do you prefer one way over the other?, Label: 1\n",
      "Processing row 3958 - Data Type: train, Message: I'm not sure using one of the existing Range classes (apache commons, guava) would be better, since their API is a lot more general. It'll probably be better to write our own simple implementation. Either way, the final validation still happens at runtime (in JavaTaskConfig), since we can't move validation logic from Config classes to Descriptors. Since there's not much validation benefit, and it's fairly clear from documentation what the expected value is, it feels slightly unnecessary to add a new class.\n",
      "\n",
      "I don't feel strongly about this. Do you prefer one way over the other?, Label: 1\n",
      "Processing row 3959 - Data Type: train, Message: FWIW, it still won't move all validation to compile time. E.g., we can't assert at compile time that lower bound is indeed lower than the upper bound, that none of the bounds are negative, etc. The only thing it will help with is preventing formatting mistakes for the range syntax. \n",
      "\n",
      "We could achieve that by changing the method signature to `withBootstrapPartitions(int startIndex, int endIndex)` and document that startIndex <= endIndex. Would that be sufficient?, Label: 1\n",
      "Processing row 3960 - Data Type: train, Message: FWIW, it still won't move all validation to compile time. E.g., we can't assert at compile time that lower bound is indeed lower than the upper bound, that none of the bounds are negative, etc. The only thing it will help with is preventing formatting mistakes for the range syntax. \n",
      "\n",
      "We could achieve that by changing the method signature to `withBootstrapPartitions(int startIndex, int endIndex)` and document that startIndex <= endIndex. Would that be sufficient?, Label: 1\n",
      "Processing row 3961 - Data Type: train, Message: Will correct, for this method and the following, Label: 0\n",
      "Processing row 3962 - Data Type: train, Message: Will correct, for this method and the following, Label: 0\n",
      "Processing row 3963 - Data Type: train, Message: It was just recently added for some specific purpose. I am not sure exactly what was it., Label: 1\n",
      "Processing row 3964 - Data Type: train, Message: It was just recently added for some specific purpose. I am not sure exactly what was it., Label: 1\n",
      "Processing row 3965 - Data Type: train, Message: Well, by definition they are not. But the way they are written, they kind of are. Just with some warnings., Label: 0\n",
      "Processing row 3966 - Data Type: train, Message: Well, by definition they are not. But the way they are written, they kind of are. Just with some warnings., Label: 0\n",
      "Processing row 3967 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 3968 - Data Type: train, Message: Sure, Label: 0\n",
      "Processing row 3969 - Data Type: train, Message: Reverted the anti-pattern, made the constants private, Label: 0\n",
      "Processing row 3970 - Data Type: train, Message: Reverted the anti-pattern, made the constants private, Label: 0\n",
      "Processing row 3971 - Data Type: train, Message: It wouldn't. This code is in isTable() which is not a recursive function., Label: 0\n",
      "Processing row 3972 - Data Type: train, Message: It wouldn't. This code is in isTable() which is not a recursive function., Label: 0\n",
      "Processing row 3973 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3974 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3975 - Data Type: train, Message: Totally agree. This is an existing test that using it. I don't know how to rewrite it quickly. Any suggestions?, Label: 1\n",
      "Processing row 3976 - Data Type: train, Message: Totally agree. This is an existing test that using it. I don't know how to rewrite it quickly. Any suggestions?, Label: 1\n",
      "Processing row 3977 - Data Type: train, Message: Using Optional as a field type has always been something I've been unsure of. I like Optional as a field type since it forces the empty check, but a couple points against it is that it is still possible to set it to null and the original intention was for it to just be for return types.\n",
      "Since you mention it though, I'm good with using it as a field type., Label: 0\n",
      "Processing row 3978 - Data Type: train, Message: Using Optional as a field type has always been something I've been unsure of. I like Optional as a field type since it forces the empty check, but a couple points against it is that it is still possible to set it to null and the original intention was for it to just be for return types.\n",
      "Since you mention it though, I'm good with using it as a field type., Label: 0\n",
      "Processing row 3979 - Data Type: train, Message: Object.equals already facts in not-null checks in it's implementation. If I use plain string comparison, then I'd to do all those checks. I think it makes things simple(I generally use it for object-equality checks). , Label: 0\n",
      "Processing row 3980 - Data Type: train, Message: Object.equals already facts in not-null checks in it's implementation. If I use plain string comparison, then I'd to do all those checks. I think it makes things simple(I generally use it for object-equality checks). , Label: 0\n",
      "Processing row 3981 - Data Type: train, Message: By default, we intend to choose `ZkJobCoordinatorFactory`. So if the cooridnator factory is not overridden to `AzureJobCoordinatorFactory` or `PassThroughCoordinatory`, the right behavior should be set coordinatorUtils to `ZkJobCoordinatorUtilsfactory`. We should not throw up here. , Label: 0\n",
      "Processing row 3982 - Data Type: train, Message: By default, we intend to choose `ZkJobCoordinatorFactory`. So if the cooridnator factory is not overridden to `AzureJobCoordinatorFactory` or `PassThroughCoordinatory`, the right behavior should be set coordinatorUtils to `ZkJobCoordinatorUtilsfactory`. We should not throw up here. , Label: 0\n",
      "Processing row 3983 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3984 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 3985 - Data Type: train, Message: Before QueryTranslator performs \"translate()\", \"SamzaSqlApplicationConfig\" or \"SamzaSqlApplication\" has to know whether the Sql is a query . If we still use the approach of this PR that passes the query only to Calcite when users perform SELECT sql statement, to around commenting these lines, I am not very sure if we can add an API \"hasSqlQuery()\" in \"interface DslConverter\" or somewhere. \n",
      "\n",
      "Or, we can think of other solutions, for example, we still pass the whole Sql statement to Calcite, but still, we need to figure out a way to deal with the issue of missing schema of log.outputStream.\n",
      ", Label: 0\n",
      "Processing row 3986 - Data Type: train, Message: Before QueryTranslator performs \"translate()\", \"SamzaSqlApplicationConfig\" or \"SamzaSqlApplication\" has to know whether the Sql is a query . If we still use the approach of this PR that passes the query only to Calcite when users perform SELECT sql statement, to around commenting these lines, I am not very sure if we can add an API \"hasSqlQuery()\" in \"interface DslConverter\" or somewhere. \n",
      "\n",
      "Or, we can think of other solutions, for example, we still pass the whole Sql statement to Calcite, but still, we need to figure out a way to deal with the issue of missing schema of log.outputStream.\n",
      ", Label: 0\n",
      "Processing row 3987 - Data Type: train, Message: Event Hubs uses eventData, which is a AMQP map under to hood. The kv-pair format from Samza is therefore not kept. Users may specify that they want to add the key in the map in addition to the value. I will clarify, Label: 0\n",
      "Processing row 3988 - Data Type: val, Message: Event Hubs uses eventData, which is a AMQP map under to hood. The kv-pair format from Samza is therefore not kept. Users may specify that they want to add the key in the map in addition to the value. I will clarify, Label: 0\n",
      "Processing row 3989 - Data Type: train, Message: This is resolved, not sure why it still doesn't show the diff in the preview., Label: 1\n",
      "Processing row 3990 - Data Type: train, Message: This is resolved, not sure why it still doesn't show the diff in the preview., Label: 1\n",
      "Processing row 3991 - Data Type: train, Message: `cluster-manager.jobcoordinator.jmx.enabled` is the config we use which can be misleading since it has jobcoordinator in it. I thought about it and wanted to rename this config to `cluster-manager.jmx.enabled` but we also have a legacy yarn config for the same. \n",
      "\n",
      "To avoid confusion I created a new, I agree one config for JC and Container but is renaming an existing config acceptable?, Label: 1\n",
      "Processing row 3992 - Data Type: train, Message: `cluster-manager.jobcoordinator.jmx.enabled` is the config we use which can be misleading since it has jobcoordinator in it. I thought about it and wanted to rename this config to `cluster-manager.jmx.enabled` but we also have a legacy yarn config for the same. \n",
      "\n",
      "To avoid confusion I created a new, I agree one config for JC and Container but is renaming an existing config acceptable?, Label: 1\n",
      "Processing row 3993 - Data Type: train, Message: no, there is not start in adminClient., Label: 0\n",
      "Processing row 3994 - Data Type: train, Message: no, there is not start in adminClient., Label: 0\n",
      "Processing row 3995 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3996 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 3997 - Data Type: train, Message: Correct., Label: 0\n",
      "Processing row 3998 - Data Type: train, Message: Correct., Label: 0\n",
      "Processing row 3999 - Data Type: train, Message: Join has two inputs to it. And the type of input could be either a stream, local table or remote table. And that is what I wanted to represent here in the enum. Should I change the enum name to InputType and rename the values to STREAM, LOCAL_TABLE, REMOTE_TABLE ? Splitting them as a boolean for stream or table and then another boolean for local or remote would be another approach., Label: 1\n",
      "Processing row 4000 - Data Type: train, Message: Join has two inputs to it. And the type of input could be either a stream, local table or remote table. And that is what I wanted to represent here in the enum. Should I change the enum name to InputType and rename the values to STREAM, LOCAL_TABLE, REMOTE_TABLE ? Splitting them as a boolean for stream or table and then another boolean for local or remote would be another approach., Label: 1\n",
      "Processing row 4001 - Data Type: train, Message: race condition w/ new topic additions, Label: 0\n",
      "Processing row 4002 - Data Type: train, Message: race condition w/ new topic additions, Label: 0\n",
      "Processing row 4003 - Data Type: train, Message: will do, Label: 1\n",
      "Processing row 4004 - Data Type: train, Message: will do, Label: 1\n",
      "Processing row 4005 - Data Type: train, Message: will do, Label: 1\n",
      "Processing row 4006 - Data Type: train, Message: will do, Label: 1\n",
      "Processing row 4007 - Data Type: val, Message: Yes, good point. We want to make all the previous metadata of the job execution available to the interface so that it can generate grouping that is partition aware(or in future do other optimizations). \n",
      "\n",
      "1. Currently in samza, `SystemStreamPartitionGrouper` is only instantiated through the `SystemStreamPartitionGrouperFactory` using reflection. So, to invoke the appropriate `SystemStreamPartitionGrouper` constructor which takes in the `GrouperContext` optional, the factory has to be aware of the GrouperContext optional. To accomplish this, we need to make a interface change(add a new method) in `SystemStreamPartitionGrouperFactory`. However, the problem then becomes the factory invoking the right constructor and any custom implementations in the future, would come to know that this `GrouperContext` is available by following a trial through the factory which may not be obvious. By adding this to the interface we make the interface contract clear and upfront.\n",
      "2. I think the grouper context will be present for a job all the time. During the first run of the samza job, it will be empty. I'm not sure of the necessity to make it optional though.\n",
      "\n",
      "This interface change was approved in SEP-5. If you have strong opinions about this, then lets discuss offline. , Label: 0\n",
      "Processing row 4008 - Data Type: val, Message: Yes, good point. We want to make all the previous metadata of the job execution available to the interface so that it can generate grouping that is partition aware(or in future do other optimizations). \n",
      "\n",
      "1. Currently in samza, `SystemStreamPartitionGrouper` is only instantiated through the `SystemStreamPartitionGrouperFactory` using reflection. So, to invoke the appropriate `SystemStreamPartitionGrouper` constructor which takes in the `GrouperContext` optional, the factory has to be aware of the GrouperContext optional. To accomplish this, we need to make a interface change(add a new method) in `SystemStreamPartitionGrouperFactory`. However, the problem then becomes the factory invoking the right constructor and any custom implementations in the future, would come to know that this `GrouperContext` is available by following a trial through the factory which may not be obvious. By adding this to the interface we make the interface contract clear and upfront.\n",
      "2. I think the grouper context will be present for a job all the time. During the first run of the samza job, it will be empty. I'm not sure of the necessity to make it optional though.\n",
      "\n",
      "This interface change was approved in SEP-5. If you have strong opinions about this, then lets discuss offline. , Label: 0\n",
      "Processing row 4009 - Data Type: train, Message: Same as above, Label: 0\n",
      "Processing row 4010 - Data Type: train, Message: Same as above, Label: 0\n",
      "Processing row 4011 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4012 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4013 - Data Type: train, Message: I had considered this, but since external context is passed through the ApplicationRunner and not through the SamzaApplication (unlike ApplicationContainerContext/ApplicationTaskContext), I didn't want to couple it with being \"application-defined\".\n",
      "Do you still think we should add that label?, Label: 1\n",
      "Processing row 4014 - Data Type: train, Message: I had considered this, but since external context is passed through the ApplicationRunner and not through the SamzaApplication (unlike ApplicationContainerContext/ApplicationTaskContext), I didn't want to couple it with being \"application-defined\".\n",
      "Do you still think we should add that label?, Label: 1\n",
      "Processing row 4015 - Data Type: train, Message: I thought you hadn't pushed the change yet to avoid the unused import check. It looked like other Samza API classes still were using the FQN. Could you confirm?, Label: 1\n",
      "Processing row 4016 - Data Type: train, Message: I thought you hadn't pushed the change yet to avoid the unused import check. It looked like other Samza API classes still were using the FQN. Could you confirm?, Label: 1\n",
      "Processing row 4017 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4018 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4019 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4020 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4021 - Data Type: train, Message: At the moment Samza-Sql-Shell prefers return values for expected error or must-handle errors. I know it's controversial but as I mentioned in a previous comment, we need to change the way of reporting errors entirely if we decide to use exceptions. Can we keep this issue for a while and see what we can do as a future work?, Label: 1\n",
      "Processing row 4022 - Data Type: train, Message: At the moment Samza-Sql-Shell prefers return values for expected error or must-handle errors. I know it's controversial but as I mentioned in a previous comment, we need to change the way of reporting errors entirely if we decide to use exceptions. Can we keep this issue for a while and see what we can do as a future work?, Label: 1\n",
      "Processing row 4023 - Data Type: train, Message: this was an outdated upload, Label: 0\n",
      "Processing row 4024 - Data Type: train, Message: this was an outdated upload, Label: 0\n",
      "Processing row 4025 - Data Type: train, Message: rolled back, Label: 0\n",
      "Processing row 4026 - Data Type: train, Message: rolled back, Label: 0\n",
      "Processing row 4027 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4028 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4029 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4030 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4031 - Data Type: train, Message: This is checking/validating across re-deployments of the job, where the set of standby tasks could have changed for a variety of reasons., Label: 1\n",
      "Processing row 4032 - Data Type: train, Message: This is checking/validating across re-deployments of the job, where the set of standby tasks could have changed for a variety of reasons., Label: 1\n",
      "Processing row 4033 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4034 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4035 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 4036 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 4037 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4038 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4039 - Data Type: train, Message: I too initially had CompletableFuture and then moved to CompletionStage. CompletionStage offers much stricter async programming semantics and CompletableFuture is concrete implementation of the CompletionStage interface. I chose to go with the interface., Label: 0\n",
      "Processing row 4040 - Data Type: train, Message: I too initially had CompletableFuture and then moved to CompletionStage. CompletionStage offers much stricter async programming semantics and CompletableFuture is concrete implementation of the CompletionStage interface. I chose to go with the interface., Label: 0\n",
      "Processing row 4041 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4042 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4043 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4044 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4045 - Data Type: train, Message: Good question. Usually the id and physical are the same for intermediate streams since they are generated. If the user overrides it for some reason, then we won't append the unique id, for either stream or batch cases. \n",
      "\n",
      "This check is not very obvious given I couldn't find a way to tell that the physical name has been generated already due to the double planning problem in Samza. If we only invoke the planner once during submission, then we don't need this logic anymore :(., Label: 0\n",
      "Processing row 4046 - Data Type: train, Message: Good question. Usually the id and physical are the same for intermediate streams since they are generated. If the user overrides it for some reason, then we won't append the unique id, for either stream or batch cases. \n",
      "\n",
      "This check is not very obvious given I couldn't find a way to tell that the physical name has been generated already due to the double planning problem in Samza. If we only invoke the planner once during submission, then we don't need this logic anymore :(., Label: 0\n",
      "Processing row 4047 - Data Type: train, Message: I am not sure i understand the comment. Are you asking whether we should handle null values for unionSchema?, Label: 1\n",
      "Processing row 4048 - Data Type: train, Message: I am not sure i understand the comment. Are you asking whether we should handle null values for unionSchema?, Label: 1\n",
      "Processing row 4049 - Data Type: train, Message: Good point. In that case I think we can use a prefix \"io.read.and.write.retry.policy\" to indicate that this TableRetryPolicy is used for both read and write.\n",
      "Another solution could be preventing users to use same instance. But that's not convenient for users., Label: 0\n",
      "Processing row 4050 - Data Type: train, Message: Good point. In that case I think we can use a prefix \"io.read.and.write.retry.policy\" to indicate that this TableRetryPolicy is used for both read and write.\n",
      "Another solution could be preventing users to use same instance. But that's not convenient for users., Label: 0\n",
      "Processing row 4051 - Data Type: train, Message: But if we don't keep the ClassName, this key will be the same as the key we have been using to (de)serialize the TableRetryPolicy. And thus it will override the existing key. I suggest we use a short ClassName here without the namespace., Label: 0\n",
      "Processing row 4052 - Data Type: train, Message: But if we don't keep the ClassName, this key will be the same as the key we have been using to (de)serialize the TableRetryPolicy. And thus it will override the existing key. I suggest we use a short ClassName here without the namespace., Label: 0\n",
      "Processing row 4053 - Data Type: train, Message: same as above, Label: 0\n",
      "Processing row 4054 - Data Type: train, Message: same as above, Label: 0\n",
      "Processing row 4055 - Data Type: train, Message: Maybe we could put it in a class in `package org.apache.samza.util`?, Label: 1\n",
      "Processing row 4056 - Data Type: train, Message: Maybe we could put it in a class in `package org.apache.samza.util`?, Label: 1\n",
      "Processing row 4057 - Data Type: train, Message: no, reverted that , Label: 0\n",
      "Processing row 4058 - Data Type: train, Message: no, reverted that , Label: 0\n",
      "Processing row 4059 - Data Type: train, Message: 1. This was meant to be used in the tests alone. Not meant to be a public API.  Will change the visibility of it.\n",
      "2. Other util classes are not even having a constructor that can instantiate a meta-store., Label: 0\n",
      "Processing row 4060 - Data Type: train, Message: 1. This was meant to be used in the tests alone. Not meant to be a public API.  Will change the visibility of it.\n",
      "2. Other util classes are not even having a constructor that can instantiate a meta-store., Label: 0\n",
      "Processing row 4061 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4062 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4063 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4064 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4065 - Data Type: val, Message: Java requires a varargs parameter to be the last parameter. I could move the `classLoader` argument earlier in the params list (even first?). Would that be worth it? If I do that, would it be worth it to make `getObj` consistent with the new parameter ordering too (hopefully the IDE can help me out with the re-ordering)?, Label: 1\n",
      "Processing row 4066 - Data Type: train, Message: Java requires a varargs parameter to be the last parameter. I could move the `classLoader` argument earlier in the params list (even first?). Would that be worth it? If I do that, would it be worth it to make `getObj` consistent with the new parameter ordering too (hopefully the IDE can help me out with the re-ordering)?, Label: 1\n",
      "Processing row 4067 - Data Type: train, Message: Yep, it's good that you brought the question up. It'll be good to have some more context about this. I added some javadoc in `ReflectionUtil`.\n",
      "Also, I wanted to correct something I said earlier: in a constructor scope, it is possible to use `getClass().getClassLoader`. It just can't be used in a static scope., Label: 0\n",
      "Processing row 4068 - Data Type: train, Message: Yep, it's good that you brought the question up. It'll be good to have some more context about this. I added some javadoc in `ReflectionUtil`.\n",
      "Also, I wanted to correct something I said earlier: in a constructor scope, it is possible to use `getClass().getClassLoader`. It just can't be used in a static scope., Label: 0\n",
      "Processing row 4069 - Data Type: train, Message: Its neccessary because it allows the regex-expansion to be Kafka-agnostic, which allows the regexGenerator to be moved to samza-core (so that the job-model-manager can invoke it). \n",
      "\n",
      "Currently, the regexGenerator is in samza-kafka, so the job-model-manager cannot invoke the regexGenerator, without adding a dependency (circular) from samza-core to samza-kafka. \n",
      "Also, reading topic info from Zk without using a documented API, bypassing the broker, seems rakish., Label: 0\n",
      "Processing row 4070 - Data Type: train, Message: Its neccessary because it allows the regex-expansion to be Kafka-agnostic, which allows the regexGenerator to be moved to samza-core (so that the job-model-manager can invoke it). \n",
      "\n",
      "Currently, the regexGenerator is in samza-kafka, so the job-model-manager cannot invoke the regexGenerator, without adding a dependency (circular) from samza-core to samza-kafka. \n",
      "Also, reading topic info from Zk without using a documented API, bypassing the broker, seems rakish., Label: 0\n",
      "Processing row 4071 - Data Type: train, Message: I think the upper layers viz the SamzaContainer/StreamProcessor already logs exception before shutdown. Logging here again will be redundant., Label: 0\n",
      "Processing row 4072 - Data Type: train, Message: I think the upper layers viz the SamzaContainer/StreamProcessor already logs exception before shutdown. Logging here again will be redundant., Label: 0\n",
      "Processing row 4073 - Data Type: train, Message: Yup, this is an outdated comment. , Label: 0\n",
      "Processing row 4074 - Data Type: train, Message: Yup, this is an outdated comment. , Label: 0\n",
      "Processing row 4075 - Data Type: val, Message: Infact, it was the code that wasn't reflective of the comments and it now is :), Label: 0\n",
      "Processing row 4076 - Data Type: train, Message: Infact, it was the code that wasn't reflective of the comments and it now is :), Label: 0\n",
      "Processing row 4077 - Data Type: train, Message: it doesn't matter since what we want to achieve at the end is to calculate the duration (latency) so we will compare 2 nanoTime points. The only case where this matter is when we read the eventTime from the kafka record timestamp, which is EpochMilli ... any suggestions how to handle this?, Label: 1\n",
      "Processing row 4078 - Data Type: train, Message: it doesn't matter since what we want to achieve at the end is to calculate the duration (latency) so we will compare 2 nanoTime points. The only case where this matter is when we read the eventTime from the kafka record timestamp, which is EpochMilli ... any suggestions how to handle this?, Label: 1\n",
      "Processing row 4079 - Data Type: train, Message: Good catch. I forgot to undo this., Label: 0\n",
      "Processing row 4080 - Data Type: val, Message: Good catch. I forgot to undo this., Label: 0\n",
      "Processing row 4081 - Data Type: train, Message: it doesnt. need some way of giving KafkaConsumer proxy a handle to the SystemConsumer., Label: 0\n",
      "Processing row 4082 - Data Type: train, Message: it doesnt. need some way of giving KafkaConsumer proxy a handle to the SystemConsumer., Label: 0\n",
      "Processing row 4083 - Data Type: train, Message: I agree that, it shuts down the executor service and the call site can instantiate a new one potentially based on its result. It currently shuts it down or not based on `container != null` and maybe i will extract that out from the method and establish a clear contract on this method where it will always invoke shutdownNow. By that, it is clear on the call site that upon invocation of this method, if executor service needs to used a new one needs to be created. \n",
      "\n",
      "I prefer to use immutable method parameters wherever possible since its easier to reason about and also not worry about the side effects. In this case, this method is instance method anyways and IMO, I don't quite understand the benefit of passing the containerExecutorService as a method parameter.\n",
      "\n",
      "As far as creating an executor service upon success, I am debating whether to do it here vs create a new executor service in `onNewJobModel`. wdyt?, Label: 0\n",
      "Processing row 4084 - Data Type: train, Message: I agree that, it shuts down the executor service and the call site can instantiate a new one potentially based on its result. It currently shuts it down or not based on `container != null` and maybe i will extract that out from the method and establish a clear contract on this method where it will always invoke shutdownNow. By that, it is clear on the call site that upon invocation of this method, if executor service needs to used a new one needs to be created. \n",
      "\n",
      "I prefer to use immutable method parameters wherever possible since its easier to reason about and also not worry about the side effects. In this case, this method is instance method anyways and IMO, I don't quite understand the benefit of passing the containerExecutorService as a method parameter.\n",
      "\n",
      "As far as creating an executor service upon success, I am debating whether to do it here vs create a new executor service in `onNewJobModel`. wdyt?, Label: 0\n",
      "Processing row 4085 - Data Type: train, Message: Good point. \n",
      "1. My intent was to ensure the previous executor service was terminated so that we don't leak executor service. But looking at the code deeper, i realized I can't use `isTerminated` because the container thread will contend for the lock to check the state both for `afterStop` and `afterFailure`. One option is to push the creation of executor service to OnNewJobModel to give executor service a chance to acquire the lock and finish the `afterX`. What do you think?\n",
      "2. Exception will cause the job coordinator to shutdown and subsequently the stream processor as well., Label: 1\n",
      "Processing row 4086 - Data Type: train, Message: Good point. \n",
      "1. My intent was to ensure the previous executor service was terminated so that we don't leak executor service. But looking at the code deeper, i realized I can't use `isTerminated` because the container thread will contend for the lock to check the state both for `afterStop` and `afterFailure`. One option is to push the creation of executor service to OnNewJobModel to give executor service a chance to acquire the lock and finish the `afterX`. What do you think?\n",
      "2. Exception will cause the job coordinator to shutdown and subsequently the stream processor as well., Label: 1\n",
      "Processing row 4087 - Data Type: train, Message: As discussed, in order for us to mock and verify, we need to mock multiple nested data, it is not worth the effort to do it for now, as the code are simply copied from existing code., Label: 0\n",
      "Processing row 4088 - Data Type: train, Message: As discussed, in order for us to mock and verify, we need to mock multiple nested data, it is not worth the effort to do it for now, as the code are simply copied from existing code., Label: 0\n",
      "Processing row 4089 - Data Type: train, Message: Yes.  At the end of this function, the changelog properties if defined for the store in user-config are picked-up and populated in the resultant change-log-topic-properties. So this cleanup.policy check is still necessary. We could simplify the code, but I prefer not to couple clean-up with a critical-fix.  What do you think?, Label: 0\n",
      "Processing row 4090 - Data Type: train, Message: Yes.  At the end of this function, the changelog properties if defined for the store in user-config are picked-up and populated in the resultant change-log-topic-properties. So this cleanup.policy check is still necessary. We could simplify the code, but I prefer not to couple clean-up with a critical-fix.  What do you think?, Label: 0\n",
      "Processing row 4091 - Data Type: train, Message: The control flow to create the checkpoint stream is the following:\n",
      "\n",
      "1. Build the checkpoint spec in `KafkaCheckpointManagerFactory`, which uses kafkaConfig.getCheckpointProperties to populate the config in `CheckpointSpec`.\n",
      "2. `KafkaCheckpointManager.createStream` uses the checkpoint spec that was built from 1 and `KafkaSystemAdmin.createStream` in-turn invokes `KafkaSystemAdmin.toKafkaSpec`.\n",
      "3. `KafkaSystemAdmin.toKafkaSpec(CheckpointSpec)` above is used to convert the incoming spec of type `StreamSpec` to `KafkaStreamSpec` .\n",
      " \n",
      "\n",
      "The config in incoming checkpoint `StreamSpec` is already built using   `kafkaConfig.getCheckpointTopicProperties` in `KafkaCheckpointManagerFactory`. So using `kafkaConfig.getCheckpointProperties` here again would be redundant, unnecessary and might return incorrect config-bag.\n",
      "\n",
      "What do you think?, Label: 0\n",
      "Processing row 4092 - Data Type: train, Message: The control flow to create the checkpoint stream is the following:\n",
      "\n",
      "1. Build the checkpoint spec in `KafkaCheckpointManagerFactory`, which uses kafkaConfig.getCheckpointProperties to populate the config in `CheckpointSpec`.\n",
      "2. `KafkaCheckpointManager.createStream` uses the checkpoint spec that was built from 1 and `KafkaSystemAdmin.createStream` in-turn invokes `KafkaSystemAdmin.toKafkaSpec`.\n",
      "3. `KafkaSystemAdmin.toKafkaSpec(CheckpointSpec)` above is used to convert the incoming spec of type `StreamSpec` to `KafkaStreamSpec` .\n",
      " \n",
      "\n",
      "The config in incoming checkpoint `StreamSpec` is already built using   `kafkaConfig.getCheckpointTopicProperties` in `KafkaCheckpointManagerFactory`. So using `kafkaConfig.getCheckpointProperties` here again would be redundant, unnecessary and might return incorrect config-bag.\n",
      "\n",
      "What do you think?, Label: 0\n",
      "Processing row 4093 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 4094 - Data Type: val, Message: Removed., Label: 0\n",
      "Processing row 4095 - Data Type: train, Message: There is nothing in the ContainerPlacementMetadata to determine the container-id (not processor-id) of the resources already acquired. \n",
      "The containerid in this callback is of the container whose stop failed. \n",
      "\n",
      "Given that there are likely many placement actions in the queue (not just one), the resource acquired may be useful for handling subsequent placement actions that are in the queue. \n",
      "Stop-fail is rare occurrence, so relying on the allocator to relinquish is perhaps not that bad., Label: 0\n",
      "Processing row 4096 - Data Type: train, Message: There is nothing in the ContainerPlacementMetadata to determine the container-id (not processor-id) of the resources already acquired. \n",
      "The containerid in this callback is of the container whose stop failed. \n",
      "\n",
      "Given that there are likely many placement actions in the queue (not just one), the resource acquired may be useful for handling subsequent placement actions that are in the queue. \n",
      "Stop-fail is rare occurrence, so relying on the allocator to relinquish is perhaps not that bad., Label: 0\n",
      "Processing row 4097 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 4098 - Data Type: val, Message: Removed., Label: 0\n",
      "Processing row 4099 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 4100 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 4101 - Data Type: train, Message: I did it to keep compatibility since the prior version read directly from the `JobModelManager` which would return an empty string if it doesn't exist.\n",
      "We can break that if we want. Thoughts?, Label: 1\n",
      "Processing row 4102 - Data Type: train, Message: I did it to keep compatibility since the prior version read directly from the `JobModelManager` which would return an empty string if it doesn't exist.\n",
      "We can break that if we want. Thoughts?, Label: 1\n",
      "Processing row 4103 - Data Type: train, Message: Logical id. I updated the variable name to clarify it.., Label: 0\n",
      "Processing row 4104 - Data Type: train, Message: Logical id. I updated the variable name to clarify it.., Label: 0\n",
      "Processing row 4105 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4106 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4107 - Data Type: train, Message: I do agree this seemed a bit icky, will try and work around it. Basically they are wrapping exceptions in Jackson as standard practice to add further context to the exception. The code that does this is nested here [MapDeserializer](https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.12.1/src/main/java/com/fasterxml/jackson/databind/deser/std/MapDeserializer.java#L621) which calls [ContainerDeserializerBase](https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.12.1/src/main/java/com/fasterxml/jackson/databind/deser/std/ContainerDeserializerBase.java#L173)\n",
      "\n",
      "\n",
      "The originator of this exception is here in Samza and states it is for 0.13 and 0.14 support is this throw still required if not will simplify this? [reference](https://github.com/apache/samza/blob/master/samza-core/src/main/java/org/apache/samza/serializers/model/SamzaObjectMapper.java#L109)\n",
      "\n",
      "Will continue to look into it., Label: 1\n",
      "Processing row 4108 - Data Type: train, Message: I do agree this seemed a bit icky, will try and work around it. Basically they are wrapping exceptions in Jackson as standard practice to add further context to the exception. The code that does this is nested here [MapDeserializer](https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.12.1/src/main/java/com/fasterxml/jackson/databind/deser/std/MapDeserializer.java#L621) which calls [ContainerDeserializerBase](https://github.com/FasterXML/jackson-databind/blob/jackson-databind-2.12.1/src/main/java/com/fasterxml/jackson/databind/deser/std/ContainerDeserializerBase.java#L173)\n",
      "\n",
      "\n",
      "The originator of this exception is here in Samza and states it is for 0.13 and 0.14 support is this throw still required if not will simplify this? [reference](https://github.com/apache/samza/blob/master/samza-core/src/main/java/org/apache/samza/serializers/model/SamzaObjectMapper.java#L109)\n",
      "\n",
      "Will continue to look into it., Label: 1\n",
      "Processing row 4109 - Data Type: train, Message:  @kw2542 a question on the API here, for general use case for SamzaException when should we use this?  For example if we get a deserialization error generally or serialization error would we always want SamzaException to wrap the Jackson exception. Dont think this would happen now as they are allowed to throw JsonProcessingException. Therefore this exception is thrown inside a deserialize call so would follow the API more suitably if it was a Json exception. Or should we add a catch up and wrap any Jackson exception in a Samza Exception. \n",
      "\n",
      "In the case above with the current default jackson handling it wraps the SamzaException with further details but the root cause is still SamzaException., Label: 0\n",
      "Processing row 4110 - Data Type: train, Message:  @kw2542 a question on the API here, for general use case for SamzaException when should we use this?  For example if we get a deserialization error generally or serialization error would we always want SamzaException to wrap the Jackson exception. Dont think this would happen now as they are allowed to throw JsonProcessingException. Therefore this exception is thrown inside a deserialize call so would follow the API more suitably if it was a Json exception. Or should we add a catch up and wrap any Jackson exception in a Samza Exception. \n",
      "\n",
      "In the case above with the current default jackson handling it wraps the SamzaException with further details but the root cause is still SamzaException., Label: 0\n",
      "Processing row 4111 - Data Type: train, Message: Right, removed `toString()`, Label: 0\n",
      "Processing row 4112 - Data Type: train, Message: Right, removed `toString()`, Label: 0\n",
      "Processing row 4113 - Data Type: val, Message: Also not used elsewhere in samza and removed., Label: 0\n",
      "Processing row 4114 - Data Type: train, Message: Also not used elsewhere in samza and removed., Label: 0\n",
      "Processing row 4115 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 4116 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 4117 - Data Type: train, Message: Is there a default we can use for the OSS release?, Label: 1\n",
      "Processing row 4118 - Data Type: val, Message: Is there a default we can use for the OSS release?, Label: 1\n",
      "Processing row 4119 - Data Type: train, Message: We can set a default for `zookeeper.clientCnxnSocket = org.apache.zookeeper.ClientCnxnSocketNetty`\n",
      "\n",
      "keyStoreLocation feels sketchy.\n",
      "`zookeeper.ssl.keyStore.location = ./identity.p12`\n",
      "\n",
      "zookeeper.client.secure definitely do not enable by default.\n",
      ", Label: 0\n",
      "Processing row 4120 - Data Type: train, Message: We can set a default for `zookeeper.clientCnxnSocket = org.apache.zookeeper.ClientCnxnSocketNetty`\n",
      "\n",
      "keyStoreLocation feels sketchy.\n",
      "`zookeeper.ssl.keyStore.location = ./identity.p12`\n",
      "\n",
      "zookeeper.client.secure definitely do not enable by default.\n",
      ", Label: 0\n",
      "Processing row 4121 - Data Type: train, Message: Yes. but I didn't want to open a separate PR for this one line java doc change., Label: 0\n",
      "Processing row 4122 - Data Type: train, Message: Yes. but I didn't want to open a separate PR for this one line java doc change., Label: 0\n",
      "Processing row 4123 - Data Type: train, Message: Removed that. It was indeed unnecessary., Label: 0\n",
      "Processing row 4124 - Data Type: train, Message: Removed that. It was indeed unnecessary., Label: 0\n",
      "Processing row 4125 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 4126 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 4127 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4128 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4129 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4130 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4131 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4132 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4133 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 4134 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 4135 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4136 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4137 - Data Type: train, Message: @eskabetxe I see! \n",
      "\n",
      "> I don't know if is needed\n",
      "\n",
      "My take is that it isn't needed - the constructor takes a `JedisCluster`. \n",
      "\n",
      "As part of the initialization of `JedisCluster` , it contacts the cluster:\n",
      "\n",
      "https://github.com/redis/jedis/blob/379bbed0ee363bfc9f31e4591f5d46c28976cff5/src/main/java/redis/clients/jedis/UnifiedJedis.java#L105-L107\n",
      "\n",
      "https://github.com/redis/jedis/blob/379bbed0ee363bfc9f31e4591f5d46c28976cff5/src/main/java/redis/clients/jedis/providers/ClusterConnectionProvider.java#L27\n",
      "\n",
      "https://github.com/redis/jedis/blob/379bbed0ee363bfc9f31e4591f5d46c28976cff5/src/main/java/redis/clients/jedis/providers/ClusterConnectionProvider.java#L36-L49\n",
      "\n",
      "That runs commands in the cluster. So if there are problems contacting the cluster, we'll know before we even construct a `RedisClusterContainer`, Label: 0\n",
      "Processing row 4138 - Data Type: train, Message: @eskabetxe I see! \n",
      "\n",
      "> I don't know if is needed\n",
      "\n",
      "My take is that it isn't needed - the constructor takes a `JedisCluster`. \n",
      "\n",
      "As part of the initialization of `JedisCluster` , it contacts the cluster:\n",
      "\n",
      "https://github.com/redis/jedis/blob/379bbed0ee363bfc9f31e4591f5d46c28976cff5/src/main/java/redis/clients/jedis/UnifiedJedis.java#L105-L107\n",
      "\n",
      "https://github.com/redis/jedis/blob/379bbed0ee363bfc9f31e4591f5d46c28976cff5/src/main/java/redis/clients/jedis/providers/ClusterConnectionProvider.java#L27\n",
      "\n",
      "https://github.com/redis/jedis/blob/379bbed0ee363bfc9f31e4591f5d46c28976cff5/src/main/java/redis/clients/jedis/providers/ClusterConnectionProvider.java#L36-L49\n",
      "\n",
      "That runs commands in the cluster. So if there are problems contacting the cluster, we'll know before we even construct a `RedisClusterContainer`, Label: 0\n",
      "Processing row 4139 - Data Type: train, Message: crap, Label: 0\n",
      "Processing row 4140 - Data Type: val, Message: crap, Label: 0\n",
      "Processing row 4141 - Data Type: val, Message: Yes, it has been thrown when \"99999999999999999999999999\", Label: 0\n",
      "Processing row 4142 - Data Type: train, Message: Yes, it has been thrown when \"99999999999999999999999999\", Label: 0\n",
      "Processing row 4143 - Data Type: train, Message: The code for old ChannelBufferInputStream and new ByteBufInputStream are quite similar, so I expect the same behaviour. Is there a test case that would trigger the bug?, Label: 1\n",
      "Processing row 4144 - Data Type: train, Message: The code for old ChannelBufferInputStream and new ByteBufInputStream are quite similar, so I expect the same behaviour. Is there a test case that would trigger the bug?, Label: 1\n",
      "Processing row 4145 - Data Type: val, Message: is it necessary? I  just checked, it inherits from parent pom, \n",
      "so these config properties are still available in child modules\n",
      ", Label: 1\n",
      "Processing row 4146 - Data Type: train, Message: is it necessary? I  just checked, it inherits from parent pom, \n",
      "so these config properties are still available in child modules\n",
      ", Label: 1\n",
      "Processing row 4147 - Data Type: train, Message: https://github.com/apache/james-project/pull/1075#issuecomment-1176958222, Label: 0\n",
      "Processing row 4148 - Data Type: train, Message: https://github.com/apache/james-project/pull/1075#issuecomment-1176958222, Label: 0\n",
      "Processing row 4149 - Data Type: train, Message: It is based on your suggestion \"please move the key generation out of JMAP-draft. Suggestion: server/container/guice/common\"\n",
      "\n",
      "Can you give more detail?  \n",
      "I tried to move the SecurityKeyload to `server/container/guice/common`, but see it is a bit not correct, So I only move the generateKeystore method \n",
      "\n",
      ", Label: 1\n",
      "Processing row 4150 - Data Type: train, Message: It is based on your suggestion \"please move the key generation out of JMAP-draft. Suggestion: server/container/guice/common\"\n",
      "\n",
      "Can you give more detail?  \n",
      "I tried to move the SecurityKeyload to `server/container/guice/common`, but see it is a bit not correct, So I only move the generateKeystore method \n",
      "\n",
      ", Label: 1\n",
      "Processing row 4151 - Data Type: train, Message: > Actually I missed that but I agree with @vttranlina\n",
      "@thanhbv200585 can you change back to sth like you did before, crowdsecurity is fine. Remind that James repo is not the property of Linagora :)\n",
      "\n",
      "I see what you mean. But what if this collection belongs to Crowdsec? When this Linagora collection contributed into Crowdsec Hub?, Label: 1\n",
      "Processing row 4152 - Data Type: train, Message: > Actually I missed that but I agree with @vttranlina\n",
      "@thanhbv200585 can you change back to sth like you did before, crowdsecurity is fine. Remind that James repo is not the property of Linagora :)\n",
      "\n",
      "I see what you mean. But what if this collection belongs to Crowdsec? When this Linagora collection contributed into Crowdsec Hub?, Label: 1\n",
      "Processing row 4153 - Data Type: train, Message: Bug - Returning empty string. Expected \"LDAP\", Label: 0\n",
      "Processing row 4154 - Data Type: train, Message: Bug - Returning empty string. Expected \"LDAP\", Label: 0\n",
      "Processing row 4155 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 4156 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 4157 - Data Type: train, Message: formatting issue due to unwanted white spaces., Label: 0\n",
      "Processing row 4158 - Data Type: train, Message: formatting issue due to unwanted white spaces., Label: 0\n",
      "Processing row 4159 - Data Type: train, Message: Not clear to me why these typos are there again. I'm double sure I corrected because otherwise the test failed, Label: 1\n",
      "Processing row 4160 - Data Type: train, Message: Not clear to me why these typos are there again. I'm double sure I corrected because otherwise the test failed, Label: 1\n",
      "Processing row 4161 - Data Type: train, Message: Rewritten the code to make it local but I needed to do the same at least for `Database `object because of the `db.disconnect()` statement in the `finally`, Label: 0\n",
      "Processing row 4162 - Data Type: train, Message: Rewritten the code to make it local but I needed to do the same at least for `Database `object because of the `db.disconnect()` statement in the `finally`, Label: 0\n",
      "Processing row 4163 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4164 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4165 - Data Type: val, Message: oppps. Le me fix that, Label: 0\n",
      "Processing row 4166 - Data Type: val, Message: oppps. Le me fix that, Label: 0\n",
      "Processing row 4167 - Data Type: train, Message: Changed variable name with a more meaningful one., Label: 0\n",
      "Processing row 4168 - Data Type: train, Message: Changed variable name with a more meaningful one., Label: 0\n",
      "Processing row 4169 - Data Type: train, Message: I agree with you that simply ignoring the error may lead the ssh client wrongly believe that data have been correctly written. From the protocol point of view it seems that _SSH_MSG_CHANNEL_FAILURE_ should be used only as a possible response of _SSH_MSG_CHANNEL_REQUEST_ so I think that the only useful message in this case is _SSH_MSG_CHANNEL_CLOSE_ _without_ sending _SSH_MSG_CHANNEL_EOF_.\n",
      "\n",
      "That should result in something like\n",
      "```\n",
      "if (ioSession.isOpen()) {\n",
      "\t    // SSHD-795 IOException (Broken pipe) on a socket local forwarding channel\n",
      "\t    // causes SSH client-server connection down...\n",
      "            boolean immediatly = !isOpen();\n",
      "\n",
      "            if(log.isDebugEnabled()) {            \t\n",
      "                log.debug(\"handleWriteDataFailure closing channel. Immediatly: {}\", immediatly);\n",
      "            }\n",
      "            \n",
      "            close(immediatly);\n",
      "}\n",
      "else ....\n",
      "```, Label: 0\n",
      "Processing row 4170 - Data Type: train, Message: I agree with you that simply ignoring the error may lead the ssh client wrongly believe that data have been correctly written. From the protocol point of view it seems that _SSH_MSG_CHANNEL_FAILURE_ should be used only as a possible response of _SSH_MSG_CHANNEL_REQUEST_ so I think that the only useful message in this case is _SSH_MSG_CHANNEL_CLOSE_ _without_ sending _SSH_MSG_CHANNEL_EOF_.\n",
      "\n",
      "That should result in something like\n",
      "```\n",
      "if (ioSession.isOpen()) {\n",
      "\t    // SSHD-795 IOException (Broken pipe) on a socket local forwarding channel\n",
      "\t    // causes SSH client-server connection down...\n",
      "            boolean immediatly = !isOpen();\n",
      "\n",
      "            if(log.isDebugEnabled()) {            \t\n",
      "                log.debug(\"handleWriteDataFailure closing channel. Immediatly: {}\", immediatly);\n",
      "            }\n",
      "            \n",
      "            close(immediatly);\n",
      "}\n",
      "else ....\n",
      "```, Label: 0\n",
      "Processing row 4171 - Data Type: train, Message: No completely sure this is the correct way (`TcpipServerChannel.close(false)` is also called in case of `handleWriteDataFailure` and `ioHandler.exceptionCaught`) but it seems to be the only  one for the `SSH_MSG_CHANNEL_EOF` message to be send back to the ssh client, Label: 1\n",
      "Processing row 4172 - Data Type: train, Message: No completely sure this is the correct way (`TcpipServerChannel.close(false)` is also called in case of `handleWriteDataFailure` and `ioHandler.exceptionCaught`) but it seems to be the only  one for the `SSH_MSG_CHANNEL_EOF` message to be send back to the ssh client, Label: 1\n",
      "Processing row 4173 - Data Type: train, Message: Yes, it's a mistake during merge, Label: 0\n",
      "Processing row 4174 - Data Type: train, Message: Yes, it's a mistake during merge, Label: 0\n",
      "Processing row 4175 - Data Type: train, Message: Ack, Label: 0\n",
      "Processing row 4176 - Data Type: val, Message: Ack, Label: 0\n",
      "Processing row 4177 - Data Type: train, Message: How can I do this without having all parameters in the constructor arguments? Again the reason for the builder is:\n",
      "`Error:(47,13) java: (sizes) ParameterNumber: More than 8 parameters (found 15).`, Label: 1\n",
      "Processing row 4178 - Data Type: train, Message: How can I do this without having all parameters in the constructor arguments? Again the reason for the builder is:\n",
      "`Error:(47,13) java: (sizes) ParameterNumber: More than 8 parameters (found 15).`, Label: 1\n",
      "Processing row 4179 - Data Type: train, Message: This diff is very misleading. The line 125 was not changed, the change was in the doc of org.apache.sshd.common.keyprovider.KeyPairProvider#getKeyTypes in line 135, which returns a HashSet, which does NOT keep any order. The order is important in the other \"part\" later in AbstractServerSession: \"provided\" vs. \"available\" signatures..., Label: 0\n",
      "Processing row 4180 - Data Type: train, Message: This diff is very misleading. The line 125 was not changed, the change was in the doc of org.apache.sshd.common.keyprovider.KeyPairProvider#getKeyTypes in line 135, which returns a HashSet, which does NOT keep any order. The order is important in the other \"part\" later in AbstractServerSession: \"provided\" vs. \"available\" signatures..., Label: 0\n",
      "Processing row 4181 - Data Type: train, Message: We have `read` which calls `checkData` which calls `checkDataResponse`.  Having the 3 methods setting `eofSignalled` to null when entering while the only place where it can be set to a non null value is later inside the `checkDataResponse` seems a bit redundant to me.  Also, I think checking the EOF value in case an exception has been thrown is meaningless, so only keeping the `eofSignalled.set(null)` from inside `checkDataResponse` sounds enough to me., Label: 0\n",
      "Processing row 4182 - Data Type: train, Message: We have `read` which calls `checkData` which calls `checkDataResponse`.  Having the 3 methods setting `eofSignalled` to null when entering while the only place where it can be set to a non null value is later inside the `checkDataResponse` seems a bit redundant to me.  Also, I think checking the EOF value in case an exception has been thrown is meaningless, so only keeping the `eofSignalled.set(null)` from inside `checkDataResponse` sounds enough to me., Label: 0\n",
      "Processing row 4183 - Data Type: val, Message: Finally, I figured out one of the problems. This use of the Cipher class is incorrect. When verifying an AT, that should be processed in `update` rather than `doFinal`., Label: 0\n",
      "Processing row 4184 - Data Type: train, Message: Finally, I figured out one of the problems. This use of the Cipher class is incorrect. When verifying an AT, that should be processed in `update` rather than `doFinal`., Label: 0\n",
      "Processing row 4185 - Data Type: val, Message: SSH doesn't seem to support that: https://github.com/openbsd/src/blob/master/usr.bin/ssh/cipher.c, Label: 0\n",
      "Processing row 4186 - Data Type: train, Message: SSH doesn't seem to support that: https://github.com/openbsd/src/blob/master/usr.bin/ssh/cipher.c, Label: 0\n",
      "Processing row 4187 - Data Type: train, Message: I've mostly optimized away all the garbage here. I do an initial IV clone when calling the public `init` method, but that's the only time. I don't see the IV being cloned further by the `Cipher` classes that use `GCMParameterSpec`., Label: 0\n",
      "Processing row 4188 - Data Type: val, Message: I've mostly optimized away all the garbage here. I do an initial IV clone when calling the public `init` method, but that's the only time. I don't see the IV being cloned further by the `Cipher` classes that use `GCMParameterSpec`., Label: 0\n",
      "Processing row 4189 - Data Type: val, Message: Well, but... I don't known how to do... '':-) (any suggestion?), Label: 1\n",
      "Processing row 4190 - Data Type: train, Message: Well, but... I don't known how to do... '':-) (any suggestion?), Label: 1\n",
      "Processing row 4191 - Data Type: val, Message: Because I am too lazy to fill it for _all_ algorithms.. For most it doesn't make a difference.\n",
      "But can do it for all.. Or we do it like in the original PR - handing in a default, would that also be an option?, Label: 1\n",
      "Processing row 4192 - Data Type: train, Message: Because I am too lazy to fill it for _all_ algorithms.. For most it doesn't make a difference.\n",
      "But can do it for all.. Or we do it like in the original PR - handing in a default, would that also be an option?, Label: 1\n",
      "Processing row 4193 - Data Type: train, Message: Just to clarify, you're using the standard \"Docker For Mac\", or are you running your own VM with docker installed in it?\n",
      "\n",
      "testcontainers has some built-in algorithms that are trying to discover a few well-known/established patterns for discovering how to connect to the docker daemon HTTP API.\n",
      "\n",
      "The most common case is that it's trying to discover the well-known location of the docker unix socket\n",
      "\n",
      "When using the standard \"Docker for Mac\" it's managing all this stuff automagically (there's a unix socket mounted at `/var/run/docker` on the MacOS filesystem), and things should \"just work\"\n",
      "\n",
      "If you're running your own Linux VM though, testcontainers will probably some help to figure out how to connect to your docker daemon inside your VM...\n",
      ", Label: 0\n",
      "Processing row 4194 - Data Type: train, Message: Just to clarify, you're using the standard \"Docker For Mac\", or are you running your own VM with docker installed in it?\n",
      "\n",
      "testcontainers has some built-in algorithms that are trying to discover a few well-known/established patterns for discovering how to connect to the docker daemon HTTP API.\n",
      "\n",
      "The most common case is that it's trying to discover the well-known location of the docker unix socket\n",
      "\n",
      "When using the standard \"Docker for Mac\" it's managing all this stuff automagically (there's a unix socket mounted at `/var/run/docker` on the MacOS filesystem), and things should \"just work\"\n",
      "\n",
      "If you're running your own Linux VM though, testcontainers will probably some help to figure out how to connect to your docker daemon inside your VM...\n",
      ", Label: 0\n",
      "Processing row 4195 - Data Type: val, Message: I've been thinking more about this -- I'll add it with validation for now. Reason: we are indeed waiting until sendKexInit has sent the buffer (or rather, has queued it for sending on the IOSession). But I'm still not happy with that whole KEX implementation. In particular, this having to wait until the buffer is sent should not be necessary, but with the current implementation is unavoidable because of the `ReservedSessionMessagesHandler.sendKexInitRequest` hook added for SSHD-1097, which can modify the buffer and even might send it on its own.\n",
      "\n",
      "That hook was added recently, and is used only in that \"endless tarpit\" thing, where it actually only suppresses writing the buffer. If that were changed to something that could only say \"don't send the message\", I could extract that whole KEX state machine in a separate class and it would even possible to do an implementation that didn't have to wait at all for this race condition case handled here.\n",
      "\n",
      "I wouldn't add a full explanation of how KEX works, that's explained in the RFCs. But the new timeout property will have a comment explaining what it is for., Label: 0\n",
      "Processing row 4196 - Data Type: train, Message: I've been thinking more about this -- I'll add it with validation for now. Reason: we are indeed waiting until sendKexInit has sent the buffer (or rather, has queued it for sending on the IOSession). But I'm still not happy with that whole KEX implementation. In particular, this having to wait until the buffer is sent should not be necessary, but with the current implementation is unavoidable because of the `ReservedSessionMessagesHandler.sendKexInitRequest` hook added for SSHD-1097, which can modify the buffer and even might send it on its own.\n",
      "\n",
      "That hook was added recently, and is used only in that \"endless tarpit\" thing, where it actually only suppresses writing the buffer. If that were changed to something that could only say \"don't send the message\", I could extract that whole KEX state machine in a separate class and it would even possible to do an implementation that didn't have to wait at all for this race condition case handled here.\n",
      "\n",
      "I wouldn't add a full explanation of how KEX works, that's explained in the RFCs. But the new timeout property will have a comment explaining what it is for., Label: 0\n",
      "Processing row 4197 - Data Type: train, Message: hi @lgoldstein \n",
      "Thanks for taking time for review.\n",
      "\n",
      "Actually this was copy-paste from existing code, see https://github.com/apache/mina-sshd/blob/master/sshd-common/src/main/java/org/apache/sshd/common/util/buffer/Buffer.java#L366\n",
      "In getCertificateOptions I provided it correctly but somehow didn't align these two., Label: 0\n",
      "Processing row 4198 - Data Type: train, Message: hi @lgoldstein \n",
      "Thanks for taking time for review.\n",
      "\n",
      "Actually this was copy-paste from existing code, see https://github.com/apache/mina-sshd/blob/master/sshd-common/src/main/java/org/apache/sshd/common/util/buffer/Buffer.java#L366\n",
      "In getCertificateOptions I provided it correctly but somehow didn't align these two., Label: 0\n",
      "Processing row 4199 - Data Type: val, Message: It's my intention to replace hamcrest with assertj. The motivation is to be able to use assertj's assertions on Collections, such as containsExactlyInAnyOrder.\n",
      "\n",
      "I don't believe this is possible with junit (or hamcrest)., Label: 1\n",
      "Processing row 4200 - Data Type: train, Message: It's my intention to replace hamcrest with assertj. The motivation is to be able to use assertj's assertions on Collections, such as containsExactlyInAnyOrder.\n",
      "\n",
      "I don't believe this is possible with junit (or hamcrest)., Label: 1\n",
      "Processing row 4201 - Data Type: train, Message: That type information was needed in some intermediate version -- but fortunately, it's no longer useful. , Label: 0\n",
      "Processing row 4202 - Data Type: train, Message: That type information was needed in some intermediate version -- but fortunately, it's no longer useful. , Label: 0\n",
      "Processing row 4203 - Data Type: train, Message: It's not possible to handle missing START events. Those START events are now the only source of knowledge about when the ride started, so it's not possible to know how long the ride was., Label: 1\n",
      "Processing row 4204 - Data Type: train, Message: It's not possible to handle missing START events. Those START events are now the only source of knowledge about when the ride started, so it's not possible to know how long the ride was., Label: 1\n",
      "Processing row 4205 - Data Type: val, Message: reworked, as above, Label: 0\n",
      "Processing row 4206 - Data Type: train, Message: reworked, as above, Label: 0\n",
      "Processing row 4207 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4208 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4209 - Data Type: train, Message: But if I do that, in order to construct Pipeline from proto, I have to lookup DatanodeDetails based on UUID, which is a map in NodeManager. Not sure why making this into DatanodeDetails is better? , Label: 1\n",
      "Processing row 4210 - Data Type: train, Message: I think the `-P` and `-p` with different meaning can be more confusing., Label: 1\n",
      "Processing row 4211 - Data Type: train, Message: I thought it is the final class and did like that. I think this should be marked as final like other classes like OMVolumeArgs. (As these classes represent proto structure data). And also as for few parameters, I need a deep copy, so I changed like this(And also I feel, if I use super.clone it will make shallow copy, and then I need to change few fields, so I think it will be double work in cloning). Let me know what do you think., Label: 0\n",
      "Processing row 4212 - Data Type: train, Message: Thanks @dineshchitlangia, just noticed and fixed it.\n",
      "\n",
      "A new usage of `OMConfigKeys` was added in the second merge from master.  I usually rebuild locally, but it seems I forgot it in this case.  Thankfully CI caught it.\n",
      "\n",
      "In the end, I had to remove the new code, though, as it introduced failures in token-related test cases., Label: 0\n",
      "Processing row 4213 - Data Type: train, Message: Ahh, ok I see what you mean, nm!, Label: 0\n",
      "Processing row 4214 - Data Type: val, Message: getDao() is needed for TestTaskTimeService which uses mocking., Label: 0\n",
      "Processing row 4215 - Data Type: val, Message: The function to LogEntryString does not expect an exception to be thrown, should I return an empty string at 886 instead ?, Label: 1\n",
      "Processing row 4216 - Data Type: train, Message: @elek I have added a commit which addresses the review comments.\n",
      "There are three places in the test where we call Thread.sleep(100). For two instances we are checking that a condition c is true before and after 100ms. These are not required to be replaced by GenericTestUtil.waitFor. The rest I have changed., Label: 0\n",
      "Processing row 4217 - Data Type: train, Message: Thank you for catching this @bharatviswa504 .\n",
      "It seems that in all such callers, the response is assumed to be non-null.\n",
      "\n",
      "We can address this in following ways:\n",
      "1. Avoid returning NULL and instead rethrow the InterruptedException\n",
      "2. Return empty `response` instance\n",
      "3. Return NULL and put a null check in caller method.\n",
      "\n",
      "I am more inclined to option 1 as it keeps the code base simple.\n",
      "\n",
      "What are your thoughts ?, Label: 1\n",
      "Processing row 4218 - Data Type: train, Message: In #300 `protobuf-compile.version` has been disappeared and we have only `datanode.protobuf-compile.version`. I reorganized this setting to be more similar:\n",
      "\n",
      "```\n",
      "   <!-- Maven protoc compiler -->\n",
      "    <protobuf-maven-plugin.version>0.5.1</protobuf-maven-plugin.version>\n",
      "    <hadooprpc.protobuf-compile.version>3.10.0</hadooprpc.protobuf-compile.version>\n",
      "    <datanode.protobuf-compile.version>3.10.0</datanode.protobuf-compile.version>\n",
      " ```\n",
      "\n",
      "But let me know if you have any better idea..., Label: 0\n",
      "Processing row 4219 - Data Type: train, Message: It may be possible that the location info is null, and not the key info itself., Label: 1\n",
      "Processing row 4220 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4221 - Data Type: train, Message: Moving to Line 56 is ok, but could you give some advice on uni test here ?, Label: 1\n",
      "Processing row 4222 - Data Type: train, Message: And is rebase required here ?, Label: 1\n",
      "Processing row 4223 - Data Type: train, Message: Thanks for the detailed explanation. And how can I run checks on my own fork ?, Label: 1\n",
      "Processing row 4224 - Data Type: val, Message: If two options are both given, why bother filtering twice?, Label: 1\n",
      "Processing row 4225 - Data Type: train, Message: @bharatviswa504\n",
      "What do you think about this `cleanup write-request` ?\n",
      "Could we set the write-operation with a `default` or \n",
      "we need a separated interface addressed the `write-operation` ?, Label: 1\n",
      "Processing row 4226 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4227 - Data Type: train, Message: because clusters are not already deployed, if we introduce this change now, we do not have that problem. Of course we are referring to customer deployments here and not any internal test setups, right?, Label: 1\n",
      "Processing row 4228 - Data Type: train, Message: the code around the previous call doesn't need to bother about the object range, only the base id. the code here requires the object range.\n",
      "worry about an extra call during directory create might be premature in the overall cpu profile?, Label: 1\n",
      "Processing row 4229 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4230 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4231 - Data Type: train, Message: @xiaoyuyao @elek could we just remove this line or add something else ?, Label: 1\n",
      "Processing row 4232 - Data Type: val, Message: Code has changed, Label: 0\n",
      "Processing row 4233 - Data Type: train, Message: This code has changed., Label: 0\n",
      "Processing row 4234 - Data Type: train, Message: the function has changed. this comment gets resolved indirectly, Label: 0\n",
      "Processing row 4235 - Data Type: train, Message: Based on the function, this interface nothing more just providing an SCM client. Yes, I agree that it's used by admin commands but I am not sure if it's important here. (It can be used for any other command, eg. with Freon), Label: 1\n",
      "Processing row 4236 - Data Type: val, Message: Changed, Label: 0\n",
      "Processing row 4237 - Data Type: train, Message: > Typo: dependency has bee -> dependency has been\n",
      "\n",
      ":honeybee:, Label: 0\n",
      "Processing row 4238 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 4239 - Data Type: train, Message: snprintf just appends a null character at the end and we dont need that null character thats why i mentioned string[len+2]. In snprintf we have to pass len+3 because its function requirement., Label: 0\n",
      "Processing row 4240 - Data Type: train, Message: changed\n",
      ", Label: 0\n",
      "Processing row 4241 - Data Type: val, Message: removed, Label: 0\n",
      "Processing row 4242 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4243 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4244 - Data Type: train, Message: Yes. Unfortunately I found that the original check is broken. we might just want to remove it:\n",
      "```\n",
      "$ ozone fs -rm -r ofs://omservice/\n",
      "2020-05-14 18:51:50 INFO  deprecation:1394 - io.bytes.per.checksum is deprecated. Instead, use dfs.bytes-per-checksum\n",
      "2020-05-14 18:51:50 INFO  BasicRootedOzoneFileSystem:476 - delete: key =\n",
      "2020-05-14 18:51:50 WARN  BasicRootedOzoneFileSystem:488 - delete: OFS does not support rm root. To wipe the cluster, please re-init OM instead.\n",
      "rm: `ofs://omservice/': Input/output error\n",
      "```\n",
      "\n",
      "`addTrailingSlashIfNeeded` doesn't really add '/' to empty string (root).\n",
      "\n",
      "~also I noticed the `Input/output error` part. looking into it.~ IMO the `Input/output error` should be fine. Seems like hadoop common Delete.java throws when `fs.delete` returns false. Not much I can do on the FileSystem side, unless we want to return true for rm root., Label: 0\n",
      "Processing row 4245 - Data Type: val, Message: Indeed for o3fs this logic is fixed in HDDS-2973: https://github.com/apache/hadoop-ozone/commit/d1b8c08a71f141be32da459ffa377f7ebdddae27#diff-e48c4ce6b86d4a33c3f38ba8d6d06ea3R442, Label: 0\n",
      "Processing row 4246 - Data Type: val, Message: @bharatviswa504  I have tried to move the duplicate lines to separate method and also perform other cleanups. \n",
      "At the very least, the thread interrupt must be done in the catch block and not in a separate method being called from the catch block. So, the thread.interrupt() is the only line that cannot be avoided from being duplicated., Label: 0\n",
      "Processing row 4247 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4248 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 4249 - Data Type: train, Message: in the previous design, quota just describes the Space Quota, if we want to describe the Count Quota, which one is better to use ? quota is a little ambiguous to describe which one it wants to express. \n",
      "IMO, I prefer to use spaceQuota and countQuota instead, Label: 1\n",
      "Processing row 4250 - Data Type: train, Message: Accept., Label: 0\n",
      "Processing row 4251 - Data Type: train, Message: We need it for `docker-compose up`. Do you see any possibility to set generic environment variables for all the containers? This approach works only for `docker-compose exec` IMHO., Label: 1\n",
      "Processing row 4252 - Data Type: train, Message: > (I'm not sure because I have trouble starting any of the environments with coverage enabled.)\n",
      "\n",
      "How did you try? Docker bridge ip supposed to be available on all the containers. But can be wrong on OSX. But worked well on github environments., Label: 0\n",
      "Processing row 4253 - Data Type: train, Message: Thanks to investigate it. I uploaded a synchronized version. \n",
      "\n",
      "The main problem is that the same functionality is written in Jacoco project under LGPL which couldn't be imported. I wrote my own version from scratch, and this mistake clearly proves that it's independent, as I added my own mistakes ;-), Label: 0\n",
      "Processing row 4254 - Data Type: train, Message: OK., Label: 0\n",
      "Processing row 4255 - Data Type: train, Message: Thanks adoroszlai  for the tipï¼ŒI'll add a volume/bucket to the key. \n",
      "On how to locate the failed key. We can see this in the Exception in client. Typically, the failed keys are displayed in the log with an Exception, such as:\n",
      "\n",
      "`17:45:30.550 [OM StateMachine ApplyTransaction Thread - 0] ERROR OMAudit - user=micahzhao | ip=127.0.0.1 | op=RENAME_KEY {dir/key2=dir/file2, dir/file1=dir/file2} | ret=FAILURE`\n",
      "`org.apache.hadoop.ozone.om.exceptions.OMException: Key not found /a88fb570-5b5d-43db-81e0-d6597f4ea81f/4ad1e6c3-41c3-439d-8082-ae24a601ba38/dir/file1`\n",
      "`at org.apache.hadoop.ozone.om.request.key.OMKeysRenameRequest.validateAndUpdateCacheâ€¦â€¦`, Label: 0\n",
      "Processing row 4256 - Data Type: train, Message: Thanks for @adoroszlai 's reply. At present, our client calls RpcClient#renameKeys through [OzoneBucket#renameKeys](https://github.com/apache/hadoop-ozone/pull/1150/files#diff-a4a0be1d5df61f0de3bdce909bb3a4a3R1273) to batch renameKeys.  OzoneBucket is a bucket-level API, we can only rename Keys in a single volume/bucket use it.\n",
      "I will remove the volume/bucket existence check in OMKeysRenameRequest, it had already checked here. Any other suggestions for changes?, Label: 0\n",
      "Processing row 4257 - Data Type: train, Message: As said, if we fail entire batch, not sure what is the purpose of unDeletedKeys.\n",
      "This will be required if we delete a few entries and skip them. Let me know if i am missing something here., Label: 1\n",
      "Processing row 4258 - Data Type: train, Message: The current behavior is we fail the entire batch if we are not able to delete the key.\n",
      "\n",
      "So, proposal is to change this behavior? \n",
      "\n",
      "And also I see we fail to delete only when key not found. In this case, there is no real point in returning them as unDeletedKeys. Not sure, even in this case if it is helpful.\n",
      "\n",
      "2nd case we fail is when checking ACLS,  when user does not have permission, in this case even if we return unDeletedKeys, not sure how it will be used.\n",
      "\n",
      "3rd case, when reading DB failure, then also whole batch will be failed. As anyway, at that time OM will be terminated, as this is a critical error to avoid DB divergence.\n",
      "\n",
      "So, still, I am not really sure what is real use case of returning unDeletedKeys and how that will be used. Just trying to understand it can be used.\n",
      "\n",
      "The current PR, kept the behavior of existing behavior,(but only removed return of unDeletedKeys) where it used to fail the entire batch.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 4259 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4260 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4261 - Data Type: train, Message: It was auto generated. I did not modify anything here in this file., Label: 0\n",
      "Processing row 4262 - Data Type: val, Message: Integration test failure seems unrelated to the changes here., Label: 0\n",
      "Processing row 4263 - Data Type: train, Message: > I see there is StrToSign if it's S3 auth. I 'm curious about how big this StrToSign can be? And whether 4096 bytes can hold all these.\n",
      "\n",
      "It should not be too big and not cause overflow.\n",
      "\n",
      "https://docs.aws.amazon.com/general/latest/gr/sigv4-create-string-to-sign.html\n",
      "\n",
      "I saw something similar in other places too e.g. \n",
      "org/apache/hadoop/security/token/TokenIdentifier.class with 4096 bytes limit. , Label: 0\n",
      "Processing row 4264 - Data Type: train, Message: I wanted to do explicit serialization. But this also looks safe serialization.\n",
      ", Label: 0\n",
      "Processing row 4265 - Data Type: train, Message: One failure in coverage check looks unreleted., Label: 0\n",
      "Processing row 4266 - Data Type: train, Message: I have used DBStoreBuilder now. But i had to create a db with the same name 'om.db' as the tool only reads from those DB whose DBDefinition is defined. I'm not sure whether that would be a problem., Label: 1\n",
      "Processing row 4267 - Data Type: train, Message: BTW, I find OM met NPE too, HDDS-3999 it is also related the `commitUploadPartInfo`, not sure the relation between these two issue., Label: 1\n",
      "Processing row 4268 - Data Type: val, Message: #verifyPrefixKey() function is doing the same by fetching entries using \"omMgr.getPrefixTable().get(dbKey);\" call.\n",
      "Are you suggesting something different from this verification check?, Label: 1\n",
      "Processing row 4269 - Data Type: train, Message: I spent some time looking around in the code. Not sure how we can do this cleanly for the other sleep., Label: 1\n",
      "Processing row 4270 - Data Type: train, Message: no, I couldn't find the other thread closing the container. one theory could be, We stopped processing the heartbeat from the datanode and if it assumes data node is dead, it could close the container. \n",
      "Yes there is a race condition still unless it could be done atomically. I changed it to try/catch to avoid any race condition., Label: 0\n",
      "Processing row 4271 - Data Type: train, Message: Yes, I learned from you that `load` can be used, but it doesnt work for me:\n",
      "\n",
      "```\n",
      "bats compose_testlib.bats\n",
      "bats: /home/elek/projects/ozone/hadoop-ozone/dist/src/test/shell/../../main/compose/testlib.sh.bash does not exist\n",
      "```\n",
      "\n",
      "Don't know why...., Label: 1\n",
      "Processing row 4272 - Data Type: train, Message: @bharatviswa504 thank you! \n",
      "\n",
      "I was confused on which `createDirectory` API it is. Can you paste a link here so I have better understanding on the context?, Label: 1\n",
      "Processing row 4273 - Data Type: train, Message: @bharatviswa504  \n",
      "\n",
      "I am currently have a problem to verify that a directory is created successfully. \n",
      "\n",
      "What is the API to retrieve the information of directory? Seems that it is not considered as a key or a file so either `getKey` and `getFileStatus` does not work.\n",
      "\n",
      "Basically I can do \n",
      "\n",
      "`bucket.createDirectory(\"/dir1\");` then I need to do a `bucket.getDirectoryStatus`.\n",
      "\n",
      "I also tried another direction: after a `createDirectory` call, try to put a file to that directory and then read that file to justify that `createDirectory` succeed. Later I realized this also does not work because without `createDirectory`, the create file call will always work even for multiple level directory (e.g. `/dir1/dir2/dir3/file`). \n",
      "\n",
      ", Label: 0\n",
      "Processing row 4274 - Data Type: train, Message: Hi @elek , in most automated robot tests `fs.defaultFS` isn't really used.\n",
      "Mostly it improves QoL when user logs into the docker-compose cluster and manually checks for something (e.g. `docker-compose exec om /bin/bash` then `ozone fs -ls /`).\n",
      "\n",
      "I can remove them from this PR., Label: 0\n",
      "Processing row 4275 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4276 - Data Type: train, Message: NA, like above., Label: 0\n",
      "Processing row 4277 - Data Type: train, Message: yup, Label: 0\n",
      "Processing row 4278 - Data Type: train, Message: yup, Label: 0\n",
      "Processing row 4279 - Data Type: val, Message: Made few changes to not to duplicate code., Label: 0\n",
      "Processing row 4280 - Data Type: train, Message: > We may end up lot of unfilled different containers on backend but the new request fail to find any match.\n",
      "\n",
      "The number of storage-classes are limited. Today we have two (REDUCED/STANDARD) So we couldn't have a lot of unfilled containers as we should have one open containers for all the storage-classes. I couldn't see any fragmentation as keys can be stored in the same container if they are in the same storage-class.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 4281 - Data Type: train, Message: Good point. We can support it with mapping numbers to storage classes:\n",
      "\n",
      "```\n",
      "setReplication(1) --> StorageClass=REDUCED (can be STANALONE/ONE->CLOSED/ONE or different)\n",
      "setReplication(3) --> StorageClass=STANDARD (can be RATIS/THREE or EC or anything else...)\n",
      "```, Label: 0\n",
      "Processing row 4282 - Data Type: train, Message: Yes, this is also possible. This section shows the possibilities with the storage-class abstraction. With this abstraction we can define different behavior for the buckets which are used for random read write. The exact details can be changes, Label: 0\n",
      "Processing row 4283 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4284 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4285 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4286 - Data Type: train, Message: Okay, you are right. \n",
      "\n",
      "I will fix it as follow: \n",
      "\n",
      "ContainerID --> å®¹å™¨ID\n",
      "LocalID --> æœ¬åœ°ID, Label: 0\n",
      "Processing row 4287 - Data Type: train, Message: The error occurred on line 423,I think that when `logCapturer.clearOutput();` is executed, there will be a situation where the previous instruction has not been completed, which will cause the data in the cache to not be completely cleared.This will cause this error., Label: 0\n",
      "Processing row 4288 - Data Type: val, Message: Solved it, Label: 0\n",
      "Processing row 4289 - Data Type: train, Message: It is wired to me that my local checkstyle contains when there is no `version` in here., Label: 0\n",
      "Processing row 4290 - Data Type: train, Message: Probably not. \n",
      "\n",
      "SCMNodeDetails and OMNodeDetails do not share the same fields. E.g. OMNodeDetails uses RPC port while SCMNodeDetails has three different server port., Label: 0\n",
      "Processing row 4291 - Data Type: train, Message: Thanks for comments.\n",
      " I have seen your report on hadoop https://issues.apache.org/jira/browse/HADOOP-15369.\n",
      "But right now when i run following command, it fails.\n",
      "`mvn versions:set -DnewVersion=1.1.0 && mvn versions:commit && mvn clean package -DskipTests -Dmaven.javadoc.skip=true\n",
      "`\n",
      "I must modify ozone.version manually and then build, Do you have any suggestions?, Label: 1\n",
      "Processing row 4292 - Data Type: train, Message: Agree., Label: 0\n",
      "Processing row 4293 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4294 - Data Type: train, Message: Have excluded \"RR_NOT_CHECKED\" for integration-test, I think we can remove the isNull check?, Label: 1\n",
      "Processing row 4295 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4296 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 4297 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 4298 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4299 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4300 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 4301 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 4302 - Data Type: train, Message: Test is creating 0 to 5110 directories and `5110` directory is the last one. \n",
      "I am suspecting that `5110` exists in table cache and its again visible while iterating over DB, do you think so?, Label: 1\n",
      "Processing row 4303 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4304 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4305 - Data Type: val, Message: I have add OzoneTestUtils.configureFSOptimizedPaths, which is visible to all `integration-test` cases. Also, I've add the same function into TestOmRequestUtils.configureFSOptimizedPaths, this is basically added to avoid adding new project dependency to `integration-test`. All the `ozone-manager` project test cases using `TestOmRequestUtils` function. \n",
      "\n",
      "Do you agree to this changes ?, Label: 0\n",
      "Processing row 4306 - Data Type: train, Message: Like I explained in below comment, test is to verify the stored elements can be matched against bucketInfo and there is no relation with FSO enabled or not. If required I can make `OZONE_OM_ENABLE_FILESYSTEM_PATHS=true` value, should I change to true?, Label: 1\n",
      "Processing row 4307 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4308 - Data Type: train, Message: I copied this comments \"Add to cache\" from V0 S3MultipartUploadCommitPartRequest class. I think, its added to convey that the entry will be added to cache and later will do the commit operation. Its Request framework logic and anyway its not a important comment and I will remove it. Hope this is same thought you also have, right?, Label: 0\n",
      "Processing row 4309 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4310 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4311 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4312 - Data Type: train, Message: Removed it, Label: 0\n",
      "Processing row 4313 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4314 - Data Type: train, Message: ```\n",
      " If we have two separated config classes (RatisReplicationConfig and ECReplicationConfig), then it's not easy to pass through the same API right?\n",
      " ```\n",
      " \n",
      " In Java I assume we will have a common superclass / interface, so it will be possible. Unfortunately we can do it only with protobuf 3 and I wouldn't like to be blocked by that.\n",
      " \n",
      " Until using proto3 I followed the same approach what we used earlier:\n",
      " \n",
      "  We have multiple subclasses (like `CloseContainerRequestProto`, `ListContainerRequestProto` ...) and based on a type `ContainerCommandRequestProto.type` we choose the right one.\n",
      "  \n",
      "  Here I did exactly the same. The type is encoded in the `replication type` and based on the type we have two protos. But we can deserialize them to good old java classes which have common marker interface.\n",
      "  \n",
      "> So, we need another config class for non Ratis ( you named only RatisReplicationConfig, why do we need to bother Ratis or non Ratis? it's just replication right )?\n",
      "\n",
      "If I understood well, you talk about STANDALONE. \n",
      " \n",
      "  1. STANDALONE replication is deprecated, therefore I didn't create configuration for that.\n",
      "  2. The supported way to use ONE factor is using one node Ratis\n",
      "  3. we do need to bother Ratis or non Ratis because they are different replications. In this model we may have different replication configuration for each of the replcation method\n",
      "  \n",
      ">  I think we can bring ReplicationConfig changes in master itself and in EC branch we just need to add new EC config.\n",
      "\n",
      "I think the current state of the EC development is more like a proto-type phase. I would prefer to do this first on EC branch, check if it works well end2end (at least the read / write path). If it works well we can add it to the master.\n",
      "\n",
      "But I wouldn't change master until we see a working poc from ec.     \n",
      "\n",
      ">  So, why can't we add replication type with more specific like EC_3_2 and replication factor is 5.\n",
      "\n",
      "Because it's a less generic approach and instead of using meaningful, typed fields to hold information we would use string based naming conventions which is more error-prone, what I would like to avoid.\n",
      "\n",
      "And what about if we need to introduce 2-3 new parameters for EC? Would it be EC_3_2_PARAM1_PARAM2_PARAM3?, Label: 1\n",
      "Processing row 4315 - Data Type: train, Message: Sorry, I didn't get the challenge here. Can you please explain it in more details?\n",
      "\n",
      "I am not sure if it's an answer: but I would prefer to keep it in a separated field to make sure we add it only when it's needed. It provides more visibility and code path which more easy to understand..., Label: 1\n",
      "Processing row 4316 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4317 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4318 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4319 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4320 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4321 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4322 - Data Type: train, Message: yup, Label: 0\n",
      "Processing row 4323 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4324 - Data Type: val, Message: yup, Label: 0\n",
      "Processing row 4325 - Data Type: val, Message: yup, Label: 0\n",
      "Processing row 4326 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4327 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4328 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4329 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4330 - Data Type: train, Message: hello,I think it should be check in the DownloadAndImportReplicator,because of  the source datanode will through outputstream to the tar,if tar is null,the task status should be set failed,the tar size check in TarContainerPacker I think is not useful., Label: 0\n",
      "Processing row 4331 - Data Type: val, Message: Good point. \n",
      "\n",
      "This is the result when I use IDE instead of CLI ;-) Fixed now with \n",
      "\n",
      "```\n",
      "sed -i -E 's/[[:space:]]+```/```/g' ReconApi.zh.md`\n",
      "```\n",
      "\n",
      "But after I tested with `hugo serve` I found that the rendering still not perfect. Section titles are hard to identify/read:\n",
      "\n",
      "![image](https://user-images.githubusercontent.com/170549/117798820-cc9f0200-b251-11eb-8f50-2b59f1cad48a.png)\n",
      "\n",
      "Here it's not clear that 'containers/unhealthy is a section title'\n",
      "\n",
      "https://ozone.apache.org/docs/1.1.0/interface/reconapi.html \n",
      "\n",
      "I fixed this styling, too. And now it seems to be more readable: \n",
      "\n",
      "![image](https://user-images.githubusercontent.com/170549/117798613-9792af80-b251-11eb-94a8-0f9c46ce8e89.png)\n",
      ", Label: 0\n",
      "Processing row 4332 - Data Type: train, Message: For ha --scm should it pass multiple scms? What is the expected behavior, I can open a Jira for this., Label: 1\n",
      "Processing row 4333 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4334 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4335 - Data Type: train, Message: Why is that, it throws exception right?, Label: 1\n",
      "Processing row 4336 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4337 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 4338 - Data Type: train, Message: Thanks. I corrected it. It was left by mistake., Label: 0\n",
      "Processing row 4339 - Data Type: train, Message: Thanks, @bharatviswa504 for the comments, I'm thinking below changes:\n",
      "If the flag is 'false' technically it will be OBS(object store) and I'll be mapping these buckets to OBS instead of LEGACY.\n",
      "If the flag is 'true' it will be a normalized path with intermediate directories and I'll be mapping these buckets to LEGACY_FILESYSTEM. Now, with my above proposal, there will be only one LEGACY_FILESYSTEM that represents an un-optimized filesystem.\n",
      "Does this make sense to you?\n",
      " , Label: 1\n",
      "Processing row 4340 - Data Type: val, Message: Changed to Bucket Type., Label: 0\n",
      "Processing row 4341 - Data Type: train, Message: Is there a case when `nsSummaryTable` is null? (like the first time initializing the table), Label: 1\n",
      "Processing row 4342 - Data Type: train, Message: Modify it like `Tip: For the [OM HA]({{< ref \"feature/OM-HA.md\">}}) cluster`ï¼Ÿ, Label: 0\n",
      "Processing row 4343 - Data Type: train, Message: Your suggestion is also good, it will be more intuitive. Then I will combine the two, what do you think?, Label: 0\n",
      "Processing row 4344 - Data Type: train, Message: when a scmclient  is taking a grpc call, if any exception in this list thrown,  it will stop retry, or else it will try for a maxcount at a specified interval , which are set at `SCMClientConfig.java`. here , i want `scmclient.getpipeline()` not to retry if PipelineNotFoundException is threw. , Label: 0\n",
      "Processing row 4345 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4346 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4347 - Data Type: train, Message: What do you mean by embedded structure?\n",
      "you mean to create another proto structure containing ecReplicationConfig/ratisReplicationConfig/standaloneReplicationConfig ? Isn't this force to create proto structures for ratisReplicationConfig/standaloneReplicationConfig as well? IIRC, Currently we have proto structures only for EcReplicationConfig. Not sure this embedded structure confuses ( All other structures have ECREplicationCOnfig, type and  factor. But bucket will have some embedded structure). , Label: 1\n",
      "Processing row 4348 - Data Type: val, Message: Removed the wrong comment., Label: 0\n",
      "Processing row 4349 - Data Type: train, Message: Renamed, Label: 0\n",
      "Processing row 4350 - Data Type: train, Message: I will fix the problem and we should not use port 9890. This will conflict with the port in docker-compose, Label: 0\n",
      "Processing row 4351 - Data Type: val, Message: interface name `org.apache.hadoop.hdds.scm.storage.DataStreamOutput` conflicts with `org.apache.ratis.client.api.DataStreamOutput`, Label: 0\n",
      "Processing row 4352 - Data Type: train, Message: write `netty.buffer.ByteBuf` instead of write `byte[]`, Label: 0\n",
      "Processing row 4353 - Data Type: train, Message: `slice(int, int)` does not copy the underlying buffer.\n",
      "maybe we should use `retainedSlice(int, int)` here to increase the reference count to the underlying buffer., Label: 0\n",
      "Processing row 4354 - Data Type: train, Message: However, most fields and methods we are trying to reuse are private. Is it a good idea to make them protected?, Label: 1\n",
      "Processing row 4355 - Data Type: train, Message: > We don't have hsync feature build in yet in Ozone. Can we make it zero for now?\n",
      "\n",
      "Yes., Label: 0\n",
      "Processing row 4356 - Data Type: train, Message: Is there buffer copy when computing checksum?\n",
      "\n",
      "i.e. Mapped/DirectByteBuffer -> in heap memory, Label: 1\n",
      "Processing row 4357 - Data Type: train, Message: should we follow @avijayanhwx suggestion yesterday that if the policy is `HTTP_AND_HTTPS`, we will fall back to `HTTP`?, Label: 1\n",
      "Processing row 4358 - Data Type: train, Message: the error detail is not exist,but we cluster has this problem that such as uuid was lost, Label: 0\n",
      "Processing row 4359 - Data Type: train, Message: This is for the case where SCMs have consistent but different ports from the default. This key ```OZONE_SCM_RATIS_PORT_KEY``` is only used between SCM nodes right now and the config of the client may not cover it.\n",
      "Another scenario could be that SCMs have inconsistent ratis ports such as MiniOzoneCluster., Label: 0\n",
      "Processing row 4360 - Data Type: train, Message: For the unit test: Is there a better way than adding a `reservedInBytes` getter to `VolumeInfo` for testing, and then asserting its value for each volume?, Label: 1\n",
      "Processing row 4361 - Data Type: val, Message: Using only one list now., Label: 0\n",
      "Processing row 4362 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4363 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4364 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4365 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4366 - Data Type: val, Message: I'm removing this check for now, seems like it's causing various other failures, Label: 0\n",
      "Processing row 4367 - Data Type: train, Message: Yes, the reason for this change was a little involved. \n",
      "\n",
      "`createbucketenv.robot` creates a bucket in `OBJECT_STORE` layout (default since no args passed)\n",
      "Now during test run`createmrenv.robot` does not end up creating itâ€™s own bucket since it finds them already created by `createbucketenv.robot` - but it uses OFS and needs file system semantics, which are only present in `FILE_SYSTEM_OPTIMIZED` buckets.\n",
      "\n",
      "I changed the bucket name here so that it doesn't find a bucket with the same name already created by `createbucketenv.robot` and creates its own buckets in FSO layout.\n",
      "\n",
      "Does the reasoning make sense?, Label: 1\n",
      "Processing row 4368 - Data Type: train, Message: No, sorry. I didn't know this method is inherited., Label: 0\n",
      "Processing row 4369 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4370 - Data Type: train, Message: Will do, Label: 1\n",
      "Processing row 4371 - Data Type: train, Message: @szetszwo \n",
      "like this\n",
      "```\n",
      "public Response put(\n",
      "      @PathParam(\"bucket\") String bucketName,\n",
      "      @PathParam(\"path\") String keyPath,\n",
      "      @HeaderParam(\"Content-Length\") long length,\n",
      "      @QueryParam(\"partNumber\")  int partNumber,\n",
      "      @QueryParam(\"uploadId\") @DefaultValue(\"\") String uploadID,\n",
      "      File bodyFile) throws IOException, OS3Exception {\n",
      "```\n",
      "\n",
      "If change InputStream to File, all UT related to put cannot be used. Is there any way to solve this problem, Label: 1\n",
      "Processing row 4372 - Data Type: val, Message: If streaming is enabled through configuration, do you need to retain the InputStream?, Label: 1\n",
      "Processing row 4373 - Data Type: train, Message: Changing only the proto file fails the backwards compatibility check here:\n",
      "\n",
      "```\n",
      "[INFO] CONFLICT: \"StartContainerBalancerRequestProto\" field: \"idleiterations\" has been removed, but is not reserved [ScmAdminProtocol.proto]\n",
      "[INFO] CONFLICT: \"StartContainerBalancerRequestProto\" field: \"iterations\" ID: 3 has an updated name, previously \"idleiterations\" [ScmAdminProtocol.proto]\n",
      "```\n",
      "\n",
      "With the proto lock file in its original state., Label: 0\n",
      "Processing row 4374 - Data Type: val, Message: Thanks @adoroszlai  can review this.\n",
      "This exception is 100% reproducible when we use FIO concurrent testing.  Looking at the stack, we can see that it was a thread safety problem of RepeatedOmKeyInfo, and the problem did not reappear after this fix.\n",
      "\n",
      "I checked that a similar error had occurred in OM before, when TreeMap was used in OmMultipartKeyInfoï¼šhttps://issues.apache.org/jira/browse/HDDS-2356\n",
      "\n",
      "Recreating this problem with UT can be complex, and currently we only encounter this problem with FUSE and FIO concurrent writes. We have not found this problem in other operations., Label: 0\n",
      "Processing row 4375 - Data Type: val, Message: The same conditions exist in the `RpcClient` constructor (RpcClient.java) where `caCertPem` and `caCertPems` are used in a similar check to see if `caCertPems` exists to set the `caCertPems` to `caCertPem` if necessary.  Not sure if we need to address this.  Are we guaranteed to have at least one of them valid and non null (`caCertPem`)?, Label: 1\n",
      "Processing row 4376 - Data Type: train, Message: Thanks @hanishakoneru for following up.  Yes, I agree - looking at the code for the certificates, it may not be set in neither the `CaCertPemList` nor the `CaCertificate`.  I've added an additional check for null CaCertificate and throws if the not null precondition is not met in the `OzoneClientCache` prior to setCaCerts for the transport.\n",
      "\n",
      "As a result we handle this with the client creation jax injection error 500 http response (max retries) with an exception trace indicating the precondition failure of not null check on the certificate:  \n",
      "_java.lang.NullPointerException\n",
      "at com.google.common.base.Preconditions.checkNotNull(Preconditions.java:880)\n",
      ",org.apache.hadoop.ozone.s3.OzoneClientCache.setCertificate(OzoneClientCache.java:146)_\n",
      "\n",
      "Do we need to do anything in addition?\n",
      "\n",
      "The same conditional check of `caCertPems` for null or empty then setting the `caCertPerms` with the `caCertPer` exists in the `RpcClient` constructor code.  I can followup on this with new jira to patch the `RpcClient` if you think it is needed(?). , Label: 0\n",
      "Processing row 4377 - Data Type: val, Message: Yes, logging a separate error for misconfigured ozone.security while _grpc.tls.enabled_ is `true` for the s3g Grpc TLS channel is much better. \n",
      "\n",
      "I have modified the code for this case on both the s3g Grpc client and the s3g Grpc server.  For the client, `GrpcOmTransport`, should `grpc.tls.enabled` be set when _ozone.security_ = `false`, we log the error \"...security not enabled when TLS specified.\".  Also, we don't set the sslContextBuilder for tls and default to plaintext channel.  Similarly, for the server, `GrpcOzoneManagerServer`, should `grpc.tls.enabled` be set when _ozone.security_ = `false`, we log the error (\"... not enabled when TLS..., using plaintext.\") and default to a plaintext channel., Label: 0\n",
      "Processing row 4378 - Data Type: train, Message: Thanks to @adoroszlai â€™s review, I think the original intention of this [jira](https://issues.apache.org/jira/projects/HDDS/issues/HDDS-6119) is to change `dfs.datanode.keytab.file` to `dfs.datanode.kerberos.keytab.file`, which is similar to naming conventions such as `dfs.datanode.kerberos.principal`. \n",
      "The purpose of this issue is to change its naming for consistency. Do you think this is feasible? If change the naming, the code you mentioned also needs to be changed., Label: 1\n",
      "Processing row 4379 - Data Type: train, Message: thank for pointing out this . i think it is better to remove `scm#stop` here and terminate the process directly.\n",
      "as a service , SCM should has `start` and `stop` method as other services.\n",
      "if we encounter any unexpected case which we can not handle, we could terminate the process without stoping other services gracefully. or do you have any better suggestion here?, Label: 1\n",
      "Processing row 4380 - Data Type: val, Message: it does not matter here, we can set any positive integer., Label: 0\n",
      "Processing row 4381 - Data Type: train, Message: Previously, the bucket-level replication config is set at the bucket creation. If it's missing, client-side default will be used as bucket-level replication config.\n",
      "Now, the bucket-level replication config can be empty. If it's missing, bucket-level replication config will just be `null`. The cluster-level replication config will be used when creating keys in that bucket.\n",
      "\n",
      "Note there is a compatibility change in `ozone sh bucket list` and `ozone sh bucket info`. Those buckets without bucket-level replication config will not show `replicationConfig` in the result.\n",
      "\n",
      "Here is the matrix of default key replication config in different buckets.\n",
      "\n",
      "| cluster level config | default bucket | EC bucket | RATIS bucket |\n",
      "| --- | --- | --- | --- |\n",
      "| RATIS (default) | RATIS | EC | RATIS |\n",
      "| EC | EC | EC | RATIS |, Label: 0\n",
      "Processing row 4382 - Data Type: train, Message: We don't need, since the `replication` and `type` can't be `null`.\n",
      "And it's also weird to fallback to client side config here., Label: 0\n",
      "Processing row 4383 - Data Type: val, Message: we now need to close the `ozoneOutputStream` before creating new directories, I have mentioned the reason in the code comment. This is a behavior change in the test, could you please review this @rakeshadr?, Label: 0\n",
      "Processing row 4384 - Data Type: train, Message: There might be a issue here. If a new test case is added in bucketlist.robot. The test case would fail because of no access id.\n",
      "If might confuse the user.\n",
      "Maybe it's better to do a clean up here?, Label: 1\n",
      "Processing row 4385 - Data Type: train, Message: If we try to implement a check using inheritance then there would be a lot more code that will be added, hence I believe we could leave out this one., Label: 0\n",
      "Processing row 4386 - Data Type: val, Message: I think it reuse is not a good choice?, Label: 1\n",
      "Processing row 4387 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 4388 - Data Type: train, Message: Sorry about that, Ill make the necessary changes !!\n",
      ", Label: 0\n",
      "Processing row 4389 - Data Type: val, Message: Sorry about that, I have reverted the change !!, Label: 0\n",
      "Processing row 4390 - Data Type: train, Message: Each method is associated with a single S3 Endpoint and there are 2 metrics associated with each endpoint, hence we are measuring the number of times a method succeeds and fails, and once an object is initialised we can reuse it for both the metrics, therefore I felt clubbing them together would make more sense !!, Label: 0\n",
      "Processing row 4391 - Data Type: train, Message: I have removed them\n",
      "Please have a look now !\n",
      ", Label: 0\n",
      "Processing row 4392 - Data Type: train, Message: Updated it !!\n",
      ", Label: 0\n",
      "Processing row 4393 - Data Type: train, Message: Yes I am sorry about that, Ill make sure it does not happen in the future!!, Label: 0\n",
      "Processing row 4394 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4395 - Data Type: val, Message: sure, Label: 0\n",
      "Processing row 4396 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4397 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4398 - Data Type: train, Message: I have removed it and replaced it with current role \n",
      "Thanks !!, Label: 0\n",
      "Processing row 4399 - Data Type: train, Message: yeah this is prob not used, removed., Label: 0\n",
      "Processing row 4400 - Data Type: train, Message: Make sense!, Label: 0\n",
      "Processing row 4401 - Data Type: val, Message: Hey Jojo, the latest idea is to be able to set if the request and response is with empty payload or not via option  [--empty-req](https://github.com/apache/ozone/pull/3614/files#diff-c2423ca69889970743c3fc1e72385459675b8ac9dd4d80227ea4b92090625690R60), [--empty-resp](https://github.com/apache/ozone/pull/3614/files#diff-c2423ca69889970743c3fc1e72385459675b8ac9dd4d80227ea4b92090625690R66) . Feel free to let me know how do you think!, Label: 0\n",
      "Processing row 4402 - Data Type: train, Message: Make sense. Checking!, Label: 0\n",
      "Processing row 4403 - Data Type: train, Message: Ah. I actually misread its LICENSE. I thought it was LGPL only after 2.1.\n",
      "\n",
      "Done, Label: 0\n",
      "Processing row 4404 - Data Type: train, Message: Understood will do !!, Label: 0\n",
      "Processing row 4405 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4406 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4407 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4408 - Data Type: train, Message: Its just a cancel, do not have any count and metrics update at this place. InterruptException case, its removed., Label: 0\n",
      "Processing row 4409 - Data Type: train, Message: Not doing any count of failed metrics in this exception case, Label: 0\n",
      "Processing row 4410 - Data Type: val, Message: Right, this ozonesecure directory is supposed for the non-HA case.  There is another ozonesecure-ha directory for the HA case. , Label: 0\n",
      "Processing row 4411 - Data Type: train, Message: Is there a scenario where multiple `HttpServer2` are created in a process, except in testing, or may exist in the future?, Label: 1\n",
      "Processing row 4412 - Data Type: train, Message: When call stop of serviceManager, as its registered part of serviceManager causes stop to fail. We must support stop as common framework or do nothing in stop.\n",
      "So this is removed., Label: 0\n",
      "Processing row 4413 - Data Type: train, Message: 1. For this PR, will avoid serviceManager.stop() and scope out this cleanup\n",
      "2. OR remove serviceManager.stop() and add explicit member fields of class and do cleanup as SCM stop\n",
      "3. OR SCMBlockDeletingService stop() call internally shutdown()\n",
      "Which process should we do currently?, Label: 1\n",
      "Processing row 4414 - Data Type: train, Message: I checked, BlockManagerImpl is also calling close of blockingService twice (may be code bug but not in scope). But this has no impact.\n",
      "Considering this, will call shutdown() in stop() of SCMBlockDeletingService, and this do not have any impact for code reuse.\n",
      ", Label: 1\n",
      "Processing row 4415 - Data Type: train, Message: ![image](https://user-images.githubusercontent.com/112169209/194745690-ec68d287-ef69-47c2-9c79-44148dfc6b71.png)\n",
      ", Label: 0\n",
      "Processing row 4416 - Data Type: train, Message: Could not Understand which Line  text need to remove siyao suggested to keep text., Label: 1\n",
      "Processing row 4417 - Data Type: train, Message: This should not be able to happen, as if a node has a replica it cannot get another copy of it. For a delete to be scheduled it must have a copy which will prevent an add etc.\n",
      "\n",
      "However I will change this to two IF statements rather than if .. else if, Label: 0\n",
      "Processing row 4418 - Data Type: train, Message: yes!! definitely!, Label: 0\n",
      "Processing row 4419 - Data Type: train, Message: Oh sorry, I keep forget that it shows the 3 line above the line the comment intends to :) Done , Label: 0\n",
      "Processing row 4420 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4421 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4422 - Data Type: train, Message: Done , Label: 0\n",
      "Processing row 4423 - Data Type: train, Message: Yes, the range is 0-2.\n",
      "\n",
      "- If we're 2 datanodes away from the limit, we don't need to take any action.\n",
      "- This check is intended for the case when we're 1 datanode away from the limit. In this case we can allow only one new datanode at max to be selected. So, we restrict potential sources - that means only a new target can be selected now.\n",
      "- In your example where max is 2 and count is 2 (we've reached the limit), yes this check will fail but the check in `adaptOnReachingIterationLimits` will pass. It will restrict both sources and targets, so no new datanodes will be selected.\n",
      "\n",
      "Does this make sense or have I misunderstood your comment?, Label: 1\n",
      "Processing row 4424 - Data Type: val, Message: Looking into it, I don't see a straightforward way to do this. @JacksonYao287 Since this PR has been open for quite a while, do you think we should create a different JIRA to investigate restricting sources when targets are unavailable?, Label: 1\n",
      "Processing row 4425 - Data Type: train, Message: Not really...\n",
      "As in this case we need to redo the initialization step in a new instance that loads the certificate data from disk again and instantiates with a clean internal state.\n",
      "If I create the new instance within the switch and call init, I need to get to the same switch case again, with the result of the new initialization, and I can not imagine a way of doing so within the switch case., Label: 0\n",
      "Processing row 4426 - Data Type: train, Message: Is this really needed ? @sumitagrawl , Label: 1\n",
      "Processing row 4427 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4428 - Data Type: train, Message: With 3 states, I think it is fine as it is for now. If we started getting more states we can change it. I personally don't see a great benefit with the switch statement over the `if` calls., Label: 0\n",
      "Processing row 4429 - Data Type: train, Message: Removed the comment., Label: 0\n",
      "Processing row 4430 - Data Type: train, Message: Can I just make the similar change like \"layoutMsg\" ? if the client doesn't set the replication, then we just mention \"with server-side default replication type\" ? @adoroszlai \n",
      "\n",
      "```\n",
      " String layoutMsg = bucketLayout != null\n",
      "        ? \"with bucket layout \" + bucketLayout\n",
      "        : \"with server-side default bucket layout\";\n",
      "```\n",
      ", Label: 1\n",
      "Processing row 4431 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4432 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4433 - Data Type: train, Message: Thanks @sadanand48  have added role info for each instance !!, Label: 0\n",
      "Processing row 4434 - Data Type: val, Message: finished, Label: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 4435 - Data Type: train, Message: finished, Label: 0\n",
      "Processing row 4436 - Data Type: val, Message: finished, Label: 0\n",
      "Processing row 4437 - Data Type: val, Message: Thanks. 1.7.10 is several years old and I don't know why maven suggested that I pick that up. , Label: 0\n",
      "Processing row 4438 - Data Type: val, Message: I'm not really convinced that mis-rep count really means much and it is worth ordering them further, as the container already has enough replicas. We want these to start with a lower priority than anything else (under rep, decommission), which setting it to 6 does. After that, we can only lower the priority further. If we have a mis rep count of 1 or 2 for a 3-2 and a 6-3 container, which is higher priority? I'm not sure about a good way to do this., Label: 1\n",
      "Processing row 4439 - Data Type: train, Message: Could you tell me why it would be more useful? The process is short-term and hence the LeadershipManager will be temporary. The cost of creating a such class is a bit wasting I think., Label: 1\n",
      "Processing row 4440 - Data Type: train, Message: Got it!, Label: 0\n",
      "Processing row 4441 - Data Type: val, Message: 1. ratisClientConfig is only for HDDS clients, shall we use it? \n",
      "2. RatisHelper seems not the best place to hold the common raft logic #transferRatisLeadership, since it is under hdds module and mainly used for XceiverClient. Shall we create a new class for it?, Label: 1\n",
      "Processing row 4442 - Data Type: train, Message: > If `leaderId` is not set due to ratis \n",
      "\n",
      "In that case `updatePeerList()` will never get called and `OMHAMetrics` won't be registered.\n",
      "\n",
      "> error getting leader a blank \"\" string is passed to `omHAMetricsInit`\n",
      "\n",
      "`OMHAMetrics` check whether the current `OMNodeId` is equal to `leaderId`. If `leaderId` is empty then this check will return false and state will be set to 0. If `leaderId` is empty, then there is no leader and setting state to follower seems reasonable to me.\n",
      ", Label: 0\n",
      "Processing row 4443 - Data Type: train, Message: @adoroszlai You are right. This was missed because the code was \n",
      "\n",
      "```java\n",
      "String leaderId = \"\";\n",
      "try{\n",
      "  leader = \n",
      "} catch() {\n",
      "\n",
      "}\n",
      "\n",
      "if (Objects.nonNull(leader)) {\n",
      "\n",
      "}\n",
      "\n",
      "// leaderId could be deliberately left empty down here due to failure to get the leader\n",
      "// after refactoring `String leaderId = \"\";` was removed.\n",
      "```\n",
      "\n",
      "> If we have any leader information, its id cannot be null.\n",
      "\n",
      "I didn't know that.\n",
      "\n",
      "How can we handle this now since the code has been merged?, Label: 1\n",
      "Processing row 4444 - Data Type: train, Message: I think instead of persisting `deleteDiffs`, `renameDiffs`, `createDiffs` and `modifyDiffs`, we can persist `oldObjIdToKeyMap` and `newObjIdToKeyMap` because they are one used to generate `deleteDiffs`, `renameDiffs`, `createDiffs` and `modifyDiffs`. And it can be different for different snapshots.  , Label: 0\n",
      "Processing row 4445 - Data Type: train, Message: `FileAlreadyExistsException` is a subclass of `IOException`, maybe we don't need to include both?, Label: 1\n",
      "Processing row 4446 - Data Type: train, Message: @adoroszlai Done. But maybe we could go even one more step further. What about adding containerCount into DatanodeDetails, or even better... we could add a Set of ContainerID into DatanodeDetails?, Label: 1\n",
      "Processing row 4447 - Data Type: train, Message: I made this change after the IDE warned me that `omResponse.getCreateSnapshotResponse() != null`  would always return true. Since it is coming from proto object `OMResponse` I guess [that would be the case.](https://developers.google.com/protocol-buffers/docs/reference/java-generated)\n",
      "\n",
      "> Note that no Java protocol buffer methods accept or return nulls unless otherwise specified.\n",
      ", Label: 0\n",
      "Processing row 4448 - Data Type: train, Message: One more idea is to create the checkpoint in OmCreateSnapshotCreateRequest#validateAndUpdateCache inside the bucket lock, but the problem here is that if OM crashes/shuts down during the time the entry is in cache and not flushed to DB, a waste checkpoint will be created since it won't be accessed anymore, i.e a failed createSnapshotRequest will create checkpoints and adds up to the space. , Label: 0\n",
      "Processing row 4449 - Data Type: val, Message: I asked whether Rocksdb createCheckpoint call  is synchronous in the rocksdb community group and this is what I got.\n",
      "> 'checkpoint is always sync  after the CreateCheckpoint is completed a point in time copy of your database exists in the output directory'\n",
      "\n",
      "That aside, the problem of unnecessary checkpoint creation when snapshot create fails is still an issue. \n",
      ", Label: 0\n",
      "Processing row 4450 - Data Type: train, Message: yes., Label: 0\n",
      "Processing row 4451 - Data Type: train, Message: Thanks for finding this. Didn't get this, how is it covered by null check., Label: 1\n",
      "Processing row 4452 - Data Type: train, Message: HddsServerUtil would need dependency on hdds-server module which will cause circular dependency.\n",
      "The exception thrown here is [caught here and rethrown](https://github.com/apache/ozone/blob/e90e2dd8ea1770bafea759015c955fc6e2281b9f/hadoop-ozone/ozone-manager/src/main/java/org/apache/hadoop/ozone/om/OmSnapshotManager.java#L270) as IOException., Label: 0\n",
      "Processing row 4453 - Data Type: train, Message: There are `DatanodeStoreSchemaTwoImpl` and `DatanodeStoreSchemaThreeImpl`.  The key types for `delTxTable` are different  in v2 and v3., Label: 0\n",
      "Processing row 4454 - Data Type: train, Message: Ok, but how OzoneManger will initialize S3 secret store without dependency on it? You suggest to start using class loader for this interface implementations?, Label: 1\n",
      "Processing row 4455 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4456 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4457 - Data Type: train, Message: Sorry, I missunderstand your main point. \n",
      "Why S3 secret cache should updating on key/bucket read/write operations? \n",
      "Your suggestion is remove cache update operations from `SecretRequest` and create a LoadingCache directly in SecretManager? Load all values on start from storage and update cache manually on each write operation?, Label: 1\n",
      "Processing row 4458 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4459 - Data Type: val, Message: Meaning those are instance variables parsed by picocli. e.g. `limit`, Label: 0\n",
      "Processing row 4460 - Data Type: train, Message: I get your idea. But Schema V3 table key is not fully composed of ASCII characters (gibberish if printed as-is). That is intended for seekability and space-saving I presume.\n",
      "\n",
      "e.g. for `block_data`:\n",
      "\n",
      "https://github.com/apache/ozone/blob/886fc3d419e07a5736a2112fd748c3b212c2f11f/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/metadata/DatanodeSchemaThreeDBDefinition.java#L42-L43\n",
      "\n",
      "https://github.com/apache/ozone/blob/886fc3d419e07a5736a2112fd748c3b212c2f11f/hadoop-hdds/container-service/src/main/java/org/apache/hadoop/ozone/container/metadata/DatanodeSchemaThreeDBDefinition.java#L150-L154\n",
      "\n",
      "The logic to print it is left untouched. Arguably all valuable key info is extracted here already., Label: 0\n",
      "Processing row 4461 - Data Type: train, Message: Hey, `org.rocksdb.WriteBatch` itself is not thread safe, see https://github.com/facebook/rocksdb/wiki/Basic-Operations\n",
      "> However other objects (like Iterator and WriteBatch) may require external synchronization. If two threads share such an object, they must protect access to it using their own locking protocol.\n",
      "\n",
      "Indeed, making a *batch* operation thread safe does not sound right since a batch is supposed to be sequential.  Making it thread safe decreases the performance., Label: 0\n",
      "Processing row 4462 - Data Type: train, Message: I guess you mean changing the classes to `static`?  I actually started with `static` and passing `writeBatch` around.  The `static` keywords were removed when printing the debug messages with the `name`.  It does not look good to pass also the `name` around., Label: 1\n",
      "Processing row 4463 - Data Type: train, Message: Got it I have exposed the `deletedContainersCount` to the response as well !!, Label: 0\n",
      "Processing row 4464 - Data Type: val, Message: @kerneltime Should I do the web ui change as part of another PR?, Label: 1\n",
      "Processing row 4465 - Data Type: val, Message: > For OMKeyRenamRequest, we should not allow empty key name, that part is ok. Only for OMKeyRenameRequestWithFSO, can remove toKeyName.length() == 0 check, and any further check if causing issue.\n",
      "\n",
      "@sumitagrawl why do you think that we should differentiate the way we handle FSO and non FSO buckets during the rename of a key/directory? \n",
      "\n",
      "> I am proposing to fix at OM layer, because other client integration do not need any change when passing source and destination, and OM layer should support api with this behaviour.\n",
      "\n",
      "I don't think so, the rename in case of a non FSO bucket is also doing the necessary changes in the destination path (in both implementations in `BasicOzoneFilesystem` and `BasicRootedOzoneFilesystem`). I believe it wasn't intentional that in case of a non FSO bucket we didn't do the change. \n",
      "\n",
      "as a conclusion, I'd like to avoid to remove the key name check from the `OMKeyRenameRequestWithFSO` as it would cause inconsistency (with `OMKeyRenameRequest`), which is not necessary in this case and it can be confusing. let me know what you think of it., Label: 1\n",
      "Processing row 4466 - Data Type: val, Message: with this logic also the non FSO destinations can have an empty key name, as the path can also be `vol/buck/dir1/dir2/key` and the destination can be `/vol/buck` too. that is why there is this part in `BasicRootedOzoneFileSystem` in the `rename()` method, to avoid that case and that is why it is not failing in a case like that in the `OMKeyRenameRequest`.\n",
      "```\n",
      "else if (dstStatus.isDirectory()) {\n",
      "  // If dst is a directory, rename source as subpath of it.\n",
      "  // for example rename /source to /dst will lead to /dst/source\n",
      "  dst = new Path(dst, src.getName());\n",
      "  FileStatus[] statuses;\n",
      "  try {\n",
      "    statuses = listStatus(dst);\n",
      "  } catch (FileNotFoundException fnde) {\n",
      "    statuses = null;\n",
      "  }\n",
      "\n",
      "  if (statuses != null && statuses.length > 0) {\n",
      "    // If dst exists and not a directory not empty\n",
      "    LOG.warn(\"Failed to rename {} to {}, file already exists\" +\n",
      "        \" or not empty!\", src, dst);\n",
      "    return false;\n",
      "  }\n",
      " ```, Label: 0\n",
      "Processing row 4467 - Data Type: train, Message: The problem is `OmSnapshotManager` is not part of `OMMetadataManager` and it is part of `OzoneManager` so we won't be able to get `OmSnapshot` in `OMKeyPurgeResponse` as it only has `OMMetadataManager`, Label: 0\n",
      "Processing row 4468 - Data Type: train, Message: Both jackson-mapper-asl & jackson-core-asl have the same patch version. jackson-jaxrs doesn't seem to have a patched version., Label: 0\n",
      "Processing row 4469 - Data Type: val, Message: Wouldn't it be better to mark this interface as @NotNull? , Label: 1\n",
      "Processing row 4470 - Data Type: val, Message: Can't come up with any negative test cases unfortuanatelly. Calling revoke with no secret will result in correct execution of revoke method hence this case will be indistinguishable from case with secret., Label: 0\n",
      "Processing row 4471 - Data Type: train, Message: There is not, Label: 0\n",
      "Processing row 4472 - Data Type: train, Message: Yup updated thanks attila!, Label: 0\n",
      "Processing row 4473 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4474 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4475 - Data Type: val, Message: yeah, Label: 0\n",
      "Processing row 4476 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4477 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4478 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4479 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4480 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4481 - Data Type: train, Message: oops unintentionally. Thanks attila!, Label: 0\n",
      "Processing row 4482 - Data Type: train, Message: 1. It makes sense to move `estimatedTotalKeys = estimatedSize;` this in synchronized block. Will update it.\n",
      "2. Regarding having double check `if (estimatedTotalKeys != -1)` inside the synchronized block, I agree but [findbug failed](https://github.com/apache/ozone/actions/runs/4813599053/jobs/8571917550) once when I did something similar to create singleton object. Another reason is that it doesn't matter that much because result is used by same thread. I'll add the check and see if findbug works. If does I'll update in next revision otherwise leave as it is.\n",
      ", Label: 0\n",
      "Processing row 4483 - Data Type: train, Message: I verified and I can see it is not creating directory in rename operation., Label: 0\n",
      "Processing row 4484 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4485 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4486 - Data Type: train, Message: yes sure!, Label: 0\n",
      "Processing row 4487 - Data Type: val, Message: yup added!, Label: 0\n",
      "Processing row 4488 - Data Type: val, Message: oh yes removed!, Label: 0\n",
      "Processing row 4489 - Data Type: train, Message: oh yes removed!, Label: 0\n",
      "Processing row 4490 - Data Type: val, Message: updated!, Label: 0\n",
      "Processing row 4491 - Data Type: train, Message: I find it very unlikely that anyone has an implementation of the pipeline choosing policy. Whats the alternative to never being able to change this?\n",
      "\n",
      "The healthy policy isn't good IMO, as it mutates the array it is passed. That could have some strange side effect, if for example the caller was using an iterator over the array or something.\n",
      "\n",
      "I wonder if we could fix he Healthy policy somehow to avoid making it throw on the exception., Label: 1\n",
      "Processing row 4492 - Data Type: train, Message: I wonder why that test used the HealthyPolicy - I changed it to Random and the tests all pass now. The default is also to use Random on the cluster, so its not really clear why \"Healthy\" was used in this test class (even though it was me who put that line of code there, I do not remember!)., Label: 0\n",
      "Processing row 4493 - Data Type: train, Message: I'm confused, In hsync the keys will be `OpenKeyTable` until it is committed right? We here only care about those keys in `keyTable` and `deletedTable`. Please correct me if I'm wrong. , Label: 1\n",
      "Processing row 4494 - Data Type: train, Message: It is being added to `notReclaimableKeyInfo`,  \n",
      "```\n",
      "if (!(infoList.getOmKeyInfoList().size() == 1))\n",
      "```\n",
      "This here is checking for the case where size != 1, which also means size > 1. , Label: 0\n",
      "Processing row 4495 - Data Type: train, Message: For case 2, if all versions are reclaimable then notReclaimableKeyInfoList will be 0. So it will be added to `keyBlocksList` and it will be deleted by the PurgeRequest \n",
      "```\n",
      " if (notReclaimableKeyInfoList.size() !=\n",
      "      infoList.getOmKeyInfoList().size()) {\n",
      "    keyBlocksList.addAll(blockGroupList);\n",
      "  }\n",
      "```\n",
      "3) I don't see a case where we only delete a few blocks in `OMKeyInfo`. Let me know if there is some case., Label: 0\n",
      "Processing row 4496 - Data Type: train, Message: If all versions are reclaimable they are never put it `keysToModify`, they will be deleted by the `KeyDeletingService` itself. It won't even come here., Label: 0\n",
      "Processing row 4497 - Data Type: train, Message: Initially integration tests were failing so I added that.  I removed the redundant null checks from here and change it to exception because we should not be in the situation., Label: 0\n",
      "Processing row 4498 - Data Type: train, Message: The thing is that, it is a race condition, but the problem is not the race...\n",
      "\n",
      "The problem is more of a question instead, around what we want to do with 1.1 or older clients, as all 1.2 or newer client versions work based off of the caCertPemList instead of the caCertPem value.\n",
      "So newer clients rightfully get the list of the old and the new rootCA certificate, and will work with the cluster fine during the rotation, whichever root of trust the certificates of cluster services have old or new.\n",
      "\n",
      "But with older clients we have a similar tradeoff as we had once we have introduce SCM HA. With SCM HA old clients got the sub-CA certificate that OM has read from its filesystem as the signer of its certificate, and if the post 1.2 DN that the pre 1.2 DN trying to connect to has its certificate signed by the same cert, then the client was able to read from the DN. Now in our case, we again need a decision, either we give back the old root CA certificate, which is returned by the certClient at this point, or we return the new certificate.\n",
      "\n",
      "Based on your question I am happy that I thought this through more, and I think we should return the new rootCA certificate here. With that, we will have a glitch in old clients, as we don't know how many DNs have already renewed their certificates with the new rootCA and its subCAs, but for sure the number will be all DNs eventually, while less and less DNs will use their old certificates. So I need to change this code accordingly. Thank you for pointing this out!, Label: 0\n",
      "Processing row 4499 - Data Type: train, Message: Good point. We can set `maxOuterLoopIterations` to a higher value. Looks like the number of iterations are bounded by both `maxOuterLoopIterations` and `OUTER_LOOP_MAX_RETRY`. The latter is a constant and its value currently is `3`, so we need to increase that too. Any suggestions for what their values should be?, Label: 1\n",
      "Processing row 4500 - Data Type: train, Message: I haven't seen it happen yet., Label: 0\n",
      "Processing row 4501 - Data Type: train, Message: If you think this PR works as expected and what you're suggesting is an improvement that can be made separately, let's do that in https://issues.apache.org/jira/browse/HDDS-9054?, Label: 0\n",
      "Processing row 4502 - Data Type: train, Message: @Galsza , do you mean a serial ID which is beyond the scope of LONG can represent? , Label: 1\n",
      "Processing row 4503 - Data Type: train, Message: Long.MAX_VALUE is a very big data.  If every 1s it generate 1000 certificates, then Long.MAX_VALUE will be exhausted by 292 million years.  For a fresh new Ozone cluster, which certificate serial ID starts from 1, Long.MAX_VALUE is enough for this cluster's whole lifetime.  For a already existing Ozone cluster, it's existing max certificate serial ID could be a bigger number. But given the certificate rotation is yearly scheduled, it's very unlikely it will exhaust the numbers. , Label: 0\n",
      "Processing row 4504 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4505 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4506 - Data Type: train, Message: It is not used anymore., Label: 0\n",
      "Processing row 4507 - Data Type: train, Message: When I looked at it, I couldn't find easy way to get start and end entry. Let me take a look as you are suggesting but I'm unsure if compacted files will be there., Label: 1\n",
      "Processing row 4508 - Data Type: train, Message: @adoroszlai  thanks for review, I have a question here.. If we'll not remove step -> `Execute tests`, then unit.sh (unit tests) will run as part of basic check and we want to separate out unit test run out of basic checks...? Did I understood anything wrong here ?, Label: 1\n",
      "Processing row 4509 - Data Type: train, Message: If you really want it to be safe, I can add a condition in the constructor of [CompcationFileInfo](https://github.com/apache/ozone/pull/5303/files#diff-f6807cfb3d601de6e4d002178c53f17767c9547ae04d19c16e089ececaea10a3R26) to make sure that either all three are present or none but creating a another class for it is unnecessary nesting to me. , Label: 0\n",
      "Processing row 4510 - Data Type: train, Message: I wasn't aware that `required` has been removed from proto3. The only reason I used `required` to show that a field is mandatory. I don't get why they think \"It is nearly impossible to safely change a field from required to optional\". To me, it should be OK to change required to optional but not vice-versa.\n",
      "\n",
      "Since it is suggested that required fields should be implemented at the application layer instead, I will change it to optional., Label: 0\n",
      "Processing row 4511 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 4512 - Data Type: train, Message: Need Atomic add kind of feature, like, check and add if not present, else return. \n",
      "With Synchronized set, Add/delete is thread safe but not not achieve above kind of logic., Label: 0\n",
      "Processing row 4513 - Data Type: train, Message: > I have a question! Would it be a good idea to mention the `this.getClass().getName()` to over here, since the stack trace would not be printed?\n",
      "\n",
      "Whenever there is a log printed in logs, log4j always prints the class name from where this log has appeared, so I believe that is not needed., Label: 1\n",
      "Processing row 4514 - Data Type: train, Message: I don't like the names of the generics, nor the R parameter. (I was going for BASE with B)\n",
      "It was only added because the current implementation returns the object the method is enclosed in, so right now, it just conveys that type information.  \n",
      "Ideally, I would want to remove it.\n",
      "\n",
      "One solution would be just to return the IMetadataContext<B> itself, but you wouldn't be able to do much with the return result, short of just setting more metadata., Label: 0\n",
      "Processing row 4515 - Data Type: train, Message: I had to change the signature of this method.\n",
      "Ideally, it should have been that way anyway.\n",
      "Everything still compiles, which means we weren't putting values in keys that weren't expecting them.\n",
      "\n",
      "I fear that some users might be doing exactly that though, so this whole IMetadataContext might have to be put off for a bigger version., Label: 0\n",
      "Processing row 4516 - Data Type: train, Message: Ah, got it.\n",
      "Yeah, stupid mistake.\n",
      "I think initially I mistook the error for the sync modifier, but it was the `T object` parameter.\n",
      "Reverted that weird change., Label: 0\n",
      "Processing row 4517 - Data Type: train, Message: It seems the right RFC for Date formats is RFC7231:\n",
      "https://tools.ietf.org/html/rfc7231#section-7.1.1.1\n",
      "\n",
      "But I admit to be a little confused, especially in respect of what RFC1123 actually says about Date formats. , Label: 0\n",
      "Processing row 4518 - Data Type: train, Message: We can add @deprecated to those methods in Wicket-8.x, but I'm afraid nobody reads JSDoc anyway. Or log an error instead?, Label: 1\n",
      "Processing row 4519 - Data Type: train, Message: modal.js is a beast on its own. IMHO we shouldn't put any effort in it, but deprecate the whole thing instead., Label: 0\n",
      "Processing row 4520 - Data Type: train, Message: ModalWindow is broken beyond repair - not only its JS, but the Wicket internals are broken too, e.g. the need to wrap a Form around it., Label: 0\n",
      "Processing row 4521 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4522 - Data Type: val, Message: Not following you. Class seems to have been removed., Label: 0\n",
      "Processing row 4523 - Data Type: train, Message: The only difference I can spot is this...\n",
      "\n",
      "![image](https://user-images.githubusercontent.com/462655/58690662-c714be00-8392-11e9-9050-c88a730d8b82.png)\n",
      "\n",
      "And this is a method I have added., Label: 0\n",
      "Processing row 4524 - Data Type: train, Message: ![image](https://user-images.githubusercontent.com/462655/58693295-1a8a0a80-8399-11e9-89e4-e0126bd6fba5.png)\n",
      "\n",
      "One of master has CRLF. Which one is correct?, Label: 1\n",
      "Processing row 4525 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4526 - Data Type: val, Message: Done!, Label: 0\n",
      "Processing row 4527 - Data Type: val, Message: Actually I don't like it when a class name replicates its package name. I've avoided it with other 'themes' too, e.g. for palette and tree., Label: 0\n",
      "Processing row 4528 - Data Type: train, Message: I didn't quite get you.  Do you want the `writeJavaScriptUrl(final Response response, final CharSequence url, final String id, boolean defer, String charset, boolean async)` to be dropped?, Label: 1\n",
      "Processing row 4529 - Data Type: val, Message: I mainly need it to have put and add below accepting the enum. Is there any other mechanism to avoid doing `attributes.put(SCRIPT_SRC.getName(), val)` every time? I mean the .getName(), Label: 1\n",
      "Processing row 4530 - Data Type: train, Message: âœ”ï¸ changed, Label: 0\n",
      "Processing row 4531 - Data Type: val, Message: @svenmeier any thoughts about what version should go here?, Label: 1\n",
      "Processing row 4532 - Data Type: val, Message: sorry, this was a regression from our previous commit, Label: 0\n",
      "Processing row 4533 - Data Type: val, Message: My latest commit adds support for multiple files. I have tested it locally and it seems to work (with multiple files). Not sure if the way I did it is the best/correct one., Label: 0\n",
      "Processing row 4534 - Data Type: train, Message: To myself: can we use getParameterValues instead?, Label: 1\n",
      "Processing row 4535 - Data Type: train, Message: @martin-g This is true but \n",
      "\n",
      "![image](https://github.com/apache/wicket/assets/462655/888c755f-399f-4231-a3f1-218ef968a492)\n",
      "\n",
      "Thus the only way I see is add a clearResponseFilters method. Or do you have a better idea?, Label: 1\n",
      "Processing row 4536 - Data Type: train, Message: > Maven Surefire plugin is only for executing the tests via Maven. It does not affect the compilation phase!\n",
      "\n",
      "I agree, sorry for mixing up compile and surefire plugins.\n",
      "\n",
      "> In addition: the src/test/java don't have module-info.java, i.e. they are not Java modules!\n",
      "\n",
      "IMO (esp. after reading https://stackoverflow.com/questions/46613214/java-9-maven-junit-does-test-code-need-module-info-java-of-its-own-and-wher), /src/main/java/module-info.java is used for compiling both /src/main/java and /src/test/java, but compilation of test code seems to be different in Eclipse and Maven, leading to different results (Maven compiles test sources, but Eclipse doesn't do in this case). I think more research is needed here. It would be great if Eclipse would follow Maven in this use case. Meanwhile we could keep requires static jakarta.servlet which would prevent Eclipse developers from manually fixing the build path (via exclude module-info.java, see also my comment in WICKET-7072)., Label: 0\n",
      "Processing row 4537 - Data Type: train, Message: > Fully agree on this!\n",
      "\n",
      "Ok, great!\n",
      "\n",
      "> I just want to propose an improvement:\n",
      "\n",
      "Thank you for this proposal. I'm unsure how to do this practically:\n",
      "- revert the change, commit, redo the change with appropriate comment and commit\n",
      "\n",
      "or\n",
      "\n",
      "- revert the change, commit, wait until PR is merged into master (with commits squashed), open another PR for WICKET-7072, redo the change with appropriate comment and commit?, Label: 0\n",
      "Processing row 4538 - Data Type: train, Message: Copied from previous PR #659:\n",
      "\n",
      ">>> wicket-core/src/main/java/org/apache/wicket/protocol/http/mock/MockHttpSession.java\n",
      "\n",
      ">> I think this class should be moved to wicket-tester\n",
      "\n",
      "Ok, we could do that (I also thought about moving the whole  _package _org/apache/wicket/protocol/http/mock_ to wicket-tester but org.apache.wicket.core.util.string.ComponentRenderer in /src/main/java makes use of org.apache.wicket.protocol.http.mock.MockServletContext, so that wonâ€™t work).\n",
      "\n",
      "Should we move only MockHttpSession to wicket-tester then? If not, how to rewrite this line in MockHttpSession.invalidate()?\n",
      ", Label: 1\n",
      "Processing row 4539 - Data Type: train, Message: I don't think that moving the package from wicket-core to wicket-util would have advantages.\n",
      "\n",
      "My initial assumption was that mocking stuff should be only test scoped, but it currently isn't (as ComponentRenderer shows). IMO we should leave it as it is (possibly requiring a better fix in MockHttpSession.java, see diff) OR move just MockHttpSession.java to wicket-tester?, Label: 1\n",
      "Processing row 4540 - Data Type: train, Message: > See org.apache.wicket.session.HttpSessionStore#getSessionAttributePrefix\n",
      "\n",
      "Ok, I see you changed this\n",
      "originally:  ... _attributes.get(\"wicket:\" + BaseWicketTester.TestFilterConfig.class.getName() + \":session\");_\n",
      "to: ... _attributes.get(\"wicket:org.apache.wicket.util.tester.BaseWicketTester.TestFilterConfig:session\");_\n",
      "\n",
      "I wonder if that's correct since TestFilterConfig is an inner class?\n",
      "\n",
      "A simple alternative would be to save TestFilterConfig as new file and adapt the line to _attributes.get(\"wicket:org.apache.wicket.util.tester.TestFilterConfig:session\");_, Label: 1\n",
      "Processing row 4541 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4542 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4543 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4544 - Data Type: train, Message: <img width=\"914\" alt=\"èž¢å¹•å¿«ç…§ 2020-04-11 ä¸Šåˆ10 42 30\" src=\"https://user-images.githubusercontent.com/6762509/79033600-f5357200-7be1-11ea-840d-3de18dc1845b.png\">\n",
      ", Label: 0\n",
      "Processing row 4545 - Data Type: train, Message: Experiment Spec contains \"image\" and we are about to ship 0.4.0 release. So, renaming as \"containerImage\" cause unnecessary confusions in upcoming releases. If we want to rename, it is better to do for 0.4.0 release itself. Thoughts?, Label: 1\n",
      "Processing row 4546 - Data Type: train, Message: Slightly changed the definition of \"environment\" in Experiment spec. For example, Below spec is valid.\n",
      "\n",
      "environment: {\n",
      "\"image\":\"..\",\n",
      "\"name\":\"..\"\n",
      "}\n",
      "\n",
      "If \"image\" is available, set it as k8 container image. If \"name\" is available, fetch the environment details using name from DB/Cache and use the details for K8 init container process. Hope this make the whole thing intuitive and simpler. Thoughts? @tangzhankun @wangdatan , Label: 0\n",
      "Processing row 4547 - Data Type: train, Message: updateEnvironment and createEnvironment calls update and insert method of db mapper class respectively. Hence the different methods. (or) Am I missing anything?, Label: 1\n",
      "Processing row 4548 - Data Type: train, Message: > Do you get chance to test this? Is it actually work?\n",
      "\n",
      "Yes. Please refer https://github.com/apache/submarine/pull/299#issuecomment-644230611 for more details.\n",
      "\n",
      "> for example, this hardcoded a conda path to /opt/conda/envs/env/bin. And i'm not sure if write something to `~/.bashrc` is portable enough or not. I'd like to hear thoughts from @sunilgovind.\n",
      "\n",
      "Had come across mutliple ways while working on it and finally used the approach described here - \n",
      "https://medium.com/@chadlagore/conda-environments-with-docker-82cdc9d25754\n",
      "\n",
      "But, yes, we can improve further.\n",
      "\n",
      "> Another thing is, this assumes conda is part of Docker image, what if the Conda is not there, and if that happens, how we can give useful information to users if conda is not installed.\n",
      "\n",
      "Yes, even used the examples/test cases with \"continuumio/anaconda3\" as dockerImage. This question kind of answer my question mentioned in https://github.com/apache/submarine/pull/299#issuecomment-648614756 ? In this case, users will need to build a new image containing both the stuff?\n",
      "\n",
      "Will think about doing conda existence check..\n",
      "\n",
      "> Also, I think we need to check minimum (or maybe maximum) version of conda\n",
      "\n",
      "Why? Can you explain? Do we need to inform users in case version is not as expected?, Label: 1\n",
      "Processing row 4549 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4550 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4551 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4552 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4553 - Data Type: train, Message: @woodcutter-eric It will return the `err`, which one can maybe see the error message in the console?, Label: 1\n",
      "Processing row 4554 - Data Type: val, Message: Are there any recommended solutions?, Label: 1\n",
      "Processing row 4555 - Data Type: train, Message: But different models may have the same tag, right?, Label: 1\n",
      "Processing row 4556 - Data Type: train, Message: Thank you for the feedback.\n",
      "I didn't notice that this document is under the version-0.7.0 directory!, Label: 0\n",
      "Processing row 4557 - Data Type: train, Message: Should we remain `protobuf>=3.9.2,<3.20` or relax the version constraint (e.g. `protobuf>=3.9.2`) for future Tensorflow patches?, Label: 1\n",
      "Processing row 4558 - Data Type: train, Message: @cdmikechen kind doesn't show the problem in sonarcloud., Label: 0\n",
      "Processing row 4559 - Data Type: train, Message: Removing of this condition is safe. Moreover, this check is useless, because, any collection implements interface Iterable, and if object is Collection, then previous condition `(object instanceof Iterable<?>)` is true.\n",
      ", Label: 0\n",
      "Processing row 4560 - Data Type: train, Message: @garydgregory Are you referring to the p tag?\n",
      "I thought it was a convention because there are p tags in comments of other methods.\n",
      "Do you want to commit and delete other p tags?, Label: 1\n",
      "Processing row 4561 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 4562 - Data Type: val, Message: Fixed in multiple locations., Label: 0\n",
      "Processing row 4563 - Data Type: train, Message: Changed, Label: 0\n",
      "Processing row 4564 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 4565 - Data Type: train, Message: reversed , Label: 0\n",
      "Processing row 4566 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4567 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4568 - Data Type: train, Message: The BloomFilter constructor that  takes a Hasher effectively does the same thing: creates the container and populates it.  Should that also be removed?  Perhaps a Jira ticket should be opened for that change., Label: 1\n",
      "Processing row 4569 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4570 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4571 - Data Type: val, Message: Done/, Label: 0\n",
      "Processing row 4572 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4573 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4574 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4575 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4576 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4577 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4578 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4579 - Data Type: train, Message: fixed., Label: 0\n",
      "Processing row 4580 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4581 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4582 - Data Type: val, Message: After thinking about it for a bit, it was pointless.  Removed and replaced with a much simpler explanation., Label: 0\n",
      "Processing row 4583 - Data Type: train, Message: @kinow, unfortunately the javadoc for commons-collection 3.1 is not available on https://commons.apache.org/proper/commons-collections/javadocs/. Should I use links to the 3.2.2 ?, Label: 1\n",
      "Processing row 4584 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4585 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4586 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4587 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4588 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4589 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4590 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 4591 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 4592 - Data Type: val, Message: removed, Label: 0\n",
      "Processing row 4593 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 4594 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 4595 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4596 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 4597 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 4598 - Data Type: val, Message: Modified to specify exact upper limit, Label: 0\n",
      "Processing row 4599 - Data Type: train, Message: Looks like another failure in a part of the code I didn't touch?, Label: 1\n",
      "Processing row 4600 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4601 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4602 - Data Type: val, Message: I was also unsure. Not sure if RegionInstallationSupport is better but if you prefer it that is fine for me., Label: 1\n",
      "Processing row 4603 - Data Type: train, Message: I will try to avoid it. Sometimes I tend to press Ctrl-Shift-O :-), Label: 0\n",
      "Processing row 4604 - Data Type: train, Message: Correct., Label: 0\n",
      "Processing row 4605 - Data Type: train, Message: Unfortunately that doesn't solve the problem I'm having.  That same exception in v4.1.2 would have been turned into a warning at https://github.com/apache/karaf/pull/708/files#diff-0a5a9e3c3d44c1b639a942a084b31627L676 and not re-thrown.  I'm really trying to get back to that behaviour., Label: 0\n",
      "Processing row 4606 - Data Type: val, Message: Yeah, whether the warning happens or not, I need the \"Is a directory\" IOException to not show up outside of this method.   Previously the exception would be thrown on opening the FileInputStream, so the exception would get caught at line 674 and the method would return null.  Now (after converting to NIO) the exception is thrown when the stream is read from, so it is thrown on line 682 and is never caught.  That's why I'm adding the catch block where I am and returning null.\n",
      "I hope that's more clear?, Label: 0\n",
      "Processing row 4607 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4608 - Data Type: train, Message: This change is unrelated with the bug. I noticed it when writing the unit tests. I wasn't expecting the deleted bundle to remain in the in memory wiring map. If it was intentional I can remove it from the commit., Label: 0\n",
      "Processing row 4609 - Data Type: val, Message: I put version 11 also supported by Karaf. If you consider first there was version 8!, Label: 0\n",
      "Processing row 4610 - Data Type: train, Message: Unfortunately the 8-jre alpine version for ARM does not work well on ARM devices because it uses OpenJDK Zero. Of version 11 I only found this image which also works on ARM devices. Since the original dockerfile referred to OpenJDK I did not take into consideration other images such as adoptopenjdk ones., Label: 0\n",
      "Processing row 4611 - Data Type: train, Message: Could this image be used adoptopenjdk: 11-jre-hotspot-bionic? I saw that it also includes ARM architectures and the image is up to date. What are you saying? Could I try this one?, Label: 1\n",
      "Processing row 4612 - Data Type: train, Message: I have simplified the conditions.\n",
      "Wouldn't really be comfortable adding integration tests, being this my first contribution to the project., Label: 0\n",
      "Processing row 4613 - Data Type: train, Message: I agree that it can be misleading. What about \"The maven feature is an optional...\"?, Label: 1\n",
      "Processing row 4614 - Data Type: train, Message: I'm happy for you to update it :+1:  Is there a tar option in JDK? There is `java.util.zip.GZIPOutputStream` and `java.util.zip.ZipOutputStream` but I don't know anything native for tarballs?, Label: 1\n",
      "Processing row 4615 - Data Type: val, Message: I removed `commons-compress` dependency and just left the zip option. Sadly maintaining file permissions (e.g. 0755 in bin/karaf) does not seem to work. Seems to be a bug/limitation in JDK:\n",
      "https://bugs.openjdk.org/browse/JDK-6194856\n",
      "https://stackoverflow.com/questions/10699334/change-permission-of-a-zipentry\n",
      ", Label: 0\n",
      "Processing row 4616 - Data Type: train, Message: Might want to keep `karaf.history` filename for the root instance for retrocompatibility? If so there needs to be a condition here., Label: 1\n",
      "Processing row 4617 - Data Type: train, Message: Done, it will stay `karaf.history` now!, Label: 0\n",
      "Processing row 4618 - Data Type: train, Message: Oh, misunderstood. OpenJDK is JDK provider. Background: upgrade from java11 to java17 created an issue with camel-ldap -component in karaf container. Found out that com.sun.jndi.ldap was not exported by default., Label: 0\n",
      "Processing row 4619 - Data Type: train, Message: I think I fixed this with the latest push but let me know if the style is still not right., Label: 0\n",
      "Processing row 4620 - Data Type: train, Message: ```\n",
      "from twitter.common.log.options import LogOptions\n",
      "```\n",
      "I'm sorry I can not use this well.\n",
      "Can you give me a hint of what to do?, Label: 1\n",
      "Processing row 4621 - Data Type: val, Message: OK, Label: 0\n",
      "Processing row 4622 - Data Type: train, Message: > @sunOnly Why does DBCP plugin still keep this?\n",
      "\n",
      "The local test does not take effect. See if there is a better entry point, Label: 0\n",
      "Processing row 4623 - Data Type: train, Message: We can wait for the Dubbo team...\n",
      "I write this from my understanding to the scope of `Rpc*Context` and `RpcInvocation`. \n",
      " The `RpcServiceContext#isConsumerSide()` implements like:\n",
      "```java\n",
      "public boolean isConsumerSide() {\n",
      "        return this.getUrl().getSide(\"provider\").equals(\"consumer\");\n",
      "}\n",
      "```, Label: 0\n",
      "Processing row 4624 - Data Type: train, Message: I don't know why here[https://github.com/apache/skywalking-java/pull/73#issuecomment-987712730](url) says it fails as Consumer not invoking `MonitorFilter`. As I see, logically, the Consumer did not use `MonitorFilter` and it uses `MonitorClusterFilter`, but from our class bytes perspective, both class bytes are defined in `MonitorFilter#invoke()`, we just need to enhance it once. Am I in the right way?, Label: 1\n",
      "Processing row 4625 - Data Type: train, Message: Agree, Label: 0\n",
      "Processing row 4626 - Data Type: train, Message: I cannot find adoptium/openjdk8 in hub.docker.com, Label: 0\n",
      "Processing row 4627 - Data Type: train, Message: > According to [apache/skywalking-booster-ui#311 (comment)](https://github.com/apache/skywalking-booster-ui/pull/311#issuecomment-1680548512), this should be renamed as `nacos-client`.\n",
      "\n",
      "shall i add nacos server component ?, Label: 1\n",
      "Processing row 4628 - Data Type: train, Message: @lujiajing1126 Can you provide the memory analysis data of these two caching ways?, Label: 1\n",
      "Processing row 4629 - Data Type: train, Message: Does that mean that plugins, profiles etc defined in flink-parent are autmatically enabled here also? If that is the case that might make our life more difficult in the long run\n",
      "\n",
      "Looking at the statefun project that also does not use the flink parent: https://github.com/apache/flink-statefun/blob/master/pom.xml\n",
      "\n",
      ", Label: 1\n",
      "Processing row 4630 - Data Type: train, Message: Good catch, fixed ðŸ‘ , Label: 0\n",
      "Processing row 4631 - Data Type: train, Message: We will still need a delay here as even after the pod is ready it still takes a bit for the REST server to listen at the port. This is how I currently see the job status check still hitting a timeout. BTW @gyfora job status checks blocking the operator threads isn't so nice! , Label: 0\n",
      "Processing row 4632 - Data Type: train, Message: The annotation does not seem to change anything wrt the original error. There is a separate reschedule interval for this condition, which absent of more sophisticated readiness check I have set to 5s for now - that seems to avoids the timeout exception. , Label: 0\n",
      "Processing row 4633 - Data Type: train, Message: It's possible to reconstruct the config like this:\n",
      "```\n",
      "        FlinkControllerConfig config = new FlinkControllerConfig(this);\n",
      "        Set<String> namespaces = config.getNamespaces();\n",
      "```\n",
      "But that should not be necessary. @gyfora maybe?, Label: 1\n",
      "Processing row 4634 - Data Type: train, Message: Hi @gyfora thanks for sharing this point and I think about it as well and I totally agree that there is some error handle missing here.\n",
      "I discuss it a little in the [jira](https://issues.apache.org/jira/browse/FLINK-26178). I think using the job state enum should be reasonable as this state itself is an enum. I believe the key is [FLINK-26139](https://issues.apache.org/jira/browse/FLINK-26139) has not been resolved properly which makes the error handle in this part is misleading. I would spend some time on FLINK-26139, hoping to propose a state machine to describe the job state transition later.\n",
      "\n",
      "This PR seems to be done a little early. We may finish it after we resolve FLINK-26139. What's your advice?, Label: 1\n",
      "Processing row 4635 - Data Type: train, Message: removed the extra comments., Label: 0\n",
      "Processing row 4636 - Data Type: train, Message: renamed, Label: 0\n",
      "Processing row 4637 - Data Type: train, Message: Yes, But the `default` branch is forced. So I throw an exception there., Label: 0\n",
      "Processing row 4638 - Data Type: train, Message: Fixed now., Label: 0\n",
      "Processing row 4639 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4640 - Data Type: val, Message: The IDE complains this , Label: 0\n",
      "Processing row 4641 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4642 - Data Type: train, Message: The `observeJmDeployment()` method will output log WARN msg when the rest service is not working. \n",
      "Adding it here seems to be redundant?, Label: 1\n",
      "Processing row 4643 - Data Type: val, Message: `getWebInterfaceURL` is neat but one drawback of `clusterClient#getWebInterfaceURL` is that it only returns the current web url(i.e. address of the leader of jm) but does not guarantee the JM can actually work. In `isJobManagerPortReady`, we currently have already used `getWebInterfaceURL` and will 'telnet' the port in the url. In the jira, we think it may not be enough and that's why I finally choose the `listJob` call., Label: 0\n",
      "Processing row 4644 - Data Type: train, Message: You are right, they are unrelated. You can check the commit history. It is a hotfix used for helping debug the github CI problem. Yang and I think it may be useful for our further development so I leave it here. Do you have any suggestion?, Label: 1\n",
      "Processing row 4645 - Data Type: val, Message: I have updated for above changes and enhanced current tests to cover the case when falling to check the jm deployment. \n",
      "One thing I am not so sure is that I reuse the `OPERATOR_OBSERVER_PROGRESS_CHECK_INTERVAL_IN_SEC` for the timeout of `clusterClient.listJobs()`. AFAIK, the rest call is also a kind of 'progress'. Is there any strong point I ignore to introduce a new config for the rest call timeout?\n",
      " cc @gyfora @wangyang0918 @tweise \n",
      ", Label: 1\n",
      "Processing row 4646 - Data Type: train, Message: I wonder do we need to set the `JobStatus#state` to `SUSPEND` here? One is the observed state, one is the desired state. Maybe we could just clear the state and let the next reconcile to sync the state by observer? , Label: 1\n",
      "Processing row 4647 - Data Type: val, Message: Get it, Label: 0\n",
      "Processing row 4648 - Data Type: val, Message: > but why would anything happen anyways\n",
      "\n",
      "I think the `restartNonce` have the semantic of bring the job to a `start/running` status somehow? If not go with this check it will work like ask job to restart once, but it still suspend :).\n",
      "\n",
      "> we could discuss whether we should allow spec changes in suspended state\n",
      "\n",
      "If JobState changes from suspended to suspended, with other spec changes, It will not take effect, I think it will not bring bad impact to allow the change. The problem of the `restartNonce` field change in suspended state is only the problem of the semantic, as I said first., Label: 1\n",
      "Processing row 4649 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4650 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4651 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 4652 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4653 - Data Type: val, Message: I'm also torn with it, with some other method have already use this pattern, so I also add here. But I also think it's fussy to add `final` to each local variable. \n",
      "IMO, the local final variable should introduce in some performance critical path, so I prefer to drop them in these method., Label: 0\n",
      "Processing row 4654 - Data Type: train, Message: hmmm, I made a silly mistake here :(\n",
      "After fixing the Mode bug, I was wondering if there was any other spec needed to be changed to last reconciled spec in Observer. When testing with `DeploymentSpec spec = deployment.get().getSpec();` in `observeJmDeployment`, I somehow broke my previous codes and committed the wrong codes.\n",
      "It should be fixed by now., Label: 0\n",
      "Processing row 4655 - Data Type: val, Message: @gyfora, this check refers to the logic in `CheckpointConfig#setCheckpointInterval` which compares to the `MINIMAL_CHECKPOINT_TIME`, therefore this check is necessary.\n",
      "@wangyang0918 WDYT?, Label: 0\n",
      "Processing row 4656 - Data Type: train, Message: Good point, fixed, Label: 0\n",
      "Processing row 4657 - Data Type: train, Message: thanks @wangyang0918 bit weird, it worked on my arm64 arch laptop, changed it to the debug version in the example, anyway, to be able to attach a terminal to it. PTAL, Label: 0\n",
      "Processing row 4658 - Data Type: train, Message: bumped the fluent bit version to address the issue appears on latest macs \n",
      "\n",
      "```\n",
      "no matching manifest for linux/arm64/v8 in the manifest list entries.\n",
      "```, Label: 0\n",
      "Processing row 4659 - Data Type: train, Message: @bgeng777, I don't think `spec.getFlinkConfiguration()` should be replaced with `effectiveConfig`. The validation of Flink config validates the user-defined configuration. Validating the `effectiveConfig` which merges the default config and user-defined config is unnecessary., Label: 0\n",
      "Processing row 4660 - Data Type: train, Message: Does the option change have to be copy to `configuration.md` manually ? , Label: 1\n",
      "Processing row 4661 - Data Type: train, Message: I also think about it, The good thing is that we can do no special thing for the local filesystem when `fetch` and `delete` (If no copy, we may can't delete after submit too). Do you think we need to handle the difference now ?, Label: 1\n",
      "Processing row 4662 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4663 - Data Type: train, Message: Good point, fixed, Label: 0\n",
      "Processing row 4664 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4665 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4666 - Data Type: train, Message: I guess the logic would be more straight forward if this config in sessionJob directly overrides the parent config. \n",
      "\n",
      "If we do the merging work. Then a user will need to check two CRs instead of one to determine what are the actual headers that is applied during jar fetching during debugging. It could be a little bit confusing., Label: 0\n",
      "Processing row 4667 - Data Type: train, Message: For some reason the deployment was corrupted, and could never finish starting, and it is impossible to delete it, impossible.\n",
      "\n",
      "This happened to me several times, in different namespaces., Label: 0\n",
      "Processing row 4668 - Data Type: val, Message: The method would be enormous. It seemed like a good practice to me to separate the behavior of deleting the cluster using the flink client and, on the other hand, deleting the kubernetes deployment. At first it is more complicated but then it becomes easier to read, Label: 0\n",
      "Processing row 4669 - Data Type: train, Message: Ok, Label: 0\n",
      "Processing row 4670 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 4671 - Data Type: train, Message: Good suggestion, I have pushed the commit, PTAL again, Label: 0\n",
      "Processing row 4672 - Data Type: train, Message: hah, thanks for remind. I did't notice that just now. , Label: 0\n",
      "Processing row 4673 - Data Type: train, Message: Replaced with generic parameters, Label: 0\n",
      "Processing row 4674 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4675 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4676 - Data Type: train, Message: @morhidi, the `Metrics` should be integrated in the `FlinkDeploymentController` and `FlinkSessionController`, like above `Controller`. Any misunderstanding?, Label: 1\n",
      "Processing row 4677 - Data Type: train, Message: @gyfora , config options like `kubernetes.operator.watched.namespaces`, `kubernetes.operator.dynamic.namespaces.enabled` include the default value in the description. Do I need to update these description of these options?, Label: 1\n",
      "Processing row 4678 - Data Type: train, Message: Corrected!, Label: 0\n",
      "Processing row 4679 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 4680 - Data Type: train, Message: `isEmpty` not found, using `isNullOrWhitespaceOnly` instead, Label: 0\n",
      "Processing row 4681 - Data Type: val, Message: @gyfora, IMO, the `TimeNanos` makes sense because this use the `clock.relativeTimeNanos` not the seconds. WDYT?, Label: 0\n",
      "Processing row 4682 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 4683 - Data Type: train, Message: Dropped the `ParameterizedTest` approach, Label: 0\n",
      "Processing row 4684 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4685 - Data Type: train, Message: I think there could be something wrong with the first deployment logic (or I don't understand it). But it would be better to deal with that outside of this PR., Label: 0\n",
      "Processing row 4686 - Data Type: train, Message: Added!, Label: 0\n",
      "Processing row 4687 - Data Type: train, Message: added\n",
      ", Label: 0\n",
      "Processing row 4688 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4689 - Data Type: train, Message: > Why can't we always mount the usrlib dir?\n",
      "\n",
      "Great question! Check the end of my PR description for more context. It turns out, when [StandaloneApplicationClusterEntryPoint](https://github.com/apache/flink/blob/40d50f177c8ac63057dea2c755173a0dc138ede5/flink-container/src/main/java/org/apache/flink/container/entrypoint/StandaloneApplicationClusterEntryPoint.java#L104) starts, it tries to find the `usrlib` folder. And if it's not null [it'll be used for loading the classes, not the system classpath](https://github.com/apache/flink/blob/40d50f177c8ac63057dea2c755173a0dc138ede5/flink-clients/src/main/java/org/apache/flink/client/program/DefaultPackagedProgramRetriever.java#L143-L147). So, we simply can't have a `usrlib` folder when we want to load classes from `/opt/flink/lib`.\n",
      "\n",
      "> What if PipelineOptions.CLASSPATHS points to a directory outside usrlib?\n",
      "\n",
      "Exactly. I don't know the context and all the use-cases, but in my mind `UserLibMountDecorator` shouldn't be part of the operator - let the user create/mount the right folder and place jars there. But deleting it in the context of this PR is a big change IMO, so added a check based on the comment on the `UserLibMountDecorator` class: `Mount the Flink User Lib directory to enable Flink to pick up a Jars defined in pipeline.classpaths.`. Which is think is misleading. WDYT?, Label: 0\n",
      "Processing row 4690 - Data Type: val, Message: Done, Label: 0\n",
      "Processing row 4691 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4692 - Data Type: train, Message: âœ… , Label: 0\n",
      "Processing row 4693 - Data Type: train, Message: Moved., Label: 0\n",
      "Processing row 4694 - Data Type: train, Message: That's a key-value store which is designed to store config info:\n",
      "```\n",
      "    /** Config information from running clusters. */\n",
      "    private Map<String, String> clusterInfo = new HashMap<>();\n",
      "```\n",
      "For example one key is `DashboardConfiguration.FIELD_NAME_FLINK_VERSION`.\n",
      "I can put it there but at the first glance it's not intended to store structures like this.\n",
      "Are we sure that we want to do that?\n",
      ", Label: 1\n",
      "Processing row 4695 - Data Type: train, Message: Good point, renamed to:\n",
      "```\n",
      "kubernetes.operator.job.health-check.enabled\n",
      "kubernetes.operator.job.health-check.restarts.window\n",
      "kubernetes.operator.job.health-check.restarts.threshold\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 4696 - Data Type: val, Message: Fixed., Label: 0\n",
      "Processing row 4697 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4698 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4699 - Data Type: train, Message: @morhidi Understand, I looked at using https://junit-pioneer.org/docs/environment-variables/ which has some nice capabilities to change system env vars, but noticed when running it I get `This extension uses reflection to mutate JDK-internal state, which is fragile` warnings when running in intellij. Do you think it would be ok to add a method to EnvUtils e.g. setEnvironment(Map env) and use this to override System env vars ? Or can you think of something better ?, Label: 1\n",
      "Processing row 4700 - Data Type: train, Message: Actually noticed there is a method in TestUtils, am I ok to use that ?, Label: 1\n",
      "Processing row 4701 - Data Type: train, Message: will do, Label: 1\n",
      "Processing row 4702 - Data Type: train, Message: Executing the mvn command locally verifies that it passes.\n",
      "\n",
      "`mvn clean install -Pgenerate-docs`\n",
      "\n",
      "<img width=\"1766\" alt=\"image\" src=\"https://user-images.githubusercontent.com/54518670/200539642-305f3458-950f-4f88-be5b-9e976fa4377b.png\">\n",
      "<img width=\"1191\" alt=\"image\" src=\"https://user-images.githubusercontent.com/54518670/200539773-be41dbbc-507c-4a20-a5a8-7e2cb944299e.png\">\n",
      ", Label: 0\n",
      "Processing row 4703 - Data Type: train, Message: Or, I turn off the PR and resubmit it again., Label: 0\n",
      "Processing row 4704 - Data Type: train, Message: > there should not be any more changed files after running\n",
      "> \n",
      "> ```\n",
      "> mvn clean install -Pgenerate-docs\n",
      "> ```\n",
      "\n",
      "This file has been changed.\n",
      "\n",
      "`docs/content/docs/custom-resource/reference.md`, Label: 0\n",
      "Processing row 4705 - Data Type: train, Message: Yes, You're right. \n",
      "\n",
      "Let me put it clearly, there are the following scenarios.\n",
      "1. Cancel the same job via cli more than 1 time-> Throws an error which is out of the scope of the operator. (IMO)\n",
      "2. Cancelled the job via cli and suspended the same job via operator -> No error.\n",
      "\n",
      ", Label: 0\n",
      "Processing row 4706 - Data Type: train, Message: @gyfora - The build pipeline is failing with the below error. At this place: https://github.com/apache/flink-kubernetes-operator/actions/runs/3574448062/jobs/6009735670. \n",
      "\n",
      "Could you please help me here? Not sure if re-triggering solves it. \n",
      "\n",
      "```\n",
      "flinkdeployment.flink.apache.org \"session-cluster-1\" deleted\n",
      "flinksessionjob.flink.apache.org \"flink-example-statemachine\" deleted\n",
      "persistentvolumeclaim \"session-cluster-1-pvc\" deleted\n",
      "ingressclass.networking.k8s.io \"nginx\" deleted\n",
      "No resources found\n",
      "Error: Process completed with exit code 1.\n",
      "```, Label: 1\n",
      "Processing row 4707 - Data Type: val, Message: It is thrown by `IllegalConfigurationException` - [JobManagerProcessUtils.java#L7](https://github.com/apache/flink/blob/5c3658aa06b79e8039043145560a1ad2bcce68b0/flink-runtime/src/main/java/org/apache/flink/runtime/jobmanager/JobManagerProcessUtils.java#L78)\n",
      "\n",
      "Full error message is very descriptive, example:\n",
      "\n",
      "```\n",
      "TaskManager memory configuration failed: Either required fine-grained memory \n",
      "(taskmanager.memory.task.heap.size and taskmanager.memory.managed.size), \n",
      "or Total Flink Memory size (Key: 'taskmanager.memory.flink.size' , default: null (fallback keys: [])), \n",
      "or Total Process Memory size (Key: 'taskmanager.memory.process.size' , \n",
      "default: null (fallback keys: [])) need to be configured explicitly.\n",
      "```, Label: 0\n",
      "Processing row 4708 - Data Type: train, Message: I hear you, how about this:\n",
      "```\n",
      "2023-01-25 13:16:04,184 o.a.f.k.o.u.EventCollector     [INFO ] >>> Event  | Info    | SCALINGREPORT   | Scaling vertices: Vertex ID 611fc81374e72d3d19e2d14196df735c | Parallelism 1 -> 2 | Processing capacity 100,00 -> 157,00 | Target data rate 110,00\n",
      "```\n",
      "vs\n",
      "\n",
      "```\n",
      "2023-01-25 13:16:04,274 o.a.f.k.o.u.EventCollector     [INFO ] >>> Event  | Info    | SCALINGREPORT   | Recommended parallelism change: Vertex ID b6844a4ed9bebdbbd33e4ebc1662745e | Parallelism 1 -> 2 | Processing capacity 100,00 -> 157,00 | Target data rate 110,00\n",
      "```, Label: 0\n",
      "Processing row 4709 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 4710 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 4711 - Data Type: val, Message: I moved it to `.Values.operatorPod.webhook.resources`, does it sound ok for you ?, Label: 1\n",
      "Processing row 4712 - Data Type: train, Message: For some reason the fabric8 crd gen includes all the fields from the `ResourceLifecycleState`, and this is why `terminal` and `description` also appear. This is not good I agree, maybe some annotation needed above those fields to ignore those by the crd generator. I can take a look at those tomorrow afternoon (CET). However, maybe that is not required to commit the automated generated yaml files, am I right?, Label: 1\n",
      "Processing row 4713 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4714 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4715 - Data Type: train, Message: I tried but the the `TestUtils.ValidatingResponseProvider` class requires the event to be returned at construction time, and I couldn't find a way to intercept the `createOrReplace` call inside `EventUtils.createOrUpdateEvent`, Label: 0\n",
      "Processing row 4716 - Data Type: train, Message: Agreed, I have updated the logic to remove from savepoint history/status even if cleanup is disabled. This ensures savepointHistory in CR is within maxCount and maxAge. The only difference is cleanup disabled will not send `disposeSavepoint` REST call to JM., Label: 0\n",
      "Processing row 4717 - Data Type: train, Message: I rely on the `lastStableSpec` to do the rollback.\n",
      "It is indeed the spec used to roll back to a working state.\n",
      "But once the job is rolled back I need to be able to detect changes to the current spec (the one which has lead to the rollback). As the job spec has not been updated we need to be able to compare it with a specific stored spec from which we will be able to do comparison and find changes\n",
      "I can't rely on the `lastReconcileSpec` or `lastStableSpec` as they are not align with the job spec.\n",
      "This is why I introduce this `lastRollbackSpec` which contains the job spec leading to failure., Label: 0\n",
      "Processing row 4718 - Data Type: train, Message: The lock is there to ensure correctness while checkpointing. What is being checkpointed? This is not stateful function, neither are the other operators., Label: 1\n",
      "Processing row 4719 - Data Type: train, Message: We can but it is not essential for this pipeline., Label: 0\n",
      "Processing row 4720 - Data Type: train, Message: > improvement1\n",
      "\n",
      "The improvement1 sounds make sense to me, and I need to improve the `SerializableState`. The current `deserialize` method needs to create a object first, and then call `object.deserialize(serializedResult)`. In general, the serialize is a separate object.\n",
      "\n",
      "I'm afraid whether it's too complex If we introduce 2 class for each state.\n",
      "\n",
      "> improvement2\n",
      "\n",
      "For improvement2, my concern is the serialized type is changed, and all old jobs cannot be compatible directly. \n",
      "\n",
      "The compatibility of `byte[]` must be stronger than String, but the benefits it brings are uncertain (because there may not be classes that can only be serialized into `byte[]` in the future).\n",
      "\n",
      "The negative impact is certain, and it will bring additional migration costs to historical users., Label: 0\n",
      "Processing row 4721 - Data Type: train, Message: Thanks for pointing it out.\n",
      "\n",
      "If the `applyParallelismOverrides` is expected here, we can call the related code here. The `applyParallelismOverrides` just calls the `stateStore.getParallelismOverrides(ctx)` and `scalingRealizer.realize(ctx, userOverrides);`, and `stateStore` and `scalingRealizer` can be reached here. \n",
      "\n",
      "I plan to extract the `org.apache.flink.autoscaler.JobAutoScalerImpl#applyParallelismOverrides` to a static method, WDYT?, Label: 0\n",
      "Processing row 4722 - Data Type: train, Message: Thanks @gyfora  for the quick review! The rest comments are addressed.\n",
      "\n",
      "> As we are bundling dependencies into a father and we are likely going to publish that to maven (right?) .\n",
      "\n",
      "During add the fat jar, I have a question: where do users to download this fat jar? In maven repo or dist?\n",
      "\n",
      "> We need to add a NOTICE file to list the bundled dependencies by license\n",
      "\n",
      "Sorry, I didn't do it before. Is the NOTICE file created by tools or manually? Is there any doc to explain it?, Label: 1\n",
      "Processing row 4723 - Data Type: train, Message: Lookup is performed by name and namespace. Update / Create uses the ConfigMap object which potentially involves version checks. That's how the code currently works. I didn't want to mess with the APIs to avoid introducing regressions., Label: 0\n",
      "Processing row 4724 - Data Type: train, Message: Sure. Take a look at https://github.com/apache/flink-kubernetes-operator/pull/710/commits/e6568d958a141e77be54af6c456212faa69869b8. Does that reflect what you had in mind?, Label: 1\n",
      "Processing row 4725 - Data Type: val, Message: Not sure I am missing something, but I thought only vertices which are scaled are entered into the scaling history. Since this is what we build our `targetParallelisms` based on (see `getTargetParallelismOfScaledVertices`) and iterate over  `targetParallelisms`, not the `actualParallelism`, I assumed this already being dealt with., Label: 1\n",
      "Processing row 4726 - Data Type: train, Message: Do you mean just store maxRestartTime per job instead of the startTime endTime pairs? \n",
      "1. How are we going to prevent an abnormally large timestamp that happened a month from \"locking\" the restart time forever?\n",
      "2. How about the idea of adding the exponential moving average we were discussing as a potential improvement?, Label: 1\n",
      "Processing row 4727 - Data Type: val, Message: https://github.com/apache/flink-kubernetes-operator/pull/711/commits/93ae804e1466fc75009ca10714a65ad984efbd14\n",
      ", Label: 0\n",
      "Processing row 4728 - Data Type: train, Message: I guess [this](https://github.com/apache/flink-kubernetes-operator/pull/711#issuecomment-1815381974) got buried in the notifications:\n",
      "```\n",
      "@gyfora me and Max briefly discussed offline and came to the conclusion that starting with\n",
      " evaluating the maximum restart time capped by the RESTART_TIME setting is probably \n",
      "good enough for the first step. It has the benefit of giving the most \"conservative\" \n",
      "evaluation and we can add the moving average after some baseline testing. What do you think?\n",
      "```, Label: 0\n",
      "Processing row 4729 - Data Type: train, Message: We need the custom css, because Helveticus Themes override the color of at least the Icon that switches to code view and Rainbow Stone does silly things to the outlines of the boxes, due to margins defined on all div containers. \n",
      "Those are the two changes I revered two, when I asked about the proper way to overwrite earlier in this PR., Label: 0\n",
      "Processing row 4730 - Data Type: train, Message: Hello UnnecessaryDotClass is a rule from codenarc, applying that the .class suffix is not needed in Groovy\n",
      "\n",
      "https://groovy-lang.org/style-guide.html#_classes_as_first_class_citizens, Label: 0\n",
      "Processing row 4731 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4732 - Data Type: val, Message: right sorry I should have done the same here !, Label: 0\n",
      "Processing row 4733 - Data Type: train, Message: well neither does the button currently trigger that method nor does the method actually return the original., Label: 0\n",
      "Processing row 4734 - Data Type: train, Message: Yeah I didn't think about the user can change the name.\n",
      "=> but where would you then find out what the original file name extension was in case of a document of type PPT/XLS/DOCX et cetera ? , Label: 1\n",
      "Processing row 4735 - Data Type: val, Message: Hiding vs disabling:\n",
      "https://ux.stackexchange.com/questions/107513/what-is-better-for-ux-hiding-or-disabling-irrelevant-buttons\n",
      "Quote:\n",
      "> I lean towards disabling unless there's a good reason to hide. If you hide a button that I'm looking for, then I'll waste time (and have to think) searching for it.\n",
      "\n",
      "https://www.theusabilitypeople.com/thought_leadership/disable-hide-or-grey-out\n",
      "Quote:\n",
      "> 1) When there is no way that an end user will EVER have access to a feature or function, do not show it to them! (This is mostly for system admin features/functions that most end users will not need: e.g. Add/Remove users, etc.)\n",
      "\n",
      "I think those quotes sum it up quite well for me. I know we also changed exactly this button and section like a 100 times before.\n",
      "\n",
      "But there is a qualified yes and no to hiding vs disabling and I think above quotes sum it up pretty well.\n",
      "\n",
      "And in case of above button I think, same as on the whiteboard I would assume the better UX would be to disable it rather the hide true|false.\n",
      "\n",
      "Happy to be convinced with other opinions though., Label: 0\n",
      "Processing row 4736 - Data Type: train, Message: which room menu items are you referring to ?\n",
      "That might be a bit of a different problem I think. I think the room menu items users are complaining cause it is around permissions. Not contextual. \n",
      "Above button simply depends on if you click on a document or not in order to enable it. \n",
      "But _EVERY_ user can see the button (if they can see the FileTree). Its not a permission thing. \n",
      "Which I think would be a slightly different use-case again. Cause if you remove permissions from a user to do sth, I would argue probably you should also remove the UI elements, cause that is indeed confusing to disable them, cause the user thinks he just need to click the right icon to enable it., Label: 1\n",
      "Processing row 4737 - Data Type: val, Message: I think previously those numbers are just floating on the bottom without any explanation other than tool tip. \n",
      "\n",
      "I think the entire concept of \"home\" drive vs \"public\" drive, it just doesn't make much sense anymore. There are now 6 folders by default:\n",
      "![image](https://user-images.githubusercontent.com/5152064/79625676-a7d77880-817e-11ea-9c2e-311fb4d54ea0.png)\n",
      "\n",
      "=> So how would any user understand what those numbers are adding up now ?\n",
      "Us/we understand it cause historically in OpenMeetings that is how we designed some of those drives and store them internally. \n",
      "\n",
      "But now: What folder belongs to home drive and what to public drive ?, Label: 1\n",
      "Processing row 4738 - Data Type: train, Message: my tab size in eclipse was wrong yeah, Label: 0\n",
      "Processing row 4739 - Data Type: val, Message: you've got tab size 2 whitespaces I assume ?, Label: 1\n",
      "Processing row 4740 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4741 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4742 - Data Type: train, Message: Sure, added. Is it big enough?, Label: 1\n",
      "Processing row 4743 - Data Type: train, Message: And its actually just 2 places. Since we are creating dialog in 3 different ways:\n",
      "1) DIV.dialog (jquery-ui dialog)\n",
      "2) div.draggable (making a DIV draggable)\n",
      "3) DIV.modal (Bootstap way)\n",
      "\n",
      "And each of those has its own way of fixing the issue., Label: 0\n",
      "Processing row 4744 - Data Type: train, Message: And div.dialog actually is only 2 places in the code left., Label: 0\n",
      "Processing row 4745 - Data Type: train, Message: I can, I just had to think for almost 15min around if those 3 use-cases:\n",
      "\n",
      "1. It should return false (not stopBroadCast) in case MediaType.AUDIO == mediaType and hasVideo == true\n",
      "2. It should return true (do stopBroadCast)in case MediaType.AUDIO == mediaType and hasVideo == false\n",
      "3. It should return true (do stopBroadCast) in case MediaType.AUDIO != mediaType\n",
      "\n",
      "are correct with this statement. I think this double negation with ||, I don't think a lot of people find it easy to translate it actual behaviour.\n",
      ", Label: 0\n",
      "Processing row 4746 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4747 - Data Type: train, Message: its not a constructor?, Label: 1\n",
      "Processing row 4748 - Data Type: val, Message: There is a try/catch block. That should log sth.\n",
      "https://www.overops.com/blog/swallowed-exceptions-the-silent-killer-of-java-applications/, Label: 0\n",
      "Processing row 4749 - Data Type: train, Message: shouldn't it log something if there is an exception ?, Label: 1\n",
      "Processing row 4750 - Data Type: train, Message: silent exception / swallowing exceptions is not good. For various reasons:\n",
      "https://www.overops.com/blog/swallowed-exceptions-the-silent-killer-of-java-applications/\n",
      "\n",
      "I think you should at least create a log if you catch an exception. , Label: 0\n",
      "Processing row 4751 - Data Type: train, Message: ```\n",
      "} catch (URISyntaxException e) {\n",
      "        return getWebappPath(DEFAULT_BASE_URL);\n",
      "    }\n",
      "```\n",
      "Will not compile. It will throw an exception in the catch block. Which will just not compile. I also don't see why you need to split this into 2 methods.\n",
      "\n",
      "> your current code will return https://localhost:5443/openmeetings\n",
      "\n",
      "No it won't. It says \".getPath()\" so it won't. DEFAULT_BASE_URL is actually the same it will use by default. \n",
      "\n",
      "There is no different between our alternatives. Except your alternative splits it into 2 methods. For no obvious reason. \n",
      ", Label: 0\n",
      "Processing row 4752 - Data Type: train, Message: why are they redundant? They are required to be packaged up in the .war file. How would they be linked into the war file of the -web project if they are not defined as dependencies?, Label: 1\n",
      "Processing row 4753 - Data Type: train, Message: Hi Mr @solomax , the mail clients ignore the css style in the head and so the design is not there anymore, we have the mail by default.\n",
      "Do you have any recommendations?, Label: 1\n",
      "Processing row 4754 - Data Type: val, Message: Hi @solomax, can we have a build of this latest change (to deploy on vm/or any server) and test it to make sure everything is ok with the mail?\n",
      ", Label: 1\n",
      "Processing row 4755 - Data Type: train, Message: > We can let all new added Exceptions inherit from IOException, so we needn't change here.\n",
      "\n",
      "Nice suggestion!, Label: 0\n",
      "Processing row 4756 - Data Type: train, Message: How about implementing this comment in another refactor PR(#1387)?, Label: 1\n",
      "Processing row 4757 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4758 - Data Type: train, Message: I will merge this first, then I will find some unhealthy workers and then provide a fire flame about the cost during trim action. WDYT?, Label: 0\n",
      "Processing row 4759 - Data Type: train, Message: Turning package private methods to public., Label: 0\n",
      "Processing row 4760 - Data Type: train, Message: `shuffleClient` is a singleton. It can not close., Label: 0\n",
      "Processing row 4761 - Data Type: val, Message: Celeborn has server dependencies conflicts. I'll remove integration test for MR., Label: 0\n",
      "Processing row 4762 - Data Type: train, Message: OK, Label: 0\n",
      "Processing row 4763 - Data Type: train, Message: can you help to explain what kind of message needs to be added to TransportMessage#getParsedPayload?, Label: 1\n",
      "Processing row 4764 - Data Type: train, Message: no, this is a bug, it is fixed in latest commit, Label: 0\n",
      "Processing row 4765 - Data Type: train, Message: no, this is a bug, it is fixed in latest commit, Label: 0\n",
      "Processing row 4766 - Data Type: val, Message: I feel kinda sad.\n",
      "Anyway I reverted as you suggested !, Label: 0\n",
      "Processing row 4767 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4768 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4769 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4770 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4771 - Data Type: train, Message: Done!, Label: 0\n",
      "Processing row 4772 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4773 - Data Type: train, Message: The method without delta its deprecated. `Deprecated\n",
      "Use assertEquals(double expected, double actual, double delta) instead` , Label: 0\n",
      "Processing row 4774 - Data Type: val, Message: I used html tags because I saw the other Javadoc in this class are using it.  Do you want me to change them as well?, Label: 1\n",
      "Processing row 4775 - Data Type: train, Message: I have used ListUtils.isEqualList for comparing the lists now(requires extra dependency). Since we are already overriding equals everywhere for this story.\n",
      "Is this fine?Or you want me to sort the list for which we have to write the comparator function and then do list1.equals(list2)., Label: 1\n",
      "Processing row 4776 - Data Type: train, Message: Can you show me an example with the consul variables please?\n",
      "BTW is it save to put this and the cretaConenction in the GeoJvmInit ?\n",
      "\n",
      "This  method  just has to be called  ones during \"start\"\n",
      "So it can be used by all processors., Label: 1\n",
      "Processing row 4777 - Data Type: train, Message: Oh, my bad, I forgot updating the file names. Shall I rename the files and update the PR with the changes ?, Label: 1\n",
      "Processing row 4778 - Data Type: train, Message: Just to clarify @bossenti, we need to make sure the reference to component in `consul-configs.component.html` is not updated with `sp` prefix right? , Label: 1\n",
      "Processing row 4779 - Data Type: train, Message: I have updated the found usages to the selector to the new name. Shall I update the pr?, Label: 1\n",
      "Processing row 4780 - Data Type: train, Message: @tenthe You mean here?\n",
      "https://github.com/apache/streampipes/blob/dev/pom.xml ?\n",
      "\n",
      "What is the difference between these two pom files?\n",
      "The change should look something like:\n",
      "\n",
      "```\n",
      "...\n",
      "<jts.version>1.19.0</jts.version>\n",
      "...\n",
      "\n",
      "<dependency>\n",
      "  <groupId>org.locationtech.jts<</groupId>\n",
      "  <artifactId>jts-core</artifactId>\n",
      "  <version>${jts.version}</version>\n",
      "</dependency>\n",
      "```\n",
      "\n",
      "Should I do it for these entries?\n",
      "\n",
      "- jts\n",
      "- postgresql  -> pretty sure that this entry already exist sin the parent pom\n",
      "- sis\n",
      "- com.squareup.okhttp\n",
      "\n",
      "I did not add \n",
      "\n",
      "```\n",
      "        <dependency>\n",
      "            <groupId>com.squareup.okhttp3</groupId>\n",
      "            <artifactId>okhttp</artifactId>\n",
      "            <version>3.13.1</version>\n",
      "        </dependency>\n",
      "```\n",
      "\n",
      "\n",
      "The entry in the geo.jvm pom should also be changed to following entry?\n",
      "\n",
      "```\n",
      "<dependency>\n",
      "  <groupId>org.locationtech.jts<</groupId>\n",
      "  <artifactId>jts-core</artifactId>\n",
      "  <version>${jts.version}</version>\n",
      "</dependency>\n",
      "```, Label: 1\n",
      "Processing row 4781 - Data Type: train, Message: The parent pom would also need new code format process in an extra commit!\n",
      "Did not want to add this here as well\n",
      ", Label: 0\n",
      "Processing row 4782 - Data Type: train, Message: I have tried removing it. Still getting the same error. \n",
      "I have come across a quick fix in Intellij IDEA.\n",
      "\n",
      "![image](https://user-images.githubusercontent.com/56036364/211213665-f6367abf-4202-449b-9196-88054e5aa5ee.png)\n",
      "\n",
      "Replace with object destructuring:\n",
      "\n",
      "```\n",
      "if (this.property instanceof EventPropertyList) {\n",
      "    // @ts-ignore\n",
      "    ({runtimeType: this.property.eventProperty.runtimeType} = (\n",
      "        this.cachedProperty as EventPropertyList\n",
      "    ).eventProperty);\n",
      "}\n",
      "```\n",
      "\n",
      "Replace with index access:\n",
      "\n",
      "```\n",
      "if (this.property instanceof EventPropertyList) {\n",
      "    // @ts-ignore\n",
      "    this.property.eventProperty.runtimeType = (\n",
      "        this.cachedProperty as EventPropertyList\n",
      "    ).eventProperty[\"runtimeType\"];\n",
      "}\n",
      "```\n",
      "\n",
      "Both above code snippets fix the error., Label: 0\n",
      "Processing row 4783 - Data Type: train, Message: is it correct to adapt this reference as well?, Label: 1\n",
      "Processing row 4784 - Data Type: train, Message: > why should I need to install osv-scanner when using ghcr.io/google/osv-scanner:latest?\n",
      "\n",
      "Actually i was talking about being inside of an container and doing all steps inside it.\n",
      "My bad, i get it wrong, Label: 0\n",
      "Processing row 4785 - Data Type: train, Message: when i run osv-scanner for scanning our repo initially in my local machine, these are the errors it was throwing:\n",
      "\n",
      "```\n",
      "Failed to resolve version of io.nats:jnats: property \"nats.version\" could not be foundScanned /home/ibergx00/Documents/oss/streampipes/streampipes-extensions/streampipes-sinks-brokers-jvm/pom.xml file and found 18 packages\n",
      "\n",
      "Failed to resolve version of com.google.inject:guice: property \"guice.version\" could not be foundScanned /home/ibergx00/Documents/oss/streampipes/streampipes-maven-plugin/pom.xml file and found 18 packages\n",
      "\n",
      "Failed to resolve version of org.apache.flink:flink-connector-kafka_2.11: property \"flink.version\" could not be found\n",
      "Failed to resolve version of org.apache.flink:flink-java: property \"flink.version\" could not be found\n",
      "Failed to resolve version of org.apache.flink:flink-streaming-java_2.11: property \"flink.version\" could not be found\n",
      "Failed to resolve version of org.apache.flink:flink-clients_2.11: property \"flink.version\" could not be found Scanned /home/ibergx00/Documents/oss/streampipes/streampipes-wrapper-flink/pom.xml file and found 9 packages\n",
      "\n",
      "```\n",
      "![failureosv](https://user-images.githubusercontent.com/102871719/230627553-d48a466b-f29a-477d-bb38-16449399e239.png)\n",
      "\n",
      "\n",
      "\n",
      "after i made those changes in `pom.xml`, error get resolved, Label: 0\n",
      "Processing row 4786 - Data Type: train, Message: Initially, I added a condition to check the running status of the current adapter to execute the request only for started/stopped adapters but I was unable to figure out how to access the `running` field. So I commented out that condition and this is what I was left with..., Label: 0\n",
      "Processing row 4787 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4788 - Data Type: train, Message: This is only meant as clean up. And thanks for the reminder as I just saw that there's such a class. However, [ResetManagement's reset method](https://github.com/apache/streampipes/blob/a6d219a4c8f97c23e328454ed2cdc5da9c87c33f/streampipes-rest/src/main/java/org/apache/streampipes/rest/ResetManagement.java#L58C11-L58C11) only deletes all adapters, data lakes, and visualizations, whereas for this test, a new user is created. If the user is not deleted, then later E2E tests under `userManagement` will fail. I guess the only solution here would be to only delete the user in the clean up. What do you think?, Label: 0\n",
      "Processing row 4789 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4790 - Data Type: train, Message: Separate commit or separate PR?, Label: 1\n",
      "Processing row 4791 - Data Type: train, Message: Don't we squash the PR when we merge it? otherwise i rebase it a bit to look cleaner :smile: , Label: 1\n",
      "Processing row 4792 - Data Type: train, Message: Ok It looks like the socket factory doesn't really work as we expect..., Label: 0\n",
      "Processing row 4793 - Data Type: train, Message: TODO: fix æž„å»ºé¡¹ç›®, Label: 0\n",
      "Processing row 4794 - Data Type: val, Message: A question here -- as it stands now, the USER_MESSAGE_CUSTOM_PAYLOAD_SERIALIZER_CLASS config option has no default value, so if not set, its value will be null. So I believe I'd have to first check for null and then check length on the trimmed string. I'm happy to do that, but I thought I'd check first in case that affects things ...\n",
      "\n",
      "Or should USER_MESSAGE_CUSTOM_PAYLOAD_SERIALIZER_CLASS have an empty string as the default value?, Label: 1\n",
      "Processing row 4795 - Data Type: train, Message: As it stands now, this method gets called from MessageTypeSerializer.Snapshot.writeSnapshot, for all types of message serializers, not just custom ones. For non-custom ones, a null is returned and this is the value that is written into the snapshot, after the MesssageFactoryType. So, the version 2 serialized format is always a MessageFactoryType value and then the custom payload serializer class name (string, which can be null), for all types of serializers.\n",
      "\n",
      "The writeSnapshot method could be changed to only call getCustomPayloadSerializerClassName in the event that the serializer is custom, and then to either 1) force a null serializer class name to be written to the snapshot or 2) skip the write of the serializer class name altogether in the non-custom case. This would make the read/writeSnapshot code and testing a bit more complicated but would definitely be doable, would one of those options be better?, Label: 1\n",
      "Processing row 4796 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4797 - Data Type: val, Message: This was changed to a pointer so that different statefunContext instances can reference the same sync.Mutex, as opposed to each having their own sync.Mutex. I thought this was necessary because derived statefunContext instances all reference the same response object, and the mutex is used to prevent concurrent modifications to the response object?, Label: 1\n",
      "Processing row 4798 - Data Type: train, Message: this formatting stuff is not right, let me fix that., Label: 0\n",
      "Processing row 4799 - Data Type: train, Message: The reason why I copied it instead of use the already existing copy of `XStreamUtils` is because of the different package: it is used by `ScenarioSimulationXMLPersistence` (that is in `drools` repo). I plan in another ticket to update `ScenarioSimulationXMLPersistence` to abstract over `XStream` instance and try to get rid of this clone but it takes time because I need to wait for a community release of 7 and then I can use it here.\n",
      "Btw I have removed all the methods I'm not using., Label: 0\n",
      "Processing row 4800 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4801 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4802 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4803 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4804 - Data Type: train, Message: no problem, we just need to decide a process id then I change it on the .bpmn2 and the README.\n",
      "I think we can use some more domain approach to show the value of kogito providing the endpoints based on this, myprocess seems not to give this domain approach, WDYT?\n",
      ", Label: 0\n",
      "Processing row 4805 - Data Type: train, Message: what about \"greetings\"?, Label: 1\n",
      "Processing row 4806 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4807 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4808 - Data Type: train, Message: Resolving since this code is outdated after moving the refactoring out of this PR., Label: 0\n",
      "Processing row 4809 - Data Type: train, Message: @danielezonca all the `*ConfigGenerator` classes (and a few others) don't implement the `useInjection` method but checks directly for `annotator != null`.\n",
      "I agree that we should make it consistent.\n",
      "\n",
      "Do you want me to change everywhere (or at least all the `*ConfigGenerator` classes)?, Label: 1\n",
      "Processing row 4810 - Data Type: val, Message: In my idea, this class is useful to make the code-generation code more readable, since a lot of common patterns in JavaParser are constantly repeated (e.g. creating a variable, a generic type definition, etc.).\n",
      "\n",
      "Here is a snippet in which some of those methods are used: https://github.com/kiegroup/kogito-runtimes/pull/412/files#diff-50ac5c7365b5b0682209e3695be81b51R105-R133\n",
      "\n",
      "I would like to keep this class. I agree with you on splitting it into several `*Utils` classes to avoid having a big dump of everything in the end, maybe moving all of them in a dedicated `utils` subpackage.\n",
      "\n",
      "I think I'm using all of these methods somehow, but not all the overloaded version, which could be cleaned up as well.\n",
      "\n",
      "In addition, there was already a `CodegenUtils` class in the `process` subpackage that was instead used all around in rules and decisions as well. I moved those methods in this class.\n",
      "\n",
      "Let me know what you think about my suggestions., Label: 0\n",
      "Processing row 4811 - Data Type: train, Message: removed. thanks!, Label: 0\n",
      "Processing row 4812 - Data Type: train, Message: I think it's a good idea, but then I this `ExecutionIdProvider` in my opinion should also contain the logic to extract the evaluation ID and be injected as part of the `DecisionConfig` object (maybe we could call it `ExecutionIdManager`).\n",
      "\n",
      "**Pros:**\n",
      "- It completely encapsulates the execution ID logic, so that it can be completely swapped if needed. The only \"contract\" would be that the ID is a `String` and is injected/extracted in/from the `DMNContext`.\n",
      "- Other components that need to deal with DMN execution IDs (e.g. [the tracing addon I'm implementing](https://issues.redhat.com/browse/FAI-85)) don't need to know how to extract it in order to read it, they will only rely on the provider object referenced in the `DecisionConfig`.\n",
      "\n",
      "What do you think? , Label: 0\n",
      "Processing row 4813 - Data Type: train, Message: asked in chat yesterday @tarilabs , Label: 0\n",
      "Processing row 4814 - Data Type: train, Message: Agree, Label: 0\n",
      "Processing row 4815 - Data Type: train, Message: that's unnecessary because there is no in `src/main/resources/archetype-resources/src/test` (this is the config of the _archetype_), Label: 0\n",
      "Processing row 4816 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4817 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4818 - Data Type: train, Message: removed the last line., Label: 0\n",
      "Processing row 4819 - Data Type: train, Message: well..I did the same in the tracing addon so I assume it is, Label: 0\n",
      "Processing row 4820 - Data Type: train, Message: will replace with an empty set as this is overridden anyway., Label: 0\n",
      "Processing row 4821 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4822 - Data Type: val, Message: Yeah, it's a good point, I had the same impression when reading the variable name _legacy_ but it seems that in reality, we're just wrapping this with a new public API. So no using `WorkflowProcessInstance` for what is needed for this PR seemed just too big of a change to me. Fact is that the core is still heavily dependent on this internal implementation. For instance, all event listeners rely on that. Perhpas is something we need to consider moving forward, if we need a big change for that before we get into 1.0 or we will simply continue with the current approach.\n",
      "@mswiderski did you had any plans around that?, Label: 0\n",
      "Processing row 4823 - Data Type: train, Message: Could you explain the reason for not liking it?, Label: 1\n",
      "Processing row 4824 - Data Type: val, Message: > Yes with child I meant child from a \"file system\" perspective.\n",
      "> Personally I prefer Quarkus (and OptaPlanner) setup that is a bit different:\n",
      "> \n",
      ">     * [build-parent](https://github.com/quarkusio/quarkus/blob/master/build-parent/pom.xml#L5-L9): inherit from root pom\n",
      "> \n",
      ">     * [root pom](https://github.com/quarkusio/quarkus/blob/master/pom.xml#L6-L10): it is inheriting from jboss-parent while we want to be agnostic so no parent here\n",
      "\n",
      "Do we really keep this not inheriting? I think this will be required for later, so I can bring this here too, thanks for pointing it up\n",
      "\n",
      "> \n",
      ">     * all other modules (i.e. [core](https://github.com/quarkusio/quarkus/blob/master/core/pom.xml#L5-L10)): inherit directly or not from `build-parent`\n",
      "> \n",
      "maybe they are not inheriting directly, but this is probably for a reason, it is not part of the build chain, just built as a leaf artifact in the repository?\n",
      "> \n",
      "> Btw no strong opinion and thanks for the PR because it is a step forward with project configuration :)\n",
      "\n",
      "That is fine to object with explaining why ;)\n",
      "\n",
      ", Label: 1\n",
      "Processing row 4825 - Data Type: val, Message: therefore, the simple lastIndexOf() check does not work, Label: 0\n",
      "Processing row 4826 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 4827 - Data Type: val, Message: I tried to propagate it but I didn't know up to where or where to really deal with it. Any advise?, Label: 1\n",
      "Processing row 4828 - Data Type: train, Message: This comment is not actually code, but displaying what the code below is generating, are we sure we want to remove it?, Label: 1\n",
      "Processing row 4829 - Data Type: train, Message: As you correctly detect, for SpringBoot we need to add lazy annotation to handlers passed as parameters in the constructor. \n",
      "SpringBoot has issues with circular dependencies when using construction injection. If, as happens in one of the examples, one of the beans injected into the handler, depends on the Process, SpringBoot wont start unless we include lazy annotation (this issue does not appear in Quarkus)\n",
      "I use a descriptive name, but we can use a more abstract one for the new method something as constructorParam. wdyt?, Label: 0\n",
      "Processing row 4830 - Data Type: train, Message: > weird why is that so? How was that solved before? I am pretty sure we were injecting a collection\n",
      "\n",
      "handler.getName\n",
      "\n",
      "\n",
      ", Label: 0\n",
      "Processing row 4831 - Data Type: train, Message: Regarding lazy, I removed from process constructor parameters and add to handler constructor. \n",
      "\n",
      "```\n",
      "\n",
      "    public GreetingTravellerService_greetTraveller_3_Handler() {\n",
      "        this.service = new org.acme.travels.services.GreetingTravellerService();\n",
      "    }\n",
      "\n",
      "    @org.springframework.beans.factory.annotation.Autowired()\n",
      "    @org.springframework.context.annotation.Lazy()\n",
      "    public GreetingTravellerService_greetTraveller_3_Handler(org.acme.travels.services.GreetingTravellerService service) {\n",
      "        this.service = service;\n",
      "    }\n",
      "```, Label: 0\n",
      "Processing row 4832 - Data Type: val, Message: :) , Label: 0\n",
      "Processing row 4833 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4834 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4835 - Data Type: train, Message: ok, Label: 0\n",
      "Processing row 4836 - Data Type: train, Message: indeed, it was already there, what was changed is the content. Anyway, since Jax-rs client is not going to be used, the change is not longer needed, so removing, Label: 0\n",
      "Processing row 4837 - Data Type: train, Message: This is not a public API. And even if it was, it is implementing a well known interface defined in jdk8, users familiar with utils.function package will probably expect an apply as public method in this case(but it does not matter since it is not public), Label: 0\n",
      "Processing row 4838 - Data Type: train, Message: FYI https://issues.redhat.com/browse/KOGITO-3448, Label: 0\n",
      "Processing row 4839 - Data Type: val, Message: open to suggestions :) `testIfinispanPersistence`? just really checking if the cache was created and contains the new process in it, as the error would be that it would silently use in memory and not Infinispan., Label: 0\n",
      "Processing row 4840 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 4841 - Data Type: train, Message: ![](https://media.giphy.com/media/3o8doT9BL7dgtolp7O/giphy.gif), Label: 0\n",
      "Processing row 4842 - Data Type: train, Message: @radtriste not sure I got the idea... you mean to be reused across our kogito-runtimes poms? like in the pluginManagement section?, Label: 1\n",
      "Processing row 4843 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4844 - Data Type: val, Message: You are probably right: we generate classes using templates it is easy to remove an annotation and breaks without an integration tests that test it. I don't know if we can enforce this at API/design level to be honest :thinking: \n",
      "Any idea/suggestion?, Label: 1\n",
      "Processing row 4845 - Data Type: train, Message: Sorry but I don't understand what do you mean. I just created a local variable instead of instantiate multiple times  `CDIDependencyInjectionAnnotator`.\n",
      "Can you please clarify your comment?\n",
      ", Label: 1\n",
      "Processing row 4846 - Data Type: train, Message: Yes I agree that it produce a lot of noise in the logs but my goal was to centralize it for now.\n",
      "I moved the logging to `generate()` method of `ApplicationGenerator` so that it is not a side effect inside `GeneratedFile` constructor and it will be easier to change in the future (i.e. dump to disk instead of log).\n",
      "Wdyt?, Label: 0\n",
      "Processing row 4847 - Data Type: train, Message: maybe it makes sense to add this as header parameter? In such case, which name?, Label: 1\n",
      "Processing row 4848 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 4849 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 4850 - Data Type: train, Message: I think in this way it prevents to download the jar ðŸ¤” , Label: 0\n",
      "Processing row 4851 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4852 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4853 - Data Type: train, Message: Yes for now we only have the \"platform\" extension `kogito-quarkus` with all the other components. We can also add a process specific extension with the same mechanism. The only problem of splitting processes is to also implement proper validation like if a process invokes a DMN and no dmn extension is provided., Label: 0\n",
      "Processing row 4854 - Data Type: val, Message: > I'd rather prefix extension attributes with `kogito` in order to:\n",
      "\n",
      "I know, and I thought about that. Hence `kogitopistate` sounds too awkward to me. @cristianonicolai any ideas? We need to stick to 20 characters long., Label: 1\n",
      "Processing row 4855 - Data Type: train, Message: done , Label: 0\n",
      "Processing row 4856 - Data Type: train, Message: well I prefer the mapping for readability but this is just a preference but it avoids null checks.. anyway this is minor IMO., Label: 0\n",
      "Processing row 4857 - Data Type: val, Message: yeah.. something like JTA... but don't know.. so why not just using JTA? anyway I think we should keep the scope of the PR just to delegate and open a JIRA to review the usage of UnitOfWork, wdyt @evacchi ?\n",
      "@cristianonicolai ^, Label: 1\n",
      "Processing row 4858 - Data Type: train, Message: My bad, I originally created this PR before that change so fixed now ðŸ‘ , Label: 0\n",
      "Processing row 4859 - Data Type: train, Message: Ah ok thanks for the clarification, I would prefer to keep the `7` explicit, even because this will probably be removed in the future together with Drools8.\n",
      "For example OptaPlanner already has both 7 and 8 versions so its \"latest\" artifacts should not be never included in this bom. That's why I think `kogito-kie-bom` name is more misleading, Label: 0\n",
      "Processing row 4860 - Data Type: train, Message: The `getNativeMavenCommand` is totally dependent on `getNativeBuilderImage` in fact as it is a global setting. and in fact `getNativeBuilderImage` would only be used here. But maybe we could directly check here `params.NATIVE_BUILDER_IMAGE` instead of having an external method ..., Label: 0\n",
      "Processing row 4861 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4862 - Data Type: val, Message: @ricardozanini I guess as this is used for creating projects, not a dependency, we can simply rename and state in the docs. No need to keep the old artifact id wdyt?, Label: 0\n",
      "Processing row 4863 - Data Type: train, Message: so not match the folder name or also rename it?, Label: 1\n",
      "Processing row 4864 - Data Type: train, Message: @mareknovotny could you follow up on this PR to revisit if we can remove/adjust the productized specific settings?, Label: 1\n",
      "Processing row 4865 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4866 - Data Type: train, Message: https://issues.redhat.com/browse/KOGITO-5815, Label: 0\n",
      "Processing row 4867 - Data Type: train, Message: +1 https://issues.redhat.com/browse/KOGITO-5807, Label: 0\n",
      "Processing row 4868 - Data Type: val, Message: \n",
      "The reason why DataContext extends Castable is because all DataContexts should be Castables, but not all Castables may be DataContexts.The idea would be that you may make any class Castable to a DataContext without being a DataContext, by implementing the `DefaultCastable` interface (or `Castable` itself).\n",
      "\n",
      "i.e. suppose that you want to provide a data object and make it possible to convert it into a DataContext; but you don't want it to be passed as a DataContext itself.\n",
      "\n",
      "For instance you may have an object with some extra fields that you don't want to be available to the evaluation. By implementing the `as` method yourself you'd be able to customize what fields should be made available.\n",
      "\n",
      "TBF I am not necessarily stronly opinionated about this one, I just wanted to keep interface tiny.\n",
      "I am not strongly opionionated about `as` being an instance method (it may be very constraining). Maybe we will turn that into into some sort of static method; in that case it may make sense for the two interfaces to be separate; e.g.:\n",
      "\n",
      "     Castable.of(myContext).as(...)\n",
      "\n",
      ", Label: 0\n",
      "Processing row 4869 - Data Type: train, Message: ok I see your point. The use case is to be able convert into a *subclass* of `DataContext`. Converting a `DataContext` into the same `DataContext` is a no-op just like `(Object) new Object()` is a no-op :-) \n",
      "\n",
      "the idea is you are always able to convert a `DataContext` into an arbitrary sub-type; e.g. a `MapDataContext` into a POJO that implements `DataContext`.\n",
      "\n",
      "e.g.\n",
      "\n",
      "```\n",
      "class Person implements DataContext, DefaultCastable { String name; }\n",
      "MapDataContext ctx = MapDataContext.create();\n",
      "ctx.set(\"name\", \"Paul\");\n",
      "Person p = ctx.as(Person.class);\n",
      "p.name // \"Paul\"\n",
      "```\n",
      "\n",
      "This is generalizing e.g. the DMNContext to a more \"generic\" interface that allows conversion of classes from map-like structures (JSON-izable if you will) into arbitrary typed POJOs \n",
      "\n",
      "So, both Person and MapDataContext are DataContexts, but they are not of the same type. You convert them at the use-site in order to use typed vs untyped API\n",
      "\n",
      "I will update the description above., Label: 0\n",
      "Processing row 4870 - Data Type: train, Message: added, Label: 0\n",
      "Processing row 4871 - Data Type: val, Message: Yeah, this is basically here for demo purposes... I think I should just remove it for the time being. It has no real use at the moment., Label: 0\n",
      "Processing row 4872 - Data Type: train, Message: So, `QuarkusPredictionIdsComponentRoot` ? BTW it's not extending the object it's meant to build, it's extending `PredictionIds` which is a factory for `PredictionId`s. The reason `Factory` is not in the name is to allow to write:\n",
      "\n",
      "```\n",
      "appRoot.get(PredictionIds.class).get(modelName)\n",
      "```\n",
      "\n",
      "instead of \n",
      "\n",
      "```\n",
      "appRoot.get(PredictionIdFactory.class).get(modelName)\n",
      "```\n",
      "\n",
      "so it's just for \"esthetic\" reasons of the fluent API\n",
      ", Label: 0\n",
      "Processing row 4873 - Data Type: train, Message: so would `QuarkusPredictionIdsComponentRoot` work?, Label: 1\n",
      "Processing row 4874 - Data Type: train, Message: great, `QuarkusPredictionsIds` it is!, Label: 0\n",
      "Processing row 4875 - Data Type: train, Message: good question, Processes were the first thing I wrote, and then I adopted a different pattern everywhere else; so instead, I am removing the nested `Factory` from processes and keeping this as is., Label: 0\n",
      "Processing row 4876 - Data Type: train, Message: Thanks for the detailed explanation :pray: , Label: 0\n",
      "Processing row 4877 - Data Type: train, Message: I consider an empty data map as a valid input for the model. I tried with regression and I get a valid response. Is this wrong somehow?, Label: 1\n",
      "Processing row 4878 - Data Type: train, Message: I consider an empty data map as a valid input for the model. I tried with regression and I get a valid response. Is this wrong somehow?, Label: 1\n",
      "Processing row 4879 - Data Type: train, Message: @jstastny-cz Yea you're right. I tried to keep the same behaviour as the we had before but including the ProcessInput into accound, and I did some renames... that in this case is wrong ;D\n",
      "\n",
      "The `shouldGenSchema`  Predicate can be overwritten by the developer that uses the tool, and by default is initialized referring to  the static `shouldGenSchema`. The issue is that we may be applying the same filter twice, first the `shouldGenSchema` Predicate in line [99](https://github.com/kiegroup/kogito-runtimes/pull/1697/files/e683f946c85f2bed15c3f0f01ab8f832330aa652#diff-a9918cde5ab7d553f9c04373900b1ccfa340b2a00376e89cde80c4eca483c832L87) and then when calling the `ensureHasAnnotations` in line [100](https://github.com/kiegroup/kogito-runtimes/pull/1697/files/e683f946c85f2bed15c3f0f01ab8f832330aa652#diff-a9918cde5ab7d553f9c04373900b1ccfa340b2a00376e89cde80c4eca483c832R100).\n",
      "\n",
      "I'll fix that..., Label: 0\n",
      "Processing row 4880 - Data Type: train, Message: @evacchi Should we change `ProcessesAssetsProcessor` just like `KogitoAssetsProcessor`? (e.g. `BuildProducer<GeneratedJaxRsResourceBuildItem> jaxrsProducer`). I changed only this line because `registerResources` signature changed., Label: 1\n",
      "Processing row 4881 - Data Type: train, Message: @evacchi Is it fine to raise a validation warning at the GeneratedFile constructor like this?, Label: 1\n",
      "Processing row 4882 - Data Type: val, Message: > I expect all RESOURCE are STATIC_HTTP_RESOURCE in terms of runtime\n",
      "> ...\n",
      "> Said differently, can we just get rid of RESOURCE and convert everything to a single category?\n",
      "\n",
      "Hmm, I see several cases where files are generated not under \"META-INF/resources/\" which means those files are not intended to be published as static resources. In other words, they are not directly accessed via http but are retrieved by internal code. Am I misunderstanding?\n",
      "\n",
      "e.g.\n",
      "https://github.com/kiegroup/kogito-runtimes/blob/main/kogito-codegen-modules/kogito-codegen-processes/src/main/java/org/kie/kogito/codegen/process/ProcessCodegen.java#L539\n",
      "https://github.com/kiegroup/kogito-runtimes/blob/main/kogito-codegen-modules/kogito-codegen-processes/src/main/java/org/kie/kogito/codegen/process/persistence/PersistenceGenerator.java#L295-L298\n",
      "\n",
      "@evacchi Do you have any opinions on this?, Label: 1\n",
      "Processing row 4883 - Data Type: train, Message: https://issues.redhat.com/browse/KOGITO-6413, Label: 0\n",
      "Processing row 4884 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4885 - Data Type: train, Message: Wasn't sure about those, in that case we need to include `process-svg`, `process-management`, `source-files` and the `runtime-tools-quarkus-extension` from kogito-apps, wdyt?, Label: 1\n",
      "Processing row 4886 - Data Type: train, Message: no, Label: 0\n",
      "Processing row 4887 - Data Type: train, Message: This is the default for any SW project. If the user wants to change it, they can just create an application.properties file or any other Quarkus config method to override it. I linked in the constant documentation a description of this behavior from Quarkus docs, see: https://quarkus.io/guides/config-extending-support#example, Label: 0\n",
      "Processing row 4888 - Data Type: train, Message: Hmmmm, actually I do not like that bug proposal ;). This case is a very good example of why that proposal is not going to go through. A case where  is no chance an exception might be thrown, Label: 1\n",
      "Processing row 4889 - Data Type: val, Message: hmmmmmmmm\n",
      "I think this is actually a failure in the extension, Label: 0\n",
      "Processing row 4890 - Data Type: val, Message: https://github.com/quarkiverse/quarkus-openapi-generator/pull/92, Label: 0\n",
      "Processing row 4891 - Data Type: val, Message: hmmmm, \n",
      "Since ConfigProvider is the quarkus API, Im afraid there is no much we can do and has to document it. , Label: 0\n",
      "Processing row 4892 - Data Type: val, Message: I do not see why I cannot use my name in test, but ok, changed, Label: 0\n",
      "Processing row 4893 - Data Type: train, Message: and what about renaming already existing `version.io.quarkus.quarkus-test-maven` to something more generic like `version.io.quarkus.quarkus-test`? :thinking: \n",
      ", Label: 1\n",
      "Processing row 4894 - Data Type: train, Message: DMN is included here temporarily (I think the target should be to make it conditional rather than strong dependency) because there are some engine classes using the DMN interface. \n",
      "Those classes are not using PMML interface directly, so the dependency is not needed here, but in the example that uses DMN&PMML (which I also suspect does not exist), Label: 0\n",
      "Processing row 4895 - Data Type: train, Message: Yes, i was envisioning something like this though was lacking capacity to implement it. Thanks for the commit https://github.com/baremaps/baremaps/pull/287/commits/9ae29ccd4e06b7d2a7a9394e679737abb5f5ae65!, Label: 0\n",
      "Processing row 4896 - Data Type: train, Message: This might be a leftover from the untyped json schema for tileset that has been reverted. Anyways i removed it., Label: 0\n",
      "Processing row 4897 - Data Type: train, Message: @bchapuis this will break compliance with https://github.com/baremaps/openstreetmap-vecto/blob/main/tileset.json\n",
      "Anyways we probably rather want to adapt the schema than the code as it introduces the simple-json dependency and makes the code uglier., Label: 0\n",
      "Processing row 4898 - Data Type: train, Message: unified naming style,may be it can be keep, Label: 0\n",
      "Processing row 4899 - Data Type: train, Message: use powermock to test the method which invoke static method, mockito can not do it, Label: 0\n",
      "Processing row 4900 - Data Type: val, Message: I use system properties -Dscript.name to decide the name of the script\n",
      "What do you think about it?, Label: 1\n",
      "Processing row 4901 - Data Type: train, Message: Fixed, refactored to a separated method.\n",
      ", Label: 0\n",
      "Processing row 4902 - Data Type: train, Message: Was looking for the style sheet - could you point me to it?, Label: 1\n",
      "Processing row 4903 - Data Type: train, Message: Could do that, but doesn't `setInstanceConfig(clusterName, instanceConfig)` feel a bit odd as an API?, Label: 1\n",
      "Processing row 4904 - Data Type: train, Message: Added the comment. \"Mock\" doesn't suit the use case here because it mainly refers to \"mocking the class and mutate some behaviors at will\", Label: 0\n",
      "Processing row 4905 - Data Type: train, Message: The factory method itself is quite self-explanatory by reading the comments or reading the impl, don't you think so? , Label: 1\n",
      "Processing row 4906 - Data Type: train, Message: Yes, the hashCode doesn't prevent the trick conditions. The implementation is based on our prior knowledge about the incoming parameter (baseUrl + custom) and it won't cause any conflictions. Another reason is the `HttpRequest` class in Java library, it doesn't handle `equals` and `hashCode` function very well, the same baseUrl ends up different by the computation., Label: 0\n",
      "Processing row 4907 - Data Type: train, Message: That's the problem of using not final field, I don't know what are must-have fields which are set later. Given we have all set methods for the rest of fields, I'm not making it worse by only selecting interesting fields., Label: 1\n",
      "Processing row 4908 - Data Type: train, Message: Fixed. , Label: 0\n",
      "Processing row 4909 - Data Type: train, Message: To be clearer, do you suggest to fill a default \"true\" stoppable check result for all instances first and let the rest steps update the map? This way we can guarantee any instance has a stoppable check result even in the case of failure. But it exposes another problem, if RESTConfig is not set and we just return dummy success, the client will treat the instances as stoppable. \n",
      "\n",
      "The other idea is to throw exceptions when abnormal things happen so the client won't get confused about the result., Label: 0\n",
      "Processing row 4910 - Data Type: train, Message: That's a good point. Whether we want to find out failure reasons or stop if one constraint fails, the 1st gives us more ability to debug but the second saves the performance when the end goal is to come up with an assignment. That's up to the design. In the rebalance environment world, in which cases do we need to manually fix the fail reasons of hard constraints? If it won't even happen, I would suggest failing early., Label: 1\n",
      "Processing row 4911 - Data Type: train, Message: `calculatePoints` is a function expression, a concise way of expressing method. It's not actually computing anything without line 104, Label: 0\n",
      "Processing row 4912 - Data Type: val, Message: The MODEL is defined statically and not set dynamically on the fly. I think we should assume all types have a valid value or we're doing a bad job when assigning the weight.  Throw exception will fail all the rest operations I don't think it's good idea, Label: 0\n",
      "Processing row 4913 - Data Type: train, Message: Type and constraint need to be 1 to 1 mapping. How can we have one type mapping to multiple constraints?, Label: 1\n",
      "Processing row 4914 - Data Type: train, Message: If we use the class object then I guess the enum type definition is meaningless. , Label: 0\n",
      "Processing row 4915 - Data Type: val, Message: We can go that route (no enum) but the enum was created in the first place, I do think it's cleaner. Back to the original simple interface design, we could also get away with enums as well since it doesn't also enforce 1:1 mapping\n",
      "\n",
      "Then the weight map would consist of \n",
      "```\n",
      "Map<SoftConstraint, Float> weights = \n",
      " ImmutableMap.of(LeastUsedNode.class, 1.0f);\n",
      "```\n",
      "or \n",
      "```\n",
      "Map<SoftConstraint, Float> weights = \n",
      " ImmutableMap.of(instance of LeastUsedNode.class, 1.0f);\n",
      "```\n",
      ", Label: 0\n",
      "Processing row 4916 - Data Type: train, Message: Just a comment wouldn't stop us from implementing any constraint at their will. A stronger constraint would be to allow us to implement any ranged soft constraints and the scaler scales the value to a reasonable range plus the weight. \n",
      "\n",
      "The MIN MAX scores are just copied from previous soft constraints' interfaces. How about just use Float.MIN_VALUE and Float.MAX_VALUE?, Label: 1\n",
      "Processing row 4917 - Data Type: train, Message: Other than style, there's no difference, Label: 0\n",
      "Processing row 4918 - Data Type: train, Message: It's the first idea for me as well. However, realizing the PATH parameter can be something nasty like \"a/b/c/d\", the url becomes unnatural `\"http://endpoint.linkedin.biz/clusters/CLUSTER/propertyStore/a/b/c/d\"`. Something like this will just confuse people in practice. The URL encode is natural to HTTP request to escape the '/', Label: 0\n",
      "Processing row 4919 - Data Type: train, Message: The problem is transmitting the \"/aa/bb/cc\" in the Http request URL. Something like this `\"http://endpoint.linkedin.biz/clusters/CLUSTER/propertyStore/a/b/c/d\"` doesn't look a legit case to me. Do you think the regex can help stop the directory like \"/\"?, Label: 1\n",
      "Processing row 4920 - Data Type: val, Message: Does it mean the PR will need to wait on the baseDataAccesor's non-znRecord methods ready? It's likely to be so. Any ideas to expedite and run things in parallel? , Label: 1\n",
      "Processing row 4921 - Data Type: train, Message: Fixed. Probably a mistake, Label: 0\n",
      "Processing row 4922 - Data Type: train, Message: The simple get test is already verified after creation, do you think is it still needed for adding one specific case for get?\n",
      ", Label: 1\n",
      "Processing row 4923 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 4924 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 4925 - Data Type: train, Message: Added, Label: 0\n",
      "Processing row 4926 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 4927 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 4928 - Data Type: train, Message: It was my simple try to make it thread-safe, the atomic has the ability though; Do you have concrete suggestions on how to use it?, Label: 1\n",
      "Processing row 4929 - Data Type: val, Message: There was a change in the interface. SharedZkClient implements that interface. So this change is just a signature change, not logical change. \n",
      "\n",
      "This change is necessary., Label: 0\n",
      "Processing row 4930 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4931 - Data Type: train, Message: Forgot to remove it. Not supposed to include it., Label: 0\n",
      "Processing row 4932 - Data Type: train, Message: `DedicatedZkClientFactory` is what we provide and recommend users to create a RealmAwareZkClient which is a `DedicatedZkClient` instance. `DedicatedZkClient ` is protected and we don't want users to directly use it, right?, Label: 1\n",
      "Processing row 4933 - Data Type: train, Message: After making the fix, `handleChildChange` and `handleDataDeleted` are completely equal now. I added a comment on line 127 based on what you told me to justify the duplication - sometimes the callbacks may go missing. Should we consider calling `handleDataDeleted` from `handleChildChange`, for example, to reduce duplication? @narendly , Label: 1\n",
      "Processing row 4934 - Data Type: train, Message: I'll add it, but is that case actually possible?, Label: 1\n",
      "Processing row 4935 - Data Type: train, Message: I understand your concern and where you're coming from.  But it's still difficult. TaskDriver and ConfigAccessor are different APIs by design.\n",
      "- TaskDriver/HelixManager/HelixDataAccessor -> only serve 1 single Helix cluster\n",
      "- ConfigAccessor/ClusterSetup/etc.. -> can serve many Helix clusters\n",
      "So we need to keep a pool regardless.\n",
      "To help you understand:\n",
      "\n",
      "```\n",
      "  public TaskDriver(HelixManager manager) {\n",
      "  }\n",
      "  @Deprecated\n",
      "  public TaskDriver(RealmAwareZkClient client, String clusterName) {\n",
      "  }\n",
      "  @Deprecated\n",
      "  public TaskDriver(RealmAwareZkClient client, ZkBaseDataAccessor<ZNRecord> baseAccessor,\n",
      "      String clusterName) {}\n",
      "  @Deprecated\n",
      "  public TaskDriver(HelixAdmin admin, HelixDataAccessor accessor, ConfigAccessor cfgAccessor,\n",
      "      HelixPropertyStore<ZNRecord> propertyStore, String clusterName) {\n",
      "    this(admin, accessor, propertyStore, clusterName);\n",
      "  }\n",
      "```\n",
      "You see that every constructor of TaskDriver takes in a cluster name.\n",
      "\n",
      "Although TaskDriver does not support any ephemeral operations, by design it's meant to be a single cluster API.\n",
      "\n",
      "I think what you wanted to see was to pass in some FederatedZkClient into TaskDriver and use one TaskDriver for all clusters, but 1) that does not work, and 2) if we wanted to make that work, that's going to require a lot of code change in TaskDriver., Label: 0\n",
      "Processing row 4936 - Data Type: train, Message: Refreshing routing has a delay. And this is why `TestHelper.verify()` is used. Before routing is deleted in cached, namespace is still in cache, right? So the request still goes to TrieRouting, and IllegalArgumentException would be thrown because `anyKey` is invalid. In this case, we should catch the exception and retry, right?\n",
      "\n",
      "The better I think is this. I will update PR.\n",
      "```\n",
      "    Assert.assertTrue(TestHelper.verify(() -> {\n",
      "      for (String namespace : _routingZkAddrMap.keySet()) {\n",
      "        try {\n",
      "          _metadataStoreDirectory.getMetadataStoreRealm(namespace, \"anyKey\");\n",
      "          Assert.fail(\"Should not successfully get routing data\");\n",
      "        } catch (IllegalStateException e) {\n",
      "          // If other IllegalStateException, it is unexpected and this test should fail.\n",
      "          if (!e.getMessage().equals(\"Failed to get metadata store realm: Namespace \" + namespace\n",
      "              + \" contains either empty or invalid routing data!\")) {\n",
      "            throw e;\n",
      "          }\n",
      "        } catch (IllegalArgumentException iae) {\n",
      "          // If routing data is not yet refreshed, return false and retry.\n",
      "          if (iae.getMessage().equals(\"Provided path is not a valid Zookeeper path: anyKey\")) {\n",
      "            return false;\n",
      "          }\n",
      "          // If other IllegalArgumentException, it is not expected and this test should fail.\n",
      "          throw iae;\n",
      "        }\n",
      "      }\n",
      "      return true;\n",
      "    }, TestHelper.WAIT_DURATION));\n",
      "```, Label: 0\n",
      "Processing row 4937 - Data Type: train, Message: Please note that we want to make sure that the master for two different resources are existed in two different instances. Counter is also possible. However, I still think this implementation in more readable. Specially considering that this is only a test., Label: 0\n",
      "Processing row 4938 - Data Type: train, Message: @jiajunwang 14 hours ago Contributor\n",
      "Deprecate it?, Label: 1\n",
      "Processing row 4939 - Data Type: train, Message: @jiajunwang 14 hours ago Contributor\n",
      "Why? The periodic refresh does not need to be done synchronized, I think.\n",
      "If your timer action just adds the refresh event to the queue, there is no need to modify this.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 4940 - Data Type: train, Message: For 3, indeed changing the property is a way. \n",
      "\n",
      "The fundamental problem is that if you want to fail fast or not. \n",
      "\n",
      "In helix case, only ZkHelixManager uses CONNECTION_TIMEOUT in connect(). If connect() does not succeed, it would throw exceptions and the application won't proceed. \n",
      "\n",
      "So it seems there is no downside to do the default change too., Label: 0\n",
      "Processing row 4941 - Data Type: train, Message: changed., Label: 0\n",
      "Processing row 4942 - Data Type: train, Message: original watchForData use new one now,, Label: 0\n",
      "Processing row 4943 - Data Type: train, Message: getData will return stat too. \n",
      "`retryUntilConnected(() -> (((ZkConnection) getConnection()).getZookeeper().getData(path, true, stat)));`\n",
      "\n",
      "Here, we can't pass null to getData(). It would throw exception when getData try to fill data into stat. , Label: 0\n",
      "Processing row 4944 - Data Type: train, Message: TFTR.\n",
      "Respond status code is validated at line 511. Maybe we could validate the exception body/message as well?, Label: 1\n",
      "Processing row 4945 - Data Type: train, Message: I think auto formatter changes this.., Label: 0\n",
      "Processing row 4946 - Data Type: train, Message: Removed., Label: 0\n",
      "Processing row 4947 - Data Type: train, Message: removed., Label: 0\n",
      "Processing row 4948 - Data Type: train, Message: removed. , Label: 0\n",
      "Processing row 4949 - Data Type: train, Message: No, we cannot because there would be node not empty exception., Label: 0\n",
      "Processing row 4950 - Data Type: train, Message: I did zookeeper-api in both desktop and laptop. Is this what you meant?, Label: 1\n",
      "Processing row 4951 - Data Type: train, Message: The current `expiry` config we're using is on per-job level, though. I imagine there's a reason behind that?, Label: 1\n",
      "Processing row 4952 - Data Type: train, Message: jobState could be null in an erroneous state where a job is in the DAG but not in jobState map, but is that a situation we need to consider? This logic here wouldn't interact with such a job as it fails the jobState check conditions. I think it's fine to not deal with that case. , Label: 1\n",
      "Processing row 4953 - Data Type: train, Message: Good point. So this is also my first try. FYI, I also tried to extend the field type to include LIST_FIELD_KEY_ONLY. But then I find these 2 solutions are too complicated.\n",
      "\n",
      "It is correct that putting this logic into the IdealStateTrimmer will immediately fix the problem without too much change. The complex is that in this way, it would be hard to reason the overall logic of all trimmers. Some of them care about values, the others do not. Of course, we can add comments. But gradually, it will become harder to understand and maintain.\n",
      "\n",
      "So I go back and think about why we need these trimmers. Do we need to trim soo much information? I think we don't. The rebalancer will perform well even we detect all keys change (no value, just key's change) for all the properties. And the logic is very clean and concentrate:\n",
      "1. Keys are not ignored\n",
      "2. Values are ignored accordingly and this is specified by the getNonTrimmableFields() method.\n",
      "\n",
      "Then I firstly tried to not trim all keys (including the simple fields). But then I realize it is not optimal, since the simple fields' keys are tightly bounded with the values. And finally, I have the current proposal.\n",
      "\n",
      "Overall, the main reason for this trade-off is to make the trim logic less diverse and easier to maintain., Label: 0\n",
      "Processing row 4954 - Data Type: train, Message: Are you suggesting we read the config every time? We could if the config need to be dynamically changed. , Label: 1\n",
      "Processing row 4955 - Data Type: train, Message: The should be removed. \n",
      "\n",
      "Previously, we tried to set `protected static final long DEFAULT_JOB_PURGE_INTERVAL = 30 * 60 * 1000; // default 30 minutes` to -1 in WorkflowConfig.java, by using this function. \n",
      "\n",
      "This has its drawback as people have concerns as it pollutes production code as:\n",
      "\n",
      "1/ need to make DEFAULT_JOB_PURGE_INTERVAL not final.\n",
      "2/ The WorkflowConfig.disableJobPurge needs to be public. Thus, not testOnly., Label: 0\n",
      "Processing row 4956 - Data Type: train, Message: You mean they wouldn't be able to distinguish \"stale messages\" vs \"messages that don't have callbacks set up correctly\"? I think these cases are logically the same and can't be easily distinguished code-level. If we are loosening up on one case, it's going to affect the other. \n",
      "\n",
      "On the other hand, callback registration is done in our code and naturally there should be a callback before sending messages that require replies. I imagine the previous check was there for cautionary purpose, not that messages are commonly created with incorrect correlation ids. , Label: 1\n",
      "Processing row 4957 - Data Type: train, Message: I see what you mean now: you're saying in both cases, callback.isDone() == false, and it can't be distinguished whether the callback failed or there's no callback registered. \n",
      "\n",
      "If the callback fails due to some exception like you said, the task result will reflect that (setException(e), setInterrupted(true)). It's more difficult to tell the \"callback not registered\" case, but since customers don't want exceptions raised, there isn't any better way here., Label: 0\n",
      "Processing row 4958 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4959 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 4960 - Data Type: train, Message: 1. The API will be only called by users when they need, i.e., Helix will not automatically purge participants. And users will call it when they think it is safe, meaning no instance joining happen. The major concern from user side of having locks in purge function and in instance joining function is that they may have thousands of instances come online at the same time, if each of them tries to read and write the lock, zookeeper will have a burst, and this is dangerous.\n",
      "2. drop instances in this purge function are synchronous functions, and any exception thrown in the drop in stances will be seen by users. Do you suggest a map return or something?, Label: 1\n",
      "Processing row 4961 - Data Type: train, Message: I guess it is just because of some timing issues. When you set up a time window that equals the interval, you might have one or two refreshes happen., Label: 0\n",
      "Processing row 4962 - Data Type: train, Message: The java schedule task method that we are using is not accurate anyway. Moreover, the main test purpose here is to ensure the refresh happens. If it is faster a little bit, I guess we are still good.\n",
      "On the other hand, if the refresh does respect the interval, so during 1.5 seconds, it happens more than 2 times, then the test will still fail., Label: 0\n",
      "Processing row 4963 - Data Type: train, Message: Yes, it could happen. But since (!noNull.equal(null)) will be true, then we will go to the if statement. Right?, Label: 1\n",
      "Processing row 4964 - Data Type: train, Message: It expresses the code logic better, IMO.\n",
      "\n",
      "I can find many arguments online about this style, but I don't see much difference in this condition. If the previous return is for the exception or some early termination logic, then I think we should not use \"else\". But here, I don't see much difference. And my mind follows the current code better : ), Label: 0\n",
      "Processing row 4965 - Data Type: train, Message: My argument is that a sub-cluster can be a supercluster at the same time. It is possible to do a cascading setup. So for a sub-cluster, the additional setup still means a supercluster configuration, which will be used when it acts as a supercluster.\n",
      "\n",
      "About the first suggestion, are you talking about use WAGED as the default rebalancer for the sub-cluster resource directly? That was the original design. I just have a concern about backward compatibility. But if you think it is fine, I'm totally fine with this simpler solution.\n",
      "\n",
      "Regarding the other option, I thought about modifying the activeCluster API to accept the optional parameters. But this means we will need to modify helix-rest and helix-front as well. And there is a backward compatibility issue. I would rather deprecate this API and restrict it to only use the general resource creation APIs for activating a sub-cluster.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 4966 - Data Type: train, Message: Right. In fact, the more fundamental issue seems to be liek this:\n",
      "Dropping instance from test or admin tool vs controller adding messages to the same instance are async operations. The have race condition fundamentally. This also happens in production. This is a design flaw in Helix IMO. \n",
      "That said, to stabilize the test, we can disable controller and enable it again afterward. This is workaround for test, not production though., Label: 0\n",
      "Processing row 4967 - Data Type: train, Message: That needs a sleep() afterward. Otherwise, it won't work as it take at least one pipeline run cycle there. \n",
      "\n",
      "Are we ok with adding a sleep()?\n",
      "\n",
      ", Label: 1\n",
      "Processing row 4968 - Data Type: train, Message: Under this condition, like all other conditions modified in #1183, simply means we're in multiZk mode. The ZooKeeper used is the one corresponding to the cluster (which is made into a sharding key). , Label: 0\n",
      "Processing row 4969 - Data Type: train, Message: Some of them (like ConfigAccessor) seem to be deprecated and for testing only, but some of them are not. I think this is a good question for @narendly : is it necessary to guard the other places with similar patterns, such as `ZkBucketDataAccessor`? , Label: 1\n",
      "Processing row 4970 - Data Type: train, Message: Resolved offline with @jiajunwang: the design concern over ZooScalability is unrelated to this particular bug fix. , Label: 0\n",
      "Processing row 4971 - Data Type: val, Message: I actually want to get an opinion on this: is it really better to reject non-ZKHelixManagers, comparing to returning a null here, and let the util function to use the default pool size? This means open source customers who extend HelixManager literally cannot create a TaskStateModelFactory. , Label: 1\n",
      "Processing row 4972 - Data Type: train, Message: Thanks, I will use a boolean variable to simplify the check. And thanks for catching SyncCallbackHandler, not recording it wasn't intentional but since there wasn't an equivalent recording in ZkClient I missed it. I will add this to the check too. Only one question, for GetDataCallbackHandler and ExistsCallbackHandler I don't record a failure if the return code is NONODE (given the logic in their sync equivalent methods in ZkClient), should I again make this exception for SyncCallbackHandler? Or this doesn't make sense because SyncCallbackHandler checks the root path?, Label: 1\n",
      "Processing row 4973 - Data Type: train, Message: @dasahcc I've thought about it and this logic won't work. Because when allChecks enabled, customers would like to have all the failed checks in the response. In the logic you presented, if allChecks == true, it won't add the failed check.\n",
      "\n",
      "I do think the current 2 \"if\"s are clearer to understand.  , Label: 1\n",
      "Processing row 4974 - Data Type: val, Message: I thought about both `putIfAbsent` and `computeIfAbsent` but neither of them fit in the logic., Label: 0\n",
      "Processing row 4975 - Data Type: val, Message: 1. I think `add(Stoppable)` is better. What I consider is like `list.addAll();`. \n",
      "`mergeFailures` should be `void mergeFailures(failures1, failures2);` which does not fit in this design. Similar to appendFailures.\n",
      "2. Each stoppable is a different categories. They are strings. So the failures list is actually a list of strings of different categories: `[HELIX:abc, CUSTOM_PARTITION:efg, CUSTOM_INSTANCE: xyz]`, Label: 0\n",
      "Processing row 4976 - Data Type: val, Message: I am not sure... I think we still need to call `getNextAssignableReplica` twice when using do-while ., Label: 1\n",
      "Processing row 4977 - Data Type: train, Message: Thanks for the comment. I think it reveals a valid point -- should we continue the process when remaining capacity is 0? I think we could safe several compute cycle by checking hard constrain first and quit early. That might be more elegant comparing to this hacky way of avoiding divide by 0. \n",
      "Regarding the example in your comment, I am not sure if this will happen since the remaining capacity is an Integer. I think adding 0.01 to 1 might not change the result a lot since we only care about the relative relationship between each replicas. \n",
      "Considering the effort in development, I think maybe adding 0.01 here is the easiest way to avoid divide by 0. \n",
      "\n",
      "All comments are welcome.  :D, Label: 1\n",
      "Processing row 4978 - Data Type: train, Message: @mgao0 I had just added some more tests before your comment, is your comment considering those tests as well?, Label: 1\n",
      "Processing row 4979 - Data Type: train, Message: We need this note even when the class is defined test module? I don't think this class has any non-test usage,, Label: 1\n",
      "Processing row 4980 - Data Type: train, Message: TFTR. When we add an API to allow user to pass in `RealmAwareZkConnectionConfig` and when user pass in a null obj, shouldn't we create a default one instead of using the null?, Label: 1\n",
      "Processing row 4981 - Data Type: train, Message: I see, thanks. Is there other log that you think we should better keep INFO?, Label: 1\n",
      "Processing row 4982 - Data Type: train, Message: I think it could be both. I don't know what setting that is, can you point me to a relevant resource please?, Label: 1\n",
      "Processing row 4983 - Data Type: train, Message: Do you mean in tests or in real world? In real world, it's never set from Helix's/ZkClient's perspective. It would only be set on the ZK server, if it's intended for the ZK to support TTL and Container modes. In tests, whenever we want to test creating a ZNode in TTL or Container mode, this needs to be set. Otherwise, ZK server throws an UnimplementedException., Label: 1\n",
      "Processing row 4984 - Data Type: val, Message: Thanks for catching it, my intellij seems to be misconfigured. , Label: 0\n",
      "Processing row 4985 - Data Type: train, Message: TFTR. Wouldn't input every single variables be the opposite of builder pattern? , Label: 1\n",
      "Processing row 4986 - Data Type: train, Message: Thanks for the comment, but why this has to be synchronized? it's a read operation, Label: 1\n",
      "Processing row 4987 - Data Type: train, Message: \"when number of readers is less than 1\" conveys the same message right? Am i missing anything?, Label: 1\n",
      "Processing row 4988 - Data Type: val, Message: Ack!, Label: 0\n",
      "Processing row 4989 - Data Type: train, Message: Ack!, Label: 0\n",
      "Processing row 4990 - Data Type: val, Message: made it common for the class, Label: 0\n",
      "Processing row 4991 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 4992 - Data Type: train, Message: What you mean by \"Use the Client (jaxrs) instead of a cxf api?\"?, Label: 1\n",
      "Processing row 4993 - Data Type: train, Message: > ok Gurkan.\n",
      "\n",
      "So, ok means will you commit?, Label: 1\n",
      "Processing row 4994 - Data Type: val, Message: Thanks for the comments. I will update my patch and attach again.\n",
      "Regards.\n",
      "Gurkan, Label: 0\n",
      "Processing row 4995 - Data Type: train, Message: I think the browser by default sends ContentType: text/html as header if I do the same request in Postman I get a YAML, so I dont think a ticket is required., Label: 0\n",
      "Processing row 4996 - Data Type: train, Message: I just didn't want the code to repeat the message a lot of times. What is the issue with this pattern?, Label: 1\n",
      "Processing row 4997 - Data Type: train, Message: @cesarhernandezgt  Have you sign up for the pay as you go plan?, Label: 1\n",
      "Processing row 4998 - Data Type: train, Message: I think those sub-domains might need to be unique... can you try with a Different app name? not cloud-tomee-azure., Label: 1\n",
      "Processing row 4999 - Data Type: train, Message: Resolved.  Forgot to push!, Label: 0\n",
      "Processing row 5000 - Data Type: train, Message: Hi, thanks again for checking.\n",
      "\n",
      "So I'm wondering why when I run the full tests from the parent (as the buildbot build does), it does not fail but when I run the example project directly from itself own sub-folder like you have done, it does.\n",
      "\n",
      "I've looked at the example/pom.xml and it appears that some examples are not included as modules.  I see 165 example folders and only 158 modules listed in examples\\pom.xml.\n",
      "\n",
      "Missing examples are:\n",
      "applet\n",
      "bval-evaluation-redeployment\n",
      "java-modules\n",
      "mp-jsonb-configuration\n",
      "mp-metrics-metered\n",
      "mp-opentracing-traced\n",
      "mp-rest-jwt-principal\n",
      "\n",
      "Do you know if all of these are excluded for a reason?\n",
      "\n",
      "Specifically bval-evaluation-redeployment is not being tested by buildbot.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 5001 - Data Type: train, Message: @otaviojava fiz a alteraÃ§Ã£o conforme sugerido!, Label: 0\n",
      "Processing row 5002 - Data Type: train, Message: I've fixed my changes back to the original. Thanks for the encouragement. \n",
      "\n",
      "I think I was confused because it looks like it accepts invalid JSON! I may have I made a change to the original before I understood how it worked, and that only caused more problems. I didn't understand why 406 was acceptable, changed the test, and then... it was all downhill. Good intentions, bad results :\\, Label: 0\n",
      "Processing row 5003 - Data Type: train, Message: fixed, updating my PR now., Label: 0\n",
      "Processing row 5004 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 5005 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5006 - Data Type: val, Message: Done!, Label: 0\n",
      "Processing row 5007 - Data Type: train, Message: done , Label: 0\n",
      "Processing row 5008 - Data Type: train, Message: Fixed!, Label: 0\n",
      "Processing row 5009 - Data Type: train, Message: Hi @cesarhernandezgt thanks for review. In this case, which is the correct index-group?, Label: 1\n",
      "Processing row 5010 - Data Type: train, Message: sorry, I don't understand, do you have to change anything?, Label: 1\n",
      "Processing row 5011 - Data Type: train, Message: In portuguese do not use the word \"Side Note\", uses \"Note\" or \"Observation\", i made a mistake, in portuguese to say  \"NotaÃ§Ã£o\" or \"ObservaÃ§Ã£o\", and not \"NotaÃ§Ã£o lateral\" as i wrote. \n",
      "Do you like better, \"Note\"(NotaÃ§Ã£o) or \"Observation\"(ObservaÃ§Ã£o) ?    , Label: 1\n",
      "Processing row 5012 - Data Type: train, Message: > \" puede crear, eliminado, actualizado o eliminado a travÃ©s de un objeto\" is redundant\n",
      "\n",
      "It is corrected, Label: 0\n",
      "Processing row 5013 - Data Type: val, Message: I made some progress based on your feedback, but I think it is still heavily **WIP** ;)  It should now honor the test instance lifecycle. The `mode` thing is missing yet. I have to think about the impl for the proposed `mode` for controlling the container instances created during tests., Label: 0\n",
      "Processing row 5014 - Data Type: train, Message: The current impl relies on the test's life cycle to start a container or perform related injections.\n",
      "\n",
      "Atm the impl contains annotations and extensions for\n",
      "\n",
      "- `RunWithSingleApplicationComposer`\n",
      "- `RunWithApplicationComposer`\n",
      "\n",
      "as well as a \n",
      "\n",
      "- `TomEEEmbeddedExtension`\n",
      "\n",
      "From my understanding, the proposed `mode` is solely responsible to configure how (or when) the underlying container is started? I.e. one container to run all tests within a single test class (PER_ALL), one container for each test method of one test class (PER_EACH) and one container to run multiple test classes (PER_JVM), right?  Is this the same idea, which is currently conducted through different JUnit4 runners? \n",
      "\n",
      "From my understanding of the current JUnit implementation, the `ApplicationComposer` seems to be something similar to the PER_ALL and the `EmbeddedTomEERunner` / `SingleApplicationComposer` to the PER_JVM; I think PER_EACH (test method) isn't implemented in the JUnit 4 runners yet.\n",
      "\n",
      "Probably I am missing something but I think, I do not have the whole process or related use-cases in mind ;) - Maybe you , @rmannibucau , can add some more ideas / thoughts on the `mode` idea? \n",
      "\n",
      "EDIT-1: I added some code to draft my idea / thoughts related to `modes`. Might be better to understand from the code point of view than from my words, if I got the idea correctly, so I added the related commits here., Label: 1\n",
      "Processing row 5015 - Data Type: train, Message: Thx. Changed it., Label: 0\n",
      "Processing row 5016 - Data Type: val, Message: Good catch. `ApplicationComposerExtensionBase` isn't needed nor is it used. , Label: 0\n",
      "Processing row 5017 - Data Type: train, Message: replaced, Label: 0\n",
      "Processing row 5018 - Data Type: train, Message: attempted to fix , Label: 0\n",
      "Processing row 5019 - Data Type: train, Message: If I remove the prefix from:\n",
      "\n",
      "```java\n",
      "nonblockingDigest(final MessageDigest messageDigest, final File data)\n",
      "```\n",
      "\n",
      "will clash with an existing method name., Label: 0\n",
      "Processing row 5020 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 5021 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 5022 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 5023 - Data Type: train, Message: Okay., Label: 0\n",
      "Processing row 5024 - Data Type: train, Message: Yes exactly! I want this to be spec compliant, not something that might produce unexpected behaviour. If you don't know if the hex you are decoding is upper or lower case, I think you have bigger problems... i.e. are you sure it is even valid hex?, Label: 1\n",
      "Processing row 5025 - Data Type: train, Message: I think it is not a bad suggestion, but I also think this is perhaps feature/scope creep. My goal was to implement the decoder according to the RFC. What you have suggested sounds like an additional feature which could be added later without issue. I would rather get this PR merged as it is. Is that okay with you?, Label: 1\n",
      "Processing row 5026 - Data Type: train, Message: Fix it , Label: 0\n",
      "Processing row 5027 - Data Type: val, Message: changed , Label: 0\n",
      "Processing row 5028 - Data Type: train, Message: I've explained it in commit message: https://github.com/apache/maven-surefire/commit/2beb507001867dc61f2be55d206c5825e9f0c2ca\n",
      "\n",
      "> Fixing flaky test Surefire1177TestngParallelSuitesIT\n",
      "> \n",
      "> This test rely on displaying messages on System.out, but invocations wasn't synchronized so messeges tend to interweave and test wasn't able to assert for them properly. I added synchronization and move code a litle bit.\n",
      "\n",
      "Test asserts that messages should be either:\n",
      "```\n",
      "TestNGSuiteTest#shouldRunAndPrintItself() 1.\n",
      "TestNGSuiteTest#shouldRunAndPrintItself() 2.\n",
      "```\n",
      "or \n",
      "```\n",
      "TestNGSuiteTest#shouldRunAndPrintItself() 2.\n",
      "TestNGSuiteTest#shouldRunAndPrintItself() 1.\n",
      "```\n",
      "\n",
      "And without synchronization it often was something like this:\n",
      "\n",
      "```\n",
      "TestNGSuitTestNGSuiteTeTest#shouldRunAndPrintItself() 1.\n",
      "est#shouldRunAndPrintItself() 2.\n",
      "```, Label: 0\n",
      "Processing row 5029 - Data Type: val, Message: @eolivelli \n",
      "yes, and moreover we should change the method signature from this:\n",
      "`toClasspathElementUri( String parent, String classPathElement, File dumpLogDirectory )`\n",
      "to this:\n",
      "`toClasspathElementUri( Path parent, Path classPathElement, Path dumpLogDirectory )`\n",
      "Which requires calling `dumpLogDir.toPath()` in `ForkStarter` (Line 580) but pls do not go deeper changing File to Path in all project since it is not a matter of this PR., Label: 0\n",
      "Processing row 5030 - Data Type: train, Message: The problem I'm having with this being marked as required is, that is will make `testSourceDirectory` show up at the very top of the [documentation page](https://maven.apache.org/surefire/maven-surefire-plugin/test-mojo.html). This unnecessary highlights a property that is only used by legacy implementations of TestNG. As said above, I would remove it completely., Label: 0\n",
      "Processing row 5031 - Data Type: train, Message: this is only temporal because the abstraction is not well used in this class., Label: 0\n",
      "Processing row 5032 - Data Type: train, Message: Changed., Label: 0\n",
      "Processing row 5033 - Data Type: train, Message: I was trying to be consistent, so that the connection string has string in the properties file and the code as well.\n",
      "What approach is better?, Label: 1\n",
      "Processing row 5034 - Data Type: val, Message: There are few of them.\n",
      "@jon-bell \n",
      "@eolivelli \n",
      "Which options do we need, and which we need?, Label: 1\n",
      "Processing row 5035 - Data Type: train, Message: Not in master., Label: 0\n",
      "Processing row 5036 - Data Type: train, Message: I used the same format like it was for TESTNG_GROUPS_PROP but if you want I can follow your approach?, Label: 1\n",
      "Processing row 5037 - Data Type: val, Message: Hmm I checked and to verify ids I need to do probably some conversion of junit classes etc.\n",
      "There is no direct method to get those ids values but only method to apply if TestEngine is included or excluded by filters.\n",
      "This logic is more inside Junit itself so maybe enough will be to check only if expected filter is instance of EngineFilter?, Label: 1\n",
      "Processing row 5038 - Data Type: train, Message: Hmm there was no method: \".element()\" so I used something else :), Label: 0\n",
      "Processing row 5039 - Data Type: train, Message: assertThat( provider.getFilters() ).asList() throw exception as getFilters() return array but expected was list :/, Label: 0\n",
      "Processing row 5040 - Data Type: train, Message: > Pls add a line with a comment regarding TestNG 5.10. It was very good point.\n",
      "\n",
      "You mean this one:\n",
      "\n",
      "_The code is compiled against TestNG 5.10 and that version doesn't have the `index` field in `XmlClass`, hence use of reflection._ ?\n",
      "\n",
      "I wouldn't want to put exact TestNG 5.10 version in the source, as it's subject to change, but i added explanatory comment above XML_CLASS_SET_INDEX constant:\n",
      "\n",
      "```\n",
      "// Using reflection because XmlClass.setIndex is available since TestNG 6.3\n",
      "// XmlClass.m_index field is available since TestNG 5.13, but prior to 6.3 required invoking constructor\n",
      "// and constructor XmlClass constructor signatures evolved over time.\n",
      "```\n",
      "\n",
      "i tried to make it convey same meaning: that we have to use the reflection.\n",
      "\n",
      ", Label: 1\n",
      "Processing row 5041 - Data Type: train, Message: > The main advantage in adding this cosmetic change is that you could easily test the behaviour with multiple values for the `threadCount`\n",
      "\n",
      "i don't see advantage of doing this. Please help me understand., Label: 0\n",
      "Processing row 5042 - Data Type: train, Message: There is not much methods and classes we use, we can write our own, few util methods. The problem is with CLI., Label: 0\n",
      "Processing row 5043 - Data Type: train, Message: The fields `runMode` will be deleted in `ForkinRunListener` and `EventChannelEncoder`.\n",
      "This PR has only prepared changes in one method signature. The implementation of this abstract method comes right after. This PR is only an intermediate step., Label: 0\n",
      "Processing row 5044 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 5045 - Data Type: train, Message: it's to avoid a deep scanning which have a very poor performance where we know exactly file names we are looking for `jacoco*.exec` and directories. scanning everything is a waste of time., Label: 0\n",
      "Processing row 5046 - Data Type: train, Message: Right... Was looking into my previous thought and was able to confirm that it was indeed ok and wasn't really affecting it as it depends on the provider... eventually ended up in this RunListenerAdapter class as well, and the logic there is quite overwhelming and a bit scary :) I have made changes to that class only now (without all the other changes) and it does seem to be ok, as suggested.\n",
      "\n",
      "I've added a junit4 table with the different scenarios so that it has some examples on it. There is a different issue I found (when miss-using the junit4 displayName to not contain the parameter; causing same problem.. it is possible to avoid it, but requires messing with the UniqueID .. probably not the best since it may change... anyways, when attempting 2nd run on the failed tests (even with proper handling), junit4 fails to run only the failed and re-runs all the ones that match the 'displayName' ... but again, since this is some very odd case that I hope nobody is using (And should be discouraged I guess by some warnings when not adding {0} or anything to it)\n",
      "\n",
      "Will run some more tests and see if I can update this PR to use the newly created branch with less changes or if I should overwrite my branch's history ... will update this PR soon\n",
      "\n",
      "Thanks!, Label: 0\n",
      "Processing row 5047 - Data Type: train, Message: This code is redundant. The superclass implementation already processes the [threadcount] option. The reason I'm acquiring the default value when the option is unspecified is that the superclass implementation assigns a default value of 1, whereas TestNG currently assigns a default value of 5., Label: 0\n",
      "Processing row 5048 - Data Type: train, Message: Look closer... The value of the [parallel] option is being **removed** from the map. I'm processing the option here, and the removal of the option avoids double-processing (with the resultant failure) in the superclass implementation.\n",
      "As I pointed out in my comments, skipping the invocation of the superclass implementation has the result that all other specified options get ignored., Label: 0\n",
      "Processing row 5049 - Data Type: train, Message: I could do as you suggest and extract the logic to `setThreadCount` and `setParallel` methods. My current approach was intended to limit the scope of revisions to this single class. Would you prefer that I refactor the implementation? This would reduce the complexity a bit while expanding the scope of this PR., Label: 1\n",
      "Processing row 5050 - Data Type: train, Message: If all supported versions of TestNG provide a default for this setting, it may be best to not inject a default here. Just let TestNG provide its own default value. That's how the new code for TestNG 7.4+ behaves. I don't know the history of the original code to understand why this was coded to inject a default value of 1. (What's the benefit of specifying parallel execution if the thread count is 1?)\n",
      "If the default implementation is changed so that it behaves like the new override, this override can be removed., Label: 1\n",
      "Processing row 5051 - Data Type: train, Message: Just realized this should be 1025 here, ðŸ˜µ (`\"\\uD83D\\uDE35\"`) is actually counted as 2 characters.\n",
      "\n",
      "Do you want me to change this or just leave StringBuilder to increase the capacity on it's own?, Label: 1\n",
      "Processing row 5052 - Data Type: train, Message: `DateTimeFormatter` has no constant for a date/timestamp with milliseconds., Label: 0\n",
      "Processing row 5053 - Data Type: train, Message: Do you mean `ShutdownHook` or `ThreadGroup`?\n",
      "Both are still part of moderns JDKs such as Java 17 (LTS) and neither marked deprecated nor discouraged., Label: 1\n",
      "Processing row 5054 - Data Type: train, Message: I changed to package private.\n",
      "\n",
      "The best way will be introduce interface for this component and move implementation to another place \n",
      "but this class contains a static methods which is used in  AbstractSurefireMojo.\n",
      "\n",
      "So usage is mixed, I would not extends this PR too more., Label: 0\n",
      "Processing row 5055 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5056 - Data Type: train, Message: Any suggestions?, Label: 1\n",
      "Processing row 5057 - Data Type: train, Message: Maybe \"Using fork starter with configuration implementation \" to be in line with https://github.com/apache/maven-surefire/blob/0998f10bb486f79f40d2d4262798b1f53a5ff286/maven-surefire-common/src/main/java/org/apache/maven/plugin/surefire/AbstractSurefireMojo.java#LL2228C32-L2228C32?, Label: 1\n",
      "Processing row 5058 - Data Type: train, Message: Note that the DIN99 standard has several iterations. These here deal with DIN99b (important milestone) and DIN99o (latest to date, AFAIK). Note I'm using the new class ColorDIN99Lab for both of these. Not sure we need to have separate classes, since both denote a Lab coordinate in the DIN99 color space.\n",
      "Note that DIN99 is a German norm (DIN stands or German Institute for Standardization), most comprehensive documents and discussions it are in the German language, hence some links to it point to the original sources consulted for the implementation., Label: 0\n",
      "Processing row 5059 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5060 - Data Type: train, Message: Actually, tile length is what they call it in the TIFFF specification.  Not sure they used that term, though it might be a holdover from the earlier terminology strip-length. \n",
      "\n",
      "In either case, I think we should leave this one as is..., Label: 0\n",
      "Processing row 5061 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5062 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5063 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5064 - Data Type: train, Message: Hi, in fact I could undo the change that automatically write the tmp file as it is probably useless in case of automatic tests. But add back the code that writes the file but commented out so it could be activated manually by a developper if needed ?, Label: 1\n",
      "Processing row 5065 - Data Type: train, Message: In fact we can reuse the same ByteArrayInputStream but the code is more verbose, and closing it has no effect (however it is useful for static analysis of IDE so they do not complains about it ;) )\n",
      "\n",
      "```java\n",
      "try (ByteArrayInputStream bos = new ByteArrayInputStream(temp1)) {\n",
      "            Imaging.getImageInfo(bos, filename);\n",
      "            bos.reset();\n",
      "            Imaging.getImageSize(bos, filename);\n",
      "            bos.reset();\n",
      "            Imaging.getMetadata(bos, filename);\n",
      "            bos.reset();\n",
      "            Imaging.getICCProfile(bos, filename);\n",
      "            bos.reset();\n",
      "            final BufferedImage imageRead = Imaging.getBufferedImage(bos, filename);\n",
      "            bos.reset();\n",
      "            assertNotNull(imageRead);\n",
      "        }\n",
      "```\n",
      "\n",
      "Another option is to use the methods taking directly a byte[] but it would require to create new methods also taking the filename as the file extension is sometimes used to help reading data (unfortunately some exists but the parameter order is not consistent, sometimes the filename comes first some other time it comes after), Label: 0\n",
      "Processing row 5066 - Data Type: val, Message: I am not completely sure about those names; at least `fileResource` sounds a bit like it also verifies that the resource is an existing file (and not a directory), which it doesn't.\n",
      "\n",
      "Maybe `resourceFile` and `resourcePath` would be better (or some other name)? What do you think?, Label: 1\n",
      "Processing row 5067 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5068 - Data Type: val, Message: If it is important to expose all of those exceptions distinct from each other then I think the implementation in `SessionImpl` needs to complete the process without using the `SessionDelegate` since the delegate only throws `RepositoryException` - in which case we lose the standardized processing done by the `SessionDelegate` via the `perform` family of methods.\n",
      "Which do you prefer?, Label: 1\n",
      "Processing row 5069 - Data Type: val, Message: @reschke I'm not opposed to making the change from URL to URI, but I'm not sure what exactly the benefit is.\n",
      "If the back-end storage is `S3DataStore`, the library will give us a URL which would have to be converted to a URI.  And then a client wanting to do the upload or download would then have to convert that URI back to a URL in order to use `HttpURLConnection` or `HttpsURLConnection` - or use a library to do it, like Apache HttpComponents.  I don't see the value of converting it to a URI if what a client needs to create a connection is a URL anyway., Label: 1\n",
      "Processing row 5070 - Data Type: train, Message: Yes. Changed., Label: 0\n",
      "Processing row 5071 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5072 - Data Type: train, Message: AFAIR, two different values were not suggested. If you think we should have different values, let me know what should be default value for jcr., Label: 0\n",
      "Processing row 5073 - Data Type: train, Message: @thomasmueller ...agree with the order a,b point ..will make the changes to handle that \n",
      "\n",
      "But with the desc/asc thing ..we don't define the in our indexes if it should sort asc or desc..we just add ordered = true on the prop..so shouldn't the index always  handle both the cases ? Or maybe I am missing something ? , Label: 1\n",
      "Processing row 5074 - Data Type: train, Message: @thomasmueller  - Instead of throwing an exception - maybe we can simply set canSortByIndex = false in QueryImpl in case getOrderEntryPropertyName returns null (that way the query would still return result , sorted by QueryEngine). WDYT ? , Label: 1\n",
      "Processing row 5075 - Data Type: val, Message: Actually getOrderEntryPropertyName basically is needed to compare the property name set for the Ordering any particular implementation of DynamicOperand - In case of FullTextSearchScoreImpl - no Order is set , so I thought maybe it would be better to return null from getOrderEntryPropertyName  too.\n",
      "\n",
      "But I can return score pseudo-property here ., Label: 0\n",
      "Processing row 5076 - Data Type: train, Message: Actually \"/oak:index\".split(\"/\") would return [\"\",\"oak:index\"] -> so this ignores the first empty entry there. But yes , I think PathUtils.elements could be used here (I didn't know about that.), Label: 0\n",
      "Processing row 5077 - Data Type: train, Message: thx! fixed, Label: 0\n",
      "Processing row 5078 - Data Type: train, Message: thx! fixed, Label: 0\n",
      "Processing row 5079 - Data Type: train, Message: Oups, this one is particularly ugly - removed this part entirely (at https://github.com/apache/jackrabbit-oak/pull/238/commits/fb8b330c4f248078bb2dce62cfb19ae90a50030c ), Label: 0\n",
      "Processing row 5080 - Data Type: train, Message: committed, thx, Label: 0\n",
      "Processing row 5081 - Data Type: train, Message: That would also require `sweep2Lock` to be passed to the `BackgroundSweep2Operation` via some other means though, so not sure that's worth it?, Label: 1\n",
      "Processing row 5082 - Data Type: train, Message: Agree, and I was aware of this. However, I did this on purpose as indicated in the class comment. The alternative would have been to reuse NodeDocumentSweeper - with the risk or cost that any future change on that class would have to be carefully crafted to avoid any side-effects on NodeDocumentSweeper2 behaviour. I considered this future risk as higher versus the code-duplication. Wdyt?, Label: 0\n",
      "Processing row 5083 - Data Type: train, Message: Does this wrapping is required if we are not disposing the nodestore?, Label: 1\n",
      "Processing row 5084 - Data Type: train, Message: removed, Label: 0\n",
      "Processing row 5085 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5086 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5087 - Data Type: val, Message: ah..I still am in the habit to use String[] .. changed it to String... args now, Label: 0\n",
      "Processing row 5088 - Data Type: train, Message: comments incorporated, Label: 0\n",
      "Processing row 5089 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5090 - Data Type: train, Message: done , Label: 0\n",
      "Processing row 5091 - Data Type: train, Message: @fabriziofortino  - Agreed with your point about the performance. \n",
      "\n",
      "We can ignore older versions of indexes here (using the same filter logic as is used in the FullTextIndex while creating the index plans) - but I am wondering if that would be correct ? Because for statistics, we would want to show the older indexes as well - if they are active (being indexed) and/or consuming disk space. \n",
      "\n",
      "Thoughts ? (cc : @thomasmueller  @tihom88 ), Label: 1\n",
      "Processing row 5092 - Data Type: train, Message: @fabriziofortino  - it seems we init the searcher when we do acuireIndexNode from IndexTracker - so we wouldn't be able to avoid that. \n",
      "\n",
      "So it's either get stats for all indexes (disabled/old/active). Or get stats only for active ones and ignore disabled and old indexes completely.  We can't do the half and half approach as I thought earlier. , Label: 0\n",
      "Processing row 5093 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 5094 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5095 - Data Type: train, Message: see https://github.com/apache/jackrabbit-oak/pull/383#discussion_r727798177, Label: 0\n",
      "Processing row 5096 - Data Type: train, Message: @fabriziofortino  - yes, usage for this is not documented on lucene and I suppose it was found out by SITES team while working on https://jira.corp.adobe.com/browse/SITES-2564.\n",
      "\n",
      "I added this check for specific properties/fields because elastic docs mention that this can have significant performance impact, so I didn't want to give an option to enable this at index level.\n",
      "\n",
      ">Does it mean that for full-text queries (eg: contains(. ,\"*foo*\") this would never work?\n",
      "atm, yes..we can change this behaviour, but I am not sure if we should. (I have not tested what the corresponding behaviour in lucene), but imo, we should restrict this to per field basis. wdyt ? , Label: 0\n",
      "Processing row 5097 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5098 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5099 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5100 - Data Type: train, Message: @thomasmueller  - propertyIndex could still use it - because in restrictProperty method in FilterImpl, I added new varaibles to handle inequality, which would effectively leave the old behaviour for PropertyIndex as it is. \n",
      "\n",
      "Changes in Filter.java and FilterImpl.java should handle this. wdyt ? \n",
      ", Label: 0\n",
      "Processing row 5101 - Data Type: train, Message: @averma21  - yes there are multiple tests. \n",
      "testEqualityQuery_native - > tests simple equality condition\n",
      "testEqualityInequalityCombined_native -> equality and inequality\n",
      "testInequalityQuery_native -> tests inequality with nodes created with this property and also without this property.\n",
      "\n",
      "So effectively the condition that x<>1 should return nodes where x is set and not equal to 1 is being tested. I hope this is what you were asking for - right ?, Label: 1\n",
      "Processing row 5102 - Data Type: val, Message: ok, Label: 0\n",
      "Processing row 5103 - Data Type: train, Message: @fabriziofortino Thanks, I just refined the PR with another commit over the review. Can you review again to see if all meet what you suggested here?, Label: 1\n",
      "Processing row 5104 - Data Type: val, Message: This shows the outdated code (see the label in the header). The code in the last commit does not have the space., Label: 0\n",
      "Processing row 5105 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5106 - Data Type: train, Message: I followed the property for `DEFAULT_NUMBER_OF_DATA_DUMP_THREADS` which is also a string\n",
      "Should I change it all to `int` instead?, Label: 1\n",
      "Processing row 5107 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5108 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5109 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 5110 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 5111 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 5112 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5113 - Data Type: train, Message: I don't know if it's really needed... the old code just seems completely broken by design, and the TODO even admits that... it's just, the TODO was never fixed, and there is a complete lack of tests in this area. I would rather fix that instead of adding a way to analyze... just my opinion., Label: 0\n",
      "Processing row 5114 - Data Type: val, Message: Yes, I know it's kind of cheating... whitebox testing..., Label: 0\n",
      "Processing row 5115 - Data Type: train, Message: I don't believe an IllegalArgumentException can be thrown here as getLimit is only returning the previously parsed limit optional, Label: 0\n",
      "Processing row 5116 - Data Type: train, Message: Added log, exception itself have invalid url., Label: 0\n",
      "Processing row 5117 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5118 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 5119 - Data Type: train, Message: moved, Label: 0\n",
      "Processing row 5120 - Data Type: train, Message: Correct, I believe the error is for any sort of failure here... so not necessary just jar missing.\n",
      "And no, we do not have any test case for this., Label: 0\n",
      "Processing row 5121 - Data Type: train, Message: Do we still want to update it to info?, Label: 1\n",
      "Processing row 5122 - Data Type: train, Message: I've changed the jackson-databind version to the one in the parent module (using the same variable). I've executed mvn clean install in the module and executed the tests. All tests passed so... I suppose we can use the old version instead of the version provided by the documentation https://www.elastic.co/guide/en/elasticsearch/client/java-api-client/7.17/installation.html#maven\n",
      "@fabriziofortino , is it ok?, Label: 0\n",
      "Processing row 5123 - Data Type: train, Message: see above, Label: 0\n",
      "Processing row 5124 - Data Type: train, Message: sure! one sec....., Label: 0\n",
      "Processing row 5125 - Data Type: train, Message: only pseudo-code.... but i can add that, Label: 0\n",
      "Processing row 5126 - Data Type: train, Message: I've reverted even thought I still don't see the why stored is even ok here :) , Label: 0\n",
      "Processing row 5127 - Data Type: val, Message: Cool!, Label: 0\n",
      "Processing row 5128 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5129 - Data Type: train, Message: Why do we need to change the socket timeout?, Label: 1\n",
      "Processing row 5130 - Data Type: train, Message: Jun didn't change the old code here (from Chetan / Vikas / Tommaso probably), he just synchronized the method. So I think we should keep it as is. Unless if you can find out if the comment is better kept or removed... I can't, looking at the code., Label: 0\n",
      "Processing row 5131 - Data Type: train, Message: As in log and return false (let it return silently ?) (btw, this is not part of the PR) \n",
      "I am not entirely sure why this was thrown initially..., Label: 0\n",
      "Processing row 5132 - Data Type: train, Message: Regarding the \"throw an exception instead of returning a int as exitcode\": This could be an alternative, but I don't see any improvement over my approach. Because if you just throw an exception and let the JVM handle it, the JVM will implicitly set the exit code to \"1\". \n",
      "This would allow a binary state: Success or fail. But looking at the variety of calls to ```System.exit()``` in the various commands, I see more exit codes than just \"0\" and \"1\". I believe we even have \"-1\". \n",
      "Converting these cases all into throwing exceptions, we would also get changes in the behavior. Not to mention that java terminating a program with an exception is likely to change the output of the tool., Label: 0\n",
      "Processing row 5133 - Data Type: train, Message: agree, a left over from a previous test version. removed now, Label: 0\n",
      "Processing row 5134 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5135 - Data Type: val, Message: This is actually `false` by default.\n",
      "\n",
      "https://jackrabbit.apache.org/oak/docs/query/lucene.html#index-definition\n",
      "\n",
      "https://github.com/apache/jackrabbit-oak/blob/trunk/oak-search/src/main/java/org/apache/jackrabbit/oak/plugins/index/search/IndexDefinition.java#L428\n",
      "\n",
      "Do you see any problem with that?, Label: 1\n",
      "Processing row 5136 - Data Type: train, Message: See my previous comment., Label: 0\n",
      "Processing row 5137 - Data Type: train, Message: This method uses the same file that Mark phase uses where its essential to bail out if an error. Here though not very essential but not sure if a good idea to report inaccurate size. In rare case (as havent seen that kind of corrption in practice) that happens i think its ok to throw an error. , Label: 0\n",
      "Processing row 5138 - Data Type: val, Message: similar maybe`addTotalBlobReferencesSize`?, Label: 1\n",
      "Processing row 5139 - Data Type: train, Message: ack, Label: 0\n",
      "Processing row 5140 - Data Type: train, Message: Yes, it will continue to work. Modulo, on the other hand, behaves in a slightly weird way for negative numbers: you get negative reminders. But checking for (x % y) == 0 would still work fine., Label: 0\n",
      "Processing row 5141 - Data Type: train, Message: which part exactly is redundant?, Label: 1\n",
      "Processing row 5142 - Data Type: val, Message: reverted, Label: 0\n",
      "Processing row 5143 - Data Type: train, Message: I had left it to leave room for furture in case needed but not a strong opinion here., Label: 0\n",
      "Processing row 5144 - Data Type: train, Message: sure, Label: 0\n",
      "Processing row 5145 - Data Type: train, Message: Noted for the future! , Label: 0\n",
      "Processing row 5146 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5147 - Data Type: train, Message: These are different javadocs as compared to the one earlier which was copy-pasted from the interface. These java docs, explain the functionality of this method., Label: 0\n",
      "Processing row 5148 - Data Type: train, Message: Yes, I agree that there are some similarities between `findAndUpdate<bulk>` and `createOrUpdate<bulk>`, especially the code flow, but the similarities end there.\n",
      "\n",
      "The logic to calculate the resultSet, bulk API to call, updating the cache with updated documents, etc. are handled differently. \n",
      "\n",
      "In order to reuse `findAndModify` for both `findAndUpdate<single>` and `createOrUpdate<single>`, we use many boolean flags, and that IMHO only complicates the code., Label: 0\n",
      "Processing row 5149 - Data Type: train, Message: I have never seen this format for both stop words and comments. I don't even understand what the  `|` means in the configuration (example: `de             |  from, of`). It might be that lucene/elastic don't complain with a configuration like this but I am not sure about the results. I can create a test with this format but I am not sure about a query that proves this configuration., Label: 1\n",
      "Processing row 5150 - Data Type: train, Message: I added a comment to explain what this does. This function is not exposed outside this class. Introducing a SAM interface seems a bit too much here., Label: 0\n",
      "Processing row 5151 - Data Type: train, Message: I'd prefer to have it in for now? I was expecting (or let's say hoping) it to eventually be used, once we go more fancy with test coverage., Label: 1\n",
      "Processing row 5152 - Data Type: train, Message: Not it is not good enough.\n",
      "\n",
      "> The stack trace creates a lot more noise\n",
      "\n",
      "But it is needed. In the past, we have seem multiple cases where the caller was not sufficient. The stack trace is needed., Label: 0\n",
      "Processing row 5153 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5154 - Data Type: val, Message: Sorry, I will revert if you insist but will not do the additional overhead of creating another PR. For me things like these should be fixed along with the issues. In this case I fail to see risk of regression., Label: 0\n",
      "Processing row 5155 - Data Type: train, Message: @reschke Is changing this SPI method signature ok to only accept Map<String, ?> because that is the only one OSGi accepts (see https://docs.osgi.org/javadoc/r4v43/core/org/osgi/framework/BundleContext.html#registerService(java.lang.Class,%20S,%20java.util.Dictionary) or do we need to maintain backwards compatibility here as well?, Label: 1\n",
      "Processing row 5156 - Data Type: train, Message: Good point, I agree this should be addressed. Actually there's also the issue that `NodeStateEntryWriter` excludes the `:childOrder`.\n",
      "\n",
      "I'm not sure what the best approach is yet. Might have to do some iteration over this code.., Label: 1\n",
      "Processing row 5157 - Data Type: train, Message: I see. It's currently indeed a bit a mix between a utility class and an (writer) object - so actually the name might a bit off. But for now I don't see it doing other things than `createFlatFileFor`- so I tend to favour leaving it this way (but I agree, it's not the nicest class..), Label: 0\n",
      "Processing row 5158 - Data Type: train, Message: Yes, you are right. The method with this code already declares throwing `InterruptedException` and the caller is handling that exception explicitly, so the catch clause is not needed here. I removed it. , Label: 0\n",
      "Processing row 5159 - Data Type: train, Message: @kwin Would you take a look at the following lines? I wonder if MockBundleContext introduced a bug in the new version or if I'm missing something., Label: 1\n",
      "Processing row 5160 - Data Type: val, Message: I don't think that splitting will make it clearer though. The method has the check interwined also to check the higher code points are not split., Label: 0\n",
      "Processing row 5161 - Data Type: train, Message: I added a comment that explains this isn't a Lucene file., Label: 0\n",
      "Processing row 5162 - Data Type: train, Message: As this is from external code. So I didn't removed this. But yes there are methods we don't use., Label: 0\n",
      "Processing row 5163 - Data Type: train, Message: Now, it doesn't sort by default., Label: 0\n",
      "Processing row 5164 - Data Type: train, Message: It's not so simple to share the common code because it is creating several objects that we need during the test. In this case, I think it is not worth the effort to improve the code, some duplication is not a big issue here as this is testing code and the duplication is contained in the same file., Label: 0\n",
      "Processing row 5165 - Data Type: train, Message: This variable is used to reference two different objects. And I agree that the test could be improved, but I just copy'n'pasted the existing test and do not want to spend much more time in refactoring it. , Label: 0\n",
      "Processing row 5166 - Data Type: train, Message: If we pass null to the constructor, the `MetricStatisticsProvider` will use the `ManagementFactory.getPlatformMBeanServer()`. I think the problem here is lack of documentation on the construtor of `MetricStatisticsProvider`. I don't think this PR should correct the missing documentation. , Label: 0\n",
      "Processing row 5167 - Data Type: train, Message: I moved the executor to the top level, to be created before all tests and shutdown after the tests. There was a potential resource leak because I was not calling the shutdown method. For the `MetricStatisticsProvider`. I prefer to create it close to the code that does the testing. Almost all tests call this `runTest` method and the tests that don't do not need needs this object. So in this case, allocation of this helper object is closer to where they are used, which makes the logic simpler., Label: 0\n",
      "Processing row 5168 - Data Type: train, Message: Actually... I think the current code is clearer in this case: The \"not\" can be confusing., Label: 0\n",
      "Processing row 5169 - Data Type: train, Message: Of course ðŸ˜µâ€ðŸ’« , Label: 0\n",
      "Processing row 5170 - Data Type: train, Message: +1, renamed as suggested. wdyt?, Label: 0\n",
      "Processing row 5171 - Data Type: train, Message: Could you elaborate? I do not understand the suggestion., Label: 1\n",
      "Processing row 5172 - Data Type: train, Message: I have changed the code to read directly from the ByteBuffer instead of copying to an intermediate buffer, that is, to do this:\n",
      "```\n",
      "new String(buff.array(), pos, len, StandardCharsets.UTF_8);\n",
      "```\n",
      "However, the proposed solution of writing to the byte buffer the path segments separately just moves the work of splitting the string with the path into segments from the sort-batch thread into the transform thread, and it would complicate somewhat reading and writing to the ByteBuffer, which instead of having two strings for each entry (path and json) would now have n strings for the path and 1 for the json. Therefore, I will leave it as it is., Label: 0\n",
      "Processing row 5173 - Data Type: train, Message: I did this on purpose actually: to keep the old code as is as much as possible, in case we need to switch back to it. I agree it would be better, but hopefully we don't need the old code in the future - in which case we should remove it. I'm fine to create a jira issue about removing the old code in 6 month, so we don't forget. OK?, Label: 0\n",
      "Processing row 5174 - Data Type: train, Message: I prefer to avoid concurrency. it is filled when the first one is accessed, so I think it \"should be fine\". (I know, it sounds like \"famous last words\"), Label: 0\n",
      "Processing row 5175 - Data Type: train, Message: The CLUSTER one could remain as is in case we add support for other distributed systems such as mesos. The factory can return the right *AppLauncher based on the environment in CLUSTER mode? What do you think?\n",
      ", Label: 1\n",
      "Processing row 5176 - Data Type: train, Message: During app launch, the implementation methods such as prepareDAG throw plain Exception. Do you suggest to throw plain exception from launchApp or wrap it up with an unchecked exception. The latter might lead to the developer not preparing for errors during launch. If not throwing unchecked exception, why not throw a named exception which we could customize in the future with relevant information pertaining to launch failure.\n",
      ", Label: 1\n",
      "Processing row 5177 - Data Type: train, Message: Sounds good. What about api? Should Launcher go into org.apache.apex.engine as well?\n",
      ", Label: 1\n",
      "Processing row 5178 - Data Type: train, Message: Wouldn't that break backward compatibility?\n",
      ", Label: 1\n",
      "Processing row 5179 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 5180 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 5181 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 5182 - Data Type: train, Message: done\n",
      ", Label: 0\n",
      "Processing row 5183 - Data Type: val, Message: with additional parameter it is not needed. But let me know which is the preferred way?\n",
      ", Label: 1\n",
      "Processing row 5184 - Data Type: train, Message: I am returning default values as filename=null and offset=0, if right appender is not used.\n",
      "Even if I skip to emit filename, the ContainerErrorEvent and OperatorErrorEvent class beans are updated to have getter and setter for filename and offset. Due to which those fields will be read (check FSEventRecorder \"writeEvent\" function.). It uses BeanUtils.describe function and hence calls all getter.\n",
      "So I decided to add default values than skipping it., Label: 0\n",
      "Processing row 5185 - Data Type: train, Message: We have hardcoded \"RFA\" in our code (check classes StramClient and LaunchContainerRunnable), is it a good idea to look for \"RFA\" specifically? If RFA isn't found we should return \"null\"., Label: 1\n",
      "Processing row 5186 - Data Type: train, Message: I was little skeptical, if I put changes related to finding appenders and threshold in static code block will be be okay? If logger is initialized before that?, Label: 1\n",
      "Processing row 5187 - Data Type: train, Message: In that case we might end up either giving offset which is little before the actual log entry or our log entry never gets written to file, as container crashes immediately after logging.\n",
      "\n",
      "Should we disable our feature if immediateFlush == false ?, Label: 1\n",
      "Processing row 5188 - Data Type: train, Message: as msg do exist without name, offset (in cases when we have multiple appenders etc) I am keeping LogFileInformation separately., Label: 0\n",
      "Processing row 5189 - Data Type: train, Message: @vrozov I don't quite understand your example. If it is aggregation won't the operator emit less data. Do you mean like accumulation into a big collection as opposed to aggregation? Also, having back pressure doesn't mean no spooling, data can still get spooled once the subscribers have read the data. \n",
      "\n",
      "If we have back pressure as a per port setting, the first operator in the graph traversing from the input, that has the setting turned on will get blocked and its upstream operators will move forward and continue to process data. I don't see a big benefit to this as opposed to turning it off at a DAG level as the application would be pulling data in from the input source anyway., Label: 1\n",
      "Processing row 5190 - Data Type: train, Message: Why would it need to be disabled for aggregate output?, Label: 1\n",
      "Processing row 5191 - Data Type: val, Message: What you say makes sense but this is an oversight where there is space after one argument and no space after another in the same line. I had originally touched this line and hence made the change., Label: 1\n",
      "Processing row 5192 - Data Type: train, Message: Fixed, Label: 0\n",
      "Processing row 5193 - Data Type: train, Message: Removed, Label: 0\n",
      "Processing row 5194 - Data Type: train, Message: changed, Label: 0\n",
      "Processing row 5195 - Data Type: val, Message: Changed, Label: 0\n",
      "Processing row 5196 - Data Type: train, Message: changed code structure a bit., Label: 0\n",
      "Processing row 5197 - Data Type: train, Message: removed extra line., Label: 0\n",
      "Processing row 5198 - Data Type: train, Message: removed , Label: 0\n",
      "Processing row 5199 - Data Type: val, Message: done, Label: 0\n",
      "Processing row 5200 - Data Type: train, Message: It was added to have precise check if unifierMeta is null. I agree it would be detected on next statement but with extra stack of null pointer exceptions rather than intended check is for unifier count. Removed it., Label: 0\n",
      "Processing row 5201 - Data Type: train, Message: Fixed., Label: 0\n",
      "Processing row 5202 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5203 - Data Type: train, Message: Removing the log, as most of the information will be logged anyways, there is nothing new here., Label: 0\n",
      "Processing row 5204 - Data Type: val, Message: Thank you for the review comment. What do you think about the repetitive log message? According to me we should only have one log message (like we are having after these code changes).\n",
      ", Label: 1\n",
      "Processing row 5205 - Data Type: val, Message: Until this point, the contents of `operators` may be incorrect. If delay operator is present, likely any unifiers reachable from any of the `operators` need to be part of the group as well. In other words, if delay is part of the group, then  `operators` might change. , Label: 0\n",
      "Processing row 5206 - Data Type: train, Message: I saw that when delay is part of the group, the unifiers create a separate checkpoint group even though the upstream and downstream operators are in the same group which seems to be incorrect. In other cases, each of the operators form a separate group and the problem does not arise in that case., Label: 0\n",
      "Processing row 5207 - Data Type: val, Message: IMO if we have a dag like A -> B, where A is partitioned and A and B are in the same group, then the unifier should also be in the same group. Is this understanding correct?, Label: 1\n",
      "Processing row 5208 - Data Type: train, Message: done, Label: 0\n",
      "Processing row 5209 - Data Type: train, Message: Regarding \n",
      "1. sendContainerAskToRM is already overloaded, as kill request is sent to NM and not to RM, so adding more things to it will only complicate it further.\n",
      "2. We can't move this logic to NMCallbackHandler. This PR is because onContainerStopped may not have been called., Label: 0\n",
      "Processing row 5210 - Data Type: val, Message: @vrozov  there is a difference as I explained earlier.  The CUSTOM_SSL_KEYSTORE_CONFIG  setting used in this JIRA is only processed by the Apex CLI (Stram client) and so it doesn't need to be an attribute that any code on the App Master side needs to be aware of.\n",
      "\n",
      "As far as usability or user confusion goes, I think a setting/property is preferable to an attribute from usability point of view so @devtagare decided to use a setting here and I agree with that decision and personally I don't believe it is confusing., Label: 0\n",
      "Processing row 5211 - Data Type: train, Message: Addressed it., Label: 0\n",
      "Processing row 5212 - Data Type: train, Message: I'd vote for going with the way it currently behaves, which is shutting down an app if it is found, and if it is specified as argument twice: printing an error message on the second time, because the app is already shut down. , Label: 0\n",
      "Processing row 5213 - Data Type: train, Message: Added a comment below on how to go from here, Label: 0\n",
      "Processing row 5214 - Data Type: train, Message: Removing this method., Label: 0\n",
      "Processing row 5215 - Data Type: train, Message: Everything is working as expected, the issue was because of the bug while removing the code., Label: 0\n",
      "Processing row 5216 - Data Type: train, Message: Not required, changing it back., Label: 0\n",
      "Processing row 5217 - Data Type: train, Message: Done, Label: 0\n",
      "Processing row 5218 - Data Type: train, Message: fixed, Label: 0\n",
      "Processing row 5219 - Data Type: val, Message: fixed, Label: 0\n",
      "Processing row 5220 - Data Type: train, Message: Done, Label: 0\n"
     ]
    }
   ],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# # Replace 'model_name' with the name of the pre-trained model you're using\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# # Assuming you have a DataFrame named 'df'\n",
    "# for index, row in df.iterrows():\n",
    "#     data_type = row['data_type']\n",
    "#     message = row['comment']\n",
    "#     label = row['label']\n",
    "\n",
    "#     encoded_data = tokenizer.encode_plus(\n",
    "#         text=message,\n",
    "#         add_special_tokens=True,\n",
    "#         return_attention_mask=True,\n",
    "#         pad_to_max_length=True,\n",
    "#         max_length=256,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "\n",
    "#     input_ids = encoded_data['input_ids']\n",
    "#     attention_mask = encoded_data['attention_mask']\n",
    "    \n",
    "#     print(f\"Processing row {index + 1} - Data Type: {data_type}, Message: {message}, Label: {label}\")\n",
    "    \n",
    "#     # Here you can proceed with storing or processing 'input_ids', 'attention_mask', and 'label'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00940b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/mdr614/anaconda3/envs/toxic_gru/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='train'].comment.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "encoded_data_val = tokenizer.batch_encode_plus(\n",
    "    df[df.data_type=='val'].comment.values, \n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(df[df.data_type=='train'].label.values)\n",
    "\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(df[df.data_type=='val'].label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8ccf04ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
    "dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b499bb90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26111"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccff5eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4608"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7b4ab05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "68bfc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d6fd2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, \n",
    "                              sampler=RandomSampler(dataset_train), \n",
    "                              batch_size=batch_size)\n",
    "\n",
    "dataloader_validation = DataLoader(dataset_val, \n",
    "                                   sampler=SequentialSampler(dataset_val), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "339c8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0c94701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5, \n",
    "                  eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "01f3ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=0,\n",
    "                                            num_training_steps=len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a3d4ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87f127f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f0bfc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "63ac8eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dfe92cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c8835969",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in dataloader_val:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db5b24ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e013b36520c4596ad8aa6f595913518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "Training loss: 0.2395279289373909\n",
      "Validation loss: 0.19959874889213503\n",
      "F1 Score (Weighted): 0.9112990453593286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2\n",
      "Training loss: 0.17180071954834264\n",
      "Validation loss: 0.26256128419683794\n",
      "F1 Score (Weighted): 0.9093452163843835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3\n",
      "Training loss: 0.1288558309276114\n",
      "Validation loss: 0.3152433574806916\n",
      "F1 Score (Weighted): 0.9073013828192682\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4\n",
      "Training loss: 0.09207398843366665\n",
      "Validation loss: 0.38698983247053953\n",
      "F1 Score (Weighted): 0.9072636489031325\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1632 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5\n",
      "Training loss: 0.06854368936006615\n",
      "Validation loss: 0.4559595732719117\n",
      "F1 Score (Weighted): 0.9058740760258193\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    loss_train_total = 0\n",
    "\n",
    "    progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
    "    for batch in progress_bar:\n",
    "\n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }       \n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
    "         \n",
    "        \n",
    "    torch.save(model.state_dict(), f'finetuned_BERT_epoch_{epoch}.model')\n",
    "        \n",
    "    tqdm.write(f'\\nEpoch {epoch}')\n",
    "    \n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)             \n",
    "    tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted): {val_f1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b362e82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loss, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a955e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_flat = np.argmax(predictions, axis=1).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6729845",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
    "                                                      num_labels=len(label_dict),\n",
    "                                                      output_attentions=False,\n",
    "                                                      output_hidden_states=False)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "81149d75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('finetuned_BERT_MYDATA.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "49ca89b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, predictions, true_vals = evaluate(dataloader_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2471037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: 0\n",
      "Accuracy: 2850/3394\n",
      "\n",
      "Class: 1\n",
      "Accuracy: 1044/1214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ed27f7e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4608, 4608)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions), len(true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4dd7ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "60dff5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9051649305555556\n",
      "Precision: 0.8443163097199341\n",
      "Recall: 0.805184603299293\n",
      "f1 score 0.9044557850852919\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(preds_flat, true_vals))\n",
    "print(\"Precision:\",metrics.precision_score(preds_flat, true_vals))\n",
    "print(\"Recall:\",metrics.recall_score(preds_flat, true_vals))\n",
    "print(\"f1 score\", metrics.f1_score(preds_flat, true_vals, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58dfad4",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9096a859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>pullNumber</th>\n",
       "      <th>author</th>\n",
       "      <th>comment</th>\n",
       "      <th>path</th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pandas-dev_pandas</td>\n",
       "      <td>21318</td>\n",
       "      <td>pyryjook</td>\n",
       "      <td>Sure, Iâ€™ll make the change. Have to say that...</td>\n",
       "      <td>pandas/tests/io/json/test_json_table_schema.py</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>elastic_elasticsearch</td>\n",
       "      <td>42982</td>\n",
       "      <td>original-brownbear</td>\n",
       "      <td>Right ... obviously in my local testing I just...</td>\n",
       "      <td>plugins/repository-azure/qa/microsoft-azure-st...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pandas-dev_pandas</td>\n",
       "      <td>43056</td>\n",
       "      <td>debnathshoham</td>\n",
       "      <td>Hi @phofl , @attack68 .. I will work on these ...</td>\n",
       "      <td>pandas/tests/reshape/merge/test_merge.py</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>grpc_grpc</td>\n",
       "      <td>21988</td>\n",
       "      <td>lidizheng</td>\n",
       "      <td>Good idea for the optimization. Updated to fet...</td>\n",
       "      <td>src/python/grpcio/grpc/experimental/aio/_chann...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apache_incubator-mxnet</td>\n",
       "      <td>14359</td>\n",
       "      <td>haojin2</td>\n",
       "      <td>done</td>\n",
       "      <td>src/operator/contrib/index_copy.cc</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Project  pullNumber              author  \\\n",
       "0       pandas-dev_pandas       21318            pyryjook   \n",
       "1   elastic_elasticsearch       42982  original-brownbear   \n",
       "2       pandas-dev_pandas       43056       debnathshoham   \n",
       "3               grpc_grpc       21988           lidizheng   \n",
       "4  apache_incubator-mxnet       14359             haojin2   \n",
       "\n",
       "                                             comment  \\\n",
       "0  Sure, Iâ€™ll make the change. Have to say that...   \n",
       "1  Right ... obviously in my local testing I just...   \n",
       "2  Hi @phofl , @attack68 .. I will work on these ...   \n",
       "3  Good idea for the optimization. Updated to fet...   \n",
       "4                                               done   \n",
       "\n",
       "                                                path  actual  prediction  \n",
       "0     pandas/tests/io/json/test_json_table_schema.py       0           0  \n",
       "1  plugins/repository-azure/qa/microsoft-azure-st...       0           0  \n",
       "2           pandas/tests/reshape/merge/test_merge.py       1           0  \n",
       "3  src/python/grpcio/grpc/experimental/aio/_chann...       0           0  \n",
       "4                 src/operator/contrib/index_copy.cc       0           0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsx_file ='/u1/mdr614/On the compleness of review comments/Notebook_on the compleness/BERT_CONFU_AUTHOR/test_bert_author.xlsx' \n",
    "df_test = pd.read_excel(xlsx_file)\n",
    "#df_test = pd.read_csv(xlsx_file)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6c6a4bf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels = df_test.actual.unique()\n",
    "possible_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e0a27dae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0, 1: 1}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {0: 0, 1: 1}\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0d5e2c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f1f6a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['label'] = df_test.actual.replace(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9b05905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# import torch\n",
    "# import pandas as pd\n",
    "\n",
    "# # Replace 'model_name' with the name of the pre-trained model you're using\n",
    "# model_name = 'bert-base-uncased'\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# df_test = df_test[10000:]\n",
    "\n",
    "# # Assuming you have a DataFrame named 'df'\n",
    "# for index, row in df_test.iterrows():\n",
    "#     #data_type = row['data_type']\n",
    "#     message = row['comment']\n",
    "#     label = row['actual']\n",
    "\n",
    "#     encoded_data = tokenizer.encode_plus(\n",
    "#         text=message,\n",
    "#         add_special_tokens=True,\n",
    "#         return_attention_mask=True,\n",
    "#         pad_to_max_length=True,\n",
    "#         max_length=256,\n",
    "#         return_tensors='pt'\n",
    "#     )\n",
    "\n",
    "#     input_ids = encoded_data['input_ids']\n",
    "#     attention_mask = encoded_data['attention_mask']\n",
    "    \n",
    "#     print(f\"Processing row {index + 1}, Message: {message}, Label: {label}\")\n",
    "    \n",
    "#     # Here you can proceed with storing or processing 'input_ids', 'attention_mask', and 'label'\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f147843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mdr614/anaconda3/envs/toxic_gru/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2619: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# encoded_test_val = tokenizer.batch_encode_plus(\n",
    "#     df_test.comment.values, \n",
    "#     add_special_tokens=True, \n",
    "#     return_attention_mask=True, \n",
    "#     pad_to_max_length=True, \n",
    "#     max_length=256, \n",
    "#     return_tensors='pt'\n",
    "# )\n",
    "\n",
    "encoded_test_val = tokenizer.batch_encode_plus(\n",
    "    df_test.comment.values.tolist(),  # Convert NumPy array to list\n",
    "    add_special_tokens=True, \n",
    "    return_attention_mask=True, \n",
    "    pad_to_max_length=True, \n",
    "    max_length=256, \n",
    "    return_tensors='pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "649f32a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_test = encoded_test_val['input_ids']\n",
    "attention_masks_test = encoded_test_val['attention_mask']\n",
    "labels_test = torch.tensor(df_test.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "0e22eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = TensorDataset(input_ids_test, attention_masks_test,labels_test)\n",
    "batch_size = 8\n",
    "dataloader_test = DataLoader(dataset_test, \n",
    "                                   sampler=SequentialSampler(dataset_test), \n",
    "                                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b5c181b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(dataloader_test):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    for batch in dataloader_test:\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                'attention_mask': batch[1],\n",
    "                'labels':         batch[2],\n",
    "                }  \n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        logits = outputs[1]\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a38ecc60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "pred_test = test_model(dataloader_test) \n",
    "preds_flat_test = np.argmax(pred_test, axis=1).flatten()\n",
    "print(preds_flat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1a3699da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pred_data = pd.DataFrame(preds_flat_test, columns = [\"prediction\"])\n",
    "pd_cont = pd.concat([df_test[\"comment\"], pred_data], axis = 1)\n",
    "pd_cont.to_csv(\"test_bert_author_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c98ec1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86861"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0c3667e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16644"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2790ae22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1010</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1011</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1013</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1015 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction\n",
       "0              2\n",
       "1              0\n",
       "2              2\n",
       "3              2\n",
       "4              1\n",
       "...          ...\n",
       "1010           1\n",
       "1011           1\n",
       "1012           2\n",
       "1013           0\n",
       "1014           0\n",
       "\n",
       "[1015 rows x 1 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb8ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_slice = df_test[\"message\"]\n",
    "df_slice.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1bf974",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_cont_rst = pd.concat([df_slice.reset_index(), pred_data], axis = 1)\n",
    "pd_cont_rst.to_csv(\"done.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16be0a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "toxic_gru",
   "language": "python",
   "name": "toxic_gru"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
